The error message indicates that the 'Could not compute output' error occurred while using the `clone_model` function. The test case attempts to clone a model with multiple inputs and outputs, and associated layers including Lambda and SwapLayer. The issue is likely related to the way the method `_clone_functional_model` interacts with multiple input and output layers.

The potential error location within the `_clone_functional_model` function could be in the section where it iterates over every node in the reference model, in depth order. This is where it attempts to call the layer and compute the new tensors, but it may not handle multiple outputs correctly.

The reason for this bug could be that the function does not correctly handle layers with multiple inputs and outputs, such as the Lambda and SwapLayer in the test case. This leads to the assertion error when trying to compute the output tensors.

One possible approach for fixing the bug is to modify the logic in the `_clone_functional_model` function to correctly handle layers with multiple inputs and outputs. This may involve iterating through all the output tensors from a layer and ensuring that their corresponding tensors are computed and updated in the `tensor_map`.

Another approach could involve handling layers with multiple outputs in a separate conditional block to ensure that the computation of output tensors happens correctly.

Below is the corrected code for the `_clone_functional_model` function based on the suggested approach:

```python
# Corrected function
def _clone_functional_model(model, input_tensors=None):
    # ... (existing code)

    for x, y in zip(model.inputs, input_tensors):
        tensor_map[x] = (y, None)  # tensor, mask

    for depth in reversed(range(len(model._nodes_by_depth))):
        nodes = model._nodes_by_depth[depth]
        for node in nodes:
            # Recover the corresponding layer.
            layer = node.outbound_layer

            # Get or create layer.
            if layer not in layer_map:
                # Clone layer.
                new_layer = layer.__class__.from_config(layer.get_config())
                layer_map[layer] = new_layer
            else:
                # Reuse previously cloned layer.
                new_layer = layer_map[layer]
                # Don't call InputLayer multiple times.
                if isinstance(new_layer, InputLayer):
                    continue

            # Gather inputs to call the new layer.
            reference_input_tensors = node.input_tensors
            computed_data = []  # List of tuples (input, mask).
            for x in reference_input_tensors:
                if x in tensor_map:
                    computed_data.append(tensor_map[x])

            if len(computed_data) == len(reference_input_tensors):
                # Call layer.
                kwargs = node.arguments if node.arguments else {}
                computed_tensors = [x[0] for x in computed_data]
                computed_masks = [x[1] for x in computed_data]
                output_tensors = to_list(
                    new_layer(computed_tensors, **kwargs))
                computed_masks = to_list(
                    new_layer.compute_mask(computed_tensors,
                                           computed_masks))
                # Update tensor_map.
                for x, y, mask in zip(node.output_tensors,
                                      output_tensors,
                                      computed_masks):
                    tensor_map[x] = (y, mask)
    
    output_tensors = []
    for x in model.outputs:
        assert x in tensor_map, 'Could not compute output ' + str(x)
        tensor, mask = tensor_map[x]
        output_tensors.append(tensor)
    return Model(input_tensors, output_tensors, name=model.name)
```

In this corrected code, the iteration through the nodes has been adjusted to ensure that it correctly handles layers with multiple inputs and outputs. Additionally, the output tensors are computed and updated in the `tensor_map` as required, and the final model is returned with the correctly computed output tensors.