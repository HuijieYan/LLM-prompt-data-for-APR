The error occurs when the `test_clone_functional_model_with_multi_outputs` function is executed. The error message indicates that the output tensor from the `swap_layer_1` is not computed and the assertion fails.

The potential error location within the `_clone_functional_model` function is likely in the iteration over the nodes in the model and the creation of new layers. It seems that the tensor mapping and layer mapping might not be functioning correctly, leading to the failure to compute the output tensor from the `swap_layer_1`.

The reason behind this bug could be an issue with the mapping of tensors and layers when creating new layers during the iteration. Additionally, there might be problems with the retrieval and association of the input and output tensors for each layer.

To fix the bug, it's necessary to ensure that the input_tensors, tensor_map, and layer_map are created and populated correctly. Also, the iteration over the nodes and the handling of input/output tensors should be carefully reviewed to ensure that the mapping is accurately done.

Here's the corrected code for the `_clone_functional_model` function:

```python
def _clone_functional_model(model, input_tensors=None):
    if not isinstance(model, Model):
        raise ValueError('Expected `model` argument to be a `Model` instance, got ', model)

    layer_map = {}
    tensor_map = {}

    if input_tensors is None:
        input_layers = []
        input_tensors = []
        for layer in model._input_layers:
            input_tensor = Input(batch_shape=layer.input_shape, dtype=layer.dtype, sparse=layer.sparse, name=layer.name)
            input_tensors.append(input_tensor)
            layer_map[layer] = input_tensor
        for original, cloned in zip(model._input_layers, input_tensors):
            layer_map[original] = cloned
    else:
        input_tensors = to_list(input_tensors)
        for i, x in enumerate(input_tensors):
            if not K.is_keras_tensor(x):
                name = model._input_layers[i].name
                input_tensor = Input(tensor=x, name='input_wrapper_for_' + name)
                input_tensors[i] = input_tensor
                layer_map[input_tensors[i]] = input_tensor
        input_tensors = input_tensors

    for x, y in zip(model.inputs, input_tensors):
        tensor_map[x] = (y, None)

    for layer in model.layers:
        new_layer = layer.__class__.from_config(layer.get_config())
        layer_map[layer] = new_layer

    for node in model._nodes_by_depth[0]:
        output_tensors = []
        for input_tensor in node.inbound_layers:
            if input_tensor in tensor_map:
                output_tensors.append(tensor_map[input_tensor][0])

        computed_data = [(tensor_map[input_tensor][0], None) for input_tensor in node.input_tensors if input_tensor in tensor_map]

        if len(computed_data) == len(node.input_tensors):
            kwargs = node.arguments if node.arguments else {}
            output_tensors = to_list(new_layer(computed_data, **kwargs))
            for output_tensor, target_tensor in zip(node.output_tensors, output_tensors):
                tensor_map[output_tensor] = (target_tensor, None)

    output_tensors = []
    for x in model.outputs:
        assert x in tensor_map, 'Could not compute output ' + str(x)
        tensor, _ = tensor_map[x]
        output_tensors.append(tensor)
    return Model(input_tensors, output_tensors, name=model.name)
```