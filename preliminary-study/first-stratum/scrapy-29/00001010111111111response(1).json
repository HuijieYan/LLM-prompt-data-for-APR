{
    "scrapy": [
        {
            "bugID": 29,
            "bitvector": {
                "1.3.1": 0,
                "1.3.2": 0,
                "1.2.1": 0,
                "1.2.2": 0,
                "1.2.3": 1,
                "1.1.2": 0,
                "2.2.3": 1,
                "2.2.4": 0,
                "2.2.5": 1,
                "2.2.6": 1,
                "2.1.1": 1,
                "2.1.2": 1,
                "2.2.1": 1,
                "2.2.2": 1,
                "3.1.1": 1,
                "3.1.2": 1,
                "cot": 1
            },
            "start_line": 73,
            "file_name": "scrapy/utils/request.py",
            "replace_code": "def request_httprepr(request):\n    \n    from six.moves.urllib.parse import urlparse_cached, urlunparse\n    from scrapy.utils.python import to_bytes\n    parsed = urlparse_cached(request)\n    path = urlunparse(('', '', parsed.path or '/', parsed.params, parsed.query, ''))\n    s = to_bytes(request.method) + b\" \" + to_bytes(path) + b\" HTTP/1.1\\r\\n\"\n    hostname = parsed.netloc.split(':')[0]  # Extracting hostname from the netloc\n    s += b\"Host: \" + to_bytes(hostname) + b\"\\r\\n\"  # Using the extracted hostname\n    if request.headers:\n        s += request.headers.to_string() + b\"\\r\\n\"\n    s += b\"\\r\\n\"\n    s += request.body\n    return s"
        }
    ]
}