The error occurs when the `clone_model` function is called with a model that has multiple inputs and outputs combined with a `multi_gpu_model` call. This triggers a bug in the `_clone_functional_model` method, specifically at line 166, where it checks if the output tensor is in `tensor_map`.

The bug occurs because when the model contains a layer that doesn't support masks (in this case, the Lambda layer), the masks returned by `layer.compute_mask` are always `None`, which leads to an error in the comparison at line 166.

To fix this bug, we can modify the logic around handling layers that don't support masks. We can remove the check for masks if the layer does not support masks. Additionally, we should update the `output_masks` to correctly represent the absence of masks when they are supported.

Here's the corrected `_clone_functional_model` method:

```python
def _clone_functional_model(model, input_tensors=None):
    # ... (other code remains unchanged)

    for x, y in zip(model.inputs, input_tensors):
        tensor_map[x] = (y, None)  # tensor, mask

    # Iterated over every node in the reference model, in depth order.
    depth_keys = list(model._nodes_by_depth.keys())
    depth_keys.sort(reverse=True)
    for depth in depth_keys:
        nodes = model._nodes_by_depth[depth]
        for node in nodes:
            # Recover the corresponding layer.
            layer = node.outbound_layer

            # Get or create layer.
            if layer not in layer_map:
                # Clone layer.
                new_layer = layer.__class__.from_config(layer.get_config())
                layer_map[layer] = new_layer
                layer = new_layer
            else:
                # Reuse previously cloned layer.
                layer = layer_map[layer]
                # Don't call InputLayer multiple times.
                if isinstance(layer, InputLayer):
                    continue

            # Gather inputs to call the new layer.
            reference_input_tensors = node.input_tensors
            reference_output_tensors = node.output_tensors

            # If all previous input tensors are available in tensor_map,
            # then call node.inbound_layer on them.
            computed_data = []  # List of tuples (input, mask).
            for x in reference_input_tensors:
                if x in tensor_map:
                    computed_data.append(tensor_map[x])

            if len(computed_data) == len(reference_input_tensors):
                # Call layer.
                if node.arguments:
                    kwargs = node.arguments
                else:
                    kwargs = {}
                output_tensors = to_list(
                    layer([x[0] for x in computed_data], **kwargs))

                # Update tensor_map.
                for x, y in zip(reference_output_tensors, output_tensors):
                    tensor_map[x] = (y, None)  # tensor, mask

    # Instantiate a new model from inputs and outputs.
    output_tensors = []
    for x in model.outputs:
        assert x in tensor_map, 'Could not compute output ' + str(x)
        tensor, _ = tensor_map[x]
        output_tensors.append(tensor)
    return Model(input_tensors, output_tensors, name=model.name)
```

With these changes, the method should no longer raise an error when handling models with layers that don't support masks and should correctly compute the output tensors for cloning the model.

With the new correction in place, the issue reported by the user should be resolved, and the `assert` condition at line 166 should not fail.