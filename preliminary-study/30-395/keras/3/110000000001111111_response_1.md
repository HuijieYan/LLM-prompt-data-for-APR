The problem seems to occur in the `clone_model` function when using `multi_gpu_model` with `cpu_relocation=True`. The error message "Could not compute output Tensor" suggests that there is an issue with computing the output of the cloned model.

The potential error location within the problematic function is likely the loop where the output tensors are computed. The error message indicates that the output masks are always `None`, when they are expected to be `[None, None]`. This could be due to the fact that the specific layer being used (in this case, a Lambda layer) does not support using masks.

To fix the bug, the code should be modified to handle the case where the layer does not support using masks, ensuring that the output masks are set correctly.

Here is the corrected code for the problematic function:

```python
def _clone_functional_model(model, input_tensors=None):
    # original code
    # ...

    for x, y, mask in zip(reference_output_tensors, output_tensors, output_masks):
        tensor_map[x] = (y, mask)
        
    # corrected code
    for x, y in zip(reference_output_tensors, output_tensors):
        tensor_map[x] = (y, None)  # set the output mask to None
    # ...
```

In this corrected code, the output mask for each tensor is explicitly set to `None` when the layer does not support using masks. This approach ensures that the output masks are correctly handled, addressing the issue of "Could not compute output Tensor" when using `clone_model` in combination with `multi_gpu_model` and `cpu_relocation=True`.