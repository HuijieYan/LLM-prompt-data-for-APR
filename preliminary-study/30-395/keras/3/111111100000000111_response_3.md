1. The test case provided in the issue calls `clone_model` on a model created using a lambda layer that returns multiple outputs. When calling `clone_model`, it raises an "AssertionError: Could not compute output Tensor" due to the lambda layer not supporting masks.

2. The potential error location within the problematic function is the section that computes the output masks for each layer in the model.

3. The bug occurs because the `clone_functional_model` function does not handle cases where a layer does not support masks, causing it to always return None for the output masks of certain layers. This, in turn, leads to the "Could not compute output Tensor" error when calling `clone_model` on a model that uses such layers.

4. Possible approaches for fixing the bug include:
   a. Checking if the layer supports masks before attempting to compute masks for the layer. If the layer does not support masks, it should skip the mask computation step.
   b. Handling the case of layers without mask support differently to prevent the error from occurring.

5. Corrected code for the problematic function `clone_functional_model`:

```python
import numpy as np

def _clone_functional_model(model, input_tensors=None):
    # Previous code

    for x, y in zip(model.inputs, input_tensors):
        tensor_map[x] = (y, None)  # tensor, mask

    # Iterated over every node in the reference model, in depth order.
    depth_keys = list(model._nodes_by_depth.keys())
    depth_keys.sort(reverse=True)
    for depth in depth_keys:
        nodes = model._nodes_by_depth[depth]
        for node in nodes:
            # Recover the corresponding layer.
            layer = node.outbound_layer

            # Get or create layer.
            if layer not in layer_map:
                # Clone layer.
                new_layer = layer.__class__.from_config(layer.get_config())
                layer_map[layer] = new_layer
                layer = new_layer
            else:
                # Reuse previously cloned layer.
                layer = layer_map[layer]
                # Don't call InputLayer multiple times.
                if isinstance(layer, InputLayer):
                    continue

            # Gather inputs to call the new layer.
            reference_input_tensors = node.input_tensors
            reference_output_tensors = node.output_tensors

            # If all previous input tensors are available in tensor_map,
            # then call node.inbound_layer on them.
            computed_data = []  # List of tuples (input, mask).
            for x in reference_input_tensors:
                if x in tensor_map:
                    computed_data.append(tensor_map[x])

            if len(computed_data) == len(reference_input_tensors):
                # Call layer.
                if node.arguments:
                    kwargs = node.arguments
                else:
                    kwargs = {}
                
                computed_tensors = [x[0] for x in computed_data]
                output_tensors = to_list(
                    layer(computed_tensors, **kwargs))
                
                # Update tensor_map.
                for x, y in zip(reference_output_tensors, output_tensors):
                    tensor_map[x] = (y, None)  # No mask support, so mask is None

    # Check that we did compute the model outputs,
    # then instantiate a new model from inputs and outputs.
    output_tensors = []
    for x in model.outputs:
        assert x in tensor_map, 'Could not compute output ' + str(x)
        tensor, _ = tensor_map[x]
        output_tensors.append(tensor)
    return Model(input_tensors, output_tensors, name=model.name)
```

In the corrected code, when computing the output tensors for the layers, the code no longer attempts to compute masks for each layer. Instead, it directly adds the output tensor to the `tensor_map` with a None mask, indicating that the layer does not support masks. This modification addresses the bug by handling layers without mask support differently.