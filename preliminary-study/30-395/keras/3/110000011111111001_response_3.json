{
    "keras": [
        {
            "bugID": 3,
            "bitvector": {
                "1.1.1": 1,
                "1.1.2": 1,
                "1.2.1": 0,
                "1.2.2": 0,
                "1.2.3": 0,
                "1.3.1": 0,
                "1.3.2": 0,
                "1.4.1": 1,
                "1.4.2": 1,
                "2.1.1": 1,
                "2.1.2": 1,
                "2.1.3": 1,
                "2.1.4": 1,
                "2.1.5": 1,
                "2.1.6": 1,
                "3.1.1": 0,
                "3.1.2": 0,
                "cot": 1
            },
            "strata": {
                "1": 1,
                "2": 0,
                "3": 0,
                "4": 1,
                "5": 1,
                "6": 0,
                "7": 1
            },
            "available_bitvector": {
                "1.1.1": 1,
                "1.1.2": 1,
                "1.2.1": 0,
                "1.2.2": 0,
                "1.2.3": 0,
                "1.3.1": 0,
                "1.3.2": 0,
                "1.4.1": 1,
                "1.4.2": 1,
                "2.1.1": 1,
                "2.1.2": 1,
                "2.1.3": 0,
                "2.1.4": 0,
                "2.1.5": 1,
                "2.1.6": 1,
                "3.1.1": 0,
                "3.1.2": 0,
                "cot": 1
            },
            "available_strata": {
                "1": 1,
                "2": 0,
                "3": 0,
                "4": 1,
                "5": 1,
                "6": 0,
                "7": 1
            },
            "start_line": 26,
            "file_name": "keras/models.py",
            "replace_code": "def _clone_functional_model(model, input_tensors=None):\n    from tensorflow.python.eager.backprop import has_tape\n    if not isinstance(model, Model):\n        raise ValueError('Expected `model` argument to be a `Model` instance, got ', model)\n    if isinstance(model, Sequential):\n        raise ValueError('Expected `model` argument to be a functional `Model` instance, got a `Sequential` instance instead:', model)\n    \n    layer_map = {}  # Cache for created layers.\n    tensor_map = {}  # Map {reference_tensor: (corresponding_tensor, mask)}\n    \n    if input_tensors is None:\n        input_layers = []\n        input_tensors = []\n        for layer in model._input_layers:\n            input_tensor = Input(batch_shape=layer.batch_input_shape,\n                                 dtype=layer.dtype,\n                                 sparse=layer.sparse,\n                                 name=layer.name)\n            input_tensors.append(input_tensor)\n            # Cache newly created input layer.\n            newly_created_input_layer = input_tensor._keras_history[0]\n            layer_map[layer] = newly_created_input_layer\n            \n        for _original, _cloned in zip(model._input_layers, input_tensors):\n            layer_map[_original] = _cloned\n    \n    else:\n        input_tensors = to_list(input_tensors)\n        _input_tensors = []\n        \n        for i, x in enumerate(input_tensors):\n            if not K.is_keras_tensor(x):\n                name = model._input_layers[i].name\n                input_tensor = Input(tensor=x,\n                                     name='input_wrapper_for_' + name)\n                _input_tensors.append(input_tensor)\n                \n                original_input_layer = x._keras_history[0]\n                newly_created_input_layer = input_tensor._keras_history[0]\n                layer_map[original_input_layer] = newly_created_input_layer\n            else:\n                _input_tensors.append(x)\n    \n        input_tensors = _input_tensors\n    \n    for x, y in zip(model.inputs, input_tensors):\n        tensor_map[x] = (y, None)  # tensor, mask\n    \n    # Iterate over every node in the reference model, in reverse depth order\n    nodes = []\n    for layer in reversed(model.layers):\n        for node_outbound in layer._outbound_nodes:\n            if isinstance(node_outbound, list):\n                for node in node_outbound:\n                    nodes.append(node)\n            else:\n                nodes.append(node_outbound)\n    \n    for node in nodes:\n    \n        layer = node.outbound_layer\n        if layer not in layer_map:\n            new_layer = layer.__class__.from_config(layer.get_config())\n            layer_map[layer] = new_layer\n            layer = new_layer\n        else:\n            layer = layer_map[layer]\n            if isinstance(layer, InputLayer):\n                continue\n    \n        reference_input_tensors = []\n        reference_output_tensors = []\n        \n        for inbound_index, inbound_node in enumerate(node.inbound_layers):\n            inbound_tensor_index = node.input_tensors[inbound_index]\n            x = inbound_node.inbound_nodes.index(node)\n            inbound_tensor = inbound_node.inbound_tensors[x]\n            \n            if inbound_tensor in tensor_map:\n                reference_input_tensors.append(inbound_tensor)\n                reference_output_tensors.append(inbound_tensor)\n        \n        computed_data = []\n        if len(reference_input_tensors) == len(node.input_tensors):\n            for x in reference_input_tensors:\n                computed_data.append(tensor_map[x])\n    \n        if len(computed_data) == len(reference_input_tensors):\n            if node.arguments:\n                kwargs = node.arguments\n            else:\n                kwargs = {}\n                \n            if len(computed_data) == 1:\n                computed_tensor, computed_mask = computed_data[0]\n                \n                if has_arg(layer.call, 'mask'):\n                    if 'mask' not in kwargs:\n                        kwargs['mask'] = computed_mask\n    \n                output_tensors = to_list(layer(computed_tensor, **kwargs))\n                output_masks = to_list(layer.compute_mask(computed_tensor, computed_mask))\n                computed_tensors = [computed_tensor]\n                computed_masks = [computed_mask]\n            else:\n                computed_tensors = [x[0] for x in computed_data]\n                computed_masks = [x[1] for x in computed_data]\n                if has_arg(layer.call, 'mask'):\n                    if 'mask' not in kwargs:\n                        kwargs['mask'] = computed_masks\n    \n                output_tensors = to_list(layer(computed_tensors, **kwargs))\n                output_masks = to_list(layer.compute_mask(computed_tensors, computed_masks))\n    \n            for k, (x, y) in enumerate(zip(reference_output_tensors, output_tensors)):\n                tensor_map[x] = (y, output_masks[k])\n    \n    output_tensors = [tensor_map[x][0] for x in model.outputs]\n    return Model(inputs=input_tensors, outputs=output_tensors)"
        }
    ]
}