The bug lies in the overridden `get_indexer` method of the `IntervalIndex` class. It is failing to handle the case when the columns are of type `CategoricalIndex` created from an `IntervalIndex`. This results in a `TypeError: No matching signature found` when using the `round` method on the DataFrame.

The issue arises due to the `get_indexer` method expecting a specific signature that is not being met when dealing with the `CategoricalIndex` created from an `IntervalIndex`.

To fix this bug, we need to modify the `get_indexer` method to handle the case when the input `target` is of type `CategoricalIndex`. We need to incorporate the necessary logic to properly handle the `CategoricalIndex` created from an `IntervalIndex` and return the correct result.

Here's the corrected version of the `get_indexer` method:

```python
@Appender(_index_shared_docs["get_indexer"])
def get_indexer(
    self,
    target: AnyArrayLike,
    method: Optional[str] = None,
    limit: Optional[int] = None,
    tolerance: Optional[Any] = None,
) -> np.ndarray:

    if isinstance(target, CategoricalIndex):
        target_as_index = ensure_index(target._codes)
    else:
        target_as_index = ensure_index(target)

    self._check_method(method)

    if self.is_overlapping:
        msg = (
            "cannot handle overlapping indices; use "
            "IntervalIndex.get_indexer_non_unique"
        )
        raise InvalidIndexError(msg)

    if isinstance(target_as_index, IntervalIndex):
        # rest of the logic remains the same
        # ...

    return ensure_platform_int(indexer)
```

In this corrected version, we handle the specific case when the input `target` is of type `CategoricalIndex` by converting it to an `IntervalIndex` using `ensure_index(target._codes)` and then proceeding with the existing logic.

This updated logic should resolve the issue and allow the `round` method to work correctly when the columns are of type `CategoricalIndex` created from an `IntervalIndex`. This fix satisfies the expected input/output variable information and should also resolve the issue reported in the GitHub bug.