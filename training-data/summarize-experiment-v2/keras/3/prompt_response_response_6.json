{
    "keras": [
        {
            "bugID": 3,
            "start_line": 26,
            "file_name": "keras/models.py",
            "replace_code": "def _clone_functional_model(model, input_tensors=None):\n    if not isinstance(model, Model):\n        raise ValueError('Expected `model` argument to be a `Model` instance, got ', model)\n    if isinstance(model, Sequential):\n        raise ValueError('Expected `model` argument to be a functional `Model` instance, got a `Sequential` instance instead:', model)\n\n    new_input_tensors = []\n    layer_map = {}\n    tensor_map = {}\n\n    if input_tensors is None:\n        input_tensors = [Input(batch_shape=layer.batch_input_shape, dtype=layer.dtype, sparse=layer.sparse, name=layer.name) for layer in model._input_layers]\n    else:\n        input_tensors = to_list(input_tensors)\n        for i, x in enumerate(input_tensors):\n            if not K.is_keras_tensor(x):\n                name = model._input_layers[i].name\n                input_tensor = Input(tensor=x, name='input_wrapper_for_' + name)\n                input_tensors[i] = input_tensor\n\n    for original, cloned in zip(model._input_layers, input_tensors):\n        layer_map[original] = cloned\n\n    for x, y in zip(model.inputs, input_tensors):\n        tensor_map[x] = (y, None)\n\n    # Cloning the model's layers\n    for layer in model.layers:\n        new_layer = layer.__class__.from_config(layer.get_config())\n        layer_map[layer] = new_layer\n\n    new_outputs = [layer_map[output] for output in model.outputs]\n    return Model(input_tensors, new_outputs, name=model.name)",
            "import_list": [
                "from . import backend as K",
                "from .utils.generic_utils import has_arg",
                "from .utils.generic_utils import to_list",
                "from .engine.input_layer import Input",
                "from .engine.input_layer import InputLayer",
                "from .engine.training import Model",
                "from .engine.sequential import Sequential"
            ]
        }
    ]
}