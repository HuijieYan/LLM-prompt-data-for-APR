{
    "scrapy": [
        {
            "bugID": 29,
            "bitvector": {
                "1.1.1": 1,
                "1.1.2": 1,
                "1.2.1": 0,
                "1.2.2": 0,
                "1.2.3": 0,
                "1.3.1": 1,
                "1.3.2": 1,
                "1.4.1": 0,
                "1.4.2": 0,
                "2.1.1": 0,
                "2.1.2": 0,
                "2.1.3": 0,
                "2.1.4": 0,
                "2.1.5": 0,
                "2.1.6": 0,
                "3.1.1": 0,
                "3.1.2": 0,
                "cot": 0
            },
            "strata": {
                "1": 1,
                "2": 0,
                "3": 1,
                "4": 0,
                "5": 0,
                "6": 0,
                "7": 0
            },
            "available_bitvector": {
                "1.1.1": 1,
                "1.1.2": 1,
                "1.2.1": 0,
                "1.2.2": 0,
                "1.2.3": 0,
                "1.3.1": 1,
                "1.3.2": 0,
                "1.4.1": 0,
                "1.4.2": 0,
                "2.1.1": 0,
                "2.1.2": 0,
                "2.1.3": 0,
                "2.1.4": 0,
                "2.1.5": 0,
                "2.1.6": 0,
                "3.1.1": 0,
                "3.1.2": 0,
                "cot": 0
            },
            "available_strata": {
                "1": 1,
                "2": 0,
                "3": 1,
                "4": 0,
                "5": 0,
                "6": 0,
                "7": 0
            },
            "start_line": 73,
            "file_name": "scrapy/utils/request.py",
            "replace_code": "def request_httprepr(request: Request) -> bytes:\n    \"\"\"Return the raw HTTP representation (as bytes) of the given request.\n    This is provided only for reference since it's not the actual stream of\n    bytes that will be sent when performing the request (that's controlled\n    by Twisted).\n    \"\"\"\n    parsed = urlparse_cached(request.url)\n    path = urlunparse(('', '', parsed.path or '/', parsed.params, parsed.query, ''))\n    s = request.method + \" \" + path.encode('utf-8') + \" HTTP/1.1\\r\\n\".encode('utf-8')\n    s += \"Host: \".encode('utf-8') + parsed.hostname.encode('utf-8') + \"\\r\\n\".encode('utf-8')\n    if request.headers:\n        s += b\"\".join([f\"{header}:{val}\\r\\n\".encode('utf-8') for header, val in request.headers.items()])\n    s += b\"\\r\\n\" + request.body\n    return s",
            "imports": [
                "from scrapy.utils.url import urlparse_cached, urlunparse",
                "from scrapy.http import Request"
            ]
        }
    ]
}