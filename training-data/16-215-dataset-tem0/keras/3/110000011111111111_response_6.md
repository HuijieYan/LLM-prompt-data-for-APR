The bug in the `_clone_functional_model` function seems to be related to the creation of new layers and the mapping of input and output tensors. The error message indicates that the output tensor `Tensor("swap_layer_1/Identity:0", shape=(?, 4), dtype=float32)` could not be computed.

The failing test `test_clone_functional_model_with_multi_outputs` creates a model with multiple inputs and outputs, including a custom `SwapLayer` which swaps the inputs. The error occurs when trying to clone the model using `keras.models.clone_model`.

The input parameters and variables at the function's return indicate that the issue might be related to the mapping of input and output tensors, as well as the creation of new layers.

The GitHub issue also provides insight into the cause of the bug, mentioning that the error appears when using a functional model with a layer that has multiple outputs without mask support.

To fix the bug, the function `_clone_functional_model` needs to be modified to properly handle the creation of new layers and the mapping of input and output tensors, especially in cases where layers have multiple outputs without mask support.

Here's the corrected code for the `_clone_functional_model` function:

```python
def _clone_functional_model(model, input_tensors=None):
    if not isinstance(model, Model):
        raise ValueError('Expected `model` argument to be a `Model` instance, got ', model)

    layer_map = {}  # Cache for created layers.
    tensor_map = {}  # Map {reference_tensor: (corresponding_tensor, mask)}

    if input_tensors is None:
        input_tensors = [Input(batch_shape=layer.batch_input_shape, dtype=layer.dtype, sparse=layer.sparse, name=layer.name) for layer in model._input_layers]
    else:
        input_tensors = [Input(tensor=x, name='input_wrapper_for_' + model._input_layers[i].name) if not K.is_keras_tensor(x) else x for i, x in enumerate(input_tensors)]

    for x, y in zip(model.inputs, input_tensors):
        tensor_map[x] = (y, None)  # tensor, mask

    for depth in sorted(model._nodes_by_depth.keys(), reverse=True):
        for node in model._nodes_by_depth[depth]:
            layer = node.outbound_layer

            if layer not in layer_map:
                new_layer = layer.__class__.from_config(layer.get_config())
                layer_map[layer] = new_layer
            else:
                new_layer = layer_map[layer]

            reference_input_tensors = node.input_tensors
            reference_output_tensors = node.output_tensors

            computed_data = [(tensor_map[x][0], None) for x in reference_input_tensors if x in tensor_map]

            if len(computed_data) == len(reference_input_tensors):
                kwargs = node.arguments if node.arguments else {}
                computed_tensors = [x[0] for x in computed_data]
                output_tensors = to_list(new_layer(computed_tensors, **kwargs))
                for x, y in zip(reference_output_tensors, output_tensors):
                    tensor_map[x] = (y, None)

    output_tensors = [tensor_map[x][0] for x in model.outputs]
    return Model(input_tensors, output_tensors, name=model.name)
```

This corrected code should address the issues related to creating new layers and mapping input and output tensors. It should pass the failing test and resolve the issue reported in the GitHub post.