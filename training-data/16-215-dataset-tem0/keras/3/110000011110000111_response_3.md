The buggy function `_clone_functional_model` is used to clone a functional `Model` instance. The failing test `test_clone_functional_model_with_multi_outputs` is trying to clone a model with multiple outputs, but it is encountering an error when calling `keras.models.clone_model(model)`.

The error message indicates that the output tensor of the `SwapLayer` is not being computed, leading to an assertion error. This is likely due to the way the function is handling layers with multiple outputs and the creation of new layers.

The GitHub issue also provides additional context, suggesting that the error may be related to the handling of layers with multiple outputs and the lack of mask support for certain layers.

To fix the bug, the function `_clone_functional_model` needs to be modified to properly handle layers with multiple outputs and address the issue with mask support for certain layers.

Here's the corrected code for the problematic function:

```python
def _clone_functional_model(model, input_tensors=None):
    if not isinstance(model, Model):
        raise ValueError('Expected `model` argument to be a `Model` instance, got ', model)

    layer_map = {}  # Cache for created layers.
    tensor_map = {}  # Map {reference_tensor: (corresponding_tensor, mask)}

    if input_tensors is None:
        input_tensors = [Input(batch_shape=layer.batch_input_shape, dtype=layer.dtype, sparse=layer.sparse, name=layer.name) for layer in model._input_layers]

    for original, cloned in zip(model._input_layers, input_tensors):
        layer_map[original] = cloned

    for x, y in zip(model.inputs, input_tensors):
        tensor_map[x] = (y, None)  # tensor, mask

    for layer in model.layers:
        if layer not in layer_map:
            new_layer = layer.__class__.from_config(layer.get_config())
            layer_map[layer] = new_layer

    for node in model._nodes_by_depth:
        for layer in node.outbound_layer:
            if layer not in layer_map:
                new_layer = layer.__class__.from_config(layer.get_config())
                layer_map[layer] = new_layer

    for node in model._nodes_by_depth:
        for layer in node.outbound_layer:
            reference_input_tensors = node.input_tensors
            reference_output_tensors = node.output_tensors

            computed_data = []
            for x in reference_input_tensors:
                if x in tensor_map:
                    computed_data.append(tensor_map[x])

            if len(computed_data) == len(reference_input_tensors):
                kwargs = node.arguments if node.arguments else {}
                computed_tensors = [x[0] for x in computed_data]
                computed_masks = [x[1] for x in computed_data] if len(computed_data) > 1 and has_arg(layer.call, 'mask') else None
                output_tensors = to_list(layer(computed_tensors, **kwargs))
                output_masks = to_list(layer.compute_mask(computed_tensors, computed_masks)) if computed_masks else [None] * len(output_tensors)

                for x, y, mask in zip(reference_output_tensors, output_tensors, output_masks):
                    tensor_map[x] = (y, mask)

    output_tensors = [tensor_map[x][0] for x in model.outputs]
    return Model(input_tensors, output_tensors, name=model.name)
```

This corrected function should now properly handle layers with multiple outputs and address the issue with mask support for certain layers. It should pass the failing test and resolve the issue reported in the GitHub post.