```python
def rnn(step_function, inputs, initial_states,
        go_backwards=False, mask=None, constants=None,
        unroll=False, input_length=None):
    """Iterates over the time dimension of a tensor.

    # Arguments
        step_function: RNN step function.
        .
        .
        .
        # Returns
            A tuple, `(last_output, outputs, new_states)`.

                last_output: the latest output of the rnn, of shape `(samples, ...)`
                outputs: tensor with shape `(samples, time, ...)` where each
                    entry `outputs[s, t]` is the output of the step function
                    at time `t` for sample `s`.
                new_states: list of tensors, latest states returned by
                    the step function, of shape `(samples, ...)`.

    # Raises
        ValueError: if input dimension is less than 3.
        ValueError: if `unroll` is `True` but input timestep is not a fixed number.
        ValueError: if `mask` is provided (not `None`) but states is not provided
            (`len(states)` == 0).
    """
    import tensorflow as tf
    import tensorflow.python.ops.control_flow_ops as control_flow_ops
    import tensorflow.python.ops.tensor_array_ops as tensor_array_ops
    
    def reverse(x, axes):
        return tf.reverse(x, axis=axes)
    
    def expand_dims(x, axis=-1):
        return tf.expand_dims(x, axis=axis)
    
    def zeros_like(x):
        return tf.zeros_like(x)
    
    def cast(x, dtype):
        return tf.cast(x, dtype=dtype)
    
    def stack(x, axis=0):
        return tf.stack(x, axis=axis)
    
    def _step(time, output_ta_t, *states):
        # ... omitted code ...
        pass
    
    def unstack(input_tensor):
        return tf.unstack(input_tensor)
    
    def tile(x, n):
        return tf.tile(x, n)
    
    def transpose(x):
        return tf.transpose(x)
    
    def rnn_change_data(inputs):
        shape = list(inputs.get_shape())
        axes = [1, 0]
        axes.extend(list(range(2, len(shape))))
        return tf.transpose(inputs, perm=axes)
    
    def rnn_change_mask(mask, axes):
        if mask.dtype != tf.bool:
            mask = cast(mask, tf.bool)
        if len(mask.get_shape()) == len(axes) - 1:
            mask = expand_dims(mask)
        return tf.transpose(mask, axes)
    
    def rnn_initial_constants(constants):
        if constants is None:
            return []
        return constants
    
    def rnn_change_inputs_go_backwards(input_list, go_backwards):
        if go_backwards:
            input_list = reverse(input_list, axis=0)
        return input_list
    
    def rnn_body_func_with_mask(inp, mask_ta, states):
        current_input = inp
        mask_t = mask_ta.read(time)
        output, new_states = step_function(current_input, states + constants)
        if getattr(output, '_uses_learning_phase', False):
            global uses_learning_phase
            uses_learning_phase = True
        return create_result(output, states, new_states, mask_t, mask_t, mask_t, zeros_like(output), output_ta_t)
    
    def rnn_body_func_without_mask(inp, states):
        current_input = inp
        output, new_states = step_function(current_input, states + constants)
        if getattr(output, '_uses_learning_phase', False):
            global uses_learning_phase
            uses_learning_phase = True
        return create_result(output, states, new_states, None, states[0], None, None, output_ta_t)
    
    def rnn_loop(time, input_ta, output_ta, states, mask_ta=None):
        if mask_ta is not None:
            return rnn_body_func_with_mask(input_ta.read(time), mask_ta, states)
        else:
            return rnn_body_func_without_mask(input_ta.read(time), states)
    
    def create_result(output, return_states, new_states, tiled_mask_t, prev_output, output_ta_t, modified_states, modified_outputs):
        output = tf.where(tiled_mask_t, output, prev_output)
        return_states = [tf.where(tiled_mask_t, new_states[i], modified_states[i]) for i in range(len(return_states))]
        modified_outputs = stack([output, output])
        modified_states = return_states
        result = control_flow_ops.while_loop(rnn_condition, rnn_loop, loop_vars, parallel_iterations=32, swap_memory=True)
        return modified_outputs, modified_states
    
    def rnn_condition(time, *_):
        return time < time_steps
    
    def tensor_array(stack, size, output_dtype, tensor_array_name):
        return stack(dtype=output_dtype, size=size, tensor_array_name=tensor_array_name)
    
    def rnn_unroll_with_mask(input_list, mask_list):
        successive_states = []
        successive_outputs = []
        if go_backwards:
            input_list = reverse(input_list, axis=0)
            mask_list = reverse(mask_list, axis=0)
        for inp, mask_t in zip(input_list, mask_list):
            output, new_states = step_function(inp, states + constants)
            if getattr(output, '_uses_learning_phase', False):
                uses_learning_phase = True
            tiled_mask_t = tile(mask_t, tf.stack([1, tf.shape(output)[1]]))
            if not successive_outputs:
                prev_output = zeros_like(output)
            else:
                prev_output = successive_outputs[-1]
            output, successive_states = create_result(output, states, new_states, tiled_mask_t, prev_output, output, states, successive_states)
        last_output = successive_outputs[-1]
        new_states = successive_states[-1]
        outputs = stack(successive_outputs)
        return last_output, outputs, new_states
    
    def rnn_unroll_without_mask(input_list):
        states = initial_states
        successive_states = []
        successive_outputs = []
        for inp in input_list:
            output, states = step_function(inp, states + constants)
            if getattr(output, '_uses_learning_phase', False):
                uses_learning_phase = True
            successive_outputs.append(output)
            successive_states.append(states)
        last_output = successive_outputs[-1]
        new_states = successive_states[-1]
        outputs = stack(successive_outputs)
        return last_output, outputs, new_states
    
    def rnn_transpose(outputs, axes):
        return tf.transpose(outputs, axes)
    
    def main_rn_function():
        if go_backwards:
            inputs = reverse(inputs, 0)
        states = tuple(initial_states)
        time_steps = tf.shape(inputs)[0]
        outputs, _ = step_function(inputs[0], initial_states + constants)
        output_ta = tensor_array(tensor_array_ops.TensorArray, time_steps, outputs.dtype, 'output_ta')
        input_ta = tensor_array(tensor_array_ops.TensorArray, time_steps, inputs.dtype, 'input_ta')
        input_ta = input_ta.unstack(inputs)
        time = tf.constant(0, dtype='int32', name='time')

        if mask is not None:
            if not states:
                raise ValueError('No initial states provided! '
                                 'When using masking in an RNN, you should '
                                 'provide initial states '
                                 '(and your step function should return '
                                 'as its first state at time `t` '
                                 'the output at time `t-1`).')
            if go_backwards:
                mask = reverse(mask, 0)
            mask_ta = tensor_array(tensor_array_ops.TensorArray, time_steps, tf.bool, 'mask_ta')
            mask_ta = mask_ta.unstack(mask)
    
            return rnn_unroll_with_mask(input_ta, mask_ta)
        else:
            return rnn_unroll_without_mask(input_ta)

    return main_rn_function()
```