{
    "keras": [
        {
            "bugID": 26,
            "bitvector": {
                "1.1.1": 1,
                "1.1.2": 1,
                "1.2.1": 1,
                "1.2.2": 1,
                "1.2.3": 1,
                "1.3.1": 0,
                "1.3.2": 0,
                "1.4.1": 1,
                "1.4.2": 1,
                "2.1.1": 1,
                "2.1.2": 1,
                "2.1.3": 1,
                "2.1.4": 1,
                "2.1.5": 1,
                "2.1.6": 1,
                "3.1.1": 1,
                "3.1.2": 1,
                "cot": 0
            },
            "strata": {
                "1": 1,
                "2": 1,
                "3": 0,
                "4": 1,
                "5": 1,
                "6": 1,
                "7": 0
            },
            "available_bitvector": {
                "1.1.1": 1,
                "1.1.2": 1,
                "1.2.1": 0,
                "1.2.2": 0,
                "1.2.3": 0,
                "1.3.1": 0,
                "1.3.2": 0,
                "1.4.1": 1,
                "1.4.2": 1,
                "2.1.1": 1,
                "2.1.2": 1,
                "2.1.3": 0,
                "2.1.4": 0,
                "2.1.5": 0,
                "2.1.6": 0,
                "3.1.1": 0,
                "3.1.2": 0,
                "cot": 0
            },
            "available_strata": {
                "1": 1,
                "2": 0,
                "3": 0,
                "4": 1,
                "5": 0,
                "6": 0,
                "7": 0
            },
            "start_line": 2676,
            "file_name": "keras/backend/tensorflow_backend.py",
            "replace_code": "def rnn(step_function, inputs, initial_states,\n        go_backwards=False, mask=None, constants=None,\n        unroll=False, input_length=None):\n    \"\"\"Iterates over the time dimension of a tensor.\n\n    # Arguments\n    ...\n    \"\"\"\n    import tensorflow as tf\n    import numpy as np\n\n    def np_ones_like(tensor):\n        return np.ones_like(tensor)\n\n    def reference_operations_rnn(inputs, args, initial_states, go_backwards=False,\n            mask=None, input_length=None, unroll=False):\n        states = initial_states\n        time_step = len(inputs)\n        time = tf.constant(np.arange(time_step))\n        outputs = tf.TensorArray(dtype=inputs.dtype, size=time_step)\n        \n        def _step(time, inputs, states):\n            input_slice = tf.gather(inputs, time)\n            output, new_states = step_function(input_slice, states)\n            outputs = outputs.write(time, output)\n            return time + 1, inputs, new_states\n        \n        _, _, states = tf.while_loop(lambda time, inputs, states: time < time_step,\n                                     _step,\n                                     loop_vars=[time, inputs, states],\n                                     swap_memory=True)\n        last_output = states[0]\n        outputs = outputs.stack()\n        return last_output, outputs, states\n\n    if unroll:\n        mask_is_not_None = mask != None\n        if mask_is_not_None: \n            outputs = reference_operations_rnn(inputs, [None, None], initial_states, \n                                               go_backwards, mask, \n                                               input_length, unroll)\n        else:\n            outputs = reference_operations_rnn(inputs, [None, None], initial_states, \n                                               go_backwards, None, \n                                               input_length, unroll)\n    else:\n\n        if mask is not None:\n            padded_mask, _ = _pad_sequences(\n                mask, padding='post', value=-1, dtype=mask.dtype)\n            mask_values = tf.cast(padded_mask >= 0, tf.float32)\n            original_input_length = input_length\n            input_length = tf.reduce_sum(mask_values, axis=1)\n\n        first_output, _ = step_function(inputs[0], initial_states + constants)\n\n        indices = tf.range(1, tf.shape(inputs)[0])\n        \n        def _step_unroll(time, output_ta_t, states):\n            current_input = tf.gather(inputs, time)\n            output, new_states = step_function(current_input, states)\n            output_ta_t = output_ta_t.write(time, output)\n            return time + 1, output_ta_t, new_states\n\n        time = tf.constant(1, name='time')\n        ta = tf.TensorArray(dtype=first_output.dtype,\n                            size=tf.shape(inputs)[0],\n                            name='output_ta')\n        ta = ta.write(0, first_output)\n\n        if len(initial_states) == 1:\n            states = [tf.expand_dims(states, axis=1) for states in initial_states]\n\n        _, output_final_ta, final_states = control_flow_ops.while_loop(\n            cond=lambda time, *_: time < tf.shape(inputs)[0],\n            body=_step_unroll,\n            loop_vars=(time, ta, initial_states),\n            swap_memory=True)\n\n        outputs = output_final_ta.stack()\n        if mask is not None:\n            output_length = reduce_sum(mask_values, axis=1)\n            output_length = tf.cast(output_length, dtype=tf.int32)\n            outputs = tf.boolean_mask(outputs, tf.sequence_mask(output_length))\n\n    last_output = final_states[0]\n    new_states= final_states[1:]\n\n    return last_output, outputs, new_states",
            "import_list": [
                "import tensorflow as tf",
                "import numpy as np"
            ]
        }
    ]
}