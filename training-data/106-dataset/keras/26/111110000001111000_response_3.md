```python
import tensorflow as tf 
from tensorflow.python.util import nest 
from tensorflow.python.ops import tensor_array_ops, control_flow_ops

def rnn(step_function, inputs, initial_states,
        go_backwards=False, mask=None, constants=None,
        unroll=False, input_length=None):
    def expand_dims(x, dim=-1):
        return tf.expand_dims(x, dim)

    inputs = tf.convert_to_tensor(inputs)
    ndim = len(inputs.get_shape())
    if ndim < 3:
        raise ValueError('Input should be at least 3D.')

    if mask is not None:
        mask = tf.expand_dims(mask, -1)
        mask = tf.cast(mask, tf.bool)

    if constants is None:
        constants = []
    else:
        constants = nest.flatten(constants)
        
    if unroll:
        if input_length is None:
            raise ValueError("`input_length` must be specified when `unroll` is used.")
        states = initial_states
        successive_states = []
        successive_outputs = []
        time = input_length
        current_input = inputs
        for t in range(time):
            output, new_states = step_function(current_input, states + constants)
            if getattr(output, '_uses_learning_phase', False):
                uses_learning_phase = True
            if mask is not None:
                # apply mask
                new_output = output if successive_outputs else tf.zeros_like(output)
                output = tf.where(mask[t], new_output, successive_outputs[-1])
                new_states = [tf.where(mask[t], new_state, state) for new_state, state in zip(new_states, states)]
                
            successive_outputs.append(output)
            successive_states.append(new_states)
            states = new_states
            current_input = output
        last_output = successive_outputs[-1]
        new_states = successive_states[-1]
        outputs = tf.stack(successive_outputs, axis=1)
        return last_output, outputs, new_states
        
    else:
        if not go_backwards:
            time = tf.shape(inputs)[1]
            idx = lambda time: time
        else:
            time = tf.constant(0, dtype='int32')
            idx = lambda time: -1 - time
            
        states = initial_states
        output_ta = tensor_array_ops.TensorArray(dtype=outputs.dtype, size=time, dynamic_size=False)
 
        def _step(time, output_ta, *states):
            current_input = inputs[:,idx(time),:]
            output, new_states = step_function(current_input, states + constants)
            output_ta = output_ta.write(time, output)
            return (time + 1, output_ta) + tuple(new_states)
        
        final_outputs = control_flow_ops.while_loop(
            cond=lambda time, *_: time < time,
            body=_step,
            loop_vars=(time, output_ta) + tuple(states),
            parallel_iterations=32,
            swap_memory=unroll)
        last_time = final_outputs[0]
        output_ta = final_outputs[1]
        new_states = final_outputs[2:]

        outputs = output_ta.stack()
        if go_backwards:
            outputs = tf.reverse(outputs, [1])
        outputs._uses_learning_phase = uses_learning_phase
        
        last_output = outputs[:, idx(last_time - 1),:]
        return last_output, outputs, new_states
```