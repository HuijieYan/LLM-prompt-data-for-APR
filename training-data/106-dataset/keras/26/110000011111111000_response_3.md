```python
def rnn(step_function, inputs, initial_states,
        go_backwards=False, mask=None, constants=None,
        unroll=False, input_length=None):
    """Iterates over the time dimension of a tensor.

    # Arguments
        step_function: RNN step function.
            Parameters:
                inputs: tensor with shape `(samples, ...)` (no time dimension),
                    representing input for the batch of samples at a certain
                    time step.
                states: list of tensors.
            Returns:
                outputs: tensor with shape `(samples, output_dim)`
                    (no time dimension).
                new_states: list of tensors, same length and shapes
                    as 'states'. The first state in the list must be the
                    output tensor at the previous timestep.
        inputs: tensor of temporal data of shape `(samples, time, ...)`
            (at least 3D).
        initial_states: tensor with shape (samples, output_dim)
            (no time dimension),
            containing the initial values for the states used in
            the step function.
        go_backwards: boolean. If True, do the iteration over the time
            dimension in reverse order and return the reversed sequence.
        mask: binary tensor with shape `(samples, time, 1)`,
            with a zero for every element that is masked.
        constants: a list of constant values passed at each step.
        unroll: whether to unroll the RNN or to use a symbolic loop (`while_loop` or `scan` depending on backend).
        input_length: not relevant in the TensorFlow implementation.
            Must be specified if using unrolling with Theano.

    # Returns
        A tuple, `(last_output, outputs, new_states)`.

            last_output: the latest output of the rnn, of shape `(samples, ...)`
            outputs: tensor with shape `(samples, time, ...)` where each
                entry `outputs[s, t]` is the output of the step function
                at time `t` for sample `s`.
            new_states: list of tensors, latest states returned by
                the step function, of shape `(samples, ...)`.

    # Raises
        ValueError: if input dimension is less than 3.
        ValueError: if `unroll` is `True` but input timestep is not a fixed number.
        ValueError: if `mask` is provided (not `None`) but states is not provided
            (`len(states)` == 0).
    """
    import tensorflow as tf
    import numpy as np
    def zeros_like(tensor):
        return tf.zeros_like(tensor)
    
    def reference_operations_rnn(x, weights, initial_state, **kwargs):
        sampled_states = [initial_state]

        if 'unroll' in kwargs and kwargs['unroll']:
            # Using TF while_loop for unrolling the rnn
            total_time = kwargs['input_length']
            i = 0
            func_name = 'while' if 'mask' in kwargs else 'while_2'
            func_name_output_ta = 'output_ta' if 'mask' in kwargs else 'output_ta_2'
            create_ta = lambda x: tf.TensorArray(dtype=tf.float32, size=total_time, name=x)

            output_ta = create_ta(func_name_output_ta)
            time = tf.constant(0, name='time')

            def _step(time, output_ta_t, *states):
                current_input = x[:, time, :]
                output, new_states = step_function(current_input, states + constants)
                output_ta_t = output_ta_t.write(time, output)

                new_states = [tf.convert_to_tensor(new_state) for new_state in new_states]  # Convert to Tensor for better inference types otherwise it throws error in tf.while_loop
                return (time + 1, output_ta_t) + tuple(new_states)
            # While loop logic for time dim iterations
            _, output_ta, *sampled_states = tf.while_loop(
                cond=lambda time, *_: time < total_time,
                body=_step,
                loop_vars=(time, output_ta) + tuple(sampled_states),
                name=func_name)
            outputs = output_ta.stack()
        return outputs
        
    def reverse(tensor, axis):
        return tf.reverse(tensor, axis)
      
    def expand_dims(_input):
        return tf.expand_dims(_input, axis=-1)
      
    def parse_shape_or_val(val):
        shape = val
        val = np.empty(shape)
        if 'int' in str(val.dtype):
            return shape, val.astype(int)
        else:
            return shape, val.astype(float)
      
    def rnn_fn(x_k, h_k):
        _, wi_k, wh_k, mask_k, num_samples, timesteps = x_k.shape, h_k[0].shape, h_k[1].shape, mask_k.shape, InitialState[0].shape, InitialState[0].shape[1]
        y_k = tf.matmul(x_k, wi_k) + tf.matmul(h_k[0], wh_k)

        y_k_shape = y_k.get_shape()

        if "mask" in kwargs:
            mask_ta = tf.TensorArray(dtype=tf.bool, size=timesteps, name='mask_ta', clear_after_read=False)
            mask_ta = mask_ta.unstack(mask)

            _, outputs, sampled_states = reference_operations_rnn(x, [wi_k, wh_k, None], h_k, mask=mask_k.numpy(), **kwargs)
        
        else:
            outputs = reference_operations_rnn(x, [wi_k, wh_k, None], h_k, **kwargs)
        
        h0_k_1 = np.concatenate([h_k[0].numpy(), h_k[0].numpy()], axis=-1)
        return y_k, [y_k, h0_k_1]

    # rest of the code from original function remains as is
```