The error message indicates that the `startswith` method in the `sitemap_urls_from_robots` function is expecting a bytes object but is receiving a string instead. This is likely due to the response body being passed as a string instead of bytes.

The root cause of the bug is that in Python 3, response bodies are returned as bytes, not strings. Thus, when passing the response body to the `sitemap_urls_from_robots` function, it should be decoded into a string to match the format expected by the `startswith` method.

To fix the bug, the response body should be decoded from bytes to a string before passing it to the `sitemap_urls_from_robots` function.

Here's the corrected code for the problematic function:

```python
def _parse_sitemap(self, response):
    if response.url.endswith('/robots.txt'):
        for url in sitemap_urls_from_robots(response.body.decode('utf-8')):  # Decode bytes to string
            yield Request(url, callback=self._parse_sitemap)
    else:
        body = self._get_sitemap_body(response)
        if body is None:
            logger.warning("Ignoring invalid sitemap: %(response)s",
                           {'response': response}, extra={'spider': self})
            return

        s = Sitemap(body)
        if s.type == 'sitemapindex':
            for loc in iterloc(s, self.sitemap_alternate_links):
                if any(x.search(loc) for x in self._follow):
                    yield Request(loc, callback=self._parse_sitemap)
        elif s.type == 'urlset':
            for loc in iterloc(s):
                for r, c in self._cbs:
                    if r.search(loc):
                        yield Request(loc, callback=c)
                        break
```

In the corrected code, we simply decode the response body using `response.body.decode('utf-8')` before passing it to the `sitemap_urls_from_robots` function.