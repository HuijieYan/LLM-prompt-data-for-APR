{
    "pandas": [
        {
            "bugID": 6,
            "bitvector": {
                "1.1.1": 1,
                "1.1.2": 1,
                "1.2.1": 0,
                "1.2.2": 0,
                "1.2.3": 0,
                "1.3.1": 0,
                "1.3.2": 0,
                "1.4.1": 0,
                "1.4.2": 0,
                "2.1.1": 0,
                "2.1.2": 0,
                "2.1.3": 1,
                "2.1.4": 1,
                "2.1.5": 1,
                "2.1.6": 1,
                "3.1.1": 0,
                "3.1.2": 0,
                "cot": 1
            },
            "strata": {
                "1": 1,
                "2": 0,
                "3": 0,
                "4": 0,
                "5": 1,
                "6": 0,
                "7": 1
            },
            "available_bitvector": {
                "1.1.1": 1,
                "1.1.2": 1,
                "1.2.1": 0,
                "1.2.2": 0,
                "1.2.3": 0,
                "1.3.1": 0,
                "1.3.2": 0,
                "1.4.1": 0,
                "1.4.2": 0,
                "2.1.1": 0,
                "2.1.2": 0,
                "2.1.3": 1,
                "2.1.4": 1,
                "2.1.5": 1,
                "2.1.6": 1,
                "3.1.1": 0,
                "3.1.2": 0,
                "cot": 1
            },
            "available_strata": {
                "1": 1,
                "2": 0,
                "3": 0,
                "4": 0,
                "5": 1,
                "6": 0,
                "7": 1
            },
            "start_line": 601,
            "file_name": "pandas/core/groupby/grouper.py",
            "replace_code": "def get_grouper(\n    obj: pd.DataFrame or pd.Series,\n    key=None,\n    axis: int = 0,\n    level=None,\n    sort: bool = True,\n    observed: bool = False,\n    mutated: bool = False,\n    validate: bool = True,\n    dropna: bool = True,\n) -> \"Tuple[ops.BaseGrouper, List[Hashable], pd.DataFrame or pd.Series]\":\n    import pandas as pd\n    from pandas.core.indexes.base import Index\n    from pandas.core.indexes.period import PeriodIndex\n    from pandas.core.series import Series\n    from pandas.core.arrays.datetimes import Sequence\n    import numpy as np\n    from pandas.core.indexes.multi import MultiIndex\n    import pandas.core.reshape.ops as ops\n    from typing import List, Hashable, Tuple\n    group_axis = obj._get_axis(axis)\n    \n    if level is not None:\n        if isinstance(group_axis, MultiIndex):\n            if isinstance(level, list) and len(level) == 1:\n                level = level[0]\n    \n            if key is None and np.isscalar(level):\n                key = group_axis.get_level_values(level)\n                level = None\n        else:\n            if isinstance(level, list):\n                nlevels = len(level)\n                if nlevels == 1:\n                    level = level[0]\n                elif nlevels == 0:\n                    raise ValueError(\"No group keys passed!\")\n                else:\n                    raise ValueError(\"multiple levels only valid with MultiIndex\")\n    \n            if isinstance(level, str):\n                if obj._get_axis(axis).name != level:\n                    raise ValueError(\n                        f\"level name {level} is not the name \"\n                        f\"of the {obj._get_axis_name(axis)}\"\n                    )\n            elif level > 0 or level < -1:\n                raise ValueError(\"level > 0 or level < -1 only valid with MultiIndex\")\n    \n            level = None\n            key = group_axis\n    \n    if isinstance(key, ops.Grouping):\n        binner, grouper, obj = key._get_grouper(obj, validate=False)\n        if key.key is None:\n            return grouper, [], obj\n        else:\n            return grouper, [key.key], obj\n    \n    elif isinstance(key, ops.BaseGrouper):\n        return key, [], obj\n    \n    if not isinstance(key, list):\n        keys = [key]\n        match_axis_length = False\n    else:\n        keys = key\n        match_axis_length = len(keys) == len(group_axis)\n    \n    any_callable = any(callable(g) or isinstance(g, dict) for g in keys)\n    any_groupers = any(isinstance(g, ops.Grouping) for g in keys)\n    any_arraylike = any(\n        isinstance(g, (list, tuple, Series, Index, np.ndarray)) for g in keys\n    )\n    \n    if not any_callable and not any_arraylike and not any_groupers and match_axis_length and level is None:\n        if isinstance(obj, pd.DataFrame):\n            all_in_columns_index = all(\n                g in obj.columns or g in obj.index.names for g in keys\n            )\n        else:\n            assert isinstance(obj, pd.Series)\n            all_in_columns_index = all(g in obj.index.names for g in keys)\n    \n        if not all_in_columns_index:\n            keys = [np.asarray(keys)]\n    \n    if isinstance(level, (tuple, list)):\n        if key is None:\n            keys = [None] * len(level)\n        levels = level\n    else:\n        levels = [level] * len(keys)\n    \n    groupings: List[ops.Grouping] = []\n    exclusions: List[Hashable] = []\n    \n    def is_in_axis(key) -> bool:\n        if not pd.api.types.is_hashable(key):\n            items = obj.axes[-1]\n            try:\n                items.get_loc(key)\n            except (KeyError, TypeError, pd.errors.InvalidIndexError):\n                return False\n    \n        return True\n    \n    def is_in_obj(gpr) -> bool:\n        if not hasattr(gpr, \"name\"):\n            return False\n        try:\n            return gpr is obj[gpr.name]\n        except (KeyError, IndexError):\n            return False\n    \n    for i, (gpr, level) in enumerate(zip(keys, levels)):\n        if is_in_obj(gpr):\n            in_axis, name = True, gpr.name\n            exclusions.append(name)\n        elif is_in_axis(gpr):\n            if gpr in obj:\n                if validate:\n                    obj._check_label_or_level_ambiguity(gpr, axis=axis)\n                in_axis, name, gpr = True, gpr, obj[gpr]\n                exclusions.append(name)\n            elif obj._is_level_reference(gpr, axis=axis):\n                in_axis, name, level, gpr = False, None, gpr, None\n            else:\n                raise KeyError(gpr)\n        elif isinstance(gpr, ops.Grouping) and gpr.key is not None:\n            exclusions.append(gpr.key)\n            in_axis, name = False, None\n        else:\n            in_axis, name = False, None\n    \n        if isinstance(gpr, pd.Categorical) and len(gpr) != obj.shape[axis]:\n            raise ValueError(\n                f\"Length of grouper ({len(gpr)}) and axis ({obj.shape[axis]}) \"\n                \"must be same length\"\n            )\n    \n        ping = (\n            ops.Grouping(\n                group_axis,\n                gpr,\n                obj=obj,\n                name=name,\n                level=level,\n                sort=sort,\n                observed=observed,\n                in_axis=in_axis,\n                dropna=dropna,\n            )\n            if not isinstance(gpr, ops.Grouping)\n            else gpr\n        )\n    \n        groupings.append(ping)\n    \n    if len(groupings) == 0 and len(obj):\n        raise ValueError(\"No group keys passed!\")\n    elif len(groupings) == 0:\n        groupings.append(ops.Grouping(Index([], dtype=\"int\"), np.array([], dtype=np.intp)))\n    \n    grouper = ops.BaseGrouper(group_axis, groupings, sort=sort, mutated=mutated)\n    return grouper, exclusions, obj"
        }
    ]
}