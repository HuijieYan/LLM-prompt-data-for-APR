Please fix the function/method provided below and provide the corrected function/method as the output.


# Buggy function source code
```python
# this is the buggy function you need to fix
def _get_merge_keys(self):
    """
    Note: has side effects (copy/delete key columns)

    Parameters
    ----------
    left
    right
    on

    Returns
    -------
    left_keys, right_keys
    """
    left_keys = []
    right_keys = []
    join_names = []
    right_drop = []
    left_drop = []

    left, right = self.left, self.right

    is_lkey = lambda x: is_array_like(x) and len(x) == len(left)
    is_rkey = lambda x: is_array_like(x) and len(x) == len(right)

    # Note that pd.merge_asof() has separate 'on' and 'by' parameters. A
    # user could, for example, request 'left_index' and 'left_by'. In a
    # regular pd.merge(), users cannot specify both 'left_index' and
    # 'left_on'. (Instead, users have a MultiIndex). That means the
    # self.left_on in this function is always empty in a pd.merge(), but
    # a pd.merge_asof(left_index=True, left_by=...) will result in a
    # self.left_on array with a None in the middle of it. This requires
    # a work-around as designated in the code below.
    # See _validate_specification() for where this happens.

    # ugh, spaghetti re #733
    if _any(self.left_on) and _any(self.right_on):
        for lk, rk in zip(self.left_on, self.right_on):
            if is_lkey(lk):
                left_keys.append(lk)
                if is_rkey(rk):
                    right_keys.append(rk)
                    join_names.append(None)  # what to do?
                else:
                    if rk is not None:
                        right_keys.append(right._get_label_or_level_values(rk))
                        join_names.append(rk)
                    else:
                        # work-around for merge_asof(right_index=True)
                        right_keys.append(right.index)
                        join_names.append(right.index.name)
            else:
                if not is_rkey(rk):
                    if rk is not None:
                        right_keys.append(right._get_label_or_level_values(rk))
                    else:
                        # work-around for merge_asof(right_index=True)
                        right_keys.append(right.index)
                    if lk is not None and lk == rk:
                        # avoid key upcast in corner case (length-0)
                        if len(left) > 0:
                            right_drop.append(rk)
                        else:
                            left_drop.append(lk)
                else:
                    right_keys.append(rk)
                if lk is not None:
                    left_keys.append(left._get_label_or_level_values(lk))
                    join_names.append(lk)
                else:
                    # work-around for merge_asof(left_index=True)
                    left_keys.append(left.index)
                    join_names.append(left.index.name)
    elif _any(self.left_on):
        for k in self.left_on:
            if is_lkey(k):
                left_keys.append(k)
                join_names.append(None)
            else:
                left_keys.append(left._get_label_or_level_values(k))
                join_names.append(k)
        if isinstance(self.right.index, MultiIndex):
            right_keys = [
                lev._values.take(lev_codes)
                for lev, lev_codes in zip(
                    self.right.index.levels, self.right.index.codes
                )
            ]
        else:
            right_keys = [self.right.index._values]
    elif _any(self.right_on):
        for k in self.right_on:
            if is_rkey(k):
                right_keys.append(k)
                join_names.append(None)
            else:
                right_keys.append(right._get_label_or_level_values(k))
                join_names.append(k)
        if isinstance(self.left.index, MultiIndex):
            left_keys = [
                lev._values.take(lev_codes)
                for lev, lev_codes in zip(
                    self.left.index.levels, self.left.index.codes
                )
            ]
        else:
            left_keys = [self.left.index.values]

    if left_drop:
        self.left = self.left._drop_labels_or_levels(left_drop)

    if right_drop:
        self.right = self.right._drop_labels_or_levels(right_drop)

    return left_keys, right_keys, join_names

```




# A GitHub issue title for this bug
```text
pd.merge_asof not working when merging TZ-aware index+series
```

## The associated detailed issue description
```text
Hi!

I don't know how to solve following issue, can you please take a look? What am I doing wrong?

Problem description
import io
import pandas as pd


data_1 = io.StringIO("""
                           xyz  
from_date                                                       
2019-10-01 00:30:00+00:00  0.9
2019-10-01 01:00:00+00:00  0.8
2019-10-01 01:30:00+00:00  0.7
2019-10-01 02:00:00+00:00  0.6""")
df = pd.read_csv(data_1, sep='\s{2,}', engine='python')
df.index = pd.to_datetime(df.index, utc=True)


data_2 = io.StringIO("""
                from_date         abc
2019-10-01 00:00:00+00:00        2.46
2019-10-01 00:30:00+00:00        2.46
2019-10-01 01:00:00+00:00        2.46
2019-10-01 01:30:00+00:00        2.46
2019-10-01 02:00:00+00:00        2.19
""")
df2 = pd.read_csv(data_2, sep='\s{2,}', engine='python')
df2['from_date'] = pd.to_datetime(df2['from_date'], utc=True)


print(f"pandas version: {pd.__version__}")
print(f"df index dtype: {df.index.dtype}")
print(f"df2 dt column dtype: {df2['from_date'].dtype}")
print("check", df.index.dtype == df2.from_date.dtype )
pd.merge_asof(left=df, right=df2, left_index=True, right_on=['from_date'])
Output
pandas version: 0.25.3
df index dtype: datetime64[ns, UTC]
df2 dt column dtype: datetime64[ns, UTC]
check True
---------------------------------------------------------------------------
MergeError                                Traceback (most recent call last)
<ipython-input-82-bdb9feab8f76> in <module>
     28 print(f"df2 dt column dtype: {df2['from_date'].dtype}")
     29 print("check", df.index.dtype == df2.from_date.dtype )
---> 30 pd.merge_asof(left=df, right=df2, left_index=True, right_on=['from_date'], direction='nearest')

c:\users\asd\lib\site-packages\pandas\core\reshape\merge.py in merge_asof(left, right, on, left_on, right_on, left_index, right_index, by, left_by, right_by, suffixes, tolerance, allow_exact_matches, direction)
    537         tolerance=tolerance,
    538         allow_exact_matches=allow_exact_matches,
--> 539         direction=direction,
    540     )
    541     return op.get_result()

c:\users\asd\lib\site-packages\pandas\core\reshape\merge.py in __init__(self, left, right, on, left_on, right_on, left_index, right_index, by, left_by, right_by, axis, suffixes, copy, fill_method, how, tolerance, allow_exact_matches, direction)
   1552             how=how,
   1553             suffixes=suffixes,
-> 1554             fill_method=fill_method,
   1555         )
   1556 

c:\users\asd\lib\site-packages\pandas\core\reshape\merge.py in __init__(self, left, right, on, left_on, right_on, left_index, right_index, axis, suffixes, copy, fill_method, how)
   1442             how=how,
   1443             suffixes=suffixes,
-> 1444             sort=True,  # factorize sorts
   1445         )
   1446 

c:\users\asd\lib\site-packages\pandas\core\reshape\merge.py in __init__(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)
    624             self.right_join_keys,
    625             self.join_names,
--> 626         ) = self._get_merge_keys()
    627 
    628         # validate the merge keys dtypes. We may need to coerce

c:\users\asd\lib\site-packages\pandas\core\reshape\merge.py in _get_merge_keys(self)
   1636                         )
   1637                     )
-> 1638                 raise MergeError(msg)
   1639 
   1640         # validate tolerance; must be a Timedelta if we have a DTI

MergeError: incompatible merge keys [0] dtype('<M8[ns]') and datetime64[ns, UTC], must be the same type
Expected Output
merged dataframes
```



