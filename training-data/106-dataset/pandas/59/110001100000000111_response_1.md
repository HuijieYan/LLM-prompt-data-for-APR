Potential error location: The error is likely occurring in the `_get_corr` function when trying to allocate an extremely large amount of memory for an array.

Reasons behind the occurrence of the bug: The bug could be caused by the change in behavior between pandas 0.25.3 and 1.0.1, leading to a memory allocation error when trying to perform the rolling correlation.

Possible approaches for fixing the bug: One possible approach could be to modify the `_get_corr` function to handle the rolling correlation in a more memory-efficient way. This could involve breaking the calculations into smaller chunks to avoid excessive memory allocation. Additionally, the `_get_window` function may need to be modified to handle large window sizes more efficiently.

Corrected code:
```python
# corrected corr function
def corr(self, other=None, pairwise=None, **kwargs):
    if other is None:
        other = self._selected_obj
        # only default unset
        pairwise = True if pairwise is None else pairwise
    other = self._shallow_copy(other)
    window = self._get_window(other)
    periods = min(self.min_periods, window)

    def _get_corr(a, b):
        results = []
        for i in range(0, len(a), periods):
            a_chunk = a[i:i+periods].rolling(
                window=window, min_periods=periods, center=self.center
            )
            b_chunk = b[i:i+periods].rolling(
                window=window, min_periods=periods, center=self.center
            )
            results.append(a_chunk.cov(b_chunk, **kwargs) / (a_chunk.std(**kwargs) * b_chunk.std(**kwargs)))
        
        return pd.concat(results)

    return _flex_binary_moment(
        self._selected_obj, other._selected_obj, _get_corr, pairwise=bool(pairwise)
    )
```
In the corrected code, the rolling correlation calculations are broken into smaller chunks to avoid excessive memory allocation. This should help prevent the MemoryError when using `series.rolling().corr(other)` with large datasets.