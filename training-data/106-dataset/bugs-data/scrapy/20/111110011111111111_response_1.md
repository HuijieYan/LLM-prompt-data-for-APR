The error occurs in the function `sitemap_urls_from_robots` on line 42 of the `scrapy/utils/sitemap.py` file. The error message indicates a `TypeError` related to the `startswith` function, and it's caused by the first argument being of type `str` instead of `bytes` or a tuple of `bytes`.

This issue arises due to the usage of byte literals (e.g., `b'example'`) in Python 3 and the transition from Python 2 to Python 3. The `robots_text` is being passed as a byte string, while the `line.lstrip().startswith('Sitemap:')` operation assumes a string input.

To fix this bug, it's necessary to ensure that all relevant input strings are encoded into byte literals for consistency. Additionally, when calling the `sitemap_urls_from_robots` function, the response body should be converted to a byte literal. 

Here's the corrected code for the `sitemap_urls_from_robots` function and the `_parse_sitemap` function in `scrapy/spiders/sitemap.py`:

```python
# In scrapy/utils/sitemap.py
def sitemap_urls_from_robots(robots_text):
    """Return an iterator over all sitemap urls contained in the given
    robots.txt file
    """
    for line in robots_text.decode('utf-8').splitlines():
        if line.lstrip().startswith('Sitemap:'):
            yield line.split(' ')[1]

# In scrapy/spiders/sitemap.py
def _parse_sitemap(self, response):
    if response.url.endswith('/robots.txt'):
        for url in sitemap_urls_from_robots(response.body):
            yield Request(url, callback=self._parse_sitemap)
    else:
        body = self._get_sitemap_body(response)
        if body is None:
            logger.warning("Ignoring invalid sitemap: %(response)s",
                           {'response': response}, extra={'spider': self})
            return

        s = Sitemap(body)
        if s.type == 'sitemapindex':
            for loc in iterloc(s, self.sitemap_alternate_links):
                if any(x.search(loc) for x in self._follow):
                    yield Request(loc, callback=self._parse_sitemap)
        elif s.type == 'urlset':
            for loc in iterloc(s):
                for r, c in self._cbs:
                    if r.search(loc):
                        yield Request(loc, callback=c)
                        break
```

In the updated code, the `robots_text` is decoded from bytes to a UTF-8 string before being split into lines. This allows the `startswith` function to work as expected. Additionally, the `response.body` parameter in the `sitemap_urls_from_robots` call is left unchanged, assuming it is already in bytes format. If the body is not in bytes format, it should be encoded to bytes when passed to the `sitemap_urls_from_robots` function.