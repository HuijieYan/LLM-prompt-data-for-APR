{
    "1.1.1": "def gunzip(data):\n    \n    f = GzipFile(fileobj=BytesIO(data))\n    output = b''\n    chunk = b'.'\n    while chunk:\n        try:\n            chunk = read1(f, 8196)\n            output += chunk\n        except (IOError, EOFError, struct.error):\n            # complete only if there is some data, otherwise re-raise\n            # see issue 87 about catching struct.error\n            # some pages are quite small so output is '' and f.extrabuf\n            # contains the whole page content\n            if output or getattr(f, 'extrabuf', None):\n                try:\n                    output += f.extrabuf\n                finally:\n                    break\n            else:\n                raise\n    return output\n",
    "1.1.2": "Gunzip the given data and return as much data as possible.\n\nThis is resilient to CRC checksum errors.",
    "1.2.1": null,
    "1.2.2": null,
    "1.2.3": null,
    "1.3.1": "/Volumes/SSD2T/bgp_envs_non_pandas/repos/scrapy_11/scrapy/utils/gz.py",
    "1.3.2": [
        "read1(gzf, size=-1)",
        "read1(gzf, size=-1)"
    ],
    "1.4.1": [
        "    def test_gunzip_illegal_eof(self):\n        with open(join(SAMPLEDIR, 'unexpected-eof.gz'), 'rb') as f:\n            text = html_to_unicode('charset=cp1252', gunzip(f.read()))[1]\n            with open(join(SAMPLEDIR, 'unexpected-eof-output.txt'), 'rb') as o:\n                expected_text = o.read().decode(\"utf-8\")\n                self.assertEqual(len(text), len(expected_text))\n                self.assertEqual(text, expected_text)"
    ],
    "1.4.2": [
        "/Volumes/SSD2T/bgp_envs_non_pandas/repos/scrapy_11/tests/test_utils_gz.py"
    ],
    "2.1.1": [
        [
            "E       FileNotFoundError: [Errno 2] No such file or directory: '/Volumes/SSD2T/bgp_envs_non_pandas/repos/scrapy_11/tests/sample_data/compressed/unexpected-eof.gz'"
        ]
    ],
    "2.1.2": [
        [
            "self = <tests.test_utils_gz.GunzipTest testMethod=test_gunzip_illegal_eof>\n\n    def test_gunzip_illegal_eof(self):\n>       with open(join(SAMPLEDIR, 'unexpected-eof.gz'), 'rb') as f:",
            "\n/Volumes/SSD2T/bgp_envs_non_pandas/repos/scrapy_11/tests/test_utils_gz.py:73: FileNotFoundError"
        ]
    ],
    "2.1.3": null,
    "2.1.4": null,
    "2.1.5": [
        [
            {
                "data": "b'\\x1f\\x8b\\x08\\x00\\xd9U\\x04W\\x00\\x03dW\\xdbR\\xdbZ\\x12\\xfd\\x9c\\x99\\xa7\\xf9\\x82\\xa9\\xf9\\x99\\x99\\xf30\\x0fs\\xa9\\xa9sj\\xbeG(\\x90`\\x14G\\xb2\\xb5\\xe5\\x8b$\\xdf\\xb4m]\\xb6u\\x97%b\\x92\\x006\\x84p\\r`\\x0e1vLM\\xb7\\x85\\xc1\\xd4$U!\\xc6[\\xbd\\xbbW\\xaf^\\xab\\xf5\\xb7\\x7f\\xfd\\xf5\\xb7\\x7f\\xfc\\xf2\\xcf_\\xff\\xf4\\xdf\\xff\\xfc\\xfd\\xd7_\\xfe\\xf8\\x07\\x0e\\xff\\x88^\\xa4\\x07\\xf5\\xd3\\x80\\x93\\xb6x\\xc11#\\xb5z_1\\xcb"
            },
            {
                "f": "<gzip _io.BytesIO object at 0x108eb89a0 0x108823fa0>",
                "output": "array of shape 8576",
                "chunk": "array of shape 380"
            }
        ]
    ],
    "2.1.6": [
        [
            {
                "data": "bytes"
            },
            {
                "f": "GzipFile",
                "output": "bytes",
                "chunk": "bytes"
            }
        ]
    ],
    "3.1.1": [
        "response.body is duplicate\n"
    ],
    "3.1.2": [
        "Access the text page(not mine) by browsers or wget and you will find the response content is not duplicate, but scrapy's response.body is duplicate. I had tried set the scrapy's headers same as a real brower's, but it is still duplicate.\n\nJust use the follow sample code, and you will find the issue.\n\nscrapy shell \"http://files.qidian.com/Author4/3615059/88542882.txt\"\nSorry for my bad english.\n"
    ]
}