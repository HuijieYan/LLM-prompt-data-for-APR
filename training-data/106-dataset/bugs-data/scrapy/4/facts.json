{
    "1.1.1": "def _clean_req(self, request, method, results):\n    \n\n    cb = request.callback\n\n    @wraps(cb)\n    def cb_wrapper(response):\n        try:\n            output = cb(response)\n            output = list(iterate_spider_output(output))\n        except:\n            case = _create_testcase(method, 'callback')\n            results.addError(case, sys.exc_info())\n\n    def eb_wrapper(failure):\n        case = _create_testcase(method, 'errback')\n        exc_info = failure.value, failure.type, failure.getTracebackObject()\n        results.addError(case, exc_info)\n\n    request.callback = cb_wrapper\n    request.errback = eb_wrapper\n",
    "1.1.2": "stop the request from returning objects and records any errors ",
    "1.2.1": "class ContractsManager(object)",
    "1.2.2": null,
    "1.2.3": [
        "cb_wrapper(response)",
        "eb_wrapper(failure)"
    ],
    "1.3.1": "/Volumes/SSD2T/bgp_envs/repos/scrapy_4/scrapy/contracts/__init__.py",
    "1.3.2": [
        "_create_testcase(method, desc)",
        "cb_wrapper(response)",
        "eb_wrapper(failure)"
    ],
    "1.4.1": [
        "    def test_errback(self):\n        spider = TestSpider()\n        response = ResponseMock()\n\n        try:\n            raise HttpError(response, 'Ignoring non-200 response')\n        except HttpError:\n            failure_mock = failure.Failure()\n\n        request = self.conman.from_method(spider.returns_request, self.results)\n        request.errback(failure_mock)\n\n        self.assertFalse(self.results.failures)\n        self.assertTrue(self.results.errors)"
    ],
    "1.4.2": [
        "/Volumes/SSD2T/bgp_envs/repos/scrapy_4/tests/test_contracts.py"
    ],
    "2.1.1": [
        [
            "E           AttributeError: 'getset_descriptor' object has no attribute '__traceback__'"
        ]
    ],
    "2.1.2": [
        [
            "self = <tests.test_contracts.ContractsManagerTest testMethod=test_errback>\n\n    def test_errback(self):\n        spider = TestSpider()\n        response = ResponseMock()\n    \n        try:\n            raise HttpError(response, 'Ignoring non-200 response')\n        except HttpError:\n            failure_mock = failure.Failure()\n    \n        request = self.conman.from_method(spider.returns_request, self.results)\n>       request.errback(failure_mock)\n\n/Volumes/SSD2T/bgp_envs/repos/scrapy_4/tests/test_contracts.py:201: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/Volumes/SSD2T/bgp_envs/repos/scrapy_4/scrapy/contracts/__init__.py:88: in eb_wrapper\n    results.addError(case, exc_info)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <traceback.TracebackException object at 0x1043475b0>\nexc_type = HttpError('Ignoring non-200 response')\nexc_value = <class 'scrapy.spidermiddlewares.httperror.HttpError'>\nexc_traceback = <traceback object at 0x10389e9c0>\n\n    def __init__(self, exc_type, exc_value, exc_traceback, *, limit=None,\n            lookup_lines=True, capture_locals=False, _seen=None):\n        # NB: we need to accept exc_traceback, exc_value, exc_traceback to\n        # permit backwards compat with the existing API, otherwise we\n        # need stub thunk objects just to glue it together.\n        # Handle loops in __cause__ or __context__.\n        if _seen is None:\n            _seen = set()\n        _seen.add(id(exc_value))\n        # Gracefully handle (the way Python 2.4 and earlier did) the case of\n        # being called with no type or value (None, None, None).\n        if (exc_value and exc_value.__cause__ is not None\n            and id(exc_value.__cause__) not in _seen):\n            cause = TracebackException(\n                type(exc_value.__cause__),\n                exc_value.__cause__,\n>               exc_value.__cause__.__traceback__,\n                limit=limit,\n                lookup_lines=False,\n                capture_locals=capture_locals,\n                _seen=_seen)",
            "\n/usr/local/Cellar/python@3.8/3.8.18_1/Frameworks/Python.framework/Versions/3.8/lib/python3.8/traceback.py:484: AttributeError"
        ]
    ],
    "2.1.3": [
        [
            {
                "request": "<GET http://scrapy.org>",
                "results.addError": "<bound method TextTestResult.addError of <unittest.runner.TextTestResult run=0 errors=0 failures=0>>",
                "results": "<unittest.runner.TextTestResult run=0 errors=0 failures=0>"
            },
            {
                "request.errback": "<function ContractsManager._clean_req.<locals>.eb_wrapper at 0x1078eac10>",
                "eb_wrapper": "<function ContractsManager._clean_req.<locals>.eb_wrapper at 0x1078eac10>"
            }
        ]
    ],
    "2.1.4": [
        [
            {
                "request": "Request",
                "results.addError": "method",
                "results": "TextTestResult"
            },
            {
                "request.errback": "function",
                "eb_wrapper": "function"
            }
        ]
    ],
    "2.1.5": [
        [
            {
                "request": "<GET http://scrapy.org>",
                "results.addError": "<bound method TextTestResult.addError of <unittest.runner.TextTestResult run=0 errors=0 failures=0>>",
                "results": "<unittest.runner.TextTestResult run=0 errors=0 failures=0>"
            },
            {
                "request.errback": "<function ContractsManager._clean_req.<locals>.eb_wrapper at 0x1129d6c10>",
                "eb_wrapper": "<function ContractsManager._clean_req.<locals>.eb_wrapper at 0x1129d6c10>"
            }
        ]
    ],
    "2.1.6": [
        [
            {
                "request": "Request",
                "results.addError": "method",
                "results": "TextTestResult"
            },
            {
                "request.errback": "function",
                "eb_wrapper": "function"
            }
        ]
    ],
    "3.1.1": [
        "AttributeError from contract errback\n"
    ],
    "3.1.2": [
        "\nWhen running a contract with a URL that returns non-200 response, I get the following:\n\n2018-08-09 14:40:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bureauxlocaux.com/annonce/a-louer-bureaux-a-louer-a-nantes--1289-358662> (referer: None)\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py\", line 653, in _runCallbacks\n    current.result = callback(current.result, *args, **kw)\n  File \"/usr/local/lib/python3.6/site-packages/scrapy/contracts/__init__.py\", line 89, in eb_wrapper\n    results.addError(case, exc_info)\n  File \"/usr/local/lib/python3.6/unittest/runner.py\", line 67, in addError\n    super(TextTestResult, self).addError(test, err)\n  File \"/usr/local/lib/python3.6/unittest/result.py\", line 17, in inner\n    return method(self, *args, **kw)\n  File \"/usr/local/lib/python3.6/unittest/result.py\", line 115, in addError\n    self.errors.append((test, self._exc_info_to_string(err, test)))\n  File \"/usr/local/lib/python3.6/unittest/result.py\", line 186, in _exc_info_to_string\n    exctype, value, tb, limit=length, capture_locals=self.tb_locals)\n  File \"/usr/local/lib/python3.6/traceback.py\", line 470, in __init__\n    exc_value.__cause__.__traceback__,\nAttributeError: 'getset_descriptor' object has no attribute '__traceback__'\nHere is how exc_info looks like:\n\n(HttpError('Ignoring non-200 response',), <class 'scrapy.spidermiddlewares.httperror.HttpError'>, <traceback object at 0x7f4bdca1d948>)\n"
    ]
}