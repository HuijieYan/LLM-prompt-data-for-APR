{
    "1.1.1": "def get_grouper(\n    obj: FrameOrSeries,\n    key=None,\n    axis: int = 0,\n    level=None,\n    sort: bool = True,\n    observed: bool = False,\n    mutated: bool = False,\n    validate: bool = True,\n    dropna: bool = True,\n) -> \"Tuple[ops.BaseGrouper, List[Hashable], FrameOrSeries]\":\n    \n    group_axis = obj._get_axis(axis)\n\n    # validate that the passed single level is compatible with the passed\n    # axis of the object\n    if level is not None:\n        # TODO: These if-block and else-block are almost same.\n        # MultiIndex instance check is removable, but it seems that there are\n        # some processes only for non-MultiIndex in else-block,\n        # eg. `obj.index.name != level`. We have to consider carefully whether\n        # these are applicable for MultiIndex. Even if these are applicable,\n        # we need to check if it makes no side effect to subsequent processes\n        # on the outside of this condition.\n        # (GH 17621)\n        if isinstance(group_axis, MultiIndex):\n            if is_list_like(level) and len(level) == 1:\n                level = level[0]\n\n            if key is None and is_scalar(level):\n                # Get the level values from group_axis\n                key = group_axis.get_level_values(level)\n                level = None\n\n        else:\n            # allow level to be a length-one list-like object\n            # (e.g., level=[0])\n            # GH 13901\n            if is_list_like(level):\n                nlevels = len(level)\n                if nlevels == 1:\n                    level = level[0]\n                elif nlevels == 0:\n                    raise ValueError(\"No group keys passed!\")\n                else:\n                    raise ValueError(\"multiple levels only valid with MultiIndex\")\n\n            if isinstance(level, str):\n                if obj._get_axis(axis).name != level:\n                    raise ValueError(\n                        f\"level name {level} is not the name \"\n                        f\"of the {obj._get_axis_name(axis)}\"\n                    )\n            elif level > 0 or level < -1:\n                raise ValueError(\"level > 0 or level < -1 only valid with MultiIndex\")\n\n            # NOTE: `group_axis` and `group_axis.get_level_values(level)`\n            # are same in this section.\n            level = None\n            key = group_axis\n\n    # a passed-in Grouper, directly convert\n    if isinstance(key, Grouper):\n        binner, grouper, obj = key._get_grouper(obj, validate=False)\n        if key.key is None:\n            return grouper, [], obj\n        else:\n            return grouper, [key.key], obj\n\n    # already have a BaseGrouper, just return it\n    elif isinstance(key, ops.BaseGrouper):\n        return key, [], obj\n\n    if not isinstance(key, list):\n        keys = [key]\n        match_axis_length = False\n    else:\n        keys = key\n        match_axis_length = len(keys) == len(group_axis)\n\n    # what are we after, exactly?\n    any_callable = any(callable(g) or isinstance(g, dict) for g in keys)\n    any_groupers = any(isinstance(g, Grouper) for g in keys)\n    any_arraylike = any(\n        isinstance(g, (list, tuple, Series, Index, np.ndarray)) for g in keys\n    )\n\n    # is this an index replacement?\n    if (\n        not any_callable\n        and not any_arraylike\n        and not any_groupers\n        and match_axis_length\n        and level is None\n    ):\n        if isinstance(obj, DataFrame):\n            all_in_columns_index = all(\n                g in obj.columns or g in obj.index.names for g in keys\n            )\n        else:\n            assert isinstance(obj, Series)\n            all_in_columns_index = all(g in obj.index.names for g in keys)\n\n        if not all_in_columns_index:\n            keys = [com.asarray_tuplesafe(keys)]\n\n    if isinstance(level, (tuple, list)):\n        if key is None:\n            keys = [None] * len(level)\n        levels = level\n    else:\n        levels = [level] * len(keys)\n\n    groupings: List[Grouping] = []\n    exclusions: List[Hashable] = []\n\n    # if the actual grouper should be obj[key]\n    def is_in_axis(key) -> bool:\n        if not _is_label_like(key):\n            # items -> .columns for DataFrame, .index for Series\n            items = obj.axes[-1]\n            try:\n                items.get_loc(key)\n            except (KeyError, TypeError, InvalidIndexError):\n                # TypeError shows up here if we pass e.g. Int64Index\n                return False\n\n        return True\n\n    # if the grouper is obj[name]\n    def is_in_obj(gpr) -> bool:\n        if not hasattr(gpr, \"name\"):\n            return False\n        try:\n            return gpr is obj[gpr.name]\n        except (KeyError, IndexError):\n            return False\n\n    for i, (gpr, level) in enumerate(zip(keys, levels)):\n\n        if is_in_obj(gpr):  # df.groupby(df['name'])\n            in_axis, name = True, gpr.name\n            exclusions.append(name)\n\n        elif is_in_axis(gpr):  # df.groupby('name')\n            if gpr in obj:\n                if validate:\n                    obj._check_label_or_level_ambiguity(gpr, axis=axis)\n                in_axis, name, gpr = True, gpr, obj[gpr]\n                exclusions.append(name)\n            elif obj._is_level_reference(gpr, axis=axis):\n                in_axis, name, level, gpr = False, None, gpr, None\n            else:\n                raise KeyError(gpr)\n        elif isinstance(gpr, Grouper) and gpr.key is not None:\n            # Add key to exclusions\n            exclusions.append(gpr.key)\n            in_axis, name = False, None\n        else:\n            in_axis, name = False, None\n\n        if is_categorical_dtype(gpr) and len(gpr) != obj.shape[axis]:\n            raise ValueError(\n                f\"Length of grouper ({len(gpr)}) and axis ({obj.shape[axis]}) \"\n                \"must be same length\"\n            )\n\n        # create the Grouping\n        # allow us to passing the actual Grouping as the gpr\n        ping = (\n            Grouping(\n                group_axis,\n                gpr,\n                obj=obj,\n                name=name,\n                level=level,\n                sort=sort,\n                observed=observed,\n                in_axis=in_axis,\n                dropna=dropna,\n            )\n            if not isinstance(gpr, Grouping)\n            else gpr\n        )\n\n        groupings.append(ping)\n\n    if len(groupings) == 0 and len(obj):\n        raise ValueError(\"No group keys passed!\")\n    elif len(groupings) == 0:\n        groupings.append(Grouping(Index([], dtype=\"int\"), np.array([], dtype=np.intp)))\n\n    # create the internals grouper\n    grouper = ops.BaseGrouper(group_axis, groupings, sort=sort, mutated=mutated)\n    return grouper, exclusions, obj\n",
    "1.1.2": "Create and return a BaseGrouper, which is an internal\nmapping of how to create the grouper indexers.\nThis may be composed of multiple Grouping objects, indicating\nmultiple groupers\n\nGroupers are ultimately index mappings. They can originate as:\nindex mappings, keys to columns, functions, or Groupers\n\nGroupers enable local references to axis,level,sort, while\nthe passed in axis, level, and sort are 'global'.\n\nThis routine tries to figure out what the passing in references\nare and then creates a Grouping for each one, combined into\na BaseGrouper.\n\nIf observed & we have a categorical grouper, only show the observed\nvalues.\n\nIf validate, then check for key/level overlaps.",
    "1.2.1": null,
    "1.2.2": null,
    "1.2.3": null,
    "1.3.1": "/Volumes/SSD2T/bgp_envs/repos/pandas_6/pandas/core/groupby/grouper.py",
    "1.3.2": [
        "_is_label_like(val) -> bool",
        "_get_grouper(self, obj, validate: bool=True)",
        "is_in_axis(key) -> bool",
        "is_in_obj(gpr) -> bool"
    ],
    "1.4.1": [
        "def test_size_period_index():\n    # https://github.com/pandas-dev/pandas/issues/34010\n    ser = Series([1], index=PeriodIndex([\"2000\"], name=\"A\", freq=\"D\"))\n    grp = ser.groupby(level=\"A\")\n    result = grp.size()\n    tm.assert_series_equal(result, ser)"
    ],
    "1.4.2": [
        "/Volumes/SSD2T/bgp_envs/repos/pandas_6/pandas/tests/groupby/test_size.py"
    ],
    "2.1.1": [
        [
            "E   ValueError: Given date string not likely a datetime."
        ]
    ],
    "2.1.2": [
        [
            "def test_size_period_index():\n        # https://github.com/pandas-dev/pandas/issues/34010\n        ser = Series([1], index=PeriodIndex([\"2000\"], name=\"A\", freq=\"D\"))\n>       grp = ser.groupby(level=\"A\")\n\npandas/tests/groupby/test_size.py:44: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \npandas/core/series.py:1655: in groupby\n    return SeriesGroupBy(\npandas/core/groupby/groupby.py:522: in __init__\n    grouper, exclusions, obj = get_grouper(\npandas/core/groupby/grouper.py:762: in get_grouper\n    if is_in_obj(gpr):  # df.groupby(df['name'])\npandas/core/groupby/grouper.py:756: in is_in_obj\n    return gpr is obj[gpr.name]\npandas/core/series.py:878: in __getitem__\n    return self._get_value(key)\npandas/core/series.py:991: in _get_value\n    loc = self.index.get_loc(label)\npandas/core/indexes/period.py:499: in get_loc\n    asdt, reso = parse_time_string(key, self.freq)\npandas/_libs/tslibs/parsing.pyx:281: in pandas._libs.tslibs.parsing.parse_time_string\n    res = parse_datetime_string_with_reso(arg, freq=freq,\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n>   raise ValueError('Given date string not likely a datetime.')",
            "\npandas/_libs/tslibs/parsing.pyx:308: ValueError"
        ]
    ],
    "2.1.3": [
        [
            {
                "obj._get_axis": "<bound method NDFrame._get_axis of A\n2000-01-01    1\nFreq: D, dtype: int64>",
                "obj": "A\n2000-01-01    1\nFreq: D, dtype: int64",
                "axis": "0",
                "level": "'A'",
                "obj._get_axis_name": "<bound method NDFrame._get_axis_name of <class 'pandas.core.series.Series'>>",
                "obj.index": "PeriodIndex(['2000-01-01'], dtype='period[D]', name='A', freq='D')",
                "obj.axes": "[PeriodIndex(['2000-01-01'], dtype='period[D]', name='A', freq='D')]",
                "validate": "True",
                "obj._check_label_or_level_ambiguity": "<bound method NDFrame._check_label_or_level_ambiguity of A\n2000-01-01    1\nFreq: D, dtype: int64>",
                "obj._is_level_reference": "<bound method NDFrame._is_level_reference of A\n2000-01-01    1\nFreq: D, dtype: int64>",
                "obj.shape": "(1,)",
                "sort": "True",
                "observed": "False",
                "dropna": "True",
                "mutated": "False"
            },
            {
                "group_axis": "PeriodIndex(['2000-01-01'], dtype='period[D]', name='A', freq='D')",
                "key": "PeriodIndex(['2000-01-01'], dtype='period[D]', name='A', freq='D')",
                "group_axis.get_level_values": "<bound method Index._get_level_values of PeriodIndex(['2000-01-01'], dtype='period[D]', name='A', freq='D')>",
                "keys": "[PeriodIndex(['2000-01-01'], dtype='period[D]', name='A', freq='D')]",
                "match_axis_length": "False",
                "any_callable": "False",
                "any_groupers": "False",
                "any_arraylike": "True",
                "levels": "[None]",
                "groupings": "[]",
                "exclusions": "[]",
                "gpr": "PeriodIndex(['2000-01-01'], dtype='period[D]', name='A', freq='D')",
                "gpr.name": "'A'",
                "i": "0",
                "is_in_obj": "<function get_grouper.<locals>.is_in_obj at 0x11ec0fdc0>",
                "is_in_axis": "<function get_grouper.<locals>.is_in_axis at 0x11ec0fe50>"
            }
        ]
    ],
    "2.1.4": [
        [
            {
                "obj._get_axis": "method",
                "obj": "Series",
                "axis": "int",
                "level": "str",
                "obj._get_axis_name": "method",
                "obj.index": "PeriodIndex",
                "obj.axes": "list",
                "validate": "bool",
                "obj._check_label_or_level_ambiguity": "method",
                "obj._is_level_reference": "method",
                "obj.shape": "tuple",
                "sort": "bool",
                "observed": "bool",
                "dropna": "bool",
                "mutated": "bool"
            },
            {
                "group_axis": "PeriodIndex",
                "key": "PeriodIndex",
                "group_axis.get_level_values": "method",
                "keys": "list",
                "match_axis_length": "bool",
                "any_callable": "bool",
                "any_groupers": "bool",
                "any_arraylike": "bool",
                "levels": "list",
                "groupings": "list",
                "exclusions": "list",
                "gpr": "PeriodIndex",
                "gpr.name": "str",
                "i": "int",
                "is_in_obj": "function",
                "is_in_axis": "function"
            }
        ]
    ],
    "2.1.5": [
        [
            {
                "obj._get_axis": "<bound method NDFrame._get_axis of A\n2000-01-01    1\nFreq: D, dtype: int64>",
                "obj": "A\n2000-01-01    1\nFreq: D, dtype: int64",
                "axis": "0",
                "level": "'A'",
                "obj._get_axis_name": "<bound method NDFrame._get_axis_name of <class 'pandas.core.series.Series'>>",
                "obj.index": "PeriodIndex(['2000-01-01'], dtype='period[D]', name='A', freq='D')",
                "obj.axes": "[PeriodIndex(['2000-01-01'], dtype='period[D]', name='A', freq='D')]",
                "validate": "True",
                "obj._check_label_or_level_ambiguity": "<bound method NDFrame._check_label_or_level_ambiguity of A\n2000-01-01    1\nFreq: D, dtype: int64>",
                "obj._is_level_reference": "<bound method NDFrame._is_level_reference of A\n2000-01-01    1\nFreq: D, dtype: int64>",
                "obj.shape": "(1,)",
                "sort": "True",
                "observed": "False",
                "dropna": "True",
                "mutated": "False"
            },
            {
                "group_axis": "PeriodIndex(['2000-01-01'], dtype='period[D]', name='A', freq='D')",
                "key": "PeriodIndex(['2000-01-01'], dtype='period[D]', name='A', freq='D')",
                "group_axis.get_level_values": "<bound method Index._get_level_values of PeriodIndex(['2000-01-01'], dtype='period[D]', name='A', freq='D')>",
                "keys": "[PeriodIndex(['2000-01-01'], dtype='period[D]', name='A', freq='D')]",
                "match_axis_length": "False",
                "any_callable": "False",
                "any_groupers": "False",
                "any_arraylike": "True",
                "levels": "[None]",
                "groupings": "[]",
                "exclusions": "[]",
                "gpr": "PeriodIndex(['2000-01-01'], dtype='period[D]', name='A', freq='D')",
                "gpr.name": "'A'",
                "i": "0",
                "is_in_obj": "<function get_grouper.<locals>.is_in_obj at 0x1152bddc0>",
                "is_in_axis": "<function get_grouper.<locals>.is_in_axis at 0x1152bde50>"
            }
        ]
    ],
    "2.1.6": [
        [
            {
                "obj._get_axis": "method",
                "obj": "Series",
                "axis": "int",
                "level": "str",
                "obj._get_axis_name": "method",
                "obj.index": "PeriodIndex",
                "obj.axes": "list",
                "validate": "bool",
                "obj._check_label_or_level_ambiguity": "method",
                "obj._is_level_reference": "method",
                "obj.shape": "tuple",
                "sort": "bool",
                "observed": "bool",
                "dropna": "bool",
                "mutated": "bool"
            },
            {
                "group_axis": "PeriodIndex",
                "key": "PeriodIndex",
                "group_axis.get_level_values": "method",
                "keys": "list",
                "match_axis_length": "bool",
                "any_callable": "bool",
                "any_groupers": "bool",
                "any_arraylike": "bool",
                "levels": "list",
                "groupings": "list",
                "exclusions": "list",
                "gpr": "PeriodIndex",
                "gpr.name": "str",
                "i": "int",
                "is_in_obj": "function",
                "is_in_axis": "function"
            }
        ]
    ],
    "3.1.1": [
        "BUG: ValueError: Given date string not likely a datetime when grouping by PeriodIndex level\n"
    ],
    "3.1.2": [
        " I have checked that this issue has not already been reported.\n I have confirmed this bug exists on the latest version of pandas.\n (optional) I have confirmed this bug exists on the master branch of pandas.\nCode Sample, a copy-pastable example\nIn [10]: t = pd.Series([1], index=pd.PeriodIndex(['2000'], name=\"A\", freq=\"D\"))\n\nIn [11]: t.groupby(level=\"A\").size()\n---------------------------------------------------------------------------\nKeyError                                  Traceback (most recent call last)\n~/Envs/dask-dev/lib/python3.7/site-packages/pandas/core/indexes/period.py in get_loc(self, key, method, tolerance)\n    593         try:\n--> 594             return self._engine.get_loc(key)\n    595         except KeyError:\n\npandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc()\n\npandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc()\n\npandas/_libs/index_class_helper.pxi in pandas._libs.index.Int64Engine._check_type()\n\nKeyError: 'A'\n\nDuring handling of the above exception, another exception occurred:\n\nValueError                                Traceback (most recent call last)\n<ipython-input-11-ca2eac2f77ff> in <module>\n----> 1 t.groupby(\"A\").size()\n\n~/Envs/dask-dev/lib/python3.7/site-packages/pandas/core/series.py in groupby(self, by, axis, level, as_index, sort, group_keys, squeeze, observed)\n   1685             group_keys=group_keys,\n   1686             squeeze=squeeze,\n-> 1687             observed=observed,\n   1688         )\n   1689\n\n~/Envs/dask-dev/lib/python3.7/site-packages/pandas/core/groupby/groupby.py in __init__(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated)\n    407                 sort=sort,\n    408                 observed=observed,\n--> 409                 mutated=self.mutated,\n    410             )\n    411\n\n~/Envs/dask-dev/lib/python3.7/site-packages/pandas/core/groupby/grouper.py in get_grouper(obj, key, axis, level, sort, observed, mutated, validate)\n    588\n    589         elif is_in_axis(gpr):  # df.groupby('name')\n--> 590             if gpr in obj:\n    591                 if validate:\n    592                     obj._check_label_or_level_ambiguity(gpr, axis=axis)\n\n~/Envs/dask-dev/lib/python3.7/site-packages/pandas/core/generic.py in __contains__(self, key)\n   1848     def __contains__(self, key) -> bool_t:\n   1849         \"\"\"True if the key is in the info axis\"\"\"\n-> 1850         return key in self._info_axis\n   1851\n   1852     @property\n\n~/Envs/dask-dev/lib/python3.7/site-packages/pandas/core/indexes/period.py in __contains__(self, key)\n    384         else:\n    385             try:\n--> 386                 self.get_loc(key)\n    387                 return True\n    388             except (TypeError, KeyError):\n\n~/Envs/dask-dev/lib/python3.7/site-packages/pandas/core/indexes/period.py in get_loc(self, key, method, tolerance)\n    598\n    599             try:\n--> 600                 asdt, parsed, reso = parse_time_string(key, self.freq)\n    601                 key = asdt\n    602             except TypeError:\n\npandas/_libs/tslibs/parsing.pyx in pandas._libs.tslibs.parsing.parse_time_string()\n\npandas/_libs/tslibs/parsing.pyx in pandas._libs.tslibs.parsing.parse_datetime_string_with_reso()\n\nValueError: Given date string not likely a datetime.\nProblem description\nWith a regular Index, we see the following\n\nIn [13]: s = pd.Series([1], index=pd.Index(['a'], name='A'))\n\nIn [14]: s.groupby(level=\"A\").size()\nOut[14]:\nA\na    1\ndtype: int64\nThis seems to only affect PeriodIndex. DatetimeIndex works fine.\n\nExpected Output\nA\n2000-01-01    1\nFreq: D, dtype: int64\n"
    ]
}