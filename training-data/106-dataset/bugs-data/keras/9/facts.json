{
    "1.1.1": "def process_list_block(docstring, starting_point, section_end,\n                       leading_spaces, marker):\n    ending_point = docstring.find('\\n\\n', starting_point)\n    block = docstring[starting_point:(None if ending_point == -1 else\n                                      ending_point - 1)]\n    # Place marker for later reinjection.\n    docstring_slice = docstring[starting_point:section_end].replace(block, marker)\n    docstring = (docstring[:starting_point]\n                 + docstring_slice\n                 + docstring[section_end:])\n    lines = block.split('\\n')\n    # Remove the computed number of leading white spaces from each line.\n    lines = [re.sub('^' + ' ' * leading_spaces, '', line) for line in lines]\n    # Usually lines have at least 4 additional leading spaces.\n    # These have to be removed, but first the list roots have to be detected.\n    top_level_regex = r'^    ([^\\s\\\\\\(]+):(.*)'\n    top_level_replacement = r'- __\\1__:\\2'\n    lines = [re.sub(top_level_regex, top_level_replacement, line) for line in lines]\n    # All the other lines get simply the 4 leading space (if present) removed\n    lines = [re.sub(r'^    ', '', line) for line in lines]\n    # Fix text lines after lists\n    indent = 0\n    text_block = False\n    for i in range(len(lines)):\n        line = lines[i]\n        spaces = re.search(r'\\S', line)\n        if spaces:\n            # If it is a list element\n            if line[spaces.start()] == '-':\n                indent = spaces.start() + 1\n                if text_block:\n                    text_block = False\n                    lines[i] = '\\n' + line\n            elif spaces.start() < indent:\n                text_block = True\n                indent = spaces.start()\n                lines[i] = '\\n' + line\n        else:\n            text_block = False\n            indent = 0\n    block = '\\n'.join(lines)\n    return docstring, block\n",
    "1.1.2": null,
    "1.2.1": null,
    "1.2.2": null,
    "1.2.3": null,
    "1.3.1": "/Volumes/SSD2T/bgp_envs_non_pandas/repos/keras_9/docs/autogen.py",
    "1.3.2": null,
    "1.4.1": [
        "def test_masking_is_all_zeros():\n    x = y = np.array([[[0], [0]]])\n    model = create_masking_model()\n    loss = model.train_on_batch(x, y)\n    assert loss == 0"
    ],
    "1.4.2": [
        "/Volumes/SSD2T/bgp_envs_non_pandas/repos/keras_9/tests/test_loss_masking.py"
    ],
    "2.1.1": [
        [
            "E     TypeError: len is not well defined for symbolic Tensors. (loss/time_distributed_1_loss/truediv_1:0) Please call `x.shape` rather than `len(x)` for shape information."
        ]
    ],
    "2.1.2": [
        [
            "def test_masking_is_all_zeros():\n        x = y = np.array([[[0], [0]]])\n>       model = create_masking_model()\n\ntests/test_loss_masking.py:32: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/test_loss_masking.py:15: in create_masking_model\n    model.compile(loss='mse', optimizer='sgd')\nkeras/engine/training.py:342: in compile\n    sample_weight, mask)\nkeras/engine/training_utils.py:312: in weighted\n    entry_365.append((start_databcd_nonsense_32, {'fn': type(fn).__name__ + '|' + repr(fn) + '|' + (str(len(fn)) if hasattr(fn, '__len__') and (not isinstance(fn, type)) else '') + '|' + (repr(getattr(fn, 'shape', 'No shape')) if hasattr(fn, 'shape') else '') if 'fn' in locals() else 'None', 'score_array': type(score_array).__name__ + '|' + repr(score_array) + '|' + (str(len(score_array)) if hasattr(score_array, '__len__') and (not isinstance(score_array, type)) else '') + '|' + (repr(getattr(score_array, 'shape', 'No shape')) if hasattr(score_array, 'shape') else '') if 'score_array' in locals() else 'None', 'y_true': type(y_true).__name__ + '|' + repr(y_true) + '|' + (str(len(y_true)) if hasattr(y_true, '__len__') and (not isinstance(y_true, type)) else '') + '|' + (repr(getattr(y_true, 'shape', 'No shape')) if hasattr(y_true, 'shape') else '') if 'y_true' in locals() else 'None', 'y_pred': type(y_pred).__name__ + '|' + repr(y_pred) + '|' + (str(len(y_pred)) if hasattr(y_pred, '__len__') and (not isinstance(y_pred, type)) else '') + '|' + (repr(getattr(y_pred, 'shape', 'No shape')) if hasattr(y_pred, 'shape') else '') if 'y_pred' in locals() else 'None', 'mask': type(mask).__name__ + '|' + repr(mask) + '|' + (str(len(mask)) if hasattr(mask, '__len__') and (not isinstance(mask, type)) else '') + '|' + (repr(getattr(mask, 'shape', 'No shape')) if hasattr(mask, 'shape') else '') if 'mask' in locals() else 'None', 'K.cast': type(getattr(K, 'cast', None)).__name__ + '|' + repr(getattr(K, 'cast', None)) + '|' + (str(len(getattr(K, 'cast', None))) if hasattr(getattr(K, 'cast', None), '__len__') and (not isinstance(getattr(K, 'cast', None), type)) else '') + '|' + (repr(getattr(getattr(K, 'cast', None), 'shape')) if hasattr(getattr(K, 'cast', None), 'shape') else '') if 'K' in locals() else 'None', 'K': type(K).__name__ + '|' + repr(K) + '|' + (str(len(K)) if hasattr(K, '__len__') and (not isinstance(K, type)) else '') + '|' + (repr(getattr(K, 'shape', 'No shape')) if hasattr(K, 'shape') else '') if 'K' in locals() else 'None', 'K.floatx': type(getattr(K, 'floatx', None)).__name__ + '|' + repr(getattr(K, 'floatx', None)) + '|' + (str(len(getattr(K, 'floatx', None))) if hasattr(getattr(K, 'floatx', None), '__len__') and (not isinstance(getattr(K, 'floatx', None), type)) else '') + '|' + (repr(getattr(getattr(K, 'floatx', None), 'shape')) if hasattr(getattr(K, 'floatx', None), 'shape') else '') if 'K' in locals() else 'None', 'K.mean': type(getattr(K, 'mean', None)).__name__ + '|' + repr(getattr(K, 'mean', None)) + '|' + (str(len(getattr(K, 'mean', None))) if hasattr(getattr(K, 'mean', None), '__len__') and (not isinstance(getattr(K, 'mean', None), type)) else '') + '|' + (repr(getattr(getattr(K, 'mean', None), 'shape')) if hasattr(getattr(K, 'mean', None), 'shape') else '') if 'K' in locals() else 'None', 'K.epsilon': type(getattr(K, 'epsilon', None)).__name__ + '|' + repr(getattr(K, 'epsilon', None)) + '|' + (str(len(getattr(K, 'epsilon', None))) if hasattr(getattr(K, 'epsilon', None), '__len__') and (not isinstance(getattr(K, 'epsilon', None), type)) else '') + '|' + (repr(getattr(getattr(K, 'epsilon', None), 'shape')) if hasattr(getattr(K, 'epsilon', None), 'shape') else '') if 'K' in locals() else 'None', 'weights': type(weights).__name__ + '|' + repr(weights) + '|' + (str(len(weights)) if hasattr(weights, '__len__') and (not isinstance(weights, type)) else '') + '|' + (repr(getattr(weights, 'shape', 'No shape')) if hasattr(weights, 'shape') else '') if 'weights' in locals() else 'None', 'ndim': type(ndim).__name__ + '|' + repr(ndim) + '|' + (str(len(ndim)) if hasattr(ndim, '__len__') and (not isinstance(ndim, type)) else '') + '|' + (repr(getattr(ndim, 'shape', 'No shape')) if hasattr(ndim, 'shape') else '') if 'ndim' in locals() else 'None', 'K.ndim': type(getattr(K, 'ndim', None)).__name__ + '|' + repr(getattr(K, 'ndim', None)) + '|' + (str(len(getattr(K, 'ndim', None))) if hasattr(getattr(K, 'ndim', None), '__len__') and (not isinstance(getattr(K, 'ndim', None), type)) else '') + '|' + (repr(getattr(getattr(K, 'ndim', None), 'shape')) if hasattr(getattr(K, 'ndim', None), 'shape') else '') if 'K' in locals() else 'None', 'weight_ndim': type(weight_ndim).__name__ + '|' + repr(weight_ndim) + '|' + (str(len(weight_ndim)) if hasattr(weight_ndim, '__len__') and (not isinstance(weight_ndim, type)) else '') + '|' + (repr(getattr(weight_ndim, 'shape', 'No shape')) if hasattr(weight_ndim, 'shape') else '') if 'weight_ndim' in locals() else 'None', 'K.not_equal': type(getattr(K, 'not_equal', None)).__name__ + '|' + repr(getattr(K, 'not_equal', None)) + '|' + (str(len(getattr(K, 'not_equal', None))) if hasattr(getattr(K, 'not_equal', None), '__len__') and (not isinstance(getattr(K, 'not_equal', None), type)) else '') + '|' + (repr(getattr(getattr(K, 'not_equal', None), 'shape')) if hasattr(getattr(K, 'not_equal', None), 'shape') else '') if 'K' in locals() else 'None', 'weighted': type(weighted).__name__ + '|' + repr(weighted) + '|' + (str(len(weighted)) if hasattr(weighted, '__len__') and (not isinstance(weighted, type)) else '') + '|' + (repr(getattr(weighted, 'shape', 'No shape')) if hasattr(weighted, 'shape') else '') if 'weighted' in locals() else 'None'}))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <tf.Tensor 'loss/time_distributed_1_loss/truediv_1:0' shape=(?,) dtype=float32>\n\n    def __len__(self):\n      raise TypeError(\"len is not well defined for symbolic Tensors. ({}) \"\n                      \"Please call `x.shape` rather than `len(x)` for \"\n>                     \"shape information.\".format(self.name))",
            "\n../../envs/keras_6/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:741: TypeError"
        ]
    ],
    "2.1.3": null,
    "2.1.4": null,
    "2.1.5": null,
    "2.1.6": null,
    "3.1.1": [
        "Callbacks documentation not showing bullet points correctly\n",
        "EarlyStopping documentation with wrong format\n"
    ],
    "3.1.2": [
        "The current documentation on callbacks isn't showing bullet points correctly under the \"Arguments\" section of a few models. Here's the example for ModelCheckpoint:\n\nfilepath: string, path to save the model file. monitor: quantity to monitor. verbose: verbosity mode, 0 or 1. save_best_only: if save_best_only=True, the latest best model according to the quantity monitored will not be overwritten. mode: one of {auto, min, max}. If save_best_only=True, the decision to overwrite the current save file is made based on either the maximization or the minimization of the monitored quantity. For val_acc, this should be max, for val_loss this should be min, etc. In auto mode, the direction is automatically inferred from the name of the monitored quantity. save_weights_only: if True, then only the model's weights will be saved (model.save_weights(filepath)), else the full model is saved (model.save(filepath)). period: Interval (number of epochs) between checkpoints.\n\nLooking at the source code, the docstring seems to be organized correctly:\nkeras/keras/callbacks.py\n\nLines 371 to 390 in dc9e510\n\n     # Arguments \n         filepath: string, path to save the model file. \n         monitor: quantity to monitor. \n         verbose: verbosity mode, 0 or 1. \n         save_best_only: if `save_best_only=True`, \n             the latest best model according to \n             the quantity monitored will not be overwritten. \n         mode: one of {auto, min, max}. \n             If `save_best_only=True`, the decision \n             to overwrite the current save file is made \n             based on either the maximization or the \n             minimization of the monitored quantity. For `val_acc`, \n             this should be `max`, for `val_loss` this should \n             be `min`, etc. In `auto` mode, the direction is \n             automatically inferred from the name of the monitored quantity. \n         save_weights_only: if True, then only the model's weights will be \n             saved (`model.save_weights(filepath)`), else the full model \n             is saved (`model.save(filepath)`). \n         period: Interval (number of epochs) between checkpoints. \n     \"\"\" \nIt is however showing up correctly for other models, e.g. ProgbarLogger:\n\nArguments\ncount_mode: One of \"steps\" or \"samples\". Whether the progress bar should count samples seen or steps (batches) seen.\nstateful_metrics: Iterable of string names of metrics that should not be averaged over an epoch. Metrics in this list will be logged as-is. All others will be averaged over time (e.g. loss, etc).\n",
        "EarlyStopping documentation has the wrong format. See here:\nhttps://keras.io/callbacks/#earlystopping\n\nThe Arguments section is bugged.\n"
    ]
}