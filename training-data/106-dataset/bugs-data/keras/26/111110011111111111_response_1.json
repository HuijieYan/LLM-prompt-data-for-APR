{
    "keras": [
        {
            "bugID": 26,
            "bitvector": {
                "1.1.1": 1,
                "1.1.2": 1,
                "1.2.1": 1,
                "1.2.2": 1,
                "1.2.3": 1,
                "1.3.1": 0,
                "1.3.2": 0,
                "1.4.1": 1,
                "1.4.2": 1,
                "2.1.1": 1,
                "2.1.2": 1,
                "2.1.3": 1,
                "2.1.4": 1,
                "2.1.5": 1,
                "2.1.6": 1,
                "3.1.1": 1,
                "3.1.2": 1,
                "cot": 1
            },
            "strata": {
                "1": 1,
                "2": 1,
                "3": 0,
                "4": 1,
                "5": 1,
                "6": 1,
                "7": 1
            },
            "available_bitvector": {
                "1.1.1": 1,
                "1.1.2": 1,
                "1.2.1": 0,
                "1.2.2": 0,
                "1.2.3": 0,
                "1.3.1": 0,
                "1.3.2": 0,
                "1.4.1": 1,
                "1.4.2": 1,
                "2.1.1": 1,
                "2.1.2": 1,
                "2.1.3": 0,
                "2.1.4": 0,
                "2.1.5": 0,
                "2.1.6": 0,
                "3.1.1": 0,
                "3.1.2": 0,
                "cot": 1
            },
            "available_strata": {
                "1": 1,
                "2": 0,
                "3": 0,
                "4": 1,
                "5": 0,
                "6": 0,
                "7": 1
            },
            "start_line": 2676,
            "file_name": "/keras/backend/tensorflow_backend.py",
            "replace_code": "def rnn(step_function, inputs, initial_states,\n        go_backwards=False, mask=None, constants=None,\n        unroll=False, input_length=None):\n\n    \"\"\"\n    Iterates over the time dimension of a tensor.\n    \n    Arguments and Returns information remains the same as provided in the original code.\n    \n    Raises information remains the same as provided in the original code.\n    \"\"\"\n    # Transpose to time-major\n    inputs = tf.transpose(inputs, [1, 0, 2])\n    \n    states = initial_states\n    successive_states = []\n    successive_outputs = []\n    \n    if mask is not None:\n        mask = tf.transpose(mask, [1, 0])\n    \n    for t in range(inputs.shape[0]):\n        input_t = inputs[t]\n        if mask is not None:\n            mask_t = mask[t]\n            input_t = tf.where(mask_t, input_t, tf.zeros_like(input_t))\n    \n        output, states = step_function(input_t, states + constants)\n        if getattr(output, '_uses_learning_phase', False):\n            uses_learning_phase = True\n    \n        successive_outputs.append(output)\n        successive_states.append(states)\n    \n    last_output = successive_outputs[-1]\n    new_states = successive_states[-1]\n    outputs = tf.stack(successive_outputs)\n    last_output._uses_learning_phase = uses_learning_phase\n    return last_output, outputs, new_states"
        }
    ]
}