```python
def rnn(step_function, inputs, initial_states,
        go_backwards=False, mask=None, constants=None,
        unroll=False, input_length=None):
    """Iterates over the time dimension of a tensor.
    
    # Arguments
    ... [Same as before]
    """

    # Make necessary imports
    import tensorflow as tf
    from tensorflow.python.ops import while_ops

    # ... [Code snippet omitted]

    def rnn_fn(time, output_ta_t, *states):
        """RNN step function.

        # Arguments
            time: Current timestep value.
            output_ta_t: TensorArray.
            *states: List of states.

        # Returns
            Tuple: `(time + 1,output_ta_t) + tuple(new_states)`
        """
        current_input = input_ta.read(time)
        mask_time = tf.expand_dims(mask_ta.read(time), -1) if mask_ta is not None else None
        output, new_states = step_function(current_input, list(states) + list(constants))
        if getattr(output, '_uses_learning_phase', False):
            nonlocal uses_learning_phase
            uses_learning_phase = True
        new_states = [tf.where(mask_time, new_states[i], states[i]) if mask_ta is not None else new_states[i] for i in range(len(states))]
        output_ta_t = output_ta_t.write(time, output)
        return (time + 1, output_ta_t) + tuple(new_states)

    final_outputs = while_ops.while_loop(
        cond=lambda time, *_: time < time_steps,
        body=rnn_fn,
        loop_vars=(time, output_ta) + tuple(states),
        parallel_iterations=32,
        swap_memory=True)
    last_time = final_outputs[0]
    output_ta = final_outputs[1]
    new_states = final_outputs[2:]

    # ... [Code snippet omitted]

```