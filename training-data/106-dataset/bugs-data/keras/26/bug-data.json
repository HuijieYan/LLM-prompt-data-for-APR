{
    "keras:26": {
        "/Volumes/SSD2T/bgp_envs_non_pandas/repos/keras_26/keras/backend/tensorflow_backend.py": {
            "buggy_functions": [
                {
                    "function_name": "rnn",
                    "function_code": "def rnn(step_function, inputs, initial_states,\n        go_backwards=False, mask=None, constants=None,\n        unroll=False, input_length=None):\n    \"\"\"Iterates over the time dimension of a tensor.\n\n    # Arguments\n        step_function: RNN step function.\n            Parameters:\n                inputs: tensor with shape `(samples, ...)` (no time dimension),\n                    representing input for the batch of samples at a certain\n                    time step.\n                states: list of tensors.\n            Returns:\n                outputs: tensor with shape `(samples, output_dim)`\n                    (no time dimension).\n                new_states: list of tensors, same length and shapes\n                    as 'states'. The first state in the list must be the\n                    output tensor at the previous timestep.\n        inputs: tensor of temporal data of shape `(samples, time, ...)`\n            (at least 3D).\n        initial_states: tensor with shape (samples, output_dim)\n            (no time dimension),\n            containing the initial values for the states used in\n            the step function.\n        go_backwards: boolean. If True, do the iteration over the time\n            dimension in reverse order and return the reversed sequence.\n        mask: binary tensor with shape `(samples, time, 1)`,\n            with a zero for every element that is masked.\n        constants: a list of constant values passed at each step.\n        unroll: whether to unroll the RNN or to use a symbolic loop (`while_loop` or `scan` depending on backend).\n        input_length: not relevant in the TensorFlow implementation.\n            Must be specified if using unrolling with Theano.\n\n    # Returns\n        A tuple, `(last_output, outputs, new_states)`.\n\n            last_output: the latest output of the rnn, of shape `(samples, ...)`\n            outputs: tensor with shape `(samples, time, ...)` where each\n                entry `outputs[s, t]` is the output of the step function\n                at time `t` for sample `s`.\n            new_states: list of tensors, latest states returned by\n                the step function, of shape `(samples, ...)`.\n\n    # Raises\n        ValueError: if input dimension is less than 3.\n        ValueError: if `unroll` is `True` but input timestep is not a fixed number.\n        ValueError: if `mask` is provided (not `None`) but states is not provided\n            (`len(states)` == 0).\n    \"\"\"\n    ndim = len(inputs.get_shape())\n    if ndim < 3:\n        raise ValueError('Input should be at least 3D.')\n\n    # Transpose to time-major, i.e.\n    # from (batch, time, ...) to (time, batch, ...)\n    axes = [1, 0] + list(range(2, ndim))\n    inputs = tf.transpose(inputs, (axes))\n\n    if mask is not None:\n        if mask.dtype != tf.bool:\n            mask = tf.cast(mask, tf.bool)\n        if len(mask.get_shape()) == ndim - 1:\n            mask = expand_dims(mask)\n        mask = tf.transpose(mask, axes)\n\n    if constants is None:\n        constants = []\n\n    global uses_learning_phase\n    uses_learning_phase = False\n\n    if unroll:\n        if not inputs.get_shape()[0]:\n            raise ValueError('Unrolling requires a '\n                             'fixed number of timesteps.')\n        states = initial_states\n        successive_states = []\n        successive_outputs = []\n\n        input_list = tf.unstack(inputs)\n        if go_backwards:\n            input_list.reverse()\n\n        if mask is not None:\n            mask_list = tf.unstack(mask)\n            if go_backwards:\n                mask_list.reverse()\n\n            for inp, mask_t in zip(input_list, mask_list):\n                output, new_states = step_function(inp, states + constants)\n                if getattr(output, '_uses_learning_phase', False):\n                    uses_learning_phase = True\n\n                # tf.where needs its condition tensor\n                # to be the same shape as its two\n                # result tensors, but in our case\n                # the condition (mask) tensor is\n                # (nsamples, 1), and A and B are (nsamples, ndimensions).\n                # So we need to\n                # broadcast the mask to match the shape of A and B.\n                # That's what the tile call does,\n                # it just repeats the mask along its second dimension\n                # n times.\n                tiled_mask_t = tf.tile(mask_t,\n                                       tf.stack([1, tf.shape(output)[1]]))\n\n                if not successive_outputs:\n                    prev_output = zeros_like(output)\n                else:\n                    prev_output = successive_outputs[-1]\n\n                output = tf.where(tiled_mask_t, output, prev_output)\n\n                return_states = []\n                for state, new_state in zip(states, new_states):\n                    # (see earlier comment for tile explanation)\n                    tiled_mask_t = tf.tile(mask_t,\n                                           tf.stack([1, tf.shape(new_state)[1]]))\n                    return_states.append(tf.where(tiled_mask_t,\n                                                  new_state,\n                                                  state))\n                states = return_states\n                successive_outputs.append(output)\n                successive_states.append(states)\n            last_output = successive_outputs[-1]\n            new_states = successive_states[-1]\n            outputs = tf.stack(successive_outputs)\n        else:\n            for inp in input_list:\n                output, states = step_function(inp, states + constants)\n                if getattr(output, '_uses_learning_phase', False):\n                    uses_learning_phase = True\n                successive_outputs.append(output)\n                successive_states.append(states)\n            last_output = successive_outputs[-1]\n            new_states = successive_states[-1]\n            outputs = tf.stack(successive_outputs)\n\n    else:\n        if go_backwards:\n            inputs = reverse(inputs, 0)\n\n        states = tuple(initial_states)\n\n        time_steps = tf.shape(inputs)[0]\n        outputs, _ = step_function(inputs[0], initial_states + constants)\n        output_ta = tensor_array_ops.TensorArray(\n            dtype=outputs.dtype,\n            size=time_steps,\n            tensor_array_name='output_ta')\n        input_ta = tensor_array_ops.TensorArray(\n            dtype=inputs.dtype,\n            size=time_steps,\n            tensor_array_name='input_ta')\n        input_ta = input_ta.unstack(inputs)\n        time = tf.constant(0, dtype='int32', name='time')\n\n        if mask is not None:\n            if not states:\n                raise ValueError('No initial states provided! '\n                                 'When using masking in an RNN, you should '\n                                 'provide initial states '\n                                 '(and your step function should return '\n                                 'as its first state at time `t` '\n                                 'the output at time `t-1`).')\n            if go_backwards:\n                mask = reverse(mask, 0)\n\n            mask_ta = tensor_array_ops.TensorArray(\n                dtype=tf.bool,\n                size=time_steps,\n                tensor_array_name='mask_ta')\n            mask_ta = mask_ta.unstack(mask)\n\n            def _step(time, output_ta_t, *states):\n                \"\"\"RNN step function.\n\n                # Arguments\n                    time: Current timestep value.\n                    output_ta_t: TensorArray.\n                    *states: List of states.\n\n                # Returns\n                    Tuple: `(time + 1,output_ta_t) + tuple(new_states)`\n                \"\"\"\n                current_input = input_ta.read(time)\n                mask_t = mask_ta.read(time)\n                output, new_states = step_function(current_input,\n                                                   tuple(states) +\n                                                   tuple(constants))\n                if getattr(output, '_uses_learning_phase', False):\n                    global uses_learning_phase\n                    uses_learning_phase = True\n                for state, new_state in zip(states, new_states):\n                    new_state.set_shape(state.get_shape())\n                tiled_mask_t = tf.tile(mask_t,\n                                       tf.stack([1, tf.shape(output)[1]]))\n                output = tf.where(tiled_mask_t, output, states[0])\n                new_states = [tf.where(tiled_mask_t, new_states[i], states[i]) for i in range(len(states))]\n                output_ta_t = output_ta_t.write(time, output)\n                return (time + 1, output_ta_t) + tuple(new_states)\n        else:\n            def _step(time, output_ta_t, *states):\n                \"\"\"RNN step function.\n\n                # Arguments\n                    time: Current timestep value.\n                    output_ta_t: TensorArray.\n                    *states: List of states.\n\n                # Returns\n                    Tuple: `(time + 1,output_ta_t) + tuple(new_states)`\n                \"\"\"\n                current_input = input_ta.read(time)\n                output, new_states = step_function(current_input,\n                                                   tuple(states) +\n                                                   tuple(constants))\n                if getattr(output, '_uses_learning_phase', False):\n                    global uses_learning_phase\n                    uses_learning_phase = True\n                for state, new_state in zip(states, new_states):\n                    new_state.set_shape(state.get_shape())\n                output_ta_t = output_ta_t.write(time, output)\n                return (time + 1, output_ta_t) + tuple(new_states)\n\n        final_outputs = control_flow_ops.while_loop(\n            cond=lambda time, *_: time < time_steps,\n            body=_step,\n            loop_vars=(time, output_ta) + states,\n            parallel_iterations=32,\n            swap_memory=True)\n        last_time = final_outputs[0]\n        output_ta = final_outputs[1]\n        new_states = final_outputs[2:]\n\n        outputs = output_ta.stack()\n        last_output = output_ta.read(last_time - 1)\n\n    axes = [1, 0] + list(range(2, len(outputs.get_shape())))\n    outputs = tf.transpose(outputs, axes)\n    last_output._uses_learning_phase = uses_learning_phase\n    return last_output, outputs, new_states\n",
                    "decorators": [],
                    "docstring": "Iterates over the time dimension of a tensor.\n\n# Arguments\n    step_function: RNN step function.\n        Parameters:\n            inputs: tensor with shape `(samples, ...)` (no time dimension),\n                representing input for the batch of samples at a certain\n                time step.\n            states: list of tensors.\n        Returns:\n            outputs: tensor with shape `(samples, output_dim)`\n                (no time dimension).\n            new_states: list of tensors, same length and shapes\n                as 'states'. The first state in the list must be the\n                output tensor at the previous timestep.\n    inputs: tensor of temporal data of shape `(samples, time, ...)`\n        (at least 3D).\n    initial_states: tensor with shape (samples, output_dim)\n        (no time dimension),\n        containing the initial values for the states used in\n        the step function.\n    go_backwards: boolean. If True, do the iteration over the time\n        dimension in reverse order and return the reversed sequence.\n    mask: binary tensor with shape `(samples, time, 1)`,\n        with a zero for every element that is masked.\n    constants: a list of constant values passed at each step.\n    unroll: whether to unroll the RNN or to use a symbolic loop (`while_loop` or `scan` depending on backend).\n    input_length: not relevant in the TensorFlow implementation.\n        Must be specified if using unrolling with Theano.\n\n# Returns\n    A tuple, `(last_output, outputs, new_states)`.\n\n        last_output: the latest output of the rnn, of shape `(samples, ...)`\n        outputs: tensor with shape `(samples, time, ...)` where each\n            entry `outputs[s, t]` is the output of the step function\n            at time `t` for sample `s`.\n        new_states: list of tensors, latest states returned by\n            the step function, of shape `(samples, ...)`.\n\n# Raises\n    ValueError: if input dimension is less than 3.\n    ValueError: if `unroll` is `True` but input timestep is not a fixed number.\n    ValueError: if `mask` is provided (not `None`) but states is not provided\n        (`len(states)` == 0).",
                    "start_line": 2676,
                    "end_line": 2917,
                    "variables": {
                        "ndim": [
                            2737,
                            2731,
                            2725,
                            2726
                        ],
                        "len": [
                            2737,
                            2874,
                            2725,
                            2914
                        ],
                        "inputs.get_shape": [
                            2748,
                            2725
                        ],
                        "inputs": [
                            2816,
                            2755,
                            2820,
                            2725,
                            2821,
                            2827,
                            2732,
                            2830,
                            2748
                        ],
                        "ValueError": [
                            2835,
                            2749,
                            2727
                        ],
                        "axes": [
                            2914,
                            2915,
                            2731,
                            2732,
                            2739
                        ],
                        "list": [
                            2914,
                            2731
                        ],
                        "range": [
                            2874,
                            2731,
                            2914
                        ],
                        "tf.transpose": [
                            2915,
                            2739,
                            2732
                        ],
                        "tf": [
                            2820,
                            2831,
                            2845,
                            2732,
                            2735,
                            2736,
                            2739,
                            2871,
                            2872,
                            2873,
                            2874,
                            2755,
                            2760,
                            2779,
                            2780,
                            2787,
                            2915,
                            2792,
                            2793,
                            2794,
                            2802,
                            2812
                        ],
                        "mask": [
                            2848,
                            2759,
                            2760,
                            2734,
                            2735,
                            2736,
                            2737,
                            2738,
                            2739,
                            2833,
                            2842
                        ],
                        "mask.dtype": [
                            2735
                        ],
                        "tf.bool": [
                            2736,
                            2845,
                            2735
                        ],
                        "tf.cast": [
                            2736
                        ],
                        "mask.get_shape": [
                            2737
                        ],
                        "expand_dims": [
                            2738
                        ],
                        "constants": [
                            2821,
                            2892,
                            2765,
                            2865,
                            2805,
                            2741,
                            2742
                        ],
                        "uses_learning_phase": [
                            2916,
                            2895,
                            2767,
                            2868,
                            2807,
                            2745
                        ],
                        "unroll": [
                            2747
                        ],
                        "states": [
                            2818,
                            2790,
                            2891,
                            2797,
                            2765,
                            2799,
                            2864,
                            2896,
                            2834,
                            2805,
                            2869,
                            2873,
                            2904,
                            2809,
                            2874,
                            2751
                        ],
                        "initial_states": [
                            2818,
                            2821,
                            2751
                        ],
                        "successive_states": [
                            2752,
                            2799,
                            2801,
                            2809,
                            2811
                        ],
                        "successive_outputs": [
                            2753,
                            2785,
                            2798,
                            2800,
                            2802,
                            2808,
                            2810,
                            2812,
                            2782
                        ],
                        "input_list": [
                            2755,
                            2764,
                            2757,
                            2804
                        ],
                        "tf.unstack": [
                            2760,
                            2755
                        ],
                        "go_backwards": [
                            2761,
                            2756,
                            2841,
                            2815
                        ],
                        "input_list.reverse": [
                            2757
                        ],
                        "mask_list": [
                            2760,
                            2762,
                            2764
                        ],
                        "mask_list.reverse": [
                            2762
                        ],
                        "inp": [
                            2805,
                            2764,
                            2765,
                            2804
                        ],
                        "mask_t": [
                            2792,
                            2764,
                            2862,
                            2871,
                            2779
                        ],
                        "zip": [
                            2896,
                            2764,
                            2869,
                            2790
                        ],
                        "output": [
                            2787,
                            2890,
                            2765,
                            2766,
                            2798,
                            2863,
                            2893,
                            2866,
                            2872,
                            2898,
                            2805,
                            2806,
                            2808,
                            2873,
                            2875,
                            2780,
                            2783
                        ],
                        "new_states": [
                            2917,
                            2790,
                            2890,
                            2765,
                            2863,
                            2896,
                            2801,
                            2899,
                            2869,
                            2874,
                            2811,
                            2876,
                            2909
                        ],
                        "step_function": [
                            2821,
                            2890,
                            2765,
                            2863,
                            2805
                        ],
                        "getattr": [
                            2806,
                            2866,
                            2893,
                            2766
                        ],
                        "tiled_mask_t": [
                            2787,
                            2792,
                            2794,
                            2871,
                            2873,
                            2874,
                            2779
                        ],
                        "tf.tile": [
                            2792,
                            2779,
                            2871
                        ],
                        "tf.stack": [
                            2812,
                            2793,
                            2802,
                            2872,
                            2780
                        ],
                        "tf.shape": [
                            2872,
                            2793,
                            2780,
                            2820
                        ],
                        "prev_output": [
                            2785,
                            2787,
                            2783
                        ],
                        "zeros_like": [
                            2783
                        ],
                        "tf.where": [
                            2873,
                            2794,
                            2787,
                            2874
                        ],
                        "return_states": [
                            2797,
                            2794,
                            2789
                        ],
                        "state": [
                            2790,
                            2796,
                            2896,
                            2897,
                            2869,
                            2870
                        ],
                        "new_state": [
                            2790,
                            2793,
                            2795,
                            2896,
                            2897,
                            2869,
                            2870
                        ],
                        "return_states.append": [
                            2794
                        ],
                        "successive_outputs.append": [
                            2808,
                            2798
                        ],
                        "successive_states.append": [
                            2809,
                            2799
                        ],
                        "last_output": [
                            2912,
                            2916,
                            2917,
                            2800,
                            2810
                        ],
                        "outputs": [
                            2914,
                            2915,
                            2821,
                            2917,
                            2823,
                            2802,
                            2812,
                            2911
                        ],
                        "reverse": [
                            2816,
                            2842
                        ],
                        "tuple": [
                            2818,
                            2891,
                            2892,
                            2864,
                            2865,
                            2899,
                            2876
                        ],
                        "time_steps": [
                            2820,
                            2824,
                            2828,
                            2902,
                            2846
                        ],
                        "_": [
                            2821
                        ],
                        "output_ta": [
                            2912,
                            2822,
                            2904,
                            2908,
                            2911
                        ],
                        "tensor_array_ops.TensorArray": [
                            2826,
                            2844,
                            2822
                        ],
                        "tensor_array_ops": [
                            2826,
                            2844,
                            2822
                        ],
                        "outputs.dtype": [
                            2823
                        ],
                        "input_ta": [
                            2889,
                            2826,
                            2861,
                            2830
                        ],
                        "inputs.dtype": [
                            2827
                        ],
                        "input_ta.unstack": [
                            2830
                        ],
                        "time": [
                            2889,
                            2861,
                            2862,
                            2831,
                            2898,
                            2899,
                            2902,
                            2904,
                            2875,
                            2876
                        ],
                        "tf.constant": [
                            2831
                        ],
                        "mask_ta": [
                            2848,
                            2844,
                            2862
                        ],
                        "mask_ta.unstack": [
                            2848
                        ],
                        "current_input": [
                            2889,
                            2890,
                            2861,
                            2863
                        ],
                        "input_ta.read": [
                            2889,
                            2861
                        ],
                        "mask_ta.read": [
                            2862
                        ],
                        "new_state.set_shape": [
                            2897,
                            2870
                        ],
                        "state.get_shape": [
                            2897,
                            2870
                        ],
                        "i": [
                            2874
                        ],
                        "output_ta_t": [
                            2898,
                            2875,
                            2876,
                            2899
                        ],
                        "output_ta_t.write": [
                            2898,
                            2875
                        ],
                        "final_outputs": [
                            2907,
                            2908,
                            2901,
                            2909
                        ],
                        "control_flow_ops.while_loop": [
                            2901
                        ],
                        "control_flow_ops": [
                            2901
                        ],
                        "_step": [
                            2903
                        ],
                        "last_time": [
                            2912,
                            2907
                        ],
                        "output_ta.stack": [
                            2911
                        ],
                        "output_ta.read": [
                            2912
                        ],
                        "outputs.get_shape": [
                            2914
                        ],
                        "last_output._uses_learning_phase": [
                            2916
                        ]
                    },
                    "filtered_variables": {
                        "ndim": [
                            2737,
                            2731,
                            2725,
                            2726
                        ],
                        "inputs.get_shape": [
                            2748,
                            2725
                        ],
                        "inputs": [
                            2816,
                            2755,
                            2820,
                            2725,
                            2821,
                            2827,
                            2732,
                            2830,
                            2748
                        ],
                        "axes": [
                            2914,
                            2915,
                            2731,
                            2732,
                            2739
                        ],
                        "tf.transpose": [
                            2915,
                            2739,
                            2732
                        ],
                        "tf": [
                            2820,
                            2831,
                            2845,
                            2732,
                            2735,
                            2736,
                            2739,
                            2871,
                            2872,
                            2873,
                            2874,
                            2755,
                            2760,
                            2779,
                            2780,
                            2787,
                            2915,
                            2792,
                            2793,
                            2794,
                            2802,
                            2812
                        ],
                        "mask": [
                            2848,
                            2759,
                            2760,
                            2734,
                            2735,
                            2736,
                            2737,
                            2738,
                            2739,
                            2833,
                            2842
                        ],
                        "mask.dtype": [
                            2735
                        ],
                        "tf.bool": [
                            2736,
                            2845,
                            2735
                        ],
                        "tf.cast": [
                            2736
                        ],
                        "mask.get_shape": [
                            2737
                        ],
                        "expand_dims": [
                            2738
                        ],
                        "constants": [
                            2821,
                            2892,
                            2765,
                            2865,
                            2805,
                            2741,
                            2742
                        ],
                        "uses_learning_phase": [
                            2916,
                            2895,
                            2767,
                            2868,
                            2807,
                            2745
                        ],
                        "unroll": [
                            2747
                        ],
                        "states": [
                            2818,
                            2790,
                            2891,
                            2797,
                            2765,
                            2799,
                            2864,
                            2896,
                            2834,
                            2805,
                            2869,
                            2873,
                            2904,
                            2809,
                            2874,
                            2751
                        ],
                        "initial_states": [
                            2818,
                            2821,
                            2751
                        ],
                        "successive_states": [
                            2752,
                            2799,
                            2801,
                            2809,
                            2811
                        ],
                        "successive_outputs": [
                            2753,
                            2785,
                            2798,
                            2800,
                            2802,
                            2808,
                            2810,
                            2812,
                            2782
                        ],
                        "input_list": [
                            2755,
                            2764,
                            2757,
                            2804
                        ],
                        "tf.unstack": [
                            2760,
                            2755
                        ],
                        "go_backwards": [
                            2761,
                            2756,
                            2841,
                            2815
                        ],
                        "input_list.reverse": [
                            2757
                        ],
                        "mask_list": [
                            2760,
                            2762,
                            2764
                        ],
                        "mask_list.reverse": [
                            2762
                        ],
                        "inp": [
                            2805,
                            2764,
                            2765,
                            2804
                        ],
                        "mask_t": [
                            2792,
                            2764,
                            2862,
                            2871,
                            2779
                        ],
                        "output": [
                            2787,
                            2890,
                            2765,
                            2766,
                            2798,
                            2863,
                            2893,
                            2866,
                            2872,
                            2898,
                            2805,
                            2806,
                            2808,
                            2873,
                            2875,
                            2780,
                            2783
                        ],
                        "new_states": [
                            2917,
                            2790,
                            2890,
                            2765,
                            2863,
                            2896,
                            2801,
                            2899,
                            2869,
                            2874,
                            2811,
                            2876,
                            2909
                        ],
                        "step_function": [
                            2821,
                            2890,
                            2765,
                            2863,
                            2805
                        ],
                        "tiled_mask_t": [
                            2787,
                            2792,
                            2794,
                            2871,
                            2873,
                            2874,
                            2779
                        ],
                        "tf.tile": [
                            2792,
                            2779,
                            2871
                        ],
                        "tf.stack": [
                            2812,
                            2793,
                            2802,
                            2872,
                            2780
                        ],
                        "tf.shape": [
                            2872,
                            2793,
                            2780,
                            2820
                        ],
                        "prev_output": [
                            2785,
                            2787,
                            2783
                        ],
                        "zeros_like": [
                            2783
                        ],
                        "tf.where": [
                            2873,
                            2794,
                            2787,
                            2874
                        ],
                        "return_states": [
                            2797,
                            2794,
                            2789
                        ],
                        "state": [
                            2790,
                            2796,
                            2896,
                            2897,
                            2869,
                            2870
                        ],
                        "new_state": [
                            2790,
                            2793,
                            2795,
                            2896,
                            2897,
                            2869,
                            2870
                        ],
                        "return_states.append": [
                            2794
                        ],
                        "successive_outputs.append": [
                            2808,
                            2798
                        ],
                        "successive_states.append": [
                            2809,
                            2799
                        ],
                        "last_output": [
                            2912,
                            2916,
                            2917,
                            2800,
                            2810
                        ],
                        "outputs": [
                            2914,
                            2915,
                            2821,
                            2917,
                            2823,
                            2802,
                            2812,
                            2911
                        ],
                        "reverse": [
                            2816,
                            2842
                        ],
                        "time_steps": [
                            2820,
                            2824,
                            2828,
                            2902,
                            2846
                        ],
                        "_": [
                            2821
                        ],
                        "output_ta": [
                            2912,
                            2822,
                            2904,
                            2908,
                            2911
                        ],
                        "tensor_array_ops.TensorArray": [
                            2826,
                            2844,
                            2822
                        ],
                        "tensor_array_ops": [
                            2826,
                            2844,
                            2822
                        ],
                        "outputs.dtype": [
                            2823
                        ],
                        "input_ta": [
                            2889,
                            2826,
                            2861,
                            2830
                        ],
                        "inputs.dtype": [
                            2827
                        ],
                        "input_ta.unstack": [
                            2830
                        ],
                        "time": [
                            2889,
                            2861,
                            2862,
                            2831,
                            2898,
                            2899,
                            2902,
                            2904,
                            2875,
                            2876
                        ],
                        "tf.constant": [
                            2831
                        ],
                        "mask_ta": [
                            2848,
                            2844,
                            2862
                        ],
                        "mask_ta.unstack": [
                            2848
                        ],
                        "current_input": [
                            2889,
                            2890,
                            2861,
                            2863
                        ],
                        "input_ta.read": [
                            2889,
                            2861
                        ],
                        "mask_ta.read": [
                            2862
                        ],
                        "new_state.set_shape": [
                            2897,
                            2870
                        ],
                        "state.get_shape": [
                            2897,
                            2870
                        ],
                        "i": [
                            2874
                        ],
                        "output_ta_t": [
                            2898,
                            2875,
                            2876,
                            2899
                        ],
                        "output_ta_t.write": [
                            2898,
                            2875
                        ],
                        "final_outputs": [
                            2907,
                            2908,
                            2901,
                            2909
                        ],
                        "control_flow_ops.while_loop": [
                            2901
                        ],
                        "control_flow_ops": [
                            2901
                        ],
                        "_step": [
                            2903
                        ],
                        "last_time": [
                            2912,
                            2907
                        ],
                        "output_ta.stack": [
                            2911
                        ],
                        "output_ta.read": [
                            2912
                        ],
                        "outputs.get_shape": [
                            2914
                        ],
                        "last_output._uses_learning_phase": [
                            2916
                        ]
                    },
                    "diff_line_number": 2874,
                    "class_data": null,
                    "variable_values": [
                        [
                            {},
                            {}
                        ]
                    ],
                    "angelic_variable_values": [
                        [
                            {},
                            {}
                        ]
                    ]
                }
            ],
            "inscope_functions": [
                "def get_uid(prefix=''):\n    \"\"\"Get the uid for the default graph.\n\n    # Arguments\n        prefix: An optional prefix of the graph.\n\n    # Returns\n        A unique identifier for the graph.\n    \"\"\"\n    global _GRAPH_UID_DICTS\n    graph = tf.get_default_graph()\n    if graph not in _GRAPH_UID_DICTS:\n        _GRAPH_UID_DICTS[graph] = defaultdict(int)\n    _GRAPH_UID_DICTS[graph][prefix] += 1\n    return _GRAPH_UID_DICTS[graph][prefix]",
                "def reset_uids():\n    \"\"\"Resets graph identifiers.\n    \"\"\"\n    global _GRAPH_UID_DICTS\n    _GRAPH_UID_DICTS = {}",
                "def clear_session():\n    \"\"\"Destroys the current TF graph and creates a new one.\n\n    Useful to avoid clutter from old models / layers.\n    \"\"\"\n    global _SESSION\n    global _GRAPH_LEARNING_PHASES\n    tf.reset_default_graph()\n    reset_uids()\n    _SESSION = None\n    phase = tf.placeholder_with_default(False,\n                                        shape=(),\n                                        name='keras_learning_phase')\n    _GRAPH_LEARNING_PHASES = {}\n    _GRAPH_LEARNING_PHASES[tf.get_default_graph()] = phase",
                "def manual_variable_initialization(value):\n    \"\"\"Sets the manual variable initialization flag.\n\n    This boolean flag determines whether\n    variables should be initialized\n    as they are instantiated (default), or if\n    the user should handle the initialization\n    (e.g. via `tf.initialize_all_variables()`).\n\n    # Arguments\n        value: Python boolean.\n    \"\"\"\n    global _MANUAL_VAR_INIT\n    _MANUAL_VAR_INIT = value",
                "def learning_phase():\n    \"\"\"Returns the learning phase flag.\n\n    The learning phase flag is a bool tensor (0 = test, 1 = train)\n    to be passed as input to any Keras function\n    that uses a different behavior at train time and test time.\n\n    # Returns\n        Learning phase (scalar integer tensor or Python integer).\n    \"\"\"\n    graph = tf.get_default_graph()\n    if graph not in _GRAPH_LEARNING_PHASES:\n        phase = tf.placeholder_with_default(False,\n                                            shape=(),\n                                            name='keras_learning_phase')\n        _GRAPH_LEARNING_PHASES[graph] = phase\n    return _GRAPH_LEARNING_PHASES[graph]",
                "def set_learning_phase(value):\n    \"\"\"Sets the learning phase to a fixed value.\n\n    # Arguments\n        value: Learning phase value, either 0 or 1 (integers).\n\n    # Raises\n        ValueError: if `value` is neither `0` nor `1`.\n    \"\"\"\n    global _GRAPH_LEARNING_PHASES\n    if value not in {0, 1}:\n        raise ValueError('Expected learning phase to be '\n                         '0 or 1.')\n    _GRAPH_LEARNING_PHASES[tf.get_default_graph()] = value",
                "def get_session():\n    \"\"\"Returns the TF session to be used by the backend.\n\n    If a default TensorFlow session is available, we will return it.\n\n    Else, we will return the global Keras session.\n\n    If no global Keras session exists at this point:\n    we will create a new global session.\n\n    Note that you can manually set the global session\n    via `K.set_session(sess)`.\n\n    # Returns\n        A TensorFlow session.\n    \"\"\"\n    global _SESSION\n\n    default_session = tf.get_default_session()\n\n    if default_session is not None:\n        session = default_session\n    else:\n        if _SESSION is None:\n            if not os.environ.get('OMP_NUM_THREADS'):\n                config = tf.ConfigProto(allow_soft_placement=True)\n            else:\n                num_thread = int(os.environ.get('OMP_NUM_THREADS'))\n                config = tf.ConfigProto(intra_op_parallelism_threads=num_thread,\n                                        allow_soft_placement=True)\n            _SESSION = tf.Session(config=config)\n        session = _SESSION\n    if not _MANUAL_VAR_INIT:\n        with session.graph.as_default():\n            variables = tf.global_variables()\n            candidate_vars = []\n            for v in variables:\n                if not getattr(v, '_keras_initialized', False):\n                    candidate_vars.append(v)\n            if candidate_vars:\n                # This step is expensive, so we only run it on variables\n                # not already marked as initialized.\n                is_initialized = session.run(\n                    [tf.is_variable_initialized(v) for v in candidate_vars])\n                uninitialized_vars = []\n                for flag, v in zip(is_initialized, candidate_vars):\n                    if not flag:\n                        uninitialized_vars.append(v)\n                    v._keras_initialized = True\n                if uninitialized_vars:\n                    session.run(tf.variables_initializer(uninitialized_vars))\n    # hack for list_devices() function.\n    # list_devices() function is not available under tensorflow r1.3.\n    if not hasattr(session, 'list_devices'):\n        session.list_devices = lambda: device_lib.list_local_devices()\n    return session",
                "def set_session(session):\n    \"\"\"Sets the global TensorFlow session.\n\n    # Arguments\n        session: A TF Session.\n    \"\"\"\n    global _SESSION\n    _SESSION = session",
                "def _get_current_tf_device():\n    \"\"\"Return explicit device of current context, otherwise returns `None`.\n\n    # Returns\n        If the current device scope is explicitly set, it returns a string with\n        the device (`CPU` or `GPU`). If the scope is not explicitly set, it will\n        return `None`.\n    \"\"\"\n    g = tf.get_default_graph()\n    op = _TfDeviceCaptureOp()\n    g._apply_device_functions(op)\n    return op.device",
                "def _is_current_explicit_device(device_type):\n    \"\"\"Check if the current device is explicitly set on the device type specified.\n\n    # Arguments\n        device_type: A string containing `GPU` or `CPU` (case-insensitive).\n\n    # Returns\n        A boolean indicating if the current device scope is explicitly set on the device type.\n\n    # Raises\n        ValueError: If the `device_type` string indicates an unsupported device.\n    \"\"\"\n    device_type = device_type.upper()\n    if device_type not in ['CPU', 'GPU']:\n        raise ValueError('`device_type` should be either \"CPU\" or \"GPU\".')\n    device = _get_current_tf_device()\n    return (device is not None and device.device_type == device_type.upper())",
                "def _get_available_gpus():\n    \"\"\"Get a list of available gpu devices (formatted as strings).\n\n    # Returns\n        A list of available GPU devices.\n    \"\"\"\n    global _LOCAL_DEVICES\n    if _LOCAL_DEVICES is None:\n        _LOCAL_DEVICES = get_session().list_devices()\n    return [x.name for x in _LOCAL_DEVICES if x.device_type == 'GPU']",
                "def _has_nchw_support():\n    \"\"\"Check whether the current scope supports NCHW ops.\n\n    TensorFlow does not support NCHW on CPU. Therefore we check if we are not explicitly put on\n    CPU, and have GPUs available. In this case there will be soft-placing on the GPU device.\n\n    # Returns\n        bool: if the current scope device placement would support nchw\n    \"\"\"\n    explicitly_on_cpu = _is_current_explicit_device('CPU')\n    gpus_available = len(_get_available_gpus()) > 0\n    return (not explicitly_on_cpu and gpus_available)",
                "def _to_tensor(x, dtype):\n    \"\"\"Convert the input `x` to a tensor of type `dtype`.\n\n    # Arguments\n        x: An object to be converted (numpy array, list, tensors).\n        dtype: The destination type.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.convert_to_tensor(x, dtype=dtype)",
                "def is_sparse(tensor):\n    \"\"\"Returns whether a tensor is a sparse tensor.\n\n    # Arguments\n        tensor: A tensor instance.\n\n    # Returns\n        A boolean.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> a = K.placeholder((2, 2), sparse=False)\n        >>> print(K.is_sparse(a))\n        False\n        >>> b = K.placeholder((2, 2), sparse=True)\n        >>> print(K.is_sparse(b))\n        True\n    ```\n    \"\"\"\n    return isinstance(tensor, tf.SparseTensor)",
                "def to_dense(tensor):\n    \"\"\"Converts a sparse tensor into a dense tensor and returns it.\n\n    # Arguments\n        tensor: A tensor instance (potentially sparse).\n\n    # Returns\n        A dense tensor.\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> b = K.placeholder((2, 2), sparse=True)\n        >>> print(K.is_sparse(b))\n        True\n        >>> c = K.to_dense(b)\n        >>> print(K.is_sparse(c))\n        False\n    ```\n    \"\"\"\n    if is_sparse(tensor):\n        return tf.sparse_tensor_to_dense(tensor)\n    else:\n        return tensor",
                "def variable(value, dtype=None, name=None, constraint=None):\n    \"\"\"Instantiates a variable and returns it.\n\n    # Arguments\n        value: Numpy array, initial value of the tensor.\n        dtype: Tensor type.\n        name: Optional name string for the tensor.\n        constraint: Optional projection function to be\n            applied to the variable after an optimizer update.\n\n    # Returns\n        A variable instance (with Keras metadata included).\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> val = np.array([[1, 2], [3, 4]])\n        >>> kvar = K.variable(value=val, dtype='float64', name='example_var')\n        >>> K.dtype(kvar)\n        'float64'\n        >>> print(kvar)\n        example_var\n        >>> K.eval(kvar)\n        array([[ 1.,  2.],\n               [ 3.,  4.]])\n    ```\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    if hasattr(value, 'tocoo'):\n        sparse_coo = value.tocoo()\n        indices = np.concatenate((np.expand_dims(sparse_coo.row, 1),\n                                  np.expand_dims(sparse_coo.col, 1)), 1)\n        v = tf.SparseTensor(indices=indices,\n                            values=sparse_coo.data,\n                            dense_shape=sparse_coo.shape)\n        v._keras_shape = sparse_coo.shape\n        v._uses_learning_phase = False\n        return v\n    v = tf.Variable(value, dtype=tf.as_dtype(dtype), name=name)\n    if isinstance(value, np.ndarray):\n        v._keras_shape = value.shape\n    elif hasattr(value, 'get_shape'):\n        v._keras_shape = int_shape(value)\n    v._uses_learning_phase = False\n    # TODO: move to Variable constructor when supported in public release.\n    try:\n        v.constraint = constraint\n    except AttributeError:\n        v._constraint = constraint\n    return v",
                "def constant(value, dtype=None, shape=None, name=None):\n    \"\"\"Creates a constant tensor.\n\n    # Arguments\n        value: A constant value (or list)\n        dtype: The type of the elements of the resulting tensor.\n        shape: Optional dimensions of resulting tensor.\n        name: Optional name for the tensor.\n\n    # Returns\n        A Constant Tensor.\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    return tf.constant(value, dtype=dtype, shape=shape, name=name)",
                "def is_keras_tensor(x):\n    \"\"\"Returns whether `x` is a Keras tensor.\n\n    A \"Keras tensor\" is a tensor that was returned by a Keras layer,\n    (`Layer` class) or by `Input`.\n\n    # Arguments\n        x: A candidate tensor.\n\n    # Returns\n        A boolean: Whether the argument is a Keras tensor.\n\n    # Raises\n        ValueError: In case `x` is not a symbolic tensor.\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> from keras.layers import Input, Dense\n        >>> np_var = numpy.array([1, 2])\n        >>> K.is_keras_tensor(np_var) # A numpy array is not a symbolic tensor.\n        ValueError\n        >>> k_var = tf.placeholder('float32', shape=(1,1))\n        >>> K.is_keras_tensor(k_var) # A variable indirectly created outside of keras is not a Keras tensor.\n        False\n        >>> keras_var = K.variable(np_var)\n        >>> K.is_keras_tensor(keras_var)  # A variable created with the keras backend is not a Keras tensor.\n        False\n        >>> keras_placeholder = K.placeholder(shape=(2, 4, 5))\n        >>> K.is_keras_tensor(keras_placeholder)  # A placeholder is not a Keras tensor.\n        False\n        >>> keras_input = Input([10])\n        >>> K.is_keras_tensor(keras_input) # An Input is a Keras tensor.\n        True\n        >>> keras_layer_output = Dense(10)(keras_input)\n        >>> K.is_keras_tensor(keras_layer_output) # Any Keras layer output is a Keras tensor.\n        True\n    ```\n    \"\"\"\n    if not is_tensor(x):\n        raise ValueError('Unexpectedly found an instance of type `' +\n                         str(type(x)) + '`. '\n                         'Expected a symbolic tensor instance.')\n    return hasattr(x, '_keras_history')",
                "def is_tensor(x):\n    return isinstance(x, tf_ops._TensorLike) or tf_ops.is_dense_tensor_like(x)",
                "def placeholder(shape=None, ndim=None, dtype=None, sparse=False, name=None):\n    \"\"\"Instantiates a placeholder tensor and returns it.\n\n    # Arguments\n        shape: Shape of the placeholder\n            (integer tuple, may include `None` entries).\n        ndim: Number of axes of the tensor.\n            At least one of {`shape`, `ndim`} must be specified.\n            If both are specified, `shape` is used.\n        dtype: Placeholder type.\n        sparse: Boolean, whether the placeholder should have a sparse type.\n        name: Optional name string for the placeholder.\n\n    # Returns\n        Tensor instance (with Keras metadata included).\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> input_ph = K.placeholder(shape=(2, 4, 5))\n        >>> input_ph._keras_shape\n        (2, 4, 5)\n        >>> input_ph\n        <tf.Tensor 'Placeholder_4:0' shape=(2, 4, 5) dtype=float32>\n    ```\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    if not shape:\n        if ndim:\n            shape = tuple([None for _ in range(ndim)])\n    if sparse:\n        x = tf.sparse_placeholder(dtype, shape=shape, name=name)\n    else:\n        x = tf.placeholder(dtype, shape=shape, name=name)\n    x._keras_shape = shape\n    x._uses_learning_phase = False\n    return x",
                "def is_placeholder(x):\n    \"\"\"Returns whether `x` is a placeholder.\n\n    # Arguments\n        x: A candidate placeholder.\n\n    # Returns\n        Boolean.\n    \"\"\"\n    try:\n        return x.op.type == 'Placeholder'\n    except AttributeError:\n        return False",
                "def shape(x):\n    \"\"\"Returns the symbolic shape of a tensor or variable.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A symbolic shape (which is itself a tensor).\n\n    # Examples\n    ```python\n        # TensorFlow example\n        >>> from keras import backend as K\n        >>> tf_session = K.get_session()\n        >>> val = np.array([[1, 2], [3, 4]])\n        >>> kvar = K.variable(value=val)\n        >>> inputs = keras.backend.placeholder(shape=(2, 4, 5))\n        >>> K.shape(kvar)\n        <tf.Tensor 'Shape_8:0' shape=(2,) dtype=int32>\n        >>> K.shape(inputs)\n        <tf.Tensor 'Shape_9:0' shape=(3,) dtype=int32>\n        # To get integer shape (Instead, you can use K.int_shape(x))\n        >>> K.shape(kvar).eval(session=tf_session)\n        array([2, 2], dtype=int32)\n        >>> K.shape(inputs).eval(session=tf_session)\n        array([2, 4, 5], dtype=int32)\n    ```\n    \"\"\"\n    return tf.shape(x)",
                "def int_shape(x):\n    \"\"\"Returns the shape of tensor or variable as a tuple of int or None entries.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tuple of integers (or None entries).\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> inputs = K.placeholder(shape=(2, 4, 5))\n        >>> K.int_shape(inputs)\n        (2, 4, 5)\n        >>> val = np.array([[1, 2], [3, 4]])\n        >>> kvar = K.variable(value=val)\n        >>> K.int_shape(kvar)\n        (2, 2)\n    ```\n    \"\"\"\n    if hasattr(x, '_keras_shape'):\n        return x._keras_shape\n    try:\n        return tuple(x.get_shape().as_list())\n    except ValueError:\n        return None",
                "def ndim(x):\n    \"\"\"Returns the number of axes in a tensor, as an integer.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        Integer (scalar), number of axes.\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> inputs = K.placeholder(shape=(2, 4, 5))\n        >>> val = np.array([[1, 2], [3, 4]])\n        >>> kvar = K.variable(value=val)\n        >>> K.ndim(inputs)\n        3\n        >>> K.ndim(kvar)\n        2\n    ```\n    \"\"\"\n    dims = x.get_shape()._dims\n    if dims is not None:\n        return len(dims)\n    return None",
                "def dtype(x):\n    \"\"\"Returns the dtype of a Keras tensor or variable, as a string.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        String, dtype of `x`.\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> K.dtype(K.placeholder(shape=(2,4,5)))\n        'float32'\n        >>> K.dtype(K.placeholder(shape=(2,4,5), dtype='float32'))\n        'float32'\n        >>> K.dtype(K.placeholder(shape=(2,4,5), dtype='float64'))\n        'float64'\n        # Keras variable\n        >>> kvar = K.variable(np.array([[1, 2], [3, 4]]))\n        >>> K.dtype(kvar)\n        'float32_ref'\n        >>> kvar = K.variable(np.array([[1, 2], [3, 4]]), dtype='float32')\n        >>> K.dtype(kvar)\n        'float32_ref'\n    ```\n    \"\"\"\n    return x.dtype.base_dtype.name",
                "def eval(x):\n    \"\"\"Evaluates the value of a variable.\n\n    # Arguments\n        x: A variable.\n\n    # Returns\n        A Numpy array.\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> kvar = K.variable(np.array([[1, 2], [3, 4]]), dtype='float32')\n        >>> K.eval(kvar)\n        array([[ 1.,  2.],\n               [ 3.,  4.]], dtype=float32)\n    ```\n    \"\"\"\n    return to_dense(x).eval(session=get_session())",
                "def zeros(shape, dtype=None, name=None):\n    \"\"\"Instantiates an all-zeros variable and returns it.\n\n    # Arguments\n        shape: Tuple of integers, shape of returned Keras variable\n        dtype: String, data type of returned Keras variable\n        name: String, name of returned Keras variable\n\n    # Returns\n        A variable (including Keras metadata), filled with `0.0`.\n        Note that if `shape` was symbolic, we cannot return a variable,\n        and will return a dynamically-shaped tensor instead.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> kvar = K.zeros((3,4))\n        >>> K.eval(kvar)\n        array([[ 0.,  0.,  0.,  0.],\n               [ 0.,  0.,  0.,  0.],\n               [ 0.,  0.,  0.,  0.]], dtype=float32)\n    ```\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    tf_dtype = tf.as_dtype(dtype)\n    v = tf.zeros(shape=shape, dtype=tf_dtype, name=name)\n    if py_all(v.get_shape().as_list()):\n        return variable(v, dtype=dtype, name=name)\n    return v",
                "def ones(shape, dtype=None, name=None):\n    \"\"\"Instantiates an all-ones variable and returns it.\n\n    # Arguments\n        shape: Tuple of integers, shape of returned Keras variable.\n        dtype: String, data type of returned Keras variable.\n        name: String, name of returned Keras variable.\n\n    # Returns\n        A Keras variable, filled with `1.0`.\n        Note that if `shape` was symbolic, we cannot return a variable,\n        and will return a dynamically-shaped tensor instead.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> kvar = K.ones((3,4))\n        >>> K.eval(kvar)\n        array([[ 1.,  1.,  1.,  1.],\n               [ 1.,  1.,  1.,  1.],\n               [ 1.,  1.,  1.,  1.]], dtype=float32)\n    ```\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    tf_dtype = tf.as_dtype(dtype)\n    v = tf.ones(shape=shape, dtype=tf_dtype, name=name)\n    if py_all(v.get_shape().as_list()):\n        return variable(v, dtype=dtype, name=name)\n    return v",
                "def eye(size, dtype=None, name=None):\n    \"\"\"Instantiate an identity matrix and returns it.\n\n    # Arguments\n        size: Integer, number of rows/columns.\n        dtype: String, data type of returned Keras variable.\n        name: String, name of returned Keras variable.\n\n    # Returns\n        A Keras variable, an identity matrix.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> kvar = K.eye(3)\n        >>> K.eval(kvar)\n        array([[ 1.,  0.,  0.],\n               [ 0.,  1.,  0.],\n               [ 0.,  0.,  1.]], dtype=float32)\n    ```\n\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    tf_dtype = tf.as_dtype(dtype)\n    return variable(tf.eye(size, dtype=tf_dtype), dtype, name)",
                "def zeros_like(x, dtype=None, name=None):\n    \"\"\"Instantiates an all-zeros variable of the same shape as another tensor.\n\n    # Arguments\n        x: Keras variable or Keras tensor.\n        dtype: String, dtype of returned Keras variable.\n             None uses the dtype of x.\n        name: String, name for the variable to create.\n\n    # Returns\n        A Keras variable with the shape of x filled with zeros.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> kvar = K.variable(np.random.random((2,3)))\n        >>> kvar_zeros = K.zeros_like(kvar)\n        >>> K.eval(kvar_zeros)\n        array([[ 0.,  0.,  0.],\n               [ 0.,  0.,  0.]], dtype=float32)\n    ```\n    \"\"\"\n    return tf.zeros_like(x, dtype=dtype, name=name)",
                "def ones_like(x, dtype=None, name=None):\n    \"\"\"Instantiates an all-ones variable of the same shape as another tensor.\n\n    # Arguments\n        x: Keras variable or tensor.\n        dtype: String, dtype of returned Keras variable.\n             None uses the dtype of x.\n        name: String, name for the variable to create.\n\n    # Returns\n        A Keras variable with the shape of x filled with ones.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> kvar = K.variable(np.random.random((2,3)))\n        >>> kvar_ones = K.ones_like(kvar)\n        >>> K.eval(kvar_ones)\n        array([[ 1.,  1.,  1.],\n               [ 1.,  1.,  1.]], dtype=float32)\n    ```\n    \"\"\"\n    return tf.ones_like(x, dtype=dtype, name=name)",
                "def identity(x, name=None):\n    \"\"\"Returns a tensor with the same content as the input tensor.\n\n    # Arguments\n        x: The input tensor.\n        name: String, name for the variable to create.\n\n    # Returns\n        A tensor of the same shape, type and content.\n    \"\"\"\n    return tf.identity(x, name)",
                "def random_uniform_variable(shape, low, high, dtype=None,\n                            name=None, seed=None):\n    \"\"\"Instantiates a variable with values drawn from a uniform distribution.\n\n    # Arguments\n        shape: Tuple of integers, shape of returned Keras variable.\n        low: Float, lower boundary of the output interval.\n        high: Float, upper boundary of the output interval.\n        dtype: String, dtype of returned Keras variable.\n        name: String, name of returned Keras variable.\n        seed: Integer, random seed.\n\n    # Returns\n        A Keras variable, filled with drawn samples.\n\n    # Example\n    ```python\n        # TensorFlow example\n        >>> kvar = K.random_uniform_variable((2,3), 0, 1)\n        >>> kvar\n        <tensorflow.python.ops.variables.Variable object at 0x10ab40b10>\n        >>> K.eval(kvar)\n        array([[ 0.10940075,  0.10047495,  0.476143  ],\n               [ 0.66137183,  0.00869417,  0.89220798]], dtype=float32)\n    ```\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    tf_dtype = tf.as_dtype(dtype)\n    if seed is None:\n        # ensure that randomness is conditioned by the Numpy RNG\n        seed = np.random.randint(10e8)\n    value = tf.random_uniform_initializer(\n        low, high, dtype=tf_dtype, seed=seed)(shape)\n    return variable(value, dtype=dtype, name=name)",
                "def random_normal_variable(shape, mean, scale, dtype=None,\n                           name=None, seed=None):\n    \"\"\"Instantiates a variable with values drawn from a normal distribution.\n\n    # Arguments\n        shape: Tuple of integers, shape of returned Keras variable.\n        mean: Float, mean of the normal distribution.\n        scale: Float, standard deviation of the normal distribution.\n        dtype: String, dtype of returned Keras variable.\n        name: String, name of returned Keras variable.\n        seed: Integer, random seed.\n\n    # Returns\n        A Keras variable, filled with drawn samples.\n\n    # Example\n    ```python\n        # TensorFlow example\n        >>> kvar = K.random_normal_variable((2,3), 0, 1)\n        >>> kvar\n        <tensorflow.python.ops.variables.Variable object at 0x10ab12dd0>\n        >>> K.eval(kvar)\n        array([[ 1.19591331,  0.68685907, -0.63814116],\n               [ 0.92629528,  0.28055015,  1.70484698]], dtype=float32)\n    ```\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    tf_dtype = tf.as_dtype(dtype)\n    if seed is None:\n        # ensure that randomness is conditioned by the Numpy RNG\n        seed = np.random.randint(10e8)\n    value = tf.random_normal_initializer(\n        mean, scale, dtype=tf_dtype, seed=seed)(shape)\n    return variable(value, dtype=dtype, name=name)",
                "def count_params(x):\n    \"\"\"Returns the static number of elements in a Keras variable or tensor.\n\n    # Arguments\n        x: Keras variable or tensor.\n\n    # Returns\n        Integer, the number of elements in `x`, i.e., the product of the\n        array's static dimensions.\n\n    # Example\n    ```python\n        >>> kvar = K.zeros((2,3))\n        >>> K.count_params(kvar)\n        6\n        >>> K.eval(kvar)\n        array([[ 0.,  0.,  0.],\n               [ 0.,  0.,  0.]], dtype=float32)\n    ```\n    \"\"\"\n    return np.prod(int_shape(x))",
                "def cast(x, dtype):\n    \"\"\"Casts a tensor to a different dtype and returns it.\n\n    You can cast a Keras variable but it still returns a Keras tensor.\n\n    # Arguments\n        x: Keras tensor (or variable).\n        dtype: String, either (`'float16'`, `'float32'`, or `'float64'`).\n\n    # Returns\n        Keras tensor with dtype `dtype`.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> input = K.placeholder((2, 3), dtype='float32')\n        >>> input\n        <tf.Tensor 'Placeholder_2:0' shape=(2, 3) dtype=float32>\n        # It doesn't work in-place as below.\n        >>> K.cast(input, dtype='float16')\n        <tf.Tensor 'Cast_1:0' shape=(2, 3) dtype=float16>\n        >>> input\n        <tf.Tensor 'Placeholder_2:0' shape=(2, 3) dtype=float32>\n        # you need to assign it.\n        >>> input = K.cast(input, dtype='float16')\n        >>> input\n        <tf.Tensor 'Cast_2:0' shape=(2, 3) dtype=float16>\n    ```\n    \"\"\"\n    return tf.cast(x, dtype)",
                "def update(x, new_x):\n    \"\"\"Update the value of `x` to `new_x`.\n\n    # Arguments\n        x: A `Variable`.\n        new_x: A tensor of same shape as `x`.\n\n    # Returns\n        The variable `x` updated.\n    \"\"\"\n    return tf.assign(x, new_x)",
                "def update_add(x, increment):\n    \"\"\"Update the value of `x` by adding `increment`.\n\n    # Arguments\n        x: A `Variable`.\n        increment: A tensor of same shape as `x`.\n\n    # Returns\n        The variable `x` updated.\n    \"\"\"\n    return tf.assign_add(x, increment)",
                "def update_sub(x, decrement):\n    \"\"\"Update the value of `x` by subtracting `decrement`.\n\n    # Arguments\n        x: A `Variable`.\n        decrement: A tensor of same shape as `x`.\n\n    # Returns\n        The variable `x` updated.\n    \"\"\"\n    return tf.assign_sub(x, decrement)",
                "def moving_average_update(x, value, momentum):\n    \"\"\"Compute the moving average of a variable.\n\n    # Arguments\n        x: A `Variable`.\n        value: A tensor with the same shape as `x`.\n        momentum: The moving average momentum.\n\n    # Returns\n        An operation to update the variable.\n    \"\"\"\n    return moving_averages.assign_moving_average(\n        x, value, momentum, zero_debias=True)",
                "def dot(x, y):\n    \"\"\"Multiplies 2 tensors (and/or variables) and returns a *tensor*.\n\n    When attempting to multiply a nD tensor\n    with a nD tensor, it reproduces the Theano behavior.\n    (e.g. `(2, 3) * (4, 3, 5) -> (2, 4, 5)`)\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A tensor, dot product of `x` and `y`.\n\n    # Examples\n    ```python\n        # dot product between tensors\n        >>> x = K.placeholder(shape=(2, 3))\n        >>> y = K.placeholder(shape=(3, 4))\n        >>> xy = K.dot(x, y)\n        >>> xy\n        <tf.Tensor 'MatMul_9:0' shape=(2, 4) dtype=float32>\n    ```\n\n    ```python\n        # dot product between tensors\n        >>> x = K.placeholder(shape=(32, 28, 3))\n        >>> y = K.placeholder(shape=(3, 4))\n        >>> xy = K.dot(x, y)\n        >>> xy\n        <tf.Tensor 'MatMul_9:0' shape=(32, 28, 4) dtype=float32>\n    ```\n\n    ```python\n        # Theano-like behavior example\n        >>> x = K.random_uniform_variable(shape=(2, 3), low=0, high=1)\n        >>> y = K.ones((4, 3, 5))\n        >>> xy = K.dot(x, y)\n        >>> K.int_shape(xy)\n        (2, 4, 5)\n    ```\n    \"\"\"\n    if ndim(x) is not None and (ndim(x) > 2 or ndim(y) > 2):\n        x_shape = []\n        for i, s in zip(int_shape(x), tf.unstack(tf.shape(x))):\n            if i is not None:\n                x_shape.append(i)\n            else:\n                x_shape.append(s)\n        x_shape = tuple(x_shape)\n        y_shape = []\n        for i, s in zip(int_shape(y), tf.unstack(tf.shape(y))):\n            if i is not None:\n                y_shape.append(i)\n            else:\n                y_shape.append(s)\n        y_shape = tuple(y_shape)\n        y_permute_dim = list(range(ndim(y)))\n        y_permute_dim = [y_permute_dim.pop(-2)] + y_permute_dim\n        xt = tf.reshape(x, [-1, x_shape[-1]])\n        yt = tf.reshape(tf.transpose(y, perm=y_permute_dim), [y_shape[-2], -1])\n        return tf.reshape(tf.matmul(xt, yt),\n                          x_shape[:-1] + y_shape[:-2] + y_shape[-1:])\n    if is_sparse(x):\n        out = tf.sparse_tensor_dense_matmul(x, y)\n    else:\n        out = tf.matmul(x, y)\n    return out",
                "def batch_dot(x, y, axes=None):\n    \"\"\"Batchwise dot product.\n\n    `batch_dot` is used to compute dot product of `x` and `y` when\n    `x` and `y` are data in batch, i.e. in a shape of\n    `(batch_size, :)`.\n    `batch_dot` results in a tensor or variable with less dimensions\n    than the input. If the number of dimensions is reduced to 1,\n    we use `expand_dims` to make sure that ndim is at least 2.\n\n    # Arguments\n        x: Keras tensor or variable with `ndim >= 2`.\n        y: Keras tensor or variable with `ndim >= 2`.\n        axes: list of (or single) int with target dimensions.\n            The lengths of `axes[0]` and `axes[1]` should be the same.\n\n    # Returns\n        A tensor with shape equal to the concatenation of `x`'s shape\n        (less the dimension that was summed over) and `y`'s shape\n        (less the batch dimension and the dimension that was summed over).\n        If the final rank is 1, we reshape it to `(batch_size, 1)`.\n\n    # Examples\n        Assume `x = [[1, 2], [3, 4]]` and `y = [[5, 6], [7, 8]]`\n        `batch_dot(x, y, axes=1) = [[17], [53]]` which is the main diagonal\n        of `x.dot(y.T)`, although we never have to calculate the off-diagonal\n        elements.\n\n        Shape inference:\n        Let `x`'s shape be `(100, 20)` and `y`'s shape be `(100, 30, 20)`.\n        If `axes` is (1, 2), to find the output shape of resultant tensor,\n            loop through each dimension in `x`'s shape and `y`'s shape:\n\n        * `x.shape[0]` : 100 : append to output shape\n        * `x.shape[1]` : 20 : do not append to output shape,\n            dimension 1 of `x` has been summed over. (`dot_axes[0]` = 1)\n        * `y.shape[0]` : 100 : do not append to output shape,\n            always ignore first dimension of `y`\n        * `y.shape[1]` : 30 : append to output shape\n        * `y.shape[2]` : 20 : do not append to output shape,\n            dimension 2 of `y` has been summed over. (`dot_axes[1]` = 2)\n        `output_shape` = `(100, 30)`\n\n    ```python\n        >>> x_batch = K.ones(shape=(32, 20, 1))\n        >>> y_batch = K.ones(shape=(32, 30, 20))\n        >>> xy_batch_dot = K.batch_dot(x_batch, y_batch, axes=[1, 2])\n        >>> K.int_shape(xy_batch_dot)\n        (32, 1, 30)\n    ```\n    \"\"\"\n    if isinstance(axes, int):\n        axes = (axes, axes)\n    x_ndim = ndim(x)\n    y_ndim = ndim(y)\n    if axes is None:\n        # behaves like tf.batch_matmul as default\n        axes = [x_ndim - 1, y_ndim - 2]\n    if py_any([isinstance(a, (list, tuple)) for a in axes]):\n        raise ValueError('Multiple target dimensions are not supported. ' +\n                         'Expected: None, int, (int, int), ' +\n                         'Provided: ' + str(axes))\n    if x_ndim > y_ndim:\n        diff = x_ndim - y_ndim\n        y = tf.reshape(y, tf.concat([tf.shape(y), [1] * (diff)], axis=0))\n    elif y_ndim > x_ndim:\n        diff = y_ndim - x_ndim\n        x = tf.reshape(x, tf.concat([tf.shape(x), [1] * (diff)], axis=0))\n    else:\n        diff = 0\n    if ndim(x) == 2 and ndim(y) == 2:\n        if axes[0] == axes[1]:\n            out = tf.reduce_sum(tf.multiply(x, y), axes[0])\n        else:\n            out = tf.reduce_sum(tf.multiply(tf.transpose(x, [1, 0]), y), axes[1])\n    else:\n        if axes is not None:\n            adj_x = None if axes[0] == ndim(x) - 1 else True\n            adj_y = True if axes[1] == ndim(y) - 1 else None\n        else:\n            adj_x = None\n            adj_y = None\n        out = tf.matmul(x, y, adjoint_a=adj_x, adjoint_b=adj_y)\n    if diff:\n        if x_ndim > y_ndim:\n            idx = x_ndim + y_ndim - 3\n        else:\n            idx = x_ndim - 1\n        out = tf.squeeze(out, list(range(idx, idx + diff)))\n    if ndim(out) == 1:\n        out = expand_dims(out, 1)\n    return out",
                "def transpose(x):\n    \"\"\"Transposes a tensor and returns it.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n\n    # Examples\n    ```python\n        >>> var = K.variable([[1, 2, 3], [4, 5, 6]])\n        >>> K.eval(var)\n        array([[ 1.,  2.,  3.],\n               [ 4.,  5.,  6.]], dtype=float32)\n        >>> var_transposed = K.transpose(var)\n        >>> K.eval(var_transposed)\n        array([[ 1.,  4.],\n               [ 2.,  5.],\n               [ 3.,  6.]], dtype=float32)\n    ```\n\n    ```python\n        >>> inputs = K.placeholder((2, 3))\n        >>> inputs\n        <tf.Tensor 'Placeholder_11:0' shape=(2, 3) dtype=float32>\n        >>> input_transposed = K.transpose(inputs)\n        >>> input_transposed\n        <tf.Tensor 'transpose_4:0' shape=(3, 2) dtype=float32>\n\n    ```\n    \"\"\"\n    return tf.transpose(x)",
                "def gather(reference, indices):\n    \"\"\"Retrieves the elements of indices `indices` in the tensor `reference`.\n\n    # Arguments\n        reference: A tensor.\n        indices: An integer tensor of indices.\n\n    # Returns\n        A tensor of same type as `reference`.\n    \"\"\"\n    return tf.gather(reference, indices)",
                "def max(x, axis=None, keepdims=False):\n    \"\"\"Maximum value in a tensor.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer, the axis to find maximum values.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1. If `keepdims` is `True`,\n            the reduced dimension is retained with length 1.\n\n    # Returns\n        A tensor with maximum values of `x`.\n    \"\"\"\n    return tf.reduce_max(x, axis, keepdims)",
                "def min(x, axis=None, keepdims=False):\n    \"\"\"Minimum value in a tensor.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer, the axis to find minimum values.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1. If `keepdims` is `True`,\n            the reduced dimension is retained with length 1.\n\n    # Returns\n        A tensor with miminum values of `x`.\n    \"\"\"\n    return tf.reduce_min(x, axis, keepdims)",
                "def sum(x, axis=None, keepdims=False):\n    \"\"\"Sum of the values in a tensor, alongside the specified axis.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer, the axis to sum over.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1. If `keepdims` is `True`,\n            the reduced dimension is retained with length 1.\n\n    # Returns\n        A tensor with sum of `x`.\n    \"\"\"\n    return tf.reduce_sum(x, axis, keepdims)",
                "def prod(x, axis=None, keepdims=False):\n    \"\"\"Multiplies the values in a tensor, alongside the specified axis.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer, the axis to compute the product.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1. If `keepdims` is `True`,\n            the reduced dimension is retained with length 1.\n\n    # Returns\n        A tensor with the product of elements of `x`.\n    \"\"\"\n    return tf.reduce_prod(x, axis, keepdims)",
                "def cumsum(x, axis=0):\n    \"\"\"Cumulative sum of the values in a tensor, alongside the specified axis.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer, the axis to compute the sum.\n\n    # Returns\n        A tensor of the cumulative sum of values of `x` along `axis`.\n    \"\"\"\n    return tf.cumsum(x, axis=axis)",
                "def cumprod(x, axis=0):\n    \"\"\"Cumulative product of the values in a tensor, alongside the specified axis.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer, the axis to compute the product.\n\n    # Returns\n        A tensor of the cumulative product of values of `x` along `axis`.\n    \"\"\"\n    return tf.cumprod(x, axis=axis)",
                "def var(x, axis=None, keepdims=False):\n    \"\"\"Variance of a tensor, alongside the specified axis.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer, the axis to compute the variance.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1. If `keepdims` is `True`,\n            the reduced dimension is retained with length 1.\n\n    # Returns\n        A tensor with the variance of elements of `x`.\n    \"\"\"\n    if x.dtype.base_dtype == tf.bool:\n        x = tf.cast(x, floatx())\n    m = tf.reduce_mean(x, axis, True)\n    devs_squared = tf.square(x - m)\n    return tf.reduce_mean(devs_squared,\n                          axis,\n                          keepdims)",
                "def std(x, axis=None, keepdims=False):\n    \"\"\"Standard deviation of a tensor, alongside the specified axis.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer, the axis to compute the standard deviation.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1. If `keepdims` is `True`,\n            the reduced dimension is retained with length 1.\n\n    # Returns\n        A tensor with the standard deviation of elements of `x`.\n    \"\"\"\n    return tf.sqrt(var(x, axis=axis, keepdims=keepdims))",
                "def mean(x, axis=None, keepdims=False):\n    \"\"\"Mean of a tensor, alongside the specified axis.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: A list of integer. Axes to compute the mean.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1 for each entry in `axis`. If `keepdims` is `True`,\n            the reduced dimensions are retained with length 1.\n\n    # Returns\n        A tensor with the mean of elements of `x`.\n    \"\"\"\n    if x.dtype.base_dtype == tf.bool:\n        x = tf.cast(x, floatx())\n    return tf.reduce_mean(x, axis, keepdims)",
                "def any(x, axis=None, keepdims=False):\n    \"\"\"Bitwise reduction (logical OR).\n\n    # Arguments\n        x: Tensor or variable.\n        axis: axis along which to perform the reduction.\n        keepdims: whether the drop or broadcast the reduction axes.\n\n    # Returns\n        A uint8 tensor (0s and 1s).\n    \"\"\"\n    x = tf.cast(x, tf.bool)\n    return tf.reduce_any(x, axis, keepdims)",
                "def all(x, axis=None, keepdims=False):\n    \"\"\"Bitwise reduction (logical AND).\n\n    # Arguments\n        x: Tensor or variable.\n        axis: axis along which to perform the reduction.\n        keepdims: whether the drop or broadcast the reduction axes.\n\n    # Returns\n        A uint8 tensor (0s and 1s).\n    \"\"\"\n    x = tf.cast(x, tf.bool)\n    return tf.reduce_all(x, axis, keepdims)",
                "def argmax(x, axis=-1):\n    \"\"\"Returns the index of the maximum value along an axis.\n\n    # Arguments\n        x: Tensor or variable.\n        axis: axis along which to perform the reduction.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.argmax(x, axis)",
                "def argmin(x, axis=-1):\n    \"\"\"Returns the index of the minimum value along an axis.\n\n    # Arguments\n        x: Tensor or variable.\n        axis: axis along which to perform the reduction.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.argmin(x, axis)",
                "def square(x):\n    \"\"\"Element-wise square.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.square(x)",
                "def abs(x):\n    \"\"\"Element-wise absolute value.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.abs(x)",
                "def sqrt(x):\n    \"\"\"Element-wise square root.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    zero = _to_tensor(0., x.dtype.base_dtype)\n    inf = _to_tensor(np.inf, x.dtype.base_dtype)\n    x = tf.clip_by_value(x, zero, inf)\n    return tf.sqrt(x)",
                "def exp(x):\n    \"\"\"Element-wise exponential.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.exp(x)",
                "def log(x):\n    \"\"\"Element-wise log.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.log(x)",
                "def logsumexp(x, axis=None, keepdims=False):\n    \"\"\"Computes log(sum(exp(elements across dimensions of a tensor))).\n\n    This function is more numerically stable than log(sum(exp(x))).\n    It avoids overflows caused by taking the exp of large inputs and\n    underflows caused by taking the log of small inputs.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer, the axis to reduce over.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1. If `keepdims` is `True`, the reduced dimension is\n            retained with length 1.\n\n    # Returns\n        The reduced tensor.\n    \"\"\"\n    return tf.reduce_logsumexp(x, axis, keepdims)",
                "def round(x):\n    \"\"\"Element-wise rounding to the closest integer.\n\n    In case of tie, the rounding mode used is \"half to even\".\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.round(x)",
                "def sign(x):\n    \"\"\"Element-wise sign.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.sign(x)",
                "def pow(x, a):\n    \"\"\"Element-wise exponentiation.\n\n    # Arguments\n        x: Tensor or variable.\n        a: Python integer.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.pow(x, a)",
                "def clip(x, min_value, max_value):\n    \"\"\"Element-wise value clipping.\n\n    # Arguments\n        x: Tensor or variable.\n        min_value: Python float or integer.\n        max_value: Python float or integer.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if max_value is not None and max_value < min_value:\n        max_value = min_value\n    if max_value is None:\n        max_value = np.inf\n    min_value = _to_tensor(min_value, x.dtype.base_dtype)\n    max_value = _to_tensor(max_value, x.dtype.base_dtype)\n    return tf.clip_by_value(x, min_value, max_value)",
                "def equal(x, y):\n    \"\"\"Element-wise equality between two tensors.\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A bool tensor.\n    \"\"\"\n    return tf.equal(x, y)",
                "def not_equal(x, y):\n    \"\"\"Element-wise inequality between two tensors.\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A bool tensor.\n    \"\"\"\n    return tf.not_equal(x, y)",
                "def greater(x, y):\n    \"\"\"Element-wise truth value of (x > y).\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A bool tensor.\n    \"\"\"\n    return tf.greater(x, y)",
                "def greater_equal(x, y):\n    \"\"\"Element-wise truth value of (x >= y).\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A bool tensor.\n    \"\"\"\n    return tf.greater_equal(x, y)",
                "def less(x, y):\n    \"\"\"Element-wise truth value of (x < y).\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A bool tensor.\n    \"\"\"\n    return tf.less(x, y)",
                "def less_equal(x, y):\n    \"\"\"Element-wise truth value of (x <= y).\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A bool tensor.\n    \"\"\"\n    return tf.less_equal(x, y)",
                "def maximum(x, y):\n    \"\"\"Element-wise maximum of two tensors.\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.maximum(x, y)",
                "def minimum(x, y):\n    \"\"\"Element-wise minimum of two tensors.\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.minimum(x, y)",
                "def sin(x):\n    \"\"\"Computes sin of x element-wise.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.sin(x)",
                "def cos(x):\n    \"\"\"Computes cos of x element-wise.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.cos(x)",
                "def _regular_normalize_batch_in_training(x, gamma, beta,\n                                         reduction_axes, epsilon=1e-3):\n    \"\"\"Non-fused version of `normalize_batch_in_training`.\n\n    # Arguments\n        x: Input tensor or variable.\n        gamma: Tensor by which to scale the input.\n        beta: Tensor with which to center the input.\n        reduction_axes: iterable of integers,\n            axes over which to normalize.\n        epsilon: Fuzz factor.\n\n    # Returns\n        A tuple length of 3, `(normalized_tensor, mean, variance)`.\n    \"\"\"\n    mean, var = tf.nn.moments(x, reduction_axes,\n                              None, None, False)\n    normed = tf.nn.batch_normalization(x, mean, var,\n                                       beta, gamma,\n                                       epsilon)\n    return normed, mean, var",
                "def _broadcast_normalize_batch_in_training(x, gamma, beta,\n                                           reduction_axes, epsilon=1e-3):\n    \"\"\"Non-fused, broadcast version of `normalize_batch_in_training`.\n\n    # Arguments\n        x: Input tensor or variable.\n        gamma: Tensor by which to scale the input.\n        beta: Tensor with which to center the input.\n        reduction_axes: iterable of integers,\n            axes over which to normalize.\n        epsilon: Fuzz factor.\n\n    # Returns\n        A tuple length of 3, `(normalized_tensor, mean, variance)`.\n    \"\"\"\n    mean, var = tf.nn.moments(x, reduction_axes,\n                              None, None, False)\n    target_shape = []\n    for axis in range(ndim(x)):\n        if axis in reduction_axes:\n            target_shape.append(1)\n        else:\n            target_shape.append(tf.shape(x)[axis])\n    target_shape = tf.stack(target_shape)\n\n    broadcast_mean = tf.reshape(mean, target_shape)\n    broadcast_var = tf.reshape(var, target_shape)\n    if gamma is None:\n        broadcast_gamma = None\n    else:\n        broadcast_gamma = tf.reshape(gamma, target_shape)\n    if beta is None:\n        broadcast_beta = None\n    else:\n        broadcast_beta = tf.reshape(beta, target_shape)\n\n    normed = tf.nn.batch_normalization(\n        x,\n        broadcast_mean,\n        broadcast_var,\n        broadcast_beta,\n        broadcast_gamma,\n        epsilon)\n    return normed, mean, var",
                "def _fused_normalize_batch_in_training(x, gamma, beta, reduction_axes,\n                                       epsilon=1e-3):\n    \"\"\"Fused version of `normalize_batch_in_training`.\n\n    # Arguments\n        x: Input tensor or variable.\n        gamma: Tensor by which to scale the input.\n        beta: Tensor with which to center the input.\n        reduction_axes: iterable of integers,\n            axes over which to normalize.\n        epsilon: Fuzz factor.\n\n    # Returns\n        A tuple length of 3, `(normalized_tensor, mean, variance)`.\n    \"\"\"\n    if list(reduction_axes) == [0, 1, 2]:\n        normalization_axis = 3\n        tf_data_format = 'NHWC'\n    else:\n        normalization_axis = 1\n        tf_data_format = 'NCHW'\n\n    if gamma is None:\n        gamma = tf.constant(1.0,\n                            dtype=x.dtype,\n                            shape=[x.get_shape()[normalization_axis]])\n    if beta is None:\n        beta = tf.constant(0.0,\n                           dtype=x.dtype,\n                           shape=[x.get_shape()[normalization_axis]])\n\n    return tf.nn.fused_batch_norm(\n        x,\n        gamma,\n        beta,\n        epsilon=epsilon,\n        data_format=tf_data_format)",
                "def normalize_batch_in_training(x, gamma, beta,\n                                reduction_axes, epsilon=1e-3):\n    \"\"\"Computes mean and std for batch then apply batch_normalization on batch.\n\n    # Arguments\n        x: Input tensor or variable.\n        gamma: Tensor by which to scale the input.\n        beta: Tensor with which to center the input.\n        reduction_axes: iterable of integers,\n            axes over which to normalize.\n        epsilon: Fuzz factor.\n\n    # Returns\n        A tuple length of 3, `(normalized_tensor, mean, variance)`.\n    \"\"\"\n    if ndim(x) == 4 and list(reduction_axes) in [[0, 1, 2], [0, 2, 3]]:\n        if not _has_nchw_support() and list(reduction_axes) == [0, 2, 3]:\n            return _broadcast_normalize_batch_in_training(x, gamma, beta,\n                                                          reduction_axes,\n                                                          epsilon=epsilon)\n        return _fused_normalize_batch_in_training(\n            x, gamma, beta, reduction_axes,\n            epsilon=epsilon)\n    else:\n        if sorted(reduction_axes) == list(range(ndim(x)))[:-1]:\n            return _regular_normalize_batch_in_training(x, gamma, beta,\n                                                        reduction_axes,\n                                                        epsilon=epsilon)\n        else:\n            return _broadcast_normalize_batch_in_training(x, gamma, beta,\n                                                          reduction_axes,\n                                                          epsilon=epsilon)",
                "def batch_normalization(x, mean, var, beta, gamma, epsilon=1e-3):\n    \"\"\"Applies batch normalization on x given mean, var, beta and gamma.\n\n    I.e. returns:\n    `output = (x - mean) / (sqrt(var) + epsilon) * gamma + beta`\n\n    # Arguments\n        x: Input tensor or variable.\n        mean: Mean of batch.\n        var: Variance of batch.\n        beta: Tensor with which to center the input.\n        gamma: Tensor by which to scale the input.\n        epsilon: Fuzz factor.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.nn.batch_normalization(x, mean, var, beta, gamma, epsilon)",
                "def concatenate(tensors, axis=-1):\n    \"\"\"Concatenates a list of tensors alongside the specified axis.\n\n    # Arguments\n        tensors: list of tensors to concatenate.\n        axis: concatenation axis.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if axis < 0:\n        rank = ndim(tensors[0])\n        if rank:\n            axis %= rank\n        else:\n            axis = 0\n\n    if py_all([is_sparse(x) for x in tensors]):\n        return tf.sparse_concat(axis, tensors)\n    else:\n        return tf.concat([to_dense(x) for x in tensors], axis)",
                "def reshape(x, shape):\n    \"\"\"Reshapes a tensor to the specified shape.\n\n    # Arguments\n        x: Tensor or variable.\n        shape: Target shape tuple.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.reshape(x, shape)",
                "def permute_dimensions(x, pattern):\n    \"\"\"Permutes axes in a tensor.\n\n    # Arguments\n        x: Tensor or variable.\n        pattern: A tuple of\n            dimension indices, e.g. `(0, 2, 1)`.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.transpose(x, perm=pattern)",
                "def resize_images(x, height_factor, width_factor, data_format):\n    \"\"\"Resizes the images contained in a 4D tensor.\n\n    # Arguments\n        x: Tensor or variable to resize.\n        height_factor: Positive integer.\n        width_factor: Positive integer.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n\n    # Returns\n        A tensor.\n\n    # Raises\n        ValueError: if `data_format` is neither `\"channels_last\"` or `\"channels_first\"`.\n    \"\"\"\n    if data_format == 'channels_first':\n        original_shape = int_shape(x)\n        new_shape = tf.shape(x)[2:]\n        new_shape *= tf.constant(np.array([height_factor, width_factor]).astype('int32'))\n        x = permute_dimensions(x, [0, 2, 3, 1])\n        x = tf.image.resize_nearest_neighbor(x, new_shape)\n        x = permute_dimensions(x, [0, 3, 1, 2])\n        x.set_shape((None, None, original_shape[2] * height_factor if original_shape[2] is not None else None,\n                     original_shape[3] * width_factor if original_shape[3] is not None else None))\n        return x\n    elif data_format == 'channels_last':\n        original_shape = int_shape(x)\n        new_shape = tf.shape(x)[1:3]\n        new_shape *= tf.constant(np.array([height_factor, width_factor]).astype('int32'))\n        x = tf.image.resize_nearest_neighbor(x, new_shape)\n        x.set_shape((None, original_shape[1] * height_factor if original_shape[1] is not None else None,\n                     original_shape[2] * width_factor if original_shape[2] is not None else None, None))\n        return x\n    else:\n        raise ValueError('Unknown data_format: ' + str(data_format))",
                "def resize_volumes(x, depth_factor, height_factor, width_factor, data_format):\n    \"\"\"Resizes the volume contained in a 5D tensor.\n\n    # Arguments\n        x: Tensor or variable to resize.\n        depth_factor: Positive integer.\n        height_factor: Positive integer.\n        width_factor: Positive integer.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n\n    # Returns\n        A tensor.\n\n    # Raises\n        ValueError: if `data_format` is neither `\"channels_last\"` or `\"channels_first\"`.\n    \"\"\"\n    if data_format == 'channels_first':\n        output = repeat_elements(x, depth_factor, axis=2)\n        output = repeat_elements(output, height_factor, axis=3)\n        output = repeat_elements(output, width_factor, axis=4)\n        return output\n    elif data_format == 'channels_last':\n        output = repeat_elements(x, depth_factor, axis=1)\n        output = repeat_elements(output, height_factor, axis=2)\n        output = repeat_elements(output, width_factor, axis=3)\n        return output\n    else:\n        raise ValueError('Unknown data_format: ' + str(data_format))",
                "def repeat_elements(x, rep, axis):\n    \"\"\"Repeats the elements of a tensor along an axis, like `np.repeat`.\n\n    If `x` has shape `(s1, s2, s3)` and `axis` is `1`, the output\n    will have shape `(s1, s2 * rep, s3)`.\n\n    # Arguments\n        x: Tensor or variable.\n        rep: Python integer, number of times to repeat.\n        axis: Axis along which to repeat.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    x_shape = x.get_shape().as_list()\n    # For static axis\n    if x_shape[axis] is not None:\n        # slices along the repeat axis\n        splits = tf.split(value=x, num_or_size_splits=x_shape[axis], axis=axis)\n        # repeat each slice the given number of reps\n        x_rep = [s for s in splits for _ in range(rep)]\n        return concatenate(x_rep, axis)\n\n    # Here we use tf.tile to mimic behavior of np.repeat so that\n    # we can handle dynamic shapes (that include None).\n    # To do that, we need an auxiliary axis to repeat elements along\n    # it and then merge them along the desired axis.\n\n    # Repeating\n    auxiliary_axis = axis + 1\n    x_shape = tf.shape(x)\n    x_rep = tf.expand_dims(x, axis=auxiliary_axis)\n    reps = np.ones(len(x.get_shape()) + 1)\n    reps[auxiliary_axis] = rep\n    x_rep = tf.tile(x_rep, reps)\n\n    # Merging\n    reps = np.delete(reps, auxiliary_axis)\n    reps[axis] = rep\n    reps = tf.constant(reps, dtype='int32')\n    x_shape = x_shape * reps\n    x_rep = tf.reshape(x_rep, x_shape)\n\n    # Fix shape representation\n    x_shape = x.get_shape().as_list()\n    x_rep.set_shape(x_shape)\n    x_rep._keras_shape = tuple(x_shape)\n    return x_rep",
                "def repeat(x, n):\n    \"\"\"Repeats a 2D tensor.\n\n    if `x` has shape (samples, dim) and `n` is `2`,\n    the output will have shape `(samples, 2, dim)`.\n\n    # Arguments\n        x: Tensor or variable.\n        n: Python integer, number of times to repeat.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    assert ndim(x) == 2\n    x = tf.expand_dims(x, 1)\n    pattern = tf.stack([1, n, 1])\n    return tf.tile(x, pattern)",
                "def arange(start, stop=None, step=1, dtype='int32'):\n    \"\"\"Creates a 1D tensor containing a sequence of integers.\n\n    The function arguments use the same convention as\n    Theano's arange: if only one argument is provided,\n    it is in fact the \"stop\" argument and \"start\" is 0.\n\n    The default type of the returned tensor is `'int32'` to\n    match TensorFlow's default.\n\n    # Arguments\n        start: Start value.\n        stop: Stop value.\n        step: Difference between two successive values.\n        dtype: Integer dtype to use.\n\n    # Returns\n        An integer tensor.\n\n    \"\"\"\n    # Match the behavior of numpy and Theano by returning an empty sequence.\n    if stop is None:\n        try:\n            if start < 0:\n                start = 0\n        except TypeError:\n            # Handle case where start is a tensor\n            start = tf.cond(start < 0,\n                            true_fn=lambda: tf.constant(0, dtype=start.dtype),\n                            false_fn=lambda: start)\n\n    result = tf.range(start, limit=stop, delta=step, name='arange')\n    if dtype != 'int32':\n        result = cast(result, dtype)\n    return result",
                "def tile(x, n):\n    \"\"\"Creates a tensor by tiling `x` by `n`.\n\n    # Arguments\n        x: A tensor or variable\n        n: A list of integer. The length must be the same as the number of\n            dimensions in `x`.\n\n    # Returns\n        A tiled tensor.\n    \"\"\"\n    if isinstance(n, int):\n        n = [n]\n    return tf.tile(x, n)",
                "def flatten(x):\n    \"\"\"Flatten a tensor.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A tensor, reshaped into 1-D\n    \"\"\"\n    return tf.reshape(x, [-1])",
                "def batch_flatten(x):\n    \"\"\"Turn a nD tensor into a 2D tensor with same 0th dimension.\n\n    In other words, it flattens each data samples of a batch.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    x = tf.reshape(x, tf.stack([-1, prod(shape(x)[1:])]))\n    return x",
                "def expand_dims(x, axis=-1):\n    \"\"\"Adds a 1-sized dimension at index \"axis\".\n\n    # Arguments\n        x: A tensor or variable.\n        axis: Position where to add a new axis.\n\n    # Returns\n        A tensor with expanded dimensions.\n    \"\"\"\n    return tf.expand_dims(x, axis)",
                "def squeeze(x, axis):\n    \"\"\"Removes a 1-dimension from the tensor at index \"axis\".\n\n    # Arguments\n        x: A tensor or variable.\n        axis: Axis to drop.\n\n    # Returns\n        A tensor with the same data as `x` but reduced dimensions.\n    \"\"\"\n    return tf.squeeze(x, [axis])",
                "def temporal_padding(x, padding=(1, 1)):\n    \"\"\"Pads the middle dimension of a 3D tensor.\n\n    # Arguments\n        x: Tensor or variable.\n        padding: Tuple of 2 integers, how many zeros to\n            add at the start and end of dim 1.\n\n    # Returns\n        A padded 3D tensor.\n    \"\"\"\n    assert len(padding) == 2\n    pattern = [[0, 0], [padding[0], padding[1]], [0, 0]]\n    return tf.pad(x, pattern)",
                "def spatial_2d_padding(x, padding=((1, 1), (1, 1)), data_format=None):\n    \"\"\"Pads the 2nd and 3rd dimensions of a 4D tensor.\n\n    # Arguments\n        x: Tensor or variable.\n        padding: Tuple of 2 tuples, padding pattern.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n\n    # Returns\n        A padded 4D tensor.\n\n    # Raises\n        ValueError: if `data_format` is neither `\"channels_last\"` or `\"channels_first\"`.\n    \"\"\"\n    assert len(padding) == 2\n    assert len(padding[0]) == 2\n    assert len(padding[1]) == 2\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format: ' + str(data_format))\n\n    if data_format == 'channels_first':\n        pattern = [[0, 0],\n                   [0, 0],\n                   list(padding[0]),\n                   list(padding[1])]\n    else:\n        pattern = [[0, 0],\n                   list(padding[0]), list(padding[1]),\n                   [0, 0]]\n    return tf.pad(x, pattern)",
                "def spatial_3d_padding(x, padding=((1, 1), (1, 1), (1, 1)), data_format=None):\n    \"\"\"Pads 5D tensor with zeros along the depth, height, width dimensions.\n\n    Pads these dimensions with respectively\n    \"padding[0]\", \"padding[1]\" and \"padding[2]\" zeros left and right.\n\n    For 'channels_last' data_format,\n    the 2nd, 3rd and 4th dimension will be padded.\n    For 'channels_first' data_format,\n    the 3rd, 4th and 5th dimension will be padded.\n\n    # Arguments\n        x: Tensor or variable.\n        padding: Tuple of 3 tuples, padding pattern.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n\n    # Returns\n        A padded 5D tensor.\n\n    # Raises\n        ValueError: if `data_format` is neither `\"channels_last\"` or `\"channels_first\"`.\n\n    \"\"\"\n    assert len(padding) == 3\n    assert len(padding[0]) == 2\n    assert len(padding[1]) == 2\n    assert len(padding[2]) == 2\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format: ' + str(data_format))\n\n    if data_format == 'channels_first':\n        pattern = [\n            [0, 0],\n            [0, 0],\n            [padding[0][0], padding[0][1]],\n            [padding[1][0], padding[1][1]],\n            [padding[2][0], padding[2][1]]\n        ]\n    else:\n        pattern = [\n            [0, 0],\n            [padding[0][0], padding[0][1]],\n            [padding[1][0], padding[1][1]],\n            [padding[2][0], padding[2][1]],\n            [0, 0]\n        ]\n    return tf.pad(x, pattern)",
                "def stack(x, axis=0):\n    \"\"\"Stacks a list of rank `R` tensors into a rank `R+1` tensor.\n\n    # Arguments\n        x: List of tensors.\n        axis: Axis along which to perform stacking.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.stack(x, axis=axis)",
                "def one_hot(indices, num_classes):\n    \"\"\"Computes the one-hot representation of an integer tensor.\n\n    # Arguments\n        indices: nD integer tensor of shape\n            `(batch_size, dim1, dim2, ... dim(n-1))`\n        num_classes: Integer, number of classes to consider.\n\n    # Returns\n        (n + 1)D one hot representation of the input\n        with shape `(batch_size, dim1, dim2, ... dim(n-1), num_classes)`\n    \"\"\"\n    return tf.one_hot(indices, depth=num_classes, axis=-1)",
                "def reverse(x, axes):\n    \"\"\"Reverse a tensor along the specified axes.\n\n    # Arguments\n        x: Tensor to reverse.\n        axes: Integer or iterable of integers.\n            Axes to reverse.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if isinstance(axes, int):\n        axes = [axes]\n    return tf.reverse(x, axes)",
                "def get_value(x):\n    \"\"\"Returns the value of a variable.\n\n    # Arguments\n        x: input variable.\n\n    # Returns\n        A Numpy array.\n    \"\"\"\n    return x.eval(session=get_session())",
                "def batch_get_value(ops):\n    \"\"\"Returns the value of more than one tensor variable.\n\n    # Arguments\n        ops: list of ops to run.\n\n    # Returns\n        A list of Numpy arrays.\n    \"\"\"\n    if ops:\n        return get_session().run(ops)\n    else:\n        return []",
                "def set_value(x, value):\n    \"\"\"Sets the value of a variable, from a Numpy array.\n\n    # Arguments\n        x: Tensor to set to a new value.\n        value: Value to set the tensor to, as a Numpy array\n            (of the same shape).\n    \"\"\"\n    value = np.asarray(value, dtype=dtype(x))\n    tf_dtype = tf.as_dtype(x.dtype.name.split('_')[0])\n    if hasattr(x, '_assign_placeholder'):\n        assign_placeholder = x._assign_placeholder\n        assign_op = x._assign_op\n    else:\n        assign_placeholder = tf.placeholder(tf_dtype, shape=value.shape)\n        assign_op = x.assign(assign_placeholder)\n        x._assign_placeholder = assign_placeholder\n        x._assign_op = assign_op\n    get_session().run(assign_op, feed_dict={assign_placeholder: value})",
                "def batch_set_value(tuples):\n    \"\"\"Sets the values of many tensor variables at once.\n\n    # Arguments\n        tuples: a list of tuples `(tensor, value)`.\n            `value` should be a Numpy array.\n    \"\"\"\n    if tuples:\n        assign_ops = []\n        feed_dict = {}\n        for x, value in tuples:\n            value = np.asarray(value, dtype=dtype(x))\n            tf_dtype = tf.as_dtype(x.dtype.name.split('_')[0])\n            if hasattr(x, '_assign_placeholder'):\n                assign_placeholder = x._assign_placeholder\n                assign_op = x._assign_op\n            else:\n                assign_placeholder = tf.placeholder(tf_dtype,\n                                                    shape=value.shape)\n                assign_op = x.assign(assign_placeholder)\n                x._assign_placeholder = assign_placeholder\n                x._assign_op = assign_op\n            assign_ops.append(assign_op)\n            feed_dict[assign_placeholder] = value\n        get_session().run(assign_ops, feed_dict=feed_dict)",
                "def get_variable_shape(x):\n    \"\"\"Returns the shape of a variable.\n\n    # Arguments\n        x: A variable.\n\n    # Returns\n        A tuple of integers.\n    \"\"\"\n    return int_shape(x)",
                "def print_tensor(x, message=''):\n    \"\"\"Prints `message` and the tensor value when evaluated.\n\n     Note that `print_tensor` returns a new tensor identical to `x`\n     which should be used in the following code. Otherwise the\n     print operation is not taken into account during evaluation.\n\n     # Example\n     ```python\n         >>> x = K.print_tensor(x, message=\"x is: \")\n     ```\n\n    # Arguments\n        x: Tensor to print.\n        message: Message to print jointly with the tensor.\n\n    # Returns\n        The same tensor `x`, unchanged.\n    \"\"\"\n    return tf.Print(x, [x], message)",
                "def function(inputs, outputs, updates=None, **kwargs):\n    \"\"\"Instantiates a Keras function.\n\n    # Arguments\n        inputs: List of placeholder tensors.\n        outputs: List of output tensors.\n        updates: List of update ops.\n        **kwargs: Passed to `tf.Session.run`.\n\n    # Returns\n        Output values as Numpy arrays.\n\n    # Raises\n        ValueError: if invalid kwargs are passed in.\n    \"\"\"\n    if kwargs:\n        for key in kwargs:\n            if not (has_arg(tf.Session.run, key, True) or has_arg(Function.__init__, key, True)):\n                msg = 'Invalid argument \"%s\" passed to K.function with TensorFlow backend' % key\n                raise ValueError(msg)\n    return Function(inputs, outputs, updates=updates, **kwargs)",
                "def gradients(loss, variables):\n    \"\"\"Returns the gradients of `loss` w.r.t. `variables`.\n\n    # Arguments\n        loss: Scalar tensor to minimize.\n        variables: List of variables.\n\n    # Returns\n        A gradients tensor.\n    \"\"\"\n    return tf.gradients(loss, variables, colocate_gradients_with_ops=True)",
                "def stop_gradient(variables):\n    \"\"\"Returns `variables` but with zero gradient w.r.t. every other variable.\n\n    # Arguments\n        variables: tensor or list of tensors to consider constant with respect\n            to any other variable.\n\n    # Returns\n        A single tensor or a list of tensors (depending on the passed argument)\n            that has constant gradient with respect to any other variable.\n    \"\"\"\n    if isinstance(variables, (list, tuple)):\n        return map(tf.stop_gradient, variables)\n    else:\n        return tf.stop_gradient(variables)",
                "def rnn(step_function, inputs, initial_states,\n        go_backwards=False, mask=None, constants=None,\n        unroll=False, input_length=None):\n    \"\"\"Iterates over the time dimension of a tensor.\n\n    # Arguments\n        step_function: RNN step function.\n            Parameters:\n                inputs: tensor with shape `(samples, ...)` (no time dimension),\n                    representing input for the batch of samples at a certain\n                    time step.\n                states: list of tensors.\n            Returns:\n                outputs: tensor with shape `(samples, output_dim)`\n                    (no time dimension).\n                new_states: list of tensors, same length and shapes\n                    as 'states'. The first state in the list must be the\n                    output tensor at the previous timestep.\n        inputs: tensor of temporal data of shape `(samples, time, ...)`\n            (at least 3D).\n        initial_states: tensor with shape (samples, output_dim)\n            (no time dimension),\n            containing the initial values for the states used in\n            the step function.\n        go_backwards: boolean. If True, do the iteration over the time\n            dimension in reverse order and return the reversed sequence.\n        mask: binary tensor with shape `(samples, time, 1)`,\n            with a zero for every element that is masked.\n        constants: a list of constant values passed at each step.\n        unroll: whether to unroll the RNN or to use a symbolic loop (`while_loop` or `scan` depending on backend).\n        input_length: not relevant in the TensorFlow implementation.\n            Must be specified if using unrolling with Theano.\n\n    # Returns\n        A tuple, `(last_output, outputs, new_states)`.\n\n            last_output: the latest output of the rnn, of shape `(samples, ...)`\n            outputs: tensor with shape `(samples, time, ...)` where each\n                entry `outputs[s, t]` is the output of the step function\n                at time `t` for sample `s`.\n            new_states: list of tensors, latest states returned by\n                the step function, of shape `(samples, ...)`.\n\n    # Raises\n        ValueError: if input dimension is less than 3.\n        ValueError: if `unroll` is `True` but input timestep is not a fixed number.\n        ValueError: if `mask` is provided (not `None`) but states is not provided\n            (`len(states)` == 0).\n    \"\"\"\n    ndim = len(inputs.get_shape())\n    if ndim < 3:\n        raise ValueError('Input should be at least 3D.')\n\n    # Transpose to time-major, i.e.\n    # from (batch, time, ...) to (time, batch, ...)\n    axes = [1, 0] + list(range(2, ndim))\n    inputs = tf.transpose(inputs, (axes))\n\n    if mask is not None:\n        if mask.dtype != tf.bool:\n            mask = tf.cast(mask, tf.bool)\n        if len(mask.get_shape()) == ndim - 1:\n            mask = expand_dims(mask)\n        mask = tf.transpose(mask, axes)\n\n    if constants is None:\n        constants = []\n\n    global uses_learning_phase\n    uses_learning_phase = False\n\n    if unroll:\n        if not inputs.get_shape()[0]:\n            raise ValueError('Unrolling requires a '\n                             'fixed number of timesteps.')\n        states = initial_states\n        successive_states = []\n        successive_outputs = []\n\n        input_list = tf.unstack(inputs)\n        if go_backwards:\n            input_list.reverse()\n\n        if mask is not None:\n            mask_list = tf.unstack(mask)\n            if go_backwards:\n                mask_list.reverse()\n\n            for inp, mask_t in zip(input_list, mask_list):\n                output, new_states = step_function(inp, states + constants)\n                if getattr(output, '_uses_learning_phase', False):\n                    uses_learning_phase = True\n\n                # tf.where needs its condition tensor\n                # to be the same shape as its two\n                # result tensors, but in our case\n                # the condition (mask) tensor is\n                # (nsamples, 1), and A and B are (nsamples, ndimensions).\n                # So we need to\n                # broadcast the mask to match the shape of A and B.\n                # That's what the tile call does,\n                # it just repeats the mask along its second dimension\n                # n times.\n                tiled_mask_t = tf.tile(mask_t,\n                                       tf.stack([1, tf.shape(output)[1]]))\n\n                if not successive_outputs:\n                    prev_output = zeros_like(output)\n                else:\n                    prev_output = successive_outputs[-1]\n\n                output = tf.where(tiled_mask_t, output, prev_output)\n\n                return_states = []\n                for state, new_state in zip(states, new_states):\n                    # (see earlier comment for tile explanation)\n                    tiled_mask_t = tf.tile(mask_t,\n                                           tf.stack([1, tf.shape(new_state)[1]]))\n                    return_states.append(tf.where(tiled_mask_t,\n                                                  new_state,\n                                                  state))\n                states = return_states\n                successive_outputs.append(output)\n                successive_states.append(states)\n            last_output = successive_outputs[-1]\n            new_states = successive_states[-1]\n            outputs = tf.stack(successive_outputs)\n        else:\n            for inp in input_list:\n                output, states = step_function(inp, states + constants)\n                if getattr(output, '_uses_learning_phase', False):\n                    uses_learning_phase = True\n                successive_outputs.append(output)\n                successive_states.append(states)\n            last_output = successive_outputs[-1]\n            new_states = successive_states[-1]\n            outputs = tf.stack(successive_outputs)\n\n    else:\n        if go_backwards:\n            inputs = reverse(inputs, 0)\n\n        states = tuple(initial_states)\n\n        time_steps = tf.shape(inputs)[0]\n        outputs, _ = step_function(inputs[0], initial_states + constants)\n        output_ta = tensor_array_ops.TensorArray(\n            dtype=outputs.dtype,\n            size=time_steps,\n            tensor_array_name='output_ta')\n        input_ta = tensor_array_ops.TensorArray(\n            dtype=inputs.dtype,\n            size=time_steps,\n            tensor_array_name='input_ta')\n        input_ta = input_ta.unstack(inputs)\n        time = tf.constant(0, dtype='int32', name='time')\n\n        if mask is not None:\n            if not states:\n                raise ValueError('No initial states provided! '\n                                 'When using masking in an RNN, you should '\n                                 'provide initial states '\n                                 '(and your step function should return '\n                                 'as its first state at time `t` '\n                                 'the output at time `t-1`).')\n            if go_backwards:\n                mask = reverse(mask, 0)\n\n            mask_ta = tensor_array_ops.TensorArray(\n                dtype=tf.bool,\n                size=time_steps,\n                tensor_array_name='mask_ta')\n            mask_ta = mask_ta.unstack(mask)\n\n            def _step(time, output_ta_t, *states):\n                \"\"\"RNN step function.\n\n                # Arguments\n                    time: Current timestep value.\n                    output_ta_t: TensorArray.\n                    *states: List of states.\n\n                # Returns\n                    Tuple: `(time + 1,output_ta_t) + tuple(new_states)`\n                \"\"\"\n                current_input = input_ta.read(time)\n                mask_t = mask_ta.read(time)\n                output, new_states = step_function(current_input,\n                                                   tuple(states) +\n                                                   tuple(constants))\n                if getattr(output, '_uses_learning_phase', False):\n                    global uses_learning_phase\n                    uses_learning_phase = True\n                for state, new_state in zip(states, new_states):\n                    new_state.set_shape(state.get_shape())\n                tiled_mask_t = tf.tile(mask_t,\n                                       tf.stack([1, tf.shape(output)[1]]))\n                output = tf.where(tiled_mask_t, output, states[0])\n                new_states = [tf.where(tiled_mask_t, new_states[i], states[i]) for i in range(len(states))]\n                output_ta_t = output_ta_t.write(time, output)\n                return (time + 1, output_ta_t) + tuple(new_states)\n        else:\n            def _step(time, output_ta_t, *states):\n                \"\"\"RNN step function.\n\n                # Arguments\n                    time: Current timestep value.\n                    output_ta_t: TensorArray.\n                    *states: List of states.\n\n                # Returns\n                    Tuple: `(time + 1,output_ta_t) + tuple(new_states)`\n                \"\"\"\n                current_input = input_ta.read(time)\n                output, new_states = step_function(current_input,\n                                                   tuple(states) +\n                                                   tuple(constants))\n                if getattr(output, '_uses_learning_phase', False):\n                    global uses_learning_phase\n                    uses_learning_phase = True\n                for state, new_state in zip(states, new_states):\n                    new_state.set_shape(state.get_shape())\n                output_ta_t = output_ta_t.write(time, output)\n                return (time + 1, output_ta_t) + tuple(new_states)\n\n        final_outputs = control_flow_ops.while_loop(\n            cond=lambda time, *_: time < time_steps,\n            body=_step,\n            loop_vars=(time, output_ta) + states,\n            parallel_iterations=32,\n            swap_memory=True)\n        last_time = final_outputs[0]\n        output_ta = final_outputs[1]\n        new_states = final_outputs[2:]\n\n        outputs = output_ta.stack()\n        last_output = output_ta.read(last_time - 1)\n\n    axes = [1, 0] + list(range(2, len(outputs.get_shape())))\n    outputs = tf.transpose(outputs, axes)\n    last_output._uses_learning_phase = uses_learning_phase\n    return last_output, outputs, new_states",
                "def switch(condition, then_expression, else_expression):\n    \"\"\"Switches between two operations depending on a scalar value.\n\n    Note that both `then_expression` and `else_expression`\n    should be symbolic tensors of the *same shape*.\n\n    # Arguments\n        condition: tensor (`int` or `bool`).\n        then_expression: either a tensor, or a callable that returns a tensor.\n        else_expression: either a tensor, or a callable that returns a tensor.\n\n    # Returns\n        The selected tensor.\n\n    # Raises\n        ValueError: If rank of `condition` is greater than rank of expressions.\n    \"\"\"\n    if condition.dtype != tf.bool:\n        condition = tf.cast(condition, 'bool')\n    cond_ndim = ndim(condition)\n    if not cond_ndim:\n        if not callable(then_expression):\n            def then_expression_fn():\n                return then_expression\n        else:\n            then_expression_fn = then_expression\n        if not callable(else_expression):\n            def else_expression_fn():\n                return else_expression\n        else:\n            else_expression_fn = else_expression\n        x = tf.cond(condition,\n                    then_expression_fn,\n                    else_expression_fn)\n    else:\n        # tf.where needs its condition tensor\n        # to be the same shape as its two\n        # result tensors\n        if callable(then_expression):\n            then_expression = then_expression()\n        if callable(else_expression):\n            else_expression = else_expression()\n        expr_ndim = ndim(then_expression)\n        if cond_ndim > expr_ndim:\n            raise ValueError('Rank of `condition` should be less than or'\n                             ' equal to rank of `then_expression` and '\n                             '`else_expression`. ndim(condition)=' +\n                             str(cond_ndim) + ', ndim(then_expression)'\n                             '=' + str(expr_ndim))\n        if cond_ndim > 1:\n            ndim_diff = expr_ndim - cond_ndim\n            cond_shape = tf.concat([tf.shape(condition), [1] * ndim_diff], axis=0)\n            condition = tf.reshape(condition, cond_shape)\n            expr_shape = tf.shape(then_expression)\n            shape_diff = expr_shape - cond_shape\n            tile_shape = tf.where(shape_diff > 0, expr_shape, tf.ones_like(expr_shape))\n            condition = tf.tile(condition, tile_shape)\n        x = tf.where(condition, then_expression, else_expression)\n    return x",
                "def in_train_phase(x, alt, training=None):\n    \"\"\"Selects `x` in train phase, and `alt` otherwise.\n\n    Note that `alt` should have the *same shape* as `x`.\n\n    # Arguments\n        x: What to return in train phase\n            (tensor or callable that returns a tensor).\n        alt: What to return otherwise\n            (tensor or callable that returns a tensor).\n        training: Optional scalar tensor\n            (or Python boolean, or Python integer)\n            specifying the learning phase.\n\n    # Returns\n        Either `x` or `alt` based on the `training` flag.\n        the `training` flag defaults to `K.learning_phase()`.\n    \"\"\"\n    if training is None:\n        training = learning_phase()\n        uses_learning_phase = True\n    else:\n        uses_learning_phase = False\n\n    if training is 1 or training is True:\n        if callable(x):\n            return x()\n        else:\n            return x\n\n    elif training is 0 or training is False:\n        if callable(alt):\n            return alt()\n        else:\n            return alt\n\n    # else: assume learning phase is a placeholder tensor.\n    x = switch(training, x, alt)\n    if uses_learning_phase:\n        x._uses_learning_phase = True\n    return x",
                "def in_test_phase(x, alt, training=None):\n    \"\"\"Selects `x` in test phase, and `alt` otherwise.\n\n    Note that `alt` should have the *same shape* as `x`.\n\n    # Arguments\n        x: What to return in test phase\n            (tensor or callable that returns a tensor).\n        alt: What to return otherwise\n            (tensor or callable that returns a tensor).\n        training: Optional scalar tensor\n            (or Python boolean, or Python integer)\n            specifying the learning phase.\n\n    # Returns\n        Either `x` or `alt` based on `K.learning_phase`.\n    \"\"\"\n    return in_train_phase(alt, x, training=training)",
                "def relu(x, alpha=0., max_value=None):\n    \"\"\"Rectified linear unit.\n\n    With default values, it returns element-wise `max(x, 0)`.\n\n    # Arguments\n        x: A tensor or variable.\n        alpha: A scalar, slope of negative section (default=`0.`).\n        max_value: Saturation threshold.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if alpha != 0.:\n        x = tf.nn.leaky_relu(x, alpha)\n    else:\n        x = tf.nn.relu(x)\n\n    if max_value is not None:\n        max_value = _to_tensor(max_value, x.dtype.base_dtype)\n        x = tf.minimum(x, max_value)\n    return x",
                "def elu(x, alpha=1.):\n    \"\"\"Exponential linear unit.\n\n    # Arguments\n        x: A tensor or variable to compute the activation function for.\n        alpha: A scalar, slope of negative section.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    res = tf.nn.elu(x)\n    if alpha == 1:\n        return res\n    else:\n        return tf.where(x > 0, res, alpha * res)",
                "def softmax(x, axis=-1):\n    \"\"\"Softmax of a tensor.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: The dimension softmax would be performed on.\n            The default is -1 which indicates the last dimension.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.nn.softmax(x, axis=axis)",
                "def softplus(x):\n    \"\"\"Softplus of a tensor.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.nn.softplus(x)",
                "def softsign(x):\n    \"\"\"Softsign of a tensor.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.nn.softsign(x)",
                "def categorical_crossentropy(target, output, from_logits=False):\n    \"\"\"Categorical crossentropy between an output tensor and a target tensor.\n\n    # Arguments\n        target: A tensor of the same shape as `output`.\n        output: A tensor resulting from a softmax\n            (unless `from_logits` is True, in which\n            case `output` is expected to be the logits).\n        from_logits: Boolean, whether `output` is the\n            result of a softmax, or is a tensor of logits.\n\n    # Returns\n        Output tensor.\n    \"\"\"\n    # Note: tf.nn.softmax_cross_entropy_with_logits\n    # expects logits, Keras expects probabilities.\n    if not from_logits:\n        # scale preds so that the class probas of each sample sum to 1\n        output /= tf.reduce_sum(output,\n                                len(output.get_shape()) - 1,\n                                True)\n        # manual computation of crossentropy\n        _epsilon = _to_tensor(epsilon(), output.dtype.base_dtype)\n        output = tf.clip_by_value(output, _epsilon, 1. - _epsilon)\n        return - tf.reduce_sum(target * tf.log(output),\n                               len(output.get_shape()) - 1)\n    else:\n        return tf.nn.softmax_cross_entropy_with_logits(labels=target,\n                                                       logits=output)",
                "def sparse_categorical_crossentropy(target, output, from_logits=False):\n    \"\"\"Categorical crossentropy with integer targets.\n\n    # Arguments\n        target: An integer tensor.\n        output: A tensor resulting from a softmax\n            (unless `from_logits` is True, in which\n            case `output` is expected to be the logits).\n        from_logits: Boolean, whether `output` is the\n            result of a softmax, or is a tensor of logits.\n\n    # Returns\n        Output tensor.\n    \"\"\"\n    # Note: tf.nn.sparse_softmax_cross_entropy_with_logits\n    # expects logits, Keras expects probabilities.\n    if not from_logits:\n        _epsilon = _to_tensor(epsilon(), output.dtype.base_dtype)\n        output = tf.clip_by_value(output, _epsilon, 1 - _epsilon)\n        output = tf.log(output)\n\n    output_shape = output.get_shape()\n    targets = cast(flatten(target), 'int64')\n    logits = tf.reshape(output, [-1, int(output_shape[-1])])\n    res = tf.nn.sparse_softmax_cross_entropy_with_logits(\n        labels=targets,\n        logits=logits)\n    if len(output_shape) >= 3:\n        # if our output includes timestep dimension\n        # or spatial dimensions we need to reshape\n        return tf.reshape(res, tf.shape(output)[:-1])\n    else:\n        return res",
                "def binary_crossentropy(target, output, from_logits=False):\n    \"\"\"Binary crossentropy between an output tensor and a target tensor.\n\n    # Arguments\n        target: A tensor with the same shape as `output`.\n        output: A tensor.\n        from_logits: Whether `output` is expected to be a logits tensor.\n            By default, we consider that `output`\n            encodes a probability distribution.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    # Note: tf.nn.sigmoid_cross_entropy_with_logits\n    # expects logits, Keras expects probabilities.\n    if not from_logits:\n        # transform back to logits\n        _epsilon = _to_tensor(epsilon(), output.dtype.base_dtype)\n        output = tf.clip_by_value(output, _epsilon, 1 - _epsilon)\n        output = tf.log(output / (1 - output))\n\n    return tf.nn.sigmoid_cross_entropy_with_logits(labels=target,\n                                                   logits=output)",
                "def sigmoid(x):\n    \"\"\"Element-wise sigmoid.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.nn.sigmoid(x)",
                "def hard_sigmoid(x):\n    \"\"\"Segment-wise linear approximation of sigmoid.\n\n    Faster than sigmoid.\n    Returns `0.` if `x < -2.5`, `1.` if `x > 2.5`.\n    In `-2.5 <= x <= 2.5`, returns `0.2 * x + 0.5`.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    x = (0.2 * x) + 0.5\n    zero = _to_tensor(0., x.dtype.base_dtype)\n    one = _to_tensor(1., x.dtype.base_dtype)\n    x = tf.clip_by_value(x, zero, one)\n    return x",
                "def tanh(x):\n    \"\"\"Element-wise tanh.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.nn.tanh(x)",
                "def dropout(x, level, noise_shape=None, seed=None):\n    \"\"\"Sets entries in `x` to zero at random, while scaling the entire tensor.\n\n    # Arguments\n        x: tensor\n        level: fraction of the entries in the tensor\n            that will be set to 0.\n        noise_shape: shape for randomly generated keep/drop flags,\n            must be broadcastable to the shape of `x`\n        seed: random seed to ensure determinism.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    retain_prob = 1. - level\n    if seed is None:\n        seed = np.random.randint(10e6)\n    # the dummy 1. works around a TF bug\n    # (float32_ref vs. float32 incompatibility)\n    return tf.nn.dropout(x * 1., retain_prob, noise_shape, seed=seed)",
                "def l2_normalize(x, axis=None):\n    \"\"\"Normalizes a tensor wrt the L2 norm alongside the specified axis.\n\n    # Arguments\n        x: Tensor or variable.\n        axis: axis along which to perform normalization.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.nn.l2_normalize(x, axis=axis)",
                "def in_top_k(predictions, targets, k):\n    \"\"\"Returns whether the `targets` are in the top `k` `predictions`.\n\n    # Arguments\n        predictions: A tensor of shape `(batch_size, classes)` and type `float32`.\n        targets: A 1D tensor of length `batch_size` and type `int32` or `int64`.\n        k: An `int`, number of top elements to consider.\n\n    # Returns\n        A 1D tensor of length `batch_size` and type `bool`.\n        `output[i]` is `True` if `predictions[i, targets[i]]` is within top-`k`\n        values of `predictions[i]`.\n    \"\"\"\n    return tf.nn.in_top_k(predictions, targets, k)",
                "def _preprocess_conv1d_input(x, data_format):\n    \"\"\"Transpose and cast the input before the conv1d.\n\n    # Arguments\n        x: input tensor.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if dtype(x) == 'float64':\n        x = tf.cast(x, 'float32')\n    tf_data_format = 'NHWC'  # to pass TF Conv2dNative operations\n    if data_format == 'channels_first':\n        if not _has_nchw_support():\n            x = tf.transpose(x, (0, 2, 1))  # NCW -> NWC\n        else:\n            tf_data_format = 'NCHW'\n    return x, tf_data_format",
                "def _preprocess_conv2d_input(x, data_format):\n    \"\"\"Transpose and cast the input before the conv2d.\n\n    # Arguments\n        x: input tensor.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if dtype(x) == 'float64':\n        x = tf.cast(x, 'float32')\n    tf_data_format = 'NHWC'\n    if data_format == 'channels_first':\n        if not _has_nchw_support():\n            x = tf.transpose(x, (0, 2, 3, 1))  # NCHW -> NHWC\n        else:\n            tf_data_format = 'NCHW'\n    return x, tf_data_format",
                "def _preprocess_conv3d_input(x, data_format):\n    \"\"\"Transpose and cast the input before the conv3d.\n\n    # Arguments\n        x: input tensor.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if dtype(x) == 'float64':\n        x = tf.cast(x, 'float32')\n    tf_data_format = 'NDHWC'\n    if data_format == 'channels_first':\n        if not _has_nchw_support():\n            x = tf.transpose(x, (0, 2, 3, 4, 1))\n        else:\n            tf_data_format = 'NCDHW'\n    return x, tf_data_format",
                "def _preprocess_padding(padding):\n    \"\"\"Convert keras' padding to tensorflow's padding.\n\n    # Arguments\n        padding: string, `\"same\"` or `\"valid\"`.\n\n    # Returns\n        a string, `\"SAME\"` or `\"VALID\"`.\n\n    # Raises\n        ValueError: if `padding` is invalid.\n    \"\"\"\n    if padding == 'same':\n        padding = 'SAME'\n    elif padding == 'valid':\n        padding = 'VALID'\n    else:\n        raise ValueError('Invalid padding: ' + str(padding))\n    return padding",
                "def conv1d(x, kernel, strides=1, padding='valid',\n           data_format=None, dilation_rate=1):\n    \"\"\"1D convolution.\n\n    # Arguments\n        x: Tensor or variable.\n        kernel: kernel tensor.\n        strides: stride integer.\n        padding: string, `\"same\"`, `\"causal\"` or `\"valid\"`.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n        dilation_rate: integer dilate rate.\n\n    # Returns\n        A tensor, result of 1D convolution.\n\n    # Raises\n        ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format: ' + str(data_format))\n\n    kernel_shape = kernel.get_shape().as_list()\n    if padding == 'causal':\n        # causal (dilated) convolution:\n        left_pad = dilation_rate * (kernel_shape[0] - 1)\n        x = temporal_padding(x, (left_pad, 0))\n        padding = 'valid'\n    padding = _preprocess_padding(padding)\n    if data_format == 'channels_last':\n        tf_data_format = 'NWC'\n    else:\n        tf_data_format = 'NCW'\n    x = tf.nn.convolution(\n        input=x,\n        filter=kernel,\n        dilation_rate=(dilation_rate,),\n        strides=(strides,),\n        padding=padding,\n        data_format=tf_data_format)\n    return x",
                "def conv2d(x, kernel, strides=(1, 1), padding='valid',\n           data_format=None, dilation_rate=(1, 1)):\n    \"\"\"2D convolution.\n\n    # Arguments\n        x: Tensor or variable.\n        kernel: kernel tensor.\n        strides: strides tuple.\n        padding: string, `\"same\"` or `\"valid\"`.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n            Whether to use Theano or TensorFlow/CNTK data format\n            for inputs/kernels/outputs.\n        dilation_rate: tuple of 2 integers.\n\n    # Returns\n        A tensor, result of 2D convolution.\n\n    # Raises\n        ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format: ' + str(data_format))\n\n    x, tf_data_format = _preprocess_conv2d_input(x, data_format)\n\n    padding = _preprocess_padding(padding)\n    x = tf.nn.convolution(\n        input=x,\n        filter=kernel,\n        dilation_rate=dilation_rate,\n        strides=strides,\n        padding=padding,\n        data_format=tf_data_format)\n\n    if data_format == 'channels_first' and tf_data_format == 'NHWC':\n        x = tf.transpose(x, (0, 3, 1, 2))  # NHWC -> NCHW\n    return x",
                "def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),\n                     padding='valid', data_format=None):\n    \"\"\"2D deconvolution (i.e. transposed convolution).\n\n    # Arguments\n        x: Tensor or variable.\n        kernel: kernel tensor.\n        output_shape: 1D int tensor for the output shape.\n        strides: strides tuple.\n        padding: string, `\"same\"` or `\"valid\"`.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n            Whether to use Theano or TensorFlow/CNTK data format\n            for inputs/kernels/outputs.\n\n    # Returns\n        A tensor, result of transposed 2D convolution.\n\n    # Raises\n        ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format: ' + str(data_format))\n    if isinstance(output_shape, (tuple, list)):\n        output_shape = tf.stack(output_shape)\n\n    x, tf_data_format = _preprocess_conv2d_input(x, data_format)\n\n    if data_format == 'channels_first' and tf_data_format == 'NHWC':\n        output_shape = (output_shape[0],\n                        output_shape[2],\n                        output_shape[3],\n                        output_shape[1])\n    if output_shape[0] is None:\n        output_shape = (tf.shape(x)[0],) + tuple(output_shape[1:])\n        output_shape = tf.stack(list(output_shape))\n\n    padding = _preprocess_padding(padding)\n    if tf_data_format == 'NHWC':\n        strides = (1,) + strides + (1,)\n    else:\n        strides = (1, 1) + strides\n\n    x = tf.nn.conv2d_transpose(x, kernel, output_shape, strides,\n                               padding=padding,\n                               data_format=tf_data_format)\n    if data_format == 'channels_first' and tf_data_format == 'NHWC':\n        x = tf.transpose(x, (0, 3, 1, 2))  # NHWC -> NCHW\n    return x",
                "def separable_conv1d(x, depthwise_kernel, pointwise_kernel, strides=1,\n                     padding='valid', data_format=None, dilation_rate=1):\n    \"\"\"1D convolution with separable filters.\n\n    # Arguments\n        x: input tensor\n        depthwise_kernel: convolution kernel for the depthwise convolution.\n        pointwise_kernel: kernel for the 1x1 convolution.\n        strides: stride integer.\n        padding: string, `\"same\"` or `\"valid\"`.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n        dilation_rate: integer dilation rate.\n\n    # Returns\n        Output tensor.\n\n    # Raises\n        ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format: ' + str(data_format))\n\n    x, tf_data_format = _preprocess_conv1d_input(x, data_format)\n    padding = _preprocess_padding(padding)\n    if tf_data_format == 'NHWC':\n        spatial_start_dim = 1\n        strides = (1,) + strides * 2 + (1,)\n    else:\n        spatial_start_dim = 2\n        strides = (1, 1) + strides * 2\n    x = tf.expand_dims(x, spatial_start_dim)\n    depthwise_kernel = tf.expand_dims(depthwise_kernel, 0)\n    pointwise_kernel = tf.expand_dims(pointwise_kernel, 0)\n    dilation_rate = (1,) + dilation_rate\n\n    x = tf.nn.separable_conv2d(x, depthwise_kernel, pointwise_kernel,\n                               strides=strides,\n                               padding=padding,\n                               rate=dilation_rate,\n                               data_format=tf_data_format)\n\n    x = tf.squeeze(x, [spatial_start_dim])\n\n    if data_format == 'channels_first' and tf_data_format == 'NHWC':\n        x = tf.transpose(x, (0, 2, 1))  # NWC -> NCW\n\n    return x",
                "def separable_conv2d(x, depthwise_kernel, pointwise_kernel, strides=(1, 1),\n                     padding='valid', data_format=None, dilation_rate=(1, 1)):\n    \"\"\"2D convolution with separable filters.\n\n    # Arguments\n        x: input tensor\n        depthwise_kernel: convolution kernel for the depthwise convolution.\n        pointwise_kernel: kernel for the 1x1 convolution.\n        strides: strides tuple (length 2).\n        padding: string, `\"same\"` or `\"valid\"`.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n        dilation_rate: tuple of integers,\n            dilation rates for the separable convolution.\n\n    # Returns\n        Output tensor.\n\n    # Raises\n        ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format: ' + str(data_format))\n\n    x, tf_data_format = _preprocess_conv2d_input(x, data_format)\n    padding = _preprocess_padding(padding)\n    if tf_data_format == 'NHWC':\n        strides = (1,) + strides + (1,)\n    else:\n        strides = (1, 1) + strides\n\n    x = tf.nn.separable_conv2d(x, depthwise_kernel, pointwise_kernel,\n                               strides=strides,\n                               padding=padding,\n                               rate=dilation_rate,\n                               data_format=tf_data_format)\n    if data_format == 'channels_first' and tf_data_format == 'NHWC':\n        x = tf.transpose(x, (0, 3, 1, 2))  # NHWC -> NCHW\n    return x",
                "def depthwise_conv2d(x, depthwise_kernel, strides=(1, 1), padding='valid',\n                     data_format=None, dilation_rate=(1, 1)):\n    \"\"\"2D convolution with separable filters.\n\n    # Arguments\n        x: input tensor\n        depthwise_kernel: convolution kernel for the depthwise convolution.\n        strides: strides tuple (length 2).\n        padding: string, `\"same\"` or `\"valid\"`.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n        dilation_rate: tuple of integers,\n            dilation rates for the separable convolution.\n\n    # Returns\n        Output tensor.\n\n    # Raises\n        ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format: ' + str(data_format))\n\n    x, tf_data_format = _preprocess_conv2d_input(x, data_format)\n    padding = _preprocess_padding(padding)\n    if tf_data_format == 'NHWC':\n        strides = (1,) + strides + (1,)\n    else:\n        strides = (1, 1) + strides\n\n    x = tf.nn.depthwise_conv2d(x, depthwise_kernel,\n                               strides=strides,\n                               padding=padding,\n                               rate=dilation_rate,\n                               data_format=tf_data_format)\n    if data_format == 'channels_first' and tf_data_format == 'NHWC':\n        x = tf.transpose(x, (0, 3, 1, 2))  # NHWC -> NCHW\n    return x",
                "def conv3d(x, kernel, strides=(1, 1, 1), padding='valid',\n           data_format=None, dilation_rate=(1, 1, 1)):\n    \"\"\"3D convolution.\n\n    # Arguments\n        x: Tensor or variable.\n        kernel: kernel tensor.\n        strides: strides tuple.\n        padding: string, `\"same\"` or `\"valid\"`.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n            Whether to use Theano or TensorFlow/CNTK data format\n            for inputs/kernels/outputs.\n        dilation_rate: tuple of 3 integers.\n\n    # Returns\n        A tensor, result of 3D convolution.\n\n    # Raises\n        ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format: ' + str(data_format))\n\n    x, tf_data_format = _preprocess_conv3d_input(x, data_format)\n    padding = _preprocess_padding(padding)\n    x = tf.nn.convolution(\n        input=x,\n        filter=kernel,\n        dilation_rate=dilation_rate,\n        strides=strides,\n        padding=padding,\n        data_format=tf_data_format)\n    if data_format == 'channels_first' and tf_data_format == 'NDHWC':\n        x = tf.transpose(x, (0, 4, 1, 2, 3))\n    return x",
                "def conv3d_transpose(x, kernel, output_shape, strides=(1, 1, 1),\n                     padding='valid', data_format=None):\n    \"\"\"3D deconvolution (i.e. transposed convolution).\n\n    # Arguments\n        x: input tensor.\n        kernel: kernel tensor.\n        output_shape: 1D int tensor for the output shape.\n        strides: strides tuple.\n        padding: string, \"same\" or \"valid\".\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n            Whether to use Theano or TensorFlow/CNTK data format\n            for inputs/kernels/outputs.\n\n    # Returns\n        A tensor, result of transposed 3D convolution.\n\n    # Raises\n        ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format: ' + str(data_format))\n    if isinstance(output_shape, (tuple, list)):\n        output_shape = tf.stack(output_shape)\n\n    x, tf_data_format = _preprocess_conv3d_input(x, data_format)\n\n    if data_format == 'channels_first' and tf_data_format == 'NDHWC':\n        output_shape = (output_shape[0],\n                        output_shape[2],\n                        output_shape[3],\n                        output_shape[4],\n                        output_shape[1])\n    if output_shape[0] is None:\n        output_shape = (tf.shape(x)[0],) + tuple(output_shape[1:])\n        output_shape = tf.stack(list(output_shape))\n\n    padding = _preprocess_padding(padding)\n    if tf_data_format == 'NDHWC':\n        strides = (1,) + strides + (1,)\n    else:\n        strides = (1, 1) + strides\n\n    x = tf.nn.conv3d_transpose(x, kernel, output_shape, strides,\n                               padding=padding,\n                               data_format=tf_data_format)\n    if data_format == 'channels_first' and tf_data_format == 'NDHWC':\n        x = tf.transpose(x, (0, 4, 1, 2, 3))\n    return x",
                "def pool2d(x, pool_size, strides=(1, 1),\n           padding='valid', data_format=None,\n           pool_mode='max'):\n    \"\"\"2D Pooling.\n\n    # Arguments\n        x: Tensor or variable.\n        pool_size: tuple of 2 integers.\n        strides: tuple of 2 integers.\n        padding: string, `\"same\"` or `\"valid\"`.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n        pool_mode: string, `\"max\"` or `\"avg\"`.\n\n    # Returns\n        A tensor, result of 2D pooling.\n\n    # Raises\n        ValueError: if `data_format` is neither `\"channels_last\"` or `\"channels_first\"`.\n        ValueError: if `pool_mode` is neither `\"max\"` or `\"avg\"`.\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format: ' + str(data_format))\n\n    x, tf_data_format = _preprocess_conv2d_input(x, data_format)\n    padding = _preprocess_padding(padding)\n    if tf_data_format == 'NHWC':\n        strides = (1,) + strides + (1,)\n        pool_size = (1,) + pool_size + (1,)\n    else:\n        strides = (1, 1) + strides\n        pool_size = (1, 1) + pool_size\n\n    if pool_mode == 'max':\n        x = tf.nn.max_pool(x, pool_size, strides,\n                           padding=padding,\n                           data_format=tf_data_format)\n    elif pool_mode == 'avg':\n        x = tf.nn.avg_pool(x, pool_size, strides,\n                           padding=padding,\n                           data_format=tf_data_format)\n    else:\n        raise ValueError('Invalid pool_mode: ' + str(pool_mode))\n\n    if data_format == 'channels_first' and tf_data_format == 'NHWC':\n        x = tf.transpose(x, (0, 3, 1, 2))  # NHWC -> NCHW\n    return x",
                "def pool3d(x, pool_size, strides=(1, 1, 1), padding='valid',\n           data_format=None, pool_mode='max'):\n    \"\"\"3D Pooling.\n\n    # Arguments\n        x: Tensor or variable.\n        pool_size: tuple of 3 integers.\n        strides: tuple of 3 integers.\n        padding: string, `\"same\"` or `\"valid\"`.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n        pool_mode: string, `\"max\"` or `\"avg\"`.\n\n    # Returns\n        A tensor, result of 3D pooling.\n\n    # Raises\n        ValueError: if `data_format` is neither `\"channels_last\"` or `\"channels_first\"`.\n        ValueError: if `pool_mode` is neither `\"max\"` or `\"avg\"`.\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format: ' + str(data_format))\n\n    x, tf_data_format = _preprocess_conv3d_input(x, data_format)\n    padding = _preprocess_padding(padding)\n    if tf_data_format == 'NDHWC':\n        strides = (1,) + strides + (1,)\n        pool_size = (1,) + pool_size + (1,)\n    else:\n        strides = (1, 1) + strides\n        pool_size = (1, 1) + pool_size\n\n    if pool_mode == 'max':\n        x = tf.nn.max_pool3d(x, pool_size, strides,\n                             padding=padding,\n                             data_format=tf_data_format)\n    elif pool_mode == 'avg':\n        x = tf.nn.avg_pool3d(x, pool_size, strides,\n                             padding=padding,\n                             data_format=tf_data_format)\n    else:\n        raise ValueError('Invalid pool_mode: ' + str(pool_mode))\n\n    if data_format == 'channels_first' and tf_data_format == 'NDHWC':\n        x = tf.transpose(x, (0, 4, 1, 2, 3))\n    return x",
                "def bias_add(x, bias, data_format=None):\n    \"\"\"Adds a bias vector to a tensor.\n\n    # Arguments\n        x: Tensor or variable.\n        bias: Bias tensor to add.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n\n    # Returns\n        Output tensor.\n\n    # Raises\n        ValueError: In one of the two cases below:\n                    1. invalid `data_format` argument.\n                    2. invalid bias shape.\n                       the bias should be either a vector or\n                       a tensor with ndim(x) - 1 dimension\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format: ' + str(data_format))\n    bias_shape = int_shape(bias)\n    if len(bias_shape) != 1 and len(bias_shape) != ndim(x) - 1:\n        raise ValueError('Unexpected bias dimensions %d, expect to be 1 or %d dimensions'\n                         % (len(bias_shape), ndim(x)))\n    if ndim(x) == 5:\n        if data_format == 'channels_first':\n            if len(bias_shape) == 1:\n                x += reshape(bias, (1, bias_shape[0], 1, 1, 1))\n            else:\n                x += reshape(bias, (1, bias_shape[3]) + bias_shape[:3])\n        elif data_format == 'channels_last':\n            if len(bias_shape) == 1:\n                x += reshape(bias, (1, 1, 1, bias_shape[0]))\n            else:\n                x += reshape(bias, (1,) + bias_shape)\n    elif ndim(x) == 4:\n        if data_format == 'channels_first':\n            if len(bias_shape) == 1:\n                if _has_nchw_support():\n                    x = tf.nn.bias_add(x, bias,\n                                       data_format='NCHW')\n                else:\n                    x += reshape(bias, (1, bias_shape[0], 1, 1))\n            else:\n                x += reshape(bias, (1, bias_shape[2]) + bias_shape[:2])\n        elif data_format == 'channels_last':\n            if len(bias_shape) == 1:\n                x = tf.nn.bias_add(x, bias,\n                                   data_format='NHWC')\n            else:\n                x += reshape(bias, (1,) + bias_shape)\n    elif ndim(x) == 3:\n        if data_format == 'channels_first':\n            if len(bias_shape) == 1:\n                x += reshape(bias, (1, bias_shape[0], 1))\n            else:\n                x += reshape(bias, (1, bias_shape[1], bias_shape[0]))\n        elif data_format == 'channels_last':\n            if len(bias_shape) == 1:\n                x += reshape(bias, (1, 1, bias_shape[0]))\n            else:\n                x += reshape(bias, (1, ) + bias_shape)\n    else:\n        x = tf.nn.bias_add(x, bias)\n    return x",
                "def random_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n    \"\"\"Returns a tensor with normal distribution of values.\n\n    # Arguments\n        shape: A tuple of integers, the shape of tensor to create.\n        mean: A float, mean of the normal distribution to draw samples.\n        stddev: A float, standard deviation of the normal distribution\n            to draw samples.\n        dtype: String, dtype of returned tensor.\n        seed: Integer, random seed.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    if seed is None:\n        seed = np.random.randint(10e6)\n    return tf.random_normal(shape, mean=mean, stddev=stddev,\n                            dtype=dtype, seed=seed)",
                "def random_uniform(shape, minval=0.0, maxval=1.0, dtype=None, seed=None):\n    \"\"\"Returns a tensor with uniform distribution of values.\n\n    # Arguments\n        shape: A tuple of integers, the shape of tensor to create.\n        minval: A float, lower boundary of the uniform distribution\n            to draw samples.\n        maxval: A float, upper boundary of the uniform distribution\n            to draw samples.\n        dtype: String, dtype of returned tensor.\n        seed: Integer, random seed.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    if seed is None:\n        seed = np.random.randint(10e6)\n    return tf.random_uniform(shape, minval=minval, maxval=maxval,\n                             dtype=dtype, seed=seed)",
                "def random_binomial(shape, p=0.0, dtype=None, seed=None):\n    \"\"\"Returns a tensor with random binomial distribution of values.\n\n    # Arguments\n        shape: A tuple of integers, the shape of tensor to create.\n        p: A float, `0. <= p <= 1`, probability of binomial distribution.\n        dtype: String, dtype of returned tensor.\n        seed: Integer, random seed.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    if seed is None:\n        seed = np.random.randint(10e6)\n    return tf.where(tf.random_uniform(shape, dtype=dtype, seed=seed) <= p,\n                    tf.ones(shape, dtype=dtype),\n                    tf.zeros(shape, dtype=dtype))",
                "def truncated_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n    \"\"\"Returns a tensor with truncated random normal distribution of values.\n\n    The generated values follow a normal distribution\n    with specified mean and standard deviation,\n    except that values whose magnitude is more than\n    two standard deviations from the mean are dropped and re-picked.\n\n    # Arguments\n        shape: A tuple of integers, the shape of tensor to create.\n        mean: Mean of the values.\n        stddev: Standard deviation of the values.\n        dtype: String, dtype of returned tensor.\n        seed: Integer, random seed.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    if seed is None:\n        seed = np.random.randint(10e6)\n    return tf.truncated_normal(shape, mean, stddev, dtype=dtype, seed=seed)",
                "def ctc_label_dense_to_sparse(labels, label_lengths):\n    \"\"\"Converts CTC labels from dense to sparse.\n\n    # Arguments\n        labels: dense CTC labels.\n        label_lengths: length of the labels.\n\n    # Returns\n        A sparse tensor representation of the labels.\n    \"\"\"\n    label_shape = tf.shape(labels)\n    num_batches_tns = tf.stack([label_shape[0]])\n    max_num_labels_tns = tf.stack([label_shape[1]])\n\n    def range_less_than(_, current_input):\n        return tf.expand_dims(tf.range(label_shape[1]), 0) < tf.fill(\n            max_num_labels_tns, current_input)\n\n    init = tf.cast(tf.fill([1, label_shape[1]], 0), tf.bool)\n    dense_mask = functional_ops.scan(range_less_than, label_lengths,\n                                     initializer=init, parallel_iterations=1)\n    dense_mask = dense_mask[:, 0, :]\n\n    label_array = tf.reshape(tf.tile(tf.range(label_shape[1]), num_batches_tns),\n                             label_shape)\n    label_ind = tf.boolean_mask(label_array, dense_mask)\n\n    batch_array = tf.transpose(tf.reshape(tf.tile(tf.range(label_shape[0]),\n                                                  max_num_labels_tns), reverse(label_shape, 0)))\n    batch_ind = tf.boolean_mask(batch_array, dense_mask)\n    indices = tf.transpose(tf.reshape(concatenate([batch_ind, label_ind], axis=0), [2, -1]))\n\n    vals_sparse = tf.gather_nd(labels, indices)\n\n    return tf.SparseTensor(tf.to_int64(indices), vals_sparse, tf.to_int64(label_shape))",
                "def ctc_batch_cost(y_true, y_pred, input_length, label_length):\n    \"\"\"Runs CTC loss algorithm on each batch element.\n\n    # Arguments\n        y_true: tensor `(samples, max_string_length)`\n            containing the truth labels.\n        y_pred: tensor `(samples, time_steps, num_categories)`\n            containing the prediction, or output of the softmax.\n        input_length: tensor `(samples, 1)` containing the sequence length for\n            each batch item in `y_pred`.\n        label_length: tensor `(samples, 1)` containing the sequence length for\n            each batch item in `y_true`.\n\n    # Returns\n        Tensor with shape (samples,1) containing the\n            CTC loss of each element.\n    \"\"\"\n    label_length = tf.to_int32(tf.squeeze(label_length, axis=-1))\n    input_length = tf.to_int32(tf.squeeze(input_length, axis=-1))\n    sparse_labels = tf.to_int32(ctc_label_dense_to_sparse(y_true, label_length))\n\n    y_pred = tf.log(tf.transpose(y_pred, perm=[1, 0, 2]) + epsilon())\n\n    return tf.expand_dims(ctc.ctc_loss(inputs=y_pred,\n                                       labels=sparse_labels,\n                                       sequence_length=input_length), 1)",
                "def ctc_decode(y_pred, input_length, greedy=True, beam_width=100,\n               top_paths=1):\n    \"\"\"Decodes the output of a softmax.\n\n    Can use either greedy search (also known as best path)\n    or a constrained dictionary search.\n\n    # Arguments\n        y_pred: tensor `(samples, time_steps, num_categories)`\n            containing the prediction, or output of the softmax.\n        input_length: tensor `(samples, )` containing the sequence length for\n            each batch item in `y_pred`.\n        greedy: perform much faster best-path search if `true`.\n            This does not use a dictionary.\n        beam_width: if `greedy` is `false`: a beam search decoder will be used\n            with a beam of this width.\n        top_paths: if `greedy` is `false`,\n            how many of the most probable paths will be returned.\n\n    # Returns\n        Tuple:\n            List: if `greedy` is `true`, returns a list of one element that\n                contains the decoded sequence.\n                If `false`, returns the `top_paths` most probable\n                decoded sequences.\n                Important: blank labels are returned as `-1`.\n            Tensor `(top_paths, )` that contains\n                the log probability of each decoded sequence.\n    \"\"\"\n    y_pred = tf.log(tf.transpose(y_pred, perm=[1, 0, 2]) + epsilon())\n    input_length = tf.to_int32(input_length)\n\n    if greedy:\n        (decoded, log_prob) = ctc.ctc_greedy_decoder(\n            inputs=y_pred,\n            sequence_length=input_length)\n    else:\n        (decoded, log_prob) = ctc.ctc_beam_search_decoder(\n            inputs=y_pred,\n            sequence_length=input_length, beam_width=beam_width,\n            top_paths=top_paths)\n\n    decoded_dense = [tf.sparse_to_dense(st.indices, st.dense_shape, st.values, default_value=-1)\n                     for st in decoded]\n    return (decoded_dense, log_prob)",
                "def map_fn(fn, elems, name=None, dtype=None):\n    \"\"\"Map the function fn over the elements elems and return the outputs.\n\n    # Arguments\n        fn: Callable that will be called upon each element in elems\n        elems: tensor\n        name: A string name for the map node in the graph\n        dtype: Output data type.\n\n    # Returns\n        Tensor with dtype `dtype`.\n    \"\"\"\n    return tf.map_fn(fn, elems, name=name, dtype=dtype)",
                "def foldl(fn, elems, initializer=None, name=None):\n    \"\"\"Reduce elems using fn to combine them from left to right.\n\n    # Arguments\n        fn: Callable that will be called upon each element in elems and an\n            accumulator, for instance `lambda acc, x: acc + x`\n        elems: tensor\n        initializer: The first value used (`elems[0]` in case of None)\n        name: A string name for the foldl node in the graph\n\n    # Returns\n        Tensor with same type and shape as `initializer`.\n    \"\"\"\n    return tf.foldl(fn, elems, initializer=initializer, name=name)",
                "def foldr(fn, elems, initializer=None, name=None):\n    \"\"\"Reduce elems using fn to combine them from right to left.\n\n    # Arguments\n        fn: Callable that will be called upon each element in elems and an\n            accumulator, for instance `lambda acc, x: acc + x`\n        elems: tensor\n        initializer: The first value used (`elems[-1]` in case of None)\n        name: A string name for the foldr node in the graph\n\n    # Returns\n        Tensor with same type and shape as `initializer`.\n    \"\"\"\n    return tf.foldr(fn, elems, initializer=initializer, name=name)",
                "def local_conv1d(inputs, kernel, kernel_size, strides, data_format=None):\n    \"\"\"Apply 1D conv with un-shared weights.\n\n    # Arguments\n        inputs: 3D tensor with shape: (batch_size, steps, input_dim)\n        kernel: the unshared weight for convolution,\n                with shape (output_length, feature_dim, filters)\n        kernel_size: a tuple of a single integer,\n                     specifying the length of the 1D convolution window\n        strides: a tuple of a single integer,\n                 specifying the stride length of the convolution\n        data_format: the data format, channels_first or channels_last\n\n    # Returns\n        the tensor after 1d conv with un-shared weights, with shape (batch_size, output_length, filters)\n\n    # Raises\n        ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format: ' + str(data_format))\n\n    stride = strides[0]\n    kernel_shape = int_shape(kernel)\n    output_length, feature_dim, filters = kernel_shape\n\n    xs = []\n    for i in range(output_length):\n        slice_length = slice(i * stride,\n                             i * stride + kernel_size[0])\n        xs.append(reshape(inputs[:, slice_length, :],\n                          (1, -1, feature_dim)))\n    x_aggregate = concatenate(xs, axis=0)\n    # Shape: `(output_length, batch_size, filters)`.\n    output = batch_dot(x_aggregate, kernel)\n    return permute_dimensions(output, (1, 0, 2))",
                "def local_conv2d(inputs, kernel, kernel_size, strides, output_shape, data_format=None):\n    \"\"\"Apply 2D conv with un-shared weights.\n\n    # Arguments\n        inputs: 4D tensor with shape:\n                (batch_size, filters, new_rows, new_cols)\n                if data_format='channels_first'\n                or 4D tensor with shape:\n                (batch_size, new_rows, new_cols, filters)\n                if data_format='channels_last'.\n        kernel: the unshared weight for convolution,\n                with shape (output_items, feature_dim, filters)\n        kernel_size: a tuple of 2 integers, specifying the\n                     width and height of the 2D convolution window.\n        strides: a tuple of 2 integers, specifying the strides\n                 of the convolution along the width and height.\n        output_shape: a tuple with (output_row, output_col)\n        data_format: the data format, channels_first or channels_last\n\n    # Returns\n        A 4d tensor with shape:\n        (batch_size, filters, new_rows, new_cols)\n        if data_format='channels_first'\n        or 4D tensor with shape:\n        (batch_size, new_rows, new_cols, filters)\n        if data_format='channels_last'.\n\n    # Raises\n        ValueError: if `data_format` is neither\n                    `channels_last` or `channels_first`.\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format: ' + str(data_format))\n\n    stride_row, stride_col = strides\n    output_row, output_col = output_shape\n    kernel_shape = int_shape(kernel)\n    _, feature_dim, filters = kernel_shape\n\n    xs = []\n    for i in range(output_row):\n        for j in range(output_col):\n            slice_row = slice(i * stride_row,\n                              i * stride_row + kernel_size[0])\n            slice_col = slice(j * stride_col,\n                              j * stride_col + kernel_size[1])\n            if data_format == 'channels_first':\n                xs.append(reshape(inputs[:, :, slice_row, slice_col],\n                                  (1, -1, feature_dim)))\n            else:\n                xs.append(reshape(inputs[:, slice_row, slice_col, :],\n                                  (1, -1, feature_dim)))\n\n    x_aggregate = concatenate(xs, axis=0)\n    output = batch_dot(x_aggregate, kernel)\n    output = reshape(output,\n                     (output_row, output_col, -1, filters))\n\n    if data_format == 'channels_first':\n        output = permute_dimensions(output, (2, 3, 0, 1))\n    else:\n        output = permute_dimensions(output, (2, 0, 1, 3))\n    return output",
                "def __init__(self):\n    self.device = None",
                "def _set_device(self, device):\n    \"\"\"This method captures TF's explicit device scope setting.\"\"\"\n    self.device = device",
                "def __init__(self, inputs, outputs,\n             updates=None,\n             name=None,\n             **session_kwargs):\n    updates = updates or []\n    if not isinstance(inputs, (list, tuple)):\n        raise TypeError('`inputs` to a TensorFlow backend function '\n                        'should be a list or tuple.')\n    if not isinstance(outputs, (list, tuple)):\n        raise TypeError('`outputs` of a TensorFlow backend function '\n                        'should be a list or tuple.')\n    if not isinstance(updates, (list, tuple)):\n        raise TypeError('`updates` in a TensorFlow backend function '\n                        'should be a list or tuple.')\n    self.inputs = list(inputs)\n    self.outputs = list(outputs)\n    with tf.control_dependencies(self.outputs):\n        updates_ops = []\n        for update in updates:\n            if isinstance(update, tuple):\n                p, new_p = update\n                updates_ops.append(tf.assign(p, new_p))\n            else:\n                # assumed already an op\n                updates_ops.append(update)\n        self.updates_op = tf.group(*updates_ops)\n    self.name = name\n    # additional tensor substitutions\n    self.feed_dict = session_kwargs.pop('feed_dict', {})\n    # additional operations\n    self.fetches = session_kwargs.pop('fetches', [])\n    if not isinstance(self.fetches, list):\n        self.fetches = [self.fetches]\n    # The main use case of `fetches` being passed to a model is the ability\n    # to run custom updates\n    # (since the outputs of fetches are never returned).\n    # This requires us to wrap fetches in `identity` ops.\n    self.fetches = [tf.identity(x) for x in self.fetches]\n    self.session_kwargs = session_kwargs\n    if session_kwargs:\n        raise ValueError('Some keys in session_kwargs are not '\n                         'supported at this '\n                         'time: %s', session_kwargs.keys())\n    self._callable_fn = None\n    self._feed_arrays = None\n    self._feed_symbols = None\n    self._symbol_vals = None\n    self._session = None",
                "def _make_callable(self, feed_arrays, feed_symbols, symbol_vals, session):\n    \"\"\"Generates a callable that runs the graph.\n\n    # Arguments\n        feed_arrays: List of input tensors to be fed\n            Numpy arrays at runtime.\n        feed_symbols: List of input tensors to be fed\n            symbolic tensors at runtime.\n        symbol_vals: List of symbolic tensors to be fed to `feed_symbols`.\n        session: Session to use to generate the callable.\n\n    # Returns\n        Function that runs the graph according to the above options.\n    \"\"\"\n    # Prepare callable options.\n    callable_opts = config_pb2.CallableOptions()\n    # Handle external-data feed.\n    for x in feed_arrays:\n        callable_opts.feed.append(x.name)\n    if self.feed_dict:\n        for key in sorted(self.feed_dict.keys()):\n            callable_opts.feed.append(key.name)\n    # Handle symbolic feed.\n    for x, y in zip(feed_symbols, symbol_vals):\n        connection = callable_opts.tensor_connection.add()\n        if x.dtype != y.dtype:\n            y = tf.cast(y, dtype=x.dtype)\n        from_tensor = tf_ops._as_graph_element(y)\n        if from_tensor is None:\n            from_tensor = y\n        connection.from_tensor = from_tensor.name  # Data tensor\n        connection.to_tensor = x.name  # Placeholder\n    # Handle fetches.\n    for x in self.outputs + self.fetches:\n        callable_opts.fetch.append(x.name)\n    # Handle updates.\n    callable_opts.target.append(self.updates_op.name)\n    # Create callable.\n    callable_fn = session._make_callable_from_options(callable_opts)\n    # Cache parameters corresponding to the generated callable, so that\n    # we can detect future mismatches and refresh the callable.\n    self._callable_fn = callable_fn\n    self._feed_arrays = feed_arrays\n    self._feed_symbols = feed_symbols\n    self._symbol_vals = symbol_vals\n    self._session = session",
                "def _call(self, inputs):\n    if not isinstance(inputs, (list, tuple)):\n        raise TypeError('`inputs` should be a list or tuple.')\n\n    session = get_session()\n    feed_arrays = []\n    array_vals = []\n    feed_symbols = []\n    symbol_vals = []\n    for tensor, value in zip(self.inputs, inputs):\n        if value is None:\n            continue\n        if is_tensor(value):\n            # Case: feeding symbolic tensor.\n            feed_symbols.append(tensor)\n            symbol_vals.append(value)\n        else:\n            feed_arrays.append(tensor)\n            # We need to do array conversion and type casting\n            # at this level, since\n            # `callable_fn` only supports exact matches.\n            array_vals.append(\n                np.asarray(value,\n                           dtype=tensor.dtype.base_dtype.name))\n    if self.feed_dict:\n        for key in sorted(self.feed_dict.keys()):\n            array_vals.append(\n                np.asarray(self.feed_dict[key],\n                           dtype=key.dtype.base_dtype.name))\n\n    # Refresh callable if anything has changed.\n    if (self._callable_fn is None or\n            feed_arrays != self._feed_arrays or\n            symbol_vals != self._symbol_vals or\n            feed_symbols != self._feed_symbols or\n            session != self._session):\n        self._make_callable(feed_arrays,\n                            feed_symbols,\n                            symbol_vals,\n                            session)\n    fetched = self._callable_fn(*array_vals)\n    return fetched[:len(self.outputs)]",
                "def _legacy_call(self, inputs):\n    if not isinstance(inputs, (list, tuple)):\n        raise TypeError('`inputs` should be a list or tuple.')\n    feed_dict = self.feed_dict.copy()\n    for tensor, value in zip(self.inputs, inputs):\n        if is_sparse(tensor):\n            sparse_coo = value.tocoo()\n            indices = np.concatenate(\n                (np.expand_dims(sparse_coo.row, 1),\n                 np.expand_dims(sparse_coo.col, 1)), 1)\n            value = (indices, sparse_coo.data, sparse_coo.shape)\n        feed_dict[tensor] = value\n    fetches = self.outputs + [self.updates_op] + self.fetches\n    session = get_session()\n    updated = session.run(fetches=fetches, feed_dict=feed_dict,\n                          **self.session_kwargs)\n    return updated[:len(self.outputs)]",
                "def __call__(self, inputs):\n    if hasattr(get_session(), '_make_callable_from_options'):\n        if py_any(is_sparse(x) for x in self.inputs):\n            if py_any(is_tensor(x) for x in inputs):\n                raise ValueError(\n                    'Feeding from symbolic tensors is not '\n                    'supported with sparse inputs.')\n            return self._legacy_call(inputs)\n\n        return self._call(inputs)\n    else:\n        if py_any(is_tensor(x) for x in inputs):\n            raise ValueError(\n                'In order to feed symbolic tensors to a Keras model '\n                'in TensorFlow, you need tensorflow 1.8 or higher.')\n        return self._legacy_call(inputs)",
                "def range_less_than(_, current_input):\n    return tf.expand_dims(tf.range(label_shape[1]), 0) < tf.fill(\n        max_num_labels_tns, current_input)",
                "def _step(time, output_ta_t, *states):\n    \"\"\"RNN step function.\n\n    # Arguments\n        time: Current timestep value.\n        output_ta_t: TensorArray.\n        *states: List of states.\n\n    # Returns\n        Tuple: `(time + 1,output_ta_t) + tuple(new_states)`\n    \"\"\"\n    current_input = input_ta.read(time)\n    mask_t = mask_ta.read(time)\n    output, new_states = step_function(current_input,\n                                       tuple(states) +\n                                       tuple(constants))\n    if getattr(output, '_uses_learning_phase', False):\n        global uses_learning_phase\n        uses_learning_phase = True\n    for state, new_state in zip(states, new_states):\n        new_state.set_shape(state.get_shape())\n    tiled_mask_t = tf.tile(mask_t,\n                           tf.stack([1, tf.shape(output)[1]]))\n    output = tf.where(tiled_mask_t, output, states[0])\n    new_states = [tf.where(tiled_mask_t, new_states[i], states[i]) for i in range(len(states))]\n    output_ta_t = output_ta_t.write(time, output)\n    return (time + 1, output_ta_t) + tuple(new_states)",
                "def _step(time, output_ta_t, *states):\n    \"\"\"RNN step function.\n\n    # Arguments\n        time: Current timestep value.\n        output_ta_t: TensorArray.\n        *states: List of states.\n\n    # Returns\n        Tuple: `(time + 1,output_ta_t) + tuple(new_states)`\n    \"\"\"\n    current_input = input_ta.read(time)\n    output, new_states = step_function(current_input,\n                                       tuple(states) +\n                                       tuple(constants))\n    if getattr(output, '_uses_learning_phase', False):\n        global uses_learning_phase\n        uses_learning_phase = True\n    for state, new_state in zip(states, new_states):\n        new_state.set_shape(state.get_shape())\n    output_ta_t = output_ta_t.write(time, output)\n    return (time + 1, output_ta_t) + tuple(new_states)",
                "def then_expression_fn():\n    return then_expression",
                "def else_expression_fn():\n    return else_expression"
            ],
            "inscope_function_signatures": [
                "get_uid(prefix='')",
                "reset_uids()",
                "clear_session()",
                "manual_variable_initialization(value)",
                "learning_phase()",
                "set_learning_phase(value)",
                "get_session()",
                "set_session(session)",
                "_get_current_tf_device()",
                "_is_current_explicit_device(device_type)",
                "_get_available_gpus()",
                "_has_nchw_support()",
                "_to_tensor(x, dtype)",
                "is_sparse(tensor)",
                "to_dense(tensor)",
                "variable(value, dtype=None, name=None, constraint=None)",
                "constant(value, dtype=None, shape=None, name=None)",
                "is_keras_tensor(x)",
                "is_tensor(x)",
                "placeholder(shape=None, ndim=None, dtype=None, sparse=False, name=None)",
                "is_placeholder(x)",
                "shape(x)",
                "int_shape(x)",
                "ndim(x)",
                "dtype(x)",
                "eval(x)",
                "zeros(shape, dtype=None, name=None)",
                "ones(shape, dtype=None, name=None)",
                "eye(size, dtype=None, name=None)",
                "zeros_like(x, dtype=None, name=None)",
                "ones_like(x, dtype=None, name=None)",
                "identity(x, name=None)",
                "random_uniform_variable(shape, low, high, dtype=None, name=None, seed=None)",
                "random_normal_variable(shape, mean, scale, dtype=None, name=None, seed=None)",
                "count_params(x)",
                "cast(x, dtype)",
                "update(x, new_x)",
                "update_add(x, increment)",
                "update_sub(x, decrement)",
                "moving_average_update(x, value, momentum)",
                "dot(x, y)",
                "batch_dot(x, y, axes=None)",
                "transpose(x)",
                "gather(reference, indices)",
                "max(x, axis=None, keepdims=False)",
                "min(x, axis=None, keepdims=False)",
                "sum(x, axis=None, keepdims=False)",
                "prod(x, axis=None, keepdims=False)",
                "cumsum(x, axis=0)",
                "cumprod(x, axis=0)",
                "var(x, axis=None, keepdims=False)",
                "std(x, axis=None, keepdims=False)",
                "mean(x, axis=None, keepdims=False)",
                "any(x, axis=None, keepdims=False)",
                "all(x, axis=None, keepdims=False)",
                "argmax(x, axis=-1)",
                "argmin(x, axis=-1)",
                "square(x)",
                "abs(x)",
                "sqrt(x)",
                "exp(x)",
                "log(x)",
                "logsumexp(x, axis=None, keepdims=False)",
                "round(x)",
                "sign(x)",
                "pow(x, a)",
                "clip(x, min_value, max_value)",
                "equal(x, y)",
                "not_equal(x, y)",
                "greater(x, y)",
                "greater_equal(x, y)",
                "less(x, y)",
                "less_equal(x, y)",
                "maximum(x, y)",
                "minimum(x, y)",
                "sin(x)",
                "cos(x)",
                "_regular_normalize_batch_in_training(x, gamma, beta, reduction_axes, epsilon=0.001)",
                "_broadcast_normalize_batch_in_training(x, gamma, beta, reduction_axes, epsilon=0.001)",
                "_fused_normalize_batch_in_training(x, gamma, beta, reduction_axes, epsilon=0.001)",
                "normalize_batch_in_training(x, gamma, beta, reduction_axes, epsilon=0.001)",
                "batch_normalization(x, mean, var, beta, gamma, epsilon=0.001)",
                "concatenate(tensors, axis=-1)",
                "reshape(x, shape)",
                "permute_dimensions(x, pattern)",
                "resize_images(x, height_factor, width_factor, data_format)",
                "resize_volumes(x, depth_factor, height_factor, width_factor, data_format)",
                "repeat_elements(x, rep, axis)",
                "repeat(x, n)",
                "arange(start, stop=None, step=1, dtype='int32')",
                "tile(x, n)",
                "flatten(x)",
                "batch_flatten(x)",
                "expand_dims(x, axis=-1)",
                "squeeze(x, axis)",
                "temporal_padding(x, padding=(1, 1))",
                "spatial_2d_padding(x, padding=((1, 1), (1, 1)), data_format=None)",
                "spatial_3d_padding(x, padding=((1, 1), (1, 1), (1, 1)), data_format=None)",
                "stack(x, axis=0)",
                "one_hot(indices, num_classes)",
                "reverse(x, axes)",
                "get_value(x)",
                "batch_get_value(ops)",
                "set_value(x, value)",
                "batch_set_value(tuples)",
                "get_variable_shape(x)",
                "print_tensor(x, message='')",
                "function(inputs, outputs, updates=None, **kwargs)",
                "gradients(loss, variables)",
                "stop_gradient(variables)",
                "rnn(step_function, inputs, initial_states, go_backwards=False, mask=None, constants=None, unroll=False, input_length=None)",
                "switch(condition, then_expression, else_expression)",
                "in_train_phase(x, alt, training=None)",
                "in_test_phase(x, alt, training=None)",
                "relu(x, alpha=0.0, max_value=None)",
                "elu(x, alpha=1.0)",
                "softmax(x, axis=-1)",
                "softplus(x)",
                "softsign(x)",
                "categorical_crossentropy(target, output, from_logits=False)",
                "sparse_categorical_crossentropy(target, output, from_logits=False)",
                "binary_crossentropy(target, output, from_logits=False)",
                "sigmoid(x)",
                "hard_sigmoid(x)",
                "tanh(x)",
                "dropout(x, level, noise_shape=None, seed=None)",
                "l2_normalize(x, axis=None)",
                "in_top_k(predictions, targets, k)",
                "_preprocess_conv1d_input(x, data_format)",
                "_preprocess_conv2d_input(x, data_format)",
                "_preprocess_conv3d_input(x, data_format)",
                "_preprocess_padding(padding)",
                "conv1d(x, kernel, strides=1, padding='valid', data_format=None, dilation_rate=1)",
                "conv2d(x, kernel, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1))",
                "conv2d_transpose(x, kernel, output_shape, strides=(1, 1), padding='valid', data_format=None)",
                "separable_conv1d(x, depthwise_kernel, pointwise_kernel, strides=1, padding='valid', data_format=None, dilation_rate=1)",
                "separable_conv2d(x, depthwise_kernel, pointwise_kernel, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1))",
                "depthwise_conv2d(x, depthwise_kernel, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1))",
                "conv3d(x, kernel, strides=(1, 1, 1), padding='valid', data_format=None, dilation_rate=(1, 1, 1))",
                "conv3d_transpose(x, kernel, output_shape, strides=(1, 1, 1), padding='valid', data_format=None)",
                "pool2d(x, pool_size, strides=(1, 1), padding='valid', data_format=None, pool_mode='max')",
                "pool3d(x, pool_size, strides=(1, 1, 1), padding='valid', data_format=None, pool_mode='max')",
                "bias_add(x, bias, data_format=None)",
                "random_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None)",
                "random_uniform(shape, minval=0.0, maxval=1.0, dtype=None, seed=None)",
                "random_binomial(shape, p=0.0, dtype=None, seed=None)",
                "truncated_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None)",
                "ctc_label_dense_to_sparse(labels, label_lengths)",
                "ctc_batch_cost(y_true, y_pred, input_length, label_length)",
                "ctc_decode(y_pred, input_length, greedy=True, beam_width=100, top_paths=1)",
                "map_fn(fn, elems, name=None, dtype=None)",
                "foldl(fn, elems, initializer=None, name=None)",
                "foldr(fn, elems, initializer=None, name=None)",
                "local_conv1d(inputs, kernel, kernel_size, strides, data_format=None)",
                "local_conv2d(inputs, kernel, kernel_size, strides, output_shape, data_format=None)",
                "__init__(self)",
                "_set_device(self, device)",
                "__init__(self, inputs, outputs, updates=None, name=None, **session_kwargs)",
                "_make_callable(self, feed_arrays, feed_symbols, symbol_vals, session)",
                "_call(self, inputs)",
                "_legacy_call(self, inputs)",
                "__call__(self, inputs)",
                "range_less_than(_, current_input)",
                "_step(time, output_ta_t, *states)",
                "_step(time, output_ta_t, *states)",
                "then_expression_fn()",
                "else_expression_fn()"
            ],
            "variables_in_file": {
                "py_all": [
                    1891,
                    699,
                    28,
                    731
                ],
                "all": [
                    28
                ],
                "py_any": [
                    2605,
                    2606,
                    2614,
                    1143,
                    29
                ],
                "any": [
                    29
                ],
                "py_sum": [
                    30
                ],
                "sum": [
                    30
                ],
                "_SESSION": [
                    36,
                    175,
                    182,
                    183,
                    217,
                    93
                ],
                "_GRAPH_LEARNING_PHASES": [
                    128,
                    97,
                    98,
                    132,
                    133,
                    41,
                    149
                ],
                "_GRAPH_UID_DICTS": [
                    71,
                    72,
                    73,
                    74,
                    47,
                    81
                ],
                "_MANUAL_VAR_INIT": [
                    184,
                    114,
                    52
                ],
                "_LOCAL_DEVICES": [
                    57,
                    274,
                    275,
                    273
                ],
                "graph": [
                    128,
                    132,
                    133,
                    70,
                    71,
                    72,
                    73,
                    74,
                    127
                ],
                "tf.get_default_graph": [
                    98,
                    70,
                    241,
                    149,
                    127
                ],
                "tf": [
                    513,
                    2055,
                    2056,
                    2057,
                    1546,
                    3080,
                    3084,
                    1559,
                    3098,
                    4123,
                    4124,
                    3618,
                    1059,
                    3110,
                    2087,
                    2088,
                    3624,
                    1066,
                    1579,
                    2091,
                    4136,
                    562,
                    1074,
                    1075,
                    1076,
                    3122,
                    1079,
                    1592,
                    1081,
                    4155,
                    2110,
                    1605,
                    70,
                    3143,
                    2122,
                    3659,
                    3148,
                    3149,
                    2638,
                    4171,
                    3152,
                    3665,
                    1618,
                    3578,
                    4087,
                    2136,
                    91,
                    4187,
                    4089,
                    94,
                    1631,
                    2654,
                    98,
                    2150,
                    3174,
                    3175,
                    3179,
                    1644,
                    2669,
                    3180,
                    2671,
                    3696,
                    3186,
                    2163,
                    3704,
                    1657,
                    1149,
                    127,
                    1152,
                    129,
                    3994,
                    2179,
                    1157,
                    1670,
                    1159,
                    3209,
                    3210,
                    3212,
                    1167,
                    1683,
                    149,
                    1173,
                    3733,
                    3225,
                    1695,
                    3744,
                    3745,
                    2213,
                    3753,
                    170,
                    1707,
                    2732,
                    3244,
                    3757,
                    2735,
                    2736,
                    177,
                    3800,
                    2739,
                    180,
                    182,
                    697,
                    186,
                    698,
                    1211,
                    1725,
                    3257,
                    1727,
                    195,
                    2755,
                    1224,
                    2760,
                    202,
                    3279,
                    1748,
                    3796,
                    2264,
                    729,
                    730,
                    1755,
                    1244,
                    1756,
                    1758,
                    1759,
                    2779,
                    2780,
                    3292,
                    1763,
                    2787,
                    2277,
                    3807,
                    1767,
                    2792,
                    1769,
                    2793,
                    2794,
                    3308,
                    1261,
                    241,
                    2802,
                    2292,
                    760,
                    761,
                    2812,
                    3325,
                    1278,
                    3329,
                    2308,
                    2820,
                    3845,
                    3849,
                    1802,
                    1806,
                    1295,
                    2831,
                    3856,
                    786,
                    1810,
                    3346,
                    3350,
                    1308,
                    2845,
                    3367,
                    1321,
                    811,
                    3371,
                    2350,
                    304,
                    2355,
                    2871,
                    824,
                    2872,
                    1338,
                    1339,
                    1340,
                    1341,
                    1342,
                    2873,
                    2874,
                    3901,
                    3909,
                    2374,
                    327,
                    2379,
                    1869,
                    1361,
                    3925,
                    855,
                    859,
                    351,
                    1378,
                    1379,
                    356,
                    1380,
                    1892,
                    1894,
                    2915,
                    3432,
                    3949,
                    1394,
                    1395,
                    1907,
                    2420,
                    2937,
                    2938,
                    892,
                    896,
                    1409,
                    1410,
                    1921,
                    3972,
                    2951,
                    392,
                    398,
                    1423,
                    3470,
                    1941,
                    1942,
                    3479,
                    1944,
                    3992,
                    3993,
                    2971,
                    1436,
                    2972,
                    2462,
                    1951,
                    1952,
                    1953,
                    2973,
                    2467,
                    2975,
                    2976,
                    2977,
                    2471,
                    1448,
                    426,
                    2483,
                    1460,
                    3508,
                    4019,
                    953,
                    3518,
                    3519,
                    1474,
                    1475,
                    3527,
                    4039,
                    969,
                    4040,
                    3531,
                    4041,
                    4044,
                    1487,
                    4047,
                    4052,
                    982,
                    4054,
                    4056,
                    2009,
                    2521,
                    1499,
                    4058,
                    4059,
                    4061,
                    4063,
                    995,
                    2021,
                    2022,
                    2025,
                    2030,
                    3567,
                    1520,
                    2032,
                    3568,
                    3569,
                    3060,
                    3572,
                    3062,
                    4083,
                    4084,
                    4085,
                    3066,
                    3581,
                    1534,
                    511
                ],
                "defaultdict": [
                    72
                ],
                "int": [
                    2306,
                    72,
                    3179,
                    1136,
                    179,
                    2108
                ],
                "prefix": [
                    73,
                    74
                ],
                "tf.reset_default_graph": [
                    91
                ],
                "reset_uids": [
                    92
                ],
                "phase": [
                    129,
                    98,
                    132,
                    94
                ],
                "tf.placeholder_with_default": [
                    129,
                    94
                ],
                "value": [
                    896,
                    898,
                    388,
                    389,
                    2564,
                    398,
                    399,
                    400,
                    401,
                    146,
                    402,
                    149,
                    2589,
                    2591,
                    2595,
                    2596,
                    426,
                    2349,
                    2355,
                    2359,
                    2372,
                    2373,
                    2380,
                    2385,
                    859,
                    861,
                    114,
                    1010,
                    2551,
                    2552,
                    2554,
                    2557
                ],
                "ValueError": [
                    261,
                    3465,
                    3853,
                    147,
                    2835,
                    2964,
                    3731,
                    3609,
                    2202,
                    1958,
                    2727,
                    4264,
                    3881,
                    3884,
                    2607,
                    3506,
                    2486,
                    2615,
                    2749,
                    3394,
                    3650,
                    1988,
                    2246,
                    3784,
                    590,
                    2640,
                    469,
                    3419,
                    3804,
                    3557,
                    3692,
                    4212,
                    1144,
                    3833
                ],
                "default_session": [
                    170,
                    172,
                    173
                ],
                "tf.get_default_session": [
                    170
                ],
                "session": [
                    194,
                    217,
                    2533,
                    2598,
                    2599,
                    202,
                    2540,
                    173,
                    205,
                    206,
                    207,
                    2577,
                    2546,
                    2581,
                    183,
                    185
                ],
                "os.environ.get": [
                    176,
                    179
                ],
                "os.environ": [
                    176,
                    179
                ],
                "os": [
                    176,
                    179
                ],
                "config": [
                    177,
                    180,
                    182
                ],
                "tf.ConfigProto": [
                    177,
                    180
                ],
                "num_thread": [
                    179,
                    180
                ],
                "tf.Session": [
                    2638,
                    182
                ],
                "session.graph.as_default": [
                    185
                ],
                "session.graph": [
                    185
                ],
                "variables": [
                    2668,
                    2669,
                    2671,
                    186,
                    188,
                    2654
                ],
                "tf.global_variables": [
                    186
                ],
                "candidate_vars": [
                    195,
                    197,
                    187,
                    190,
                    191
                ],
                "v": [
                    392,
                    395,
                    396,
                    397,
                    398,
                    400,
                    402,
                    403,
                    406,
                    408,
                    409,
                    698,
                    699,
                    188,
                    189,
                    190,
                    700,
                    701,
                    195,
                    197,
                    199,
                    200,
                    730,
                    731,
                    732,
                    733
                ],
                "getattr": [
                    2893,
                    2766,
                    2866,
                    2806,
                    189
                ],
                "candidate_vars.append": [
                    190
                ],
                "is_initialized": [
                    194,
                    197
                ],
                "session.run": [
                    202,
                    194,
                    2599
                ],
                "tf.is_variable_initialized": [
                    195
                ],
                "uninitialized_vars": [
                    201,
                    202,
                    196,
                    199
                ],
                "flag": [
                    197,
                    198
                ],
                "zip": [
                    1059,
                    197,
                    2790,
                    1066,
                    2764,
                    2896,
                    2869,
                    2518,
                    2551,
                    2589
                ],
                "uninitialized_vars.append": [
                    199
                ],
                "v._keras_initialized": [
                    200
                ],
                "tf.variables_initializer": [
                    202
                ],
                "hasattr": [
                    388,
                    2375,
                    586,
                    2604,
                    205,
                    2351,
                    401,
                    472
                ],
                "session.list_devices": [
                    206
                ],
                "device_lib.list_local_devices": [
                    206
                ],
                "device_lib": [
                    206
                ],
                "object": [
                    2425,
                    222
                ],
                "self.device": [
                    226,
                    230
                ],
                "self": [
                    2566,
                    2567,
                    2569,
                    2573,
                    2574,
                    2575,
                    2576,
                    2577,
                    2578,
                    2582,
                    2583,
                    2460,
                    2461,
                    2462,
                    2588,
                    2589,
                    2597,
                    2471,
                    2472,
                    2600,
                    2474,
                    2601,
                    2476,
                    2477,
                    2478,
                    2605,
                    2610,
                    2483,
                    2484,
                    2612,
                    2489,
                    2490,
                    2491,
                    2492,
                    2493,
                    2618,
                    2514,
                    2515,
                    2528,
                    226,
                    2531,
                    230,
                    2536,
                    2537,
                    2538,
                    2539,
                    2540,
                    2551
                ],
                "device": [
                    263,
                    230,
                    262
                ],
                "g": [
                    241,
                    243
                ],
                "op": [
                    242,
                    243,
                    244
                ],
                "_TfDeviceCaptureOp": [
                    242
                ],
                "g._apply_device_functions": [
                    243
                ],
                "op.device": [
                    244
                ],
                "device_type": [
                    259,
                    260,
                    263
                ],
                "device_type.upper": [
                    259,
                    263
                ],
                "_get_current_tf_device": [
                    262
                ],
                "device.device_type": [
                    263
                ],
                "list_devices": [
                    274
                ],
                "get_session": [
                    2336,
                    2598,
                    2604,
                    274,
                    2323,
                    2386,
                    2546,
                    2359,
                    669
                ],
                "x.name": [
                    2513,
                    275,
                    2529,
                    2526
                ],
                "x": [
                    513,
                    514,
                    515,
                    516,
                    2054,
                    2055,
                    3080,
                    2057,
                    1546,
                    3084,
                    529,
                    1559,
                    3098,
                    3611,
                    1057,
                    3618,
                    1059,
                    3110,
                    3624,
                    1577,
                    1578,
                    1579,
                    3625,
                    2605,
                    2606,
                    562,
                    1074,
                    3122,
                    1078,
                    1079,
                    1592,
                    1081,
                    2614,
                    2110,
                    3371,
                    3652,
                    1605,
                    586,
                    587,
                    2122,
                    589,
                    3659,
                    3374,
                    3665,
                    1618,
                    3578,
                    3666,
                    3883,
                    2136,
                    2137,
                    3885,
                    1631,
                    3886,
                    3480,
                    2150,
                    615,
                    3583,
                    1644,
                    3694,
                    3889,
                    3696,
                    3697,
                    1138,
                    2163,
                    3704,
                    1657,
                    3705,
                    3891,
                    1152,
                    1155,
                    2179,
                    1157,
                    1670,
                    1159,
                    648,
                    1162,
                    1167,
                    1683,
                    3735,
                    3225,
                    669,
                    1695,
                    3744,
                    2213,
                    3241,
                    3242,
                    1707,
                    3243,
                    3244,
                    3245,
                    3753,
                    3757,
                    3758,
                    3257,
                    1211,
                    1725,
                    1727,
                    3786,
                    3279,
                    1748,
                    3796,
                    1751,
                    2264,
                    3800,
                    1755,
                    1244,
                    3292,
                    3807,
                    3808,
                    2277,
                    1770,
                    1261,
                    3835,
                    3324,
                    3325,
                    1278,
                    3329,
                    2308,
                    3332,
                    3845,
                    3849,
                    1803,
                    1804,
                    1295,
                    1807,
                    1808,
                    786,
                    275,
                    1811,
                    2323,
                    3345,
                    3346,
                    3350,
                    3353,
                    3857,
                    1308,
                    3366,
                    3367,
                    1321,
                    1833,
                    811,
                    1835,
                    2349,
                    2350,
                    1839,
                    304,
                    2351,
                    1842,
                    1843,
                    2352,
                    2353,
                    2356,
                    1847,
                    824,
                    2357,
                    1338,
                    1339,
                    1340,
                    1341,
                    2358,
                    3894,
                    3896,
                    3897,
                    3901,
                    3904,
                    2372,
                    2373,
                    2374,
                    2375,
                    2376,
                    2377,
                    3906,
                    3909,
                    3912,
                    1869,
                    2381,
                    2382,
                    2383,
                    1361,
                    3913,
                    3916,
                    3918,
                    3921,
                    3923,
                    3925,
                    3926,
                    2398,
                    3425,
                    1378,
                    1379,
                    1380,
                    1891,
                    1894,
                    3432,
                    3433,
                    3439,
                    1394,
                    1395,
                    1907,
                    2420,
                    1409,
                    1410,
                    1921,
                    2951,
                    3467,
                    3470,
                    1423,
                    3471,
                    1940,
                    1941,
                    1943,
                    1944,
                    921,
                    1945,
                    1946,
                    1436,
                    1948,
                    1950,
                    1951,
                    3479,
                    1953,
                    1954,
                    2977,
                    1956,
                    2978,
                    1448,
                    2483,
                    1460,
                    3510,
                    953,
                    1978,
                    3006,
                    1983,
                    1472,
                    1473,
                    1474,
                    1475,
                    3007,
                    3009,
                    3518,
                    3527,
                    969,
                    3018,
                    3531,
                    3020,
                    3021,
                    3532,
                    1487,
                    2512,
                    2513,
                    3856,
                    468,
                    2005,
                    470,
                    982,
                    472,
                    2009,
                    2518,
                    1499,
                    476,
                    2520,
                    2521,
                    2526,
                    2528,
                    2529,
                    3041,
                    995,
                    2021,
                    2022,
                    2023,
                    3559,
                    3567,
                    1520,
                    1010,
                    2035,
                    3060,
                    3572,
                    3062,
                    3065,
                    3066,
                    3067,
                    3581,
                    1534,
                    511
                ],
                "x.device_type": [
                    275
                ],
                "explicitly_on_cpu": [
                    289,
                    287
                ],
                "_is_current_explicit_device": [
                    287
                ],
                "gpus_available": [
                    288,
                    289
                ],
                "len": [
                    2177,
                    2196,
                    2197,
                    2198,
                    2583,
                    288,
                    2725,
                    2601,
                    3883,
                    3885,
                    3888,
                    2737,
                    3893,
                    2874,
                    3899,
                    2239,
                    2240,
                    2241,
                    2242,
                    3908,
                    3144,
                    3915,
                    3150,
                    3920,
                    2914,
                    2023,
                    617,
                    3183
                ],
                "_get_available_gpus": [
                    288
                ],
                "tf.convert_to_tensor": [
                    304
                ],
                "dtype": [
                    3968,
                    513,
                    386,
                    387,
                    898,
                    3969,
                    3973,
                    398,
                    3345,
                    786,
                    3988,
                    3989,
                    3992,
                    3993,
                    3994,
                    3366,
                    424,
                    425,
                    426,
                    811,
                    2092,
                    2093,
                    2349,
                    4015,
                    304,
                    4016,
                    4019,
                    695,
                    696,
                    697,
                    953,
                    4155,
                    700,
                    2373,
                    3324,
                    853,
                    854,
                    727,
                    728,
                    729,
                    855,
                    732,
                    861,
                    3945,
                    3946,
                    3950,
                    761,
                    758,
                    759,
                    760,
                    505,
                    506,
                    891,
                    892,
                    890,
                    511
                ],
                "isinstance": [
                    2465,
                    2306,
                    327,
                    2668,
                    2477,
                    2108,
                    399,
                    1136,
                    2543,
                    2451,
                    3507,
                    3732,
                    2454,
                    1143,
                    2457,
                    2586,
                    476
                ],
                "tensor": [
                    353,
                    2596,
                    2565,
                    327,
                    2590,
                    2559,
                    2551,
                    2556,
                    2589,
                    350,
                    351
                ],
                "tf.SparseTensor": [
                    392,
                    4063,
                    327
                ],
                "is_sparse": [
                    1891,
                    2590,
                    2605,
                    1078,
                    350
                ],
                "tf.sparse_tensor_to_dense": [
                    351
                ],
                "name_scope": [
                    356
                ],
                "tf.name_scope": [
                    356
                ],
                "floatx": [
                    3969,
                    387,
                    1379,
                    425,
                    3946,
                    728,
                    4016,
                    1339,
                    3989,
                    854,
                    759,
                    696,
                    506,
                    891
                ],
                "sparse_coo": [
                    2593,
                    2594,
                    2595,
                    389,
                    390,
                    391,
                    393,
                    394,
                    395,
                    2591
                ],
                "value.tocoo": [
                    389,
                    2591
                ],
                "indices": [
                    2592,
                    2595,
                    390,
                    392,
                    1224,
                    2292,
                    4059,
                    4061,
                    4063
                ],
                "np.concatenate": [
                    2592,
                    390
                ],
                "np": [
                    3971,
                    2564,
                    390,
                    391,
                    2569,
                    399,
                    1942,
                    3991,
                    921,
                    1952,
                    2592,
                    2593,
                    2594,
                    1576,
                    2349,
                    4018,
                    1473,
                    2373,
                    3276,
                    858,
                    2023,
                    2028,
                    3948,
                    895
                ],
                "np.expand_dims": [
                    2593,
                    2594,
                    390,
                    391
                ],
                "sparse_coo.row": [
                    2593,
                    390
                ],
                "sparse_coo.col": [
                    2594,
                    391
                ],
                "sparse_coo.data": [
                    393,
                    2595
                ],
                "sparse_coo.shape": [
                    2595,
                    394,
                    395
                ],
                "v._keras_shape": [
                    400,
                    402,
                    395
                ],
                "v._uses_learning_phase": [
                    403,
                    396
                ],
                "tf.Variable": [
                    398
                ],
                "tf.as_dtype": [
                    2374,
                    398,
                    2350,
                    729,
                    855,
                    760,
                    697,
                    892
                ],
                "name": [
                    513,
                    898,
                    732,
                    2472,
                    426,
                    811,
                    4171,
                    4187,
                    398,
                    786,
                    761,
                    824,
                    730,
                    698,
                    4155,
                    700,
                    861,
                    511
                ],
                "np.ndarray": [
                    399
                ],
                "value.shape": [
                    400,
                    2355,
                    2380
                ],
                "int_shape": [
                    2398,
                    1059,
                    1066,
                    3882,
                    4268,
                    402,
                    1940,
                    4215,
                    921,
                    1950
                ],
                "v.constraint": [
                    406
                ],
                "constraint": [
                    408,
                    406
                ],
                "AttributeError": [
                    530,
                    407
                ],
                "v._constraint": [
                    408
                ],
                "tf.constant": [
                    1952,
                    2088,
                    426,
                    1802,
                    1806,
                    2030,
                    2831,
                    1942
                ],
                "shape": [
                    513,
                    514,
                    897,
                    3972,
                    3993,
                    426,
                    3949,
                    3994,
                    1907,
                    4019,
                    3992,
                    2136,
                    730,
                    698,
                    507,
                    860,
                    509,
                    511
                ],
                "is_tensor": [
                    2614,
                    2554,
                    468,
                    2606
                ],
                "str": [
                    3465,
                    3853,
                    3731,
                    2967,
                    2968,
                    3609,
                    2202,
                    1958,
                    4264,
                    3881,
                    3506,
                    3394,
                    3650,
                    1988,
                    2246,
                    3784,
                    470,
                    3419,
                    3804,
                    3557,
                    3692,
                    4212,
                    3833,
                    1146
                ],
                "type": [
                    470
                ],
                "tf_ops._TensorLike": [
                    476
                ],
                "tf_ops": [
                    2522,
                    476
                ],
                "tf_ops.is_dense_tensor_like": [
                    476
                ],
                "ndim": [
                    1155,
                    2054,
                    1162,
                    1163,
                    2962,
                    1174,
                    1057,
                    2725,
                    2726,
                    1833,
                    2731,
                    3883,
                    3885,
                    3886,
                    1072,
                    2737,
                    1842,
                    3897,
                    3913,
                    1751,
                    1885,
                    1138,
                    1139,
                    2939,
                    508,
                    509
                ],
                "tuple": [
                    2818,
                    2451,
                    3732,
                    2454,
                    2457,
                    2586,
                    3744,
                    2465,
                    1064,
                    1071,
                    2864,
                    2865,
                    3507,
                    2876,
                    3518,
                    2891,
                    2892,
                    589,
                    2899,
                    2668,
                    2543,
                    2037,
                    1143,
                    509
                ],
                "_": [
                    2821,
                    2011,
                    509,
                    4269
                ],
                "range": [
                    2914,
                    2731,
                    4219,
                    1072,
                    4272,
                    1842,
                    4273,
                    1173,
                    1751,
                    2874,
                    2011,
                    509
                ],
                "sparse": [
                    510
                ],
                "tf.sparse_placeholder": [
                    511
                ],
                "tf.placeholder": [
                    513,
                    2379,
                    2355
                ],
                "x._keras_shape": [
                    514,
                    587
                ],
                "x._uses_learning_phase": [
                    515,
                    3020
                ],
                "x.op.type": [
                    529
                ],
                "x.op": [
                    529
                ],
                "tf.shape": [
                    1152,
                    2820,
                    1941,
                    2971,
                    2973,
                    1951,
                    3744,
                    1059,
                    1066,
                    562,
                    2872,
                    3518,
                    4039,
                    1755,
                    2780,
                    2021,
                    2793,
                    3186,
                    1149
                ],
                "as_list": [
                    589,
                    2035,
                    2005,
                    699,
                    3421,
                    731
                ],
                "x.get_shape": [
                    615,
                    2023,
                    1804,
                    589,
                    1808,
                    2035,
                    2005
                ],
                "dims": [
                    616,
                    617,
                    615
                ],
                "_dims": [
                    615
                ],
                "x.dtype.base_dtype.name": [
                    648
                ],
                "x.dtype.base_dtype": [
                    1472,
                    1473,
                    1378,
                    648,
                    1577,
                    1578,
                    3242,
                    3243,
                    3065,
                    1338
                ],
                "x.dtype": [
                    1472,
                    1473,
                    1378,
                    2374,
                    648,
                    1577,
                    1578,
                    1803,
                    3242,
                    3243,
                    2350,
                    1807,
                    2520,
                    2521,
                    1338,
                    3065
                ],
                "eval": [
                    669
                ],
                "to_dense": [
                    669,
                    1894
                ],
                "tf_dtype": [
                    897,
                    2374,
                    892,
                    2379,
                    2350,
                    2355,
                    729,
                    761,
                    855,
                    760,
                    697,
                    698,
                    860,
                    730
                ],
                "tf.zeros": [
                    698,
                    3994
                ],
                "v.get_shape": [
                    699,
                    731
                ],
                "variable": [
                    898,
                    700,
                    761,
                    732,
                    861
                ],
                "tf.ones": [
                    3993,
                    730
                ],
                "tf.eye": [
                    761
                ],
                "size": [
                    761
                ],
                "tf.zeros_like": [
                    786
                ],
                "tf.ones_like": [
                    811,
                    2975
                ],
                "tf.identity": [
                    824,
                    2483
                ],
                "seed": [
                    897,
                    3970,
                    3971,
                    3973,
                    3990,
                    3991,
                    3992,
                    4017,
                    4018,
                    4019,
                    3275,
                    3276,
                    3279,
                    856,
                    858,
                    860,
                    3947,
                    3948,
                    3950,
                    893,
                    895
                ],
                "np.random.randint": [
                    3971,
                    3948,
                    3276,
                    4018,
                    3991,
                    858,
                    895
                ],
                "np.random": [
                    3971,
                    3948,
                    3276,
                    4018,
                    3991,
                    858,
                    895
                ],
                "tf.random_uniform_initializer": [
                    859
                ],
                "low": [
                    860
                ],
                "high": [
                    860
                ],
                "tf.random_normal_initializer": [
                    896
                ],
                "mean": [
                    897,
                    1730,
                    1869,
                    3949,
                    1776,
                    4019,
                    1748,
                    1725,
                    1758,
                    1727
                ],
                "scale": [
                    897
                ],
                "np.prod": [
                    921
                ],
                "tf.cast": [
                    1409,
                    1379,
                    3367,
                    2521,
                    4047,
                    2736,
                    1394,
                    3346,
                    953,
                    2938,
                    1339,
                    3325
                ],
                "tf.assign": [
                    969,
                    2467
                ],
                "new_x": [
                    969
                ],
                "tf.assign_add": [
                    982
                ],
                "increment": [
                    982
                ],
                "tf.assign_sub": [
                    995
                ],
                "decrement": [
                    995
                ],
                "moving_averages.assign_moving_average": [
                    1009
                ],
                "moving_averages": [
                    1009
                ],
                "momentum": [
                    1010
                ],
                "y": [
                    1155,
                    1157,
                    1670,
                    1159,
                    1163,
                    1167,
                    1683,
                    1057,
                    1066,
                    1072,
                    1075,
                    1079,
                    1592,
                    1081,
                    1605,
                    1618,
                    2518,
                    2520,
                    2521,
                    2522,
                    2524,
                    1631,
                    1644,
                    1139,
                    1657,
                    1149
                ],
                "x_shape": [
                    1058,
                    1061,
                    2021,
                    1063,
                    1064,
                    2031,
                    2032,
                    1074,
                    2035,
                    2036,
                    1077,
                    2005,
                    2007,
                    2037,
                    2009
                ],
                "i": [
                    1059,
                    1060,
                    1061,
                    1066,
                    1067,
                    1068,
                    4272,
                    4274,
                    4275,
                    2874,
                    4219,
                    4220,
                    4221
                ],
                "s": [
                    1059,
                    1063,
                    1066,
                    1070,
                    2011
                ],
                "tf.unstack": [
                    2760,
                    1066,
                    1059,
                    2755
                ],
                "x_shape.append": [
                    1061,
                    1063
                ],
                "y_shape": [
                    1065,
                    1068,
                    1070,
                    1071,
                    1075,
                    1077
                ],
                "y_shape.append": [
                    1068,
                    1070
                ],
                "y_permute_dim": [
                    1072,
                    1073,
                    1075
                ],
                "list": [
                    1794,
                    2451,
                    3732,
                    1173,
                    2454,
                    2457,
                    2586,
                    2460,
                    2461,
                    2207,
                    2208,
                    3745,
                    2211,
                    1833,
                    1834,
                    2731,
                    2477,
                    1072,
                    1842,
                    3507,
                    3519,
                    2914,
                    2668,
                    2543,
                    1143
                ],
                "y_permute_dim.pop": [
                    1073
                ],
                "xt": [
                    1074,
                    1076
                ],
                "tf.reshape": [
                    1152,
                    2972,
                    1074,
                    1075,
                    1076,
                    2122,
                    4052,
                    2136,
                    4056,
                    4059,
                    1758,
                    1759,
                    1763,
                    1767,
                    3179,
                    2032,
                    3186,
                    1907,
                    1149
                ],
                "yt": [
                    1075,
                    1076
                ],
                "tf.transpose": [
                    1921,
                    3329,
                    1159,
                    3856,
                    3350,
                    3479,
                    4123,
                    3624,
                    3371,
                    2732,
                    3757,
                    1075,
                    2739,
                    1211,
                    3531,
                    3665,
                    4056,
                    4059,
                    3807,
                    2915,
                    4087,
                    3704,
                    3581
                ],
                "tf.matmul": [
                    1081,
                    1076,
                    1167
                ],
                "out": [
                    1157,
                    1159,
                    1167,
                    1173,
                    1174,
                    1079,
                    1175,
                    1081,
                    1082,
                    1176
                ],
                "tf.sparse_tensor_dense_matmul": [
                    1079
                ],
                "axes": [
                    2306,
                    2307,
                    1156,
                    1157,
                    2308,
                    1159,
                    1161,
                    1162,
                    1163,
                    2731,
                    2732,
                    2739,
                    2914,
                    2915,
                    1136,
                    1137,
                    1140,
                    1142,
                    1143,
                    1146
                ],
                "x_ndim": [
                    1169,
                    1138,
                    1170,
                    1172,
                    1142,
                    1147,
                    1148,
                    1150,
                    1151
                ],
                "y_ndim": [
                    1169,
                    1170,
                    1139,
                    1142,
                    1147,
                    1148,
                    1150,
                    1151
                ],
                "a": [
                    1559,
                    1143
                ],
                "diff": [
                    1152,
                    1154,
                    1168,
                    1173,
                    1148,
                    1149,
                    1151
                ],
                "tf.concat": [
                    1152,
                    2971,
                    1149,
                    1894
                ],
                "tf.reduce_sum": [
                    1157,
                    3143,
                    1159,
                    3149,
                    1278
                ],
                "tf.multiply": [
                    1157,
                    1159
                ],
                "adj_x": [
                    1162,
                    1165,
                    1167
                ],
                "adj_y": [
                    1163,
                    1166,
                    1167
                ],
                "idx": [
                    1170,
                    1172,
                    1173
                ],
                "tf.squeeze": [
                    2163,
                    4084,
                    1173,
                    4083,
                    3578
                ],
                "expand_dims": [
                    2738,
                    1175
                ],
                "tf.gather": [
                    1224
                ],
                "reference": [
                    1224
                ],
                "tf.reduce_max": [
                    1244
                ],
                "axis": [
                    1410,
                    1295,
                    1423,
                    3098,
                    1436,
                    1308,
                    1321,
                    1340,
                    1343,
                    1361,
                    1751,
                    1752,
                    2007,
                    2009,
                    1755,
                    1884,
                    1244,
                    2012,
                    1887,
                    3292,
                    1889,
                    1380,
                    1892,
                    1894,
                    2020,
                    2150,
                    2277,
                    1261,
                    2029,
                    1520,
                    1395,
                    2163,
                    1278
                ],
                "keepdims": [
                    1344,
                    1410,
                    1380,
                    1261,
                    1295,
                    1520,
                    1361,
                    1395,
                    1244,
                    1278
                ],
                "tf.reduce_min": [
                    1261
                ],
                "tf.reduce_prod": [
                    1295
                ],
                "tf.cumsum": [
                    1308
                ],
                "tf.cumprod": [
                    1321
                ],
                "tf.bool": [
                    1409,
                    1378,
                    2735,
                    2736,
                    4047,
                    1394,
                    2937,
                    1338,
                    2845
                ],
                "m": [
                    1340,
                    1341
                ],
                "tf.reduce_mean": [
                    1380,
                    1340,
                    1342
                ],
                "devs_squared": [
                    1341,
                    1342
                ],
                "tf.square": [
                    1448,
                    1341
                ],
                "tf.sqrt": [
                    1361,
                    1475
                ],
                "var": [
                    1730,
                    1869,
                    1776,
                    1361,
                    1759,
                    1748,
                    1725,
                    1727
                ],
                "tf.reduce_any": [
                    1395
                ],
                "tf.reduce_all": [
                    1410
                ],
                "tf.argmax": [
                    1423
                ],
                "tf.argmin": [
                    1436
                ],
                "tf.abs": [
                    1460
                ],
                "zero": [
                    1472,
                    1474,
                    3242,
                    3244
                ],
                "_to_tensor": [
                    1472,
                    1473,
                    3173,
                    3208,
                    1577,
                    1578,
                    3147,
                    3242,
                    3243,
                    3065
                ],
                "inf": [
                    1473,
                    1474
                ],
                "np.inf": [
                    1576,
                    1473
                ],
                "tf.clip_by_value": [
                    1474,
                    3174,
                    3209,
                    1579,
                    3148,
                    3244
                ],
                "tf.exp": [
                    1487
                ],
                "tf.log": [
                    3175,
                    4123,
                    3210,
                    3149,
                    4087,
                    1499
                ],
                "tf.reduce_logsumexp": [
                    1520
                ],
                "tf.round": [
                    1534
                ],
                "tf.sign": [
                    1546
                ],
                "tf.pow": [
                    1559
                ],
                "max_value": [
                    1573,
                    1574,
                    1575,
                    1576,
                    1578,
                    1579,
                    3064,
                    3065,
                    3066
                ],
                "min_value": [
                    1577,
                    1579,
                    1573,
                    1574
                ],
                "tf.equal": [
                    1592
                ],
                "tf.not_equal": [
                    1605
                ],
                "tf.greater": [
                    1618
                ],
                "tf.greater_equal": [
                    1631
                ],
                "tf.less": [
                    1644
                ],
                "tf.less_equal": [
                    1657
                ],
                "tf.maximum": [
                    1670
                ],
                "tf.minimum": [
                    3066,
                    1683
                ],
                "tf.sin": [
                    1695
                ],
                "tf.cos": [
                    1707
                ],
                "tf.nn.moments": [
                    1748,
                    1725
                ],
                "tf.nn": [
                    3845,
                    3080,
                    3849,
                    3212,
                    3470,
                    1810,
                    3225,
                    3098,
                    3618,
                    3110,
                    3753,
                    3122,
                    3257,
                    1725,
                    3901,
                    1727,
                    3909,
                    3527,
                    3659,
                    1869,
                    3279,
                    3152,
                    1748,
                    3796,
                    3925,
                    3800,
                    3292,
                    3432,
                    1769,
                    3180,
                    3308,
                    3696,
                    3060,
                    3572,
                    3062
                ],
                "reduction_axes": [
                    1794,
                    1833,
                    1834,
                    1836,
                    1839,
                    1842,
                    1848,
                    1748,
                    1844,
                    1752,
                    1725
                ],
                "normed": [
                    1776,
                    1769,
                    1730,
                    1727
                ],
                "tf.nn.batch_normalization": [
                    1769,
                    1869,
                    1727
                ],
                "beta": [
                    1728,
                    1764,
                    1767,
                    1835,
                    1805,
                    1806,
                    1839,
                    1869,
                    1843,
                    1813,
                    1847
                ],
                "gamma": [
                    1728,
                    1760,
                    1763,
                    1801,
                    1802,
                    1835,
                    1869,
                    1839,
                    1843,
                    1812,
                    1847
                ],
                "epsilon": [
                    1729,
                    3173,
                    3208,
                    3147,
                    1837,
                    1869,
                    1775,
                    1840,
                    1845,
                    1814,
                    4087,
                    1849,
                    4123
                ],
                "target_shape": [
                    1763,
                    1767,
                    1750,
                    1753,
                    1755,
                    1756,
                    1758,
                    1759
                ],
                "target_shape.append": [
                    1753,
                    1755
                ],
                "tf.stack": [
                    3745,
                    1756,
                    2812,
                    2277,
                    2056,
                    2793,
                    4040,
                    4041,
                    2802,
                    2872,
                    3508,
                    3733,
                    2136,
                    2780,
                    3519
                ],
                "broadcast_mean": [
                    1771,
                    1758
                ],
                "broadcast_var": [
                    1772,
                    1759
                ],
                "broadcast_gamma": [
                    1761,
                    1763,
                    1774
                ],
                "broadcast_beta": [
                    1773,
                    1765,
                    1767
                ],
                "normalization_axis": [
                    1808,
                    1795,
                    1804,
                    1798
                ],
                "tf_data_format": [
                    3331,
                    1796,
                    3332,
                    1799,
                    3847,
                    3467,
                    3851,
                    3855,
                    3347,
                    3476,
                    3478,
                    1815,
                    3352,
                    3353,
                    3735,
                    3611,
                    3737,
                    3613,
                    3748,
                    3622,
                    3623,
                    3368,
                    3755,
                    3756,
                    3373,
                    3374,
                    3510,
                    3512,
                    3522,
                    3652,
                    3654,
                    3529,
                    3530,
                    3786,
                    3788,
                    3663,
                    3664,
                    3798,
                    3802,
                    3806,
                    3429,
                    3431,
                    3559,
                    3561,
                    3438,
                    3694,
                    3702,
                    3703,
                    3576,
                    3835,
                    3580,
                    3837,
                    3326
                ],
                "tf.nn.fused_batch_norm": [
                    1810
                ],
                "_has_nchw_support": [
                    3328,
                    1834,
                    3370,
                    3349,
                    3900
                ],
                "_broadcast_normalize_batch_in_training": [
                    1835,
                    1847
                ],
                "_fused_normalize_batch_in_training": [
                    1838
                ],
                "sorted": [
                    1842,
                    2515,
                    2567
                ],
                "_regular_normalize_batch_in_training": [
                    1843
                ],
                "rank": [
                    1885,
                    1886,
                    1887
                ],
                "tensors": [
                    1891,
                    1892,
                    1885,
                    1894
                ],
                "tf.sparse_concat": [
                    1892
                ],
                "pattern": [
                    1921,
                    2178,
                    2179,
                    2210,
                    2213,
                    2056,
                    2057,
                    2249,
                    2257,
                    2264,
                    2205
                ],
                "data_format": [
                    3606,
                    3607,
                    3608,
                    3609,
                    3611,
                    3623,
                    3647,
                    3648,
                    3649,
                    3650,
                    3652,
                    3664,
                    3689,
                    3690,
                    3691,
                    3692,
                    3694,
                    4209,
                    4210,
                    4211,
                    4212,
                    3703,
                    3728,
                    3729,
                    3730,
                    3731,
                    2199,
                    2200,
                    2201,
                    2202,
                    3737,
                    2204,
                    3735,
                    4261,
                    4262,
                    4263,
                    4264,
                    3756,
                    4278,
                    4290,
                    2243,
                    2244,
                    2245,
                    2246,
                    3781,
                    2248,
                    3782,
                    3783,
                    3784,
                    3786,
                    3806,
                    3830,
                    3831,
                    3832,
                    3833,
                    3835,
                    3327,
                    3855,
                    3348,
                    3878,
                    3879,
                    3880,
                    3369,
                    3881,
                    3887,
                    3892,
                    3898,
                    3907,
                    3914,
                    3919,
                    3416,
                    3417,
                    3418,
                    3419,
                    3428,
                    3462,
                    3463,
                    3464,
                    3465,
                    3467,
                    1939,
                    3478,
                    1949,
                    1958,
                    3503,
                    3504,
                    3505,
                    3506,
                    3510,
                    3512,
                    1977,
                    1982,
                    1988,
                    3530,
                    3554,
                    3555,
                    3556,
                    3557,
                    3559,
                    3580
                ],
                "original_shape": [
                    1954,
                    1955,
                    1940,
                    1946,
                    1947,
                    1950
                ],
                "new_shape": [
                    1952,
                    1953,
                    1941,
                    1942,
                    1944,
                    1951
                ],
                "astype": [
                    1952,
                    1942
                ],
                "np.array": [
                    1952,
                    1942
                ],
                "height_factor": [
                    1952,
                    1984,
                    1954,
                    1942,
                    1946,
                    1979
                ],
                "width_factor": [
                    1952,
                    1985,
                    1955,
                    1942,
                    1947,
                    1980
                ],
                "permute_dimensions": [
                    4227,
                    4291,
                    4293,
                    1943,
                    1945
                ],
                "tf.image.resize_nearest_neighbor": [
                    1944,
                    1953
                ],
                "tf.image": [
                    1944,
                    1953
                ],
                "x.set_shape": [
                    1954,
                    1946
                ],
                "output": [
                    4226,
                    4227,
                    3208,
                    3209,
                    3210,
                    3213,
                    2863,
                    2866,
                    2872,
                    2873,
                    1978,
                    1979,
                    1980,
                    1981,
                    2875,
                    1983,
                    1984,
                    1985,
                    1986,
                    4286,
                    4287,
                    4291,
                    4293,
                    3143,
                    3144,
                    4294,
                    2890,
                    3147,
                    3148,
                    2765,
                    2766,
                    2893,
                    3149,
                    3150,
                    2898,
                    3153,
                    2780,
                    2783,
                    2787,
                    3173,
                    3174,
                    3175,
                    3177,
                    3179,
                    2798,
                    3186,
                    2805,
                    2806,
                    2808
                ],
                "repeat_elements": [
                    1984,
                    1985,
                    1978,
                    1979,
                    1980,
                    1983
                ],
                "depth_factor": [
                    1978,
                    1983
                ],
                "splits": [
                    2009,
                    2011
                ],
                "tf.split": [
                    2009
                ],
                "x_rep": [
                    2022,
                    2025,
                    2032,
                    2036,
                    2037,
                    2038,
                    2011,
                    2012
                ],
                "rep": [
                    2024,
                    2011,
                    2029
                ],
                "concatenate": [
                    4224,
                    4059,
                    2012,
                    4285
                ],
                "auxiliary_axis": [
                    2024,
                    2020,
                    2022,
                    2028
                ],
                "tf.expand_dims": [
                    2150,
                    2022,
                    2055,
                    4044,
                    3567,
                    3568,
                    3569,
                    4089
                ],
                "reps": [
                    2023,
                    2024,
                    2025,
                    2028,
                    2029,
                    2030,
                    2031
                ],
                "np.ones": [
                    2023
                ],
                "tf.tile": [
                    2976,
                    2792,
                    2025,
                    2057,
                    4052,
                    2871,
                    4056,
                    2779,
                    2110
                ],
                "np.delete": [
                    2028
                ],
                "x_rep.set_shape": [
                    2036
                ],
                "x_rep._keras_shape": [
                    2037
                ],
                "n": [
                    2056,
                    2108,
                    2109,
                    2110
                ],
                "stop": [
                    2081,
                    2091
                ],
                "start": [
                    2083,
                    2084,
                    2087,
                    2088,
                    2089,
                    2091
                ],
                "TypeError": [
                    2085,
                    2544,
                    2452,
                    2455,
                    2458,
                    2587
                ],
                "tf.cond": [
                    2951,
                    2087
                ],
                "start.dtype": [
                    2088
                ],
                "result": [
                    2091,
                    2093,
                    2094
                ],
                "tf.range": [
                    4052,
                    2091,
                    4044,
                    4056
                ],
                "step": [
                    2091
                ],
                "cast": [
                    3178,
                    2093
                ],
                "prod": [
                    2136
                ],
                "padding": [
                    2177,
                    2178,
                    3846,
                    3850,
                    3469,
                    3475,
                    2196,
                    2197,
                    2198,
                    3612,
                    2207,
                    2208,
                    2211,
                    3620,
                    3747,
                    3754,
                    3389,
                    3390,
                    2239,
                    2240,
                    2241,
                    2242,
                    3391,
                    3392,
                    3394,
                    3395,
                    3521,
                    3528,
                    3653,
                    3787,
                    2252,
                    2253,
                    2254,
                    3661,
                    2259,
                    2260,
                    2261,
                    3797,
                    3801,
                    3422,
                    3426,
                    3427,
                    3560,
                    3437,
                    3695,
                    3701,
                    3574,
                    3836
                ],
                "tf.pad": [
                    2264,
                    2179,
                    2213
                ],
                "image_data_format": [
                    3648,
                    3555,
                    2244,
                    3782,
                    3463,
                    3879,
                    4262,
                    3690,
                    3831,
                    3504,
                    3729,
                    4210,
                    3607,
                    2200,
                    3417
                ],
                "tf.one_hot": [
                    2292
                ],
                "num_classes": [
                    2292
                ],
                "tf.reverse": [
                    2308
                ],
                "x.eval": [
                    2323
                ],
                "ops": [
                    2336,
                    2335
                ],
                "run": [
                    2336,
                    2386,
                    2359
                ],
                "np.asarray": [
                    2569,
                    2564,
                    2373,
                    2349
                ],
                "x.dtype.name.split": [
                    2374,
                    2350
                ],
                "x.dtype.name": [
                    2374,
                    2350
                ],
                "assign_placeholder": [
                    2376,
                    2379,
                    2381,
                    2382,
                    2352,
                    2385,
                    2355,
                    2356,
                    2357,
                    2359
                ],
                "x._assign_placeholder": [
                    2352,
                    2376,
                    2357,
                    2382
                ],
                "assign_op": [
                    2377,
                    2381,
                    2383,
                    2384,
                    2353,
                    2356,
                    2358,
                    2359
                ],
                "x._assign_op": [
                    2377,
                    2353,
                    2358,
                    2383
                ],
                "x.assign": [
                    2356,
                    2381
                ],
                "tuples": [
                    2369,
                    2372
                ],
                "assign_ops": [
                    2384,
                    2370,
                    2386
                ],
                "feed_dict": [
                    2371,
                    2596,
                    2599,
                    2385,
                    2386,
                    2588
                ],
                "assign_ops.append": [
                    2384
                ],
                "tf.Print": [
                    2420
                ],
                "message": [
                    2420
                ],
                "updates": [
                    2464,
                    2457,
                    2450,
                    2641
                ],
                "inputs": [
                    2816,
                    2820,
                    2821,
                    2827,
                    2830,
                    2451,
                    2586,
                    2460,
                    2589,
                    2725,
                    2732,
                    2606,
                    2610,
                    2612,
                    2614,
                    4279,
                    2618,
                    4282,
                    2748,
                    2755,
                    2641,
                    2543,
                    2551,
                    4222
                ],
                "outputs": [
                    2914,
                    2915,
                    2821,
                    2917,
                    2823,
                    2641,
                    2802,
                    2454,
                    2812,
                    2461,
                    2911
                ],
                "self.inputs": [
                    2605,
                    2460,
                    2589,
                    2551
                ],
                "self.outputs": [
                    2528,
                    2597,
                    2601,
                    2583,
                    2461,
                    2462
                ],
                "tf.control_dependencies": [
                    2462
                ],
                "updates_ops": [
                    2471,
                    2467,
                    2470,
                    2463
                ],
                "update": [
                    2464,
                    2465,
                    2466,
                    2470
                ],
                "p": [
                    3992,
                    2466,
                    2467
                ],
                "new_p": [
                    2466,
                    2467
                ],
                "updates_ops.append": [
                    2467,
                    2470
                ],
                "self.updates_op": [
                    2531,
                    2597,
                    2471
                ],
                "tf.group": [
                    2471
                ],
                "self.name": [
                    2472
                ],
                "self.feed_dict": [
                    2566,
                    2567,
                    2569,
                    2474,
                    2514,
                    2515,
                    2588
                ],
                "session_kwargs.pop": [
                    2474,
                    2476
                ],
                "session_kwargs": [
                    2474,
                    2476,
                    2484,
                    2485,
                    2488
                ],
                "self.fetches": [
                    2528,
                    2597,
                    2476,
                    2477,
                    2478,
                    2483
                ],
                "self.session_kwargs": [
                    2600,
                    2484
                ],
                "session_kwargs.keys": [
                    2488
                ],
                "self._callable_fn": [
                    2536,
                    2489,
                    2573,
                    2582
                ],
                "self._feed_arrays": [
                    2537,
                    2490,
                    2574
                ],
                "self._feed_symbols": [
                    2576,
                    2538,
                    2491
                ],
                "self._symbol_vals": [
                    2539,
                    2492,
                    2575
                ],
                "self._session": [
                    2577,
                    2540,
                    2493
                ],
                "callable_opts": [
                    2529,
                    2531,
                    2533,
                    2510,
                    2513,
                    2516,
                    2519
                ],
                "config_pb2.CallableOptions": [
                    2510
                ],
                "config_pb2": [
                    2510
                ],
                "feed_arrays": [
                    2537,
                    2574,
                    2512,
                    2578,
                    2547,
                    2559
                ],
                "callable_opts.feed.append": [
                    2513,
                    2516
                ],
                "callable_opts.feed": [
                    2513,
                    2516
                ],
                "key": [
                    2567,
                    2569,
                    2570,
                    2637,
                    2638,
                    2639,
                    2515,
                    2516
                ],
                "self.feed_dict.keys": [
                    2515,
                    2567
                ],
                "key.name": [
                    2516
                ],
                "feed_symbols": [
                    2538,
                    2576,
                    2579,
                    2549,
                    2518,
                    2556
                ],
                "symbol_vals": [
                    2539,
                    2575,
                    2580,
                    2550,
                    2518,
                    2557
                ],
                "connection": [
                    2525,
                    2526,
                    2519
                ],
                "callable_opts.tensor_connection.add": [
                    2519
                ],
                "callable_opts.tensor_connection": [
                    2519
                ],
                "y.dtype": [
                    2520
                ],
                "from_tensor": [
                    2522,
                    2523,
                    2524,
                    2525
                ],
                "tf_ops._as_graph_element": [
                    2522
                ],
                "connection.from_tensor": [
                    2525
                ],
                "from_tensor.name": [
                    2525
                ],
                "connection.to_tensor": [
                    2526
                ],
                "callable_opts.fetch.append": [
                    2529
                ],
                "callable_opts.fetch": [
                    2529
                ],
                "callable_opts.target.append": [
                    2531
                ],
                "callable_opts.target": [
                    2531
                ],
                "self.updates_op.name": [
                    2531
                ],
                "callable_fn": [
                    2536,
                    2533
                ],
                "session._make_callable_from_options": [
                    2533
                ],
                "array_vals": [
                    2568,
                    2563,
                    2548,
                    2582
                ],
                "feed_symbols.append": [
                    2556
                ],
                "symbol_vals.append": [
                    2557
                ],
                "feed_arrays.append": [
                    2559
                ],
                "array_vals.append": [
                    2568,
                    2563
                ],
                "tensor.dtype.base_dtype.name": [
                    2565
                ],
                "tensor.dtype.base_dtype": [
                    2565
                ],
                "tensor.dtype": [
                    2565
                ],
                "key.dtype.base_dtype.name": [
                    2570
                ],
                "key.dtype.base_dtype": [
                    2570
                ],
                "key.dtype": [
                    2570
                ],
                "self._make_callable": [
                    2578
                ],
                "fetched": [
                    2582,
                    2583
                ],
                "self.feed_dict.copy": [
                    2588
                ],
                "fetches": [
                    2597,
                    2599
                ],
                "updated": [
                    2601,
                    2599
                ],
                "self._legacy_call": [
                    2610,
                    2618
                ],
                "self._call": [
                    2612
                ],
                "kwargs": [
                    2641,
                    2636,
                    2637
                ],
                "has_arg": [
                    2638
                ],
                "tf.Session.run": [
                    2638
                ],
                "Function.__init__": [
                    2638
                ],
                "Function": [
                    2641,
                    2638
                ],
                "msg": [
                    2640,
                    2639
                ],
                "tf.gradients": [
                    2654
                ],
                "loss": [
                    2654
                ],
                "map": [
                    2669
                ],
                "tf.stop_gradient": [
                    2669,
                    2671
                ],
                "inputs.get_shape": [
                    2748,
                    2725
                ],
                "mask": [
                    2848,
                    2759,
                    2760,
                    2734,
                    2735,
                    2736,
                    2737,
                    2738,
                    2739,
                    2833,
                    2842
                ],
                "mask.dtype": [
                    2735
                ],
                "mask.get_shape": [
                    2737
                ],
                "constants": [
                    2821,
                    2892,
                    2765,
                    2865,
                    2805,
                    2741,
                    2742
                ],
                "uses_learning_phase": [
                    2916,
                    3003,
                    3019,
                    2895,
                    2767,
                    2868,
                    2807,
                    2745,
                    3001
                ],
                "unroll": [
                    2747
                ],
                "states": [
                    2818,
                    2790,
                    2891,
                    2797,
                    2765,
                    2799,
                    2864,
                    2896,
                    2834,
                    2805,
                    2869,
                    2873,
                    2904,
                    2809,
                    2874,
                    2751
                ],
                "initial_states": [
                    2818,
                    2821,
                    2751
                ],
                "successive_states": [
                    2752,
                    2799,
                    2801,
                    2809,
                    2811
                ],
                "successive_outputs": [
                    2753,
                    2785,
                    2798,
                    2800,
                    2802,
                    2808,
                    2810,
                    2812,
                    2782
                ],
                "input_list": [
                    2755,
                    2764,
                    2757,
                    2804
                ],
                "go_backwards": [
                    2761,
                    2756,
                    2841,
                    2815
                ],
                "input_list.reverse": [
                    2757
                ],
                "mask_list": [
                    2760,
                    2762,
                    2764
                ],
                "mask_list.reverse": [
                    2762
                ],
                "inp": [
                    2805,
                    2764,
                    2765,
                    2804
                ],
                "mask_t": [
                    2792,
                    2764,
                    2862,
                    2871,
                    2779
                ],
                "new_states": [
                    2917,
                    2790,
                    2890,
                    2765,
                    2863,
                    2896,
                    2801,
                    2899,
                    2869,
                    2874,
                    2811,
                    2876,
                    2909
                ],
                "step_function": [
                    2821,
                    2890,
                    2765,
                    2863,
                    2805
                ],
                "tiled_mask_t": [
                    2787,
                    2792,
                    2794,
                    2871,
                    2873,
                    2874,
                    2779
                ],
                "prev_output": [
                    2785,
                    2787,
                    2783
                ],
                "zeros_like": [
                    2783
                ],
                "tf.where": [
                    2977,
                    2787,
                    2794,
                    3084,
                    3992,
                    2873,
                    2874,
                    2975
                ],
                "return_states": [
                    2797,
                    2794,
                    2789
                ],
                "state": [
                    2790,
                    2796,
                    2896,
                    2897,
                    2869,
                    2870
                ],
                "new_state": [
                    2790,
                    2793,
                    2795,
                    2896,
                    2897,
                    2869,
                    2870
                ],
                "return_states.append": [
                    2794
                ],
                "successive_outputs.append": [
                    2808,
                    2798
                ],
                "successive_states.append": [
                    2809,
                    2799
                ],
                "last_output": [
                    2912,
                    2916,
                    2917,
                    2800,
                    2810
                ],
                "reverse": [
                    2816,
                    4057,
                    2842
                ],
                "time_steps": [
                    2820,
                    2824,
                    2828,
                    2902,
                    2846
                ],
                "output_ta": [
                    2912,
                    2822,
                    2904,
                    2908,
                    2911
                ],
                "tensor_array_ops.TensorArray": [
                    2826,
                    2844,
                    2822
                ],
                "tensor_array_ops": [
                    2826,
                    2844,
                    2822
                ],
                "outputs.dtype": [
                    2823
                ],
                "input_ta": [
                    2889,
                    2826,
                    2861,
                    2830
                ],
                "inputs.dtype": [
                    2827
                ],
                "input_ta.unstack": [
                    2830
                ],
                "time": [
                    2889,
                    2861,
                    2862,
                    2831,
                    2898,
                    2899,
                    2902,
                    2904,
                    2875,
                    2876
                ],
                "mask_ta": [
                    2848,
                    2844,
                    2862
                ],
                "mask_ta.unstack": [
                    2848
                ],
                "current_input": [
                    2889,
                    2890,
                    4045,
                    2861,
                    2863
                ],
                "input_ta.read": [
                    2889,
                    2861
                ],
                "mask_ta.read": [
                    2862
                ],
                "new_state.set_shape": [
                    2897,
                    2870
                ],
                "state.get_shape": [
                    2897,
                    2870
                ],
                "output_ta_t": [
                    2898,
                    2875,
                    2876,
                    2899
                ],
                "output_ta_t.write": [
                    2898,
                    2875
                ],
                "final_outputs": [
                    2907,
                    2908,
                    2901,
                    2909
                ],
                "control_flow_ops.while_loop": [
                    2901
                ],
                "control_flow_ops": [
                    2901
                ],
                "_step": [
                    2903
                ],
                "last_time": [
                    2912,
                    2907
                ],
                "output_ta.stack": [
                    2911
                ],
                "output_ta.read": [
                    2912
                ],
                "outputs.get_shape": [
                    2914
                ],
                "last_output._uses_learning_phase": [
                    2916
                ],
                "condition.dtype": [
                    2937
                ],
                "condition": [
                    2976,
                    2977,
                    2971,
                    2951,
                    2937,
                    2938,
                    2939,
                    2972
                ],
                "cond_ndim": [
                    2963,
                    2967,
                    2969,
                    2970,
                    2939,
                    2940
                ],
                "callable": [
                    2946,
                    3012,
                    2958,
                    2960,
                    2941,
                    3006
                ],
                "then_expression": [
                    2945,
                    2977,
                    2958,
                    2959,
                    2973,
                    2962,
                    2941,
                    2943
                ],
                "then_expression_fn": [
                    2952,
                    2945
                ],
                "else_expression": [
                    2977,
                    2946,
                    2948,
                    2950,
                    2960,
                    2961
                ],
                "else_expression_fn": [
                    2953,
                    2950
                ],
                "expr_ndim": [
                    2968,
                    2962,
                    2963,
                    2970
                ],
                "ndim_diff": [
                    2970,
                    2971
                ],
                "cond_shape": [
                    2971,
                    2972,
                    2974
                ],
                "expr_shape": [
                    2973,
                    2974,
                    2975
                ],
                "shape_diff": [
                    2974,
                    2975
                ],
                "tile_shape": [
                    2976,
                    2975
                ],
                "training": [
                    3041,
                    3011,
                    3018,
                    2999,
                    3000,
                    3005
                ],
                "learning_phase": [
                    3000
                ],
                "alt": [
                    3041,
                    3012,
                    3013,
                    3015,
                    3018
                ],
                "switch": [
                    3018
                ],
                "in_train_phase": [
                    3041
                ],
                "alpha": [
                    3081,
                    3059,
                    3060,
                    3084
                ],
                "tf.nn.leaky_relu": [
                    3060
                ],
                "tf.nn.relu": [
                    3062
                ],
                "res": [
                    3080,
                    3082,
                    3084,
                    3180,
                    3186,
                    3188
                ],
                "tf.nn.elu": [
                    3080
                ],
                "tf.nn.softmax": [
                    3098
                ],
                "tf.nn.softplus": [
                    3110
                ],
                "tf.nn.softsign": [
                    3122
                ],
                "from_logits": [
                    3172,
                    3141,
                    3206
                ],
                "output.get_shape": [
                    3144,
                    3177,
                    3150
                ],
                "_epsilon": [
                    3173,
                    3174,
                    3208,
                    3209,
                    3147,
                    3148
                ],
                "output.dtype.base_dtype": [
                    3208,
                    3147,
                    3173
                ],
                "output.dtype": [
                    3208,
                    3147,
                    3173
                ],
                "target": [
                    3152,
                    3178,
                    3212,
                    3149
                ],
                "tf.nn.softmax_cross_entropy_with_logits": [
                    3152
                ],
                "output_shape": [
                    3732,
                    3733,
                    3738,
                    3739,
                    3740,
                    3741,
                    3742,
                    3743,
                    3744,
                    3745,
                    3753,
                    4267,
                    3507,
                    3508,
                    3513,
                    3514,
                    3515,
                    3516,
                    3517,
                    3518,
                    3519,
                    3527,
                    3177,
                    3179,
                    3183
                ],
                "targets": [
                    3178,
                    3308,
                    3181
                ],
                "flatten": [
                    3178
                ],
                "logits": [
                    3179,
                    3182
                ],
                "tf.nn.sparse_softmax_cross_entropy_with_logits": [
                    3180
                ],
                "tf.nn.sigmoid_cross_entropy_with_logits": [
                    3212
                ],
                "tf.nn.sigmoid": [
                    3225
                ],
                "one": [
                    3243,
                    3244
                ],
                "tf.nn.tanh": [
                    3257
                ],
                "retain_prob": [
                    3274,
                    3279
                ],
                "level": [
                    3274
                ],
                "tf.nn.dropout": [
                    3279
                ],
                "noise_shape": [
                    3279
                ],
                "tf.nn.l2_normalize": [
                    3292
                ],
                "tf.nn.in_top_k": [
                    3308
                ],
                "predictions": [
                    3308
                ],
                "k": [
                    3308
                ],
                "kernel_shape": [
                    3424,
                    4268,
                    4269,
                    4215,
                    4216,
                    3421
                ],
                "kernel.get_shape": [
                    3421
                ],
                "kernel": [
                    4226,
                    3527,
                    3753,
                    3434,
                    4268,
                    3472,
                    3698,
                    4215,
                    3421,
                    4286
                ],
                "left_pad": [
                    3424,
                    3425
                ],
                "dilation_rate": [
                    3424,
                    3621,
                    3435,
                    3662,
                    3473,
                    3570,
                    3699,
                    3575
                ],
                "temporal_padding": [
                    3425
                ],
                "_preprocess_padding": [
                    3521,
                    3427,
                    3747,
                    3653,
                    3836,
                    3560,
                    3787,
                    3469,
                    3695,
                    3612
                ],
                "tf.nn.convolution": [
                    3432,
                    3696,
                    3470
                ],
                "strides": [
                    3841,
                    3845,
                    3849,
                    3474,
                    3614,
                    3616,
                    3619,
                    3749,
                    3751,
                    3753,
                    4266,
                    3523,
                    3525,
                    3527,
                    3655,
                    3657,
                    3660,
                    3789,
                    3792,
                    3796,
                    3800,
                    3563,
                    3436,
                    3566,
                    3700,
                    3573,
                    4214,
                    3838
                ],
                "_preprocess_conv2d_input": [
                    3652,
                    3786,
                    3467,
                    3510,
                    3611
                ],
                "tf.nn.conv2d_transpose": [
                    3527
                ],
                "_preprocess_conv1d_input": [
                    3559
                ],
                "spatial_start_dim": [
                    3562,
                    3565,
                    3578,
                    3567
                ],
                "depthwise_kernel": [
                    3568,
                    3618,
                    3659,
                    3572
                ],
                "pointwise_kernel": [
                    3569,
                    3618,
                    3572
                ],
                "tf.nn.separable_conv2d": [
                    3618,
                    3572
                ],
                "tf.nn.depthwise_conv2d": [
                    3659
                ],
                "_preprocess_conv3d_input": [
                    3835,
                    3694,
                    3735
                ],
                "tf.nn.conv3d_transpose": [
                    3753
                ],
                "pool_size": [
                    3842,
                    3845,
                    3849,
                    3790,
                    3793,
                    3796,
                    3800,
                    3839
                ],
                "pool_mode": [
                    3844,
                    3848,
                    3853,
                    3795,
                    3799,
                    3804
                ],
                "tf.nn.max_pool": [
                    3796
                ],
                "tf.nn.avg_pool": [
                    3800
                ],
                "tf.nn.max_pool3d": [
                    3845
                ],
                "tf.nn.avg_pool3d": [
                    3849
                ],
                "bias_shape": [
                    3882,
                    3883,
                    3885,
                    3888,
                    3889,
                    3891,
                    3893,
                    3894,
                    3896,
                    3899,
                    3904,
                    3906,
                    3908,
                    3912,
                    3915,
                    3916,
                    3918,
                    3920,
                    3921,
                    3923
                ],
                "bias": [
                    3904,
                    3906,
                    3909,
                    3912,
                    3882,
                    3916,
                    3918,
                    3889,
                    3921,
                    3891,
                    3923,
                    3925,
                    3894,
                    3896,
                    3901
                ],
                "reshape": [
                    3904,
                    3906,
                    3912,
                    3916,
                    3918,
                    3889,
                    3921,
                    3891,
                    3923,
                    3894,
                    4279,
                    3896,
                    4282,
                    4222,
                    4287
                ],
                "tf.nn.bias_add": [
                    3925,
                    3909,
                    3901
                ],
                "tf.random_normal": [
                    3949
                ],
                "stddev": [
                    4019,
                    3949
                ],
                "tf.random_uniform": [
                    3992,
                    3972
                ],
                "minval": [
                    3972
                ],
                "maxval": [
                    3972
                ],
                "tf.truncated_normal": [
                    4019
                ],
                "label_shape": [
                    4039,
                    4040,
                    4041,
                    4044,
                    4047,
                    4052,
                    4053,
                    4056,
                    4057,
                    4063
                ],
                "labels": [
                    4061,
                    4039
                ],
                "num_batches_tns": [
                    4040,
                    4052
                ],
                "max_num_labels_tns": [
                    4041,
                    4057,
                    4045
                ],
                "tf.fill": [
                    4044,
                    4047
                ],
                "init": [
                    4049,
                    4047
                ],
                "dense_mask": [
                    4048,
                    4058,
                    4050,
                    4054
                ],
                "functional_ops.scan": [
                    4048
                ],
                "functional_ops": [
                    4048
                ],
                "range_less_than": [
                    4048
                ],
                "label_lengths": [
                    4048
                ],
                "label_array": [
                    4052,
                    4054
                ],
                "label_ind": [
                    4059,
                    4054
                ],
                "tf.boolean_mask": [
                    4058,
                    4054
                ],
                "batch_array": [
                    4056,
                    4058
                ],
                "batch_ind": [
                    4058,
                    4059
                ],
                "vals_sparse": [
                    4061,
                    4063
                ],
                "tf.gather_nd": [
                    4061
                ],
                "tf.to_int64": [
                    4063
                ],
                "label_length": [
                    4083,
                    4085
                ],
                "tf.to_int32": [
                    4083,
                    4084,
                    4085,
                    4124
                ],
                "input_length": [
                    4129,
                    4133,
                    4084,
                    4091,
                    4124
                ],
                "sparse_labels": [
                    4090,
                    4085
                ],
                "ctc_label_dense_to_sparse": [
                    4085
                ],
                "y_true": [
                    4085
                ],
                "y_pred": [
                    4128,
                    4132,
                    4087,
                    4089,
                    4123
                ],
                "ctc.ctc_loss": [
                    4089
                ],
                "ctc": [
                    4089,
                    4131,
                    4127
                ],
                "greedy": [
                    4126
                ],
                "decoded": [
                    4137,
                    4131,
                    4127
                ],
                "log_prob": [
                    4138,
                    4131,
                    4127
                ],
                "ctc.ctc_greedy_decoder": [
                    4127
                ],
                "ctc.ctc_beam_search_decoder": [
                    4131
                ],
                "beam_width": [
                    4133
                ],
                "top_paths": [
                    4134
                ],
                "decoded_dense": [
                    4136,
                    4138
                ],
                "tf.sparse_to_dense": [
                    4136
                ],
                "st.indices": [
                    4136
                ],
                "st": [
                    4136,
                    4137
                ],
                "st.dense_shape": [
                    4136
                ],
                "st.values": [
                    4136
                ],
                "tf.map_fn": [
                    4155
                ],
                "fn": [
                    4171,
                    4155,
                    4187
                ],
                "elems": [
                    4171,
                    4155,
                    4187
                ],
                "tf.foldl": [
                    4171
                ],
                "initializer": [
                    4187,
                    4171
                ],
                "tf.foldr": [
                    4187
                ],
                "stride": [
                    4220,
                    4221,
                    4214
                ],
                "output_length": [
                    4216,
                    4219
                ],
                "feature_dim": [
                    4269,
                    4216,
                    4283,
                    4280,
                    4223
                ],
                "filters": [
                    4216,
                    4269,
                    4288
                ],
                "xs": [
                    4224,
                    4282,
                    4271,
                    4279,
                    4218,
                    4285,
                    4222
                ],
                "slice_length": [
                    4220,
                    4222
                ],
                "slice": [
                    4274,
                    4220,
                    4276
                ],
                "kernel_size": [
                    4275,
                    4221,
                    4277
                ],
                "xs.append": [
                    4282,
                    4222,
                    4279
                ],
                "x_aggregate": [
                    4224,
                    4226,
                    4285,
                    4286
                ],
                "batch_dot": [
                    4226,
                    4286
                ],
                "stride_row": [
                    4274,
                    4266,
                    4275
                ],
                "stride_col": [
                    4266,
                    4276,
                    4277
                ],
                "output_row": [
                    4272,
                    4267,
                    4288
                ],
                "output_col": [
                    4288,
                    4273,
                    4267
                ],
                "j": [
                    4273,
                    4276,
                    4277
                ],
                "slice_row": [
                    4282,
                    4274,
                    4279
                ],
                "slice_col": [
                    4282,
                    4276,
                    4279
                ]
            },
            "filtered_variables_in_file": {
                "py_all": [
                    1891,
                    699,
                    28,
                    731
                ],
                "py_any": [
                    2605,
                    2606,
                    2614,
                    1143,
                    29
                ],
                "py_sum": [
                    30
                ],
                "_SESSION": [
                    36,
                    175,
                    182,
                    183,
                    217,
                    93
                ],
                "_GRAPH_LEARNING_PHASES": [
                    128,
                    97,
                    98,
                    132,
                    133,
                    41,
                    149
                ],
                "_GRAPH_UID_DICTS": [
                    71,
                    72,
                    73,
                    74,
                    47,
                    81
                ],
                "_MANUAL_VAR_INIT": [
                    184,
                    114,
                    52
                ],
                "_LOCAL_DEVICES": [
                    57,
                    274,
                    275,
                    273
                ],
                "graph": [
                    128,
                    132,
                    133,
                    70,
                    71,
                    72,
                    73,
                    74,
                    127
                ],
                "tf.get_default_graph": [
                    98,
                    70,
                    241,
                    149,
                    127
                ],
                "tf": [
                    513,
                    2055,
                    2056,
                    2057,
                    1546,
                    3080,
                    3084,
                    1559,
                    3098,
                    4123,
                    4124,
                    3618,
                    1059,
                    3110,
                    2087,
                    2088,
                    3624,
                    1066,
                    1579,
                    2091,
                    4136,
                    562,
                    1074,
                    1075,
                    1076,
                    3122,
                    1079,
                    1592,
                    1081,
                    4155,
                    2110,
                    1605,
                    70,
                    3143,
                    2122,
                    3659,
                    3148,
                    3149,
                    2638,
                    4171,
                    3152,
                    3665,
                    1618,
                    3578,
                    4087,
                    2136,
                    91,
                    4187,
                    4089,
                    94,
                    1631,
                    2654,
                    98,
                    2150,
                    3174,
                    3175,
                    3179,
                    1644,
                    2669,
                    3180,
                    2671,
                    3696,
                    3186,
                    2163,
                    3704,
                    1657,
                    1149,
                    127,
                    1152,
                    129,
                    3994,
                    2179,
                    1157,
                    1670,
                    1159,
                    3209,
                    3210,
                    3212,
                    1167,
                    1683,
                    149,
                    1173,
                    3733,
                    3225,
                    1695,
                    3744,
                    3745,
                    2213,
                    3753,
                    170,
                    1707,
                    2732,
                    3244,
                    3757,
                    2735,
                    2736,
                    177,
                    3800,
                    2739,
                    180,
                    182,
                    697,
                    186,
                    698,
                    1211,
                    1725,
                    3257,
                    1727,
                    195,
                    2755,
                    1224,
                    2760,
                    202,
                    3279,
                    1748,
                    3796,
                    2264,
                    729,
                    730,
                    1755,
                    1244,
                    1756,
                    1758,
                    1759,
                    2779,
                    2780,
                    3292,
                    1763,
                    2787,
                    2277,
                    3807,
                    1767,
                    2792,
                    1769,
                    2793,
                    2794,
                    3308,
                    1261,
                    241,
                    2802,
                    2292,
                    760,
                    761,
                    2812,
                    3325,
                    1278,
                    3329,
                    2308,
                    2820,
                    3845,
                    3849,
                    1802,
                    1806,
                    1295,
                    2831,
                    3856,
                    786,
                    1810,
                    3346,
                    3350,
                    1308,
                    2845,
                    3367,
                    1321,
                    811,
                    3371,
                    2350,
                    304,
                    2355,
                    2871,
                    824,
                    2872,
                    1338,
                    1339,
                    1340,
                    1341,
                    1342,
                    2873,
                    2874,
                    3901,
                    3909,
                    2374,
                    327,
                    2379,
                    1869,
                    1361,
                    3925,
                    855,
                    859,
                    351,
                    1378,
                    1379,
                    356,
                    1380,
                    1892,
                    1894,
                    2915,
                    3432,
                    3949,
                    1394,
                    1395,
                    1907,
                    2420,
                    2937,
                    2938,
                    892,
                    896,
                    1409,
                    1410,
                    1921,
                    3972,
                    2951,
                    392,
                    398,
                    1423,
                    3470,
                    1941,
                    1942,
                    3479,
                    1944,
                    3992,
                    3993,
                    2971,
                    1436,
                    2972,
                    2462,
                    1951,
                    1952,
                    1953,
                    2973,
                    2467,
                    2975,
                    2976,
                    2977,
                    2471,
                    1448,
                    426,
                    2483,
                    1460,
                    3508,
                    4019,
                    953,
                    3518,
                    3519,
                    1474,
                    1475,
                    3527,
                    4039,
                    969,
                    4040,
                    3531,
                    4041,
                    4044,
                    1487,
                    4047,
                    4052,
                    982,
                    4054,
                    4056,
                    2009,
                    2521,
                    1499,
                    4058,
                    4059,
                    4061,
                    4063,
                    995,
                    2021,
                    2022,
                    2025,
                    2030,
                    3567,
                    1520,
                    2032,
                    3568,
                    3569,
                    3060,
                    3572,
                    3062,
                    4083,
                    4084,
                    4085,
                    3066,
                    3581,
                    1534,
                    511
                ],
                "defaultdict": [
                    72
                ],
                "prefix": [
                    73,
                    74
                ],
                "tf.reset_default_graph": [
                    91
                ],
                "reset_uids": [
                    92
                ],
                "phase": [
                    129,
                    98,
                    132,
                    94
                ],
                "tf.placeholder_with_default": [
                    129,
                    94
                ],
                "value": [
                    896,
                    898,
                    388,
                    389,
                    2564,
                    398,
                    399,
                    400,
                    401,
                    146,
                    402,
                    149,
                    2589,
                    2591,
                    2595,
                    2596,
                    426,
                    2349,
                    2355,
                    2359,
                    2372,
                    2373,
                    2380,
                    2385,
                    859,
                    861,
                    114,
                    1010,
                    2551,
                    2552,
                    2554,
                    2557
                ],
                "default_session": [
                    170,
                    172,
                    173
                ],
                "tf.get_default_session": [
                    170
                ],
                "session": [
                    194,
                    217,
                    2533,
                    2598,
                    2599,
                    202,
                    2540,
                    173,
                    205,
                    206,
                    207,
                    2577,
                    2546,
                    2581,
                    183,
                    185
                ],
                "os.environ.get": [
                    176,
                    179
                ],
                "os.environ": [
                    176,
                    179
                ],
                "os": [
                    176,
                    179
                ],
                "config": [
                    177,
                    180,
                    182
                ],
                "tf.ConfigProto": [
                    177,
                    180
                ],
                "num_thread": [
                    179,
                    180
                ],
                "tf.Session": [
                    2638,
                    182
                ],
                "session.graph.as_default": [
                    185
                ],
                "session.graph": [
                    185
                ],
                "variables": [
                    2668,
                    2669,
                    2671,
                    186,
                    188,
                    2654
                ],
                "tf.global_variables": [
                    186
                ],
                "candidate_vars": [
                    195,
                    197,
                    187,
                    190,
                    191
                ],
                "v": [
                    392,
                    395,
                    396,
                    397,
                    398,
                    400,
                    402,
                    403,
                    406,
                    408,
                    409,
                    698,
                    699,
                    188,
                    189,
                    190,
                    700,
                    701,
                    195,
                    197,
                    199,
                    200,
                    730,
                    731,
                    732,
                    733
                ],
                "candidate_vars.append": [
                    190
                ],
                "is_initialized": [
                    194,
                    197
                ],
                "session.run": [
                    202,
                    194,
                    2599
                ],
                "tf.is_variable_initialized": [
                    195
                ],
                "uninitialized_vars": [
                    201,
                    202,
                    196,
                    199
                ],
                "flag": [
                    197,
                    198
                ],
                "uninitialized_vars.append": [
                    199
                ],
                "v._keras_initialized": [
                    200
                ],
                "tf.variables_initializer": [
                    202
                ],
                "session.list_devices": [
                    206
                ],
                "device_lib.list_local_devices": [
                    206
                ],
                "device_lib": [
                    206
                ],
                "self.device": [
                    226,
                    230
                ],
                "self": [
                    2566,
                    2567,
                    2569,
                    2573,
                    2574,
                    2575,
                    2576,
                    2577,
                    2578,
                    2582,
                    2583,
                    2460,
                    2461,
                    2462,
                    2588,
                    2589,
                    2597,
                    2471,
                    2472,
                    2600,
                    2474,
                    2601,
                    2476,
                    2477,
                    2478,
                    2605,
                    2610,
                    2483,
                    2484,
                    2612,
                    2489,
                    2490,
                    2491,
                    2492,
                    2493,
                    2618,
                    2514,
                    2515,
                    2528,
                    226,
                    2531,
                    230,
                    2536,
                    2537,
                    2538,
                    2539,
                    2540,
                    2551
                ],
                "device": [
                    263,
                    230,
                    262
                ],
                "g": [
                    241,
                    243
                ],
                "op": [
                    242,
                    243,
                    244
                ],
                "_TfDeviceCaptureOp": [
                    242
                ],
                "g._apply_device_functions": [
                    243
                ],
                "op.device": [
                    244
                ],
                "device_type": [
                    259,
                    260,
                    263
                ],
                "device_type.upper": [
                    259,
                    263
                ],
                "_get_current_tf_device": [
                    262
                ],
                "device.device_type": [
                    263
                ],
                "list_devices": [
                    274
                ],
                "get_session": [
                    2336,
                    2598,
                    2604,
                    274,
                    2323,
                    2386,
                    2546,
                    2359,
                    669
                ],
                "x.name": [
                    2513,
                    275,
                    2529,
                    2526
                ],
                "x": [
                    513,
                    514,
                    515,
                    516,
                    2054,
                    2055,
                    3080,
                    2057,
                    1546,
                    3084,
                    529,
                    1559,
                    3098,
                    3611,
                    1057,
                    3618,
                    1059,
                    3110,
                    3624,
                    1577,
                    1578,
                    1579,
                    3625,
                    2605,
                    2606,
                    562,
                    1074,
                    3122,
                    1078,
                    1079,
                    1592,
                    1081,
                    2614,
                    2110,
                    3371,
                    3652,
                    1605,
                    586,
                    587,
                    2122,
                    589,
                    3659,
                    3374,
                    3665,
                    1618,
                    3578,
                    3666,
                    3883,
                    2136,
                    2137,
                    3885,
                    1631,
                    3886,
                    3480,
                    2150,
                    615,
                    3583,
                    1644,
                    3694,
                    3889,
                    3696,
                    3697,
                    1138,
                    2163,
                    3704,
                    1657,
                    3705,
                    3891,
                    1152,
                    1155,
                    2179,
                    1157,
                    1670,
                    1159,
                    648,
                    1162,
                    1167,
                    1683,
                    3735,
                    3225,
                    669,
                    1695,
                    3744,
                    2213,
                    3241,
                    3242,
                    1707,
                    3243,
                    3244,
                    3245,
                    3753,
                    3757,
                    3758,
                    3257,
                    1211,
                    1725,
                    1727,
                    3786,
                    3279,
                    1748,
                    3796,
                    1751,
                    2264,
                    3800,
                    1755,
                    1244,
                    3292,
                    3807,
                    3808,
                    2277,
                    1770,
                    1261,
                    3835,
                    3324,
                    3325,
                    1278,
                    3329,
                    2308,
                    3332,
                    3845,
                    3849,
                    1803,
                    1804,
                    1295,
                    1807,
                    1808,
                    786,
                    275,
                    1811,
                    2323,
                    3345,
                    3346,
                    3350,
                    3353,
                    3857,
                    1308,
                    3366,
                    3367,
                    1321,
                    1833,
                    811,
                    1835,
                    2349,
                    2350,
                    1839,
                    304,
                    2351,
                    1842,
                    1843,
                    2352,
                    2353,
                    2356,
                    1847,
                    824,
                    2357,
                    1338,
                    1339,
                    1340,
                    1341,
                    2358,
                    3894,
                    3896,
                    3897,
                    3901,
                    3904,
                    2372,
                    2373,
                    2374,
                    2375,
                    2376,
                    2377,
                    3906,
                    3909,
                    3912,
                    1869,
                    2381,
                    2382,
                    2383,
                    1361,
                    3913,
                    3916,
                    3918,
                    3921,
                    3923,
                    3925,
                    3926,
                    2398,
                    3425,
                    1378,
                    1379,
                    1380,
                    1891,
                    1894,
                    3432,
                    3433,
                    3439,
                    1394,
                    1395,
                    1907,
                    2420,
                    1409,
                    1410,
                    1921,
                    2951,
                    3467,
                    3470,
                    1423,
                    3471,
                    1940,
                    1941,
                    1943,
                    1944,
                    921,
                    1945,
                    1946,
                    1436,
                    1948,
                    1950,
                    1951,
                    3479,
                    1953,
                    1954,
                    2977,
                    1956,
                    2978,
                    1448,
                    2483,
                    1460,
                    3510,
                    953,
                    1978,
                    3006,
                    1983,
                    1472,
                    1473,
                    1474,
                    1475,
                    3007,
                    3009,
                    3518,
                    3527,
                    969,
                    3018,
                    3531,
                    3020,
                    3021,
                    3532,
                    1487,
                    2512,
                    2513,
                    3856,
                    468,
                    2005,
                    470,
                    982,
                    472,
                    2009,
                    2518,
                    1499,
                    476,
                    2520,
                    2521,
                    2526,
                    2528,
                    2529,
                    3041,
                    995,
                    2021,
                    2022,
                    2023,
                    3559,
                    3567,
                    1520,
                    1010,
                    2035,
                    3060,
                    3572,
                    3062,
                    3065,
                    3066,
                    3067,
                    3581,
                    1534,
                    511
                ],
                "x.device_type": [
                    275
                ],
                "explicitly_on_cpu": [
                    289,
                    287
                ],
                "_is_current_explicit_device": [
                    287
                ],
                "gpus_available": [
                    288,
                    289
                ],
                "_get_available_gpus": [
                    288
                ],
                "tf.convert_to_tensor": [
                    304
                ],
                "dtype": [
                    3968,
                    513,
                    386,
                    387,
                    898,
                    3969,
                    3973,
                    398,
                    3345,
                    786,
                    3988,
                    3989,
                    3992,
                    3993,
                    3994,
                    3366,
                    424,
                    425,
                    426,
                    811,
                    2092,
                    2093,
                    2349,
                    4015,
                    304,
                    4016,
                    4019,
                    695,
                    696,
                    697,
                    953,
                    4155,
                    700,
                    2373,
                    3324,
                    853,
                    854,
                    727,
                    728,
                    729,
                    855,
                    732,
                    861,
                    3945,
                    3946,
                    3950,
                    761,
                    758,
                    759,
                    760,
                    505,
                    506,
                    891,
                    892,
                    890,
                    511
                ],
                "tensor": [
                    353,
                    2596,
                    2565,
                    327,
                    2590,
                    2559,
                    2551,
                    2556,
                    2589,
                    350,
                    351
                ],
                "tf.SparseTensor": [
                    392,
                    4063,
                    327
                ],
                "is_sparse": [
                    1891,
                    2590,
                    2605,
                    1078,
                    350
                ],
                "tf.sparse_tensor_to_dense": [
                    351
                ],
                "name_scope": [
                    356
                ],
                "tf.name_scope": [
                    356
                ],
                "floatx": [
                    3969,
                    387,
                    1379,
                    425,
                    3946,
                    728,
                    4016,
                    1339,
                    3989,
                    854,
                    759,
                    696,
                    506,
                    891
                ],
                "sparse_coo": [
                    2593,
                    2594,
                    2595,
                    389,
                    390,
                    391,
                    393,
                    394,
                    395,
                    2591
                ],
                "value.tocoo": [
                    389,
                    2591
                ],
                "indices": [
                    2592,
                    2595,
                    390,
                    392,
                    1224,
                    2292,
                    4059,
                    4061,
                    4063
                ],
                "np.concatenate": [
                    2592,
                    390
                ],
                "np": [
                    3971,
                    2564,
                    390,
                    391,
                    2569,
                    399,
                    1942,
                    3991,
                    921,
                    1952,
                    2592,
                    2593,
                    2594,
                    1576,
                    2349,
                    4018,
                    1473,
                    2373,
                    3276,
                    858,
                    2023,
                    2028,
                    3948,
                    895
                ],
                "np.expand_dims": [
                    2593,
                    2594,
                    390,
                    391
                ],
                "sparse_coo.row": [
                    2593,
                    390
                ],
                "sparse_coo.col": [
                    2594,
                    391
                ],
                "sparse_coo.data": [
                    393,
                    2595
                ],
                "sparse_coo.shape": [
                    2595,
                    394,
                    395
                ],
                "v._keras_shape": [
                    400,
                    402,
                    395
                ],
                "v._uses_learning_phase": [
                    403,
                    396
                ],
                "tf.Variable": [
                    398
                ],
                "tf.as_dtype": [
                    2374,
                    398,
                    2350,
                    729,
                    855,
                    760,
                    697,
                    892
                ],
                "name": [
                    513,
                    898,
                    732,
                    2472,
                    426,
                    811,
                    4171,
                    4187,
                    398,
                    786,
                    761,
                    824,
                    730,
                    698,
                    4155,
                    700,
                    861,
                    511
                ],
                "np.ndarray": [
                    399
                ],
                "value.shape": [
                    400,
                    2355,
                    2380
                ],
                "int_shape": [
                    2398,
                    1059,
                    1066,
                    3882,
                    4268,
                    402,
                    1940,
                    4215,
                    921,
                    1950
                ],
                "v.constraint": [
                    406
                ],
                "constraint": [
                    408,
                    406
                ],
                "v._constraint": [
                    408
                ],
                "tf.constant": [
                    1952,
                    2088,
                    426,
                    1802,
                    1806,
                    2030,
                    2831,
                    1942
                ],
                "shape": [
                    513,
                    514,
                    897,
                    3972,
                    3993,
                    426,
                    3949,
                    3994,
                    1907,
                    4019,
                    3992,
                    2136,
                    730,
                    698,
                    507,
                    860,
                    509,
                    511
                ],
                "is_tensor": [
                    2614,
                    2554,
                    468,
                    2606
                ],
                "tf_ops._TensorLike": [
                    476
                ],
                "tf_ops": [
                    2522,
                    476
                ],
                "tf_ops.is_dense_tensor_like": [
                    476
                ],
                "ndim": [
                    1155,
                    2054,
                    1162,
                    1163,
                    2962,
                    1174,
                    1057,
                    2725,
                    2726,
                    1833,
                    2731,
                    3883,
                    3885,
                    3886,
                    1072,
                    2737,
                    1842,
                    3897,
                    3913,
                    1751,
                    1885,
                    1138,
                    1139,
                    2939,
                    508,
                    509
                ],
                "_": [
                    2821,
                    2011,
                    509,
                    4269
                ],
                "sparse": [
                    510
                ],
                "tf.sparse_placeholder": [
                    511
                ],
                "tf.placeholder": [
                    513,
                    2379,
                    2355
                ],
                "x._keras_shape": [
                    514,
                    587
                ],
                "x._uses_learning_phase": [
                    515,
                    3020
                ],
                "x.op.type": [
                    529
                ],
                "x.op": [
                    529
                ],
                "tf.shape": [
                    1152,
                    2820,
                    1941,
                    2971,
                    2973,
                    1951,
                    3744,
                    1059,
                    1066,
                    562,
                    2872,
                    3518,
                    4039,
                    1755,
                    2780,
                    2021,
                    2793,
                    3186,
                    1149
                ],
                "as_list": [
                    589,
                    2035,
                    2005,
                    699,
                    3421,
                    731
                ],
                "x.get_shape": [
                    615,
                    2023,
                    1804,
                    589,
                    1808,
                    2035,
                    2005
                ],
                "dims": [
                    616,
                    617,
                    615
                ],
                "_dims": [
                    615
                ],
                "x.dtype.base_dtype.name": [
                    648
                ],
                "x.dtype.base_dtype": [
                    1472,
                    1473,
                    1378,
                    648,
                    1577,
                    1578,
                    3242,
                    3243,
                    3065,
                    1338
                ],
                "x.dtype": [
                    1472,
                    1473,
                    1378,
                    2374,
                    648,
                    1577,
                    1578,
                    1803,
                    3242,
                    3243,
                    2350,
                    1807,
                    2520,
                    2521,
                    1338,
                    3065
                ],
                "to_dense": [
                    669,
                    1894
                ],
                "tf_dtype": [
                    897,
                    2374,
                    892,
                    2379,
                    2350,
                    2355,
                    729,
                    761,
                    855,
                    760,
                    697,
                    698,
                    860,
                    730
                ],
                "tf.zeros": [
                    698,
                    3994
                ],
                "v.get_shape": [
                    699,
                    731
                ],
                "variable": [
                    898,
                    700,
                    761,
                    732,
                    861
                ],
                "tf.ones": [
                    3993,
                    730
                ],
                "tf.eye": [
                    761
                ],
                "size": [
                    761
                ],
                "tf.zeros_like": [
                    786
                ],
                "tf.ones_like": [
                    811,
                    2975
                ],
                "tf.identity": [
                    824,
                    2483
                ],
                "seed": [
                    897,
                    3970,
                    3971,
                    3973,
                    3990,
                    3991,
                    3992,
                    4017,
                    4018,
                    4019,
                    3275,
                    3276,
                    3279,
                    856,
                    858,
                    860,
                    3947,
                    3948,
                    3950,
                    893,
                    895
                ],
                "np.random.randint": [
                    3971,
                    3948,
                    3276,
                    4018,
                    3991,
                    858,
                    895
                ],
                "np.random": [
                    3971,
                    3948,
                    3276,
                    4018,
                    3991,
                    858,
                    895
                ],
                "tf.random_uniform_initializer": [
                    859
                ],
                "low": [
                    860
                ],
                "high": [
                    860
                ],
                "tf.random_normal_initializer": [
                    896
                ],
                "mean": [
                    897,
                    1730,
                    1869,
                    3949,
                    1776,
                    4019,
                    1748,
                    1725,
                    1758,
                    1727
                ],
                "scale": [
                    897
                ],
                "np.prod": [
                    921
                ],
                "tf.cast": [
                    1409,
                    1379,
                    3367,
                    2521,
                    4047,
                    2736,
                    1394,
                    3346,
                    953,
                    2938,
                    1339,
                    3325
                ],
                "tf.assign": [
                    969,
                    2467
                ],
                "new_x": [
                    969
                ],
                "tf.assign_add": [
                    982
                ],
                "increment": [
                    982
                ],
                "tf.assign_sub": [
                    995
                ],
                "decrement": [
                    995
                ],
                "moving_averages.assign_moving_average": [
                    1009
                ],
                "moving_averages": [
                    1009
                ],
                "momentum": [
                    1010
                ],
                "y": [
                    1155,
                    1157,
                    1670,
                    1159,
                    1163,
                    1167,
                    1683,
                    1057,
                    1066,
                    1072,
                    1075,
                    1079,
                    1592,
                    1081,
                    1605,
                    1618,
                    2518,
                    2520,
                    2521,
                    2522,
                    2524,
                    1631,
                    1644,
                    1139,
                    1657,
                    1149
                ],
                "x_shape": [
                    1058,
                    1061,
                    2021,
                    1063,
                    1064,
                    2031,
                    2032,
                    1074,
                    2035,
                    2036,
                    1077,
                    2005,
                    2007,
                    2037,
                    2009
                ],
                "i": [
                    1059,
                    1060,
                    1061,
                    1066,
                    1067,
                    1068,
                    4272,
                    4274,
                    4275,
                    2874,
                    4219,
                    4220,
                    4221
                ],
                "s": [
                    1059,
                    1063,
                    1066,
                    1070,
                    2011
                ],
                "tf.unstack": [
                    2760,
                    1066,
                    1059,
                    2755
                ],
                "x_shape.append": [
                    1061,
                    1063
                ],
                "y_shape": [
                    1065,
                    1068,
                    1070,
                    1071,
                    1075,
                    1077
                ],
                "y_shape.append": [
                    1068,
                    1070
                ],
                "y_permute_dim": [
                    1072,
                    1073,
                    1075
                ],
                "y_permute_dim.pop": [
                    1073
                ],
                "xt": [
                    1074,
                    1076
                ],
                "tf.reshape": [
                    1152,
                    2972,
                    1074,
                    1075,
                    1076,
                    2122,
                    4052,
                    2136,
                    4056,
                    4059,
                    1758,
                    1759,
                    1763,
                    1767,
                    3179,
                    2032,
                    3186,
                    1907,
                    1149
                ],
                "yt": [
                    1075,
                    1076
                ],
                "tf.transpose": [
                    1921,
                    3329,
                    1159,
                    3856,
                    3350,
                    3479,
                    4123,
                    3624,
                    3371,
                    2732,
                    3757,
                    1075,
                    2739,
                    1211,
                    3531,
                    3665,
                    4056,
                    4059,
                    3807,
                    2915,
                    4087,
                    3704,
                    3581
                ],
                "tf.matmul": [
                    1081,
                    1076,
                    1167
                ],
                "out": [
                    1157,
                    1159,
                    1167,
                    1173,
                    1174,
                    1079,
                    1175,
                    1081,
                    1082,
                    1176
                ],
                "tf.sparse_tensor_dense_matmul": [
                    1079
                ],
                "axes": [
                    2306,
                    2307,
                    1156,
                    1157,
                    2308,
                    1159,
                    1161,
                    1162,
                    1163,
                    2731,
                    2732,
                    2739,
                    2914,
                    2915,
                    1136,
                    1137,
                    1140,
                    1142,
                    1143,
                    1146
                ],
                "x_ndim": [
                    1169,
                    1138,
                    1170,
                    1172,
                    1142,
                    1147,
                    1148,
                    1150,
                    1151
                ],
                "y_ndim": [
                    1169,
                    1170,
                    1139,
                    1142,
                    1147,
                    1148,
                    1150,
                    1151
                ],
                "a": [
                    1559,
                    1143
                ],
                "diff": [
                    1152,
                    1154,
                    1168,
                    1173,
                    1148,
                    1149,
                    1151
                ],
                "tf.concat": [
                    1152,
                    2971,
                    1149,
                    1894
                ],
                "tf.reduce_sum": [
                    1157,
                    3143,
                    1159,
                    3149,
                    1278
                ],
                "tf.multiply": [
                    1157,
                    1159
                ],
                "adj_x": [
                    1162,
                    1165,
                    1167
                ],
                "adj_y": [
                    1163,
                    1166,
                    1167
                ],
                "idx": [
                    1170,
                    1172,
                    1173
                ],
                "tf.squeeze": [
                    2163,
                    4084,
                    1173,
                    4083,
                    3578
                ],
                "expand_dims": [
                    2738,
                    1175
                ],
                "tf.gather": [
                    1224
                ],
                "reference": [
                    1224
                ],
                "tf.reduce_max": [
                    1244
                ],
                "axis": [
                    1410,
                    1295,
                    1423,
                    3098,
                    1436,
                    1308,
                    1321,
                    1340,
                    1343,
                    1361,
                    1751,
                    1752,
                    2007,
                    2009,
                    1755,
                    1884,
                    1244,
                    2012,
                    1887,
                    3292,
                    1889,
                    1380,
                    1892,
                    1894,
                    2020,
                    2150,
                    2277,
                    1261,
                    2029,
                    1520,
                    1395,
                    2163,
                    1278
                ],
                "keepdims": [
                    1344,
                    1410,
                    1380,
                    1261,
                    1295,
                    1520,
                    1361,
                    1395,
                    1244,
                    1278
                ],
                "tf.reduce_min": [
                    1261
                ],
                "tf.reduce_prod": [
                    1295
                ],
                "tf.cumsum": [
                    1308
                ],
                "tf.cumprod": [
                    1321
                ],
                "tf.bool": [
                    1409,
                    1378,
                    2735,
                    2736,
                    4047,
                    1394,
                    2937,
                    1338,
                    2845
                ],
                "m": [
                    1340,
                    1341
                ],
                "tf.reduce_mean": [
                    1380,
                    1340,
                    1342
                ],
                "devs_squared": [
                    1341,
                    1342
                ],
                "tf.square": [
                    1448,
                    1341
                ],
                "tf.sqrt": [
                    1361,
                    1475
                ],
                "var": [
                    1730,
                    1869,
                    1776,
                    1361,
                    1759,
                    1748,
                    1725,
                    1727
                ],
                "tf.reduce_any": [
                    1395
                ],
                "tf.reduce_all": [
                    1410
                ],
                "tf.argmax": [
                    1423
                ],
                "tf.argmin": [
                    1436
                ],
                "tf.abs": [
                    1460
                ],
                "zero": [
                    1472,
                    1474,
                    3242,
                    3244
                ],
                "_to_tensor": [
                    1472,
                    1473,
                    3173,
                    3208,
                    1577,
                    1578,
                    3147,
                    3242,
                    3243,
                    3065
                ],
                "inf": [
                    1473,
                    1474
                ],
                "np.inf": [
                    1576,
                    1473
                ],
                "tf.clip_by_value": [
                    1474,
                    3174,
                    3209,
                    1579,
                    3148,
                    3244
                ],
                "tf.exp": [
                    1487
                ],
                "tf.log": [
                    3175,
                    4123,
                    3210,
                    3149,
                    4087,
                    1499
                ],
                "tf.reduce_logsumexp": [
                    1520
                ],
                "tf.round": [
                    1534
                ],
                "tf.sign": [
                    1546
                ],
                "tf.pow": [
                    1559
                ],
                "max_value": [
                    1573,
                    1574,
                    1575,
                    1576,
                    1578,
                    1579,
                    3064,
                    3065,
                    3066
                ],
                "min_value": [
                    1577,
                    1579,
                    1573,
                    1574
                ],
                "tf.equal": [
                    1592
                ],
                "tf.not_equal": [
                    1605
                ],
                "tf.greater": [
                    1618
                ],
                "tf.greater_equal": [
                    1631
                ],
                "tf.less": [
                    1644
                ],
                "tf.less_equal": [
                    1657
                ],
                "tf.maximum": [
                    1670
                ],
                "tf.minimum": [
                    3066,
                    1683
                ],
                "tf.sin": [
                    1695
                ],
                "tf.cos": [
                    1707
                ],
                "tf.nn.moments": [
                    1748,
                    1725
                ],
                "tf.nn": [
                    3845,
                    3080,
                    3849,
                    3212,
                    3470,
                    1810,
                    3225,
                    3098,
                    3618,
                    3110,
                    3753,
                    3122,
                    3257,
                    1725,
                    3901,
                    1727,
                    3909,
                    3527,
                    3659,
                    1869,
                    3279,
                    3152,
                    1748,
                    3796,
                    3925,
                    3800,
                    3292,
                    3432,
                    1769,
                    3180,
                    3308,
                    3696,
                    3060,
                    3572,
                    3062
                ],
                "reduction_axes": [
                    1794,
                    1833,
                    1834,
                    1836,
                    1839,
                    1842,
                    1848,
                    1748,
                    1844,
                    1752,
                    1725
                ],
                "normed": [
                    1776,
                    1769,
                    1730,
                    1727
                ],
                "tf.nn.batch_normalization": [
                    1769,
                    1869,
                    1727
                ],
                "beta": [
                    1728,
                    1764,
                    1767,
                    1835,
                    1805,
                    1806,
                    1839,
                    1869,
                    1843,
                    1813,
                    1847
                ],
                "gamma": [
                    1728,
                    1760,
                    1763,
                    1801,
                    1802,
                    1835,
                    1869,
                    1839,
                    1843,
                    1812,
                    1847
                ],
                "epsilon": [
                    1729,
                    3173,
                    3208,
                    3147,
                    1837,
                    1869,
                    1775,
                    1840,
                    1845,
                    1814,
                    4087,
                    1849,
                    4123
                ],
                "target_shape": [
                    1763,
                    1767,
                    1750,
                    1753,
                    1755,
                    1756,
                    1758,
                    1759
                ],
                "target_shape.append": [
                    1753,
                    1755
                ],
                "tf.stack": [
                    3745,
                    1756,
                    2812,
                    2277,
                    2056,
                    2793,
                    4040,
                    4041,
                    2802,
                    2872,
                    3508,
                    3733,
                    2136,
                    2780,
                    3519
                ],
                "broadcast_mean": [
                    1771,
                    1758
                ],
                "broadcast_var": [
                    1772,
                    1759
                ],
                "broadcast_gamma": [
                    1761,
                    1763,
                    1774
                ],
                "broadcast_beta": [
                    1773,
                    1765,
                    1767
                ],
                "normalization_axis": [
                    1808,
                    1795,
                    1804,
                    1798
                ],
                "tf_data_format": [
                    3331,
                    1796,
                    3332,
                    1799,
                    3847,
                    3467,
                    3851,
                    3855,
                    3347,
                    3476,
                    3478,
                    1815,
                    3352,
                    3353,
                    3735,
                    3611,
                    3737,
                    3613,
                    3748,
                    3622,
                    3623,
                    3368,
                    3755,
                    3756,
                    3373,
                    3374,
                    3510,
                    3512,
                    3522,
                    3652,
                    3654,
                    3529,
                    3530,
                    3786,
                    3788,
                    3663,
                    3664,
                    3798,
                    3802,
                    3806,
                    3429,
                    3431,
                    3559,
                    3561,
                    3438,
                    3694,
                    3702,
                    3703,
                    3576,
                    3835,
                    3580,
                    3837,
                    3326
                ],
                "tf.nn.fused_batch_norm": [
                    1810
                ],
                "_has_nchw_support": [
                    3328,
                    1834,
                    3370,
                    3349,
                    3900
                ],
                "_broadcast_normalize_batch_in_training": [
                    1835,
                    1847
                ],
                "_fused_normalize_batch_in_training": [
                    1838
                ],
                "_regular_normalize_batch_in_training": [
                    1843
                ],
                "rank": [
                    1885,
                    1886,
                    1887
                ],
                "tensors": [
                    1891,
                    1892,
                    1885,
                    1894
                ],
                "tf.sparse_concat": [
                    1892
                ],
                "pattern": [
                    1921,
                    2178,
                    2179,
                    2210,
                    2213,
                    2056,
                    2057,
                    2249,
                    2257,
                    2264,
                    2205
                ],
                "data_format": [
                    3606,
                    3607,
                    3608,
                    3609,
                    3611,
                    3623,
                    3647,
                    3648,
                    3649,
                    3650,
                    3652,
                    3664,
                    3689,
                    3690,
                    3691,
                    3692,
                    3694,
                    4209,
                    4210,
                    4211,
                    4212,
                    3703,
                    3728,
                    3729,
                    3730,
                    3731,
                    2199,
                    2200,
                    2201,
                    2202,
                    3737,
                    2204,
                    3735,
                    4261,
                    4262,
                    4263,
                    4264,
                    3756,
                    4278,
                    4290,
                    2243,
                    2244,
                    2245,
                    2246,
                    3781,
                    2248,
                    3782,
                    3783,
                    3784,
                    3786,
                    3806,
                    3830,
                    3831,
                    3832,
                    3833,
                    3835,
                    3327,
                    3855,
                    3348,
                    3878,
                    3879,
                    3880,
                    3369,
                    3881,
                    3887,
                    3892,
                    3898,
                    3907,
                    3914,
                    3919,
                    3416,
                    3417,
                    3418,
                    3419,
                    3428,
                    3462,
                    3463,
                    3464,
                    3465,
                    3467,
                    1939,
                    3478,
                    1949,
                    1958,
                    3503,
                    3504,
                    3505,
                    3506,
                    3510,
                    3512,
                    1977,
                    1982,
                    1988,
                    3530,
                    3554,
                    3555,
                    3556,
                    3557,
                    3559,
                    3580
                ],
                "original_shape": [
                    1954,
                    1955,
                    1940,
                    1946,
                    1947,
                    1950
                ],
                "new_shape": [
                    1952,
                    1953,
                    1941,
                    1942,
                    1944,
                    1951
                ],
                "astype": [
                    1952,
                    1942
                ],
                "np.array": [
                    1952,
                    1942
                ],
                "height_factor": [
                    1952,
                    1984,
                    1954,
                    1942,
                    1946,
                    1979
                ],
                "width_factor": [
                    1952,
                    1985,
                    1955,
                    1942,
                    1947,
                    1980
                ],
                "permute_dimensions": [
                    4227,
                    4291,
                    4293,
                    1943,
                    1945
                ],
                "tf.image.resize_nearest_neighbor": [
                    1944,
                    1953
                ],
                "tf.image": [
                    1944,
                    1953
                ],
                "x.set_shape": [
                    1954,
                    1946
                ],
                "output": [
                    4226,
                    4227,
                    3208,
                    3209,
                    3210,
                    3213,
                    2863,
                    2866,
                    2872,
                    2873,
                    1978,
                    1979,
                    1980,
                    1981,
                    2875,
                    1983,
                    1984,
                    1985,
                    1986,
                    4286,
                    4287,
                    4291,
                    4293,
                    3143,
                    3144,
                    4294,
                    2890,
                    3147,
                    3148,
                    2765,
                    2766,
                    2893,
                    3149,
                    3150,
                    2898,
                    3153,
                    2780,
                    2783,
                    2787,
                    3173,
                    3174,
                    3175,
                    3177,
                    3179,
                    2798,
                    3186,
                    2805,
                    2806,
                    2808
                ],
                "repeat_elements": [
                    1984,
                    1985,
                    1978,
                    1979,
                    1980,
                    1983
                ],
                "depth_factor": [
                    1978,
                    1983
                ],
                "splits": [
                    2009,
                    2011
                ],
                "tf.split": [
                    2009
                ],
                "x_rep": [
                    2022,
                    2025,
                    2032,
                    2036,
                    2037,
                    2038,
                    2011,
                    2012
                ],
                "rep": [
                    2024,
                    2011,
                    2029
                ],
                "concatenate": [
                    4224,
                    4059,
                    2012,
                    4285
                ],
                "auxiliary_axis": [
                    2024,
                    2020,
                    2022,
                    2028
                ],
                "tf.expand_dims": [
                    2150,
                    2022,
                    2055,
                    4044,
                    3567,
                    3568,
                    3569,
                    4089
                ],
                "reps": [
                    2023,
                    2024,
                    2025,
                    2028,
                    2029,
                    2030,
                    2031
                ],
                "np.ones": [
                    2023
                ],
                "tf.tile": [
                    2976,
                    2792,
                    2025,
                    2057,
                    4052,
                    2871,
                    4056,
                    2779,
                    2110
                ],
                "np.delete": [
                    2028
                ],
                "x_rep.set_shape": [
                    2036
                ],
                "x_rep._keras_shape": [
                    2037
                ],
                "n": [
                    2056,
                    2108,
                    2109,
                    2110
                ],
                "stop": [
                    2081,
                    2091
                ],
                "start": [
                    2083,
                    2084,
                    2087,
                    2088,
                    2089,
                    2091
                ],
                "tf.cond": [
                    2951,
                    2087
                ],
                "start.dtype": [
                    2088
                ],
                "result": [
                    2091,
                    2093,
                    2094
                ],
                "tf.range": [
                    4052,
                    2091,
                    4044,
                    4056
                ],
                "step": [
                    2091
                ],
                "cast": [
                    3178,
                    2093
                ],
                "prod": [
                    2136
                ],
                "padding": [
                    2177,
                    2178,
                    3846,
                    3850,
                    3469,
                    3475,
                    2196,
                    2197,
                    2198,
                    3612,
                    2207,
                    2208,
                    2211,
                    3620,
                    3747,
                    3754,
                    3389,
                    3390,
                    2239,
                    2240,
                    2241,
                    2242,
                    3391,
                    3392,
                    3394,
                    3395,
                    3521,
                    3528,
                    3653,
                    3787,
                    2252,
                    2253,
                    2254,
                    3661,
                    2259,
                    2260,
                    2261,
                    3797,
                    3801,
                    3422,
                    3426,
                    3427,
                    3560,
                    3437,
                    3695,
                    3701,
                    3574,
                    3836
                ],
                "tf.pad": [
                    2264,
                    2179,
                    2213
                ],
                "image_data_format": [
                    3648,
                    3555,
                    2244,
                    3782,
                    3463,
                    3879,
                    4262,
                    3690,
                    3831,
                    3504,
                    3729,
                    4210,
                    3607,
                    2200,
                    3417
                ],
                "tf.one_hot": [
                    2292
                ],
                "num_classes": [
                    2292
                ],
                "tf.reverse": [
                    2308
                ],
                "x.eval": [
                    2323
                ],
                "ops": [
                    2336,
                    2335
                ],
                "run": [
                    2336,
                    2386,
                    2359
                ],
                "np.asarray": [
                    2569,
                    2564,
                    2373,
                    2349
                ],
                "x.dtype.name.split": [
                    2374,
                    2350
                ],
                "x.dtype.name": [
                    2374,
                    2350
                ],
                "assign_placeholder": [
                    2376,
                    2379,
                    2381,
                    2382,
                    2352,
                    2385,
                    2355,
                    2356,
                    2357,
                    2359
                ],
                "x._assign_placeholder": [
                    2352,
                    2376,
                    2357,
                    2382
                ],
                "assign_op": [
                    2377,
                    2381,
                    2383,
                    2384,
                    2353,
                    2356,
                    2358,
                    2359
                ],
                "x._assign_op": [
                    2377,
                    2353,
                    2358,
                    2383
                ],
                "x.assign": [
                    2356,
                    2381
                ],
                "tuples": [
                    2369,
                    2372
                ],
                "assign_ops": [
                    2384,
                    2370,
                    2386
                ],
                "feed_dict": [
                    2371,
                    2596,
                    2599,
                    2385,
                    2386,
                    2588
                ],
                "assign_ops.append": [
                    2384
                ],
                "tf.Print": [
                    2420
                ],
                "message": [
                    2420
                ],
                "updates": [
                    2464,
                    2457,
                    2450,
                    2641
                ],
                "inputs": [
                    2816,
                    2820,
                    2821,
                    2827,
                    2830,
                    2451,
                    2586,
                    2460,
                    2589,
                    2725,
                    2732,
                    2606,
                    2610,
                    2612,
                    2614,
                    4279,
                    2618,
                    4282,
                    2748,
                    2755,
                    2641,
                    2543,
                    2551,
                    4222
                ],
                "outputs": [
                    2914,
                    2915,
                    2821,
                    2917,
                    2823,
                    2641,
                    2802,
                    2454,
                    2812,
                    2461,
                    2911
                ],
                "self.inputs": [
                    2605,
                    2460,
                    2589,
                    2551
                ],
                "self.outputs": [
                    2528,
                    2597,
                    2601,
                    2583,
                    2461,
                    2462
                ],
                "tf.control_dependencies": [
                    2462
                ],
                "updates_ops": [
                    2471,
                    2467,
                    2470,
                    2463
                ],
                "update": [
                    2464,
                    2465,
                    2466,
                    2470
                ],
                "p": [
                    3992,
                    2466,
                    2467
                ],
                "new_p": [
                    2466,
                    2467
                ],
                "updates_ops.append": [
                    2467,
                    2470
                ],
                "self.updates_op": [
                    2531,
                    2597,
                    2471
                ],
                "tf.group": [
                    2471
                ],
                "self.name": [
                    2472
                ],
                "self.feed_dict": [
                    2566,
                    2567,
                    2569,
                    2474,
                    2514,
                    2515,
                    2588
                ],
                "session_kwargs.pop": [
                    2474,
                    2476
                ],
                "session_kwargs": [
                    2474,
                    2476,
                    2484,
                    2485,
                    2488
                ],
                "self.fetches": [
                    2528,
                    2597,
                    2476,
                    2477,
                    2478,
                    2483
                ],
                "self.session_kwargs": [
                    2600,
                    2484
                ],
                "session_kwargs.keys": [
                    2488
                ],
                "self._callable_fn": [
                    2536,
                    2489,
                    2573,
                    2582
                ],
                "self._feed_arrays": [
                    2537,
                    2490,
                    2574
                ],
                "self._feed_symbols": [
                    2576,
                    2538,
                    2491
                ],
                "self._symbol_vals": [
                    2539,
                    2492,
                    2575
                ],
                "self._session": [
                    2577,
                    2540,
                    2493
                ],
                "callable_opts": [
                    2529,
                    2531,
                    2533,
                    2510,
                    2513,
                    2516,
                    2519
                ],
                "config_pb2.CallableOptions": [
                    2510
                ],
                "config_pb2": [
                    2510
                ],
                "feed_arrays": [
                    2537,
                    2574,
                    2512,
                    2578,
                    2547,
                    2559
                ],
                "callable_opts.feed.append": [
                    2513,
                    2516
                ],
                "callable_opts.feed": [
                    2513,
                    2516
                ],
                "key": [
                    2567,
                    2569,
                    2570,
                    2637,
                    2638,
                    2639,
                    2515,
                    2516
                ],
                "self.feed_dict.keys": [
                    2515,
                    2567
                ],
                "key.name": [
                    2516
                ],
                "feed_symbols": [
                    2538,
                    2576,
                    2579,
                    2549,
                    2518,
                    2556
                ],
                "symbol_vals": [
                    2539,
                    2575,
                    2580,
                    2550,
                    2518,
                    2557
                ],
                "connection": [
                    2525,
                    2526,
                    2519
                ],
                "callable_opts.tensor_connection.add": [
                    2519
                ],
                "callable_opts.tensor_connection": [
                    2519
                ],
                "y.dtype": [
                    2520
                ],
                "from_tensor": [
                    2522,
                    2523,
                    2524,
                    2525
                ],
                "tf_ops._as_graph_element": [
                    2522
                ],
                "connection.from_tensor": [
                    2525
                ],
                "from_tensor.name": [
                    2525
                ],
                "connection.to_tensor": [
                    2526
                ],
                "callable_opts.fetch.append": [
                    2529
                ],
                "callable_opts.fetch": [
                    2529
                ],
                "callable_opts.target.append": [
                    2531
                ],
                "callable_opts.target": [
                    2531
                ],
                "self.updates_op.name": [
                    2531
                ],
                "callable_fn": [
                    2536,
                    2533
                ],
                "session._make_callable_from_options": [
                    2533
                ],
                "array_vals": [
                    2568,
                    2563,
                    2548,
                    2582
                ],
                "feed_symbols.append": [
                    2556
                ],
                "symbol_vals.append": [
                    2557
                ],
                "feed_arrays.append": [
                    2559
                ],
                "array_vals.append": [
                    2568,
                    2563
                ],
                "tensor.dtype.base_dtype.name": [
                    2565
                ],
                "tensor.dtype.base_dtype": [
                    2565
                ],
                "tensor.dtype": [
                    2565
                ],
                "key.dtype.base_dtype.name": [
                    2570
                ],
                "key.dtype.base_dtype": [
                    2570
                ],
                "key.dtype": [
                    2570
                ],
                "self._make_callable": [
                    2578
                ],
                "fetched": [
                    2582,
                    2583
                ],
                "self.feed_dict.copy": [
                    2588
                ],
                "fetches": [
                    2597,
                    2599
                ],
                "updated": [
                    2601,
                    2599
                ],
                "self._legacy_call": [
                    2610,
                    2618
                ],
                "self._call": [
                    2612
                ],
                "kwargs": [
                    2641,
                    2636,
                    2637
                ],
                "has_arg": [
                    2638
                ],
                "tf.Session.run": [
                    2638
                ],
                "Function.__init__": [
                    2638
                ],
                "Function": [
                    2641,
                    2638
                ],
                "msg": [
                    2640,
                    2639
                ],
                "tf.gradients": [
                    2654
                ],
                "loss": [
                    2654
                ],
                "tf.stop_gradient": [
                    2669,
                    2671
                ],
                "inputs.get_shape": [
                    2748,
                    2725
                ],
                "mask": [
                    2848,
                    2759,
                    2760,
                    2734,
                    2735,
                    2736,
                    2737,
                    2738,
                    2739,
                    2833,
                    2842
                ],
                "mask.dtype": [
                    2735
                ],
                "mask.get_shape": [
                    2737
                ],
                "constants": [
                    2821,
                    2892,
                    2765,
                    2865,
                    2805,
                    2741,
                    2742
                ],
                "uses_learning_phase": [
                    2916,
                    3003,
                    3019,
                    2895,
                    2767,
                    2868,
                    2807,
                    2745,
                    3001
                ],
                "unroll": [
                    2747
                ],
                "states": [
                    2818,
                    2790,
                    2891,
                    2797,
                    2765,
                    2799,
                    2864,
                    2896,
                    2834,
                    2805,
                    2869,
                    2873,
                    2904,
                    2809,
                    2874,
                    2751
                ],
                "initial_states": [
                    2818,
                    2821,
                    2751
                ],
                "successive_states": [
                    2752,
                    2799,
                    2801,
                    2809,
                    2811
                ],
                "successive_outputs": [
                    2753,
                    2785,
                    2798,
                    2800,
                    2802,
                    2808,
                    2810,
                    2812,
                    2782
                ],
                "input_list": [
                    2755,
                    2764,
                    2757,
                    2804
                ],
                "go_backwards": [
                    2761,
                    2756,
                    2841,
                    2815
                ],
                "input_list.reverse": [
                    2757
                ],
                "mask_list": [
                    2760,
                    2762,
                    2764
                ],
                "mask_list.reverse": [
                    2762
                ],
                "inp": [
                    2805,
                    2764,
                    2765,
                    2804
                ],
                "mask_t": [
                    2792,
                    2764,
                    2862,
                    2871,
                    2779
                ],
                "new_states": [
                    2917,
                    2790,
                    2890,
                    2765,
                    2863,
                    2896,
                    2801,
                    2899,
                    2869,
                    2874,
                    2811,
                    2876,
                    2909
                ],
                "step_function": [
                    2821,
                    2890,
                    2765,
                    2863,
                    2805
                ],
                "tiled_mask_t": [
                    2787,
                    2792,
                    2794,
                    2871,
                    2873,
                    2874,
                    2779
                ],
                "prev_output": [
                    2785,
                    2787,
                    2783
                ],
                "zeros_like": [
                    2783
                ],
                "tf.where": [
                    2977,
                    2787,
                    2794,
                    3084,
                    3992,
                    2873,
                    2874,
                    2975
                ],
                "return_states": [
                    2797,
                    2794,
                    2789
                ],
                "state": [
                    2790,
                    2796,
                    2896,
                    2897,
                    2869,
                    2870
                ],
                "new_state": [
                    2790,
                    2793,
                    2795,
                    2896,
                    2897,
                    2869,
                    2870
                ],
                "return_states.append": [
                    2794
                ],
                "successive_outputs.append": [
                    2808,
                    2798
                ],
                "successive_states.append": [
                    2809,
                    2799
                ],
                "last_output": [
                    2912,
                    2916,
                    2917,
                    2800,
                    2810
                ],
                "reverse": [
                    2816,
                    4057,
                    2842
                ],
                "time_steps": [
                    2820,
                    2824,
                    2828,
                    2902,
                    2846
                ],
                "output_ta": [
                    2912,
                    2822,
                    2904,
                    2908,
                    2911
                ],
                "tensor_array_ops.TensorArray": [
                    2826,
                    2844,
                    2822
                ],
                "tensor_array_ops": [
                    2826,
                    2844,
                    2822
                ],
                "outputs.dtype": [
                    2823
                ],
                "input_ta": [
                    2889,
                    2826,
                    2861,
                    2830
                ],
                "inputs.dtype": [
                    2827
                ],
                "input_ta.unstack": [
                    2830
                ],
                "time": [
                    2889,
                    2861,
                    2862,
                    2831,
                    2898,
                    2899,
                    2902,
                    2904,
                    2875,
                    2876
                ],
                "mask_ta": [
                    2848,
                    2844,
                    2862
                ],
                "mask_ta.unstack": [
                    2848
                ],
                "current_input": [
                    2889,
                    2890,
                    4045,
                    2861,
                    2863
                ],
                "input_ta.read": [
                    2889,
                    2861
                ],
                "mask_ta.read": [
                    2862
                ],
                "new_state.set_shape": [
                    2897,
                    2870
                ],
                "state.get_shape": [
                    2897,
                    2870
                ],
                "output_ta_t": [
                    2898,
                    2875,
                    2876,
                    2899
                ],
                "output_ta_t.write": [
                    2898,
                    2875
                ],
                "final_outputs": [
                    2907,
                    2908,
                    2901,
                    2909
                ],
                "control_flow_ops.while_loop": [
                    2901
                ],
                "control_flow_ops": [
                    2901
                ],
                "_step": [
                    2903
                ],
                "last_time": [
                    2912,
                    2907
                ],
                "output_ta.stack": [
                    2911
                ],
                "output_ta.read": [
                    2912
                ],
                "outputs.get_shape": [
                    2914
                ],
                "last_output._uses_learning_phase": [
                    2916
                ],
                "condition.dtype": [
                    2937
                ],
                "condition": [
                    2976,
                    2977,
                    2971,
                    2951,
                    2937,
                    2938,
                    2939,
                    2972
                ],
                "cond_ndim": [
                    2963,
                    2967,
                    2969,
                    2970,
                    2939,
                    2940
                ],
                "then_expression": [
                    2945,
                    2977,
                    2958,
                    2959,
                    2973,
                    2962,
                    2941,
                    2943
                ],
                "then_expression_fn": [
                    2952,
                    2945
                ],
                "else_expression": [
                    2977,
                    2946,
                    2948,
                    2950,
                    2960,
                    2961
                ],
                "else_expression_fn": [
                    2953,
                    2950
                ],
                "expr_ndim": [
                    2968,
                    2962,
                    2963,
                    2970
                ],
                "ndim_diff": [
                    2970,
                    2971
                ],
                "cond_shape": [
                    2971,
                    2972,
                    2974
                ],
                "expr_shape": [
                    2973,
                    2974,
                    2975
                ],
                "shape_diff": [
                    2974,
                    2975
                ],
                "tile_shape": [
                    2976,
                    2975
                ],
                "training": [
                    3041,
                    3011,
                    3018,
                    2999,
                    3000,
                    3005
                ],
                "learning_phase": [
                    3000
                ],
                "alt": [
                    3041,
                    3012,
                    3013,
                    3015,
                    3018
                ],
                "switch": [
                    3018
                ],
                "in_train_phase": [
                    3041
                ],
                "alpha": [
                    3081,
                    3059,
                    3060,
                    3084
                ],
                "tf.nn.leaky_relu": [
                    3060
                ],
                "tf.nn.relu": [
                    3062
                ],
                "res": [
                    3080,
                    3082,
                    3084,
                    3180,
                    3186,
                    3188
                ],
                "tf.nn.elu": [
                    3080
                ],
                "tf.nn.softmax": [
                    3098
                ],
                "tf.nn.softplus": [
                    3110
                ],
                "tf.nn.softsign": [
                    3122
                ],
                "from_logits": [
                    3172,
                    3141,
                    3206
                ],
                "output.get_shape": [
                    3144,
                    3177,
                    3150
                ],
                "_epsilon": [
                    3173,
                    3174,
                    3208,
                    3209,
                    3147,
                    3148
                ],
                "output.dtype.base_dtype": [
                    3208,
                    3147,
                    3173
                ],
                "output.dtype": [
                    3208,
                    3147,
                    3173
                ],
                "target": [
                    3152,
                    3178,
                    3212,
                    3149
                ],
                "tf.nn.softmax_cross_entropy_with_logits": [
                    3152
                ],
                "output_shape": [
                    3732,
                    3733,
                    3738,
                    3739,
                    3740,
                    3741,
                    3742,
                    3743,
                    3744,
                    3745,
                    3753,
                    4267,
                    3507,
                    3508,
                    3513,
                    3514,
                    3515,
                    3516,
                    3517,
                    3518,
                    3519,
                    3527,
                    3177,
                    3179,
                    3183
                ],
                "targets": [
                    3178,
                    3308,
                    3181
                ],
                "flatten": [
                    3178
                ],
                "logits": [
                    3179,
                    3182
                ],
                "tf.nn.sparse_softmax_cross_entropy_with_logits": [
                    3180
                ],
                "tf.nn.sigmoid_cross_entropy_with_logits": [
                    3212
                ],
                "tf.nn.sigmoid": [
                    3225
                ],
                "one": [
                    3243,
                    3244
                ],
                "tf.nn.tanh": [
                    3257
                ],
                "retain_prob": [
                    3274,
                    3279
                ],
                "level": [
                    3274
                ],
                "tf.nn.dropout": [
                    3279
                ],
                "noise_shape": [
                    3279
                ],
                "tf.nn.l2_normalize": [
                    3292
                ],
                "tf.nn.in_top_k": [
                    3308
                ],
                "predictions": [
                    3308
                ],
                "k": [
                    3308
                ],
                "kernel_shape": [
                    3424,
                    4268,
                    4269,
                    4215,
                    4216,
                    3421
                ],
                "kernel.get_shape": [
                    3421
                ],
                "kernel": [
                    4226,
                    3527,
                    3753,
                    3434,
                    4268,
                    3472,
                    3698,
                    4215,
                    3421,
                    4286
                ],
                "left_pad": [
                    3424,
                    3425
                ],
                "dilation_rate": [
                    3424,
                    3621,
                    3435,
                    3662,
                    3473,
                    3570,
                    3699,
                    3575
                ],
                "temporal_padding": [
                    3425
                ],
                "_preprocess_padding": [
                    3521,
                    3427,
                    3747,
                    3653,
                    3836,
                    3560,
                    3787,
                    3469,
                    3695,
                    3612
                ],
                "tf.nn.convolution": [
                    3432,
                    3696,
                    3470
                ],
                "strides": [
                    3841,
                    3845,
                    3849,
                    3474,
                    3614,
                    3616,
                    3619,
                    3749,
                    3751,
                    3753,
                    4266,
                    3523,
                    3525,
                    3527,
                    3655,
                    3657,
                    3660,
                    3789,
                    3792,
                    3796,
                    3800,
                    3563,
                    3436,
                    3566,
                    3700,
                    3573,
                    4214,
                    3838
                ],
                "_preprocess_conv2d_input": [
                    3652,
                    3786,
                    3467,
                    3510,
                    3611
                ],
                "tf.nn.conv2d_transpose": [
                    3527
                ],
                "_preprocess_conv1d_input": [
                    3559
                ],
                "spatial_start_dim": [
                    3562,
                    3565,
                    3578,
                    3567
                ],
                "depthwise_kernel": [
                    3568,
                    3618,
                    3659,
                    3572
                ],
                "pointwise_kernel": [
                    3569,
                    3618,
                    3572
                ],
                "tf.nn.separable_conv2d": [
                    3618,
                    3572
                ],
                "tf.nn.depthwise_conv2d": [
                    3659
                ],
                "_preprocess_conv3d_input": [
                    3835,
                    3694,
                    3735
                ],
                "tf.nn.conv3d_transpose": [
                    3753
                ],
                "pool_size": [
                    3842,
                    3845,
                    3849,
                    3790,
                    3793,
                    3796,
                    3800,
                    3839
                ],
                "pool_mode": [
                    3844,
                    3848,
                    3853,
                    3795,
                    3799,
                    3804
                ],
                "tf.nn.max_pool": [
                    3796
                ],
                "tf.nn.avg_pool": [
                    3800
                ],
                "tf.nn.max_pool3d": [
                    3845
                ],
                "tf.nn.avg_pool3d": [
                    3849
                ],
                "bias_shape": [
                    3882,
                    3883,
                    3885,
                    3888,
                    3889,
                    3891,
                    3893,
                    3894,
                    3896,
                    3899,
                    3904,
                    3906,
                    3908,
                    3912,
                    3915,
                    3916,
                    3918,
                    3920,
                    3921,
                    3923
                ],
                "bias": [
                    3904,
                    3906,
                    3909,
                    3912,
                    3882,
                    3916,
                    3918,
                    3889,
                    3921,
                    3891,
                    3923,
                    3925,
                    3894,
                    3896,
                    3901
                ],
                "reshape": [
                    3904,
                    3906,
                    3912,
                    3916,
                    3918,
                    3889,
                    3921,
                    3891,
                    3923,
                    3894,
                    4279,
                    3896,
                    4282,
                    4222,
                    4287
                ],
                "tf.nn.bias_add": [
                    3925,
                    3909,
                    3901
                ],
                "tf.random_normal": [
                    3949
                ],
                "stddev": [
                    4019,
                    3949
                ],
                "tf.random_uniform": [
                    3992,
                    3972
                ],
                "minval": [
                    3972
                ],
                "maxval": [
                    3972
                ],
                "tf.truncated_normal": [
                    4019
                ],
                "label_shape": [
                    4039,
                    4040,
                    4041,
                    4044,
                    4047,
                    4052,
                    4053,
                    4056,
                    4057,
                    4063
                ],
                "labels": [
                    4061,
                    4039
                ],
                "num_batches_tns": [
                    4040,
                    4052
                ],
                "max_num_labels_tns": [
                    4041,
                    4057,
                    4045
                ],
                "tf.fill": [
                    4044,
                    4047
                ],
                "init": [
                    4049,
                    4047
                ],
                "dense_mask": [
                    4048,
                    4058,
                    4050,
                    4054
                ],
                "functional_ops.scan": [
                    4048
                ],
                "functional_ops": [
                    4048
                ],
                "range_less_than": [
                    4048
                ],
                "label_lengths": [
                    4048
                ],
                "label_array": [
                    4052,
                    4054
                ],
                "label_ind": [
                    4059,
                    4054
                ],
                "tf.boolean_mask": [
                    4058,
                    4054
                ],
                "batch_array": [
                    4056,
                    4058
                ],
                "batch_ind": [
                    4058,
                    4059
                ],
                "vals_sparse": [
                    4061,
                    4063
                ],
                "tf.gather_nd": [
                    4061
                ],
                "tf.to_int64": [
                    4063
                ],
                "label_length": [
                    4083,
                    4085
                ],
                "tf.to_int32": [
                    4083,
                    4084,
                    4085,
                    4124
                ],
                "input_length": [
                    4129,
                    4133,
                    4084,
                    4091,
                    4124
                ],
                "sparse_labels": [
                    4090,
                    4085
                ],
                "ctc_label_dense_to_sparse": [
                    4085
                ],
                "y_true": [
                    4085
                ],
                "y_pred": [
                    4128,
                    4132,
                    4087,
                    4089,
                    4123
                ],
                "ctc.ctc_loss": [
                    4089
                ],
                "ctc": [
                    4089,
                    4131,
                    4127
                ],
                "greedy": [
                    4126
                ],
                "decoded": [
                    4137,
                    4131,
                    4127
                ],
                "log_prob": [
                    4138,
                    4131,
                    4127
                ],
                "ctc.ctc_greedy_decoder": [
                    4127
                ],
                "ctc.ctc_beam_search_decoder": [
                    4131
                ],
                "beam_width": [
                    4133
                ],
                "top_paths": [
                    4134
                ],
                "decoded_dense": [
                    4136,
                    4138
                ],
                "tf.sparse_to_dense": [
                    4136
                ],
                "st.indices": [
                    4136
                ],
                "st": [
                    4136,
                    4137
                ],
                "st.dense_shape": [
                    4136
                ],
                "st.values": [
                    4136
                ],
                "tf.map_fn": [
                    4155
                ],
                "fn": [
                    4171,
                    4155,
                    4187
                ],
                "elems": [
                    4171,
                    4155,
                    4187
                ],
                "tf.foldl": [
                    4171
                ],
                "initializer": [
                    4187,
                    4171
                ],
                "tf.foldr": [
                    4187
                ],
                "stride": [
                    4220,
                    4221,
                    4214
                ],
                "output_length": [
                    4216,
                    4219
                ],
                "feature_dim": [
                    4269,
                    4216,
                    4283,
                    4280,
                    4223
                ],
                "filters": [
                    4216,
                    4269,
                    4288
                ],
                "xs": [
                    4224,
                    4282,
                    4271,
                    4279,
                    4218,
                    4285,
                    4222
                ],
                "slice_length": [
                    4220,
                    4222
                ],
                "kernel_size": [
                    4275,
                    4221,
                    4277
                ],
                "xs.append": [
                    4282,
                    4222,
                    4279
                ],
                "x_aggregate": [
                    4224,
                    4226,
                    4285,
                    4286
                ],
                "batch_dot": [
                    4226,
                    4286
                ],
                "stride_row": [
                    4274,
                    4266,
                    4275
                ],
                "stride_col": [
                    4266,
                    4276,
                    4277
                ],
                "output_row": [
                    4272,
                    4267,
                    4288
                ],
                "output_col": [
                    4288,
                    4273,
                    4267
                ],
                "j": [
                    4273,
                    4276,
                    4277
                ],
                "slice_row": [
                    4282,
                    4274,
                    4279
                ],
                "slice_col": [
                    4282,
                    4276,
                    4279
                ]
            }
        },
        "test_data": [
            {
                "test_path": "/Volumes/SSD2T/bgp_envs_non_pandas/repos/keras_26/tests/keras/backend/backend_test.py",
                "test_function": "test_rnn_additional_states",
                "test_function_code": "    def test_rnn_additional_states(self):\n        # implement a simple RNN with an additional state\n        # whose shape is different from that of the output\n        num_samples = 4\n        input_dim = 5\n        output_dim = 3\n        timesteps = 6\n\n        _, x = parse_shape_or_val((num_samples, timesteps, input_dim))\n        _, h0 = parse_shape_or_val((num_samples, output_dim))\n        _, wi = parse_shape_or_val((input_dim, output_dim))\n        _, wh = parse_shape_or_val((output_dim, output_dim))\n        mask = np.random.randint(2, size=(num_samples, timesteps))\n\n        x_k = K.variable(x)\n        h0_k = [K.variable(h0), K.variable(np.concatenate([h0, h0], axis=-1))]\n        wi_k = K.variable(wi)\n        wh_k = K.variable(wh)\n        mask_k = K.variable(mask)\n\n        def rnn_fn(x_k, h_k):\n            assert len(h_k) == 2\n            y_k = K.dot(x_k, wi_k) + K.dot(h_k[0], wh_k)\n            return y_k, [y_k, K.concatenate([y_k, y_k], axis=-1)]\n\n        # test default setup\n        last_output_list = []\n        outputs_list = []\n        state_list = []\n\n        kwargs_list = [\n            {'go_backwards': False, 'mask': None},\n            {'go_backwards': False, 'mask': None, 'unroll': True, 'input_length': timesteps},\n            {'go_backwards': True, 'mask': None},\n            {'go_backwards': True, 'mask': None, 'unroll': True, 'input_length': timesteps},\n            {'go_backwards': False, 'mask': mask_k},\n            {'go_backwards': False, 'mask': mask_k, 'unroll': True, 'input_length': timesteps},\n        ]\n\n        for (i, kwargs) in enumerate(kwargs_list):\n            last_y1, y1, h1 = reference_operations.rnn(x, [wi, wh, None], h0, **kwargs)\n            last_y2, y2, h2 = K.rnn(rnn_fn, x_k, h0_k, **kwargs)\n\n            assert len(h2) == 2\n            last_y2 = K.eval(last_y2)\n            y2 = K.eval(y2)\n            h11 = h1[:, -1]\n            h12 = np.concatenate([h1[:, -1], h1[:, -1]], axis=-1)\n            h21 = K.eval(h2[0])\n            h22 = K.eval(h2[1])\n\n            if kwargs['mask'] is not None:\n                last_y1 = last_y1 * np.expand_dims(mask[:, -1], -1)\n                last_y2 = last_y2 * np.expand_dims(mask[:, -1], -1)\n                y1 = y1 * np.expand_dims(mask, -1)\n                y2 = y2 * np.expand_dims(mask, -1)\n                h11 = h11 * np.expand_dims(mask[:, -1], -1)\n                h21 = h21 * np.expand_dims(mask[:, -1], -1)\n                h12 = h12 * np.expand_dims(mask[:, -1], -1)\n                h22 = h22 * np.expand_dims(mask[:, -1], -1)\n\n            last_output_list.append(last_y2)\n            outputs_list.append(y2)\n            state_list.append((h21, h22))\n\n            if i % 2 == 0:\n                assert_allclose(last_y1, last_y2, atol=1e-05)\n                assert_allclose(y1, y2, atol=1e-05)\n                assert_allclose(h11, h21, atol=1e-05)\n                assert_allclose(h12, h22, atol=1e-05)\n            else:\n                assert_allclose(last_output_list[i - 1], last_output_list[i], atol=1e-05)\n                assert_allclose(outputs_list[i - 1], outputs_list[i], atol=1e-05)\n                assert_allclose(state_list[i - 1][0], state_list[i][0], atol=1e-05)\n                assert_allclose(state_list[i - 1][1], state_list[i][1], atol=1e-05)",
                "test_error": "ValueError: Dimension 1 in both shapes must be equal, but are 6 and 3. Shapes are [4,6] and [4,3]. for 'while_2/Select_2' (op: 'Select') with input shapes: [4,3], [4,6], [4,6].",
                "full_test_error": "graph = <tensorflow.python.framework.ops.Graph object at 0x138ae5dd0>\nnode_def = name: \"while_2/Select_2\"\nop: \"Select\"\nattr {\n  key: \"T\"\n  value {\n    type: DT_FLOAT\n  }\n}\n\ninputs = [<tf.Tensor 'while_2/Tile:0' shape=(4, 3) dtype=bool>, <tf.Tensor 'while_2/concat:0' shape=(4, 6) dtype=float32>, <tf.Tensor 'while_2/Identity_3:0' shape=(4, 6) dtype=float32>]\ncontrol_inputs = []\n\n    def _create_c_op(graph, node_def, inputs, control_inputs):\n      \"\"\"Creates a TF_Operation.\n    \n      Args:\n        graph: a `Graph`.\n        node_def: `node_def_pb2.NodeDef` for the operation to create.\n        inputs: A list of `Tensor`s (corresponding to scalar inputs) and lists of\n          `Tensor`s (corresponding to sequence inputs, e.g. \"int64 * N\",\n          \"list(int64)\"). The length of the list should be equal to the number of\n          inputs specified by this operation's op def.\n        control_inputs: A list of `Operation`s to set as control dependencies.\n    \n      Returns:\n        A wrapped TF_Operation*.\n      \"\"\"\n      # pylint: disable=protected-access\n      op_desc = c_api.TF_NewOperation(graph._c_graph, compat.as_str(node_def.op),\n                                      compat.as_str(node_def.name))\n      if node_def.device:\n        c_api.TF_SetDevice(op_desc, compat.as_str(node_def.device))\n      # Add inputs\n      for op_input in inputs:\n        if isinstance(op_input, (list, tuple)):\n          c_api.TF_AddInputList(op_desc, [t._as_tf_output() for t in op_input])\n        else:\n          c_api.TF_AddInput(op_desc, op_input._as_tf_output())\n    \n      # Add control inputs\n      for control_input in control_inputs:\n        c_api.TF_AddControlInput(op_desc, control_input._c_op)\n      # pylint: enable=protected-access\n    \n      # Add attrs\n      for name, attr_value in node_def.attr.items():\n        serialized = attr_value.SerializeToString()\n        # TODO(skyewm): this creates and deletes a new TF_Status for every attr.\n        # It might be worth creating a convenient way to re-use the same status.\n        c_api.TF_SetAttrValueProto(op_desc, compat.as_str(name), serialized)\n    \n      try:\n>       c_op = c_api.TF_FinishOperation(op_desc)\nE       tensorflow.python.framework.errors_impl.InvalidArgumentError: Dimension 1 in both shapes must be equal, but are 6 and 3. Shapes are [4,6] and [4,3]. for 'while_2/Select_2' (op: 'Select') with input shapes: [4,3], [4,6], [4,6].\n\n../../envs/keras_26/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1864: InvalidArgumentError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <backend_test.TestBackend object at 0x139196910>\n\n    def test_rnn_additional_states(self):\n        # implement a simple RNN with an additional state\n        # whose shape is different from that of the output\n        num_samples = 4\n        input_dim = 5\n        output_dim = 3\n        timesteps = 6\n    \n        _, x = parse_shape_or_val((num_samples, timesteps, input_dim))\n        _, h0 = parse_shape_or_val((num_samples, output_dim))\n        _, wi = parse_shape_or_val((input_dim, output_dim))\n        _, wh = parse_shape_or_val((output_dim, output_dim))\n        mask = np.random.randint(2, size=(num_samples, timesteps))\n    \n        x_k = K.variable(x)\n        h0_k = [K.variable(h0), K.variable(np.concatenate([h0, h0], axis=-1))]\n        wi_k = K.variable(wi)\n        wh_k = K.variable(wh)\n        mask_k = K.variable(mask)\n    \n        def rnn_fn(x_k, h_k):\n            assert len(h_k) == 2\n            y_k = K.dot(x_k, wi_k) + K.dot(h_k[0], wh_k)\n            return y_k, [y_k, K.concatenate([y_k, y_k], axis=-1)]\n    \n        # test default setup\n        last_output_list = []\n        outputs_list = []\n        state_list = []\n    \n        kwargs_list = [\n            {'go_backwards': False, 'mask': None},\n            {'go_backwards': False, 'mask': None, 'unroll': True, 'input_length': timesteps},\n            {'go_backwards': True, 'mask': None},\n            {'go_backwards': True, 'mask': None, 'unroll': True, 'input_length': timesteps},\n            {'go_backwards': False, 'mask': mask_k},\n            {'go_backwards': False, 'mask': mask_k, 'unroll': True, 'input_length': timesteps},\n        ]\n    \n        for (i, kwargs) in enumerate(kwargs_list):\n            last_y1, y1, h1 = reference_operations.rnn(x, [wi, wh, None], h0, **kwargs)\n>           last_y2, y2, h2 = K.rnn(rnn_fn, x_k, h0_k, **kwargs)\n\ntests/keras/backend/backend_test.py:643: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nkeras/backend/tensorflow_backend.py:2906: in rnn\n    swap_memory=True)\n../../envs/keras_26/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py:3501: in while_loop\n    return_same_structure)\n../../envs/keras_26/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py:3012: in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n../../envs/keras_26/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py:2937: in _BuildLoop\n    body_result = body(*packed_vars_for_body)\nkeras/backend/tensorflow_backend.py:2874: in _step\n    new_states = [tf.where(tiled_mask_t, new_states[i], states[i]) for i in range(len(states))]\nkeras/backend/tensorflow_backend.py:2874: in <listcomp>\n    new_states = [tf.where(tiled_mask_t, new_states[i], states[i]) for i in range(len(states))]\n../../envs/keras_26/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py:324: in new_func\n    return func(*args, **kwargs)\n../../envs/keras_26/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:180: in wrapper\n    return target(*args, **kwargs)\n../../envs/keras_26/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:3270: in where\n    return gen_math_ops.select(condition=condition, x=x, y=y, name=name)\n../../envs/keras_26/lib/python3.7/site-packages/tensorflow/python/ops/gen_math_ops.py:9226: in select\n    \"Select\", condition=condition, t=x, e=y, name=name)\n../../envs/keras_26/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:788: in _apply_op_helper\n    op_def=op_def)\n../../envs/keras_26/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py:507: in new_func\n    return func(*args, **kwargs)\n../../envs/keras_26/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:3616: in create_op\n    op_def=op_def)\n../../envs/keras_26/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:2027: in __init__\n    control_input_ops)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ngraph = <tensorflow.python.framework.ops.Graph object at 0x138ae5dd0>\nnode_def = name: \"while_2/Select_2\"\nop: \"Select\"\nattr {\n  key: \"T\"\n  value {\n    type: DT_FLOAT\n  }\n}\n\ninputs = [<tf.Tensor 'while_2/Tile:0' shape=(4, 3) dtype=bool>, <tf.Tensor 'while_2/concat:0' shape=(4, 6) dtype=float32>, <tf.Tensor 'while_2/Identity_3:0' shape=(4, 6) dtype=float32>]\ncontrol_inputs = []\n\n    def _create_c_op(graph, node_def, inputs, control_inputs):\n      \"\"\"Creates a TF_Operation.\n    \n      Args:\n        graph: a `Graph`.\n        node_def: `node_def_pb2.NodeDef` for the operation to create.\n        inputs: A list of `Tensor`s (corresponding to scalar inputs) and lists of\n          `Tensor`s (corresponding to sequence inputs, e.g. \"int64 * N\",\n          \"list(int64)\"). The length of the list should be equal to the number of\n          inputs specified by this operation's op def.\n        control_inputs: A list of `Operation`s to set as control dependencies.\n    \n      Returns:\n        A wrapped TF_Operation*.\n      \"\"\"\n      # pylint: disable=protected-access\n      op_desc = c_api.TF_NewOperation(graph._c_graph, compat.as_str(node_def.op),\n                                      compat.as_str(node_def.name))\n      if node_def.device:\n        c_api.TF_SetDevice(op_desc, compat.as_str(node_def.device))\n      # Add inputs\n      for op_input in inputs:\n        if isinstance(op_input, (list, tuple)):\n          c_api.TF_AddInputList(op_desc, [t._as_tf_output() for t in op_input])\n        else:\n          c_api.TF_AddInput(op_desc, op_input._as_tf_output())\n    \n      # Add control inputs\n      for control_input in control_inputs:\n        c_api.TF_AddControlInput(op_desc, control_input._c_op)\n      # pylint: enable=protected-access\n    \n      # Add attrs\n      for name, attr_value in node_def.attr.items():\n        serialized = attr_value.SerializeToString()\n        # TODO(skyewm): this creates and deletes a new TF_Status for every attr.\n        # It might be worth creating a convenient way to re-use the same status.\n        c_api.TF_SetAttrValueProto(op_desc, compat.as_str(name), serialized)\n    \n      try:\n        c_op = c_api.TF_FinishOperation(op_desc)\n      except errors.InvalidArgumentError as e:\n        # Convert to ValueError for backwards compatibility.\n>       raise ValueError(str(e))\nE       ValueError: Dimension 1 in both shapes must be equal, but are 6 and 3. Shapes are [4,6] and [4,3]. for 'while_2/Select_2' (op: 'Select') with input shapes: [4,3], [4,6], [4,6].\n\n../../envs/keras_26/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1867: ValueError",
                "traceback": "keras/backend/tensorflow_backend.py:2906: in rnn\n    swap_memory=True)\n../../envs/keras_26/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py:3501: in while_loop\n    return_same_structure)\n../../envs/keras_26/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py:3012: in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n../../envs/keras_26/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py:2937: in _BuildLoop\n    body_result = body(*packed_vars_for_body)\nkeras/backend/tensorflow_backend.py:2874: in _step\n    new_states = [tf.where(tiled_mask_t, new_states[i], states[i]) for i in range(len(states))]\nkeras/backend/tensorflow_backend.py:2874: in <listcomp>\n    new_states = [tf.where(tiled_mask_t, new_states[i], states[i]) for i in range(len(states))]\n../../envs/keras_26/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py:324: in new_func\n    return func(*args, **kwargs)\n../../envs/keras_26/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:180: in wrapper\n    return target(*args, **kwargs)\n../../envs/keras_26/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:3270: in where\n    return gen_math_ops.select(condition=condition, x=x, y=y, name=name)\n../../envs/keras_26/lib/python3.7/site-packages/tensorflow/python/ops/gen_math_ops.py:9226: in select\n    \"Select\", condition=condition, t=x, e=y, name=name)\n../../envs/keras_26/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:788: in _apply_op_helper\n    op_def=op_def)\n../../envs/keras_26/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py:507: in new_func\n    return func(*args, **kwargs)\n../../envs/keras_26/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:3616: in create_op\n    op_def=op_def)\n../../envs/keras_26/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:2027: in __init__\n    control_input_ops)",
                "test_error_location": "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ngraph = <tensorflow.python.framework.ops.Graph object at 0x138ae5dd0>\nnode_def = name: \"while_2/Select_2\"\nop: \"Select\"\nattr {\n  key: \"T\"\n  value {\n    type: DT_FLOAT\n  }\n}\n\ninputs = [<tf.Tensor 'while_2/Tile:0' shape=(4, 3) dtype=bool>, <tf.Tensor 'while_2/concat:0' shape=(4, 6) dtype=float32>, <tf.Tensor 'while_2/Identity_3:0' shape=(4, 6) dtype=float32>]\ncontrol_inputs = []\n\n    def _create_c_op(graph, node_def, inputs, control_inputs):\n      \"\"\"Creates a TF_Operation.\n    \n      Args:\n        graph: a `Graph`.\n        node_def: `node_def_pb2.NodeDef` for the operation to create.\n        inputs: A list of `Tensor`s (corresponding to scalar inputs) and lists of\n          `Tensor`s (corresponding to sequence inputs, e.g. \"int64 * N\",\n          \"list(int64)\"). The length of the list should be equal to the number of\n          inputs specified by this operation's op def.\n        control_inputs: A list of `Operation`s to set as control dependencies.\n    \n      Returns:\n        A wrapped TF_Operation*.\n      \"\"\"\n      # pylint: disable=protected-access\n      op_desc = c_api.TF_NewOperation(graph._c_graph, compat.as_str(node_def.op),\n                                      compat.as_str(node_def.name))\n      if node_def.device:\n        c_api.TF_SetDevice(op_desc, compat.as_str(node_def.device))\n      # Add inputs\n      for op_input in inputs:\n        if isinstance(op_input, (list, tuple)):\n          c_api.TF_AddInputList(op_desc, [t._as_tf_output() for t in op_input])\n        else:\n          c_api.TF_AddInput(op_desc, op_input._as_tf_output())\n    \n      # Add control inputs\n      for control_input in control_inputs:\n        c_api.TF_AddControlInput(op_desc, control_input._c_op)\n      # pylint: enable=protected-access\n    \n      # Add attrs\n      for name, attr_value in node_def.attr.items():\n        serialized = attr_value.SerializeToString()\n        # TODO(skyewm): this creates and deletes a new TF_Status for every attr.\n        # It might be worth creating a convenient way to re-use the same status.\n        c_api.TF_SetAttrValueProto(op_desc, compat.as_str(name), serialized)\n    \n      try:\n        c_op = c_api.TF_FinishOperation(op_desc)\n      except errors.InvalidArgumentError as e:\n        # Convert to ValueError for backwards compatibility.\n>       raise ValueError(str(e))\nE       ValueError: Dimension 1 in both shapes must be equal, but are 6 and 3. Shapes are [4,6] and [4,3]. for 'while_2/Select_2' (op: 'Select') with input shapes: [4,3], [4,6], [4,6].\n\n../../envs/keras_26/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1867: ValueError",
                "test_function_decorators": []
            }
        ]
    }
}