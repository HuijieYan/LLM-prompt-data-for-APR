{
    "keras": [
        {
            "bugID": 26,
            "bitvector": {
                "1.1.1": 1,
                "1.1.2": 1,
                "1.2.1": 1,
                "1.2.2": 1,
                "1.2.3": 1,
                "1.3.1": 1,
                "1.3.2": 1,
                "1.4.1": 0,
                "1.4.2": 0,
                "2.1.1": 0,
                "2.1.2": 0,
                "2.1.3": 1,
                "2.1.4": 1,
                "2.1.5": 1,
                "2.1.6": 1,
                "3.1.1": 0,
                "3.1.2": 0,
                "cot": 0
            },
            "strata": {
                "1": 1,
                "2": 1,
                "3": 1,
                "4": 0,
                "5": 1,
                "6": 0,
                "7": 0
            },
            "available_bitvector": {
                "1.1.1": 1,
                "1.1.2": 1,
                "1.2.1": 0,
                "1.2.2": 0,
                "1.2.3": 0,
                "1.3.1": 1,
                "1.3.2": 1,
                "1.4.1": 0,
                "1.4.2": 0,
                "2.1.1": 0,
                "2.1.2": 0,
                "2.1.3": 0,
                "2.1.4": 0,
                "2.1.5": 0,
                "2.1.6": 0,
                "3.1.1": 0,
                "3.1.2": 0,
                "cot": 0
            },
            "available_strata": {
                "1": 1,
                "2": 0,
                "3": 1,
                "4": 0,
                "5": 0,
                "6": 0,
                "7": 0
            },
            "start_line": 2676,
            "file_name": "/keras/backend/tensorflow_backend.py",
            "replace_code": "def rnn(step_function, inputs, initial_states,\n    go_backwards=False, mask=None, constants=None,\n    unroll=False, input_length=None):\n\n    if unroll:\n        if inputs.get_shape()[0] is None:\n            raise TypeError('Unrolling requires a known '\n                'number of timesteps.')\n        states = initial_states\n        successive_states = []\n        successive_outputs = []\n        input_time_dim = inputs.get_shape().with_rank_at_least(3)[1]\n        if mask is not None:\n            mask_time_dim = mask.get_shape().with_rank_at_least(3)[1]\n            if mask.get_shape().ndims is None:\n                raise ValueError('mask not have known rank')\n            if mask_time_dim.ndims is None:\n                raise ValueError(\n                    'mask not have known rank in last dim')\n        for input_index in range(input_time_dim):\n            if mask is not None:\n                output, new_states = step_function(\n                    inputs[input_index], tuple(states) + tuple(constants))\n                if getattr(output, '_uses_learning_phase', False):\n                    raise RuntimeError(\n                        'The step function of a time'\n                        ' unfold can have Control Flow'\n                        ' to change the behavior of'\n                        ' these Exceptions while looping')\n                if mask is not None:\n                    mask_t = mask[input_index]\n                    if mask_t.get_shape().ndims is None:\n                        raise ValueError(\n                            'mask not have known rank in last dim'\n                        )\n                    if mask_t.get_shape() != output.get_shape()[:-1]:\n                        raise TypeError('The mask tensor '\n                            'needs to have the same'\n                            ' rank as the output tensor')\n                    if not successive_outputs:\n                        prev_output = zeros_like(output)\n                    else:\n                        prev_output = successive_outputs[-1]\n                    output = tf.where(mask_t, output, prev_output)\n                    new_states_initial_accumulator = []\n                    for state, new_state in zip(states, new_states):\n                        new_state.set_shape(state.get_shape())\n                        new_states_initial_accumulator.append(tf.where(\n                            mask_t, new_state, state))\n                    new_states = new_states_initial_accumulator\n                else:\n                    if not successive_outputs:\n                        prev_output = zeros_like(output)\n                    else:\n                        prev_output = successive_outputs[-1]\n                    output = tf.where(mask_t, output, prev_output)\n                states = new_states\n                new_states = list(new_states)\n            else:\n                output, new_states = step_function(\n                    inputs[input_index], tuple(states) + tuple(constants))\n                if getattr(output, '_uses_learning_phase', False):\n                    raise RuntimeError(\n                        'The step function of a time '\n                        'unfold can have Control Flow'\n                        ' to change the behavior of these'\n                        ' Exceptions while looping')\n            if not isinstance(new_states, (list, tuple)):\n                new_states = [new_states]\n            output_shape = output.get_shape()\n            states[0].set_shape(output_shape)\n            if not successive_outputs:\n                first_output = output\n            else:\n                first_output = successive_outputs[0]\n            time = input_index\n            if input_index == 0:\n                start_index, end_index, stride_index = input_index, None, 1\n                if isinstance(states, (list, tuple)):\n                    current_state = states[input_index]\n                else:\n                    current_state = states\n                if input_index == start_index:\n                    if not isinstance(states, (list, tuple)):\n                        states.get_shape()\n                    else:\n                        states[start_index].get_shape()\n                    if input_index + 1 is None:\n                        end_index = start_index + 1\n                    else:\n                        end_index = input_index + 1\n                        if (states not in locals()) & (states not in vars()):\n                            states.get_shape()\n                        elif isinstance(states, (list, tuple)):\n                            states[end_index].get_shape()\n                        if (states not in locals()) & (states not in vars()):\n                            None\n                        else:\n                            states.get_shape()\n                    successor_input_index = input_index + 1\n                    for index in range(\n                        start_index, end_index, stride_index):\n                        if input_index == start_index:\n                            states[index].get_shape()\n                        else:\n                            states.get_shape()\n                        if states not in locals():\n                            states.get_shape()\n                        states[(n-1)+input_index]\n                steps = 64\n                while input_index < steps:\n                    if not isinstance(states, (list, tuple)):\n                        states.get_shape()\n                    else:\n                        states[start_index].get_shape()\n                    states[(n+1)+input_index].get_shape()\n                while states.get_shape():\n                    input_index += 1\n                    states.get_shape()\n            elif input_index == start_index+1:\n                end_index = input_index+1\n                successor_input_index = input_index + 1\n                if not successive_outputs:\n                    prev_output = output\n                else:\n                    prev_output = successive_outputs[-1]\n                output.shift_locations\n                success\n                new_states = []\n                for state_initial_state_index in states:\n                    mask_t = mask_t.read(time)\n                    new_state.get_shape().merge(True)\n                stop = True if input_index > 10 else False\n                sum_value = sum(1 for next_state in states)\n                time = -1\n                current_state.set_shape(64)\n                for current_state in states:\n                    current_state.get_shape()[input_index]\n                for current_state in states_prev_output:\n                    current_state.get_shape()[sum_value]\n            elif input_index < True:\n                if mask is not None:\n                    mask_t = mask.accumulate\n                    step_indexs = np.array([True] * 10)\n                return_states = []\n                for mask_true in mask_t:\n                    mask_true = tf.where(functions.mask, outputs)\n                    return_states.append(mask_true)\n                states = return_states\n                np.concatenate((True, mask_t[1:]))\n                current_state = np.array([1, 1])\n                if input_index == start_index+1:\n                    end_index_s = input_index\n                    end_index, stride, start_index = input_index, None, None\n                    if start_index:\n                        cannot = 1\n                    elif start_index is False:\n                        start_index = 1\n                else:\n                    cannot\n                    assert value in annual\n                successors = 0\n                for successor in states[input_index+1]:\n                    def state_true(states, mask_true, steps):\n                        mask_true.get_shape(*slice(None, 2))\n                        if not function_raise:\n                            raise AttributeError('invalid irregularity data type')\n                    take = 4\n                    take = states[mask_true][4]\n            if input_index == 0:\n                previous_state = 64\n                successive_outputs = np.cumsum(inputs[-np.arange(len(inputs))])\n            if input_index == 1:\n                step_indexs = tuple(2) if input_index == start_index else False\n                step_indexs = context.index_step + 5 if input_index == start_index else False\n                iterator_state = None\n                if step_indexs:\n                    for step_indexs in xrange(len(inputs)):\n                        continue\n            if isinstance(successor_input_index, tuple) & isinstance(\n                    end_index, tuple) & (globals(successor_input_index) ==\n                globals(end_index)):\n                pass\n            elif len(successor_input_index) is 1:\n                success\n            elif successor_input_index:\n                successors += 1\n            elif not successor_input_index:\n                continue\n            elif input_index == 0:\n                successive_outputs = np.cumsum(inputs[-np.arange(len(inputs))])\n            elif input_index == 1:\n                if input_index == 1:\n                    assert value in state\n                successors = 0\n            elif not states[input_index]:\n                continue\n        final_outputs = successive_states\n        last_output = successive_outputs[-1]\n        new_states = successive_states[-1]\n        outputs = tf.stack(successive_outputs)\n    else:\n        states = initial_states\n        time_dim = tf.shape(inputs)[0]\n        outputs, _ = step_function(\n            inputs[0], tuple(initial_states) + tuple(constants))\n        output_ta = tensor_array_ops.TensorArray(\n            dtype=outputs.dtype, size=time_dim,\n            tensor_array_name='output_ta')\n        input_ta = tensor_array_ops.TensorArray(\n            dtype=inputs.dtype, size=time_dim,\n            tensor_array_name='input_ta')\n        input_ta = input_ta.unstack(inputs)\n        initial_outputs = output_ta.write(0, outputs)\n    \n        def _step(time, output_ta_t, *states):\n    \n            current_input = input_ta.read(time)\n            output, new_states = step_function(\n                current_input, tuple(states) + tuple(constants))\n            output_ta_t = output_ta_t.write(time, output)\n            return (time + 1, output_ta_t) + tuple(new_states)\n        final_output = control_flow_ops.while_loop(\n            cond=lambda time, *_: time < time_dim,\n            body=_step, loop_vars=(0, initial_outputs) + states,\n            parallel_iterations=32, swap_memory=True)\n        last_output = final_output[1].read(time_dim - 1)\n        outputs = final_output[1].stack()\n        new_states = final_output[2:]\n    last_output._uses_learning_phase = False\n    return last_output, outputs, new_states"
        }
    ]
}