{
    "keras:25": {
        "/Volumes/SSD2T/bgp_envs_non_pandas/repos/keras_25/keras/applications/imagenet_utils.py": {
            "buggy_functions": [
                {
                    "function_name": "_preprocess_numpy_input",
                    "function_code": "def _preprocess_numpy_input(x, data_format, mode):\n    \"\"\"Preprocesses a Numpy array encoding a batch of images.\n\n    # Arguments\n        x: Input array, 3D or 4D.\n        data_format: Data format of the image array.\n        mode: One of \"caffe\", \"tf\" or \"torch\".\n            - caffe: will convert the images from RGB to BGR,\n                then will zero-center each color channel with\n                respect to the ImageNet dataset,\n                without scaling.\n            - tf: will scale pixels between -1 and 1,\n                sample-wise.\n            - torch: will scale pixels between 0 and 1 and then\n                will normalize each channel with respect to the\n                ImageNet dataset.\n\n    # Returns\n        Preprocessed Numpy array.\n    \"\"\"\n    if mode == 'tf':\n        x /= 127.5\n        x -= 1.\n        return x\n\n    if mode == 'torch':\n        x /= 255.\n        mean = [0.485, 0.456, 0.406]\n        std = [0.229, 0.224, 0.225]\n    else:\n        if data_format == 'channels_first':\n            # 'RGB'->'BGR'\n            if x.ndim == 3:\n                x = x[::-1, ...]\n            else:\n                x = x[:, ::-1, ...]\n        else:\n            # 'RGB'->'BGR'\n            x = x[..., ::-1]\n        mean = [103.939, 116.779, 123.68]\n        std = None\n\n    # Zero-center by mean pixel\n    if data_format == 'channels_first':\n        if x.ndim == 3:\n            x[0, :, :] -= mean[0]\n            x[1, :, :] -= mean[1]\n            x[2, :, :] -= mean[2]\n            if std is not None:\n                x[0, :, :] /= std[0]\n                x[1, :, :] /= std[1]\n                x[2, :, :] /= std[2]\n        else:\n            x[:, 0, :, :] -= mean[0]\n            x[:, 1, :, :] -= mean[1]\n            x[:, 2, :, :] -= mean[2]\n            if std is not None:\n                x[:, 0, :, :] /= std[0]\n                x[:, 1, :, :] /= std[1]\n                x[:, 2, :, :] /= std[2]\n    else:\n        x[..., 0] -= mean[0]\n        x[..., 1] -= mean[1]\n        x[..., 2] -= mean[2]\n        if std is not None:\n            x[..., 0] /= std[0]\n            x[..., 1] /= std[1]\n            x[..., 2] /= std[2]\n    return x\n",
                    "decorators": [],
                    "docstring": "Preprocesses a Numpy array encoding a batch of images.\n\n# Arguments\n    x: Input array, 3D or 4D.\n    data_format: Data format of the image array.\n    mode: One of \"caffe\", \"tf\" or \"torch\".\n        - caffe: will convert the images from RGB to BGR,\n            then will zero-center each color channel with\n            respect to the ImageNet dataset,\n            without scaling.\n        - tf: will scale pixels between -1 and 1,\n            sample-wise.\n        - torch: will scale pixels between 0 and 1 and then\n            will normalize each channel with respect to the\n            ImageNet dataset.\n\n# Returns\n    Preprocessed Numpy array.",
                    "start_line": 21,
                    "end_line": 89,
                    "variables": {
                        "mode": [
                            41,
                            46
                        ],
                        "x": [
                            42,
                            43,
                            44,
                            47,
                            53,
                            54,
                            56,
                            59,
                            65,
                            66,
                            67,
                            68,
                            70,
                            71,
                            72,
                            74,
                            75,
                            76,
                            78,
                            79,
                            80,
                            82,
                            83,
                            84,
                            86,
                            87,
                            88,
                            89
                        ],
                        "mean": [
                            66,
                            67,
                            68,
                            74,
                            75,
                            76,
                            48,
                            82,
                            83,
                            84,
                            60
                        ],
                        "std": [
                            69,
                            70,
                            71,
                            72,
                            77,
                            78,
                            79,
                            80,
                            49,
                            85,
                            86,
                            87,
                            88,
                            61
                        ],
                        "data_format": [
                            64,
                            51
                        ],
                        "x.ndim": [
                            65,
                            53
                        ]
                    },
                    "filtered_variables": {
                        "mode": [
                            41,
                            46
                        ],
                        "x": [
                            42,
                            43,
                            44,
                            47,
                            53,
                            54,
                            56,
                            59,
                            65,
                            66,
                            67,
                            68,
                            70,
                            71,
                            72,
                            74,
                            75,
                            76,
                            78,
                            79,
                            80,
                            82,
                            83,
                            84,
                            86,
                            87,
                            88,
                            89
                        ],
                        "mean": [
                            66,
                            67,
                            68,
                            74,
                            75,
                            76,
                            48,
                            82,
                            83,
                            84,
                            60
                        ],
                        "std": [
                            69,
                            70,
                            71,
                            72,
                            77,
                            78,
                            79,
                            80,
                            49,
                            85,
                            86,
                            87,
                            88,
                            61
                        ],
                        "data_format": [
                            64,
                            51
                        ],
                        "x.ndim": [
                            65,
                            53
                        ]
                    },
                    "diff_line_number": 40,
                    "class_data": null,
                    "variable_values": [
                        [
                            {},
                            {}
                        ]
                    ],
                    "angelic_variable_values": [
                        [
                            {},
                            {}
                        ]
                    ]
                }
            ],
            "inscope_functions": [
                "def _preprocess_numpy_input(x, data_format, mode):\n    \"\"\"Preprocesses a Numpy array encoding a batch of images.\n\n    # Arguments\n        x: Input array, 3D or 4D.\n        data_format: Data format of the image array.\n        mode: One of \"caffe\", \"tf\" or \"torch\".\n            - caffe: will convert the images from RGB to BGR,\n                then will zero-center each color channel with\n                respect to the ImageNet dataset,\n                without scaling.\n            - tf: will scale pixels between -1 and 1,\n                sample-wise.\n            - torch: will scale pixels between 0 and 1 and then\n                will normalize each channel with respect to the\n                ImageNet dataset.\n\n    # Returns\n        Preprocessed Numpy array.\n    \"\"\"\n    if mode == 'tf':\n        x /= 127.5\n        x -= 1.\n        return x\n\n    if mode == 'torch':\n        x /= 255.\n        mean = [0.485, 0.456, 0.406]\n        std = [0.229, 0.224, 0.225]\n    else:\n        if data_format == 'channels_first':\n            # 'RGB'->'BGR'\n            if x.ndim == 3:\n                x = x[::-1, ...]\n            else:\n                x = x[:, ::-1, ...]\n        else:\n            # 'RGB'->'BGR'\n            x = x[..., ::-1]\n        mean = [103.939, 116.779, 123.68]\n        std = None\n\n    # Zero-center by mean pixel\n    if data_format == 'channels_first':\n        if x.ndim == 3:\n            x[0, :, :] -= mean[0]\n            x[1, :, :] -= mean[1]\n            x[2, :, :] -= mean[2]\n            if std is not None:\n                x[0, :, :] /= std[0]\n                x[1, :, :] /= std[1]\n                x[2, :, :] /= std[2]\n        else:\n            x[:, 0, :, :] -= mean[0]\n            x[:, 1, :, :] -= mean[1]\n            x[:, 2, :, :] -= mean[2]\n            if std is not None:\n                x[:, 0, :, :] /= std[0]\n                x[:, 1, :, :] /= std[1]\n                x[:, 2, :, :] /= std[2]\n    else:\n        x[..., 0] -= mean[0]\n        x[..., 1] -= mean[1]\n        x[..., 2] -= mean[2]\n        if std is not None:\n            x[..., 0] /= std[0]\n            x[..., 1] /= std[1]\n            x[..., 2] /= std[2]\n    return x",
                "def _preprocess_symbolic_input(x, data_format, mode):\n    \"\"\"Preprocesses a tensor encoding a batch of images.\n\n    # Arguments\n        x: Input tensor, 3D or 4D.\n        data_format: Data format of the image tensor.\n        mode: One of \"caffe\", \"tf\" or \"torch\".\n            - caffe: will convert the images from RGB to BGR,\n                then will zero-center each color channel with\n                respect to the ImageNet dataset,\n                without scaling.\n            - tf: will scale pixels between -1 and 1,\n                sample-wise.\n            - torch: will scale pixels between 0 and 1 and then\n                will normalize each channel with respect to the\n                ImageNet dataset.\n\n    # Returns\n        Preprocessed tensor.\n    \"\"\"\n    global _IMAGENET_MEAN\n\n    if mode == 'tf':\n        x /= 127.5\n        x -= 1.\n        return x\n\n    if mode == 'torch':\n        x /= 255.\n        mean = [0.485, 0.456, 0.406]\n        std = [0.229, 0.224, 0.225]\n    else:\n        if data_format == 'channels_first':\n            # 'RGB'->'BGR'\n            if K.ndim(x) == 3:\n                x = x[::-1, ...]\n            else:\n                x = x[:, ::-1, ...]\n        else:\n            # 'RGB'->'BGR'\n            x = x[..., ::-1]\n        mean = [103.939, 116.779, 123.68]\n        std = None\n\n    if _IMAGENET_MEAN is None:\n        _IMAGENET_MEAN = K.constant(-np.array(mean))\n\n    # Zero-center by mean pixel\n    if K.dtype(x) != K.dtype(_IMAGENET_MEAN):\n        x = K.bias_add(x, K.cast(_IMAGENET_MEAN, K.dtype(x)), data_format)\n    else:\n        x = K.bias_add(x, _IMAGENET_MEAN, data_format)\n    if std is not None:\n        x /= std\n    return x",
                "def preprocess_input(x, data_format=None, mode='caffe'):\n    \"\"\"Preprocesses a tensor or Numpy array encoding a batch of images.\n\n    # Arguments\n        x: Input Numpy or symbolic tensor, 3D or 4D.\n        data_format: Data format of the image tensor/array.\n        mode: One of \"caffe\", \"tf\" or \"torch\".\n            - caffe: will convert the images from RGB to BGR,\n                then will zero-center each color channel with\n                respect to the ImageNet dataset,\n                without scaling.\n            - tf: will scale pixels between -1 and 1,\n                sample-wise.\n            - torch: will scale pixels between 0 and 1 and then\n                will normalize each channel with respect to the\n                ImageNet dataset.\n\n    # Returns\n        Preprocessed tensor or Numpy array.\n\n    # Raises\n        ValueError: In case of unknown `data_format` argument.\n    \"\"\"\n    if data_format is None:\n        data_format = K.image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format ' + str(data_format))\n\n    if isinstance(x, np.ndarray):\n        return _preprocess_numpy_input(x, data_format=data_format, mode=mode)\n    else:\n        return _preprocess_symbolic_input(x, data_format=data_format,\n                                          mode=mode)",
                "def decode_predictions(preds, top=5):\n    \"\"\"Decodes the prediction of an ImageNet model.\n\n    # Arguments\n        preds: Numpy tensor encoding a batch of predictions.\n        top: Integer, how many top-guesses to return.\n\n    # Returns\n        A list of lists of top class prediction tuples\n        `(class_name, class_description, score)`.\n        One list of tuples per sample in batch input.\n\n    # Raises\n        ValueError: In case of invalid shape of the `pred` array\n            (must be 2D).\n    \"\"\"\n    global CLASS_INDEX\n    if len(preds.shape) != 2 or preds.shape[1] != 1000:\n        raise ValueError('`decode_predictions` expects '\n                         'a batch of predictions '\n                         '(i.e. a 2D array of shape (samples, 1000)). '\n                         'Found array with shape: ' + str(preds.shape))\n    if CLASS_INDEX is None:\n        fpath = get_file('imagenet_class_index.json',\n                         CLASS_INDEX_PATH,\n                         cache_subdir='models',\n                         file_hash='c2c37ea517e94d9795004a39431a14cb')\n        with open(fpath) as f:\n            CLASS_INDEX = json.load(f)\n    results = []\n    for pred in preds:\n        top_indices = pred.argsort()[-top:][::-1]\n        result = [tuple(CLASS_INDEX[str(i)]) + (pred[i],) for i in top_indices]\n        result.sort(key=lambda x: x[2], reverse=True)\n        results.append(result)\n    return results",
                "def _obtain_input_shape(input_shape,\n                        default_size,\n                        min_size,\n                        data_format,\n                        require_flatten,\n                        weights=None):\n    \"\"\"Internal utility to compute/validate a model's input shape.\n\n    # Arguments\n        input_shape: Either None (will return the default network input shape),\n            or a user-provided shape to be validated.\n        default_size: Default input width/height for the model.\n        min_size: Minimum input width/height accepted by the model.\n        data_format: Image data format to use.\n        require_flatten: Whether the model is expected to\n            be linked to a classifier via a Flatten layer.\n        weights: One of `None` (random initialization)\n            or 'imagenet' (pre-training on ImageNet).\n            If weights='imagenet' input channels must be equal to 3.\n\n    # Returns\n        An integer shape tuple (may include None entries).\n\n    # Raises\n        ValueError: In case of invalid argument values.\n    \"\"\"\n    if weights != 'imagenet' and input_shape and len(input_shape) == 3:\n        if data_format == 'channels_first':\n            if input_shape[0] not in {1, 3}:\n                warnings.warn(\n                    'This model usually expects 1 or 3 input channels. '\n                    'However, it was passed an input_shape with ' +\n                    str(input_shape[0]) + ' input channels.')\n            default_shape = (input_shape[0], default_size, default_size)\n        else:\n            if input_shape[-1] not in {1, 3}:\n                warnings.warn(\n                    'This model usually expects 1 or 3 input channels. '\n                    'However, it was passed an input_shape with ' +\n                    str(input_shape[-1]) + ' input channels.')\n            default_shape = (default_size, default_size, input_shape[-1])\n    else:\n        if data_format == 'channels_first':\n            default_shape = (3, default_size, default_size)\n        else:\n            default_shape = (default_size, default_size, 3)\n    if weights == 'imagenet' and require_flatten:\n        if input_shape is not None:\n            if input_shape != default_shape:\n                raise ValueError('When setting`include_top=True` '\n                                 'and loading `imagenet` weights, '\n                                 '`input_shape` should be ' +\n                                 str(default_shape) + '.')\n        return default_shape\n    if input_shape:\n        if data_format == 'channels_first':\n            if input_shape is not None:\n                if len(input_shape) != 3:\n                    raise ValueError(\n                        '`input_shape` must be a tuple of three integers.')\n                if input_shape[0] != 3 and weights == 'imagenet':\n                    raise ValueError('The input must have 3 channels; got '\n                                     '`input_shape=' + str(input_shape) + '`')\n                if ((input_shape[1] is not None and input_shape[1] < min_size) or\n                   (input_shape[2] is not None and input_shape[2] < min_size)):\n                    raise ValueError('Input size must be at least ' +\n                                     str(min_size) + 'x' + str(min_size) + '; got '\n                                     '`input_shape=' + str(input_shape) + '`')\n        else:\n            if input_shape is not None:\n                if len(input_shape) != 3:\n                    raise ValueError(\n                        '`input_shape` must be a tuple of three integers.')\n                if input_shape[-1] != 3 and weights == 'imagenet':\n                    raise ValueError('The input must have 3 channels; got '\n                                     '`input_shape=' + str(input_shape) + '`')\n                if ((input_shape[0] is not None and input_shape[0] < min_size) or\n                   (input_shape[1] is not None and input_shape[1] < min_size)):\n                    raise ValueError('Input size must be at least ' +\n                                     str(min_size) + 'x' + str(min_size) + '; got '\n                                     '`input_shape=' + str(input_shape) + '`')\n    else:\n        if require_flatten:\n            input_shape = default_shape\n        else:\n            if data_format == 'channels_first':\n                input_shape = (3, None, None)\n            else:\n                input_shape = (None, None, 3)\n    if require_flatten:\n        if None in input_shape:\n            raise ValueError('If `include_top` is True, '\n                             'you should specify a static `input_shape`. '\n                             'Got `input_shape=' + str(input_shape) + '`')\n    return input_shape"
            ],
            "inscope_function_signatures": [
                "_preprocess_numpy_input(x, data_format, mode)",
                "_preprocess_symbolic_input(x, data_format, mode)",
                "preprocess_input(x, data_format=None, mode='caffe')",
                "decode_predictions(preds, top=5)",
                "_obtain_input_shape(input_shape, default_size, min_size, data_format, require_flatten, weights=None)"
            ],
            "variables_in_file": {
                "CLASS_INDEX": [
                    216,
                    212,
                    206,
                    14
                ],
                "CLASS_INDEX_PATH": [
                    208,
                    15
                ],
                "_IMAGENET_MEAN": [
                    136,
                    137,
                    140,
                    141,
                    143,
                    18
                ],
                "mode": [
                    41,
                    46,
                    178,
                    114,
                    181,
                    119
                ],
                "x": [
                    129,
                    132,
                    140,
                    141,
                    143,
                    145,
                    146,
                    42,
                    43,
                    44,
                    47,
                    177,
                    178,
                    180,
                    53,
                    54,
                    56,
                    59,
                    65,
                    66,
                    67,
                    68,
                    70,
                    71,
                    72,
                    74,
                    75,
                    76,
                    78,
                    79,
                    80,
                    82,
                    83,
                    84,
                    86,
                    87,
                    88,
                    89,
                    217,
                    115,
                    116,
                    117,
                    120,
                    126,
                    127
                ],
                "mean": [
                    66,
                    67,
                    68,
                    133,
                    137,
                    74,
                    75,
                    76,
                    48,
                    82,
                    83,
                    84,
                    121,
                    60
                ],
                "std": [
                    69,
                    70,
                    71,
                    72,
                    134,
                    77,
                    78,
                    79,
                    80,
                    49,
                    144,
                    145,
                    85,
                    86,
                    87,
                    88,
                    122,
                    61
                ],
                "data_format": [
                    64,
                    264,
                    172,
                    141,
                    173,
                    143,
                    174,
                    175,
                    178,
                    51,
                    180,
                    277,
                    307,
                    249,
                    124
                ],
                "x.ndim": [
                    65,
                    53
                ],
                "K.ndim": [
                    126
                ],
                "K": [
                    137,
                    140,
                    141,
                    173,
                    143,
                    126
                ],
                "K.constant": [
                    137
                ],
                "np.array": [
                    137
                ],
                "np": [
                    137,
                    177
                ],
                "K.dtype": [
                    140,
                    141
                ],
                "K.bias_add": [
                    141,
                    143
                ],
                "K.cast": [
                    141
                ],
                "K.image_data_format": [
                    173
                ],
                "ValueError": [
                    293,
                    296,
                    202,
                    300,
                    271,
                    175,
                    280,
                    313,
                    283,
                    287
                ],
                "str": [
                    288,
                    289,
                    261,
                    297,
                    205,
                    301,
                    175,
                    302,
                    274,
                    216,
                    315,
                    284,
                    254
                ],
                "isinstance": [
                    177
                ],
                "np.ndarray": [
                    177
                ],
                "_preprocess_numpy_input": [
                    178
                ],
                "_preprocess_symbolic_input": [
                    180
                ],
                "len": [
                    248,
                    201,
                    292,
                    279
                ],
                "preds.shape": [
                    201,
                    205
                ],
                "preds": [
                    201,
                    205,
                    214
                ],
                "fpath": [
                    211,
                    207
                ],
                "get_file": [
                    207
                ],
                "open": [
                    211
                ],
                "f": [
                    211,
                    212
                ],
                "json.load": [
                    212
                ],
                "json": [
                    212
                ],
                "results": [
                    218,
                    219,
                    213
                ],
                "pred": [
                    216,
                    214,
                    215
                ],
                "top_indices": [
                    216,
                    215
                ],
                "pred.argsort": [
                    215
                ],
                "top": [
                    215
                ],
                "result": [
                    216,
                    217,
                    218
                ],
                "tuple": [
                    216
                ],
                "i": [
                    216
                ],
                "result.sort": [
                    217
                ],
                "results.append": [
                    218
                ],
                "weights": [
                    248,
                    282,
                    268,
                    295
                ],
                "input_shape": [
                    257,
                    261,
                    262,
                    269,
                    270,
                    276,
                    278,
                    279,
                    282,
                    284,
                    285,
                    286,
                    289,
                    291,
                    292,
                    295,
                    297,
                    298,
                    299,
                    302,
                    305,
                    308,
                    310,
                    312,
                    315,
                    316,
                    248,
                    250,
                    254,
                    255
                ],
                "warnings.warn": [
                    258,
                    251
                ],
                "warnings": [
                    258,
                    251
                ],
                "default_shape": [
                    262,
                    265,
                    267,
                    270,
                    305,
                    274,
                    275,
                    255
                ],
                "default_size": [
                    265,
                    267,
                    262,
                    255
                ],
                "require_flatten": [
                    304,
                    268,
                    311
                ],
                "min_size": [
                    288,
                    298,
                    299,
                    301,
                    285,
                    286
                ]
            },
            "filtered_variables_in_file": {
                "CLASS_INDEX": [
                    216,
                    212,
                    206,
                    14
                ],
                "CLASS_INDEX_PATH": [
                    208,
                    15
                ],
                "_IMAGENET_MEAN": [
                    136,
                    137,
                    140,
                    141,
                    143,
                    18
                ],
                "mode": [
                    41,
                    46,
                    178,
                    114,
                    181,
                    119
                ],
                "x": [
                    129,
                    132,
                    140,
                    141,
                    143,
                    145,
                    146,
                    42,
                    43,
                    44,
                    47,
                    177,
                    178,
                    180,
                    53,
                    54,
                    56,
                    59,
                    65,
                    66,
                    67,
                    68,
                    70,
                    71,
                    72,
                    74,
                    75,
                    76,
                    78,
                    79,
                    80,
                    82,
                    83,
                    84,
                    86,
                    87,
                    88,
                    89,
                    217,
                    115,
                    116,
                    117,
                    120,
                    126,
                    127
                ],
                "mean": [
                    66,
                    67,
                    68,
                    133,
                    137,
                    74,
                    75,
                    76,
                    48,
                    82,
                    83,
                    84,
                    121,
                    60
                ],
                "std": [
                    69,
                    70,
                    71,
                    72,
                    134,
                    77,
                    78,
                    79,
                    80,
                    49,
                    144,
                    145,
                    85,
                    86,
                    87,
                    88,
                    122,
                    61
                ],
                "data_format": [
                    64,
                    264,
                    172,
                    141,
                    173,
                    143,
                    174,
                    175,
                    178,
                    51,
                    180,
                    277,
                    307,
                    249,
                    124
                ],
                "x.ndim": [
                    65,
                    53
                ],
                "K.ndim": [
                    126
                ],
                "K": [
                    137,
                    140,
                    141,
                    173,
                    143,
                    126
                ],
                "K.constant": [
                    137
                ],
                "np.array": [
                    137
                ],
                "np": [
                    137,
                    177
                ],
                "K.dtype": [
                    140,
                    141
                ],
                "K.bias_add": [
                    141,
                    143
                ],
                "K.cast": [
                    141
                ],
                "K.image_data_format": [
                    173
                ],
                "np.ndarray": [
                    177
                ],
                "_preprocess_numpy_input": [
                    178
                ],
                "_preprocess_symbolic_input": [
                    180
                ],
                "preds.shape": [
                    201,
                    205
                ],
                "preds": [
                    201,
                    205,
                    214
                ],
                "fpath": [
                    211,
                    207
                ],
                "get_file": [
                    207
                ],
                "f": [
                    211,
                    212
                ],
                "json.load": [
                    212
                ],
                "json": [
                    212
                ],
                "results": [
                    218,
                    219,
                    213
                ],
                "pred": [
                    216,
                    214,
                    215
                ],
                "top_indices": [
                    216,
                    215
                ],
                "pred.argsort": [
                    215
                ],
                "top": [
                    215
                ],
                "result": [
                    216,
                    217,
                    218
                ],
                "i": [
                    216
                ],
                "result.sort": [
                    217
                ],
                "results.append": [
                    218
                ],
                "weights": [
                    248,
                    282,
                    268,
                    295
                ],
                "input_shape": [
                    257,
                    261,
                    262,
                    269,
                    270,
                    276,
                    278,
                    279,
                    282,
                    284,
                    285,
                    286,
                    289,
                    291,
                    292,
                    295,
                    297,
                    298,
                    299,
                    302,
                    305,
                    308,
                    310,
                    312,
                    315,
                    316,
                    248,
                    250,
                    254,
                    255
                ],
                "warnings.warn": [
                    258,
                    251
                ],
                "warnings": [
                    258,
                    251
                ],
                "default_shape": [
                    262,
                    265,
                    267,
                    270,
                    305,
                    274,
                    275,
                    255
                ],
                "default_size": [
                    265,
                    267,
                    262,
                    255
                ],
                "require_flatten": [
                    304,
                    268,
                    311
                ],
                "min_size": [
                    288,
                    298,
                    299,
                    301,
                    285,
                    286
                ]
            }
        },
        "test_data": []
    }
}