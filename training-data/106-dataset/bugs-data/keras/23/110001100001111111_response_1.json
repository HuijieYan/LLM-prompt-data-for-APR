{
    "keras": [
        {
            "bugID": 23,
            "bitvector": {
                "1.1.1": 1,
                "1.1.2": 1,
                "1.2.1": 0,
                "1.2.2": 0,
                "1.2.3": 0,
                "1.3.1": 1,
                "1.3.2": 1,
                "1.4.1": 0,
                "1.4.2": 0,
                "2.1.1": 0,
                "2.1.2": 0,
                "2.1.3": 1,
                "2.1.4": 1,
                "2.1.5": 1,
                "2.1.6": 1,
                "3.1.1": 1,
                "3.1.2": 1,
                "cot": 1
            },
            "strata": {
                "1": 1,
                "2": 0,
                "3": 1,
                "4": 0,
                "5": 1,
                "6": 1,
                "7": 1
            },
            "available_bitvector": {
                "1.1.1": 1,
                "1.1.2": 1,
                "1.2.1": 0,
                "1.2.2": 0,
                "1.2.3": 0,
                "1.3.1": 1,
                "1.3.2": 1,
                "1.4.1": 0,
                "1.4.2": 0,
                "2.1.1": 0,
                "2.1.2": 0,
                "2.1.3": 1,
                "2.1.4": 1,
                "2.1.5": 1,
                "2.1.6": 1,
                "3.1.1": 0,
                "3.1.2": 0,
                "cot": 1
            },
            "available_strata": {
                "1": 1,
                "2": 0,
                "3": 1,
                "4": 0,
                "5": 1,
                "6": 0,
                "7": 1
            },
            "start_line": 114,
            "file_name": "/keras/engine/sequential.py",
            "replace_code": "def add(self, layer):\n\n    \"\"\"Adds a layer instance on top of the layer stack.\n    \n    # Arguments\n        layer: layer instance.\n    \n    # Raises\n        TypeError: If `layer` is not a layer instance.\n        ValueError: In case the `layer` argument does not\n            know its input shape.\n        ValueError: In case the `layer` argument has\n            multiple output tensors, or is already connected\n            somewhere else (forbidden in `Sequential` models).\n    \"\"\"\n    if not isinstance(layer, Layer):\n        raise TypeError('The added layer must be '\n                        'an instance of class Layer. '\n                        'Found: ' + str(layer))\n    self.built = False\n    \n    if isinstance(layer, InputLayer):\n        if len(layer._inbound_nodes[-1].output_tensors) != 1:\n            raise ValueError('All input layers in a Sequential model '\n                             'should have a single output tensor. '\n                             'For multi-output layers, '\n                             'use the functional API.')\n        self.inputs = network.get_source_inputs(layer.output)\n        self.outputs = [layer.output]\n        self._layers.append(layer)\n    else:\n        if not self._layers:\n            # Create an input tensor and call `layer` on the input tensor.\n            # First, we need to infer the expected input shape and dtype.\n            first_layer = layer\n            if isinstance(layer, (Model, Sequential)):\n                # We were passed a model as the first layer.\n                # This requires a specific way to figure out the\n                # input shape and dtype.\n                if not layer.layers:\n                    raise ValueError('Cannot add an empty model '\n                                     'to a `Sequential` model.')\n                # In case of nested models: recover the first layer\n                # of the deepest model to infer input shape and dtype.\n                first_layer = layer.layers[0]\n                while isinstance(first_layer, (Model, Sequential)):\n                    first_layer = first_layer.layers[0]\n                batch_shape = first_layer.batch_input_shape\n                dtype = first_layer.dtype\n    \n            if hasattr(first_layer, 'batch_input_shape'):\n                batch_shape = first_layer.batch_input_shape\n                dtype = first_layer.dtype\n                # Instantiate the input layer.\n                x = Input(\n                    batch_shape=batch_shape,\n                    dtype=dtype,\n                    name=layer.name + '_input')\n                # This will build the current layer\n                # and create the node connecting the current layer\n                # to the input layer we just created.\n                layer(x)\n                self.inputs = network.get_source_inputs(layer.output)\n                self.outputs = [layer.output]\n            else:\n                # The layer doesn't know about its expected shape.\n                # We will have to\n                # build the model lazily on `fit`/etc.\n                batch_shape = None\n                self._layers.append(layer)\n        else:\n            output_tensor = layer(self.outputs[0])\n            if isinstance(output_tensor, list):\n                raise TypeError('All layers in a Sequential model '\n                                'should have a single output tensor. '\n                                'For multi-output layers, '\n                                'use the functional API.')\n            self.outputs = [output_tensor]\n            self._layers.append(layer)\n    \n    self.built = True"
        }
    ]
}