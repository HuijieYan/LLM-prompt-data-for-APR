The bug occurs in the `add_task` function of the `Scheduler` class. The function takes various parameters and manipulates the `task` object based on those parameters. In both Buggy cases 1 and 2, the `task` object is not updated based on the 'status' and 'new_deps'. This behavior is causing the function to return without performing necessary updates to the task.

To fix the bug, we need to ensure that the function always updates the task based on the 'status' and 'new_deps' before returning.

Here's the corrected code for the `add_task` function:

```python
# this is the corrected function
@rpc_method()
def add_task(self, task_id=None, status=PENDING, runnable=True,
             deps=None, new_deps=None, expl=None, resources=None,
             priority=0, family='', module=None, params=None,
             assistant=False, tracking_url=None, worker=None, batchable=None,
             batch_id=None, retry_policy_dict={}, owners=None, **kwargs):
    # existing implementation

    # ...

    if not (task.status in (RUNNING, BATCH_RUNNING) and status == PENDING) or new_deps:
        # don't allow re-scheduling of task while it is running, it must either fail or succeed first
        if status == PENDING or status != task.status:
            self._update_task_history(task, status)
            self._state.set_status(task, PENDING if status == SUSPENDED else status, self._config)
    
    # existing implementation

    # ...

    if deps is not None:
        task.deps = set(deps)

    if new_deps is not None:
        task.deps.update(new_deps)

    if resources is not None:
        task.resources = resources

    if worker.enabled and not assistant:
        task.stakeholders.add(worker_id)

        # Task dependencies might not exist yet. Let's create dummy tasks for them for now.
        # Otherwise the task dependencies might end up being pruned if scheduling takes a long time
        for dep in task.deps or []:
            t = self._state.get_task(dep, setdefault=self._make_task(task_id=dep, status=UNKNOWN, deps=None, priority=priority))
            t.stakeholders.add(worker_id)

    self._update_priority(task, priority, worker_id)

    # Because some tasks (non-dynamic dependencies) are `_make_task`ed
    # before we know their retry_policy, we always set it here
    task.retry_policy = retry_policy

    if runnable and status != FAILED and worker.enabled:
        task.workers.add(worker_id)
        self._state.get_worker(worker_id).tasks.add(task)
        task.runnable = runnable
```

In the corrected code, after updating task.history and setting the task status, we make sure to update the dependencies, resources, stakeholders, and priority of the task before setting the task as runnable. This ensures that the task is properly updated before the function returns.