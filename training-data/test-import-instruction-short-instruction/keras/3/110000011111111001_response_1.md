The error is occurring because the function `_clone_functional_model` is not correctly handling the case when the `model` argument is a functional model with multiple outputs. Specifically, the function fails to correctly create input tensors and associate them with the output tensors.

The problematic section of the code is in the part where input tensors are created based on the model's input layers, and then the output tensors are computed for each layer in the model. This part of the code is not correctly handling the case when there are multiple output tensors for a layer.

To fix this issue, the code should be modified to correctly associate input and output tensors from multiple layers.

Here's the corrected code for the `_clone_functional_model` function:

```python
def _clone_functional_model(model, input_tensors=None):
    if not isinstance(model, Model):
        raise ValueError('Expected `model` argument to be a `Model` instance, got ', model)
    if isinstance(model, Sequential):
        raise ValueError('Expected `model` argument to be a functional `Model` instance, got a `Sequential` instance instead:', model)

    layer_map = {}  # Cache for created layers
    tensor_map = {}  # Map {reference_tensor: (corresponding_tensor, mask)}

    if input_tensors is None:
        input_tensors = [Input(batch_shape=layer.input.shape, dtype=layer.input.dtype, sparse=layer.input.sparse) for layer in model._input_layers]

    for original_tensor, new_tensor in zip(model.inputs, input_tensors):
        tensor_map[original_tensor] = (new_tensor, None)  # tensor, mask

    for depth in range(len(model._nodes_by_depth)):
        nodes = model._nodes_by_depth[depth]
        for node in nodes:
            layer = node.outbound_layer

            if layer not in layer_map:
                new_layer = layer.__class__.from_config(layer.get_config())
                layer_map[layer] = new_layer
            else:
                new_layer = layer_map[layer]

            reference_input_tensors = node.input_tensors
            reference_output_tensors = node.output_tensors

            computed_data = []
            for x in reference_input_tensors:
                if x in tensor_map:
                    computed_data.append(tensor_map[x])

            if len(computed_data) == len(reference_input_tensors):
                if node.arguments:
                    kwargs = node.arguments
                else:
                    kwargs = {}

                computed_tensors = [x[0] for x in computed_data]
                computed_masks = [x[1] for x in computed_data]

                if has_arg(new_layer.call, 'mask'):
                    kwargs['mask'] = computed_masks

                output_tensors = to_list(new_layer(computed_tensors, **kwargs))
                for x, y in zip(reference_output_tensors, output_tensors):
                    tensor_map[x] = (y, None)

    output_tensors = [tensor_map[x][0] for x in model.outputs]
    return Model(input_tensors, output_tensors, name=model.name)
```

This corrected code should handle the case of a functional model with multiple inputs and outputs correctly, and it should pass the failing test.