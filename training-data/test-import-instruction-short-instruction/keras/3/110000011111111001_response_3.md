The bug in the `_clone_functional_model` function seems to be related to the creation and mapping of input tensors. The error message indicates that the output tensor "swap_layer_1/Identity:0" cannot be computed, suggesting an issue with the creation or mapping of the input and output tensors.

It seems that the problem arises in the section of the code where the function iterates over every node in the reference model and tries to compute the output tensors. There might be an issue with how the input tensors are being mapped to the output tensors.

To fix the bug, we need to ensure that all input tensors are correctly mapped to the corresponding output tensors. Additionally, we should verify that the output tensors can indeed be computed based on the input tensors.

Here's a corrected version of the `_clone_functional_model` function:

```python
def _clone_functional_model(model, input_tensors=None):
    # ... (rest of the function remains unchanged)

    # Check that we did compute the model outputs,
    # then instantiate a new model from inputs and outputs.
    output_tensors = []
    for x in model.outputs:
        if x not in tensor_map:
            # If an output tensor is not in the tensor_map, it means it could not be computed
            raise ValueError('Could not compute output tensor ', x)
        tensor, _ = tensor_map[x]
        output_tensors.append(tensor)
    return Model(input_tensors, output_tensors, name=model.name)
```

In the corrected version above, we added a check to raise a ValueError if an output tensor is not found in the tensor_map, indicating that it could not be computed. This should address the issue raised in the failing test.

Make sure to test the corrected function with the failing test to verify that it passes successfully.