The bug in the `_clone_functional_model` function seems to be related to the way it handles the cloning of layers with multiple outputs when no masks are supported. This leads to an AssertionError when trying to compute the output tensors of the cloned model.

The error message indicates that the function is unable to compute the output tensor "swap_layer_1/Identity:0" of the model. This is likely due to the fact that the Lambda layer doesn't support using masks, and as a result, the `output_masks` are always `None`.

The GitHub issue also points out that the error can occur when using a functional model with a layer that has multiple outputs without mask support.

To fix this bug, the function needs to be modified to handle layers with multiple outputs and no mask support properly. One possible approach is to modify the function to check for the presence of masks in the output_tensors and only compute masks if the layer supports mask computation. If the layer doesn't support masks, the function should proceed without attempting to compute masks.

Here's the corrected code for the `_clone_functional_model` function:

```python
def _clone_functional_model(model, input_tensors=None):
    # ... (rest of the function remains unchanged)

    for x, y in zip(model.inputs, input_tensors):
        tensor_map[x] = (y, None)

    # Iterated over every node in the reference model, in depth order.
    depth_keys = list(model._nodes_by_depth.keys())
    depth_keys.sort(reverse=True)
    for depth in depth_keys:
        nodes = model._nodes_by_depth[depth]
        for node in nodes:
            # Recover the corresponding layer.
            layer = node.outbound_layer

            # Get or create layer.
            if layer not in layer_map:
                # Clone layer.
                new_layer = layer.__class__.from_config(layer.get_config())
                layer_map[layer] = new_layer
                layer = new_layer
            else:
                # Reuse previously cloned layer.
                layer = layer_map[layer]
                # Don't call InputLayer multiple times.
                if isinstance(layer, InputLayer):
                    continue

            # Gather inputs to call the new layer.
            reference_input_tensors = node.input_tensors
            reference_output_tensors = node.output_tensors

            # If all previous input tensors are available in tensor_map,
            # then call node.inbound_layer on them.
            computed_data = []  # List of tuples (input, mask).
            for x in reference_input_tensors:
                if x in tensor_map:
                    computed_data.append(tensor_map[x])

            if len(computed_data) == len(reference_input_tensors):
                # Call layer.
                if len(computed_data) == 1:
                    computed_tensor, _ = computed_data[0]
                    output_tensors = to_list(layer(computed_tensor))
                else:
                    computed_tensors = [x[0] for x in computed_data]
                    output_tensors = to_list(layer(computed_tensors))

                # Update tensor_map.
                for x, y in zip(reference_output_tensors, output_tensors):
                    tensor_map[x] = (y, None)

    # Check that we did compute the model outputs,
    # then instantiate a new model from inputs and outputs.
    output_tensors = []
    for x in model.outputs:
        assert x in tensor_map, 'Could not compute output ' + str(x)
        tensor, _ = tensor_map[x]
        output_tensors.append(tensor)

    return Model(input_tensors, output_tensors, name=model.name)
```

With these modifications, the function should be able to handle layers with multiple outputs and no mask support correctly, and the AssertionError should no longer occur.

The corrected function should now pass the failing test and satisfy the expected input/output variable information provided. Additionally, it should resolve the issue posted in the GitHub bug report.