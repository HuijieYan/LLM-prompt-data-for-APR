The bug in the `_clone_functional_model` function seems to be related to the creation of new layers and input tensors, as well as the mapping of input and output tensors. The bug likely causes a failure to properly compute the model outputs.

The failing test is trying to clone a functional model with multiple outputs. However, the error occurs at the assertion where it is unable to compute the output tensor `Tensor("swap_layer_1/Identity:0", shape=(?, 4), dtype=float32)`.

The cause of the bug is likely related to the improper handling of input_tensors and the mapping of input and output tensors. There is an issue with the creation and mapping of input tensors, and this seems to be affecting the computation of output tensors.

Possible approaches for fixing the bug might include:
1. Ensuring that the creation and mapping of input tensors is done correctly.
2. Checking that the input tensors are properly connected to the layers.
3. Verifying that the output tensors are properly computed and mapped.

Here is the corrected code for the `_clone_functional_model` function:

```python
def _clone_functional_model(model, input_tensors=None):
    if not isinstance(model, Model):
        raise ValueError('Expected `model` argument to be a `Model` instance, got ', model)

    layer_map = {}  
    tensor_map = {}  
    
    if input_tensors is None:
        input_tensors = [Input(batch_shape=layer.batch_input_shape,
                               dtype=layer.dtype,
                               sparse=layer.sparse,
                               name=layer.name) for layer in model._input_layers]
    else:
        input_tensors = to_list(input_tensors)
    
    for x, y in zip(model.inputs, input_tensors):
        tensor_map[x] = (y, None)  

    for depth in reversed(range(max(model._nodes_by_depth.keys()))):
        nodes = model._nodes_by_depth[depth]
        for node in nodes:
            layer = node.outbound_layer

            if layer not in layer_map:
                new_layer = layer.__class__.from_config(layer.get_config())
                layer_map[layer] = new_layer
                layer = new_layer
            else:
                layer = layer_map[layer]
                if isinstance(layer, InputLayer):
                    continue

            reference_input_tensors = node.input_tensors
            reference_output_tensors = node.output_tensors

            computed_data = [] 
            for x in reference_input_tensors:
                if x in tensor_map:
                    computed_data.append(tensor_map[x])

            if len(computed_data) == len(reference_input_tensors):
                kwargs = node.arguments if node.arguments else {}
                if len(computed_data) == 1:
                    computed_tensor, computed_mask = computed_data[0]
                    if has_arg(layer.call, 'mask') and 'mask' not in kwargs:
                        kwargs['mask'] = computed_mask
                    output_tensors = to_list(layer(computed_tensor, **kwargs))
                else:
                    computed_tensors = [x[0] for x in computed_data]
                    computed_masks = [x[1] for x in computed_data]
                    if has_arg(layer.call, 'mask') and 'mask' not in kwargs:
                        kwargs['mask'] = computed_masks
                    output_tensors = to_list(layer(computed_tensors, **kwargs))
                
                for x, y in zip(reference_output_tensors, output_tensors):
                    tensor_map[x] = (y, None)

    output_tensors = [tensor_map[x][0] for x in model.outputs]
    return Model(input_tensors, output_tensors, name=model.name)
```

With this corrected code, the failing test should pass as the input tensors are created and connected properly, and the output tensors are computed and mapped correctly.