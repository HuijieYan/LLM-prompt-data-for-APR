The bug is likely located in the section where the output_tensors are being computed. The error message "Could not compute output Tensor" suggests that the function failed to compute the output tensors for the model.

The problem is likely related to how the layer.compute_mask() method is being used. The failing test involves a Lambda layer, which does not support output masks. This causes the layer.compute_mask() method to always return None, leading to the assertion error.

To fix this bug, we can modify the code to handle the case where the layer does not support output masks. We can check if the layer supports masking before attempting to use the output masks in the computation.

Here's the corrected code for the problematic function:

```python
def _clone_functional_model(model, input_tensors=None):
    # ... (existing code)

    # Iterate over every node in the reference model, in depth order.
    depth_keys = list(model._nodes_by_depth.keys())
    depth_keys.sort(reverse=True)
    for depth in depth_keys:
        nodes = model._nodes_by_depth[depth]
        for node in nodes:
            # ... (existing code)

            # If all previous input tensors are available in tensor_map,
            # then call node.outbound_layer on them.
            computed_data = []  # List of tuples (input, mask).
            for x in reference_input_tensors:
                if x in tensor_map:
                    computed_data.append(tensor_map[x])

            if len(computed_data) == len(reference_input_tensors):
                # Call layer.
                if node.arguments:
                    kwargs = node.arguments
                else:
                    kwargs = {}

                computed_tensors = [x[0] for x in computed_data]

                # Check if the layer supports masking
                if has_arg(layer.call, 'mask'):
                    computed_masks = [x[1] for x in computed_data]
                    kwargs['mask'] = computed_masks
                    output_masks = to_list(
                        layer.compute_mask(computed_tensors, computed_masks))
                else:
                    output_masks = [None] * len(reference_output_tensors)

                output_tensors = to_list(layer(computed_tensors, **kwargs))

                # Update tensor_map.
                for x, y, mask in zip(reference_output_tensors, output_tensors, output_masks):
                    tensor_map[x] = (y, mask)

    # Check that we did compute the model outputs,
    # then instantiate a new model from inputs and outputs.
    output_tensors = []
    for x in model.outputs:
        assert x in tensor_map, 'Could not compute output ' + str(x)
        tensor, mask = tensor_map[x]
        output_tensors.append(tensor)
    return Model(input_tensors, output_tensors, name=model.name)
```

With this correction, the function should now handle the case where the layer does not support output masks, and the failing test should pass.

This fix ensures that the output masks are correctly handled even when the layer does not support masking, resolving the issue reported in the GitHub post.