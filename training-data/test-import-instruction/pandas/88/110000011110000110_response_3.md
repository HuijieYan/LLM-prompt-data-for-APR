```python
from typing import Any, List, Union
from pandas.core.frame import DataFrame
from pandas.core.generic import ABCDataFrame
from pandas.core.resample import Grouper
from pandas.core.groupby.groupby import GroupBy
from pandas.core.groupby.generic import DataFrameGroupBy
from pandas.core.groupby._groupby import Grouping, SeriesGroupBy
from pandas.core.series import Series
import pandas._typing as _typing
from pandas import MultiIndex, concat, Index, maybe_downcast_to_dtype, cartesian_product
from pandas._config import get_option
import pandas._libs.missing as libmissing
from pandas._typing import ArrayLike, Optional, Scalar
from pandas.core.dtypes.common import is_integer_dtype
from pandas.core.common import is_bool_indexer, is_int_indexer, is_list_like
import pandas.core.common as com
import numpy as np


def _add_margins(
    table: DataFrame,
    data: DataFrame,
    values: _typing.ArrayLike,
    rows: _typing.ArrayLike,
    cols: _typing.ArrayLike,
    aggfunc: _typing.Optional[_typing.Scalar],
    observed: _typing.Optional[bool],
    margins_name: _typing.Optional[Union[Scalar, _typing.Sequence]],
    fill_value: _typing.Scalar,
) -> DataFrame:
    pass

def _convert_by(by: Any) -> _typing.Optional[_typing.ArrayLike]:
    pass

def pivot_table(
    data: DataFrame,
    values: _typing.Optional[ArrayLike] = None,
    index: _typing.Optional[_typing.ArrayLike] = None,
    columns: _typing.Optional[_typing.ArrayLike] = None,
    aggfunc: _typing.Union[ArrayLike, str, _typing.Optional[Scalar], _typing.Callable] = "mean",
    fill_value: _typing.Optional[Scalar] = None,
    margins: bool = False,
    dropna: bool = True,
    margins_name: _typing.Optional[Union[Scalar, _typing.Sequence]] = "All",
    observed: _typing.Optional[bool] = False,
) -> DataFrame:

    index = _convert_by(index)
    columns = _convert_by(columns)

    if isinstance(aggfunc, list) and not _have_valid_type(values):
        pieces: List[DataFrame] = []
        keys = []
        for func in aggfunc:
            table = pivot_table(
                data,
                values=values,
                index=index,
                columns=columns,
                fill_value=fill_value,
                aggfunc=func,
                margins=margins,
                dropna=dropna,
                margins_name=margins_name,
                observed=observed,
            )
            pieces.append(table)
            keys.append(getattr(func, "__name__", func))

        return concat(pieces, keys=keys, axis=1)

    keys = index + columns

    values_passed = values is not None
    if values_passed:
        if is_list_like(values):
            values_multi = True
            values = list(values)
        else:
            values_multi = False
            values = [values]

        # GH14938 Make sure value labels are in data
        for i in values:
            if i not in data:
                raise KeyError(i)

        # to_filter = [x for x in keys + values if is_valid_list_like(x, data)]
        to_filter = []
        for x in keys + values:
            if isinstance(x, Grouper):
                x = x.key
            try:
                if x in data:
                    to_filter.append(x)
            except TypeError:
                pass
        if len(to_filter) < len(data.columns):
            data = data[to_filter]

    else:
        values = data.columns
        for key in keys:
            try:
                values = values.drop(key)
            except (TypeError, ValueError, KeyError):
                pass
        values = list(values)

    grouped = data.groupby(keys, observed=observed)

    # TODO: remove after cythonization, is needed here to pass tests
    if isinstance(grouped, SeriesGroupBy):
        grouped = GroupBy.get_grouper(grouped)

    agged = grouped.agg(aggfunc)
    out = agged
    if dropna and isinstance(agged, ABCDataFrame) and len(agged.columns):
        out = agged.dropna(how="all")

        thres = get_option("display.max_info_columns")
        if thres and len(out.columns) > thres:
            # suppress display of axis counts ( (n, 1) for row)
            out.columns.inf_repr = "{n}"
            out.index.inf_repr = "{n}"

    table = out
    if table.index.nlevels > 1:
        # Related GH #17123
        # If index_names are integers, determine whether the integers refer
        # to the level position or name.
        index_names = out.index.names[: len(index)]
        to_unstack = []
        for i in range(len(index), len(keys)):
            name = out.index.names[i]
            if name is None or name in index_names:
                to_unstack.append(i)
            else:
                to_unstack.append(name)
        table = out.unstack(to_unstack)

    if not dropna:
        if table.index.nlevels > 1:
            # GH 15102, 24065: reindex, not unstack
            m = MultiIndex.from_product(table.index.levels, names=table.index.names)
            table = table.reindex(m, axis=0)

        if table.columns.nlevels > 1:
            # GH 15102: reindex, not unstack
            m = MultiIndex.from_product(table.columns.levels, names=table.columns.names)
            table = table.reindex(m, axis=1)

    if isinstance(table, ABCDataFrame):
        table = table.sort_index(axis=1)

    if fill_value is not None:
        table = table.fillna(fill_value)

    if margins:
        data = data[data.notna().all(axis=1)]
        table = _add_margins(
            table,
            data,
            values,
            list(index) if index is not None else [],
            list(columns) if columns is not None else [],
            aggfunc,
            dropna,
            fill_value,
        )

    # TODO: add a performant check for level amount to issue a warning to users

    # discard the top level
    if (
        values_passed
        and not values_multi
        and not table.empty
        and (table.columns.nlevels > 1)
    ):
        table = table[values[0]]

    if len(index) == 0 and len(columns) > 0:
        table = table.T

    # GH 15193 Make sure empty columns are removed if dropna=True
    if isinstance(table, ABCDataFrame) and dropna:
        table = table.dropna(how="all", axis=1)

    return table
```