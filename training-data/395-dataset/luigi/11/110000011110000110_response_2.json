{
    "luigi": [
        {
            "bugID": 11,
            "bitvector": {
                "1.1.1": 1,
                "1.1.2": 1,
                "1.2.1": 0,
                "1.2.2": 0,
                "1.2.3": 0,
                "1.3.1": 0,
                "1.3.2": 0,
                "1.4.1": 1,
                "1.4.2": 1,
                "2.1.1": 1,
                "2.1.2": 1,
                "2.1.3": 0,
                "2.1.4": 0,
                "2.1.5": 0,
                "2.1.6": 0,
                "3.1.1": 1,
                "3.1.2": 1,
                "cot": 0
            },
            "strata": {
                "1": 1,
                "2": 0,
                "3": 0,
                "4": 1,
                "5": 0,
                "6": 1,
                "7": 0
            },
            "available_bitvector": {
                "1.1.1": 1,
                "1.1.2": 0,
                "1.2.1": 0,
                "1.2.2": 0,
                "1.2.3": 0,
                "1.3.1": 0,
                "1.3.2": 0,
                "1.4.1": 1,
                "1.4.2": 1,
                "2.1.1": 1,
                "2.1.2": 1,
                "2.1.3": 0,
                "2.1.4": 0,
                "2.1.5": 0,
                "2.1.6": 0,
                "3.1.1": 0,
                "3.1.2": 0,
                "cot": 0
            },
            "available_strata": {
                "1": 1,
                "2": 0,
                "3": 0,
                "4": 1,
                "5": 0,
                "6": 0,
                "7": 0
            },
            "start_line": 818,
            "file_name": "luigi/scheduler.py",
            "replace_code": "def get_work(self, host=None, assistant=False, current_tasks=None, worker=None, **kwargs):\n    # TODO: remove any expired nodes\n\n    # Algo: iterate over all nodes, find the highest priority node no dependencies and available\n    # resources.\n\n    # Resource checking looks both at currently available resources and at which resources would\n    # be available if all running tasks died and we rescheduled all workers greedily. We do both\n    # checks in order to prevent a worker with many low-priority tasks from starving other\n    # workers with higher priority tasks that share the same resources.\n\n    # TODO: remove tasks that can't be done, figure out if the worker has absolutely\n    # nothing it can wait for\n\n    if self._config.prune_on_get_work:\n        self.prune()\n\n    assert worker is not None\n    worker_id = worker\n    # Return remaining tasks that have no FAILED descendants\n    self.update(worker_id, {'host': host}, get_work=True)\n    if assistant:\n        self.add_worker(worker_id, [('assistant', assistant)])\n\n    batched_params, batched_tasks, max_batch_size = None, [], 1\n    relevant_tasks = self._state.get_pending_tasks()\n    tasks = list(relevant_tasks)\n    n_unique_pending = 0\n\n    for task in tasks:\n        if self._schedulable(task):\n            if task.status == PENDING:\n                if not assistant and len(task.workers) == 1:\n                    n_unique_pending += 1\n                elif assistant or worker_id in task.workers:\n                    batch_param_names, max_batch_size = self._state.get_batcher(worker_id, task.family)\n                    if batch_param_names and task.is_batchable():\n                        if not batched_params:\n                            batched_params = {name: set() for name in batch_param_names}\n                        if all(task.params.get(name) in batched_params[name] for name in batch_param_names):\n                            self._state.remove_task(task)\n                            batched_params = {name: batched_params[name].union({task.params[name]}) for name in batch_param_names}\n                            if len(batched_tasks) < max_batch_size:\n                                batched_tasks.append(task)\n\n    reply = {'n_pending_tasks': len(relevant_tasks),\n             'running_tasks': [],\n             'task_id': None,\n             'n_unique_pending': n_unique_pending}\n\n    if len(batched_tasks) > 1:\n        batch_string = '|'.join(task.id for task in batched_tasks)\n        batch_id = hashlib.md5(batch_string.encode('utf-8')).hexdigest()\n        for task in batched_tasks:\n            self._state.set_batch_running(task, batch_id, worker_id)\n        combined_params = batched_tasks[0].params.copy()\n        combined_params.update(dict.fromkeys(batched_params, list(batched_params.values())))\n        reply['task_family'] = batched_tasks[0].family\n        reply['task_module'] = getattr(batched_tasks[0], 'module', None)\n        reply['task_params'] = combined_params\n        reply['batch_id'] = batch_id\n        reply['batch_task_ids'] = [task.id for task in batched_tasks]\n    elif batched_tasks:\n        task = batched_tasks[0]\n        self._state.set_status(task, RUNNING, self._config)\n        task.worker_running = worker_id\n        task.time_running = time.time()\n        self._update_task_history(task, RUNNING, host=host)\n        reply['task_id'] = task.id\n        reply['task_family'] = task.family\n        reply['task_module'] = getattr(task, 'module', None)\n        reply['task_params'] = task.params\n    return reply",
            "import_list": []
        }
    ]
}