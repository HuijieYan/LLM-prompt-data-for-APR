{
    "luigi": [
        {
            "bugID": 11,
            "bitvector": {
                "1.1.1": 1,
                "1.1.2": 1,
                "1.2.1": 0,
                "1.2.2": 0,
                "1.2.3": 0,
                "1.3.1": 1,
                "1.3.2": 1,
                "1.4.1": 1,
                "1.4.2": 1,
                "2.1.1": 1,
                "2.1.2": 1,
                "2.1.3": 0,
                "2.1.4": 0,
                "2.1.5": 0,
                "2.1.6": 0,
                "3.1.1": 1,
                "3.1.2": 1,
                "cot": 0
            },
            "strata": {
                "1": 1,
                "2": 0,
                "3": 1,
                "4": 1,
                "5": 0,
                "6": 1,
                "7": 0
            },
            "available_bitvector": {
                "1.1.1": 1,
                "1.1.2": 0,
                "1.2.1": 0,
                "1.2.2": 0,
                "1.2.3": 0,
                "1.3.1": 1,
                "1.3.2": 1,
                "1.4.1": 1,
                "1.4.2": 1,
                "2.1.1": 1,
                "2.1.2": 1,
                "2.1.3": 0,
                "2.1.4": 0,
                "2.1.5": 0,
                "2.1.6": 0,
                "3.1.1": 0,
                "3.1.2": 0,
                "cot": 0
            },
            "available_strata": {
                "1": 1,
                "2": 0,
                "3": 1,
                "4": 1,
                "5": 0,
                "6": 0,
                "7": 0
            },
            "start_line": 818,
            "file_name": "luigi/scheduler.py",
            "replace_code": "def get_work(self, host=None, assistant=False, current_tasks=None, worker=None, **kwargs):\n        if self._config.prune_on_get_work:\n            self.prune()\n\n        assert worker is not None\n        worker_id = worker\n        self.update(worker_id, {'host': host}, get_work=True)\n        if assistant:\n            self.add_worker(worker_id, [('assistant', assistant)])\n\n        tasks = list(self._state.get_pending_tasks())\n        tasks.sort(key=self._rank, reverse=True)\n\n        for task in tasks:\n            if task.status == RUNNING and (assistant and getattr(task, 'runnable', bool(task.workers))) or worker_id in task.workers:\n                other_worker = self._state.get_worker(task.worker_running)\n                more_info = {'task_id': task.id, 'worker': str(other_worker)}\n                if other_worker is not None:\n                    more_info.update(other_worker.info)\n                running_tasks.append(more_info)\n\n            if task.status == PENDING and (assistant and getattr(task, 'runnable', bool(task.workers))) or worker_id in task.workers:\n                if self._upstream_status(task.id, upstream_table) != UPSTREAM_DISABLED:\n                    locally_pending_tasks += 1\n                    if len(task.workers) == 1 and not assistant:\n                        n_unique_pending += 1\n\n            if best_task and batched_params and task.family == best_task.family and len(batched_tasks) < max_batch_size and task.is_batchable() and all(task.params.get(name) == value for name, value in unbatched_params.items()):\n                for name, params in batched_params.items():\n                    params.append(task.params.get(name))\n                batched_tasks.append(task)\n\n            if current_tasks is not None:\n                self._reset_orphaned_batch_running_tasks(worker_id)\n\n            if assistant and not getattr(task, 'runnable', bool(task.workers)):\n                continue\n\n            if task.status == RUNNING and (task.worker_running in greedy_workers):\n                greedy_workers[task.worker_running] -= 1\n                for resource, amount in six.iteritems((task.resources or {})):\n                    greedy_resources[resource] += amount\n\n            if self._schedulable(task) and self._has_resources(task.resources, greedy_resources):\n                if (assistant and getattr(task, 'runnable', bool(task.workers))) or worker_id in task.workers:\n                    best_task = task\n                    batch_param_names, max_batch_size = self._state.get_batcher(\n                        worker_id, task.family)\n                    if batch_param_names and task.is_batchable():\n                        try:\n                            batched_params = {\n                                name: [task.params[name]] for name in batch_param_names\n                            }\n                            unbatched_params = {\n                                name: value for name, value in task.params.items()\n                                if name not in batched_params\n                            }\n                            batched_tasks.append(task)\n                        except KeyError:\n                            batched_params, unbatched_params = None, None\n                else:\n                    workers = itertools.chain(task.workers, [worker_id]) if assistant else task.workers\n                    for task_worker in workers:\n                        if greedy_workers.get(task_worker, 0) > 0:\n                            greedy_workers[task_worker] -= 1\n                            for resource, amount in six.iteritems((task.resources or {})):\n                                greedy_resources[resource] += amount\n                            break\n\n        response = {'n_pending_tasks': locally_pending_tasks,\n                    'running_tasks': running_tasks,\n                    'task_id': None,\n                    'n_unique_pending': n_unique_pending}\n\n        if len(batched_tasks) > 1:\n            batch_string = '|'.join(task.id for task in batched_tasks)\n            batch_id = hashlib.md5(batch_string.encode('utf-8')).hexdigest()\n            for task in batched_tasks:\n                self.set_batch_running(task, batch_id, worker_id)\n\n            combined_params = best_task.params.copy()\n            combined_params.update(batched_params)\n\n            response['task_id'] = None\n            response['task_family'] = best_task.family\n            response['task_module'] = getattr(best_task, 'module', None)\n            response['task_params'] = combined_params\n            response['batch_id'] = batch_id\n            response['batch_task_ids'] = [task.id for task in batched_tasks]\n\n        elif best_task:\n            self.set_status(best_task, RUNNING, self._config)\n            best_task.worker_running = worker_id\n            best_task.time_running = time.time()\n            self._update_task_history(best_task, RUNNING, host=host)\n\n            response['task_id'] = best_task.id\n            response['task_family'] = best_task.family\n            response['task_module'] = getattr(best_task, 'module', None)\n            response['task_params'] = best_task.params\n\n        return response",
            "imports": []
        }
    ]
}