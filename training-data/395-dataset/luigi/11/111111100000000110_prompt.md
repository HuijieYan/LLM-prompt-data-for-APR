Please fix the function/method provided below and provide the corrected function/method as the output.


# Buggy function source code
```python
# file name: /Volumes/SSD2T/bgp_envs/repos/luigi_11/luigi/scheduler.py

# relative function's signature in this file
def rpc_method(**request_args):
    # ... omitted code ...
    pass

# relative function's signature in this file
def is_batchable(self):
    # ... omitted code ...
    pass

# relative function's signature in this file
def update(self, worker_reference, get_work=False):
    # ... omitted code ...
    pass

# relative function's signature in this file
def prune(self, config):
    # ... omitted code ...
    pass

# relative function's signature in this file
def get_pending_tasks(self, state):
    # ... omitted code ...
    pass

# relative function's signature in this file
def is_trivial_worker(self, state):
    # ... omitted code ...
    pass

# relative function's signature in this file
def assistant(self):
    # ... omitted code ...
    pass

# relative function's signature in this file
def get_running_tasks(self):
    # ... omitted code ...
    pass

# relative function's signature in this file
def get_pending_tasks(self):
    # ... omitted code ...
    pass

# relative function's signature in this file
def get_batcher(self, worker_id, family):
    # ... omitted code ...
    pass

# relative function's signature in this file
def set_batch_running(self, task, batch_id, worker_id):
    # ... omitted code ...
    pass

# relative function's signature in this file
def set_status(self, task, new_status, config=None):
    # ... omitted code ...
    pass

# relative function's signature in this file
def get_active_workers(self, last_active_lt=None, last_get_work_gt=None):
    # ... omitted code ...
    pass

# relative function's signature in this file
def get_worker(self, worker_id):
    # ... omitted code ...
    pass

# relative function's signature in this file
def prune(self):
    # ... omitted code ...
    pass

# relative function's signature in this file
def update(self, worker_id, worker_reference=None, get_work=False):
    # ... omitted code ...
    pass

# relative function's signature in this file
def add_worker(self, worker, info, **kwargs):
    # ... omitted code ...
    pass

# relative function's signature in this file
def _has_resources(self, needed_resources, used_resources):
    # ... omitted code ...
    pass

# relative function's signature in this file
def _used_resources(self):
    # ... omitted code ...
    pass

# relative function's signature in this file
def _rank(self, task):
    # ... omitted code ...
    pass

# relative function's signature in this file
def _schedulable(self, task):
    # ... omitted code ...
    pass

# relative function's signature in this file
def _reset_orphaned_batch_running_tasks(self, worker_id):
    # ... omitted code ...
    pass

# relative function's signature in this file
def _upstream_status(self, task_id, upstream_status_table):
    # ... omitted code ...
    pass

# relative function's signature in this file
def resources(self):
    # ... omitted code ...
    pass

# relative function's signature in this file
def _update_task_history(self, task, status, host=None):
    # ... omitted code ...
    pass

# class declaration containing the buggy function
class Scheduler(object):
    """
    Async scheduler that can handle multiple workers, etc.
    
    Can be run locally or on a server (using RemoteScheduler + server.Server).
    """

    # ... omitted code ...


    # signature of a relative function in this class
    def prune(self):
        # ... omitted code ...
        pass

    # signature of a relative function in this class
    def update(self, worker_id, worker_reference=None, get_work=False):
        # ... omitted code ...
        pass

    # signature of a relative function in this class
    def add_worker(self, worker, info, **kwargs):
        # ... omitted code ...
        pass

    # signature of a relative function in this class
    def _has_resources(self, needed_resources, used_resources):
        # ... omitted code ...
        pass

    # signature of a relative function in this class
    def _used_resources(self):
        # ... omitted code ...
        pass

    # signature of a relative function in this class
    def _rank(self, task):
        # ... omitted code ...
        pass

    # signature of a relative function in this class
    def _schedulable(self, task):
        # ... omitted code ...
        pass

    # signature of a relative function in this class
    def _reset_orphaned_batch_running_tasks(self, worker_id):
        # ... omitted code ...
        pass

    # signature of a relative function in this class
    def _upstream_status(self, task_id, upstream_status_table):
        # ... omitted code ...
        pass

    # signature of a relative function in this class
    def resources(self):
        # ... omitted code ...
        pass

    # signature of a relative function in this class
    def _update_task_history(self, task, status, host=None):
        # ... omitted code ...
        pass



    # this is the buggy function you need to fix
    @rpc_method(allow_null=False)
    def get_work(self, host=None, assistant=False, current_tasks=None, worker=None, **kwargs):
        # TODO: remove any expired nodes
    
        # Algo: iterate over all nodes, find the highest priority node no dependencies and available
        # resources.
    
        # Resource checking looks both at currently available resources and at which resources would
        # be available if all running tasks died and we rescheduled all workers greedily. We do both
        # checks in order to prevent a worker with many low-priority tasks from starving other
        # workers with higher priority tasks that share the same resources.
    
        # TODO: remove tasks that can't be done, figure out if the worker has absolutely
        # nothing it can wait for
    
        if self._config.prune_on_get_work:
            self.prune()
    
        assert worker is not None
        worker_id = worker
        # Return remaining tasks that have no FAILED descendants
        self.update(worker_id, {'host': host}, get_work=True)
        if assistant:
            self.add_worker(worker_id, [('assistant', assistant)])
    
        batched_params, unbatched_params, batched_tasks, max_batch_size = None, None, [], 1
        best_task = None
        if current_tasks is not None:
            ct_set = set(current_tasks)
            for task in sorted(self._state.get_running_tasks(), key=self._rank):
                if task.worker_running == worker_id and task.id not in ct_set:
                    best_task = task
    
        if current_tasks is not None:
            # batch running tasks that weren't claimed since the last get_work go back in the pool
            self._reset_orphaned_batch_running_tasks(worker_id)
    
        locally_pending_tasks = 0
        running_tasks = []
        upstream_table = {}
    
        greedy_resources = collections.defaultdict(int)
        n_unique_pending = 0
    
        worker = self._state.get_worker(worker_id)
        if worker.is_trivial_worker(self._state):
            relevant_tasks = worker.get_pending_tasks(self._state)
            used_resources = collections.defaultdict(int)
            greedy_workers = dict()  # If there's no resources, then they can grab any task
        else:
            relevant_tasks = self._state.get_pending_tasks()
            used_resources = self._used_resources()
            activity_limit = time.time() - self._config.worker_disconnect_delay
            active_workers = self._state.get_active_workers(last_get_work_gt=activity_limit)
            greedy_workers = dict((worker.id, worker.info.get('workers', 1))
                                  for worker in active_workers)
        tasks = list(relevant_tasks)
        tasks.sort(key=self._rank, reverse=True)
    
        for task in tasks:
            in_workers = (assistant and getattr(task, 'runnable', bool(task.workers))) or worker_id in task.workers
            if task.status == RUNNING and in_workers:
                # Return a list of currently running tasks to the client,
                # makes it easier to troubleshoot
                other_worker = self._state.get_worker(task.worker_running)
                more_info = {'task_id': task.id, 'worker': str(other_worker)}
                if other_worker is not None:
                    more_info.update(other_worker.info)
                    running_tasks.append(more_info)
    
            if task.status == PENDING and in_workers:
                upstream_status = self._upstream_status(task.id, upstream_table)
                if upstream_status != UPSTREAM_DISABLED:
                    locally_pending_tasks += 1
                    if len(task.workers) == 1 and not assistant:
                        n_unique_pending += 1
    
            if (best_task and batched_params and task.family == best_task.family and
                    len(batched_tasks) < max_batch_size and task.is_batchable() and all(
                    task.params.get(name) == value for name, value in unbatched_params.items())):
                for name, params in batched_params.items():
                    params.append(task.params.get(name))
                batched_tasks.append(task)
            if best_task:
                continue
    
            if task.status == RUNNING and (task.worker_running in greedy_workers):
                greedy_workers[task.worker_running] -= 1
                for resource, amount in six.iteritems((task.resources or {})):
                    greedy_resources[resource] += amount
    
            if self._schedulable(task) and self._has_resources(task.resources, greedy_resources):
                if in_workers and self._has_resources(task.resources, used_resources):
                    best_task = task
                    batch_param_names, max_batch_size = self._state.get_batcher(
                        worker_id, task.family)
                    if batch_param_names and task.is_batchable():
                        try:
                            batched_params = {
                                name: [task.params[name]] for name in batch_param_names
                            }
                            unbatched_params = {
                                name: value for name, value in task.params.items()
                                if name not in batched_params
                            }
                            batched_tasks.append(task)
                        except KeyError:
                            batched_params, unbatched_params = None, None
                else:
                    workers = itertools.chain(task.workers, [worker_id]) if assistant else task.workers
                    for task_worker in workers:
                        if greedy_workers.get(task_worker, 0) > 0:
                            # use up a worker
                            greedy_workers[task_worker] -= 1
    
                            # keep track of the resources used in greedy scheduling
                            for resource, amount in six.iteritems((task.resources or {})):
                                greedy_resources[resource] += amount
    
                            break
    
        reply = {'n_pending_tasks': locally_pending_tasks,
                 'running_tasks': running_tasks,
                 'task_id': None,
                 'n_unique_pending': n_unique_pending}
    
        if len(batched_tasks) > 1:
            batch_string = '|'.join(task.id for task in batched_tasks)
            batch_id = hashlib.md5(batch_string.encode('utf-8')).hexdigest()
            for task in batched_tasks:
                self._state.set_batch_running(task, batch_id, worker_id)
    
            combined_params = best_task.params.copy()
            combined_params.update(batched_params)
    
            reply['task_id'] = None
            reply['task_family'] = best_task.family
            reply['task_module'] = getattr(best_task, 'module', None)
            reply['task_params'] = combined_params
            reply['batch_id'] = batch_id
            reply['batch_task_ids'] = [task.id for task in batched_tasks]
    
        elif best_task:
            self._state.set_status(best_task, RUNNING, self._config)
            best_task.worker_running = worker_id
            best_task.time_running = time.time()
            self._update_task_history(best_task, RUNNING, host=host)
    
            reply['task_id'] = best_task.id
            reply['task_family'] = best_task.family
            reply['task_module'] = getattr(best_task, 'module', None)
            reply['task_params'] = best_task.params
    
        return reply
    
```




