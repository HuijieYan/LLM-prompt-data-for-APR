{
    "luigi": [
        {
            "bugID": 11,
            "bitvector": {
                "1.1.1": 1,
                "1.1.2": 1,
                "1.2.1": 0,
                "1.2.2": 0,
                "1.2.3": 0,
                "1.3.1": 1,
                "1.3.2": 1,
                "1.4.1": 1,
                "1.4.2": 1,
                "2.1.1": 1,
                "2.1.2": 1,
                "2.1.3": 1,
                "2.1.4": 1,
                "2.1.5": 1,
                "2.1.6": 1,
                "3.1.1": 1,
                "3.1.2": 1,
                "cot": 1
            },
            "strata": {
                "1": 1,
                "2": 0,
                "3": 1,
                "4": 1,
                "5": 1,
                "6": 1,
                "7": 1
            },
            "available_bitvector": {
                "1.1.1": 1,
                "1.1.2": 0,
                "1.2.1": 0,
                "1.2.2": 0,
                "1.2.3": 0,
                "1.3.1": 1,
                "1.3.2": 1,
                "1.4.1": 1,
                "1.4.2": 1,
                "2.1.1": 1,
                "2.1.2": 1,
                "2.1.3": 1,
                "2.1.4": 1,
                "2.1.5": 1,
                "2.1.6": 1,
                "3.1.1": 0,
                "3.1.2": 0,
                "cot": 1
            },
            "available_strata": {
                "1": 1,
                "2": 0,
                "3": 1,
                "4": 1,
                "5": 1,
                "6": 0,
                "7": 1
            },
            "start_line": 818,
            "file_name": "luigi/scheduler.py",
            "replace_code": "def get_work(self, host=None, assistant=False, current_tasks=None, worker=None, **kwargs):\n    if self._config.prune_on_get_work:\n        self.prune()\n    \n    assert worker is not None\n    worker_id = worker\n    self.update(worker_id, {'host': host}, get_work=True)\n    if assistant:\n        self.add_worker(worker_id, [('assistant', assistant)])\n    \n    batched_params, unbatched_params, batched_tasks, max_batch_size = None, None, [], 1\n    best_task = None\n    \n    if current_tasks is not None:\n        self._reset_orphaned_batch_running_tasks(worker_id)\n    \n    locally_pending_tasks = 0\n    running_tasks = []\n    upstream_table = {}\n    \n    greedy_resources = collections.defaultdict(int)\n    n_unique_pending = 0\n    \n    worker = self._state.get_worker(worker_id)\n    relevant_tasks = worker.get_pending_tasks(self._state) if worker.is_trivial_worker(self._state) else self._state.get_pending_tasks()\n    used_resources = self._used_resources()\n    \n    activity_limit = time.time() - self._config.worker_disconnect_delay\n    active_workers = self._state.get_active_workers(last_get_work_gt=activity_limit)\n    greedy_workers = dict((worker.id, worker.info.get('workers', 1)) for worker in active_workers)\n    \n    tasks = list(relevant_tasks)\n    tasks.sort(key=self._rank, reverse=True)\n    \n    for task in tasks:\n        if task.status == PENDING:\n            upstream_status = self._upstream_status(task.id, upstream_table)\n            if upstream_status != UPSTREAM_DISABLED:\n                locally_pending_tasks += 1\n                if len(task.workers) == 1 and not assistant:\n                    n_unique_pending += 1\n    \n        if task.is_batchable() and len(batched_tasks) < max_batch_size and task.status == PENDING:\n            for t in batched_tasks:\n                if t.family == task.family and all(t.params.get(name) == task.params.get(name) for name in batched_params.keys()):\n                    batched_tasks.append(task)\n                    break\n    \n    response = {\n        'n_pending_tasks': locally_pending_tasks,\n        'running_tasks': running_tasks,\n        'task_id': None,\n        'n_unique_pending': n_unique_pending\n    }\n    \n    if len(batched_tasks) > 1:\n        batch_string = '|'.join(task.id for task in batched_tasks)\n        batch_id = hashlib.md5(batch_string.encode('utf-8')).hexdigest()\n        for t in batched_tasks:\n            self._state.set_batch_running(t, batch_id, worker_id)\n        \n        combined_params = batched_params.copy()\n        combined_params.update(unbatched_params)\n        \n        response.update({\n            'task_id': None,\n            'task_family': task.family,\n            'task_module': getattr(task, 'module', None),\n            'task_params': combined_params,\n            'batch_id': batch_id,\n            'batch_task_ids': [t.id for t in batched_tasks]\n        })\n    elif best_task:\n        self._state.set_status(best_task, RUNNING, self._config)\n        best_task.worker_running = worker_id\n        best_task.time_running = time.time()\n        self._update_task_history(best_task, RUNNING, host=host)\n        \n        response.update({\n            'task_id': best_task.id,\n            'task_family': best_task.family,\n            'task_module': getattr(best_task, 'module', None),\n            'task_params': best_task.params\n        })\n    \n    return response",
            "import_list": []
        }
    ]
}