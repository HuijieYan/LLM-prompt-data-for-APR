{
    "luigi": [
        {
            "bugID": 11,
            "bitvector": {
                "1.1.1": 1,
                "1.1.2": 1,
                "1.2.1": 1,
                "1.2.2": 1,
                "1.2.3": 1,
                "1.3.1": 0,
                "1.3.2": 0,
                "1.4.1": 0,
                "1.4.2": 0,
                "2.1.1": 0,
                "2.1.2": 0,
                "2.1.3": 1,
                "2.1.4": 1,
                "2.1.5": 1,
                "2.1.6": 1,
                "3.1.1": 0,
                "3.1.2": 0,
                "cot": 1
            },
            "strata": {
                "1": 1,
                "2": 1,
                "3": 0,
                "4": 0,
                "5": 1,
                "6": 0,
                "7": 1
            },
            "available_bitvector": {
                "1.1.1": 1,
                "1.1.2": 0,
                "1.2.1": 1,
                "1.2.2": 1,
                "1.2.3": 1,
                "1.3.1": 0,
                "1.3.2": 0,
                "1.4.1": 0,
                "1.4.2": 0,
                "2.1.1": 0,
                "2.1.2": 0,
                "2.1.3": 1,
                "2.1.4": 1,
                "2.1.5": 1,
                "2.1.6": 1,
                "3.1.1": 0,
                "3.1.2": 0,
                "cot": 1
            },
            "available_strata": {
                "1": 1,
                "2": 1,
                "3": 0,
                "4": 0,
                "5": 1,
                "6": 0,
                "7": 1
            },
            "start_line": 818,
            "file_name": "luigi/scheduler.py",
            "replace_code": "def get_work(self, host=None, assistant=False, current_tasks=None, worker=None, **kwargs):\n    if self._config.prune_on_get_work:\n        self.prune()\n    \n    assert worker is not None\n    worker_id = worker\n    self.update(worker_id, {'host': host}, get_work=True)\n    if assistant:\n        self.add_worker(worker_id, [('assistant', assistant)])\n    \n    batched_params, unbatched_params, batched_tasks, max_batch_size = {}, {}, [], float('inf')\n    best_task = None\n    if current_tasks is not None:\n        ct_set = set(current_tasks)\n        for task in sorted(self._state.get_running_tasks(), key=self._rank):\n            if task.worker_running == worker_id and task.id not in ct_set:\n                best_task = task\n                break\n    \n    if current_tasks is not None:\n        self._reset_orphaned_batch_running_tasks(worker_id)\n    \n    relevant_tasks = self._state.get_worker(worker_id).get_pending_tasks(self._state) if self._state.get_worker(worker_id).is_trivial_worker(self._state) else self._state.get_pending_tasks()\n    used_resources = self._used_resources()\n    tasks = list(relevant_tasks)\n    tasks.sort(key=self._rank, reverse=True)\n    \n    for task in tasks:\n        if task.family == best_task.family and len(batched_tasks) < max_batch_size and task.is_batchable() and all(task.params.get(name) == value for name, value in unbatched_params.items()):\n            batched_tasks.append(task)\n            for name, value in batched_params.items():\n                value.append(task.params.get(name))\n                \n        if best_task:\n            break\n    \n    # Remaining code to be modified accordingly\n    \n    reply = {'n_pending_tasks': locally_pending_tasks,\n             'running_tasks': running_tasks,\n             'task_id': None,\n             'n_unique_pending': n_unique_pending}\n    \n    return reply",
            "imports": []
        }
    ]
}