{
    "keras": [
        {
            "bugID": 5,
            "bitvector": {
                "1.1.1": 1,
                "1.1.2": 1,
                "1.2.1": 1,
                "1.2.2": 1,
                "1.2.3": 1,
                "1.3.1": 0,
                "1.3.2": 0,
                "1.4.1": 0,
                "1.4.2": 0,
                "2.1.1": 0,
                "2.1.2": 0,
                "2.1.3": 0,
                "2.1.4": 0,
                "2.1.5": 0,
                "2.1.6": 0,
                "3.1.1": 0,
                "3.1.2": 0,
                "cot": 0
            },
            "strata": {
                "1": 1,
                "2": 1,
                "3": 0,
                "4": 0,
                "5": 0,
                "6": 0,
                "7": 0
            },
            "available_bitvector": {
                "1.1.1": 1,
                "1.1.2": 1,
                "1.2.1": 0,
                "1.2.2": 0,
                "1.2.3": 0,
                "1.3.1": 0,
                "1.3.2": 0,
                "1.4.1": 0,
                "1.4.2": 0,
                "2.1.1": 0,
                "2.1.2": 0,
                "2.1.3": 0,
                "2.1.4": 0,
                "2.1.5": 0,
                "2.1.6": 0,
                "3.1.1": 0,
                "3.1.2": 0,
                "cot": 0
            },
            "available_strata": {
                "1": 1,
                "2": 0,
                "3": 0,
                "4": 0,
                "5": 0,
                "6": 0,
                "7": 0
            },
            "start_line": 123,
            "file_name": "keras/utils/data_utils.py",
            "replace_code": "def get_file(fname,\n             origin,\n             untar=False,\n             md5_hash=None,\n             file_hash=None,\n             cache_subdir='datasets',\n             hash_algorithm='auto',\n             extract=False,\n             archive_format='auto',\n             cache_dir=None):\n\n    if cache_dir is None:\n        cache_dir = os.path.join(os.path.expanduser('~'), '.keras')\n    if md5_hash is not None and file_hash is None:\n        file_hash = md5_hash\n        hash_algorithm = 'md5'\n    datadir_base = os.path.expanduser(cache_dir)\n    if not os.access(datadir_base, os.W_OK):\n        datadir_base = os.path.join('/tmp', '.keras')\n    datadir = os.path.join(datadir_base, cache_subdir)\n    os.makedirs(datadir, exist_ok=True)\n\n    if untar:\n        untar_fpath = os.path.join(datadir, fname)\n        fpath = untar_fpath + '.tar.gz'\n    else:\n        fpath = os.path.join(datadir, fname)\n\n    download = False\n    if os.path.exists(fpath):\n        if file_hash is not None:\n            if not validate_file(fpath, file_hash, hash_algorithm):\n                print('A local file was found, but it seems to be ' \n                      'incomplete or outdated because the ' + hash_algorithm +\n                      ' file hash does not match the original value of ' +\n                      file_hash + ' so we will re-download the data.')\n                download = True\n    else:\n        download = True\n\n    if download:\n        print('Downloading data from', origin)\n        error_msg = 'URL fetch failure on {}: {} -- {}'\n        try:\n            try:\n                # From Python 3.7, we specify the integrity check explicitly.\n                urlopener = urlopen(origin)\n                hasher = hashlib.sha256()\n                try:\n                    with tempfile.NamedTemporaryFile(delete=False) as tmp_file:\n                        for chunk in iter(lambda: urlopener.read(65536), b\"\"):\n                            hasher.update(chunk)\n                            tmp_file.write(chunk)\n                    tmp_file_path = tmp_file.name\n                except Exception:\n                    pass\n                finally:\n                    urlopener.close()\n                _hash = hasher.hexdigest()\n                if file_hash is not None and _hash != file_hash:\n                    raise Exception('The file {} has an invalid SHA256 hash {}.'\n                                    'Expected {}'\n                                    .format(fpath, _hash, file_hash))\n                shutil.move(tmp_file_path, fpath)\n                \n            except HTTPError as e:\n                raise Exception(error_msg.format(origin, e.code, e.msg))\n            except URLError as e:\n                raise Exception(error_msg.format(origin, e.errno, e.reason))\n        except Exception as e:\n            if os.path.exists(fpath):\n                os.remove(fpath)\n            raise",
            "import_list": [
                "import os",
                "import sys",
                "import hashlib",
                "import shutil",
                "import tarfile",
                "import zipfile",
                "import posixpath",
                "from urllib.request import urlopen",
                "from urllib.parse import urlparse",
                "from keras.utils import Progbar",
                "from backports import tempfile",
                "import tempfile"
            ]
        }
    ]
}