{
    "1.1.1": "def _clone_functional_model(model, input_tensors=None):\n    \n    if not isinstance(model, Model):\n        raise ValueError('Expected `model` argument '\n                         'to be a `Model` instance, got ', model)\n    if isinstance(model, Sequential):\n        raise ValueError('Expected `model` argument '\n                         'to be a functional `Model` instance, '\n                         'got a `Sequential` instance instead:', model)\n\n    layer_map = {}  # Cache for created layers.\n    tensor_map = {}  # Map {reference_tensor: (corresponding_tensor, mask)}\n    if input_tensors is None:\n        # Create placeholders to build the model on top of.\n        input_layers = []\n        input_tensors = []\n        for layer in model._input_layers:\n            input_tensor = Input(batch_shape=layer.batch_input_shape,\n                                 dtype=layer.dtype,\n                                 sparse=layer.sparse,\n                                 name=layer.name)\n            input_tensors.append(input_tensor)\n            # Cache newly created input layer.\n            newly_created_input_layer = input_tensor._keras_history[0]\n            layer_map[layer] = newly_created_input_layer\n        for _original, _cloned in zip(model._input_layers, input_layers):\n            layer_map[_original] = _cloned\n    else:\n        # Make sure that all input tensors come from a Keras layer.\n        # If tensor comes from an input layer: cache the input layer.\n        input_tensors = to_list(input_tensors)\n        _input_tensors = []\n        for i, x in enumerate(input_tensors):\n            if not K.is_keras_tensor(x):\n                name = model._input_layers[i].name\n                input_tensor = Input(tensor=x,\n                                     name='input_wrapper_for_' + name)\n                _input_tensors.append(input_tensor)\n                # Cache newly created input layer.\n                original_input_layer = x._keras_history[0]\n                newly_created_input_layer = input_tensor._keras_history[0]\n                layer_map[original_input_layer] = newly_created_input_layer\n            else:\n                _input_tensors.append(x)\n        input_tensors = _input_tensors\n\n    for x, y in zip(model.inputs, input_tensors):\n        tensor_map[x] = (y, None)  # tensor, mask\n\n    # Iterated over every node in the reference model, in depth order.\n    depth_keys = list(model._nodes_by_depth.keys())\n    depth_keys.sort(reverse=True)\n    for depth in depth_keys:\n        nodes = model._nodes_by_depth[depth]\n        for node in nodes:\n            # Recover the corresponding layer.\n            layer = node.outbound_layer\n\n            # Get or create layer.\n            if layer not in layer_map:\n                # Clone layer.\n                new_layer = layer.__class__.from_config(layer.get_config())\n                layer_map[layer] = new_layer\n                layer = new_layer\n            else:\n                # Reuse previously cloned layer.\n                layer = layer_map[layer]\n                # Don't call InputLayer multiple times.\n                if isinstance(layer, InputLayer):\n                    continue\n\n            # Gather inputs to call the new layer.\n            reference_input_tensors = node.input_tensors\n            reference_output_tensors = node.output_tensors\n\n            # If all previous input tensors are available in tensor_map,\n            # then call node.inbound_layer on them.\n            computed_data = []  # List of tuples (input, mask).\n            for x in reference_input_tensors:\n                if x in tensor_map:\n                    computed_data.append(tensor_map[x])\n\n            if len(computed_data) == len(reference_input_tensors):\n                # Call layer.\n                if node.arguments:\n                    kwargs = node.arguments\n                else:\n                    kwargs = {}\n                if len(computed_data) == 1:\n                    computed_tensor, computed_mask = computed_data[0]\n                    if has_arg(layer.call, 'mask'):\n                        if 'mask' not in kwargs:\n                            kwargs['mask'] = computed_mask\n                    output_tensors = to_list(\n                        layer(computed_tensor, **kwargs))\n                    output_masks = to_list(\n                        layer.compute_mask(computed_tensor,\n                                           computed_mask))\n                    computed_tensors = [computed_tensor]\n                    computed_masks = [computed_mask]\n                else:\n                    computed_tensors = [x[0] for x in computed_data]\n                    computed_masks = [x[1] for x in computed_data]\n                    if has_arg(layer.call, 'mask'):\n                        if 'mask' not in kwargs:\n                            kwargs['mask'] = computed_masks\n                    output_tensors = to_list(\n                        layer(computed_tensors, **kwargs))\n                    output_masks = to_list(\n                        layer.compute_mask(computed_tensors,\n                                           computed_masks))\n                # Update tensor_map.\n                for x, y, mask in zip(reference_output_tensors,\n                                      output_tensors,\n                                      output_masks):\n                    tensor_map[x] = (y, mask)\n\n    # Check that we did compute the model outputs,\n    # then instantiate a new model from inputs and outputs.\n    output_tensors = []\n    for x in model.outputs:\n        assert x in tensor_map, 'Could not compute output ' + str(x)\n        tensor, _ = tensor_map[x]\n        output_tensors.append(tensor)\n    return Model(input_tensors, output_tensors, name=model.name)\n",
    "1.1.2": "Clone a functional `Model` instance.\n\nModel cloning is similar to calling a model on new inputs,\nexcept that it creates new layers (and thus new weights) instead\nof sharing the weights of the existing layers.\n\n# Arguments\n    model: Instance of `Model`.\n    input_tensors: optional list of input tensors\n        to build the model upon. If not provided,\n        placeholders will be created.\n\n# Returns\n    An instance of `Model` reproducing the behavior\n    of the original model, on top of new inputs tensors,\n    using newly instantiated weights.\n\n# Raises\n    ValueError: in case of invalid `model` argument value.",
    "1.2.1": null,
    "1.2.2": null,
    "1.2.3": null,
    "1.2.4": null,
    "1.2.5": null,
    "1.3.1": "keras/models.py",
    "1.3.2": null,
    "1.4.1": [
        "def test_clone_functional_model_with_multi_outputs():\n    input_layer = keras.Input(shape=(4,))\n\n    # Layer with single input and multiple outputs\n    layer1 = keras.layers.Lambda(lambda x: [x + 1, x],\n                                 lambda shapes: [shapes, shapes])\n    x_a, x_b = layer1(input_layer)\n\n    class SwapLayer(keras.layers.Layer):\n        def call(self, inputs, **kwargs):\n            return [inputs[1], inputs[0]]\n\n        def compute_output_shape(self, input_shape):\n            return [input_shape[1], input_shape[0]]\n\n    # Layer with multiple inputs and outputs\n    x_a, x_b = SwapLayer()([x_a, x_b])\n    model = keras.Model(inputs=[input_layer], outputs=[x_a, x_b])\n    new_model = keras.models.clone_model(model)\n\n    x_test = np.random.random((10, 4))\n    pred_a, pred_b = model.predict(x_test)\n    pred_new_a, pred_new_b = new_model.predict(x_test)\n    assert(pred_a.all() == pred_new_a.all())\n    assert(pred_b.all() == pred_new_b.all())"
    ],
    "1.4.2": [
        "tests/keras/test_sequential_model.py"
    ],
    "2.1.1": [
        [
            "E           AssertionError: Could not compute output Tensor(\"swap_layer_1/Identity:0\", shape=(?, 4), dtype=float32)"
        ]
    ],
    "2.1.2": [
        [
            "def test_clone_functional_model_with_multi_outputs():\n        input_layer = keras.Input(shape=(4,))\n    \n        # Layer with single input and multiple outputs\n        layer1 = keras.layers.Lambda(lambda x: [x + 1, x],\n                                     lambda shapes: [shapes, shapes])\n        x_a, x_b = layer1(input_layer)\n    \n        class SwapLayer(keras.layers.Layer):\n            def call(self, inputs, **kwargs):\n                return [inputs[1], inputs[0]]\n    \n            def compute_output_shape(self, input_shape):\n                return [input_shape[1], input_shape[0]]\n    \n        # Layer with multiple inputs and outputs\n        x_a, x_b = SwapLayer()([x_a, x_b])\n        model = keras.Model(inputs=[input_layer], outputs=[x_a, x_b])\n>       new_model = keras.models.clone_model(model)\n\ntests/keras/test_sequential_model.py:360: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nkeras/models.py:251: in clone_model\n    return _clone_functional_model(model, input_tensors=input_tensors)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nmodel = <keras.engine.training.Model object at 0x12ee73910>\ninput_tensors = [<tf.Tensor 'input_1_1:0' shape=(?, 4) dtype=float32>]\n\n    def _clone_functional_model(model, input_tensors=None):\n        \"\"\"Clone a functional `Model` instance.\n    \n        Model cloning is similar to calling a model on new inputs,\n        except that it creates new layers (and thus new weights) instead\n        of sharing the weights of the existing layers.\n    \n        # Arguments\n            model: Instance of `Model`.\n            input_tensors: optional list of input tensors\n                to build the model upon. If not provided,\n                placeholders will be created.\n    \n        # Returns\n            An instance of `Model` reproducing the behavior\n            of the original model, on top of new inputs tensors,\n            using newly instantiated weights.\n    \n        # Raises\n            ValueError: in case of invalid `model` argument value.\n        \"\"\"\n        if not isinstance(model, Model):\n            raise ValueError('Expected `model` argument '\n                             'to be a `Model` instance, got ', model)\n        if isinstance(model, Sequential):\n            raise ValueError('Expected `model` argument '\n                             'to be a functional `Model` instance, '\n                             'got a `Sequential` instance instead:', model)\n    \n        layer_map = {}  # Cache for created layers.\n        tensor_map = {}  # Map {reference_tensor: (corresponding_tensor, mask)}\n        if input_tensors is None:\n            # Create placeholders to build the model on top of.\n            input_layers = []\n            input_tensors = []\n            for layer in model._input_layers:\n                input_tensor = Input(batch_shape=layer.batch_input_shape,\n                                     dtype=layer.dtype,\n                                     sparse=layer.sparse,\n                                     name=layer.name)\n                input_tensors.append(input_tensor)\n                # Cache newly created input layer.\n                newly_created_input_layer = input_tensor._keras_history[0]\n                layer_map[layer] = newly_created_input_layer\n            for _original, _cloned in zip(model._input_layers, input_layers):\n                layer_map[_original] = _cloned\n        else:\n            # Make sure that all input tensors come from a Keras layer.\n            # If tensor comes from an input layer: cache the input layer.\n            input_tensors = to_list(input_tensors)\n            _input_tensors = []\n            for i, x in enumerate(input_tensors):\n                if not K.is_keras_tensor(x):\n                    name = model._input_layers[i].name\n                    input_tensor = Input(tensor=x,\n                                         name='input_wrapper_for_' + name)\n                    _input_tensors.append(input_tensor)\n                    # Cache newly created input layer.\n                    original_input_layer = x._keras_history[0]\n                    newly_created_input_layer = input_tensor._keras_history[0]\n                    layer_map[original_input_layer] = newly_created_input_layer\n                else:\n                    _input_tensors.append(x)\n            input_tensors = _input_tensors\n    \n        for x, y in zip(model.inputs, input_tensors):\n            tensor_map[x] = (y, None)  # tensor, mask\n    \n        # Iterated over every node in the reference model, in depth order.\n        depth_keys = list(model._nodes_by_depth.keys())\n        depth_keys.sort(reverse=True)\n        for depth in depth_keys:\n            nodes = model._nodes_by_depth[depth]\n            for node in nodes:\n                # Recover the corresponding layer.\n                layer = node.outbound_layer\n    \n                # Get or create layer.\n                if layer not in layer_map:\n                    # Clone layer.\n                    new_layer = layer.__class__.from_config(layer.get_config())\n                    layer_map[layer] = new_layer\n                    layer = new_layer\n                else:\n                    # Reuse previously cloned layer.\n                    layer = layer_map[layer]\n                    # Don't call InputLayer multiple times.\n                    if isinstance(layer, InputLayer):\n                        continue\n    \n                # Gather inputs to call the new layer.\n                reference_input_tensors = node.input_tensors\n                reference_output_tensors = node.output_tensors\n    \n                # If all previous input tensors are available in tensor_map,\n                # then call node.inbound_layer on them.\n                computed_data = []  # List of tuples (input, mask).\n                for x in reference_input_tensors:\n                    if x in tensor_map:\n                        computed_data.append(tensor_map[x])\n    \n                if len(computed_data) == len(reference_input_tensors):\n                    # Call layer.\n                    if node.arguments:\n                        kwargs = node.arguments\n                    else:\n                        kwargs = {}\n                    if len(computed_data) == 1:\n                        computed_tensor, computed_mask = computed_data[0]\n                        if has_arg(layer.call, 'mask'):\n                            if 'mask' not in kwargs:\n                                kwargs['mask'] = computed_mask\n                        output_tensors = to_list(\n                            layer(computed_tensor, **kwargs))\n                        output_masks = to_list(\n                            layer.compute_mask(computed_tensor,\n                                               computed_mask))\n                        computed_tensors = [computed_tensor]\n                        computed_masks = [computed_mask]\n                    else:\n                        computed_tensors = [x[0] for x in computed_data]\n                        computed_masks = [x[1] for x in computed_data]\n                        if has_arg(layer.call, 'mask'):\n                            if 'mask' not in kwargs:\n                                kwargs['mask'] = computed_masks\n                        output_tensors = to_list(\n                            layer(computed_tensors, **kwargs))\n                        output_masks = to_list(\n                            layer.compute_mask(computed_tensors,\n                                               computed_masks))\n                    # Update tensor_map.\n                    for x, y, mask in zip(reference_output_tensors,\n                                          output_tensors,\n                                          output_masks):\n                        tensor_map[x] = (y, mask)\n    \n        # Check that we did compute the model outputs,\n        # then instantiate a new model from inputs and outputs.\n        output_tensors = []\n        for x in model.outputs:\n>           assert x in tensor_map, 'Could not compute output ' + str(x)",
            "\nkeras/models.py:166: AssertionError"
        ]
    ],
    "2.1.3": null,
    "2.1.4": null,
    "2.1.5": [
        [
            {
                "model": "<keras.engine.training.Model object at 0x128fd8990>",
                "model._input_layers": "[<keras.engine.input_layer.InputLayer object at 0x128e684d0>]",
                "model.inputs": "[<tf.Tensor 'input_1:0' shape=(?, 4) dtype=float32>]",
                "model._nodes_by_depth": "{0: [<keras.engine.base_layer.Node object at 0x128fd8610>], 1: [<keras.engine.base_layer.Node object at 0x128fd8450>], 2: [<keras.engine.base_layer.Node object at 0x128fd8b10>]}",
                "model.outputs": "[<tf.Tensor 'swap_layer_1/Identity:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'swap_layer_1/Identity_1:0' shape=(?, 4) dtype=float32>]",
                "model.name": "'model_1'"
            },
            {
                "layer_map": "{<keras.engine.input_layer.InputLayer object at 0x128e684d0>: <keras.engine.input_layer.InputLayer object at 0x128e68d90>, <keras.layers.core.Lambda object at 0x128fd8e90>: <keras.layers.core.Lambda object at 0x128e68e90>, <test_sequential_model.test_clone_functional_model_with_multi_outputs.<locals>.SwapLayer object at 0x128fd8550>: <test_sequential_model.test_clone_functional_model_with_multi_outputs.<locals>.SwapLayer object at 0x128e68fd0>}",
                "tensor_map": "array of shape 5",
                "input_tensors": "[<tf.Tensor 'input_1_1:0' shape=(?, 4) dtype=float32>]",
                "input_layers": "[]",
                "layer": "<test_sequential_model.test_clone_functional_model_with_multi_outputs.<locals>.SwapLayer object at 0x128e68fd0>",
                "input_tensor": "<tf.Tensor 'input_1_1:0' shape=(?, 4) dtype=float32>",
                "layer.name": "'swap_layer_1'",
                "newly_created_input_layer": "<keras.engine.input_layer.InputLayer object at 0x128e68d90>",
                "input_tensor._keras_history": "(<keras.engine.input_layer.InputLayer object at 0x128e68d90>, 0, 0)",
                "x": "<tf.Tensor 'swap_layer_1/Identity_1:0' shape=(?, 4) dtype=float32>",
                "x._keras_history": "(<test_sequential_model.test_clone_functional_model_with_multi_outputs.<locals>.SwapLayer object at 0x128fd8550>, 0, 1)",
                "y": "<tf.Tensor 'swap_layer_1_1/Identity_1:0' shape=(?, 4) dtype=float32>",
                "depth_keys": "[2, 1, 0]",
                "depth": "0",
                "nodes": "[<keras.engine.base_layer.Node object at 0x128fd8610>]",
                "node": "<keras.engine.base_layer.Node object at 0x128fd8610>",
                "node.outbound_layer": "<test_sequential_model.test_clone_functional_model_with_multi_outputs.<locals>.SwapLayer object at 0x128fd8550>",
                "new_layer": "<test_sequential_model.test_clone_functional_model_with_multi_outputs.<locals>.SwapLayer object at 0x128e68fd0>",
                "layer.__class__": "<class 'test_sequential_model.test_clone_functional_model_with_multi_outputs.<locals>.SwapLayer'>",
                "layer.get_config": "<bound method Layer.get_config of <test_sequential_model.test_clone_functional_model_with_multi_outputs.<locals>.SwapLayer object at 0x128e68fd0>>",
                "reference_input_tensors": "[<tf.Tensor 'lambda_1/add:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'lambda_1/Identity:0' shape=(?, 4) dtype=float32>]",
                "node.input_tensors": "[<tf.Tensor 'lambda_1/add:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'lambda_1/Identity:0' shape=(?, 4) dtype=float32>]",
                "reference_output_tensors": "[<tf.Tensor 'swap_layer_1/Identity:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'swap_layer_1/Identity_1:0' shape=(?, 4) dtype=float32>]",
                "node.output_tensors": "[<tf.Tensor 'swap_layer_1/Identity:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'swap_layer_1/Identity_1:0' shape=(?, 4) dtype=float32>]",
                "computed_data": "[(<tf.Tensor 'lambda_1_1/add:0' shape=(?, 4) dtype=float32>, None), (<tf.Tensor 'lambda_1_1/Identity:0' shape=(?, 4) dtype=float32>, None)]",
                "node.arguments": "{}",
                "kwargs": "{}",
                "computed_tensor": "<tf.Tensor 'input_1_1:0' shape=(?, 4) dtype=float32>",
                "layer.call": "<bound method test_clone_functional_model_with_multi_outputs.<locals>.SwapLayer.call of <test_sequential_model.test_clone_functional_model_with_multi_outputs.<locals>.SwapLayer object at 0x128e68fd0>>",
                "output_tensors": "[<tf.Tensor 'swap_layer_1_1/Identity:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'swap_layer_1_1/Identity_1:0' shape=(?, 4) dtype=float32>]",
                "layer.supports_masking": "False",
                "output_masks": "[None, None]",
                "layer.compute_mask": "<bound method Layer.compute_mask of <test_sequential_model.test_clone_functional_model_with_multi_outputs.<locals>.SwapLayer object at 0x128e68fd0>>",
                "computed_tensors": "[<tf.Tensor 'lambda_1_1/add:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'lambda_1_1/Identity:0' shape=(?, 4) dtype=float32>]",
                "computed_masks": "[None, None]",
                "tensor": "<tf.Tensor 'swap_layer_1_1/Identity_1:0' shape=(?, 4) dtype=float32>"
            }
        ]
    ],
    "2.1.6": [
        [
            {
                "model": "Model",
                "model._input_layers": "list",
                "model.inputs": "list",
                "model._nodes_by_depth": "dict",
                "model.outputs": "list",
                "model.name": "str"
            },
            {
                "layer_map": "dict",
                "tensor_map": "dict",
                "input_tensors": "list",
                "input_layers": "list",
                "layer": "SwapLayer",
                "input_tensor": "Tensor",
                "layer.name": "str",
                "newly_created_input_layer": "InputLayer",
                "input_tensor._keras_history": "tuple",
                "x": "Tensor",
                "x._keras_history": "tuple",
                "y": "Tensor",
                "depth_keys": "list",
                "depth": "int",
                "nodes": "list",
                "node": "Node",
                "node.outbound_layer": "SwapLayer",
                "new_layer": "SwapLayer",
                "layer.__class__": "type",
                "layer.get_config": "method",
                "reference_input_tensors": "list",
                "node.input_tensors": "list",
                "reference_output_tensors": "list",
                "node.output_tensors": "list",
                "computed_data": "list",
                "node.arguments": "dict",
                "kwargs": "dict",
                "computed_tensor": "Tensor",
                "layer.call": "method",
                "output_tensors": "list",
                "layer.supports_masking": "bool",
                "output_masks": "list",
                "layer.compute_mask": "method",
                "computed_tensors": "list",
                "computed_masks": "list",
                "tensor": "Tensor"
            }
        ]
    ],
    "3.1.1": [
        "'Could not compute output Tensor' error when I\u2018m using clone_model()\n"
    ],
    "3.1.2": [
        "Hi guys, I think I just met a bug.\nThere was something wrong when I was using multi_gpu_model with cpu_relocation=True. After analyzing the traceback I think it is a bug inside keras.models.clone_model\nThe script below can reproduce it\n\nfrom keras.models import Model, clone_model\nfrom keras.layers import Input, Add, Lambda\nfrom keras.utils import multi_gpu_model\n\n\ndef build_model():\n    input_layer = Input(shape=(1,))\n    test1, test2 = Lambda(lambda x: [x, x])(input_layer)\n    add = Add()([test1, test2])\n    model = Model(inputs=[input_layer], outputs=[add])\n    return model\n\n\nif __name__ == '__main__':\n    model = build_model()\n    model = clone_model(model)\n    # model = multi_gpu_model(model, cpu_relocation=True)  # it uses clone_model when set cpu_relocation=True\nIf I didn't make any mistake, the script will raise AssertionError: Could not compute output Tensor(\"add_1/add:0\", shape=(?, 1), dtype=float32)\n\nMy environment:\n\nKeras 2.2.4\ntensorflow 1.12.0\nI met the error on both 4 GTX1080tis and my own laptop with a GTX1060MQ\n\nI noticed that output_masks here will always be [None](but [None, None] is expected)\nkeras/keras/models.py\n\nLine 157 in a139716\n\n for x, y, mask in zip(reference_output_tensors, \nand that's because layer.compute_mask(...) will always return None since Lambda doesn't support using masks\nkeras/keras/models.py\n\nLine 153 in a139716\n\n output_masks = to_list( \nSo if I'm using a functional model with a layer which has more outputs without a mask support, I think the error can appear.\n\nP.S. thanks a lot for your brilliant works :)\nFrom my perspective, Keras is an amazing gift to everyone. Thank you all!\n"
    ]
}