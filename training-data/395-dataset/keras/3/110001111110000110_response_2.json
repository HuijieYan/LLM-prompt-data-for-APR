{
    "keras": [
        {
            "bugID": 3,
            "bitvector": {
                "1.1.1": 1,
                "1.1.2": 1,
                "1.2.1": 0,
                "1.2.2": 0,
                "1.2.3": 0,
                "1.3.1": 1,
                "1.3.2": 1,
                "1.4.1": 1,
                "1.4.2": 1,
                "2.1.1": 1,
                "2.1.2": 1,
                "2.1.3": 0,
                "2.1.4": 0,
                "2.1.5": 0,
                "2.1.6": 0,
                "3.1.1": 1,
                "3.1.2": 1,
                "cot": 0
            },
            "strata": {
                "1": 1,
                "2": 0,
                "3": 1,
                "4": 1,
                "5": 0,
                "6": 1,
                "7": 0
            },
            "available_bitvector": {
                "1.1.1": 1,
                "1.1.2": 1,
                "1.2.1": 0,
                "1.2.2": 0,
                "1.2.3": 0,
                "1.3.1": 1,
                "1.3.2": 0,
                "1.4.1": 1,
                "1.4.2": 1,
                "2.1.1": 1,
                "2.1.2": 1,
                "2.1.3": 0,
                "2.1.4": 0,
                "2.1.5": 0,
                "2.1.6": 0,
                "3.1.1": 1,
                "3.1.2": 1,
                "cot": 0
            },
            "available_strata": {
                "1": 1,
                "2": 0,
                "3": 1,
                "4": 1,
                "5": 0,
                "6": 1,
                "7": 0
            },
            "start_line": 26,
            "file_name": "keras/models.py",
            "replace_code": "def _clone_functional_model(model, input_tensors=None):\n    \"\"\"Clone a functional `Model` instance.\n\n    Model cloning is similar to calling a model on new inputs,\n    except that it creates new layers (and thus new weights) instead\n    of sharing the weights of the existing layers.\n\n    # Arguments\n        model: Instance of `Model`.\n        input_tensors: optional list of input tensors\n            to build the model upon. If not provided,\n            placeholders will be created.\n\n    # Returns\n        An instance of `Model` reproducing the behavior\n        of the original model, on top of new inputs tensors,\n        using newly instantiated weights.\n\n    # Raises\n        ValueError: in case of invalid `model` argument value.\n    \"\"\"\n    from keras.engine.training import Model\n    from keras.engine.network import Network\n    from keras.engine.topology import InputLayer\n    from keras.layers import Input\n    from keras.layers.merge import Concatenate\n    from keras.utils.generic_utils import to_list\n    import keras.backend as K\n    import numpy as np\n\n    if isinstance(model, Network):\n        model = model.model\n\n    if not isinstance(model, Model):\n        raise ValueError('Expected `model` argument to be a `Model` instance, got ', model)\n    \n    layer_map = {}  # Cache for created layers.\n    tensor_map = {}  # Map {reference_tensor: (corresponding_tensor, mask)}\n    \n    if input_tensors is None:\n        inputs = model.inputs\n        input_tensors = [K.placeholder(shape=K.int_shape(x), dtype=K.dtype(x)) for x in inputs]\n    else:\n        input_tensors = to_list(input_tensors)\n    \n    for input_layer, input_tensor in zip(model.inputs, input_tensors):\n        tensor_map[input_layer] = (input_tensor, None)  # tensor, mask\n    \n    for layer in model.layers:\n        if isinstance(layer, InputLayer):\n            continue\n        if layer in layer_map:\n            continue\n\n        # Here we make a shallow clone of the layer (the same name and with the same weights).\n        new_layer = layer.__class__.from_config(layer.get_config())\n        layer_map[layer] = new_layer\n\n    for source, target in zip(model.inputs, input_tensors):\n        tensor_map[source] = (target, None)\n\n    for x_layer, x_node in zip(model.layers, model._inbound_nodes):\n        if not x_node.inbound_layers:\n            continue  # no connected nodes\n    \n        source_tensors = []\n        source_shapes = []\n        for source_layer, source_node_index, tensor_index, _ in x_layer._inbound_nodes:\n            tensor_shape = source_layer._keras_shape[source_node_index]\n            source_shapes.append(tensor_shape)\n            # original tensor\n            _, src = source_layer._inbound_nodes[source_node_index]\n            source_tensors.append(src)\n    \n            for i in range(len(source_tensors)):\n                x = source_tensors[i]\n                tensor_shape = source_shapes[i]\n                tensor_shade = tensor_map[x][1]\n                y = layer_map[x_layer](tensor_map[x][0])\n                tensor_map[x_layer] = (y, tensor_shade)\n    \n    output_tensors = to_list([tensor_map[x][0] for x in model.outputs])\n    \n    return Model(input_tensors, output_tensors, name=model.name)",
            "imports": [
                "from keras.engine.training import Model",
                "from keras.engine.network import Network",
                "from keras.engine.topology import InputLayer",
                "from keras.layers import Input",
                "from keras.layers.merge import Concatenate",
                "from keras.utils.generic_utils import to_list",
                "import keras.backend as K",
                "import numpy as np"
            ]
        }
    ]
}