The error occurs when the `clone_model()` function is called in the test case. The error message indicates that the output tensor of the `swap_layer_1` layer could not be computed.

Upon analyzing the code, the potential error location within the `_clone_functional_model` function is identified at the part where it iterates over every node in the reference model and tries to compute the model outputs. It seems that there is a problem with the computation of outputs for the layers with multiple outputs, potentially related to the handling of masks.

The reason behind the occurrence of the bug is that the `clone_model()` function is not handling layers with multiple outputs properly when some of those outputs do not support masks. This leads to the assertion error when checking the computed model outputs.

To fix the bug, the handling of layers with multiple outputs and their associated masks needs to be improved. This could involve checking for the availability of masks for each output, and appropriately handling the masks based on the capabilities of the output layer.

The corrected code for the `_clone_functional_model` function is as follows:

```python
from tensorflow.python.keras.utils import generic_utils

def _clone_functional_model(model, input_tensors=None):
    # ... (rest of the function remains the same)

    input_tensors = generic_utils.to_list(input_tensors)

    output_tensors, masks = model._run_internal_graph(inputs=input_tensors)
    if len(output_tensors) == 1:
        output_tensors = output_tensors[0]
        masks = masks[0]

    return Model(input_tensors, output_tensors, name=model.name)
```

In the corrected code, the function `_run_internal_graph()` is used to compute the outputs and masks for the given input tensors. Then, the function returns a new model instance with the computed output tensors and masks.

By making these changes, the function should be able to handle layers with multiple outputs, including cases where some outputs do not support masks, without causing the assertion error.