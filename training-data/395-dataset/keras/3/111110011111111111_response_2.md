The bug is occurring in the `_clone_functional_model` function. The error message indicates that the output tensor "swap_layer_1/Identity:0" is not being computed, leading to an AssertionError.

The bug is likely occurring in the section of the code where it iterates over every node in the reference model, in depth order. During this iteration, the input tensors and the corresponding output tensors are not being handled properly. This results in the failure to compute the output tensors for the new model.

To fix this bug, the code should be modified to ensure that the input and output tensors are properly mapped and handled during the iteration over the nodes in the reference model. Additionally, checks should be implemented to verify that the model outputs are correctly computed before instantiating a new model from inputs and outputs.

Here's the corrected code for the `_clone_functional_model` function:

```python
def _clone_functional_model(model, input_tensors=None):
    if not isinstance(model, Model):
        raise ValueError('Expected `model` argument to be a `Model` instance, got ', model)
    
    layer_map = {}  # Cache for created layers.
    tensor_map = {}  # Map {reference_tensor: (corresponding_tensor, mask)}

    if input_tensors is None:
        input_layers = []
        input_tensors = []
        
        for layer in model._input_layers:
            input_tensor = Input(batch_shape=layer.batch_input_shape,
                                 dtype=layer.dtype,
                                 sparse=layer.sparse,
                                 name=layer.name)
            input_tensors.append(input_tensor)
            new_layer = input_tensor._keras_history[0]
            layer_map[layer] = new_layer
        
        for original, cloned in zip(model.inputs, input_tensors):
            layer_map[original] = cloned
    else:
        input_tensors = to_list(input_tensors)
        _input_tensors = []
        
        for i, x in enumerate(input_tensors):
            if not K.is_keras_tensor(x):
                name = model._input_layers[i].name
                input_tensor = Input(tensor=x, name='input_wrapper_for_' + name)
                _input_tensors.append(input_tensor)
                original_input_layer = x._keras_history[0]
                newly_created_input_layer = input_tensor._keras_history[0]
                layer_map[original_input_layer] = newly_created_input_layer
            else:
                _input_tensors.append(x)
        
        input_tensors = _input_tensors
    
    for x, y in zip(model.inputs, input_tensors):
        tensor_map[x] = (y, None)  # tensor, mask

    for depth in range(max(model._nodes_by_depth.keys()), -1, -1):
        nodes = model._nodes_by_depth[depth]
        
        for node in nodes:
            layer = node.outbound_layer

            if layer not in layer_map:
                new_layer = layer.__class__.from_config(layer.get_config())
                layer_map[layer] = new_layer
                layer = new_layer
            else:
                layer = layer_map[layer]
                if isinstance(layer, InputLayer):
                    continue

            reference_input_tensors = node.input_tensors
            reference_output_tensors = node.output_tensors
            computed_data = []
            
            for x in reference_input_tensors:
                if x in tensor_map:
                    computed_data.append(tensor_map[x])

            if len(computed_data) == len(reference_input_tensors):
                kwargs = node.arguments if node.arguments else {}
                computed_tensors = [x[0] for x in computed_data]
                computed_masks = [x[1] for x in computed_data]

                if has_arg(layer.call, 'mask'):
                    kwargs['mask'] = computed_masks

                output_tensors = to_list(layer(computed_tensors, **kwargs))
                tensor_map.update(zip(reference_output_tensors, zip(output_tensors, [None] * len(output_tensors))))

    output_tensors = [tensor_map[out][0] for out in model.outputs]
    return Model(input_tensors, output_tensors, name=model.name)
```

In the corrected code, adjustments have been made to properly handle the input and output tensors, as well as to iterate over the nodes in the model to compute the output tensors for the new model. This should resolve the bug related to the "Could not compute output Tensor" error when using `clone_model()`.