{
    "keras": [
        {
            "bugID": 8,
            "bitvector": {
                "1.1.1": 1,
                "1.1.2": 1,
                "1.2.1": 0,
                "1.2.2": 0,
                "1.2.3": 0,
                "1.3.1": 1,
                "1.3.2": 1,
                "1.4.1": 0,
                "1.4.2": 0,
                "2.1.1": 0,
                "2.1.2": 0,
                "2.1.3": 1,
                "2.1.4": 1,
                "2.1.5": 1,
                "2.1.6": 1,
                "3.1.1": 1,
                "3.1.2": 1,
                "cot": 1
            },
            "strata": {
                "1": 1,
                "2": 0,
                "3": 1,
                "4": 0,
                "5": 1,
                "6": 1,
                "7": 1
            },
            "available_bitvector": {
                "1.1.1": 1,
                "1.1.2": 1,
                "1.2.1": 0,
                "1.2.2": 0,
                "1.2.3": 0,
                "1.3.1": 1,
                "1.3.2": 1,
                "1.4.1": 0,
                "1.4.2": 0,
                "2.1.1": 0,
                "2.1.2": 0,
                "2.1.3": 1,
                "2.1.4": 1,
                "2.1.5": 1,
                "2.1.6": 1,
                "3.1.1": 1,
                "3.1.2": 1,
                "cot": 1
            },
            "available_strata": {
                "1": 1,
                "2": 0,
                "3": 1,
                "4": 0,
                "5": 1,
                "6": 1,
                "7": 1
            },
            "start_line": 933,
            "file_name": "keras/engine/network.py",
            "replace_code": "def from_config(cls, config, custom_objects=None):\n    # ... omitted code ...\n\n    def add_unprocessed_node(layer, node_data):\n        if layer not in unprocessed_nodes:\n            unprocessed_nodes[layer] = [node_data]\n        else:\n            unprocessed_nodes[layer].append(node_data)\n\n    def process_node(layer, node_data):\n        input_tensors = []\n        for input_data in node_data:\n            inbound_layer_name, inbound_node_index, inbound_tensor_index, kwargs = input_data\n            inbound_layer = created_layers[inbound_layer_name]\n            if len(inbound_layer._inbound_nodes) <= inbound_node_index:\n                add_unprocessed_node(layer, node_data)\n                return\n            inbound_node = inbound_layer._inbound_nodes[inbound_node_index]\n            input_tensors.append(\n                inbound_node.output_tensors[inbound_tensor_index])\n        # Call layer on its inputs, thus creating the node\n        # and building the layer if needed.\n        if input_tensors:\n            layer(unpack_singleton(input_tensors), **kwargs)\n\n    def process_layer(layer_data):\n        layer_name = layer_data['name']\n        layer = deserialize_layer(layer_data,\n                                  custom_objects=custom_objects)\n        created_layers[layer_name] = layer\n        inbound_nodes_data = layer_data['inbound_nodes']\n        for node_data in inbound_nodes_data:\n            add_unprocessed_node(layer, node_data)\n\n    # First, we create all layers and enqueue nodes to be processed\n    for layer_data in config['layers']:\n        process_layer(layer_data)\n\n    # Then we process nodes in order of layer depth, keeping track of shared layers correctly\n    while unprocessed_nodes:\n        for layer_data in config['layers']:\n            layer = created_layers[layer_data['name']]\n            if layer in unprocessed_nodes:\n                for node_data in unprocessed_nodes.pop(layer):\n                    if not all(inbound_layer in created_layers for inbound_layer, _, _, _ in node_data):\n                        add_unprocessed_node(layer, node_data)\n                    else:\n                        process_node(layer, node_data)",
            "imports": []
        }
    ]
}