```python
def from_config(cls, config, custom_objects=None):
    """Instantiates a Model from its config (output of `get_config()`).

    # Arguments
        config: Model config dictionary.
        custom_objects: Optional dictionary mapping names
            (strings) to custom classes or functions to be
            considered during deserialization.

    # Returns
        A model instance.

    # Raises
        ValueError: In case of improperly formatted config dict.
    """
    created_layers = {}
    unprocessed_nodes = {}

    def add_unprocessed_node(layer, node_data):
        if layer not in unprocessed_nodes:
            unprocessed_nodes[layer] = [node_data]
        else:
            unprocessed_nodes[layer].append(node_data)

    def process_node(layer, node_data):
        input_tensors = []
        for input_data in node_data:
            inbound_layer_name = input_data[0]
            inbound_node_index = input_data[1]
            inbound_tensor_index = input_data[2]
            if len(input_data) == 3:
                kwargs = {}
            elif len(input_data) == 4:
                kwargs = input_data[3]
            else:
                raise ValueError('Improperly formatted model config.')
            inbound_layer = created_layers[inbound_layer_name]
            if len(inbound_layer._inbound_nodes) <= inbound_node_index:
                add_unprocessed_node(layer, node_data)
                return
            inbound_node = inbound_layer._inbound_nodes[inbound_node_index]
            input_tensors.append(
                inbound_node.output_tensors[inbound_tensor_index])
        if input_tensors:
            layer(unpack_singleton(input_tensors), **kwargs)

    def process_layer(layer_data):
        layer_name = layer_data['name']
        from ..layers import deserialize as deserialize_layer
        layer = deserialize_layer(layer_data, custom_objects=custom_objects)
        created_layers[layer_name] = layer
        inbound_nodes_data = layer_data['inbound_nodes']
        for node_data in inbound_nodes_data:
            add_unprocessed_node(layer, node_data)

    for layer_data in config['layers']:
        process_layer(layer_data)
    while unprocessed_nodes:
        for layer_data in config['layers']:
            layer = created_layers[layer_data['name']]
            if layer in unprocessed_nodes:
                for node_data in unprocessed_nodes.pop(layer):
                    process_node(layer, node_data)

    name = config.get('name')
    input_tensors = []
    output_tensors = []
    for layer_data in config['input_layers']:
        layer_name, node_index, tensor_index = layer_data
        assert layer_name in created_layers
        layer = created_layers[layer_name]
        layer_output_tensors = layer._inbound_nodes[node_index].output_tensors
        input_tensors.append(layer_output_tensors[tensor_index])
    for layer_data in config['output_layers']:
        layer_name, node_index, tensor_index = layer_data
        assert layer_name in created_layers
        layer = created_layers[layer_name]
        layer_output_tensors = layer._inbound_nodes[node_index].output_tensors
        output_tensors.append(layer_output_tensors[tensor_index])

    return cls(inputs=input_tensors, outputs=output_tensors, name=name)

def test_layer_sharing_at_heterogeneous_depth_order():
    input_shape = (1, 12)
    input_layer = Input(shape=input_shape)
    A = Dense(12, name='layer_a')
    r1 = layers.Reshape((12,))(input_layer)

    Aout1 = A(r1)

    r2 = layers.Reshape((12,))(A(input_layer))
    Aout2 = A(r2)

    c1 = layers.concatenate([Aout2, Aout1])
    output = Dense(2, name='layer_b')(c1)

    M = Model(inputs=input_layer, outputs=output)

    x_val = np.random.random((10,) + input_shape)
    output_val = M.predict(x_val)

    config = M.get_config()
    weights = M.get_weights()
    M2 = Model.from_config(config)

    M2.set_weights(weights)
    output_val_2 = M2.predict(x_val)
    np.testing.assert_allclose(output_val, output_val_2, atol=1e-6)
```