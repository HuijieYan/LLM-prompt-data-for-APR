```python
# corrected function
@classmethod
def from_config(cls, config, custom_objects=None):
    """Instantiates a Model from its config (output of `get_config()`).

    # Arguments
        config: Model config dictionary.
        custom_objects: Optional dictionary mapping names
            (strings) to custom classes or functions to be
            considered during deserialization.

    # Returns
        A model instance.

    # Raises
        ValueError: In case of improperly formatted config dict.
    """
    # Layer instances created during
    # the graph reconstruction process
    created_layers = {}

    # Set to store layers whose inbound nodes have not yet been processed
    unprocessed_nodes = set()

    # Dictionary mapping layer instances to
    # node data that specifies a layer call.
    # It acts as a queue that maintains any unprocessed
    # layer call until it becomes possible to process it
    # (i.e. until the input tensors to the call all exist)
    unprocessed_nodes_data = {}

    def add_unprocessed_node(layer, node_data):
        unprocessed_nodes.add(layer)
        unprocessed_nodes_data[layer] = node_data

    def process_node(layer, node_data):
        input_tensors = []
        for input_data in node_data:
            inbound_layer_name, inbound_node_index, inbound_tensor_index, kwargs = input_data
            inbound_layer = created_layers[inbound_layer_name]
            inbound_node = inbound_layer._inbound_nodes[inbound_node_index]
            input_tensors.append(inbound_node.output_tensors[inbound_tensor_index])
        # Call layer on its inputs, thus creating the node
        # and building the layer if needed.
        if input_tensors:
            layer(unpack_singleton(input_tensors), **kwargs)

    def process_layer(layer_data):
        """Deserializes a layer, then call it on appropriate inputs.

        # Arguments
            layer_data: layer config dict.

        # Raises
            ValueError: In case of improperly formatted `layer_data` dict.
        """
        layer_name = layer_data['name']
        layer = layer_module.deserialize(layer_data, custom_objects=custom_objects)
        created_layers[layer_name] = layer
        inbound_nodes_data = layer_data['inbound_nodes']
        for node_data in inbound_nodes_data:
            add_unprocessed_node(layer, node_data)

    # First, we create all layers and enqueue nodes to be processed
    for layer_data in config['layers']:
        process_layer(layer_data)

    # Then we process nodes in order of layer depth.
    # Nodes that cannot yet be processed (if the inbound node
    # does not yet exist) are re-enqueued, and the process
    # is repeated until all nodes are processed.
    while unprocessed_nodes:
        for layer in unprocessed_nodes.copy():
            node_data = unprocessed_nodes_data.pop(layer)
            if all(inbound_layer_name in created_layers for inbound_layer_name, _, _, _ in node_data):
                process_node(layer, node_data)
                unprocessed_nodes.remove(layer)

    # Collect input tensors and output tensors for the model
    input_tensors, output_tensors = [], []
    for layer_data in config['input_layers']:
        layer_name, node_index, tensor_index = layer_data
        layer = created_layers[layer_name]
        input_tensors.append(layer._inbound_nodes[node_index].output_tensors[tensor_index])
    for layer_data in config['output_layers']:
        layer_name, node_index, tensor_index = layer_data
        layer = created_layers[layer_name]
        output_tensors.append(layer._inbound_nodes[node_index].output_tensors[tensor_index])

    return cls(inputs=input_tensors, outputs=output_tensors, name=config.get('name', None))
```