{
    "keras": [
        {
            "bugID": 31,
            "bitvector": {
                "1.1.1": 1,
                "1.1.2": 1,
                "1.2.1": 1,
                "1.2.2": 1,
                "1.2.3": 1,
                "1.3.1": 1,
                "1.3.2": 1,
                "1.4.1": 0,
                "1.4.2": 0,
                "2.1.1": 0,
                "2.1.2": 0,
                "2.1.3": 1,
                "2.1.4": 1,
                "2.1.5": 1,
                "2.1.6": 1,
                "3.1.1": 1,
                "3.1.2": 1,
                "cot": 0
            },
            "strata": {
                "1": 1,
                "2": 1,
                "3": 1,
                "4": 0,
                "5": 1,
                "6": 1,
                "7": 0
            },
            "available_bitvector": {
                "1.1.1": 1,
                "1.1.2": 1,
                "1.2.1": 0,
                "1.2.2": 0,
                "1.2.3": 0,
                "1.3.1": 1,
                "1.3.2": 1,
                "1.4.1": 0,
                "1.4.2": 0,
                "2.1.1": 0,
                "2.1.2": 0,
                "2.1.3": 1,
                "2.1.4": 1,
                "2.1.5": 1,
                "2.1.6": 1,
                "3.1.1": 1,
                "3.1.2": 1,
                "cot": 0
            },
            "available_strata": {
                "1": 1,
                "2": 0,
                "3": 1,
                "4": 0,
                "5": 1,
                "6": 1,
                "7": 0
            },
            "start_line": 3928,
            "file_name": "keras/backend/tensorflow_backend.py",
            "replace_code": "def ctc_batch_cost(y_true, y_pred, input_length, label_length):\n    \"\"\"Runs CTC loss algorithm on each batch element.\n\n    # Arguments\n        y_true: tensor `(samples, max_string_length)`\n            containing the truth labels.\n        y_pred: tensor `(samples, time_steps, num_categories)`\n            containing the prediction, or output of the softmax.\n        input_length: tensor `(samples, 1)` containing the sequence length for\n            each batch item in `y_pred`.\n        label_length: tensor `(samples, 1)` containing the sequence length for\n            each batch item in `y_true`.\n\n    # Returns\n        Tensor with shape (samples,1) containing the\n            CTC loss of each element.\n    \"\"\"\n    label_length = tf.squeeze(label_length)\n    input_length = tf.squeeze(input_length)\n    \n    def _to_sparse_tensor(y_true, label_length):\n        indices = []\n        values = []\n        label_length = label_length.numpy()\n        for i in range(len(y_true)):\n            mask = y_true[i] < label_length[i]\n            y_true_masked = tf.boolean_mask(y_true[i], mask)\n            values += y_true_masked.numpy().tolist()\n            indices += list(zip([i]*len(y_true_masked), tf.where(mask)[:,0].numpy().tolist()))\n        \n        shape = [len(y_true), tf.reduce_max(label_length).numpy()]\n        sparse_tensor = tf.SparseTensor(indices=indices, values=values, dense_shape=shape)\n        return sparse_tensor\n\n    sparse_labels = _to_sparse_tensor(y_true, label_length)\n    epsilon = ops.convert_to_tensor(1e-5, dtype=y_pred.dtype.base_dtype, name='epsilon')\n    y_pred = tf.math.log(tf.transpose(y_pred, perm=[1, 0, 2]) + epsilon)\n    loss = tf.expand_dims(tf.nn.ctc_loss_v2(labels=sparse_labels, logits=y_pred, label_length=label_length,\n                                           logit_length=input_length, blank_index=-1), 1)\n    \n    return loss",
            "imports": [
                "import tensorflow as tf",
                "from tensorflow.python.framework import ops"
            ]
        }
    ]
}