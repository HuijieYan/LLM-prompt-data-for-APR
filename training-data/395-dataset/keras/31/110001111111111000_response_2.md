```python
# file name: /Volumes/SSD2T/bgp_envs/repos/keras_31/keras/backend/tensorflow_backend.py

# relative function's signature in this file
def transpose(x):
    # ... omitted code ...
    pass

# relative function's signature in this file
def log(x):
    # ... omitted code ...
    pass

# relative function's signature in this file
def expand_dims(x, axis=-1):
    # ... omitted code ...
    pass

# relative function's signature in this file
def squeeze(x, axis):
    # ... omitted code ...
    pass

# relative function's signature in this file
def ctc_label_dense_to_sparse(labels, label_lengths):
    # ... omitted code ...
    pass



    # this is the buggy function you need to fix
    def ctc_batch_cost(y_true, y_pred, input_length, label_length):
        """Runs CTC loss algorithm on each batch element.
    
        # Arguments
            y_true: tensor `(samples, max_string_length)`
                containing the truth labels.
            y_pred: tensor `(samples, time_steps, num_categories)`
                containing the prediction, or output of the softmax.
            input_length: tensor `(samples, 1)` containing the sequence length for
                each batch item in `y_pred`.
            label_length: tensor `(samples, 1)` containing the sequence length for
            each batch item in `y_true`.
    
        # Returns
            Tensor with shape (samples,1) containing the
                CTC loss of each element.
        """
        label_length = tf.squeeze(label_length, axis=-1)
        input_length = tf.squeeze(input_length, axis=-1)
        idx = tf.where(tf.not_equal(label_length, 0))
        label_length = tf.gather(label_length, idx)
        sparse_labels = tf.to_int32(ctc_label_dense_to_sparse(y_true, label_length))
        y_pred = tf.log(y_pred + epsilon())  # don't need to transpose

        return ctc.ctc_loss(sparse_labels, y_pred, input_length, label_length)
```