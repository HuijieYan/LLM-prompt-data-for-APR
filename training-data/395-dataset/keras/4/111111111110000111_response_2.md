The error occurs when the `get_updates` function in the `TFOptimizer` class is called. The error message states that the `compute_gradients` method is being called with 3 arguments when it only takes 2 positional arguments.

The bug is occurring because the `compute_gradients` method is being called with the `params` argument, which is not expected by the `compute_gradients` method.

To fix the bug, the extra `params` argument should be removed while calling the `compute_gradients` method.

Here's the corrected code for the `get_updates` function:

```python
# this is the corrected function
def get_updates(self, loss, params):
    grads = self.optimizer.compute_gradients(loss)
    self.updates = [K.update_add(self.iterations, 1)]
    opt_update = self.optimizer.apply_gradients(
        grads, global_step=self.iterations)
    self.updates.append(opt_update)
    return self.updates
```