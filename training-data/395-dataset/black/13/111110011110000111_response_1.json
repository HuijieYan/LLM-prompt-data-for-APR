{
    "black": [
        {
            "bugID": 13,
            "bitvector": {
                "1.1.1": 1,
                "1.1.2": 1,
                "1.2.1": 1,
                "1.2.2": 1,
                "1.2.3": 1,
                "1.3.1": 0,
                "1.3.2": 0,
                "1.4.1": 1,
                "1.4.2": 1,
                "2.1.1": 1,
                "2.1.2": 1,
                "2.1.3": 0,
                "2.1.4": 0,
                "2.1.5": 0,
                "2.1.6": 0,
                "3.1.1": 1,
                "3.1.2": 1,
                "cot": 1
            },
            "strata": {
                "1": 1,
                "2": 1,
                "3": 0,
                "4": 1,
                "5": 0,
                "6": 1,
                "7": 1
            },
            "available_bitvector": {
                "1.1.1": 1,
                "1.1.2": 1,
                "1.2.1": 0,
                "1.2.2": 0,
                "1.2.3": 0,
                "1.3.1": 0,
                "1.3.2": 0,
                "1.4.1": 1,
                "1.4.2": 1,
                "2.1.1": 1,
                "2.1.2": 1,
                "2.1.3": 0,
                "2.1.4": 0,
                "2.1.5": 0,
                "2.1.6": 0,
                "3.1.1": 1,
                "3.1.2": 1,
                "cot": 1
            },
            "available_strata": {
                "1": 1,
                "2": 0,
                "3": 0,
                "4": 1,
                "5": 0,
                "6": 1,
                "7": 1
            },
            "start_line": 337,
            "file_name": "blib2to3/pgen2/tokenize.py",
            "replace_code": "def generate_tokens(readline):\n    # other parts of the function remain the same, only the async token handling is updated\n\n    async_def = False\n    async_def_indent = 0\n    async_def_nl = False\n    async_in_for = False\n    \n    while 1:  # loop over lines in stream\n        try:\n            line = readline()\n        except StopIteration:\n            line = ''\n        lnum += 1\n        # other parts of the function remain the same\n        for pre, tok in tokenize.generate_tokens(io.StringIO(line).readline):\n            # Handle async for construct\n            if async_def and tok.string == \"for\":\n                async_in_for = True\n    \n            token_values = {\n                \"async\": ASYNC,\n                \"await\": AWAIT,\n            }\n    \n            token_type = token_values.get(tok.string, NAME)\n    \n            yield (token_type, tok.string, (lnum, col), (lnum, col + len(tok.string)), line)"
        }
    ]
}