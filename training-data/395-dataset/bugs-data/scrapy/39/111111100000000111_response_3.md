The issue is with the `make_requests_from_url` method in the `Spider` class. The current implementation checks if `self.make_requests_from_url` is not equal to `Spider.make_requests_from_url`. If the condition is true, a warning message is issued and the method `make_requests_from_url` is called for each `start_url`. If the condition is false, the method `make_requests_from_url` is not used and instead, a `Request` is generated for each `start_url`.

The bug occurs because the condition `self.make_requests_from_url is not Spider.make_requests_from_url` is not a reliable way to check if the method has been overridden or not.

To fix this bug, instead of using the condition to check method overriding, we can use Python's built-in `getattr` function to check if the function has been overridden.

Here's the corrected code for the `start_requests` method:

```python
def start_requests(self):
    if getattr(self.make_requests_from_url, '__func__', None) is not getattr(Spider.make_requests_from_url, '__func__', None):
        warnings.warn(
            "Spider.make_requests_from_url method is deprecated; "
            "it won't be called in future Scrapy releases. "
            "Please override start_requests method instead."
        )
        for url in self.start_urls:
            yield self.make_requests_from_url(url)
    else:
        for url in self.start_urls:
            yield Request(url, dont_filter=True)
```