{
    "scrapy:32": {
        "/Volumes/SSD2T/bgp_envs_non_pandas/repos/scrapy_32/scrapy/crawler.py": {
            "buggy_functions": [
                {
                    "function_name": "__init__",
                    "function_code": "def __init__(self, settings):\n    super(CrawlerProcess, self).__init__(settings)\n    install_shutdown_handlers(self._signal_shutdown)\n    configure_logging(settings)\n    log_scrapy_info(settings)\n",
                    "decorators": [],
                    "docstring": null,
                    "start_line": 209,
                    "end_line": 213,
                    "variables": {
                        "__init__": [
                            210
                        ],
                        "super": [
                            210
                        ],
                        "CrawlerProcess": [
                            210
                        ],
                        "self": [
                            210,
                            211
                        ],
                        "settings": [
                            210,
                            212,
                            213
                        ],
                        "install_shutdown_handlers": [
                            211
                        ],
                        "self._signal_shutdown": [
                            211
                        ],
                        "configure_logging": [
                            212
                        ],
                        "log_scrapy_info": [
                            213
                        ]
                    },
                    "filtered_variables": {
                        "__init__": [
                            210
                        ],
                        "CrawlerProcess": [
                            210
                        ],
                        "self": [
                            210,
                            211
                        ],
                        "settings": [
                            210,
                            212,
                            213
                        ],
                        "install_shutdown_handlers": [
                            211
                        ],
                        "self._signal_shutdown": [
                            211
                        ],
                        "configure_logging": [
                            212
                        ],
                        "log_scrapy_info": [
                            213
                        ]
                    },
                    "diff_line_number": 212,
                    "class_data": {
                        "signature": "class CrawlerProcess(CrawlerRunner)",
                        "docstring": "A class to run multiple scrapy crawlers in a process simultaneously.\n\nThis class extends :class:`~scrapy.crawler.CrawlerRunner` by adding support\nfor starting a Twisted `reactor`_ and handling shutdown signals, like the\nkeyboard interrupt command Ctrl-C. It also configures top-level logging.\n\nThis utility should be a better fit than\n:class:`~scrapy.crawler.CrawlerRunner` if you aren't running another\nTwisted `reactor`_ within your application.\n\nThe CrawlerProcess object must be instantiated with a\n:class:`~scrapy.settings.Settings` object.\n\nThis class shouldn't be needed (since Scrapy is responsible of using it\naccordingly) unless writing scripts that manually handle the crawling\nprocess. See :ref:`run-from-script` for an example.",
                        "constructor_docstring": null,
                        "functions": [
                            "def __init__(self, settings):\n    super(CrawlerProcess, self).__init__(settings)\n    install_shutdown_handlers(self._signal_shutdown)\n    configure_logging(settings)\n    log_scrapy_info(settings)",
                            "def _signal_shutdown(self, signum, _):\n    install_shutdown_handlers(self._signal_kill)\n    signame = signal_names[signum]\n    logger.info('Received %(signame)s, shutting down gracefully. Send again to force ', {'signame': signame})\n    reactor.callFromThread(self.stop)",
                            "def _signal_kill(self, signum, _):\n    install_shutdown_handlers(signal.SIG_IGN)\n    signame = signal_names[signum]\n    logger.info('Received %(signame)s twice, forcing unclean shutdown', {'signame': signame})\n    reactor.callFromThread(self._stop_reactor)",
                            "def start(self, stop_after_crawl=True):\n    \"\"\"\n    This method starts a Twisted `reactor`_, adjusts its pool size to\n    :setting:`REACTOR_THREADPOOL_MAXSIZE`, and installs a DNS cache based\n    on :setting:`DNSCACHE_ENABLED` and :setting:`DNSCACHE_SIZE`.\n\n    If `stop_after_crawl` is True, the reactor will be stopped after all\n    crawlers have finished, using :meth:`join`.\n\n    :param boolean stop_after_crawl: stop or not the reactor when all\n        crawlers have finished\n    \"\"\"\n    if stop_after_crawl:\n        d = self.join()\n        if d.called:\n            return\n        d.addBoth(lambda _: self._stop_reactor())\n    cache_size = self.settings.getint('DNSCACHE_SIZE') if self.settings.getbool('DNSCACHE_ENABLED') else 0\n    reactor.installResolver(CachingThreadedResolver(reactor, cache_size, self.settings.getfloat('DNS_TIMEOUT')))\n    tp = reactor.getThreadPool()\n    tp.adjustPoolsize(maxthreads=self.settings.getint('REACTOR_THREADPOOL_MAXSIZE'))\n    reactor.addSystemEventTrigger('before', 'shutdown', self.stop)\n    reactor.run(installSignalHandlers=False)",
                            "def _stop_reactor(self, _=None):\n    try:\n        reactor.stop()\n    except RuntimeError:\n        pass"
                        ],
                        "constructor_variables": [],
                        "class_level_variables": [],
                        "class_decorators": [],
                        "function_signatures": [
                            "__init__(self, settings)",
                            "_signal_shutdown(self, signum, _)",
                            "_signal_kill(self, signum, _)",
                            "start(self, stop_after_crawl=True)",
                            "_stop_reactor(self, _=None)"
                        ]
                    },
                    "variable_values": [
                        [
                            {
                                "__init__": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "CrawlerProcess": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self": {
                                    "variable_value": "<scrapy.crawler.CrawlerProcess object at 0x10cd8baf0>",
                                    "variable_type": "CrawlerProcess",
                                    "variable_shape": null
                                },
                                "settings": {
                                    "variable_value": "{'foo': 'bar'}",
                                    "variable_type": "dict",
                                    "variable_shape": "1"
                                },
                                "install_shutdown_handlers": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self._signal_shutdown": {
                                    "variable_value": "<bound method CrawlerProcess._signal_shutdown of <scrapy.crawler.CrawlerProcess object at 0x10cd8baf0>>",
                                    "variable_type": "method",
                                    "variable_shape": null
                                },
                                "configure_logging": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "log_scrapy_info": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                }
                            },
                            {}
                        ]
                    ],
                    "angelic_variable_values": [
                        [
                            {
                                "__init__": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "CrawlerProcess": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self": {
                                    "variable_value": "<scrapy.crawler.CrawlerProcess object at 0x10406dc10>",
                                    "variable_type": "CrawlerProcess",
                                    "variable_shape": null
                                },
                                "settings": {
                                    "variable_value": "{'foo': 'bar'}",
                                    "variable_type": "dict",
                                    "variable_shape": "1"
                                },
                                "install_shutdown_handlers": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self._signal_shutdown": {
                                    "variable_value": "<bound method CrawlerProcess._signal_shutdown of <scrapy.crawler.CrawlerProcess object at 0x10406dc10>>",
                                    "variable_type": "method",
                                    "variable_shape": null
                                },
                                "configure_logging": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.settings": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "log_scrapy_info": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                }
                            },
                            {}
                        ]
                    ]
                }
            ],
            "inscope_functions": [
                "def _get_spider_loader(settings):\n    \"\"\" Get SpiderLoader instance from settings \"\"\"\n    if settings.get('SPIDER_MANAGER_CLASS'):\n        warnings.warn(\n            'SPIDER_MANAGER_CLASS option is deprecated. '\n            'Please use SPIDER_LOADER_CLASS.',\n            category=ScrapyDeprecationWarning, stacklevel=2\n        )\n    cls_path = settings.get('SPIDER_MANAGER_CLASS',\n                            settings.get('SPIDER_LOADER_CLASS'))\n    loader_cls = load_object(cls_path)\n    try:\n        verifyClass(ISpiderLoader, loader_cls)\n    except DoesNotImplement:\n        warnings.warn(\n            'SPIDER_LOADER_CLASS (previously named SPIDER_MANAGER_CLASS) does '\n            'not fully implement scrapy.interfaces.ISpiderLoader interface. '\n            'Please add all missing methods to avoid unexpected runtime errors.',\n            category=ScrapyDeprecationWarning, stacklevel=2\n        )\n    return loader_cls.from_settings(settings.frozencopy())",
                "def __init__(self, spidercls, settings):\n    if isinstance(settings, dict):\n        settings = Settings(settings)\n\n    self.spidercls = spidercls\n    self.settings = settings.copy()\n\n    self.signals = SignalManager(self)\n    self.stats = load_object(self.settings['STATS_CLASS'])(self)\n\n    handler = LogCounterHandler(self, level=settings.get('LOG_LEVEL'))\n    logging.root.addHandler(handler)\n    # lambda is assigned to Crawler attribute because this way it is not\n    # garbage collected after leaving __init__ scope\n    self.__remove_handler = lambda: logging.root.removeHandler(handler)\n    self.signals.connect(self.__remove_handler, signals.engine_stopped)\n\n    lf_cls = load_object(self.settings['LOG_FORMATTER'])\n    self.logformatter = lf_cls.from_crawler(self)\n    self.extensions = ExtensionManager.from_crawler(self)\n\n    self.spidercls.update_settings(self.settings)\n    self.settings.freeze()\n\n    self.crawling = False\n    self.spider = None\n    self.engine = None",
                "@property\ndef spiders(self):\n    if not hasattr(self, '_spiders'):\n        warnings.warn(\"Crawler.spiders is deprecated, use \"\n                      \"CrawlerRunner.spider_loader or instantiate \"\n                      \"scrapy.spiderloader.SpiderLoader with your \"\n                      \"settings.\",\n                      category=ScrapyDeprecationWarning, stacklevel=2)\n        self._spiders = _get_spider_loader(self.settings.frozencopy())\n    return self._spiders",
                "@defer.inlineCallbacks\ndef crawl(self, *args, **kwargs):\n    assert not self.crawling, \"Crawling already taking place\"\n    self.crawling = True\n\n    try:\n        self.spider = self._create_spider(*args, **kwargs)\n        self.engine = self._create_engine()\n        start_requests = iter(self.spider.start_requests())\n        yield self.engine.open_spider(self.spider, start_requests)\n        yield defer.maybeDeferred(self.engine.start)\n    except Exception:\n        self.crawling = False\n        raise",
                "def _create_spider(self, *args, **kwargs):\n    return self.spidercls.from_crawler(self, *args, **kwargs)",
                "def _create_engine(self):\n    return ExecutionEngine(self, lambda _: self.stop())",
                "@defer.inlineCallbacks\ndef stop(self):\n    if self.crawling:\n        self.crawling = False\n        yield defer.maybeDeferred(self.engine.stop)",
                "def __init__(self, settings):\n    if isinstance(settings, dict):\n        settings = Settings(settings)\n    self.settings = settings\n    self.spider_loader = _get_spider_loader(settings)\n    self._crawlers = set()\n    self._active = set()",
                "@property\ndef spiders(self):\n    warnings.warn(\"CrawlerRunner.spiders attribute is renamed to \"\n                  \"CrawlerRunner.spider_loader.\",\n                  category=ScrapyDeprecationWarning, stacklevel=2)\n    return self.spider_loader",
                "def crawl(self, crawler_or_spidercls, *args, **kwargs):\n    \"\"\"\n    Run a crawler with the provided arguments.\n\n    It will call the given Crawler's :meth:`~Crawler.crawl` method, while\n    keeping track of it so it can be stopped later.\n\n    If `crawler_or_spidercls` isn't a :class:`~scrapy.crawler.Crawler`\n    instance, this method will try to create one using this parameter as\n    the spider class given to it.\n\n    Returns a deferred that is fired when the crawling is finished.\n\n    :param crawler_or_spidercls: already created crawler, or a spider class\n        or spider's name inside the project to create it\n    :type crawler_or_spidercls: :class:`~scrapy.crawler.Crawler` instance,\n        :class:`~scrapy.spiders.Spider` subclass or string\n\n    :param list args: arguments to initialize the spider\n\n    :param dict kwargs: keyword arguments to initialize the spider\n    \"\"\"\n    crawler = crawler_or_spidercls\n    if not isinstance(crawler_or_spidercls, Crawler):\n        crawler = self._create_crawler(crawler_or_spidercls)\n\n    self.crawlers.add(crawler)\n    d = crawler.crawl(*args, **kwargs)\n    self._active.add(d)\n\n    def _done(result):\n        self.crawlers.discard(crawler)\n        self._active.discard(d)\n        return result\n\n    return d.addBoth(_done)",
                "def _create_crawler(self, spidercls):\n    if isinstance(spidercls, six.string_types):\n        spidercls = self.spider_loader.load(spidercls)\n    return Crawler(spidercls, self.settings)",
                "def stop(self):\n    \"\"\"\n    Stops simultaneously all the crawling jobs taking place.\n\n    Returns a deferred that is fired when they all have ended.\n    \"\"\"\n    return defer.DeferredList([c.stop() for c in list(self.crawlers)])",
                "@defer.inlineCallbacks\ndef join(self):\n    \"\"\"\n    join()\n\n    Returns a deferred that is fired when all managed :attr:`crawlers` have\n    completed their executions.\n    \"\"\"\n    while self._active:\n        yield defer.DeferredList(self._active)",
                "def __init__(self, settings):\n    super(CrawlerProcess, self).__init__(settings)\n    install_shutdown_handlers(self._signal_shutdown)\n    configure_logging(settings)\n    log_scrapy_info(settings)",
                "def _signal_shutdown(self, signum, _):\n    install_shutdown_handlers(self._signal_kill)\n    signame = signal_names[signum]\n    logger.info(\"Received %(signame)s, shutting down gracefully. Send again to force \",\n                {'signame': signame})\n    reactor.callFromThread(self.stop)",
                "def _signal_kill(self, signum, _):\n    install_shutdown_handlers(signal.SIG_IGN)\n    signame = signal_names[signum]\n    logger.info('Received %(signame)s twice, forcing unclean shutdown',\n                {'signame': signame})\n    reactor.callFromThread(self._stop_reactor)",
                "def start(self, stop_after_crawl=True):\n    \"\"\"\n    This method starts a Twisted `reactor`_, adjusts its pool size to\n    :setting:`REACTOR_THREADPOOL_MAXSIZE`, and installs a DNS cache based\n    on :setting:`DNSCACHE_ENABLED` and :setting:`DNSCACHE_SIZE`.\n\n    If `stop_after_crawl` is True, the reactor will be stopped after all\n    crawlers have finished, using :meth:`join`.\n\n    :param boolean stop_after_crawl: stop or not the reactor when all\n        crawlers have finished\n    \"\"\"\n    if stop_after_crawl:\n        d = self.join()\n        # Don't start the reactor if the deferreds are already fired\n        if d.called:\n            return\n        d.addBoth(lambda _: self._stop_reactor())\n\n    cache_size = self.settings.getint('DNSCACHE_SIZE') if self.settings.getbool('DNSCACHE_ENABLED') else 0\n    reactor.installResolver(CachingThreadedResolver(reactor, cache_size,\n                                                        self.settings.getfloat('DNS_TIMEOUT')))\n    tp = reactor.getThreadPool()\n    tp.adjustPoolsize(maxthreads=self.settings.getint('REACTOR_THREADPOOL_MAXSIZE'))\n    reactor.addSystemEventTrigger('before', 'shutdown', self.stop)\n    reactor.run(installSignalHandlers=False)  # blocking call",
                "def _stop_reactor(self, _=None):\n    try:\n        reactor.stop()\n    except RuntimeError:  # raised if already stopped or in shutdown stage\n        pass",
                "def _done(result):\n    self.crawlers.discard(crawler)\n    self._active.discard(d)\n    return result"
            ],
            "inscope_function_signatures": [
                "_get_spider_loader(settings)",
                "__init__(self, spidercls, settings)",
                "spiders(self)",
                "crawl(self, *args, **kwargs)",
                "_create_spider(self, *args, **kwargs)",
                "_create_engine(self)",
                "stop(self)",
                "__init__(self, settings)",
                "spiders(self)",
                "crawl(self, crawler_or_spidercls, *args, **kwargs)",
                "_create_crawler(self, spidercls)",
                "stop(self)",
                "join(self)",
                "__init__(self, settings)",
                "_signal_shutdown(self, signum, _)",
                "_signal_kill(self, signum, _)",
                "start(self, stop_after_crawl=True)",
                "_stop_reactor(self, _=None)",
                "_done(result)"
            ],
            "variables_in_file": {
                "logger": [
                    225,
                    218,
                    21
                ],
                "logging.getLogger": [
                    21
                ],
                "logging": [
                    40,
                    37,
                    21
                ],
                "__name__": [
                    21
                ],
                "object": [
                    24,
                    93
                ],
                "isinstance": [
                    113,
                    27,
                    165,
                    150
                ],
                "settings": [
                    36,
                    265,
                    271,
                    272,
                    113,
                    114,
                    115,
                    116,
                    210,
                    212,
                    213,
                    283,
                    27,
                    28,
                    31
                ],
                "dict": [
                    113,
                    27
                ],
                "Settings": [
                    114,
                    28
                ],
                "self.spidercls": [
                    81,
                    30,
                    47
                ],
                "self": [
                    151,
                    153,
                    155,
                    30,
                    31,
                    158,
                    33,
                    34,
                    159,
                    36,
                    166,
                    167,
                    40,
                    41,
                    43,
                    44,
                    45,
                    47,
                    48,
                    175,
                    50,
                    51,
                    52,
                    56,
                    185,
                    186,
                    62,
                    63,
                    67,
                    68,
                    71,
                    72,
                    73,
                    74,
                    75,
                    77,
                    81,
                    210,
                    211,
                    84,
                    88,
                    89,
                    90,
                    216,
                    220,
                    227,
                    107,
                    242,
                    115,
                    116,
                    117,
                    118,
                    246,
                    248,
                    253,
                    250,
                    252,
                    125
                ],
                "spidercls": [
                    166,
                    165,
                    30,
                    167
                ],
                "self.settings": [
                    34,
                    167,
                    43,
                    47,
                    48,
                    115,
                    248,
                    250,
                    252,
                    62,
                    31
                ],
                "settings.copy": [
                    31
                ],
                "self.signals": [
                    33,
                    41
                ],
                "SignalManager": [
                    33
                ],
                "self.stats": [
                    34
                ],
                "load_object": [
                    273,
                    34,
                    43
                ],
                "handler": [
                    40,
                    36,
                    37
                ],
                "LogCounterHandler": [
                    36
                ],
                "settings.get": [
                    272,
                    265,
                    36,
                    271
                ],
                "logging.root.addHandler": [
                    37
                ],
                "logging.root": [
                    40,
                    37
                ],
                "self.__remove_handler": [
                    40,
                    41
                ],
                "logging.root.removeHandler": [
                    40
                ],
                "self.signals.connect": [
                    41
                ],
                "signals.engine_stopped": [
                    41
                ],
                "signals": [
                    41
                ],
                "lf_cls": [
                    43,
                    44
                ],
                "self.logformatter": [
                    44
                ],
                "lf_cls.from_crawler": [
                    44
                ],
                "self.extensions": [
                    45
                ],
                "ExtensionManager.from_crawler": [
                    45
                ],
                "ExtensionManager": [
                    45
                ],
                "self.spidercls.update_settings": [
                    47
                ],
                "self.settings.freeze": [
                    48
                ],
                "self.crawling": [
                    67,
                    68,
                    77,
                    50,
                    88,
                    89
                ],
                "self.spider": [
                    73,
                    74,
                    51,
                    71
                ],
                "self.engine": [
                    72,
                    74,
                    75,
                    52,
                    90
                ],
                "hasattr": [
                    56
                ],
                "warnings.warn": [
                    57,
                    122,
                    266,
                    277
                ],
                "warnings": [
                    57,
                    122,
                    266,
                    277
                ],
                "ScrapyDeprecationWarning": [
                    281,
                    269,
                    124,
                    61
                ],
                "self._spiders": [
                    62,
                    63
                ],
                "_get_spider_loader": [
                    116,
                    62
                ],
                "self.settings.frozencopy": [
                    62
                ],
                "property": [
                    120,
                    106,
                    54
                ],
                "self._create_spider": [
                    71
                ],
                "args": [
                    81,
                    154,
                    71
                ],
                "kwargs": [
                    81,
                    154,
                    71
                ],
                "self._create_engine": [
                    72
                ],
                "start_requests": [
                    73,
                    74
                ],
                "iter": [
                    73
                ],
                "self.spider.start_requests": [
                    73
                ],
                "self.engine.open_spider": [
                    74
                ],
                "defer.maybeDeferred": [
                    90,
                    75
                ],
                "defer": [
                    65,
                    186,
                    75,
                    175,
                    177,
                    86,
                    90
                ],
                "self.engine.start": [
                    75
                ],
                "Exception": [
                    76
                ],
                "defer.inlineCallbacks": [
                    65,
                    177,
                    86
                ],
                "self.spidercls.from_crawler": [
                    81
                ],
                "ExecutionEngine": [
                    84
                ],
                "self.stop": [
                    220,
                    84,
                    253
                ],
                "self.engine.stop": [
                    90
                ],
                "crawlers": [
                    106
                ],
                "self._crawlers": [
                    107,
                    117
                ],
                "self.spider_loader": [
                    116,
                    125,
                    166
                ],
                "set": [
                    117,
                    118
                ],
                "self._active": [
                    118,
                    185,
                    186,
                    155,
                    159
                ],
                "crawler": [
                    149,
                    151,
                    153,
                    154,
                    158
                ],
                "crawler_or_spidercls": [
                    149,
                    150,
                    151
                ],
                "Crawler": [
                    150,
                    167
                ],
                "self._create_crawler": [
                    151
                ],
                "self.crawlers.add": [
                    153
                ],
                "self.crawlers": [
                    153,
                    158,
                    175
                ],
                "d": [
                    162,
                    242,
                    244,
                    246,
                    154,
                    155,
                    159
                ],
                "crawler.crawl": [
                    154
                ],
                "self._active.add": [
                    155
                ],
                "self.crawlers.discard": [
                    158
                ],
                "self._active.discard": [
                    159
                ],
                "result": [
                    160
                ],
                "d.addBoth": [
                    162,
                    246
                ],
                "_done": [
                    162
                ],
                "six.string_types": [
                    165
                ],
                "six": [
                    165
                ],
                "self.spider_loader.load": [
                    166
                ],
                "defer.DeferredList": [
                    186,
                    175
                ],
                "c.stop": [
                    175
                ],
                "c": [
                    175
                ],
                "list": [
                    175
                ],
                "CrawlerRunner": [
                    189
                ],
                "__init__": [
                    210
                ],
                "super": [
                    210
                ],
                "CrawlerProcess": [
                    210
                ],
                "install_shutdown_handlers": [
                    216,
                    211,
                    223
                ],
                "self._signal_shutdown": [
                    211
                ],
                "configure_logging": [
                    212
                ],
                "log_scrapy_info": [
                    213
                ],
                "self._signal_kill": [
                    216
                ],
                "signame": [
                    224,
                    217,
                    226,
                    219
                ],
                "signal_names": [
                    224,
                    217
                ],
                "signum": [
                    224,
                    217
                ],
                "logger.info": [
                    225,
                    218
                ],
                "reactor.callFromThread": [
                    227,
                    220
                ],
                "reactor": [
                    258,
                    227,
                    249,
                    251,
                    220,
                    253,
                    254
                ],
                "signal.SIG_IGN": [
                    223
                ],
                "signal": [
                    223
                ],
                "self._stop_reactor": [
                    227,
                    246
                ],
                "stop_after_crawl": [
                    241
                ],
                "self.join": [
                    242
                ],
                "d.called": [
                    244
                ],
                "cache_size": [
                    248,
                    249
                ],
                "self.settings.getbool": [
                    248
                ],
                "self.settings.getint": [
                    248,
                    252
                ],
                "reactor.installResolver": [
                    249
                ],
                "CachingThreadedResolver": [
                    249
                ],
                "self.settings.getfloat": [
                    250
                ],
                "tp": [
                    251,
                    252
                ],
                "reactor.getThreadPool": [
                    251
                ],
                "tp.adjustPoolsize": [
                    252
                ],
                "reactor.addSystemEventTrigger": [
                    253
                ],
                "reactor.run": [
                    254
                ],
                "reactor.stop": [
                    258
                ],
                "RuntimeError": [
                    259
                ],
                "cls_path": [
                    273,
                    271
                ],
                "loader_cls": [
                    283,
                    273,
                    275
                ],
                "verifyClass": [
                    275
                ],
                "ISpiderLoader": [
                    275
                ],
                "DoesNotImplement": [
                    276
                ],
                "loader_cls.from_settings": [
                    283
                ],
                "settings.frozencopy": [
                    283
                ]
            },
            "filtered_variables_in_file": {
                "logger": [
                    225,
                    218,
                    21
                ],
                "logging.getLogger": [
                    21
                ],
                "logging": [
                    40,
                    37,
                    21
                ],
                "settings": [
                    36,
                    265,
                    271,
                    272,
                    113,
                    114,
                    115,
                    116,
                    210,
                    212,
                    213,
                    283,
                    27,
                    28,
                    31
                ],
                "Settings": [
                    114,
                    28
                ],
                "self.spidercls": [
                    81,
                    30,
                    47
                ],
                "self": [
                    151,
                    153,
                    155,
                    30,
                    31,
                    158,
                    33,
                    34,
                    159,
                    36,
                    166,
                    167,
                    40,
                    41,
                    43,
                    44,
                    45,
                    47,
                    48,
                    175,
                    50,
                    51,
                    52,
                    56,
                    185,
                    186,
                    62,
                    63,
                    67,
                    68,
                    71,
                    72,
                    73,
                    74,
                    75,
                    77,
                    81,
                    210,
                    211,
                    84,
                    88,
                    89,
                    90,
                    216,
                    220,
                    227,
                    107,
                    242,
                    115,
                    116,
                    117,
                    118,
                    246,
                    248,
                    253,
                    250,
                    252,
                    125
                ],
                "spidercls": [
                    166,
                    165,
                    30,
                    167
                ],
                "self.settings": [
                    34,
                    167,
                    43,
                    47,
                    48,
                    115,
                    248,
                    250,
                    252,
                    62,
                    31
                ],
                "settings.copy": [
                    31
                ],
                "self.signals": [
                    33,
                    41
                ],
                "SignalManager": [
                    33
                ],
                "self.stats": [
                    34
                ],
                "load_object": [
                    273,
                    34,
                    43
                ],
                "handler": [
                    40,
                    36,
                    37
                ],
                "LogCounterHandler": [
                    36
                ],
                "settings.get": [
                    272,
                    265,
                    36,
                    271
                ],
                "logging.root.addHandler": [
                    37
                ],
                "logging.root": [
                    40,
                    37
                ],
                "self.__remove_handler": [
                    40,
                    41
                ],
                "logging.root.removeHandler": [
                    40
                ],
                "self.signals.connect": [
                    41
                ],
                "signals.engine_stopped": [
                    41
                ],
                "signals": [
                    41
                ],
                "lf_cls": [
                    43,
                    44
                ],
                "self.logformatter": [
                    44
                ],
                "lf_cls.from_crawler": [
                    44
                ],
                "self.extensions": [
                    45
                ],
                "ExtensionManager.from_crawler": [
                    45
                ],
                "ExtensionManager": [
                    45
                ],
                "self.spidercls.update_settings": [
                    47
                ],
                "self.settings.freeze": [
                    48
                ],
                "self.crawling": [
                    67,
                    68,
                    77,
                    50,
                    88,
                    89
                ],
                "self.spider": [
                    73,
                    74,
                    51,
                    71
                ],
                "self.engine": [
                    72,
                    74,
                    75,
                    52,
                    90
                ],
                "warnings.warn": [
                    57,
                    122,
                    266,
                    277
                ],
                "warnings": [
                    57,
                    122,
                    266,
                    277
                ],
                "ScrapyDeprecationWarning": [
                    281,
                    269,
                    124,
                    61
                ],
                "self._spiders": [
                    62,
                    63
                ],
                "_get_spider_loader": [
                    116,
                    62
                ],
                "self.settings.frozencopy": [
                    62
                ],
                "self._create_spider": [
                    71
                ],
                "args": [
                    81,
                    154,
                    71
                ],
                "kwargs": [
                    81,
                    154,
                    71
                ],
                "self._create_engine": [
                    72
                ],
                "start_requests": [
                    73,
                    74
                ],
                "self.spider.start_requests": [
                    73
                ],
                "self.engine.open_spider": [
                    74
                ],
                "defer.maybeDeferred": [
                    90,
                    75
                ],
                "defer": [
                    65,
                    186,
                    75,
                    175,
                    177,
                    86,
                    90
                ],
                "self.engine.start": [
                    75
                ],
                "defer.inlineCallbacks": [
                    65,
                    177,
                    86
                ],
                "self.spidercls.from_crawler": [
                    81
                ],
                "ExecutionEngine": [
                    84
                ],
                "self.stop": [
                    220,
                    84,
                    253
                ],
                "self.engine.stop": [
                    90
                ],
                "crawlers": [
                    106
                ],
                "self._crawlers": [
                    107,
                    117
                ],
                "self.spider_loader": [
                    116,
                    125,
                    166
                ],
                "self._active": [
                    118,
                    185,
                    186,
                    155,
                    159
                ],
                "crawler": [
                    149,
                    151,
                    153,
                    154,
                    158
                ],
                "crawler_or_spidercls": [
                    149,
                    150,
                    151
                ],
                "Crawler": [
                    150,
                    167
                ],
                "self._create_crawler": [
                    151
                ],
                "self.crawlers.add": [
                    153
                ],
                "self.crawlers": [
                    153,
                    158,
                    175
                ],
                "d": [
                    162,
                    242,
                    244,
                    246,
                    154,
                    155,
                    159
                ],
                "crawler.crawl": [
                    154
                ],
                "self._active.add": [
                    155
                ],
                "self.crawlers.discard": [
                    158
                ],
                "self._active.discard": [
                    159
                ],
                "result": [
                    160
                ],
                "d.addBoth": [
                    162,
                    246
                ],
                "_done": [
                    162
                ],
                "six.string_types": [
                    165
                ],
                "six": [
                    165
                ],
                "self.spider_loader.load": [
                    166
                ],
                "defer.DeferredList": [
                    186,
                    175
                ],
                "c.stop": [
                    175
                ],
                "c": [
                    175
                ],
                "CrawlerRunner": [
                    189
                ],
                "__init__": [
                    210
                ],
                "CrawlerProcess": [
                    210
                ],
                "install_shutdown_handlers": [
                    216,
                    211,
                    223
                ],
                "self._signal_shutdown": [
                    211
                ],
                "configure_logging": [
                    212
                ],
                "log_scrapy_info": [
                    213
                ],
                "self._signal_kill": [
                    216
                ],
                "signame": [
                    224,
                    217,
                    226,
                    219
                ],
                "signal_names": [
                    224,
                    217
                ],
                "signum": [
                    224,
                    217
                ],
                "logger.info": [
                    225,
                    218
                ],
                "reactor.callFromThread": [
                    227,
                    220
                ],
                "reactor": [
                    258,
                    227,
                    249,
                    251,
                    220,
                    253,
                    254
                ],
                "signal.SIG_IGN": [
                    223
                ],
                "signal": [
                    223
                ],
                "self._stop_reactor": [
                    227,
                    246
                ],
                "stop_after_crawl": [
                    241
                ],
                "self.join": [
                    242
                ],
                "d.called": [
                    244
                ],
                "cache_size": [
                    248,
                    249
                ],
                "self.settings.getbool": [
                    248
                ],
                "self.settings.getint": [
                    248,
                    252
                ],
                "reactor.installResolver": [
                    249
                ],
                "CachingThreadedResolver": [
                    249
                ],
                "self.settings.getfloat": [
                    250
                ],
                "tp": [
                    251,
                    252
                ],
                "reactor.getThreadPool": [
                    251
                ],
                "tp.adjustPoolsize": [
                    252
                ],
                "reactor.addSystemEventTrigger": [
                    253
                ],
                "reactor.run": [
                    254
                ],
                "reactor.stop": [
                    258
                ],
                "cls_path": [
                    273,
                    271
                ],
                "loader_cls": [
                    283,
                    273,
                    275
                ],
                "verifyClass": [
                    275
                ],
                "ISpiderLoader": [
                    275
                ],
                "DoesNotImplement": [
                    276
                ],
                "loader_cls.from_settings": [
                    283
                ],
                "settings.frozencopy": [
                    283
                ]
            }
        },
        "test_data": [
            {
                "test_path": "/Volumes/SSD2T/bgp_envs_non_pandas/repos/scrapy_32/tests/test_crawler.py",
                "test_function": "test_crawler_process_accepts_dict",
                "test_function_code": "    def test_crawler_process_accepts_dict(self):\n        runner = CrawlerProcess({'foo': 'bar'})\n        self.assertEqual(runner.settings['foo'], 'bar')\n        self.assertEqual(\n            runner.settings['RETRY_ENABLED'],\n            default_settings.RETRY_ENABLED\n        )\n        self.assertIsInstance(runner.settings, Settings)",
                "test_error": "KeyError: 'BOT_NAME'",
                "full_test_error": "self = <tests.test_crawler.CrawlerProcessTest testMethod=test_crawler_process_accepts_dict>\n\n    def test_crawler_process_accepts_dict(self):\n>       runner = CrawlerProcess({'foo': 'bar'})\n\n/Volumes/SSD2T/bgp_envs_non_pandas/repos/scrapy_32/tests/test_crawler.py:110: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/Volumes/SSD2T/bgp_envs_non_pandas/repos/scrapy_32/scrapy/crawler.py:213: in __init__\n    log_scrapy_info(settings)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nsettings = {'foo': 'bar'}\n\n    def log_scrapy_info(settings):\n        logger.info(\"Scrapy %(version)s started (bot: %(bot)s)\",\n>                   {'version': scrapy.__version__, 'bot': settings['BOT_NAME']})\nE       KeyError: 'BOT_NAME'\n\n/Volumes/SSD2T/bgp_envs_non_pandas/repos/scrapy_32/scrapy/utils/log.py:108: KeyError",
                "traceback": "/Volumes/SSD2T/bgp_envs_non_pandas/repos/scrapy_32/scrapy/crawler.py:213: in __init__\n    log_scrapy_info(settings)",
                "test_error_location": "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nsettings = {'foo': 'bar'}\n\n    def log_scrapy_info(settings):\n        logger.info(\"Scrapy %(version)s started (bot: %(bot)s)\",\n>                   {'version': scrapy.__version__, 'bot': settings['BOT_NAME']})\nE       KeyError: 'BOT_NAME'\n\n/Volumes/SSD2T/bgp_envs_non_pandas/repos/scrapy_32/scrapy/utils/log.py:108: KeyError",
                "test_function_decorators": []
            }
        ]
    }
}