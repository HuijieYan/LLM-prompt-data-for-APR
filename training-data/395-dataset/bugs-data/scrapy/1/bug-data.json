{
    "scrapy:1": {
        "/Volumes/SSD2T/bgp_envs/repos/scrapy_1/scrapy/spidermiddlewares/offsite.py": {
            "buggy_functions": [
                {
                    "function_name": "get_host_regex",
                    "function_code": "def get_host_regex(self, spider):\n    \"\"\"Override this method to implement a different offsite policy\"\"\"\n    allowed_domains = getattr(spider, 'allowed_domains', None)\n    if not allowed_domains:\n        return re.compile('')  # allow all by default\n    url_pattern = re.compile(\"^https?://.*$\")\n    for domain in allowed_domains:\n        if url_pattern.match(domain):\n            message = (\"allowed_domains accepts only domains, not URLs. \"\n                       \"Ignoring URL entry %s in allowed_domains.\" % domain)\n            warnings.warn(message, URLWarning)\n    domains = [re.escape(d) for d in allowed_domains if d is not None]\n    regex = r'^(.*\\.)?(%s)$' % '|'.join(domains)\n    return re.compile(regex)\n",
                    "decorators": [],
                    "docstring": "Override this method to implement a different offsite policy",
                    "start_line": 51,
                    "end_line": 64,
                    "variables": {
                        "allowed_domains": [
                            62,
                            57,
                            53,
                            54
                        ],
                        "getattr": [
                            53
                        ],
                        "spider": [
                            53
                        ],
                        "re.compile": [
                            56,
                            64,
                            55
                        ],
                        "re": [
                            56,
                            64,
                            62,
                            55
                        ],
                        "url_pattern": [
                            56,
                            58
                        ],
                        "domain": [
                            57,
                            58,
                            60
                        ],
                        "url_pattern.match": [
                            58
                        ],
                        "message": [
                            59,
                            61
                        ],
                        "warnings.warn": [
                            61
                        ],
                        "warnings": [
                            61
                        ],
                        "URLWarning": [
                            61
                        ],
                        "domains": [
                            62,
                            63
                        ],
                        "re.escape": [
                            62
                        ],
                        "d": [
                            62
                        ],
                        "regex": [
                            64,
                            63
                        ],
                        "join": [
                            63
                        ]
                    },
                    "filtered_variables": {
                        "allowed_domains": [
                            62,
                            57,
                            53,
                            54
                        ],
                        "spider": [
                            53
                        ],
                        "re.compile": [
                            56,
                            64,
                            55
                        ],
                        "re": [
                            56,
                            64,
                            62,
                            55
                        ],
                        "url_pattern": [
                            56,
                            58
                        ],
                        "domain": [
                            57,
                            58,
                            60
                        ],
                        "url_pattern.match": [
                            58
                        ],
                        "message": [
                            59,
                            61
                        ],
                        "warnings.warn": [
                            61
                        ],
                        "warnings": [
                            61
                        ],
                        "URLWarning": [
                            61
                        ],
                        "domains": [
                            62,
                            63
                        ],
                        "re.escape": [
                            62
                        ],
                        "d": [
                            62
                        ],
                        "regex": [
                            64,
                            63
                        ],
                        "join": [
                            63
                        ]
                    },
                    "diff_line_number": 56,
                    "class_data": {
                        "signature": "class OffsiteMiddleware(object)",
                        "docstring": null,
                        "constructor_docstring": null,
                        "functions": [
                            "def __init__(self, stats):\n    self.stats = stats",
                            "@classmethod\ndef from_crawler(cls, crawler):\n    o = cls(crawler.stats)\n    crawler.signals.connect(o.spider_opened, signal=signals.spider_opened)\n    return o",
                            "def process_spider_output(self, response, result, spider):\n    for x in result:\n        if isinstance(x, Request):\n            if x.dont_filter or self.should_follow(x, spider):\n                yield x\n            else:\n                domain = urlparse_cached(x).hostname\n                if domain and domain not in self.domains_seen:\n                    self.domains_seen.add(domain)\n                    logger.debug('Filtered offsite request to %(domain)r: %(request)s', {'domain': domain, 'request': x}, extra={'spider': spider})\n                    self.stats.inc_value('offsite/domains', spider=spider)\n                self.stats.inc_value('offsite/filtered', spider=spider)\n        else:\n            yield x",
                            "def should_follow(self, request, spider):\n    regex = self.host_regex\n    host = urlparse_cached(request).hostname or ''\n    return bool(regex.search(host))",
                            "def get_host_regex(self, spider):\n    \"\"\"Override this method to implement a different offsite policy\"\"\"\n    allowed_domains = getattr(spider, 'allowed_domains', None)\n    if not allowed_domains:\n        return re.compile('')\n    url_pattern = re.compile('^https?://.*$')\n    for domain in allowed_domains:\n        if url_pattern.match(domain):\n            message = 'allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains.' % domain\n            warnings.warn(message, URLWarning)\n    domains = [re.escape(d) for d in allowed_domains if d is not None]\n    regex = '^(.*\\\\.)?(%s)$' % '|'.join(domains)\n    return re.compile(regex)",
                            "def spider_opened(self, spider):\n    self.host_regex = self.get_host_regex(spider)\n    self.domains_seen = set()"
                        ],
                        "constructor_variables": [
                            "stats"
                        ],
                        "class_level_variables": [],
                        "class_decorators": [],
                        "function_signatures": [
                            "__init__(self, stats)",
                            "from_crawler(cls, crawler)",
                            "process_spider_output(self, response, result, spider)",
                            "should_follow(self, request, spider)",
                            "get_host_regex(self, spider)",
                            "spider_opened(self, spider)"
                        ]
                    },
                    "variable_values": [
                        [
                            {},
                            {}
                        ]
                    ],
                    "angelic_variable_values": [
                        [
                            {},
                            {}
                        ]
                    ]
                }
            ],
            "inscope_functions": [
                "def __init__(self, stats):\n    self.stats = stats",
                "@classmethod\ndef from_crawler(cls, crawler):\n    o = cls(crawler.stats)\n    crawler.signals.connect(o.spider_opened, signal=signals.spider_opened)\n    return o",
                "def process_spider_output(self, response, result, spider):\n    for x in result:\n        if isinstance(x, Request):\n            if x.dont_filter or self.should_follow(x, spider):\n                yield x\n            else:\n                domain = urlparse_cached(x).hostname\n                if domain and domain not in self.domains_seen:\n                    self.domains_seen.add(domain)\n                    logger.debug(\n                        \"Filtered offsite request to %(domain)r: %(request)s\",\n                        {'domain': domain, 'request': x}, extra={'spider': spider})\n                    self.stats.inc_value('offsite/domains', spider=spider)\n                self.stats.inc_value('offsite/filtered', spider=spider)\n        else:\n            yield x",
                "def should_follow(self, request, spider):\n    regex = self.host_regex\n    # hostname can be None for wrong urls (like javascript links)\n    host = urlparse_cached(request).hostname or ''\n    return bool(regex.search(host))",
                "def get_host_regex(self, spider):\n    \"\"\"Override this method to implement a different offsite policy\"\"\"\n    allowed_domains = getattr(spider, 'allowed_domains', None)\n    if not allowed_domains:\n        return re.compile('')  # allow all by default\n    url_pattern = re.compile(\"^https?://.*$\")\n    for domain in allowed_domains:\n        if url_pattern.match(domain):\n            message = (\"allowed_domains accepts only domains, not URLs. \"\n                       \"Ignoring URL entry %s in allowed_domains.\" % domain)\n            warnings.warn(message, URLWarning)\n    domains = [re.escape(d) for d in allowed_domains if d is not None]\n    regex = r'^(.*\\.)?(%s)$' % '|'.join(domains)\n    return re.compile(regex)",
                "def spider_opened(self, spider):\n    self.host_regex = self.get_host_regex(spider)\n    self.domains_seen = set()"
            ],
            "inscope_function_signatures": [
                "__init__(self, stats)",
                "from_crawler(cls, crawler)",
                "process_spider_output(self, response, result, spider)",
                "should_follow(self, request, spider)",
                "get_host_regex(self, spider)",
                "spider_opened(self, spider)"
            ],
            "variables_in_file": {
                "logger": [
                    37,
                    14
                ],
                "logging.getLogger": [
                    14
                ],
                "logging": [
                    14
                ],
                "__name__": [
                    14
                ],
                "object": [
                    17
                ],
                "self.stats": [
                    40,
                    41,
                    20
                ],
                "self": [
                    35,
                    36,
                    67,
                    68,
                    40,
                    41,
                    46,
                    20,
                    31
                ],
                "stats": [
                    20
                ],
                "o": [
                    24,
                    25,
                    26
                ],
                "cls": [
                    24
                ],
                "crawler.stats": [
                    24
                ],
                "crawler": [
                    24,
                    25
                ],
                "crawler.signals.connect": [
                    25
                ],
                "crawler.signals": [
                    25
                ],
                "o.spider_opened": [
                    25
                ],
                "signals.spider_opened": [
                    25
                ],
                "signals": [
                    25
                ],
                "classmethod": [
                    22
                ],
                "x": [
                    32,
                    34,
                    39,
                    43,
                    29,
                    30,
                    31
                ],
                "result": [
                    29
                ],
                "isinstance": [
                    30
                ],
                "Request": [
                    30
                ],
                "x.dont_filter": [
                    31
                ],
                "self.should_follow": [
                    31
                ],
                "spider": [
                    67,
                    39,
                    40,
                    41,
                    53,
                    31
                ],
                "domain": [
                    34,
                    35,
                    36,
                    39,
                    57,
                    58,
                    60
                ],
                "hostname": [
                    48,
                    34
                ],
                "urlparse_cached": [
                    48,
                    34
                ],
                "self.domains_seen": [
                    35,
                    36,
                    68
                ],
                "self.domains_seen.add": [
                    36
                ],
                "logger.debug": [
                    37
                ],
                "self.stats.inc_value": [
                    40,
                    41
                ],
                "regex": [
                    64,
                    49,
                    46,
                    63
                ],
                "self.host_regex": [
                    67,
                    46
                ],
                "host": [
                    48,
                    49
                ],
                "request": [
                    48
                ],
                "bool": [
                    49
                ],
                "regex.search": [
                    49
                ],
                "allowed_domains": [
                    62,
                    57,
                    53,
                    54
                ],
                "getattr": [
                    53
                ],
                "re.compile": [
                    56,
                    64,
                    55
                ],
                "re": [
                    56,
                    64,
                    62,
                    55
                ],
                "url_pattern": [
                    56,
                    58
                ],
                "url_pattern.match": [
                    58
                ],
                "message": [
                    59,
                    61
                ],
                "warnings.warn": [
                    61
                ],
                "warnings": [
                    61
                ],
                "URLWarning": [
                    61
                ],
                "domains": [
                    62,
                    63
                ],
                "re.escape": [
                    62
                ],
                "d": [
                    62
                ],
                "join": [
                    63
                ],
                "self.get_host_regex": [
                    67
                ],
                "set": [
                    68
                ],
                "Warning": [
                    71
                ]
            },
            "filtered_variables_in_file": {
                "logger": [
                    37,
                    14
                ],
                "logging.getLogger": [
                    14
                ],
                "logging": [
                    14
                ],
                "self.stats": [
                    40,
                    41,
                    20
                ],
                "self": [
                    35,
                    36,
                    67,
                    68,
                    40,
                    41,
                    46,
                    20,
                    31
                ],
                "stats": [
                    20
                ],
                "o": [
                    24,
                    25,
                    26
                ],
                "cls": [
                    24
                ],
                "crawler.stats": [
                    24
                ],
                "crawler": [
                    24,
                    25
                ],
                "crawler.signals.connect": [
                    25
                ],
                "crawler.signals": [
                    25
                ],
                "o.spider_opened": [
                    25
                ],
                "signals.spider_opened": [
                    25
                ],
                "signals": [
                    25
                ],
                "x": [
                    32,
                    34,
                    39,
                    43,
                    29,
                    30,
                    31
                ],
                "result": [
                    29
                ],
                "Request": [
                    30
                ],
                "x.dont_filter": [
                    31
                ],
                "self.should_follow": [
                    31
                ],
                "spider": [
                    67,
                    39,
                    40,
                    41,
                    53,
                    31
                ],
                "domain": [
                    34,
                    35,
                    36,
                    39,
                    57,
                    58,
                    60
                ],
                "hostname": [
                    48,
                    34
                ],
                "urlparse_cached": [
                    48,
                    34
                ],
                "self.domains_seen": [
                    35,
                    36,
                    68
                ],
                "self.domains_seen.add": [
                    36
                ],
                "logger.debug": [
                    37
                ],
                "self.stats.inc_value": [
                    40,
                    41
                ],
                "regex": [
                    64,
                    49,
                    46,
                    63
                ],
                "self.host_regex": [
                    67,
                    46
                ],
                "host": [
                    48,
                    49
                ],
                "request": [
                    48
                ],
                "regex.search": [
                    49
                ],
                "allowed_domains": [
                    62,
                    57,
                    53,
                    54
                ],
                "re.compile": [
                    56,
                    64,
                    55
                ],
                "re": [
                    56,
                    64,
                    62,
                    55
                ],
                "url_pattern": [
                    56,
                    58
                ],
                "url_pattern.match": [
                    58
                ],
                "message": [
                    59,
                    61
                ],
                "warnings.warn": [
                    61
                ],
                "warnings": [
                    61
                ],
                "URLWarning": [
                    61
                ],
                "domains": [
                    62,
                    63
                ],
                "re.escape": [
                    62
                ],
                "d": [
                    62
                ],
                "join": [
                    63
                ],
                "self.get_host_regex": [
                    67
                ]
            }
        },
        "test_data": []
    }
}