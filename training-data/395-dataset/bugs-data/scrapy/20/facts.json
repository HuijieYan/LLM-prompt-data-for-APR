{
    "1.1.1": "def _parse_sitemap(self, response):\n    if response.url.endswith('/robots.txt'):\n        for url in sitemap_urls_from_robots(response.body):\n            yield Request(url, callback=self._parse_sitemap)\n    else:\n        body = self._get_sitemap_body(response)\n        if body is None:\n            logger.warning(\"Ignoring invalid sitemap: %(response)s\",\n                           {'response': response}, extra={'spider': self})\n            return\n\n        s = Sitemap(body)\n        if s.type == 'sitemapindex':\n            for loc in iterloc(s, self.sitemap_alternate_links):\n                if any(x.search(loc) for x in self._follow):\n                    yield Request(loc, callback=self._parse_sitemap)\n        elif s.type == 'urlset':\n            for loc in iterloc(s):\n                for r, c in self._cbs:\n                    if r.search(loc):\n                        yield Request(loc, callback=c)\n                        break\n",
    "1.1.2": null,
    "1.2.1": "class SitemapSpider(Spider)",
    "1.2.2": null,
    "1.2.3": [
        "_parse_sitemap(self, response)",
        "_get_sitemap_body(self, response)"
    ],
    "1.3.1": "/Volumes/SSD2T/bgp_envs/repos/scrapy_20/scrapy/spiders/sitemap.py",
    "1.3.2": [
        "iterloc(it, alt=False)",
        "_parse_sitemap(self, response)",
        "_get_sitemap_body(self, response)"
    ],
    "1.4.1": [
        "    def test_get_sitemap_urls_from_robotstxt(self):\n        robots = b\"\"\"# Sitemap files\nSitemap: http://example.com/sitemap.xml\nSitemap: http://example.com/sitemap-product-index.xml\n\"\"\"\n\n        r = TextResponse(url=\"http://www.example.com/robots.txt\", body=robots)\n        spider = self.spider_class(\"example.com\")\n        self.assertEqual([req.url for req in spider._parse_sitemap(r)],\n                         ['http://example.com/sitemap.xml',\n                          'http://example.com/sitemap-product-index.xml'])"
    ],
    "1.4.2": [
        "/Volumes/SSD2T/bgp_envs/repos/scrapy_20/tests/test_spider.py"
    ],
    "2.1.1": [
        [
            "E           TypeError: startswith first arg must be bytes or a tuple of bytes, not str"
        ]
    ],
    "2.1.2": [
        [
            "self = <tests.test_spider.SitemapSpiderTest testMethod=test_get_sitemap_urls_from_robotstxt>\n\n        def test_get_sitemap_urls_from_robotstxt(self):\n            robots = b\"\"\"# Sitemap files\n    Sitemap: http://example.com/sitemap.xml\n    Sitemap: http://example.com/sitemap-product-index.xml\n    \"\"\"\n    \n            r = TextResponse(url=\"http://www.example.com/robots.txt\", body=robots)\n            spider = self.spider_class(\"example.com\")\n>           self.assertEqual([req.url for req in spider._parse_sitemap(r)],\n                             ['http://example.com/sitemap.xml',\n                              'http://example.com/sitemap-product-index.xml'])\n\n/Volumes/SSD2T/bgp_envs/repos/scrapy_20/tests/test_spider.py:339: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/Volumes/SSD2T/bgp_envs/repos/scrapy_20/tests/test_spider.py:339: in <listcomp>\n    self.assertEqual([req.url for req in spider._parse_sitemap(r)],\n/Volumes/SSD2T/bgp_envs/repos/scrapy_20/scrapy/spiders/sitemap.py:35: in _parse_sitemap\n    for url in sitemap_urls_from_robots(response.body):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nrobots_text = b'# Sitemap files\\nSitemap: http://example.com/sitemap.xml\\nSitemap: http://example.com/sitemap-product-index.xml\\n'\n\n    def sitemap_urls_from_robots(robots_text):\n        \"\"\"Return an iterator over all sitemap urls contained in the given\n        robots.txt file\n        \"\"\"\n        for line in robots_text.splitlines():\n>           if line.lstrip().startswith('Sitemap:'):",
            "\n/Volumes/SSD2T/bgp_envs/repos/scrapy_20/scrapy/utils/sitemap.py:42: TypeError"
        ]
    ],
    "2.1.3": null,
    "2.1.4": null,
    "2.1.5": [
        [
            {
                "response.url": "'http://www.example.com/robots.txt'",
                "response": "<200 http://www.example.com/robots.txt>",
                "response.text": "'# Sitemap files\\nSitemap: http://example.com/sitemap.xml\\nSitemap: http://example.com/sitemap-product-index.xml\\n'",
                "self.sitemap_alternate_links": "False",
                "self._follow": "[re.compile('')]",
                "self._cbs": "[(re.compile(''), <bound method Spider.parse of <SitemapSpider 'example.com' at 0x105173af0>>)]"
            },
            {
                "url": "'http://example.com/sitemap-product-index.xml'"
            }
        ]
    ],
    "2.1.6": [
        [
            {
                "response.url": "str",
                "response": "TextResponse",
                "response.text": "str",
                "self.sitemap_alternate_links": "bool",
                "self._follow": "list",
                "self._cbs": "list"
            },
            {
                "url": "str"
            }
        ]
    ],
    "3.1.1": null,
    "3.1.2": null
}