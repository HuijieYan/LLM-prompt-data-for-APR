{
    "youtube-dl": [
        {
            "bugID": 8,
            "bitvector": {
                "1.1.1": 1,
                "1.1.2": 1,
                "1.2.1": 1,
                "1.2.2": 1,
                "1.2.3": 1,
                "1.3.1": 1,
                "1.3.2": 1,
                "1.4.1": 1,
                "1.4.2": 1,
                "2.1.1": 1,
                "2.1.2": 1,
                "2.1.3": 0,
                "2.1.4": 0,
                "2.1.5": 0,
                "2.1.6": 0,
                "3.1.1": 1,
                "3.1.2": 1,
                "cot": 0
            },
            "strata": {
                "1": 1,
                "2": 1,
                "3": 1,
                "4": 1,
                "5": 0,
                "6": 1,
                "7": 0
            },
            "available_bitvector": {
                "1.1.1": 1,
                "1.1.2": 0,
                "1.2.1": 1,
                "1.2.2": 1,
                "1.2.3": 1,
                "1.3.1": 1,
                "1.3.2": 1,
                "1.4.1": 1,
                "1.4.2": 1,
                "2.1.1": 1,
                "2.1.2": 1,
                "2.1.3": 0,
                "2.1.4": 0,
                "2.1.5": 0,
                "2.1.6": 0,
                "3.1.1": 0,
                "3.1.2": 0,
                "cot": 0
            },
            "available_strata": {
                "1": 1,
                "2": 1,
                "3": 1,
                "4": 1,
                "5": 0,
                "6": 0,
                "7": 0
            },
            "start_line": 913,
            "file_name": "youtube_dl/YoutubeDL.py",
            "replace_code": "def build_format_selector(self, format_spec):\n    import io\n    import itertools\n    import collections\n    import tokenize\n    from youtube_dl.compat import (\n    compat_tokenize_tokenize,\n)\n    from youtube_dl.YoutubeIE import (\n    YoutubeIE,\n)\n    import unittest\n    from youtube_dl.YoutubeDL import YoutubeDL\n    def syntax_error(note, start):\n        message = (\n            'Invalid format specification: '\n            '{0}\\n\\t{1}\\n\\t{2}^'.format(note, format_spec, ' ' * start[1]))\n        return SyntaxError(message)\n    \n    PICKFIRST = 'PICKFIRST'\n    MERGE = 'MERGE'\n    SINGLE = 'SINGLE'\n    GROUP = 'GROUP'\n    FormatSelector = collections.namedtuple('FormatSelector', ['type', 'selector', 'filters'])\n    \n    def _parse_filter(tokens):\n        filter_parts = []\n        for type, string, start, _, _ in tokens:\n            if type == tokenize.OP and string == ']':\n                return ''.join(filter_parts)\n            else:\n                filter_parts.append(string)\n    \n    def _parse_format_selection(tokens, inside_merge=False, inside_choice=False, inside_group=False):\n        selectors = []\n        current_selector = None\n        for type, string, start, _, _ in tokens:\n            # ENCODING is only defined in python 3.x\n            if type == getattr(tokenize, 'ENCODING', None):\n                continue\n            # ... (rest of the code remains the same) ...\n    \n    def _build_selector_function(selector):\n        if isinstance(selector, list):\n            fs = [_build_selector_function(s) for s in selector]\n    \n            def selector_function(formats):\n                for f in fs:\n                    for format in f(formats):\n                        yield format\n            return selector_function\n        # ... (rest of the code remains the same) ...\n    \n    stream = io.BytesIO(format_spec.encode('utf-8'))\n    try:\n        tokens = list(compat_tokenize_tokenize(stream.readline))\n    except tokenize.TokenError:\n        raise syntax_error('Missing closing/opening brackets or parenthesis', (0, len(format_spec)))\n    \n    class TokenIterator(object):\n        def __init__(self, tokens):\n            self.tokens = tokens\n            self.counter = 0\n    \n        def __iter__(self):\n            return self\n    \n        def __next__(self):\n            if self.counter >= len(self.tokens):\n                raise StopIteration()\n            value = self.tokens[self.counter]\n            self.counter += 1\n            return value\n    \n        next = __next__\n    \n        def restore_last_token(self):\n            self.counter -= 1\n    \n    parsed_selector = _parse_format_selection(iter(TokenIterator(tokens)))\n    return _build_selector_function(parsed_selector)"
        }
    ]
}