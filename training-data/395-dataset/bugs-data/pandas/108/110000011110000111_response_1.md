The problem with the function `infer_dtype_from_scalar` is that it doesn't handle the `Interval` data type correctly when `pandas_dtype` is set to `True`. This results in incorrect inference of the data type as `np.object_` instead of `IntervalDtype`.

The function should be modified to correctly handle `Interval` data types and infer the appropriate data type when `pandas_dtype` is set to `True`.

Here's the corrected function:

```python
import numpy as np
from pandas._libs.tslibs import Timestamp, Timedelta, PeriodDtype

def infer_dtype_from_scalar(val, pandas_dtype: bool = False):
    # ... (existing code)

    if isinstance(val, pd.Interval):
        subtype = 'int64'  # Default subtype for IntervalDtype
        result_dtype = f"interval[{subtype}]" if pandas_dtype else np.object_
        return result_dtype, val

    # ... (remaining code)
```

In this corrected code:
- We are handling the `pd.Interval` data type case and correctly inferring the data type as `interval[int64]` when `pandas_dtype` is set to `True`.
- If `pandas_dtype` is not set to `True`, the function will return the data type as `np.object_` as before.

This correction should address the issue identified in the GitHub bug report and ensure that `Interval` data types are correctly handled when inferring data types with the `infer_dtype_from_scalar` function.