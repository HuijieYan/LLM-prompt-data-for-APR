{
    "1.1.1": null,
    "1.1.2": null,
    "1.2.1": null,
    "1.2.2": null,
    "1.2.3": null,
    "1.3.1": "/Volumes/JerrySSD/bgp_envs/repos/pandas_130/pandas/core/groupby/ops.py",
    "1.3.2": null,
    "1.4.1": [
        "def test_series_groupby_value_counts_with_grouper():\n    # GH28479\n    df = DataFrame(\n        {\n            \"Timestamp\": [\n                1565083561,\n                1565083561 + 86400,\n                1565083561 + 86500,\n                1565083561 + 86400 * 2,\n                1565083561 + 86400 * 3,\n                1565083561 + 86500 * 3,\n                1565083561 + 86400 * 4,\n            ],\n            \"Food\": [\"apple\", \"apple\", \"banana\", \"banana\", \"orange\", \"orange\", \"pear\"],\n        }\n    ).drop([3])\n\n    df[\"Datetime\"] = to_datetime(df[\"Timestamp\"].apply(lambda t: str(t)), unit=\"s\")\n    dfg = df.groupby(Grouper(freq=\"1D\", key=\"Datetime\"))\n\n    # have to sort on index because of unstable sort on values xref GH9212\n    result = dfg[\"Food\"].value_counts().sort_index()\n    expected = dfg[\"Food\"].apply(Series.value_counts).sort_index()\n    expected.index.names = result.index.names\n\n    tm.assert_series_equal(result, expected)"
    ],
    "1.4.2": [
        "/Volumes/JerrySSD/bgp_envs/repos/pandas_130/pandas/tests/groupby/test_value_counts.py"
    ],
    "2.1.1": [
        [
            "E           ValueError: operands could not be broadcast together with shape (5,) (4,)"
        ]
    ],
    "2.1.2": [
        [
            "def test_series_groupby_value_counts_with_grouper():\n        # GH28479\n        df = DataFrame(\n            {\n                \"Timestamp\": [\n                    1565083561,\n                    1565083561 + 86400,\n                    1565083561 + 86500,\n                    1565083561 + 86400 * 2,\n                    1565083561 + 86400 * 3,\n                    1565083561 + 86500 * 3,\n                    1565083561 + 86400 * 4,\n                ],\n                \"Food\": [\"apple\", \"apple\", \"banana\", \"banana\", \"orange\", \"orange\", \"pear\"],\n            }\n        ).drop([3])\n    \n        df[\"Datetime\"] = to_datetime(df[\"Timestamp\"].apply(lambda t: str(t)), unit=\"s\")\n        dfg = df.groupby(Grouper(freq=\"1D\", key=\"Datetime\"))\n    \n        # have to sort on index because of unstable sort on values xref GH9212\n>       result = dfg[\"Food\"].value_counts().sort_index()\n\npandas/tests/groupby/test_value_counts.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \npandas/core/groupby/generic.py:659: in value_counts\n    codes = [rep(level_codes) for level_codes in codes] + [llab(lab, inc)]\npandas/core/groupby/generic.py:659: in <listcomp>\n    codes = [rep(level_codes) for level_codes in codes] + [llab(lab, inc)]\n<__array_function__ internals>:5: in repeat\n    ???\n../../envs/pandas_130/lib/python3.8/site-packages/numpy/core/fromnumeric.py:482: in repeat\n    return _wrapfunc(a, 'repeat', repeats, axis=axis)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nobj = array([0, 1, 2, 3, 4]), method = 'repeat', args = (array([1, 2, 1, 1]),)\nkwds = {'axis': None}\nbound = <built-in method repeat of numpy.ndarray object at 0x11d2fac10>\n\n    def _wrapfunc(obj, method, *args, **kwds):\n        bound = getattr(obj, method, None)\n        if bound is None:\n            return _wrapit(obj, method, *args, **kwds)\n    \n        try:\n>           return bound(*args, **kwds)",
            "\n../../envs/pandas_130/lib/python3.8/site-packages/numpy/core/fromnumeric.py:61: ValueError"
        ]
    ],
    "2.1.3": null,
    "2.1.4": null,
    "2.1.5": null,
    "2.1.6": null,
    "3.1.1": [
        "value_counts() crashes if groupby object contains empty groups\n"
    ],
    "3.1.2": [
        "When you group some statistical counts for every day, it is possible that on some day there is no counts at all. This will result in empty groups in the groupby object. Performing value_counts() on such groupby objects causes crash.\n\nThe following example illustrates the problem:\n\nimport pandas as pd\ndf = pd.DataFrame({'Timestamp':[1565083561, 1565083561+86400, 1565083561+86500, 1565083561+86400*2, 1565083561+86400*3, 1565083561+86500*3, 1565083561+86400*4],\n                   'Food':['apple', 'apple', 'banana', 'banana', 'orange', 'orange', 'pear']})\ndf['Datetime'] = pd.to_datetime(df['Timestamp'].apply(lambda t:str(t)), unit='s')\ndisplay(df)\ndfg = df.groupby(pd.Grouper(freq='1D', key='Datetime'))\n[print(g) for g in dfg]\ndisplay(dfg['Food'].value_counts())\n\ndf = df.drop([3])\ndisplay(df)\ndfg = df.groupby(pd.Grouper(freq='1D', key='Datetime'))\n[print(g) for g in dfg]\ndisplay(dfg['Food'].value_counts())\nThis table does not contain days with empty data, value_counts() does not crash:\n\nTimestamp\tFood\tDatetime\n1565083561\tapple\t2019-08-06 09:26:01\n1565169961\tapple\t2019-08-07 09:26:01\n1565170061\tbanana\t2019-08-07 09:27:41\n1565256361\tbanana\t2019-08-08 09:26:01\n1565342761\torange\t2019-08-09 09:26:01\n1565343061\torange\t2019-08-09 09:31:01\n1565429161\tpear\t2019-08-10 09:26:01\nAfter groupby each day:\n(Timestamp('2019-08-06 00:00:00', freq='D'), Timestamp Food Datetime\n0 1565083561 apple 2019-08-06 09:26:01)\n(Timestamp('2019-08-07 00:00:00', freq='D'), Timestamp Food Datetime\n1 1565169961 apple 2019-08-07 09:26:01\n2 1565170061 banana 2019-08-07 09:27:41)\n(Timestamp('2019-08-08 00:00:00', freq='D'), Timestamp Food Datetime\n3 1565256361 banana 2019-08-08 09:26:01)\n(Timestamp('2019-08-09 00:00:00', freq='D'), Timestamp Food Datetime\n4 1565342761 orange 2019-08-09 09:26:01\n5 1565343061 orange 2019-08-09 09:31:01)\n(Timestamp('2019-08-10 00:00:00', freq='D'), Timestamp Food Datetime\n6 1565429161 pear 2019-08-10 09:26:01)\n\nResult of value_counts():\nDatetime Food\n2019-08-06 apple 1\n2019-08-07 apple 1\n                  banana 1\n2019-08-08 banana 1\n2019-08-09 orange 2\n2019-08-10 pear 1\nName: Food, dtype: int64\n\nThis table contains a day with empty data (2019-08-08), value_counts() will crash:\n\nTimestamp\tFood\tDatetime\n1565083561\tapple\t2019-08-06 09:26:01\n1565169961\tapple\t2019-08-07 09:26:01\n1565170061\tbanana\t2019-08-07 09:27:41\n1565342761\torange\t2019-08-09 09:26:01\n1565343061\torange\t2019-08-09 09:31:01\n1565429161\tpear\t2019-08-10 09:26:01\nAfter groupby each day (note the empty group on 2019-08-08):\n(Timestamp('2019-08-06 00:00:00', freq='D'), Timestamp Food Datetime\n0 1565083561 apple 2019-08-06 09:26:01)\n(Timestamp('2019-08-07 00:00:00', freq='D'), Timestamp Food Datetime\n1 1565169961 apple 2019-08-07 09:26:01\n2 1565170061 banana 2019-08-07 09:27:41)\n(Timestamp('2019-08-08 00:00:00', freq='D'), Empty DataFrame\nColumns: [Timestamp, Food, Datetime]\nIndex: [])\n(Timestamp('2019-08-09 00:00:00', freq='D'), Timestamp Food Datetime\n4 1565342761 orange 2019-08-09 09:26:01\n5 1565343061 orange 2019-08-09 09:31:01)\n(Timestamp('2019-08-10 00:00:00', freq='D'), Timestamp Food Datetime\n6 1565429161 pear 2019-08-10 09:26:01)\n\nvalue_counts() crashes:\n\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n<ipython-input-543-5efc1c882109> in <module>\n     14 [print(g) for g in dfg]\n     15 print('This will cause crash:')\n---> 16 display(dfg['Food'].value_counts())\n\n~/anaconda3/lib/python3.7/site-packages/pandas/core/groupby/generic.py in value_counts(self, normalize, sort, ascending, bins, dropna)\n   1137 \n   1138         # multi-index components\n-> 1139         labels = list(map(rep, self.grouper.recons_labels)) + [llab(lab, inc)]\n   1140         levels = [ping.group_index for ping in self.grouper.groupings] + [lev]\n   1141         names = self.grouper.names + [self._selection_name]\n\n~/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py in repeat(a, repeats, axis)\n    469 \n    470     \"\"\"\n--> 471     return _wrapfunc(a, 'repeat', repeats, axis=axis)\n    472 \n    473 \n\n~/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds)\n     54 def _wrapfunc(obj, method, *args, **kwds):\n     55     try:\n---> 56         return getattr(obj, method)(*args, **kwds)\n     57 \n     58     # An AttributeError occurs if the object does not have\n\nValueError: operands could not be broadcast together with shape (5,) (4,)\nIt turns out that this might result from a design flaw in DataFrame construction that it skips empty rows:\npd.DataFrame.from_dict(data={'row1':{'a':1, 'b':2}, 'row2': {'a':3, 'b':4, 'c':5}, 'row3':{}}, orient='index').fillna(0)\n\n \ta\tb\tc\nrow1\t1\t2\t0\nrow2\t3\t4\t5.0\nTake note that row3 is not constructed at all. The correct behavior should output:\n\n \ta\tb\tc\nrow1\t1\t2\t0.0\nrow2\t3\t4\t5.0\nrow3\t0\t0\t0.0\n"
    ]
}