{
    "1.1.1": "def _make_concat_multiindex(indexes, keys, levels=None, names=None) -> MultiIndex:\n\n    if (levels is None and isinstance(keys[0], tuple)) or (\n        levels is not None and len(levels) > 1\n    ):\n        zipped = list(zip(*keys))\n        if names is None:\n            names = [None] * len(zipped)\n\n        if levels is None:\n            _, levels = factorize_from_iterables(zipped)\n        else:\n            levels = [ensure_index(x) for x in levels]\n    else:\n        zipped = [keys]\n        if names is None:\n            names = [None]\n\n        if levels is None:\n            levels = [ensure_index(keys)]\n        else:\n            levels = [ensure_index(x) for x in levels]\n\n    if not all_indexes_same(indexes):\n        codes_list = []\n\n        # things are potentially different sizes, so compute the exact codes\n        # for each level and pass those to MultiIndex.from_arrays\n\n        for hlevel, level in zip(zipped, levels):\n            to_concat = []\n            for key, index in zip(hlevel, indexes):\n                try:\n                    i = level.get_loc(key)\n                except KeyError as err:\n                    raise ValueError(f\"Key {key} not in level {level}\") from err\n\n                to_concat.append(np.repeat(i, len(index)))\n            codes_list.append(np.concatenate(to_concat))\n\n        concat_index = _concat_indexes(indexes)\n\n        # these go at the end\n        if isinstance(concat_index, MultiIndex):\n            levels.extend(concat_index.levels)\n            codes_list.extend(concat_index.codes)\n        else:\n            codes, categories = factorize_from_iterable(concat_index)\n            levels.append(categories)\n            codes_list.append(codes)\n\n        if len(names) == len(levels):\n            names = list(names)\n        else:\n            # make sure that all of the passed indices have the same nlevels\n            if not len({idx.nlevels for idx in indexes}) == 1:\n                raise AssertionError(\n                    \"Cannot concat indices that do not have the same number of levels\"\n                )\n\n            # also copies\n            names = names + get_consensus_names(indexes)\n\n        return MultiIndex(\n            levels=levels, codes=codes_list, names=names, verify_integrity=False\n        )\n\n    new_index = indexes[0]\n    n = len(new_index)\n    kpieces = len(indexes)\n\n    # also copies\n    new_names = list(names)\n    new_levels = list(levels)\n\n    # construct codes\n    new_codes = []\n\n    # do something a bit more speedy\n\n    for hlevel, level in zip(zipped, levels):\n        hlevel = ensure_index(hlevel)\n        mapped = level.get_indexer(hlevel)\n\n        mask = mapped == -1\n        if mask.any():\n            raise ValueError(f\"Values not found in passed level: {hlevel[mask]!s}\")\n\n        new_codes.append(np.repeat(mapped, n))\n\n    if isinstance(new_index, MultiIndex):\n        new_levels.extend(new_index.levels)\n        new_codes.extend([np.tile(lab, kpieces) for lab in new_index.codes])\n    else:\n        new_levels.append(new_index)\n        new_codes.append(np.tile(np.arange(n), kpieces))\n\n    if len(new_names) < len(new_levels):\n        new_names.extend(new_index.names)\n\n    return MultiIndex(\n        levels=new_levels, codes=new_codes, names=new_names, verify_integrity=False\n    )\n",
    "1.1.2": null,
    "1.2.1": null,
    "1.2.2": null,
    "1.2.3": null,
    "1.3.1": "/Volumes/JerrySSD/bgp_envs/repos/pandas_11/pandas/core/reshape/concat.py",
    "1.3.2": [
        "_concat_indexes(indexes) -> Index"
    ],
    "1.4.1": [
        "@pytest.mark.parametrize(\"keys\", [[\"e\", \"f\", \"f\"], [\"f\", \"e\", \"f\"]])\ndef test_duplicate_keys(keys):\n    # GH 33654\n    df = DataFrame({\"a\": [1, 2, 3], \"b\": [4, 5, 6]})\n    s1 = Series([7, 8, 9], name=\"c\")\n    s2 = Series([10, 11, 12], name=\"d\")\n    result = concat([df, s1, s2], axis=1, keys=keys)\n    expected_values = [[1, 4, 7, 10], [2, 5, 8, 11], [3, 6, 9, 12]]\n    expected_columns = pd.MultiIndex.from_tuples(\n        [(keys[0], \"a\"), (keys[0], \"b\"), (keys[1], \"c\"), (keys[2], \"d\")]\n    )\n    expected = DataFrame(expected_values, columns=expected_columns)\n    tm.assert_frame_equal(result, expected)",
        "@pytest.mark.parametrize(\"keys\", [[\"e\", \"f\", \"f\"], [\"f\", \"e\", \"f\"]])\ndef test_duplicate_keys(keys):\n    # GH 33654\n    df = DataFrame({\"a\": [1, 2, 3], \"b\": [4, 5, 6]})\n    s1 = Series([7, 8, 9], name=\"c\")\n    s2 = Series([10, 11, 12], name=\"d\")\n    result = concat([df, s1, s2], axis=1, keys=keys)\n    expected_values = [[1, 4, 7, 10], [2, 5, 8, 11], [3, 6, 9, 12]]\n    expected_columns = pd.MultiIndex.from_tuples(\n        [(keys[0], \"a\"), (keys[0], \"b\"), (keys[1], \"c\"), (keys[2], \"d\")]\n    )\n    expected = DataFrame(expected_values, columns=expected_columns)\n    tm.assert_frame_equal(result, expected)"
    ],
    "1.4.2": [
        "/Volumes/JerrySSD/bgp_envs/repos/pandas_11/pandas/tests/reshape/test_concat.py",
        "/Volumes/JerrySSD/bgp_envs/repos/pandas_11/pandas/tests/reshape/test_concat.py"
    ],
    "2.1.1": [
        [
            "E   TypeError: int() argument must be a string, a bytes-like object or a number, not 'slice'"
        ],
        [
            "E           AssertionError: Number of manager items must equal union of block items\nE           # manager items: 10, # tot_items: 4"
        ]
    ],
    "2.1.2": [
        [
            "keys = ['e', 'f', 'f']\n\n    @pytest.mark.parametrize(\"keys\", [[\"e\", \"f\", \"f\"], [\"f\", \"e\", \"f\"]])\n    def test_duplicate_keys(keys):\n        # GH 33654\n        df = DataFrame({\"a\": [1, 2, 3], \"b\": [4, 5, 6]})\n        s1 = Series([7, 8, 9], name=\"c\")\n        s2 = Series([10, 11, 12], name=\"d\")\n>       result = concat([df, s1, s2], axis=1, keys=keys)\n\npandas/tests/reshape/test_concat.py:2813: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \npandas/core/reshape/concat.py:271: in concat\n    op = _Concatenator(\npandas/core/reshape/concat.py:451: in __init__\n    self.new_axes = self._get_new_axes()\npandas/core/reshape/concat.py:514: in _get_new_axes\n    return [\npandas/core/reshape/concat.py:515: in <listcomp>\n    self._get_concat_axis() if i == self.bm_axis else self._get_comb_axis(i)\npandas/core/reshape/concat.py:571: in _get_concat_axis\n    concat_axis = _make_concat_multiindex(\npandas/core/reshape/concat.py:653: in _make_concat_multiindex\n    return MultiIndex(\npandas/core/indexes/multi.py:283: in __new__\n    result._set_codes(codes, copy=copy, validate=False)\npandas/core/indexes/multi.py:884: in _set_codes\n    new_codes = FrozenList(\npandas/core/indexes/multi.py:885: in <genexpr>\n    _coerce_indexer_frozen(level_codes, lev, copy=copy).view()\npandas/core/indexes/multi.py:3686: in _coerce_indexer_frozen\n    array_like = coerce_indexer_dtype(array_like, categories)\npandas/core/dtypes/cast.py:845: in coerce_indexer_dtype\n    return ensure_int8(indexer)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n>   return arr.astype(np.int8, copy=copy)",
            "\npandas/_libs/algos_common_helper.pxi:61: TypeError"
        ],
        [
            "keys = ['f', 'e', 'f']\n\n    @pytest.mark.parametrize(\"keys\", [[\"e\", \"f\", \"f\"], [\"f\", \"e\", \"f\"]])\n    def test_duplicate_keys(keys):\n        # GH 33654\n        df = DataFrame({\"a\": [1, 2, 3], \"b\": [4, 5, 6]})\n        s1 = Series([7, 8, 9], name=\"c\")\n        s2 = Series([10, 11, 12], name=\"d\")\n>       result = concat([df, s1, s2], axis=1, keys=keys)\n\npandas/tests/reshape/test_concat.py:2813: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \npandas/core/reshape/concat.py:284: in concat\n    return op.get_result()\npandas/core/reshape/concat.py:497: in get_result\n    new_data = concatenate_block_managers(\npandas/core/internals/concat.py:84: in concatenate_block_managers\n    return BlockManager(blocks, axes)\npandas/core/internals/managers.py:136: in __init__\n    self._verify_integrity()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <[ValueError('all arrays must be same length') raised in repr()] BlockManager object at 0x115b8c6a0>\n\n    def _verify_integrity(self) -> None:\n        mgr_shape = self.shape\n        tot_items = sum(len(x.mgr_locs) for x in self.blocks)\n        for block in self.blocks:\n            if block._verify_integrity and block.shape[1:] != mgr_shape[1:]:\n                raise construction_error(tot_items, block.shape[1:], self.axes)\n        if len(self.items) != tot_items:\n>           raise AssertionError(\n                \"Number of manager items must equal union of \"\n                f\"block items\\n# manager items: {len(self.items)}, # \"\n                f\"tot_items: {tot_items}\"\n            )",
            "\npandas/core/internals/managers.py:323: AssertionError"
        ]
    ],
    "2.1.3": null,
    "2.1.4": null,
    "2.1.5": null,
    "2.1.6": null,
    "3.1.1": [
        "\n"
    ],
    "3.1.2": [
        "\n"
    ]
}