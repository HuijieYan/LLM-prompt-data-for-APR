```python
from pandas import Index
from pandas.core.indexes.api import ensure_index
from pandas.core.arrays.categorical import factorize_from_iterables
from pandas.core.indexes.multi import MultiIndex
import numpy as np
from pandas.core.indexes.api import ensure_index
from pandas.core.indexes.multi import MultiIndex, _concat_indexes
from pandas._libs.missing import get_consensus_names
from pandas.compat.numpy import np
from pandas._libs.missing import factorize_from_iterable
from pandas._testing import assert_frame_equal
from pandas import concat, DataFrame, Series
import pandas._testing as tm
import pytest

def _make_concat_multiindex(indexes, keys, levels=None, names=None) -> MultiIndex:
    for index in indexes:
        ensure_index(index)

    zipped = list(zip(*keys))
    if names is None:
        names = [None] * len(zipped)
    if levels is None:
        _, levels = factorize_from_iterables(zipped)
    else:
        levels = [ensure_index(x) for x in levels]

    if not all_indexes_same(indexes):
        codes_list = []
        for hlevel, level in zip(zipped, levels):
            to_concat = []
            for key, index in zip(hlevel, indexes):
                i = level.get_loc(key)
                to_concat.append(np.repeat(i, len(index)))
            codes_list.append(np.concatenate(to_concat))

        concat_index = _concat_indexes(indexes)

        if isinstance(concat_index, MultiIndex):
            levels.extend(concat_index.levels)
            codes_list.extend(concat_index.codes)
        else:
            codes, categories = factorize_from_iterable(concat_index)
            levels.append(categories)
            codes_list.append(codes)

        if len(names) != len(levels):
            names = list(names)
        else:
            if len({idx.nlevels for idx in indexes}) != 1:
                raise AssertionError(
                    "Cannot concat indices that do not have the same number of levels"
                )
            names = names + get_consensus_names(indexes)

        return MultiIndex(
            levels=levels, codes=codes_list, names=names, verify_integrity=False
        )

    new_index = indexes[0]
    n = len(new_index)
    kpieces = len(indexes)

    new_names = list(names)
    new_levels = levels.copy()
    new_codes = []

    for hlevel, level in zip(zipped, levels):
        hlevel = ensure_index(hlevel)
        mapped = level.get_indexer(hlevel)

        mask = mapped == -1
        if mask.any():
            raise ValueError(f"Values not found in passed level: {hlevel[mask]!s}")

        new_codes.append(np.repeat(mapped, n))

    if isinstance(new_index, MultiIndex):
        new_levels.extend(new_index.levels)
        new_codes.extend([np.tile(lab, kpieces) for lab in new_index.codes])
    else:
        new_levels.append(new_index)
        new_codes.append(np.tile(np.arange(n), kpieces))

    if len(new_names) < len(new_levels):
        new_names.extend(new_index.names)

    return MultiIndex(
        levels=new_levels, codes=new_codes, names=new_names, verify_integrity=False
    )

def test_duplicate_keys(keys):
    df = DataFrame({"a": [1, 2, 3], "b": [4, 5, 6]})
    s1 = Series([7, 8, 9], name="c")
    s2 = Series([10, 11, 12], name="d")
    result = concat([df, s1, s2], axis=1, keys=keys)
    expected_values = [[1, 4, 7, 10], [2, 5, 8, 11], [3, 6, 9, 12]]
    expected_columns = pd.MultiIndex.from_tuples(
        [(keys[0], "a"), (keys[0], "b"), (keys[1], "c"), (keys[2], "d")]
    )
    expected = DataFrame(expected_values, columns=expected_columns)
    tm.assert_frame_equal(result, expected)
```