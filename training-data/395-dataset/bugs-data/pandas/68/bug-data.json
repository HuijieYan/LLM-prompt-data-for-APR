{
    "pandas:68": {
        "/Volumes/JerrySSD/bgp_envs/repos/pandas_68/pandas/core/arrays/interval.py": {
            "buggy_functions": [
                {
                    "function_name": "take",
                    "function_code": "def take(self, indices, allow_fill=False, fill_value=None, axis=None, **kwargs):\n    \"\"\"\n    Take elements from the IntervalArray.\n\n    Parameters\n    ----------\n    indices : sequence of integers\n        Indices to be taken.\n\n    allow_fill : bool, default False\n        How to handle negative values in `indices`.\n\n        * False: negative values in `indices` indicate positional indices\n          from the right (the default). This is similar to\n          :func:`numpy.take`.\n\n        * True: negative values in `indices` indicate\n          missing values. These values are set to `fill_value`. Any other\n          other negative values raise a ``ValueError``.\n\n    fill_value : Interval or NA, optional\n        Fill value to use for NA-indices when `allow_fill` is True.\n        This may be ``None``, in which case the default NA value for\n        the type, ``self.dtype.na_value``, is used.\n\n        For many ExtensionArrays, there will be two representations of\n        `fill_value`: a user-facing \"boxed\" scalar, and a low-level\n        physical NA value. `fill_value` should be the user-facing version,\n        and the implementation should handle translating that to the\n        physical version for processing the take if necessary.\n\n    axis : any, default None\n        Present for compat with IntervalIndex; does nothing.\n\n    Returns\n    -------\n    IntervalArray\n\n    Raises\n    ------\n    IndexError\n        When the indices are out of bounds for the array.\n    ValueError\n        When `indices` contains negative values other than ``-1``\n        and `allow_fill` is True.\n    \"\"\"\n    nv.validate_take(tuple(), kwargs)\n\n    fill_left = fill_right = fill_value\n    if allow_fill:\n        if fill_value is None:\n            fill_left = fill_right = self.left._na_value\n        elif is_interval(fill_value):\n            self._check_closed_matches(fill_value, name=\"fill_value\")\n            fill_left, fill_right = fill_value.left, fill_value.right\n        elif not is_scalar(fill_value) and notna(fill_value):\n            msg = (\n                \"'IntervalArray.fillna' only supports filling with a \"\n                \"'scalar pandas.Interval or NA'. \"\n                f\"Got a '{type(fill_value).__name__}' instead.\"\n            )\n            raise ValueError(msg)\n\n    left_take = take(\n        self.left, indices, allow_fill=allow_fill, fill_value=fill_left\n    )\n    right_take = take(\n        self.right, indices, allow_fill=allow_fill, fill_value=fill_right\n    )\n\n    return self._shallow_copy(left_take, right_take)\n",
                    "decorators": [],
                    "docstring": "Take elements from the IntervalArray.\n\nParameters\n----------\nindices : sequence of integers\n    Indices to be taken.\n\nallow_fill : bool, default False\n    How to handle negative values in `indices`.\n\n    * False: negative values in `indices` indicate positional indices\n      from the right (the default). This is similar to\n      :func:`numpy.take`.\n\n    * True: negative values in `indices` indicate\n      missing values. These values are set to `fill_value`. Any other\n      other negative values raise a ``ValueError``.\n\nfill_value : Interval or NA, optional\n    Fill value to use for NA-indices when `allow_fill` is True.\n    This may be ``None``, in which case the default NA value for\n    the type, ``self.dtype.na_value``, is used.\n\n    For many ExtensionArrays, there will be two representations of\n    `fill_value`: a user-facing \"boxed\" scalar, and a low-level\n    physical NA value. `fill_value` should be the user-facing version,\n    and the implementation should handle translating that to the\n    physical version for processing the take if necessary.\n\naxis : any, default None\n    Present for compat with IntervalIndex; does nothing.\n\nReturns\n-------\nIntervalArray\n\nRaises\n------\nIndexError\n    When the indices are out of bounds for the array.\nValueError\n    When `indices` contains negative values other than ``-1``\n    and `allow_fill` is True.",
                    "start_line": 792,
                    "variables": {
                        "nv.validate_take": [
                            838
                        ],
                        "nv": [
                            838
                        ],
                        "tuple": [
                            838
                        ],
                        "kwargs": [
                            838
                        ],
                        "fill_left": [
                            840,
                            856,
                            843,
                            846
                        ],
                        "fill_right": [
                            840,
                            859,
                            843,
                            846
                        ],
                        "fill_value": [
                            840,
                            842,
                            844,
                            845,
                            846,
                            847,
                            851
                        ],
                        "allow_fill": [
                            856,
                            841,
                            859
                        ],
                        "self.left._na_value": [
                            843
                        ],
                        "self.left": [
                            856,
                            843
                        ],
                        "self": [
                            843,
                            845,
                            856,
                            859,
                            862
                        ],
                        "is_interval": [
                            844
                        ],
                        "self._check_closed_matches": [
                            845
                        ],
                        "fill_value.left": [
                            846
                        ],
                        "fill_value.right": [
                            846
                        ],
                        "is_scalar": [
                            847
                        ],
                        "notna": [
                            847
                        ],
                        "msg": [
                            848,
                            853
                        ],
                        "__name__": [
                            851
                        ],
                        "type": [
                            851
                        ],
                        "ValueError": [
                            853
                        ],
                        "left_take": [
                            862,
                            855
                        ],
                        "take": [
                            858,
                            855
                        ],
                        "indices": [
                            856,
                            859
                        ],
                        "right_take": [
                            858,
                            862
                        ],
                        "self.right": [
                            859
                        ],
                        "self._shallow_copy": [
                            862
                        ]
                    },
                    "filtered_variables": {
                        "nv.validate_take": [
                            838
                        ],
                        "nv": [
                            838
                        ],
                        "kwargs": [
                            838
                        ],
                        "fill_left": [
                            840,
                            856,
                            843,
                            846
                        ],
                        "fill_right": [
                            840,
                            859,
                            843,
                            846
                        ],
                        "fill_value": [
                            840,
                            842,
                            844,
                            845,
                            846,
                            847,
                            851
                        ],
                        "allow_fill": [
                            856,
                            841,
                            859
                        ],
                        "self.left._na_value": [
                            843
                        ],
                        "self.left": [
                            856,
                            843
                        ],
                        "self": [
                            843,
                            845,
                            856,
                            859,
                            862
                        ],
                        "is_interval": [
                            844
                        ],
                        "self._check_closed_matches": [
                            845
                        ],
                        "fill_value.left": [
                            846
                        ],
                        "fill_value.right": [
                            846
                        ],
                        "is_scalar": [
                            847
                        ],
                        "notna": [
                            847
                        ],
                        "msg": [
                            848,
                            853
                        ],
                        "left_take": [
                            862,
                            855
                        ],
                        "take": [
                            858,
                            855
                        ],
                        "indices": [
                            856,
                            859
                        ],
                        "right_take": [
                            858,
                            862
                        ],
                        "self.right": [
                            859
                        ],
                        "self._shallow_copy": [
                            862
                        ]
                    },
                    "diff_line_number": 792,
                    "class_data": {
                        "signature": "class IntervalArray(IntervalMixin, ExtensionArray)",
                        "docstring": null,
                        "constructor_docstring": null,
                        "functions": [
                            "def __new__(cls, data, closed=None, dtype=None, copy=False, verify_integrity=True):\n    if isinstance(data, ABCSeries) and is_interval_dtype(data):\n        data = data.values\n    if isinstance(data, (cls, ABCIntervalIndex)):\n        left = data.left\n        right = data.right\n        closed = closed or data.closed\n    else:\n        if is_scalar(data):\n            msg = f'{cls.__name__}(...) must be called with a collection of some kind, {data} was passed'\n            raise TypeError(msg)\n        data = maybe_convert_platform_interval(data)\n        left, right, infer_closed = intervals_to_interval_bounds(data, validate_closed=closed is None)\n        closed = closed or infer_closed\n    return cls._simple_new(left, right, closed, copy=copy, dtype=dtype, verify_integrity=verify_integrity)",
                            "@classmethod\ndef _simple_new(cls, left, right, closed=None, copy=False, dtype=None, verify_integrity=True):\n    result = IntervalMixin.__new__(cls)\n    closed = closed or 'right'\n    left = ensure_index(left, copy=copy)\n    right = ensure_index(right, copy=copy)\n    if dtype is not None:\n        dtype = pandas_dtype(dtype)\n        if not is_interval_dtype(dtype):\n            msg = f'dtype must be an IntervalDtype, got {dtype}'\n            raise TypeError(msg)\n        elif dtype.subtype is not None:\n            left = left.astype(dtype.subtype)\n            right = right.astype(dtype.subtype)\n    if is_float_dtype(left) and is_integer_dtype(right):\n        right = right.astype(left.dtype)\n    elif is_float_dtype(right) and is_integer_dtype(left):\n        left = left.astype(right.dtype)\n    if type(left) != type(right):\n        msg = f'must not have differing left [{type(left).__name__}] and right [{type(right).__name__}] types'\n        raise ValueError(msg)\n    elif is_categorical_dtype(left.dtype) or is_string_dtype(left.dtype):\n        msg = 'category, object, and string subtypes are not supported for IntervalArray'\n        raise TypeError(msg)\n    elif isinstance(left, ABCPeriodIndex):\n        msg = 'Period dtypes are not supported, use a PeriodIndex instead'\n        raise ValueError(msg)\n    elif isinstance(left, ABCDatetimeIndex) and str(left.tz) != str(right.tz):\n        msg = f\"left and right must have the same time zone, got '{left.tz}' and '{right.tz}'\"\n        raise ValueError(msg)\n    result._left = left\n    result._right = right\n    result._closed = closed\n    if verify_integrity:\n        result._validate()\n    return result",
                            "@classmethod\ndef _from_sequence(cls, scalars, dtype=None, copy=False):\n    return cls(scalars, dtype=dtype, copy=copy)",
                            "@classmethod\ndef _from_factorized(cls, values, original):\n    if len(values) == 0:\n        values = values.astype(original.dtype.subtype)\n    return cls(values, closed=original.closed)",
                            "@classmethod\n@Appender(_interval_shared_docs['from_breaks'] % dict(klass='IntervalArray', examples=textwrap.dedent('        Examples\\n        --------\\n        >>> pd.arrays.IntervalArray.from_breaks([0, 1, 2, 3])\\n        <IntervalArray>\\n        [(0, 1], (1, 2], (2, 3]]\\n        Length: 3, closed: right, dtype: interval[int64]\\n        ')))\ndef from_breaks(cls, breaks, closed='right', copy=False, dtype=None):\n    breaks = maybe_convert_platform_interval(breaks)\n    return cls.from_arrays(breaks[:-1], breaks[1:], closed, copy=copy, dtype=dtype)",
                            "@classmethod\n@Appender(_interval_shared_docs['from_arrays'] % dict(klass='IntervalArray', examples=textwrap.dedent('        >>> pd.arrays.IntervalArray.from_arrays([0, 1, 2], [1, 2, 3])\\n        <IntervalArray>\\n        [(0, 1], (1, 2], (2, 3]]\\n        Length: 3, closed: right, dtype: interval[int64]\\n        ')))\ndef from_arrays(cls, left, right, closed='right', copy=False, dtype=None):\n    left = maybe_convert_platform_interval(left)\n    right = maybe_convert_platform_interval(right)\n    return cls._simple_new(left, right, closed, copy=copy, dtype=dtype, verify_integrity=True)",
                            "@classmethod\n@Appender(_interval_shared_docs['from_tuples'] % dict(klass='IntervalArray', examples=textwrap.dedent('        Examples\\n        --------\\n        >>> pd.arrays.IntervalArray.from_tuples([(0, 1), (1, 2)])\\n        <IntervalArray>\\n        [(0, 1], (1, 2]]\\n        Length: 2, closed: right, dtype: interval[int64]\\n        ')))\ndef from_tuples(cls, data, closed='right', copy=False, dtype=None):\n    if len(data):\n        left, right = ([], [])\n    else:\n        left = right = data\n    for d in data:\n        if isna(d):\n            lhs = rhs = np.nan\n        else:\n            name = cls.__name__\n            try:\n                lhs, rhs = d\n            except ValueError:\n                msg = f'{name}.from_tuples requires tuples of length 2, got {d}'\n                raise ValueError(msg)\n            except TypeError:\n                msg = f'{name}.from_tuples received an invalid item, {d}'\n                raise TypeError(msg)\n        left.append(lhs)\n        right.append(rhs)\n    return cls.from_arrays(left, right, closed, copy=False, dtype=dtype)",
                            "def _validate(self):\n    \"\"\"Verify that the IntervalArray is valid.\n\n    Checks that\n\n    * closed is valid\n    * left and right match lengths\n    * left and right have the same missing values\n    * left is always below right\n    \"\"\"\n    if self.closed not in _VALID_CLOSED:\n        msg = f\"invalid option for 'closed': {self.closed}\"\n        raise ValueError(msg)\n    if len(self.left) != len(self.right):\n        msg = 'left and right must have the same length'\n        raise ValueError(msg)\n    left_mask = notna(self.left)\n    right_mask = notna(self.right)\n    if not (left_mask == right_mask).all():\n        msg = 'missing values must be missing in the same location both left and right sides'\n        raise ValueError(msg)\n    if not (self.left[left_mask] <= self.right[left_mask]).all():\n        msg = 'left side of interval must be <= right side'\n        raise ValueError(msg)",
                            "def __iter__(self):\n    return iter(np.asarray(self))",
                            "def __len__(self) -> int:\n    return len(self.left)",
                            "def __getitem__(self, value):\n    value = check_array_indexer(self, value)\n    left = self.left[value]\n    right = self.right[value]\n    if not isinstance(left, ABCIndexClass):\n        if is_scalar(left) and isna(left):\n            return self._fill_value\n        if np.ndim(left) > 1:\n            raise ValueError('multi-dimensional indexing not allowed')\n        return Interval(left, right, self.closed)\n    return self._shallow_copy(left, right)",
                            "def __setitem__(self, key, value):\n    needs_float_conversion = False\n    if is_scalar(value) and isna(value):\n        if is_integer_dtype(self.dtype.subtype):\n            needs_float_conversion = True\n        elif is_datetime64_any_dtype(self.dtype.subtype):\n            value = np.datetime64('NaT')\n        elif is_timedelta64_dtype(self.dtype.subtype):\n            value = np.timedelta64('NaT')\n        value_left, value_right = (value, value)\n    elif is_interval_dtype(value) or isinstance(value, ABCInterval):\n        self._check_closed_matches(value, name='value')\n        value_left, value_right = (value.left, value.right)\n    else:\n        try:\n            array = IntervalArray(value)\n            value_left, value_right = (array.left, array.right)\n        except TypeError:\n            msg = f\"'value' should be an interval type, got {type(value)} instead.\"\n            raise TypeError(msg)\n    key = check_array_indexer(self, key)\n    left = self.left.copy(deep=True)\n    if needs_float_conversion:\n        left = left.astype('float')\n    left.values[key] = value_left\n    self._left = left\n    right = self.right.copy(deep=True)\n    if needs_float_conversion:\n        right = right.astype('float')\n    right.values[key] = value_right\n    self._right = right",
                            "def __eq__(self, other):\n    if is_list_like(other):\n        if len(self) != len(other):\n            raise ValueError('Lengths must match to compare')\n        other = array(other)\n    elif not isinstance(other, Interval):\n        return np.zeros(len(self), dtype=bool)\n    if isinstance(other, Interval):\n        other_dtype = 'interval'\n    elif not is_categorical_dtype(other):\n        other_dtype = other.dtype\n    else:\n        other_dtype = other.categories.dtype\n        if is_interval_dtype(other_dtype):\n            if self.closed != other.categories.closed:\n                return np.zeros(len(self), dtype=bool)\n            other = other.categories.take(other.codes)\n    if is_interval_dtype(other_dtype):\n        if self.closed != other.closed:\n            return np.zeros(len(self), dtype=bool)\n        return (self.left == other.left) & (self.right == other.right)\n    if not is_object_dtype(other_dtype):\n        return np.zeros(len(self), dtype=bool)\n    result = np.zeros(len(self), dtype=bool)\n    for i, obj in enumerate(other):\n        if isinstance(obj, Interval) and self.closed == obj.closed and (self.left[i] == obj.left) and (self.right[i] == obj.right):\n            result[i] = True\n    return result",
                            "def __ne__(self, other):\n    return ~self.__eq__(other)",
                            "def fillna(self, value=None, method=None, limit=None):\n    \"\"\"\n    Fill NA/NaN values using the specified method.\n\n    Parameters\n    ----------\n    value : scalar, dict, Series\n        If a scalar value is passed it is used to fill all missing values.\n        Alternatively, a Series or dict can be used to fill in different\n        values for each index. The value should not be a list. The\n        value(s) passed should be either Interval objects or NA/NaN.\n    method : {'backfill', 'bfill', 'pad', 'ffill', None}, default None\n        (Not implemented yet for IntervalArray)\n        Method to use for filling holes in reindexed Series\n    limit : int, default None\n        (Not implemented yet for IntervalArray)\n        If method is specified, this is the maximum number of consecutive\n        NaN values to forward/backward fill. In other words, if there is\n        a gap with more than this number of consecutive NaNs, it will only\n        be partially filled. If method is not specified, this is the\n        maximum number of entries along the entire axis where NaNs will be\n        filled.\n\n    Returns\n    -------\n    filled : IntervalArray with NA/NaN filled\n    \"\"\"\n    if method is not None:\n        raise TypeError('Filling by method is not supported for IntervalArray.')\n    if limit is not None:\n        raise TypeError('limit is not supported for IntervalArray.')\n    if not isinstance(value, ABCInterval):\n        msg = f\"'IntervalArray.fillna' only supports filling with a scalar 'pandas.Interval'. Got a '{type(value).__name__}' instead.\"\n        raise TypeError(msg)\n    value = getattr(value, '_values', value)\n    self._check_closed_matches(value, name='value')\n    left = self.left.fillna(value=value.left)\n    right = self.right.fillna(value=value.right)\n    return self._shallow_copy(left, right)",
                            "@property\ndef dtype(self):\n    return IntervalDtype(self.left.dtype)",
                            "def astype(self, dtype, copy=True):\n    \"\"\"\n    Cast to an ExtensionArray or NumPy array with dtype 'dtype'.\n\n    Parameters\n    ----------\n    dtype : str or dtype\n        Typecode or data-type to which the array is cast.\n\n    copy : bool, default True\n        Whether to copy the data, even if not necessary. If False,\n        a copy is made only if the old dtype does not match the\n        new dtype.\n\n    Returns\n    -------\n    array : ExtensionArray or ndarray\n        ExtensionArray or NumPy ndarray with 'dtype' for its dtype.\n    \"\"\"\n    dtype = pandas_dtype(dtype)\n    if is_interval_dtype(dtype):\n        if dtype == self.dtype:\n            return self.copy() if copy else self\n        try:\n            new_left = self.left.astype(dtype.subtype)\n            new_right = self.right.astype(dtype.subtype)\n        except TypeError:\n            msg = f'Cannot convert {self.dtype} to {dtype}; subtypes are incompatible'\n            raise TypeError(msg)\n        return self._shallow_copy(new_left, new_right)\n    elif is_categorical_dtype(dtype):\n        return Categorical(np.asarray(self))\n    try:\n        return np.asarray(self).astype(dtype, copy=copy)\n    except (TypeError, ValueError):\n        msg = f'Cannot cast {type(self).__name__} to dtype {dtype}'\n        raise TypeError(msg)",
                            "@classmethod\ndef _concat_same_type(cls, to_concat):\n    \"\"\"\n    Concatenate multiple IntervalArray\n\n    Parameters\n    ----------\n    to_concat : sequence of IntervalArray\n\n    Returns\n    -------\n    IntervalArray\n    \"\"\"\n    closed = {interval.closed for interval in to_concat}\n    if len(closed) != 1:\n        raise ValueError('Intervals must all be closed on the same side.')\n    closed = closed.pop()\n    left = np.concatenate([interval.left for interval in to_concat])\n    right = np.concatenate([interval.right for interval in to_concat])\n    return cls._simple_new(left, right, closed=closed, copy=False)",
                            "def _shallow_copy(self, left=None, right=None, closed=None):\n    \"\"\"\n    Return a new IntervalArray with the replacement attributes\n\n    Parameters\n    ----------\n    left : array-like\n        Values to be used for the left-side of the intervals.\n        If None, the existing left and right values will be used.\n\n    right : array-like\n        Values to be used for the right-side of the intervals.\n        If None and left is IntervalArray-like, the left and right\n        of the IntervalArray-like will be used.\n\n    closed : {'left', 'right', 'both', 'neither'}, optional\n        Whether the intervals are closed on the left-side, right-side, both\n        or neither.  If None, the existing closed will be used.\n    \"\"\"\n    if left is None:\n        left, right = (self.left, self.right)\n    elif right is None:\n        if not isinstance(left, (type(self), ABCIntervalIndex)):\n            left = type(self)(left)\n        left, right = (left.left, left.right)\n    else:\n        pass\n    closed = closed or self.closed\n    return self._simple_new(left, right, closed=closed, verify_integrity=False)",
                            "def copy(self):\n    \"\"\"\n    Return a copy of the array.\n\n    Returns\n    -------\n    IntervalArray\n    \"\"\"\n    left = self.left.copy(deep=True)\n    right = self.right.copy(deep=True)\n    closed = self.closed\n    return type(self).from_arrays(left, right, closed=closed)",
                            "def isna(self):\n    return isna(self.left)",
                            "@property\ndef nbytes(self) -> int:\n    return self.left.nbytes + self.right.nbytes",
                            "@property\ndef size(self) -> int:\n    return self.left.size",
                            "def take(self, indices, allow_fill=False, fill_value=None, axis=None, **kwargs):\n    \"\"\"\n    Take elements from the IntervalArray.\n\n    Parameters\n    ----------\n    indices : sequence of integers\n        Indices to be taken.\n\n    allow_fill : bool, default False\n        How to handle negative values in `indices`.\n\n        * False: negative values in `indices` indicate positional indices\n          from the right (the default). This is similar to\n          :func:`numpy.take`.\n\n        * True: negative values in `indices` indicate\n          missing values. These values are set to `fill_value`. Any other\n          other negative values raise a ``ValueError``.\n\n    fill_value : Interval or NA, optional\n        Fill value to use for NA-indices when `allow_fill` is True.\n        This may be ``None``, in which case the default NA value for\n        the type, ``self.dtype.na_value``, is used.\n\n        For many ExtensionArrays, there will be two representations of\n        `fill_value`: a user-facing \"boxed\" scalar, and a low-level\n        physical NA value. `fill_value` should be the user-facing version,\n        and the implementation should handle translating that to the\n        physical version for processing the take if necessary.\n\n    axis : any, default None\n        Present for compat with IntervalIndex; does nothing.\n\n    Returns\n    -------\n    IntervalArray\n\n    Raises\n    ------\n    IndexError\n        When the indices are out of bounds for the array.\n    ValueError\n        When `indices` contains negative values other than ``-1``\n        and `allow_fill` is True.\n    \"\"\"\n    nv.validate_take(tuple(), kwargs)\n    fill_left = fill_right = fill_value\n    if allow_fill:\n        if fill_value is None:\n            fill_left = fill_right = self.left._na_value\n        elif is_interval(fill_value):\n            self._check_closed_matches(fill_value, name='fill_value')\n            fill_left, fill_right = (fill_value.left, fill_value.right)\n        elif not is_scalar(fill_value) and notna(fill_value):\n            msg = f\"'IntervalArray.fillna' only supports filling with a 'scalar pandas.Interval or NA'. Got a '{type(fill_value).__name__}' instead.\"\n            raise ValueError(msg)\n    left_take = take(self.left, indices, allow_fill=allow_fill, fill_value=fill_left)\n    right_take = take(self.right, indices, allow_fill=allow_fill, fill_value=fill_right)\n    return self._shallow_copy(left_take, right_take)",
                            "def value_counts(self, dropna=True):\n    \"\"\"\n    Returns a Series containing counts of each interval.\n\n    Parameters\n    ----------\n    dropna : bool, default True\n        Don't include counts of NaN.\n\n    Returns\n    -------\n    counts : Series\n\n    See Also\n    --------\n    Series.value_counts\n    \"\"\"\n    return value_counts(np.asarray(self), dropna=dropna)",
                            "def _format_data(self):\n    n = len(self)\n    max_seq_items = min((get_option('display.max_seq_items') or n) // 10, 10)\n    formatter = str\n    if n == 0:\n        summary = '[]'\n    elif n == 1:\n        first = formatter(self[0])\n        summary = f'[{first}]'\n    elif n == 2:\n        first = formatter(self[0])\n        last = formatter(self[-1])\n        summary = f'[{first}, {last}]'\n    elif n > max_seq_items:\n        n = min(max_seq_items // 2, 10)\n        head = [formatter(x) for x in self[:n]]\n        tail = [formatter(x) for x in self[-n:]]\n        head_str = ', '.join(head)\n        tail_str = ', '.join(tail)\n        summary = f'[{head_str} ... {tail_str}]'\n    else:\n        tail = [formatter(x) for x in self]\n        tail_str = ', '.join(tail)\n        summary = f'[{tail_str}]'\n    return summary",
                            "def __repr__(self) -> str:\n    data = self._format_data()\n    class_name = f'<{type(self).__name__}>\\n'\n    template = f'{class_name}{data}\\nLength: {len(self)}, closed: {self.closed}, dtype: {self.dtype}'\n    return template",
                            "def _format_space(self):\n    space = ' ' * (len(type(self).__name__) + 1)\n    return f'\\n{space}'",
                            "@property\ndef left(self):\n    \"\"\"\n    Return the left endpoints of each Interval in the IntervalArray as\n    an Index.\n    \"\"\"\n    return self._left",
                            "@property\ndef right(self):\n    \"\"\"\n    Return the right endpoints of each Interval in the IntervalArray as\n    an Index.\n    \"\"\"\n    return self._right",
                            "@property\ndef closed(self):\n    \"\"\"\n    Whether the intervals are closed on the left-side, right-side, both or\n    neither.\n    \"\"\"\n    return self._closed",
                            "@Appender(_interval_shared_docs['set_closed'] % dict(klass='IntervalArray', examples=textwrap.dedent(\"        Examples\\n        --------\\n        >>> index = pd.arrays.IntervalArray.from_breaks(range(4))\\n        >>> index\\n        <IntervalArray>\\n        [(0, 1], (1, 2], (2, 3]]\\n        Length: 3, closed: right, dtype: interval[int64]\\n        >>> index.set_closed('both')\\n        <IntervalArray>\\n        [[0, 1], [1, 2], [2, 3]]\\n        Length: 3, closed: both, dtype: interval[int64]\\n        \")))\ndef set_closed(self, closed):\n    if closed not in _VALID_CLOSED:\n        msg = f\"invalid option for 'closed': {closed}\"\n        raise ValueError(msg)\n    return self._shallow_copy(closed=closed)",
                            "@property\ndef length(self):\n    \"\"\"\n    Return an Index with entries denoting the length of each Interval in\n    the IntervalArray.\n    \"\"\"\n    try:\n        return self.right - self.left\n    except TypeError:\n        msg = 'IntervalArray contains Intervals without defined length, e.g. Intervals with string endpoints'\n        raise TypeError(msg)",
                            "@property\ndef mid(self):\n    \"\"\"\n    Return the midpoint of each Interval in the IntervalArray as an Index.\n    \"\"\"\n    try:\n        return 0.5 * (self.left + self.right)\n    except TypeError:\n        return self.left + 0.5 * self.length",
                            "@property\n@Appender(_interval_shared_docs['is_non_overlapping_monotonic'] % _shared_docs_kwargs)\ndef is_non_overlapping_monotonic(self):\n    if self.closed == 'both':\n        return bool((self.right[:-1] < self.left[1:]).all() or (self.left[:-1] > self.right[1:]).all())\n    return bool((self.right[:-1] <= self.left[1:]).all() or (self.left[:-1] >= self.right[1:]).all())",
                            "def __array__(self, dtype=None) -> np.ndarray:\n    \"\"\"\n    Return the IntervalArray's data as a numpy array of Interval\n    objects (with dtype='object')\n    \"\"\"\n    left = self.left\n    right = self.right\n    mask = self.isna()\n    closed = self._closed\n    result = np.empty(len(left), dtype=object)\n    for i in range(len(left)):\n        if mask[i]:\n            result[i] = np.nan\n        else:\n            result[i] = Interval(left[i], right[i], closed)\n    return result",
                            "def __arrow_array__(self, type=None):\n    \"\"\"\n    Convert myself into a pyarrow Array.\n    \"\"\"\n    import pyarrow\n    from pandas.core.arrays._arrow_utils import ArrowIntervalType\n    try:\n        subtype = pyarrow.from_numpy_dtype(self.dtype.subtype)\n    except TypeError:\n        raise TypeError(\"Conversion to arrow with subtype '{}' is not supported\".format(self.dtype.subtype))\n    interval_type = ArrowIntervalType(subtype, self.closed)\n    storage_array = pyarrow.StructArray.from_arrays([pyarrow.array(self.left, type=subtype, from_pandas=True), pyarrow.array(self.right, type=subtype, from_pandas=True)], names=['left', 'right'])\n    mask = self.isna()\n    if mask.any():\n        null_bitmap = pyarrow.array(~mask).buffers()[1]\n        storage_array = pyarrow.StructArray.from_buffers(storage_array.type, len(storage_array), [null_bitmap], children=[storage_array.field(0), storage_array.field(1)])\n    if type is not None:\n        if type.equals(interval_type.storage_type):\n            return storage_array\n        elif isinstance(type, ArrowIntervalType):\n            if not type.equals(interval_type):\n                raise TypeError(\"Not supported to convert IntervalArray to type with different 'subtype' ({0} vs {1}) and 'closed' ({2} vs {3}) attributes\".format(self.dtype.subtype, type.subtype, self.closed, type.closed))\n        else:\n            raise TypeError(\"Not supported to convert IntervalArray to '{0}' type\".format(type))\n    return pyarrow.ExtensionArray.from_storage(interval_type, storage_array)",
                            "@Appender(_interval_shared_docs['to_tuples'] % dict(return_type='ndarray', examples=''))\ndef to_tuples(self, na_tuple=True):\n    tuples = com.asarray_tuplesafe(zip(self.left, self.right))\n    if not na_tuple:\n        tuples = np.where(~self.isna(), tuples, np.nan)\n    return tuples",
                            "@Appender(_extension_array_shared_docs['repeat'] % _shared_docs_kwargs)\ndef repeat(self, repeats, axis=None):\n    nv.validate_repeat(tuple(), dict(axis=axis))\n    left_repeat = self.left.repeat(repeats)\n    right_repeat = self.right.repeat(repeats)\n    return self._shallow_copy(left=left_repeat, right=right_repeat)",
                            "@Appender(_interval_shared_docs['contains'] % dict(klass='IntervalArray', examples=textwrap.dedent('        >>> intervals = pd.arrays.IntervalArray.from_tuples([(0, 1), (1, 3), (2, 4)])\\n        >>> intervals\\n        <IntervalArray>\\n        [(0, 1], (1, 3], (2, 4]]\\n        Length: 3, closed: right, dtype: interval[int64]\\n        ')))\ndef contains(self, other):\n    if isinstance(other, Interval):\n        raise NotImplementedError('contains not implemented for two intervals')\n    return (self.left < other if self.open_left else self.left <= other) & (other < self.right if self.open_right else other <= self.right)",
                            "@Appender(_interval_shared_docs['overlaps'] % dict(klass='IntervalArray', examples=textwrap.dedent('        >>> data = [(0, 1), (1, 3), (2, 4)]\\n        >>> intervals = pd.arrays.IntervalArray.from_tuples(data)\\n        >>> intervals\\n        <IntervalArray>\\n        [(0, 1], (1, 3], (2, 4]]\\n        Length: 3, closed: right, dtype: interval[int64]\\n        ')))\ndef overlaps(self, other):\n    if isinstance(other, (IntervalArray, ABCIntervalIndex)):\n        raise NotImplementedError\n    elif not isinstance(other, Interval):\n        msg = f'`other` must be Interval-like, got {type(other).__name__}'\n        raise TypeError(msg)\n    op1 = le if self.closed_left and other.closed_right else lt\n    op2 = le if other.closed_left and self.closed_right else lt\n    return op1(self.left, other.right) & op2(other.left, self.right)"
                        ],
                        "constructor_variables": [],
                        "class_level_variables": [
                            "ndim",
                            "can_hold_na",
                            "_na_value",
                            "_fill_value"
                        ],
                        "class_decorators": [
                            "Appender(_interval_shared_docs['class'] % dict(klass='IntervalArray', summary='Pandas array for interval data that are closed on the same side.', versionadded='0.24.0', name='', extra_attributes='', extra_methods='', examples=textwrap.dedent('    Examples\\n    --------\\n    A new ``IntervalArray`` can be constructed directly from an array-like of\\n    ``Interval`` objects:\\n\\n    >>> pd.arrays.IntervalArray([pd.Interval(0, 1), pd.Interval(1, 5)])\\n    <IntervalArray>\\n    [(0, 1], (1, 5]]\\n    Length: 2, closed: right, dtype: interval[int64]\\n\\n    It may also be constructed using one of the constructor\\n    methods: :meth:`IntervalArray.from_arrays`,\\n    :meth:`IntervalArray.from_breaks`, and :meth:`IntervalArray.from_tuples`.\\n    ')))"
                        ],
                        "function_signatures": [
                            "__new__(cls, data, closed=None, dtype=None, copy=False, verify_integrity=True)",
                            "_simple_new(cls, left, right, closed=None, copy=False, dtype=None, verify_integrity=True)",
                            "_from_sequence(cls, scalars, dtype=None, copy=False)",
                            "_from_factorized(cls, values, original)",
                            "from_breaks(cls, breaks, closed='right', copy=False, dtype=None)",
                            "from_arrays(cls, left, right, closed='right', copy=False, dtype=None)",
                            "from_tuples(cls, data, closed='right', copy=False, dtype=None)",
                            "_validate(self)",
                            "__iter__(self)",
                            "__len__(self) -> int",
                            "__getitem__(self, value)",
                            "__setitem__(self, key, value)",
                            "__eq__(self, other)",
                            "__ne__(self, other)",
                            "fillna(self, value=None, method=None, limit=None)",
                            "dtype(self)",
                            "astype(self, dtype, copy=True)",
                            "_concat_same_type(cls, to_concat)",
                            "_shallow_copy(self, left=None, right=None, closed=None)",
                            "copy(self)",
                            "isna(self)",
                            "nbytes(self) -> int",
                            "size(self) -> int",
                            "take(self, indices, allow_fill=False, fill_value=None, axis=None, **kwargs)",
                            "value_counts(self, dropna=True)",
                            "_format_data(self)",
                            "__repr__(self) -> str",
                            "_format_space(self)",
                            "left(self)",
                            "right(self)",
                            "closed(self)",
                            "set_closed(self, closed)",
                            "length(self)",
                            "mid(self)",
                            "is_non_overlapping_monotonic(self)",
                            "__array__(self, dtype=None) -> np.ndarray",
                            "__arrow_array__(self, type=None)",
                            "to_tuples(self, na_tuple=True)",
                            "repeat(self, repeats, axis=None)",
                            "contains(self, other)",
                            "overlaps(self, other)"
                        ]
                    },
                    "variable_values": [
                        [
                            {},
                            {}
                        ]
                    ]
                }
            ],
            "snippets": [
                {
                    "snippet_code": "from pandas.core.dtypes.generic import (\n    ABCDatetimeIndex,\n    ABCIndexClass,\n    ABCInterval,\n    ABCIntervalIndex,\n    ABCPeriodIndex,\n    ABCSeries,\n)",
                    "start_line": 28,
                    "end_line": 35
                }
            ],
            "inscope_functions": [
                "def maybe_convert_platform_interval(values):\n    \"\"\"\n    Try to do platform conversion, with special casing for IntervalArray.\n    Wrapper around maybe_convert_platform that alters the default return\n    dtype in certain cases to be compatible with IntervalArray.  For example,\n    empty lists return with integer dtype instead of object dtype, which is\n    prohibited for IntervalArray.\n\n    Parameters\n    ----------\n    values : array-like\n\n    Returns\n    -------\n    array\n    \"\"\"\n    if isinstance(values, (list, tuple)) and len(values) == 0:\n        # GH 19016\n        # empty lists/tuples get object dtype by default, but this is\n        # prohibited for IntervalArray, so coerce to integer instead\n        return np.array([], dtype=np.int64)\n    elif is_categorical_dtype(values):\n        values = np.asarray(values)\n\n    return maybe_convert_platform(values)",
                "def __new__(cls, data, closed=None, dtype=None, copy=False, verify_integrity=True):\n\n    if isinstance(data, ABCSeries) and is_interval_dtype(data):\n        data = data.values\n\n    if isinstance(data, (cls, ABCIntervalIndex)):\n        left = data.left\n        right = data.right\n        closed = closed or data.closed\n    else:\n\n        # don't allow scalars\n        if is_scalar(data):\n            msg = (\n                f\"{cls.__name__}(...) must be called with a collection \"\n                f\"of some kind, {data} was passed\"\n            )\n            raise TypeError(msg)\n\n        # might need to convert empty or purely na data\n        data = maybe_convert_platform_interval(data)\n        left, right, infer_closed = intervals_to_interval_bounds(\n            data, validate_closed=closed is None\n        )\n        closed = closed or infer_closed\n\n    return cls._simple_new(\n        left,\n        right,\n        closed,\n        copy=copy,\n        dtype=dtype,\n        verify_integrity=verify_integrity,\n    )",
                "@classmethod\ndef _simple_new(\n    cls, left, right, closed=None, copy=False, dtype=None, verify_integrity=True\n):\n    result = IntervalMixin.__new__(cls)\n\n    closed = closed or \"right\"\n    left = ensure_index(left, copy=copy)\n    right = ensure_index(right, copy=copy)\n\n    if dtype is not None:\n        # GH 19262: dtype must be an IntervalDtype to override inferred\n        dtype = pandas_dtype(dtype)\n        if not is_interval_dtype(dtype):\n            msg = f\"dtype must be an IntervalDtype, got {dtype}\"\n            raise TypeError(msg)\n        elif dtype.subtype is not None:\n            left = left.astype(dtype.subtype)\n            right = right.astype(dtype.subtype)\n\n    # coerce dtypes to match if needed\n    if is_float_dtype(left) and is_integer_dtype(right):\n        right = right.astype(left.dtype)\n    elif is_float_dtype(right) and is_integer_dtype(left):\n        left = left.astype(right.dtype)\n\n    if type(left) != type(right):\n        msg = (\n            f\"must not have differing left [{type(left).__name__}] and \"\n            f\"right [{type(right).__name__}] types\"\n        )\n        raise ValueError(msg)\n    elif is_categorical_dtype(left.dtype) or is_string_dtype(left.dtype):\n        # GH 19016\n        msg = (\n            \"category, object, and string subtypes are not supported \"\n            \"for IntervalArray\"\n        )\n        raise TypeError(msg)\n    elif isinstance(left, ABCPeriodIndex):\n        msg = \"Period dtypes are not supported, use a PeriodIndex instead\"\n        raise ValueError(msg)\n    elif isinstance(left, ABCDatetimeIndex) and str(left.tz) != str(right.tz):\n        msg = (\n            \"left and right must have the same time zone, got \"\n            f\"'{left.tz}' and '{right.tz}'\"\n        )\n        raise ValueError(msg)\n\n    result._left = left\n    result._right = right\n    result._closed = closed\n    if verify_integrity:\n        result._validate()\n    return result",
                "@classmethod\ndef _from_sequence(cls, scalars, dtype=None, copy=False):\n    return cls(scalars, dtype=dtype, copy=copy)",
                "@classmethod\ndef _from_factorized(cls, values, original):\n    if len(values) == 0:\n        # An empty array returns object-dtype here. We can't create\n        # a new IA from an (empty) object-dtype array, so turn it into the\n        # correct dtype.\n        values = values.astype(original.dtype.subtype)\n    return cls(values, closed=original.closed)",
                "@classmethod\n@Appender(\n    _interval_shared_docs[\"from_breaks\"]\n    % dict(\n        klass=\"IntervalArray\",\n        examples=textwrap.dedent(\n            \"\"\"\\\n    Examples\n    --------\n    >>> pd.arrays.IntervalArray.from_breaks([0, 1, 2, 3])\n    <IntervalArray>\n    [(0, 1], (1, 2], (2, 3]]\n    Length: 3, closed: right, dtype: interval[int64]\n    \"\"\"\n        ),\n    )\n)\ndef from_breaks(cls, breaks, closed=\"right\", copy=False, dtype=None):\n    breaks = maybe_convert_platform_interval(breaks)\n\n    return cls.from_arrays(breaks[:-1], breaks[1:], closed, copy=copy, dtype=dtype)",
                "@classmethod\n@Appender(\n    _interval_shared_docs[\"from_arrays\"]\n    % dict(\n        klass=\"IntervalArray\",\n        examples=textwrap.dedent(\n            \"\"\"\\\n    >>> pd.arrays.IntervalArray.from_arrays([0, 1, 2], [1, 2, 3])\n    <IntervalArray>\n    [(0, 1], (1, 2], (2, 3]]\n    Length: 3, closed: right, dtype: interval[int64]\n    \"\"\"\n        ),\n    )\n)\ndef from_arrays(cls, left, right, closed=\"right\", copy=False, dtype=None):\n    left = maybe_convert_platform_interval(left)\n    right = maybe_convert_platform_interval(right)\n\n    return cls._simple_new(\n        left, right, closed, copy=copy, dtype=dtype, verify_integrity=True\n    )",
                "@classmethod\n@Appender(\n    _interval_shared_docs[\"from_tuples\"]\n    % dict(\n        klass=\"IntervalArray\",\n        examples=textwrap.dedent(\n            \"\"\"\\\n    Examples\n    --------\n    >>> pd.arrays.IntervalArray.from_tuples([(0, 1), (1, 2)])\n    <IntervalArray>\n    [(0, 1], (1, 2]]\n    Length: 2, closed: right, dtype: interval[int64]\n    \"\"\"\n        ),\n    )\n)\ndef from_tuples(cls, data, closed=\"right\", copy=False, dtype=None):\n    if len(data):\n        left, right = [], []\n    else:\n        # ensure that empty data keeps input dtype\n        left = right = data\n\n    for d in data:\n        if isna(d):\n            lhs = rhs = np.nan\n        else:\n            name = cls.__name__\n            try:\n                # need list of length 2 tuples, e.g. [(0, 1), (1, 2), ...]\n                lhs, rhs = d\n            except ValueError:\n                msg = f\"{name}.from_tuples requires tuples of length 2, got {d}\"\n                raise ValueError(msg)\n            except TypeError:\n                msg = f\"{name}.from_tuples received an invalid item, {d}\"\n                raise TypeError(msg)\n        left.append(lhs)\n        right.append(rhs)\n\n    return cls.from_arrays(left, right, closed, copy=False, dtype=dtype)",
                "def _validate(self):\n    \"\"\"Verify that the IntervalArray is valid.\n\n    Checks that\n\n    * closed is valid\n    * left and right match lengths\n    * left and right have the same missing values\n    * left is always below right\n    \"\"\"\n    if self.closed not in _VALID_CLOSED:\n        msg = f\"invalid option for 'closed': {self.closed}\"\n        raise ValueError(msg)\n    if len(self.left) != len(self.right):\n        msg = \"left and right must have the same length\"\n        raise ValueError(msg)\n    left_mask = notna(self.left)\n    right_mask = notna(self.right)\n    if not (left_mask == right_mask).all():\n        msg = (\n            \"missing values must be missing in the same \"\n            \"location both left and right sides\"\n        )\n        raise ValueError(msg)\n    if not (self.left[left_mask] <= self.right[left_mask]).all():\n        msg = \"left side of interval must be <= right side\"\n        raise ValueError(msg)",
                "def __iter__(self):\n    return iter(np.asarray(self))",
                "def __len__(self) -> int:\n    return len(self.left)",
                "def __getitem__(self, value):\n    value = check_array_indexer(self, value)\n    left = self.left[value]\n    right = self.right[value]\n\n    # scalar\n    if not isinstance(left, ABCIndexClass):\n        if is_scalar(left) and isna(left):\n            return self._fill_value\n        if np.ndim(left) > 1:\n            # GH#30588 multi-dimensional indexer disallowed\n            raise ValueError(\"multi-dimensional indexing not allowed\")\n        return Interval(left, right, self.closed)\n\n    return self._shallow_copy(left, right)",
                "def __setitem__(self, key, value):\n    # na value: need special casing to set directly on numpy arrays\n    needs_float_conversion = False\n    if is_scalar(value) and isna(value):\n        if is_integer_dtype(self.dtype.subtype):\n            # can't set NaN on a numpy integer array\n            needs_float_conversion = True\n        elif is_datetime64_any_dtype(self.dtype.subtype):\n            # need proper NaT to set directly on the numpy array\n            value = np.datetime64(\"NaT\")\n        elif is_timedelta64_dtype(self.dtype.subtype):\n            # need proper NaT to set directly on the numpy array\n            value = np.timedelta64(\"NaT\")\n        value_left, value_right = value, value\n\n    # scalar interval\n    elif is_interval_dtype(value) or isinstance(value, ABCInterval):\n        self._check_closed_matches(value, name=\"value\")\n        value_left, value_right = value.left, value.right\n\n    else:\n        # list-like of intervals\n        try:\n            array = IntervalArray(value)\n            value_left, value_right = array.left, array.right\n        except TypeError:\n            # wrong type: not interval or NA\n            msg = f\"'value' should be an interval type, got {type(value)} instead.\"\n            raise TypeError(msg)\n\n    key = check_array_indexer(self, key)\n    # Need to ensure that left and right are updated atomically, so we're\n    # forced to copy, update the copy, and swap in the new values.\n    left = self.left.copy(deep=True)\n    if needs_float_conversion:\n        left = left.astype(\"float\")\n    left.values[key] = value_left\n    self._left = left\n\n    right = self.right.copy(deep=True)\n    if needs_float_conversion:\n        right = right.astype(\"float\")\n    right.values[key] = value_right\n    self._right = right",
                "def __eq__(self, other):\n    # ensure pandas array for list-like and eliminate non-interval scalars\n    if is_list_like(other):\n        if len(self) != len(other):\n            raise ValueError(\"Lengths must match to compare\")\n        other = array(other)\n    elif not isinstance(other, Interval):\n        # non-interval scalar -> no matches\n        return np.zeros(len(self), dtype=bool)\n\n    # determine the dtype of the elements we want to compare\n    if isinstance(other, Interval):\n        other_dtype = \"interval\"\n    elif not is_categorical_dtype(other):\n        other_dtype = other.dtype\n    else:\n        # for categorical defer to categories for dtype\n        other_dtype = other.categories.dtype\n\n        # extract intervals if we have interval categories with matching closed\n        if is_interval_dtype(other_dtype):\n            if self.closed != other.categories.closed:\n                return np.zeros(len(self), dtype=bool)\n            other = other.categories.take(other.codes)\n\n    # interval-like -> need same closed and matching endpoints\n    if is_interval_dtype(other_dtype):\n        if self.closed != other.closed:\n            return np.zeros(len(self), dtype=bool)\n        return (self.left == other.left) & (self.right == other.right)\n\n    # non-interval/non-object dtype -> no matches\n    if not is_object_dtype(other_dtype):\n        return np.zeros(len(self), dtype=bool)\n\n    # object dtype -> iteratively check for intervals\n    result = np.zeros(len(self), dtype=bool)\n    for i, obj in enumerate(other):\n        # need object to be an Interval with same closed and endpoints\n        if (\n            isinstance(obj, Interval)\n            and self.closed == obj.closed\n            and self.left[i] == obj.left\n            and self.right[i] == obj.right\n        ):\n            result[i] = True\n\n    return result",
                "def __ne__(self, other):\n    return ~self.__eq__(other)",
                "def fillna(self, value=None, method=None, limit=None):\n    \"\"\"\n    Fill NA/NaN values using the specified method.\n\n    Parameters\n    ----------\n    value : scalar, dict, Series\n        If a scalar value is passed it is used to fill all missing values.\n        Alternatively, a Series or dict can be used to fill in different\n        values for each index. The value should not be a list. The\n        value(s) passed should be either Interval objects or NA/NaN.\n    method : {'backfill', 'bfill', 'pad', 'ffill', None}, default None\n        (Not implemented yet for IntervalArray)\n        Method to use for filling holes in reindexed Series\n    limit : int, default None\n        (Not implemented yet for IntervalArray)\n        If method is specified, this is the maximum number of consecutive\n        NaN values to forward/backward fill. In other words, if there is\n        a gap with more than this number of consecutive NaNs, it will only\n        be partially filled. If method is not specified, this is the\n        maximum number of entries along the entire axis where NaNs will be\n        filled.\n\n    Returns\n    -------\n    filled : IntervalArray with NA/NaN filled\n    \"\"\"\n    if method is not None:\n        raise TypeError(\"Filling by method is not supported for IntervalArray.\")\n    if limit is not None:\n        raise TypeError(\"limit is not supported for IntervalArray.\")\n\n    if not isinstance(value, ABCInterval):\n        msg = (\n            \"'IntervalArray.fillna' only supports filling with a \"\n            f\"scalar 'pandas.Interval'. Got a '{type(value).__name__}' instead.\"\n        )\n        raise TypeError(msg)\n\n    value = getattr(value, \"_values\", value)\n    self._check_closed_matches(value, name=\"value\")\n\n    left = self.left.fillna(value=value.left)\n    right = self.right.fillna(value=value.right)\n    return self._shallow_copy(left, right)",
                "@property\ndef dtype(self):\n    return IntervalDtype(self.left.dtype)",
                "def astype(self, dtype, copy=True):\n    \"\"\"\n    Cast to an ExtensionArray or NumPy array with dtype 'dtype'.\n\n    Parameters\n    ----------\n    dtype : str or dtype\n        Typecode or data-type to which the array is cast.\n\n    copy : bool, default True\n        Whether to copy the data, even if not necessary. If False,\n        a copy is made only if the old dtype does not match the\n        new dtype.\n\n    Returns\n    -------\n    array : ExtensionArray or ndarray\n        ExtensionArray or NumPy ndarray with 'dtype' for its dtype.\n    \"\"\"\n    dtype = pandas_dtype(dtype)\n    if is_interval_dtype(dtype):\n        if dtype == self.dtype:\n            return self.copy() if copy else self\n\n        # need to cast to different subtype\n        try:\n            new_left = self.left.astype(dtype.subtype)\n            new_right = self.right.astype(dtype.subtype)\n        except TypeError:\n            msg = (\n                f\"Cannot convert {self.dtype} to {dtype}; subtypes are incompatible\"\n            )\n            raise TypeError(msg)\n        return self._shallow_copy(new_left, new_right)\n    elif is_categorical_dtype(dtype):\n        return Categorical(np.asarray(self))\n    # TODO: This try/except will be repeated.\n    try:\n        return np.asarray(self).astype(dtype, copy=copy)\n    except (TypeError, ValueError):\n        msg = f\"Cannot cast {type(self).__name__} to dtype {dtype}\"\n        raise TypeError(msg)",
                "@classmethod\ndef _concat_same_type(cls, to_concat):\n    \"\"\"\n    Concatenate multiple IntervalArray\n\n    Parameters\n    ----------\n    to_concat : sequence of IntervalArray\n\n    Returns\n    -------\n    IntervalArray\n    \"\"\"\n    closed = {interval.closed for interval in to_concat}\n    if len(closed) != 1:\n        raise ValueError(\"Intervals must all be closed on the same side.\")\n    closed = closed.pop()\n\n    left = np.concatenate([interval.left for interval in to_concat])\n    right = np.concatenate([interval.right for interval in to_concat])\n    return cls._simple_new(left, right, closed=closed, copy=False)",
                "def _shallow_copy(self, left=None, right=None, closed=None):\n    \"\"\"\n    Return a new IntervalArray with the replacement attributes\n\n    Parameters\n    ----------\n    left : array-like\n        Values to be used for the left-side of the intervals.\n        If None, the existing left and right values will be used.\n\n    right : array-like\n        Values to be used for the right-side of the intervals.\n        If None and left is IntervalArray-like, the left and right\n        of the IntervalArray-like will be used.\n\n    closed : {'left', 'right', 'both', 'neither'}, optional\n        Whether the intervals are closed on the left-side, right-side, both\n        or neither.  If None, the existing closed will be used.\n    \"\"\"\n    if left is None:\n\n        # no values passed\n        left, right = self.left, self.right\n\n    elif right is None:\n\n        # only single value passed, could be an IntervalArray\n        # or array of Intervals\n        if not isinstance(left, (type(self), ABCIntervalIndex)):\n            left = type(self)(left)\n\n        left, right = left.left, left.right\n    else:\n\n        # both left and right are values\n        pass\n\n    closed = closed or self.closed\n    return self._simple_new(left, right, closed=closed, verify_integrity=False)",
                "def copy(self):\n    \"\"\"\n    Return a copy of the array.\n\n    Returns\n    -------\n    IntervalArray\n    \"\"\"\n    left = self.left.copy(deep=True)\n    right = self.right.copy(deep=True)\n    closed = self.closed\n    # TODO: Could skip verify_integrity here.\n    return type(self).from_arrays(left, right, closed=closed)",
                "def isna(self):\n    return isna(self.left)",
                "@property\ndef nbytes(self) -> int:\n    return self.left.nbytes + self.right.nbytes",
                "@property\ndef size(self) -> int:\n    # Avoid materializing self.values\n    return self.left.size",
                "def take(self, indices, allow_fill=False, fill_value=None, axis=None, **kwargs):\n    \"\"\"\n    Take elements from the IntervalArray.\n\n    Parameters\n    ----------\n    indices : sequence of integers\n        Indices to be taken.\n\n    allow_fill : bool, default False\n        How to handle negative values in `indices`.\n\n        * False: negative values in `indices` indicate positional indices\n          from the right (the default). This is similar to\n          :func:`numpy.take`.\n\n        * True: negative values in `indices` indicate\n          missing values. These values are set to `fill_value`. Any other\n          other negative values raise a ``ValueError``.\n\n    fill_value : Interval or NA, optional\n        Fill value to use for NA-indices when `allow_fill` is True.\n        This may be ``None``, in which case the default NA value for\n        the type, ``self.dtype.na_value``, is used.\n\n        For many ExtensionArrays, there will be two representations of\n        `fill_value`: a user-facing \"boxed\" scalar, and a low-level\n        physical NA value. `fill_value` should be the user-facing version,\n        and the implementation should handle translating that to the\n        physical version for processing the take if necessary.\n\n    axis : any, default None\n        Present for compat with IntervalIndex; does nothing.\n\n    Returns\n    -------\n    IntervalArray\n\n    Raises\n    ------\n    IndexError\n        When the indices are out of bounds for the array.\n    ValueError\n        When `indices` contains negative values other than ``-1``\n        and `allow_fill` is True.\n    \"\"\"\n    nv.validate_take(tuple(), kwargs)\n\n    fill_left = fill_right = fill_value\n    if allow_fill:\n        if fill_value is None:\n            fill_left = fill_right = self.left._na_value\n        elif is_interval(fill_value):\n            self._check_closed_matches(fill_value, name=\"fill_value\")\n            fill_left, fill_right = fill_value.left, fill_value.right\n        elif not is_scalar(fill_value) and notna(fill_value):\n            msg = (\n                \"'IntervalArray.fillna' only supports filling with a \"\n                \"'scalar pandas.Interval or NA'. \"\n                f\"Got a '{type(fill_value).__name__}' instead.\"\n            )\n            raise ValueError(msg)\n\n    left_take = take(\n        self.left, indices, allow_fill=allow_fill, fill_value=fill_left\n    )\n    right_take = take(\n        self.right, indices, allow_fill=allow_fill, fill_value=fill_right\n    )\n\n    return self._shallow_copy(left_take, right_take)",
                "def value_counts(self, dropna=True):\n    \"\"\"\n    Returns a Series containing counts of each interval.\n\n    Parameters\n    ----------\n    dropna : bool, default True\n        Don't include counts of NaN.\n\n    Returns\n    -------\n    counts : Series\n\n    See Also\n    --------\n    Series.value_counts\n    \"\"\"\n    # TODO: implement this is a non-naive way!\n    return value_counts(np.asarray(self), dropna=dropna)",
                "def _format_data(self):\n\n    # TODO: integrate with categorical and make generic\n    # name argument is unused here; just for compat with base / categorical\n    n = len(self)\n    max_seq_items = min((get_option(\"display.max_seq_items\") or n) // 10, 10)\n\n    formatter = str\n\n    if n == 0:\n        summary = \"[]\"\n    elif n == 1:\n        first = formatter(self[0])\n        summary = f\"[{first}]\"\n    elif n == 2:\n        first = formatter(self[0])\n        last = formatter(self[-1])\n        summary = f\"[{first}, {last}]\"\n    else:\n\n        if n > max_seq_items:\n            n = min(max_seq_items // 2, 10)\n            head = [formatter(x) for x in self[:n]]\n            tail = [formatter(x) for x in self[-n:]]\n            head_str = \", \".join(head)\n            tail_str = \", \".join(tail)\n            summary = f\"[{head_str} ... {tail_str}]\"\n        else:\n            tail = [formatter(x) for x in self]\n            tail_str = \", \".join(tail)\n            summary = f\"[{tail_str}]\"\n\n    return summary",
                "def __repr__(self) -> str:\n    # the short repr has no trailing newline, while the truncated\n    # repr does. So we include a newline in our template, and strip\n    # any trailing newlines from format_object_summary\n    data = self._format_data()\n    class_name = f\"<{type(self).__name__}>\\n\"\n\n    template = (\n        f\"{class_name}\"\n        f\"{data}\\n\"\n        f\"Length: {len(self)}, closed: {self.closed}, dtype: {self.dtype}\"\n    )\n    return template",
                "def _format_space(self):\n    space = \" \" * (len(type(self).__name__) + 1)\n    return f\"\\n{space}\"",
                "@property\ndef left(self):\n    \"\"\"\n    Return the left endpoints of each Interval in the IntervalArray as\n    an Index.\n    \"\"\"\n    return self._left",
                "@property\ndef right(self):\n    \"\"\"\n    Return the right endpoints of each Interval in the IntervalArray as\n    an Index.\n    \"\"\"\n    return self._right",
                "@property\ndef closed(self):\n    \"\"\"\n    Whether the intervals are closed on the left-side, right-side, both or\n    neither.\n    \"\"\"\n    return self._closed",
                "@Appender(\n    _interval_shared_docs[\"set_closed\"]\n    % dict(\n        klass=\"IntervalArray\",\n        examples=textwrap.dedent(\n            \"\"\"\\\n    Examples\n    --------\n    >>> index = pd.arrays.IntervalArray.from_breaks(range(4))\n    >>> index\n    <IntervalArray>\n    [(0, 1], (1, 2], (2, 3]]\n    Length: 3, closed: right, dtype: interval[int64]\n    >>> index.set_closed('both')\n    <IntervalArray>\n    [[0, 1], [1, 2], [2, 3]]\n    Length: 3, closed: both, dtype: interval[int64]\n    \"\"\"\n        ),\n    )\n)\ndef set_closed(self, closed):\n    if closed not in _VALID_CLOSED:\n        msg = f\"invalid option for 'closed': {closed}\"\n        raise ValueError(msg)\n\n    return self._shallow_copy(closed=closed)",
                "@property\ndef length(self):\n    \"\"\"\n    Return an Index with entries denoting the length of each Interval in\n    the IntervalArray.\n    \"\"\"\n    try:\n        return self.right - self.left\n    except TypeError:\n        # length not defined for some types, e.g. string\n        msg = (\n            \"IntervalArray contains Intervals without defined length, \"\n            \"e.g. Intervals with string endpoints\"\n        )\n        raise TypeError(msg)",
                "@property\ndef mid(self):\n    \"\"\"\n    Return the midpoint of each Interval in the IntervalArray as an Index.\n    \"\"\"\n    try:\n        return 0.5 * (self.left + self.right)\n    except TypeError:\n        # datetime safe version\n        return self.left + 0.5 * self.length",
                "@property  # type: ignore\n@Appender(\n    _interval_shared_docs[\"is_non_overlapping_monotonic\"] % _shared_docs_kwargs\n)\ndef is_non_overlapping_monotonic(self):\n    # must be increasing  (e.g., [0, 1), [1, 2), [2, 3), ... )\n    # or decreasing (e.g., [-1, 0), [-2, -1), [-3, -2), ...)\n    # we already require left <= right\n\n    # strict inequality for closed == 'both'; equality implies overlapping\n    # at a point when both sides of intervals are included\n    if self.closed == \"both\":\n        return bool(\n            (self.right[:-1] < self.left[1:]).all()\n            or (self.left[:-1] > self.right[1:]).all()\n        )\n\n    # non-strict inequality when closed != 'both'; at least one side is\n    # not included in the intervals, so equality does not imply overlapping\n    return bool(\n        (self.right[:-1] <= self.left[1:]).all()\n        or (self.left[:-1] >= self.right[1:]).all()\n    )",
                "def __array__(self, dtype=None) -> np.ndarray:\n    \"\"\"\n    Return the IntervalArray's data as a numpy array of Interval\n    objects (with dtype='object')\n    \"\"\"\n    left = self.left\n    right = self.right\n    mask = self.isna()\n    closed = self._closed\n\n    result = np.empty(len(left), dtype=object)\n    for i in range(len(left)):\n        if mask[i]:\n            result[i] = np.nan\n        else:\n            result[i] = Interval(left[i], right[i], closed)\n    return result",
                "def __arrow_array__(self, type=None):\n    \"\"\"\n    Convert myself into a pyarrow Array.\n    \"\"\"\n    import pyarrow\n    from pandas.core.arrays._arrow_utils import ArrowIntervalType\n\n    try:\n        subtype = pyarrow.from_numpy_dtype(self.dtype.subtype)\n    except TypeError:\n        raise TypeError(\n            \"Conversion to arrow with subtype '{}' \"\n            \"is not supported\".format(self.dtype.subtype)\n        )\n    interval_type = ArrowIntervalType(subtype, self.closed)\n    storage_array = pyarrow.StructArray.from_arrays(\n        [\n            pyarrow.array(self.left, type=subtype, from_pandas=True),\n            pyarrow.array(self.right, type=subtype, from_pandas=True),\n        ],\n        names=[\"left\", \"right\"],\n    )\n    mask = self.isna()\n    if mask.any():\n        # if there are missing values, set validity bitmap also on the array level\n        null_bitmap = pyarrow.array(~mask).buffers()[1]\n        storage_array = pyarrow.StructArray.from_buffers(\n            storage_array.type,\n            len(storage_array),\n            [null_bitmap],\n            children=[storage_array.field(0), storage_array.field(1)],\n        )\n\n    if type is not None:\n        if type.equals(interval_type.storage_type):\n            return storage_array\n        elif isinstance(type, ArrowIntervalType):\n            # ensure we have the same subtype and closed attributes\n            if not type.equals(interval_type):\n                raise TypeError(\n                    \"Not supported to convert IntervalArray to type with \"\n                    \"different 'subtype' ({0} vs {1}) and 'closed' ({2} vs {3}) \"\n                    \"attributes\".format(\n                        self.dtype.subtype, type.subtype, self.closed, type.closed\n                    )\n                )\n        else:\n            raise TypeError(\n                \"Not supported to convert IntervalArray to '{0}' type\".format(type)\n            )\n\n    return pyarrow.ExtensionArray.from_storage(interval_type, storage_array)",
                "@Appender(\n    _interval_shared_docs[\"to_tuples\"] % dict(return_type=\"ndarray\", examples=\"\")\n)\ndef to_tuples(self, na_tuple=True):\n    tuples = com.asarray_tuplesafe(zip(self.left, self.right))\n    if not na_tuple:\n        # GH 18756\n        tuples = np.where(~self.isna(), tuples, np.nan)\n    return tuples",
                "@Appender(_extension_array_shared_docs[\"repeat\"] % _shared_docs_kwargs)\ndef repeat(self, repeats, axis=None):\n    nv.validate_repeat(tuple(), dict(axis=axis))\n    left_repeat = self.left.repeat(repeats)\n    right_repeat = self.right.repeat(repeats)\n    return self._shallow_copy(left=left_repeat, right=right_repeat)",
                "@Appender(\n    _interval_shared_docs[\"contains\"]\n    % dict(\n        klass=\"IntervalArray\",\n        examples=textwrap.dedent(\n            \"\"\"\\\n    >>> intervals = pd.arrays.IntervalArray.from_tuples([(0, 1), (1, 3), (2, 4)])\n    >>> intervals\n    <IntervalArray>\n    [(0, 1], (1, 3], (2, 4]]\n    Length: 3, closed: right, dtype: interval[int64]\n    \"\"\"\n        ),\n    )\n)\ndef contains(self, other):\n    if isinstance(other, Interval):\n        raise NotImplementedError(\"contains not implemented for two intervals\")\n\n    return (self.left < other if self.open_left else self.left <= other) & (\n        other < self.right if self.open_right else other <= self.right\n    )",
                "@Appender(\n    _interval_shared_docs[\"overlaps\"]\n    % dict(\n        klass=\"IntervalArray\",\n        examples=textwrap.dedent(\n            \"\"\"\\\n    >>> data = [(0, 1), (1, 3), (2, 4)]\n    >>> intervals = pd.arrays.IntervalArray.from_tuples(data)\n    >>> intervals\n    <IntervalArray>\n    [(0, 1], (1, 3], (2, 4]]\n    Length: 3, closed: right, dtype: interval[int64]\n    \"\"\"\n        ),\n    )\n)\ndef overlaps(self, other):\n    if isinstance(other, (IntervalArray, ABCIntervalIndex)):\n        raise NotImplementedError\n    elif not isinstance(other, Interval):\n        msg = f\"`other` must be Interval-like, got {type(other).__name__}\"\n        raise TypeError(msg)\n\n    # equality is okay if both endpoints are closed (overlap at a point)\n    op1 = le if (self.closed_left and other.closed_right) else lt\n    op2 = le if (other.closed_left and self.closed_right) else lt\n\n    # overlaps is equivalent negation of two interval being disjoint:\n    # disjoint = (A.left > B.right) or (B.left > A.right)\n    # (simplifying the negation allows this to be done in less operations)\n    return op1(self.left, other.right) & op2(other.left, self.right)"
            ],
            "inscope_function_signatures": [
                "maybe_convert_platform_interval(values)",
                "__new__(cls, data, closed=None, dtype=None, copy=False, verify_integrity=True)",
                "_simple_new(cls, left, right, closed=None, copy=False, dtype=None, verify_integrity=True)",
                "_from_sequence(cls, scalars, dtype=None, copy=False)",
                "_from_factorized(cls, values, original)",
                "from_breaks(cls, breaks, closed='right', copy=False, dtype=None)",
                "from_arrays(cls, left, right, closed='right', copy=False, dtype=None)",
                "from_tuples(cls, data, closed='right', copy=False, dtype=None)",
                "_validate(self)",
                "__iter__(self)",
                "__len__(self) -> int",
                "__getitem__(self, value)",
                "__setitem__(self, key, value)",
                "__eq__(self, other)",
                "__ne__(self, other)",
                "fillna(self, value=None, method=None, limit=None)",
                "dtype(self)",
                "astype(self, dtype, copy=True)",
                "_concat_same_type(cls, to_concat)",
                "_shallow_copy(self, left=None, right=None, closed=None)",
                "copy(self)",
                "isna(self)",
                "nbytes(self) -> int",
                "size(self) -> int",
                "take(self, indices, allow_fill=False, fill_value=None, axis=None, **kwargs)",
                "value_counts(self, dropna=True)",
                "_format_data(self)",
                "__repr__(self) -> str",
                "_format_space(self)",
                "left(self)",
                "right(self)",
                "closed(self)",
                "set_closed(self, closed)",
                "length(self)",
                "mid(self)",
                "is_non_overlapping_monotonic(self)",
                "__array__(self, dtype=None) -> np.ndarray",
                "__arrow_array__(self, type=None)",
                "to_tuples(self, na_tuple=True)",
                "repeat(self, repeats, axis=None)",
                "contains(self, other)",
                "overlaps(self, other)"
            ],
            "variables_in_file": {
                "_VALID_CLOSED": [
                    1005,
                    46,
                    471
                ],
                "_interval_shared_docs": [
                    256,
                    384,
                    1163,
                    1038,
                    1049,
                    1179,
                    290,
                    420,
                    47,
                    310,
                    54,
                    1212,
                    962,
                    1234,
                    984,
                    363,
                    1143,
                    120,
                    1277
                ],
                "_shared_docs_kwargs": [
                    49,
                    1172,
                    1049
                ],
                "dict": [
                    121,
                    291,
                    421,
                    1163,
                    364,
                    49,
                    1174,
                    985,
                    1213,
                    1278
                ],
                "IntervalMixin": [
                    147,
                    191
                ],
                "ExtensionArray": [
                    147
                ],
                "ndim": [
                    148
                ],
                "can_hold_na": [
                    149
                ],
                "_na_value": [
                    150
                ],
                "_fill_value": [
                    150
                ],
                "np.nan": [
                    1169,
                    444,
                    1085,
                    150
                ],
                "np": [
                    523,
                    526,
                    1169,
                    150,
                    1072,
                    1329,
                    1331,
                    567,
                    696,
                    1082,
                    699,
                    444,
                    1085,
                    581,
                    587,
                    592,
                    722,
                    595,
                    723,
                    493,
                    882,
                    507
                ],
                "isinstance": [
                    226,
                    643,
                    229,
                    1126,
                    1227,
                    1293,
                    1325,
                    1295,
                    530,
                    754,
                    570,
                    565,
                    599,
                    504,
                    154,
                    157
                ],
                "data": [
                    160,
                    929,
                    164,
                    167,
                    172,
                    174,
                    442,
                    436,
                    440,
                    154,
                    155,
                    924,
                    157,
                    158,
                    159
                ],
                "ABCSeries": [
                    154
                ],
                "is_interval_dtype": [
                    579,
                    200,
                    585,
                    681,
                    530,
                    154
                ],
                "data.values": [
                    155
                ],
                "cls": [
                    446,
                    166,
                    459,
                    178,
                    308,
                    245,
                    724,
                    380,
                    157,
                    254,
                    191
                ],
                "ABCIntervalIndex": [
                    754,
                    1293,
                    157
                ],
                "left": [
                    512,
                    774,
                    778,
                    653,
                    655,
                    158,
                    547,
                    549,
                    550,
                    551,
                    173,
                    179,
                    437,
                    1077,
                    440,
                    1082,
                    1083,
                    1087,
                    194,
                    456,
                    459,
                    204,
                    208,
                    209,
                    210,
                    211,
                    722,
                    213,
                    724,
                    215,
                    219,
                    226,
                    229,
                    232,
                    745,
                    236,
                    505,
                    748,
                    754,
                    755,
                    500,
                    757,
                    504,
                    377,
                    507,
                    764,
                    381,
                    510
                ],
                "data.left": [
                    158
                ],
                "right": [
                    512,
                    775,
                    778,
                    654,
                    655,
                    159,
                    553,
                    555,
                    556,
                    173,
                    557,
                    180,
                    437,
                    1078,
                    440,
                    1087,
                    195,
                    457,
                    459,
                    205,
                    208,
                    209,
                    210,
                    211,
                    723,
                    213,
                    724,
                    216,
                    229,
                    232,
                    748,
                    237,
                    750,
                    501,
                    757,
                    378,
                    764,
                    381,
                    510
                ],
                "data.right": [
                    159
                ],
                "closed": [
                    776,
                    778,
                    160,
                    174,
                    176,
                    308,
                    181,
                    1080,
                    1087,
                    193,
                    459,
                    717,
                    718,
                    720,
                    724,
                    1005,
                    238,
                    1006,
                    1009,
                    763,
                    764,
                    381
                ],
                "data.closed": [
                    160
                ],
                "is_scalar": [
                    505,
                    164,
                    517,
                    847
                ],
                "msg": [
                    1025,
                    644,
                    648,
                    1296,
                    1297,
                    541,
                    542,
                    165,
                    169,
                    690,
                    693,
                    701,
                    702,
                    451,
                    452,
                    454,
                    455,
                    201,
                    202,
                    848,
                    853,
                    214,
                    472,
                    473,
                    218,
                    475,
                    476,
                    221,
                    480,
                    225,
                    227,
                    228,
                    484,
                    230,
                    486,
                    487,
                    234,
                    1006,
                    1007,
                    1021
                ],
                "cls.__name__": [
                    446,
                    166
                ],
                "TypeError": [
                    641,
                    1025,
                    648,
                    1034,
                    1297,
                    539,
                    542,
                    169,
                    689,
                    693,
                    700,
                    702,
                    453,
                    455,
                    202,
                    1099,
                    1100,
                    225,
                    1129,
                    1137,
                    1019,
                    639
                ],
                "maybe_convert_platform_interval": [
                    377,
                    306,
                    172,
                    378
                ],
                "infer_closed": [
                    176,
                    173
                ],
                "intervals_to_interval_bounds": [
                    173
                ],
                "cls._simple_new": [
                    178,
                    724,
                    380
                ],
                "copy": [
                    194,
                    195,
                    683,
                    308,
                    245,
                    182,
                    699,
                    381
                ],
                "dtype": [
                    680,
                    681,
                    682,
                    687,
                    688,
                    691,
                    308,
                    695,
                    183,
                    699,
                    701,
                    197,
                    199,
                    200,
                    201,
                    203,
                    204,
                    205,
                    459,
                    245,
                    381
                ],
                "verify_integrity": [
                    184,
                    239
                ],
                "result": [
                    1088,
                    236,
                    237,
                    238,
                    240,
                    241,
                    595,
                    1087,
                    1082,
                    604,
                    1085,
                    606,
                    191
                ],
                "IntervalMixin.__new__": [
                    191
                ],
                "ensure_index": [
                    194,
                    195
                ],
                "pandas_dtype": [
                    680,
                    199
                ],
                "dtype.subtype": [
                    203,
                    204,
                    205,
                    687,
                    688
                ],
                "left.astype": [
                    211,
                    204,
                    549
                ],
                "right.astype": [
                    209,
                    555,
                    205
                ],
                "is_float_dtype": [
                    208,
                    210
                ],
                "is_integer_dtype": [
                    208,
                    210,
                    518
                ],
                "left.dtype": [
                    209,
                    219
                ],
                "right.dtype": [
                    211
                ],
                "type": [
                    646,
                    778,
                    1296,
                    925,
                    541,
                    935,
                    701,
                    851,
                    213,
                    215,
                    216,
                    1123,
                    1124,
                    1126,
                    1128,
                    1133,
                    754,
                    755,
                    1138
                ],
                "__name__": [
                    646,
                    935,
                    925,
                    1296,
                    851,
                    215,
                    216,
                    701
                ],
                "ValueError": [
                    450,
                    700,
                    452,
                    228,
                    484,
                    487,
                    234,
                    719,
                    1007,
                    563,
                    853,
                    473,
                    218,
                    476,
                    509
                ],
                "is_categorical_dtype": [
                    1330,
                    219,
                    572,
                    695
                ],
                "is_string_dtype": [
                    219
                ],
                "ABCPeriodIndex": [
                    226
                ],
                "ABCDatetimeIndex": [
                    229
                ],
                "str": [
                    920,
                    893,
                    229
                ],
                "left.tz": [
                    232,
                    229
                ],
                "right.tz": [
                    232,
                    229
                ],
                "result._left": [
                    236
                ],
                "result._right": [
                    237
                ],
                "result._closed": [
                    238
                ],
                "result._validate": [
                    240
                ],
                "classmethod": [
                    288,
                    704,
                    418,
                    361,
                    243,
                    247,
                    187
                ],
                "scalars": [
                    245
                ],
                "len": [
                    930,
                    1082,
                    581,
                    935,
                    587,
                    1325,
                    718,
                    496,
                    592,
                    562,
                    595,
                    436,
                    567,
                    249,
                    474,
                    1083,
                    890,
                    1118
                ],
                "values": [
                    1325,
                    1330,
                    1331,
                    1333,
                    249,
                    253,
                    254
                ],
                "values.astype": [
                    253
                ],
                "original.dtype.subtype": [
                    253
                ],
                "original.dtype": [
                    253
                ],
                "original": [
                    253,
                    254
                ],
                "original.closed": [
                    254
                ],
                "textwrap.dedent": [
                    256,
                    384,
                    962,
                    1280,
                    128,
                    293,
                    423,
                    1179,
                    366,
                    1234,
                    310,
                    987,
                    1215
                ],
                "textwrap": [
                    256,
                    384,
                    962,
                    1280,
                    128,
                    293,
                    423,
                    1179,
                    366,
                    1234,
                    310,
                    987,
                    1215
                ],
                "breaks": [
                    306,
                    308
                ],
                "cls.from_arrays": [
                    459,
                    308
                ],
                "Appender": [
                    289,
                    419,
                    362,
                    1162,
                    1172,
                    119,
                    983,
                    1048,
                    1211,
                    1276
                ],
                "d": [
                    449,
                    451,
                    454,
                    442,
                    443
                ],
                "isna": [
                    505,
                    781,
                    443,
                    517
                ],
                "lhs": [
                    456,
                    449,
                    444
                ],
                "rhs": [
                    449,
                    444,
                    457
                ],
                "name": [
                    451,
                    454,
                    446
                ],
                "left.append": [
                    456
                ],
                "right.append": [
                    457
                ],
                "self.closed": [
                    930,
                    1058,
                    580,
                    776,
                    586,
                    600,
                    1133,
                    1104,
                    471,
                    472,
                    763,
                    510
                ],
                "self": [
                    512,
                    1018,
                    518,
                    521,
                    1033,
                    524,
                    1036,
                    531,
                    544,
                    1058,
                    547,
                    1060,
                    1061,
                    551,
                    553,
                    1067,
                    1068,
                    557,
                    562,
                    1077,
                    1078,
                    567,
                    1079,
                    1080,
                    580,
                    581,
                    586,
                    587,
                    588,
                    1098,
                    1102,
                    592,
                    1104,
                    595,
                    1107,
                    1108,
                    600,
                    601,
                    602,
                    1112,
                    609,
                    1133,
                    651,
                    653,
                    654,
                    655,
                    1166,
                    1169,
                    659,
                    1175,
                    1176,
                    1177,
                    682,
                    683,
                    687,
                    688,
                    691,
                    694,
                    696,
                    699,
                    701,
                    1230,
                    1231,
                    748,
                    754,
                    755,
                    763,
                    764,
                    774,
                    775,
                    776,
                    778,
                    781,
                    785,
                    1300,
                    1301,
                    790,
                    1306,
                    843,
                    845,
                    856,
                    859,
                    862,
                    882,
                    890,
                    898,
                    901,
                    902,
                    908,
                    909,
                    914,
                    924,
                    925,
                    930,
                    935,
                    944,
                    952,
                    960,
                    471,
                    472,
                    474,
                    477,
                    478,
                    485,
                    493,
                    496,
                    1009,
                    499,
                    500,
                    501,
                    506,
                    510
                ],
                "self.left": [
                    774,
                    1033,
                    1036,
                    653,
                    781,
                    1166,
                    785,
                    659,
                    790,
                    1175,
                    1306,
                    547,
                    1060,
                    1061,
                    1067,
                    1068,
                    687,
                    1077,
                    843,
                    588,
                    1230,
                    1107,
                    856,
                    601,
                    474,
                    477,
                    485,
                    748,
                    496,
                    500,
                    1018
                ],
                "self.right": [
                    775,
                    1033,
                    654,
                    1166,
                    785,
                    1176,
                    1306,
                    1060,
                    1061,
                    553,
                    1067,
                    1068,
                    688,
                    1078,
                    588,
                    1231,
                    1108,
                    602,
                    474,
                    859,
                    478,
                    485,
                    748,
                    501,
                    1018
                ],
                "left_mask": [
                    485,
                    477,
                    479
                ],
                "notna": [
                    477,
                    478,
                    847
                ],
                "right_mask": [
                    478,
                    479
                ],
                "all": [
                    1060,
                    1061,
                    485,
                    1067,
                    1068,
                    479
                ],
                "iter": [
                    493
                ],
                "np.asarray": [
                    493,
                    882,
                    1331,
                    696,
                    699
                ],
                "int": [
                    784,
                    788,
                    495
                ],
                "value": [
                    643,
                    517,
                    646,
                    650,
                    523,
                    651,
                    653,
                    526,
                    527,
                    654,
                    530,
                    499,
                    500,
                    501,
                    531,
                    532,
                    537,
                    541
                ],
                "check_array_indexer": [
                    544,
                    499
                ],
                "ABCIndexClass": [
                    504
                ],
                "self._fill_value": [
                    506
                ],
                "np.ndim": [
                    507
                ],
                "Interval": [
                    1227,
                    1295,
                    565,
                    599,
                    570,
                    510,
                    1087
                ],
                "self._shallow_copy": [
                    512,
                    655,
                    1009,
                    694,
                    1177,
                    862
                ],
                "needs_float_conversion": [
                    520,
                    554,
                    516,
                    548
                ],
                "self.dtype.subtype": [
                    518,
                    521,
                    1098,
                    524,
                    1133,
                    1102
                ],
                "self.dtype": [
                    930,
                    518,
                    521,
                    682,
                    1098,
                    524,
                    1133,
                    1102,
                    691
                ],
                "is_datetime64_any_dtype": [
                    521
                ],
                "np.datetime64": [
                    523
                ],
                "is_timedelta64_dtype": [
                    524
                ],
                "np.timedelta64": [
                    526
                ],
                "value_left": [
                    538,
                    532,
                    550,
                    527
                ],
                "value_right": [
                    538,
                    532,
                    556,
                    527
                ],
                "ABCInterval": [
                    530,
                    643
                ],
                "self._check_closed_matches": [
                    531,
                    651,
                    845
                ],
                "value.left": [
                    532,
                    653
                ],
                "value.right": [
                    532,
                    654
                ],
                "array": [
                    537,
                    538,
                    564
                ],
                "IntervalArray": [
                    537,
                    1293
                ],
                "array.left": [
                    538
                ],
                "array.right": [
                    538
                ],
                "key": [
                    544,
                    556,
                    550
                ],
                "self.left.copy": [
                    547,
                    774
                ],
                "left.values": [
                    550
                ],
                "self._left": [
                    944,
                    551
                ],
                "self.right.copy": [
                    553,
                    775
                ],
                "right.values": [
                    556
                ],
                "self._right": [
                    952,
                    557
                ],
                "is_list_like": [
                    561
                ],
                "other": [
                    1293,
                    1295,
                    1296,
                    1300,
                    1301,
                    1306,
                    561,
                    562,
                    564,
                    565,
                    570,
                    572,
                    573,
                    576,
                    580,
                    582,
                    586,
                    1227,
                    588,
                    1230,
                    1231,
                    596,
                    609
                ],
                "np.zeros": [
                    581,
                    587,
                    592,
                    595,
                    567
                ],
                "bool": [
                    1059,
                    581,
                    1066,
                    587,
                    592,
                    595,
                    567
                ],
                "other_dtype": [
                    576,
                    579,
                    585,
                    591,
                    571,
                    573
                ],
                "other.dtype": [
                    573
                ],
                "other.categories.dtype": [
                    576
                ],
                "other.categories": [
                    576,
                    580,
                    582
                ],
                "other.categories.closed": [
                    580
                ],
                "other.categories.take": [
                    582
                ],
                "other.codes": [
                    582
                ],
                "other.closed": [
                    586
                ],
                "other.left": [
                    1306,
                    588
                ],
                "other.right": [
                    1306,
                    588
                ],
                "is_object_dtype": [
                    591
                ],
                "i": [
                    1084,
                    596,
                    601,
                    602,
                    1083,
                    604,
                    1085,
                    1087
                ],
                "obj": [
                    596,
                    599,
                    600,
                    601,
                    602
                ],
                "enumerate": [
                    596
                ],
                "obj.closed": [
                    600
                ],
                "obj.left": [
                    601
                ],
                "obj.right": [
                    602
                ],
                "self.__eq__": [
                    609
                ],
                "method": [
                    638
                ],
                "limit": [
                    640
                ],
                "getattr": [
                    650
                ],
                "self.left.fillna": [
                    653
                ],
                "self.right.fillna": [
                    654
                ],
                "IntervalDtype": [
                    659
                ],
                "self.left.dtype": [
                    659
                ],
                "property": [
                    1027,
                    938,
                    783,
                    657,
                    946,
                    787,
                    1011,
                    1047,
                    954
                ],
                "self.copy": [
                    683
                ],
                "new_left": [
                    694,
                    687
                ],
                "self.left.astype": [
                    687
                ],
                "new_right": [
                    688,
                    694
                ],
                "self.right.astype": [
                    688
                ],
                "Categorical": [
                    696
                ],
                "astype": [
                    699
                ],
                "interval.closed": [
                    717
                ],
                "interval": [
                    722,
                    723,
                    717
                ],
                "to_concat": [
                    722,
                    723,
                    717
                ],
                "closed.pop": [
                    720
                ],
                "np.concatenate": [
                    722,
                    723
                ],
                "interval.left": [
                    722
                ],
                "interval.right": [
                    723
                ],
                "left.left": [
                    757
                ],
                "left.right": [
                    757
                ],
                "self._simple_new": [
                    764
                ],
                "from_arrays": [
                    778
                ],
                "self.left.nbytes": [
                    785
                ],
                "self.right.nbytes": [
                    785
                ],
                "self.left.size": [
                    790
                ],
                "nv.validate_take": [
                    838
                ],
                "nv": [
                    1174,
                    838
                ],
                "tuple": [
                    1174,
                    1325,
                    838
                ],
                "kwargs": [
                    838
                ],
                "fill_left": [
                    840,
                    856,
                    843,
                    846
                ],
                "fill_right": [
                    840,
                    859,
                    843,
                    846
                ],
                "fill_value": [
                    840,
                    842,
                    844,
                    845,
                    846,
                    847,
                    851
                ],
                "allow_fill": [
                    856,
                    841,
                    859
                ],
                "self.left._na_value": [
                    843
                ],
                "is_interval": [
                    844
                ],
                "fill_value.left": [
                    846
                ],
                "fill_value.right": [
                    846
                ],
                "left_take": [
                    862,
                    855
                ],
                "take": [
                    858,
                    855
                ],
                "indices": [
                    856,
                    859
                ],
                "right_take": [
                    858,
                    862
                ],
                "value_counts": [
                    882
                ],
                "dropna": [
                    882
                ],
                "n": [
                    897,
                    900,
                    906,
                    907,
                    908,
                    909,
                    890,
                    891,
                    895
                ],
                "max_seq_items": [
                    906,
                    891,
                    907
                ],
                "min": [
                    891,
                    907
                ],
                "get_option": [
                    891
                ],
                "formatter": [
                    898,
                    901,
                    902,
                    908,
                    909,
                    914,
                    893
                ],
                "summary": [
                    896,
                    899,
                    903,
                    912,
                    916,
                    918
                ],
                "first": [
                    898,
                    899,
                    901,
                    903
                ],
                "last": [
                    902,
                    903
                ],
                "head": [
                    908,
                    910
                ],
                "x": [
                    914,
                    908,
                    909
                ],
                "tail": [
                    914,
                    915,
                    909,
                    911
                ],
                "head_str": [
                    912,
                    910
                ],
                "join": [
                    915,
                    910,
                    911
                ],
                "tail_str": [
                    912,
                    915,
                    916,
                    911
                ],
                "self._format_data": [
                    924
                ],
                "class_name": [
                    928,
                    925
                ],
                "template": [
                    932,
                    927
                ],
                "space": [
                    936,
                    935
                ],
                "self._closed": [
                    960,
                    1080
                ],
                "self.length": [
                    1036
                ],
                "mask": [
                    1079,
                    1112,
                    1113,
                    1115,
                    1084
                ],
                "self.isna": [
                    1112,
                    1169,
                    1079
                ],
                "np.empty": [
                    1082
                ],
                "object": [
                    1082
                ],
                "range": [
                    1083
                ],
                "np.ndarray": [
                    1072
                ],
                "subtype": [
                    1104,
                    1098,
                    1107,
                    1108
                ],
                "pyarrow.from_numpy_dtype": [
                    1098
                ],
                "pyarrow": [
                    1098,
                    1105,
                    1107,
                    1108,
                    1141,
                    1115,
                    1116
                ],
                "format": [
                    1130,
                    1101,
                    1138
                ],
                "interval_type": [
                    1104,
                    1124,
                    1141,
                    1128
                ],
                "ArrowIntervalType": [
                    1104,
                    1126
                ],
                "storage_array": [
                    1120,
                    1125,
                    1105,
                    1141,
                    1116,
                    1117,
                    1118
                ],
                "pyarrow.StructArray.from_arrays": [
                    1105
                ],
                "pyarrow.StructArray": [
                    1105,
                    1116
                ],
                "pyarrow.array": [
                    1115,
                    1107,
                    1108
                ],
                "mask.any": [
                    1113
                ],
                "null_bitmap": [
                    1115,
                    1119
                ],
                "buffers": [
                    1115
                ],
                "pyarrow.StructArray.from_buffers": [
                    1116
                ],
                "storage_array.type": [
                    1117
                ],
                "storage_array.field": [
                    1120
                ],
                "type.equals": [
                    1128,
                    1124
                ],
                "interval_type.storage_type": [
                    1124
                ],
                "type.subtype": [
                    1133
                ],
                "type.closed": [
                    1133
                ],
                "pyarrow.ExtensionArray.from_storage": [
                    1141
                ],
                "pyarrow.ExtensionArray": [
                    1141
                ],
                "tuples": [
                    1169,
                    1170,
                    1166
                ],
                "com.asarray_tuplesafe": [
                    1166
                ],
                "com": [
                    1166
                ],
                "zip": [
                    1166
                ],
                "na_tuple": [
                    1167
                ],
                "np.where": [
                    1169
                ],
                "nv.validate_repeat": [
                    1174
                ],
                "axis": [
                    1174
                ],
                "left_repeat": [
                    1177,
                    1175
                ],
                "self.left.repeat": [
                    1175
                ],
                "repeats": [
                    1176,
                    1175
                ],
                "right_repeat": [
                    1176,
                    1177
                ],
                "self.right.repeat": [
                    1176
                ],
                "_extension_array_shared_docs": [
                    1172
                ],
                "NotImplementedError": [
                    1228,
                    1294
                ],
                "self.open_left": [
                    1230
                ],
                "self.open_right": [
                    1231
                ],
                "op1": [
                    1306,
                    1300
                ],
                "self.closed_left": [
                    1300
                ],
                "other.closed_right": [
                    1300
                ],
                "le": [
                    1300,
                    1301
                ],
                "lt": [
                    1300,
                    1301
                ],
                "op2": [
                    1306,
                    1301
                ],
                "other.closed_left": [
                    1301
                ],
                "self.closed_right": [
                    1301
                ],
                "list": [
                    1325
                ],
                "np.array": [
                    1329
                ],
                "np.int64": [
                    1329
                ],
                "maybe_convert_platform": [
                    1333
                ]
            },
            "filtered_variables_in_file": {
                "_VALID_CLOSED": [
                    1005,
                    46,
                    471
                ],
                "_interval_shared_docs": [
                    256,
                    384,
                    1163,
                    1038,
                    1049,
                    1179,
                    290,
                    420,
                    47,
                    310,
                    54,
                    1212,
                    962,
                    1234,
                    984,
                    363,
                    1143,
                    120,
                    1277
                ],
                "_shared_docs_kwargs": [
                    49,
                    1172,
                    1049
                ],
                "IntervalMixin": [
                    147,
                    191
                ],
                "ExtensionArray": [
                    147
                ],
                "ndim": [
                    148
                ],
                "can_hold_na": [
                    149
                ],
                "_na_value": [
                    150
                ],
                "_fill_value": [
                    150
                ],
                "np.nan": [
                    1169,
                    444,
                    1085,
                    150
                ],
                "np": [
                    523,
                    526,
                    1169,
                    150,
                    1072,
                    1329,
                    1331,
                    567,
                    696,
                    1082,
                    699,
                    444,
                    1085,
                    581,
                    587,
                    592,
                    722,
                    595,
                    723,
                    493,
                    882,
                    507
                ],
                "data": [
                    160,
                    929,
                    164,
                    167,
                    172,
                    174,
                    442,
                    436,
                    440,
                    154,
                    155,
                    924,
                    157,
                    158,
                    159
                ],
                "ABCSeries": [
                    154
                ],
                "is_interval_dtype": [
                    579,
                    200,
                    585,
                    681,
                    530,
                    154
                ],
                "data.values": [
                    155
                ],
                "cls": [
                    446,
                    166,
                    459,
                    178,
                    308,
                    245,
                    724,
                    380,
                    157,
                    254,
                    191
                ],
                "ABCIntervalIndex": [
                    754,
                    1293,
                    157
                ],
                "left": [
                    512,
                    774,
                    778,
                    653,
                    655,
                    158,
                    547,
                    549,
                    550,
                    551,
                    173,
                    179,
                    437,
                    1077,
                    440,
                    1082,
                    1083,
                    1087,
                    194,
                    456,
                    459,
                    204,
                    208,
                    209,
                    210,
                    211,
                    722,
                    213,
                    724,
                    215,
                    219,
                    226,
                    229,
                    232,
                    745,
                    236,
                    505,
                    748,
                    754,
                    755,
                    500,
                    757,
                    504,
                    377,
                    507,
                    764,
                    381,
                    510
                ],
                "data.left": [
                    158
                ],
                "right": [
                    512,
                    775,
                    778,
                    654,
                    655,
                    159,
                    553,
                    555,
                    556,
                    173,
                    557,
                    180,
                    437,
                    1078,
                    440,
                    1087,
                    195,
                    457,
                    459,
                    205,
                    208,
                    209,
                    210,
                    211,
                    723,
                    213,
                    724,
                    216,
                    229,
                    232,
                    748,
                    237,
                    750,
                    501,
                    757,
                    378,
                    764,
                    381,
                    510
                ],
                "data.right": [
                    159
                ],
                "closed": [
                    776,
                    778,
                    160,
                    174,
                    176,
                    308,
                    181,
                    1080,
                    1087,
                    193,
                    459,
                    717,
                    718,
                    720,
                    724,
                    1005,
                    238,
                    1006,
                    1009,
                    763,
                    764,
                    381
                ],
                "data.closed": [
                    160
                ],
                "is_scalar": [
                    505,
                    164,
                    517,
                    847
                ],
                "msg": [
                    1025,
                    644,
                    648,
                    1296,
                    1297,
                    541,
                    542,
                    165,
                    169,
                    690,
                    693,
                    701,
                    702,
                    451,
                    452,
                    454,
                    455,
                    201,
                    202,
                    848,
                    853,
                    214,
                    472,
                    473,
                    218,
                    475,
                    476,
                    221,
                    480,
                    225,
                    227,
                    228,
                    484,
                    230,
                    486,
                    487,
                    234,
                    1006,
                    1007,
                    1021
                ],
                "cls.__name__": [
                    446,
                    166
                ],
                "maybe_convert_platform_interval": [
                    377,
                    306,
                    172,
                    378
                ],
                "infer_closed": [
                    176,
                    173
                ],
                "intervals_to_interval_bounds": [
                    173
                ],
                "cls._simple_new": [
                    178,
                    724,
                    380
                ],
                "copy": [
                    194,
                    195,
                    683,
                    308,
                    245,
                    182,
                    699,
                    381
                ],
                "dtype": [
                    680,
                    681,
                    682,
                    687,
                    688,
                    691,
                    308,
                    695,
                    183,
                    699,
                    701,
                    197,
                    199,
                    200,
                    201,
                    203,
                    204,
                    205,
                    459,
                    245,
                    381
                ],
                "verify_integrity": [
                    184,
                    239
                ],
                "result": [
                    1088,
                    236,
                    237,
                    238,
                    240,
                    241,
                    595,
                    1087,
                    1082,
                    604,
                    1085,
                    606,
                    191
                ],
                "IntervalMixin.__new__": [
                    191
                ],
                "ensure_index": [
                    194,
                    195
                ],
                "pandas_dtype": [
                    680,
                    199
                ],
                "dtype.subtype": [
                    203,
                    204,
                    205,
                    687,
                    688
                ],
                "left.astype": [
                    211,
                    204,
                    549
                ],
                "right.astype": [
                    209,
                    555,
                    205
                ],
                "is_float_dtype": [
                    208,
                    210
                ],
                "is_integer_dtype": [
                    208,
                    210,
                    518
                ],
                "left.dtype": [
                    209,
                    219
                ],
                "right.dtype": [
                    211
                ],
                "is_categorical_dtype": [
                    1330,
                    219,
                    572,
                    695
                ],
                "is_string_dtype": [
                    219
                ],
                "ABCPeriodIndex": [
                    226
                ],
                "ABCDatetimeIndex": [
                    229
                ],
                "left.tz": [
                    232,
                    229
                ],
                "right.tz": [
                    232,
                    229
                ],
                "result._left": [
                    236
                ],
                "result._right": [
                    237
                ],
                "result._closed": [
                    238
                ],
                "result._validate": [
                    240
                ],
                "scalars": [
                    245
                ],
                "values": [
                    1325,
                    1330,
                    1331,
                    1333,
                    249,
                    253,
                    254
                ],
                "values.astype": [
                    253
                ],
                "original.dtype.subtype": [
                    253
                ],
                "original.dtype": [
                    253
                ],
                "original": [
                    253,
                    254
                ],
                "original.closed": [
                    254
                ],
                "textwrap.dedent": [
                    256,
                    384,
                    962,
                    1280,
                    128,
                    293,
                    423,
                    1179,
                    366,
                    1234,
                    310,
                    987,
                    1215
                ],
                "textwrap": [
                    256,
                    384,
                    962,
                    1280,
                    128,
                    293,
                    423,
                    1179,
                    366,
                    1234,
                    310,
                    987,
                    1215
                ],
                "breaks": [
                    306,
                    308
                ],
                "cls.from_arrays": [
                    459,
                    308
                ],
                "Appender": [
                    289,
                    419,
                    362,
                    1162,
                    1172,
                    119,
                    983,
                    1048,
                    1211,
                    1276
                ],
                "d": [
                    449,
                    451,
                    454,
                    442,
                    443
                ],
                "isna": [
                    505,
                    781,
                    443,
                    517
                ],
                "lhs": [
                    456,
                    449,
                    444
                ],
                "rhs": [
                    449,
                    444,
                    457
                ],
                "name": [
                    451,
                    454,
                    446
                ],
                "left.append": [
                    456
                ],
                "right.append": [
                    457
                ],
                "self.closed": [
                    930,
                    1058,
                    580,
                    776,
                    586,
                    600,
                    1133,
                    1104,
                    471,
                    472,
                    763,
                    510
                ],
                "self": [
                    512,
                    1018,
                    518,
                    521,
                    1033,
                    524,
                    1036,
                    531,
                    544,
                    1058,
                    547,
                    1060,
                    1061,
                    551,
                    553,
                    1067,
                    1068,
                    557,
                    562,
                    1077,
                    1078,
                    567,
                    1079,
                    1080,
                    580,
                    581,
                    586,
                    587,
                    588,
                    1098,
                    1102,
                    592,
                    1104,
                    595,
                    1107,
                    1108,
                    600,
                    601,
                    602,
                    1112,
                    609,
                    1133,
                    651,
                    653,
                    654,
                    655,
                    1166,
                    1169,
                    659,
                    1175,
                    1176,
                    1177,
                    682,
                    683,
                    687,
                    688,
                    691,
                    694,
                    696,
                    699,
                    701,
                    1230,
                    1231,
                    748,
                    754,
                    755,
                    763,
                    764,
                    774,
                    775,
                    776,
                    778,
                    781,
                    785,
                    1300,
                    1301,
                    790,
                    1306,
                    843,
                    845,
                    856,
                    859,
                    862,
                    882,
                    890,
                    898,
                    901,
                    902,
                    908,
                    909,
                    914,
                    924,
                    925,
                    930,
                    935,
                    944,
                    952,
                    960,
                    471,
                    472,
                    474,
                    477,
                    478,
                    485,
                    493,
                    496,
                    1009,
                    499,
                    500,
                    501,
                    506,
                    510
                ],
                "self.left": [
                    774,
                    1033,
                    1036,
                    653,
                    781,
                    1166,
                    785,
                    659,
                    790,
                    1175,
                    1306,
                    547,
                    1060,
                    1061,
                    1067,
                    1068,
                    687,
                    1077,
                    843,
                    588,
                    1230,
                    1107,
                    856,
                    601,
                    474,
                    477,
                    485,
                    748,
                    496,
                    500,
                    1018
                ],
                "self.right": [
                    775,
                    1033,
                    654,
                    1166,
                    785,
                    1176,
                    1306,
                    1060,
                    1061,
                    553,
                    1067,
                    1068,
                    688,
                    1078,
                    588,
                    1231,
                    1108,
                    602,
                    474,
                    859,
                    478,
                    485,
                    748,
                    501,
                    1018
                ],
                "left_mask": [
                    485,
                    477,
                    479
                ],
                "notna": [
                    477,
                    478,
                    847
                ],
                "right_mask": [
                    478,
                    479
                ],
                "np.asarray": [
                    493,
                    882,
                    1331,
                    696,
                    699
                ],
                "value": [
                    643,
                    517,
                    646,
                    650,
                    523,
                    651,
                    653,
                    526,
                    527,
                    654,
                    530,
                    499,
                    500,
                    501,
                    531,
                    532,
                    537,
                    541
                ],
                "check_array_indexer": [
                    544,
                    499
                ],
                "ABCIndexClass": [
                    504
                ],
                "self._fill_value": [
                    506
                ],
                "np.ndim": [
                    507
                ],
                "Interval": [
                    1227,
                    1295,
                    565,
                    599,
                    570,
                    510,
                    1087
                ],
                "self._shallow_copy": [
                    512,
                    655,
                    1009,
                    694,
                    1177,
                    862
                ],
                "needs_float_conversion": [
                    520,
                    554,
                    516,
                    548
                ],
                "self.dtype.subtype": [
                    518,
                    521,
                    1098,
                    524,
                    1133,
                    1102
                ],
                "self.dtype": [
                    930,
                    518,
                    521,
                    682,
                    1098,
                    524,
                    1133,
                    1102,
                    691
                ],
                "is_datetime64_any_dtype": [
                    521
                ],
                "np.datetime64": [
                    523
                ],
                "is_timedelta64_dtype": [
                    524
                ],
                "np.timedelta64": [
                    526
                ],
                "value_left": [
                    538,
                    532,
                    550,
                    527
                ],
                "value_right": [
                    538,
                    532,
                    556,
                    527
                ],
                "ABCInterval": [
                    530,
                    643
                ],
                "self._check_closed_matches": [
                    531,
                    651,
                    845
                ],
                "value.left": [
                    532,
                    653
                ],
                "value.right": [
                    532,
                    654
                ],
                "array": [
                    537,
                    538,
                    564
                ],
                "IntervalArray": [
                    537,
                    1293
                ],
                "array.left": [
                    538
                ],
                "array.right": [
                    538
                ],
                "key": [
                    544,
                    556,
                    550
                ],
                "self.left.copy": [
                    547,
                    774
                ],
                "left.values": [
                    550
                ],
                "self._left": [
                    944,
                    551
                ],
                "self.right.copy": [
                    553,
                    775
                ],
                "right.values": [
                    556
                ],
                "self._right": [
                    952,
                    557
                ],
                "is_list_like": [
                    561
                ],
                "other": [
                    1293,
                    1295,
                    1296,
                    1300,
                    1301,
                    1306,
                    561,
                    562,
                    564,
                    565,
                    570,
                    572,
                    573,
                    576,
                    580,
                    582,
                    586,
                    1227,
                    588,
                    1230,
                    1231,
                    596,
                    609
                ],
                "np.zeros": [
                    581,
                    587,
                    592,
                    595,
                    567
                ],
                "other_dtype": [
                    576,
                    579,
                    585,
                    591,
                    571,
                    573
                ],
                "other.dtype": [
                    573
                ],
                "other.categories.dtype": [
                    576
                ],
                "other.categories": [
                    576,
                    580,
                    582
                ],
                "other.categories.closed": [
                    580
                ],
                "other.categories.take": [
                    582
                ],
                "other.codes": [
                    582
                ],
                "other.closed": [
                    586
                ],
                "other.left": [
                    1306,
                    588
                ],
                "other.right": [
                    1306,
                    588
                ],
                "is_object_dtype": [
                    591
                ],
                "i": [
                    1084,
                    596,
                    601,
                    602,
                    1083,
                    604,
                    1085,
                    1087
                ],
                "obj": [
                    596,
                    599,
                    600,
                    601,
                    602
                ],
                "obj.closed": [
                    600
                ],
                "obj.left": [
                    601
                ],
                "obj.right": [
                    602
                ],
                "self.__eq__": [
                    609
                ],
                "method": [
                    638
                ],
                "limit": [
                    640
                ],
                "self.left.fillna": [
                    653
                ],
                "self.right.fillna": [
                    654
                ],
                "IntervalDtype": [
                    659
                ],
                "self.left.dtype": [
                    659
                ],
                "self.copy": [
                    683
                ],
                "new_left": [
                    694,
                    687
                ],
                "self.left.astype": [
                    687
                ],
                "new_right": [
                    688,
                    694
                ],
                "self.right.astype": [
                    688
                ],
                "Categorical": [
                    696
                ],
                "astype": [
                    699
                ],
                "interval.closed": [
                    717
                ],
                "interval": [
                    722,
                    723,
                    717
                ],
                "to_concat": [
                    722,
                    723,
                    717
                ],
                "closed.pop": [
                    720
                ],
                "np.concatenate": [
                    722,
                    723
                ],
                "interval.left": [
                    722
                ],
                "interval.right": [
                    723
                ],
                "left.left": [
                    757
                ],
                "left.right": [
                    757
                ],
                "self._simple_new": [
                    764
                ],
                "from_arrays": [
                    778
                ],
                "self.left.nbytes": [
                    785
                ],
                "self.right.nbytes": [
                    785
                ],
                "self.left.size": [
                    790
                ],
                "nv.validate_take": [
                    838
                ],
                "nv": [
                    1174,
                    838
                ],
                "kwargs": [
                    838
                ],
                "fill_left": [
                    840,
                    856,
                    843,
                    846
                ],
                "fill_right": [
                    840,
                    859,
                    843,
                    846
                ],
                "fill_value": [
                    840,
                    842,
                    844,
                    845,
                    846,
                    847,
                    851
                ],
                "allow_fill": [
                    856,
                    841,
                    859
                ],
                "self.left._na_value": [
                    843
                ],
                "is_interval": [
                    844
                ],
                "fill_value.left": [
                    846
                ],
                "fill_value.right": [
                    846
                ],
                "left_take": [
                    862,
                    855
                ],
                "take": [
                    858,
                    855
                ],
                "indices": [
                    856,
                    859
                ],
                "right_take": [
                    858,
                    862
                ],
                "value_counts": [
                    882
                ],
                "dropna": [
                    882
                ],
                "n": [
                    897,
                    900,
                    906,
                    907,
                    908,
                    909,
                    890,
                    891,
                    895
                ],
                "max_seq_items": [
                    906,
                    891,
                    907
                ],
                "get_option": [
                    891
                ],
                "formatter": [
                    898,
                    901,
                    902,
                    908,
                    909,
                    914,
                    893
                ],
                "summary": [
                    896,
                    899,
                    903,
                    912,
                    916,
                    918
                ],
                "first": [
                    898,
                    899,
                    901,
                    903
                ],
                "last": [
                    902,
                    903
                ],
                "head": [
                    908,
                    910
                ],
                "x": [
                    914,
                    908,
                    909
                ],
                "tail": [
                    914,
                    915,
                    909,
                    911
                ],
                "head_str": [
                    912,
                    910
                ],
                "join": [
                    915,
                    910,
                    911
                ],
                "tail_str": [
                    912,
                    915,
                    916,
                    911
                ],
                "self._format_data": [
                    924
                ],
                "class_name": [
                    928,
                    925
                ],
                "template": [
                    932,
                    927
                ],
                "space": [
                    936,
                    935
                ],
                "self._closed": [
                    960,
                    1080
                ],
                "self.length": [
                    1036
                ],
                "mask": [
                    1079,
                    1112,
                    1113,
                    1115,
                    1084
                ],
                "self.isna": [
                    1112,
                    1169,
                    1079
                ],
                "np.empty": [
                    1082
                ],
                "np.ndarray": [
                    1072
                ],
                "subtype": [
                    1104,
                    1098,
                    1107,
                    1108
                ],
                "pyarrow.from_numpy_dtype": [
                    1098
                ],
                "pyarrow": [
                    1098,
                    1105,
                    1107,
                    1108,
                    1141,
                    1115,
                    1116
                ],
                "interval_type": [
                    1104,
                    1124,
                    1141,
                    1128
                ],
                "ArrowIntervalType": [
                    1104,
                    1126
                ],
                "storage_array": [
                    1120,
                    1125,
                    1105,
                    1141,
                    1116,
                    1117,
                    1118
                ],
                "pyarrow.StructArray.from_arrays": [
                    1105
                ],
                "pyarrow.StructArray": [
                    1105,
                    1116
                ],
                "pyarrow.array": [
                    1115,
                    1107,
                    1108
                ],
                "mask.any": [
                    1113
                ],
                "null_bitmap": [
                    1115,
                    1119
                ],
                "buffers": [
                    1115
                ],
                "pyarrow.StructArray.from_buffers": [
                    1116
                ],
                "storage_array.type": [
                    1117
                ],
                "storage_array.field": [
                    1120
                ],
                "type.equals": [
                    1128,
                    1124
                ],
                "interval_type.storage_type": [
                    1124
                ],
                "type.subtype": [
                    1133
                ],
                "type.closed": [
                    1133
                ],
                "pyarrow.ExtensionArray.from_storage": [
                    1141
                ],
                "pyarrow.ExtensionArray": [
                    1141
                ],
                "tuples": [
                    1169,
                    1170,
                    1166
                ],
                "com.asarray_tuplesafe": [
                    1166
                ],
                "com": [
                    1166
                ],
                "na_tuple": [
                    1167
                ],
                "np.where": [
                    1169
                ],
                "nv.validate_repeat": [
                    1174
                ],
                "axis": [
                    1174
                ],
                "left_repeat": [
                    1177,
                    1175
                ],
                "self.left.repeat": [
                    1175
                ],
                "repeats": [
                    1176,
                    1175
                ],
                "right_repeat": [
                    1176,
                    1177
                ],
                "self.right.repeat": [
                    1176
                ],
                "_extension_array_shared_docs": [
                    1172
                ],
                "self.open_left": [
                    1230
                ],
                "self.open_right": [
                    1231
                ],
                "op1": [
                    1306,
                    1300
                ],
                "self.closed_left": [
                    1300
                ],
                "other.closed_right": [
                    1300
                ],
                "le": [
                    1300,
                    1301
                ],
                "lt": [
                    1300,
                    1301
                ],
                "op2": [
                    1306,
                    1301
                ],
                "other.closed_left": [
                    1301
                ],
                "self.closed_right": [
                    1301
                ],
                "np.array": [
                    1329
                ],
                "np.int64": [
                    1329
                ],
                "maybe_convert_platform": [
                    1333
                ]
            }
        },
        "/Volumes/JerrySSD/bgp_envs/repos/pandas_68/pandas/tests/extension/base/methods.py": {
            "buggy_functions": [
                {
                    "function_name": "test_shift_fill_value",
                    "function_code": "def test_shift_fill_value(self, data):\n    arr = data[:4]\n    fill_value = data[0]\n    result = arr.shift(1, fill_value=fill_value)\n    expected = data.take([0, 0, 1, 2])\n    self.assert_extension_array_equal(result, expected)\n\n    result = arr.shift(-2, fill_value=fill_value)\n    expected = data.take([2, 3, 0, 0])\n    self.assert_extension_array_equal(result, expected)\n",
                    "decorators": [],
                    "docstring": null,
                    "start_line": 283,
                    "variables": {
                        "arr": [
                            290,
                            284,
                            286
                        ],
                        "data": [
                            291,
                            284,
                            285,
                            287
                        ],
                        "fill_value": [
                            290,
                            285,
                            286
                        ],
                        "result": [
                            288,
                            290,
                            292,
                            286
                        ],
                        "arr.shift": [
                            290,
                            286
                        ],
                        "expected": [
                            288,
                            291,
                            292,
                            287
                        ],
                        "data.take": [
                            291,
                            287
                        ],
                        "self.assert_extension_array_equal": [
                            288,
                            292
                        ],
                        "self": [
                            288,
                            292
                        ]
                    },
                    "filtered_variables": {
                        "arr": [
                            290,
                            284,
                            286
                        ],
                        "data": [
                            291,
                            284,
                            285,
                            287
                        ],
                        "fill_value": [
                            290,
                            285,
                            286
                        ],
                        "result": [
                            288,
                            290,
                            292,
                            286
                        ],
                        "arr.shift": [
                            290,
                            286
                        ],
                        "expected": [
                            288,
                            291,
                            292,
                            287
                        ],
                        "data.take": [
                            291,
                            287
                        ],
                        "self.assert_extension_array_equal": [
                            288,
                            292
                        ],
                        "self": [
                            288,
                            292
                        ]
                    },
                    "diff_line_number": 283,
                    "class_data": {
                        "signature": "class BaseMethodsTests(BaseExtensionTests)",
                        "docstring": "Various Series and DataFrame methods.",
                        "constructor_docstring": null,
                        "functions": [
                            "@pytest.mark.parametrize('dropna', [True, False])\ndef test_value_counts(self, all_data, dropna):\n    all_data = all_data[:10]\n    if dropna:\n        other = np.array(all_data[~all_data.isna()])\n    else:\n        other = all_data\n    result = pd.Series(all_data).value_counts(dropna=dropna).sort_index()\n    expected = pd.Series(other).value_counts(dropna=dropna).sort_index()\n    self.assert_series_equal(result, expected)",
                            "def test_count(self, data_missing):\n    df = pd.DataFrame({'A': data_missing})\n    result = df.count(axis='columns')\n    expected = pd.Series([0, 1])\n    self.assert_series_equal(result, expected)",
                            "def test_series_count(self, data_missing):\n    ser = pd.Series(data_missing)\n    result = ser.count()\n    expected = 1\n    assert result == expected",
                            "def test_apply_simple_series(self, data):\n    result = pd.Series(data).apply(id)\n    assert isinstance(result, pd.Series)",
                            "def test_argsort(self, data_for_sorting):\n    result = pd.Series(data_for_sorting).argsort()\n    expected = pd.Series(np.array([2, 0, 1], dtype=np.int64))\n    self.assert_series_equal(result, expected)",
                            "def test_argsort_missing_array(self, data_missing_for_sorting):\n    result = data_missing_for_sorting.argsort()\n    expected = np.array([2, 0, 1], dtype=np.dtype('int'))\n    result = result.astype('int64', casting='safe')\n    expected = expected.astype('int64', casting='safe')\n    tm.assert_numpy_array_equal(result, expected)",
                            "def test_argsort_missing(self, data_missing_for_sorting):\n    result = pd.Series(data_missing_for_sorting).argsort()\n    expected = pd.Series(np.array([1, -1, 0], dtype=np.int64))\n    self.assert_series_equal(result, expected)",
                            "@pytest.mark.parametrize('na_position, expected', [('last', np.array([2, 0, 1], dtype=np.dtype('intp'))), ('first', np.array([1, 2, 0], dtype=np.dtype('intp')))])\ndef test_nargsort(self, data_missing_for_sorting, na_position, expected):\n    result = nargsort(data_missing_for_sorting, na_position=na_position)\n    tm.assert_numpy_array_equal(result, expected)",
                            "@pytest.mark.parametrize('ascending', [True, False])\ndef test_sort_values(self, data_for_sorting, ascending):\n    ser = pd.Series(data_for_sorting)\n    result = ser.sort_values(ascending=ascending)\n    expected = ser.iloc[[2, 0, 1]]\n    if not ascending:\n        expected = expected[::-1]\n    self.assert_series_equal(result, expected)",
                            "@pytest.mark.parametrize('ascending', [True, False])\ndef test_sort_values_missing(self, data_missing_for_sorting, ascending):\n    ser = pd.Series(data_missing_for_sorting)\n    result = ser.sort_values(ascending=ascending)\n    if ascending:\n        expected = ser.iloc[[2, 0, 1]]\n    else:\n        expected = ser.iloc[[0, 2, 1]]\n    self.assert_series_equal(result, expected)",
                            "@pytest.mark.parametrize('ascending', [True, False])\ndef test_sort_values_frame(self, data_for_sorting, ascending):\n    df = pd.DataFrame({'A': [1, 2, 1], 'B': data_for_sorting})\n    result = df.sort_values(['A', 'B'])\n    expected = pd.DataFrame({'A': [1, 1, 2], 'B': data_for_sorting.take([2, 0, 1])}, index=[2, 0, 1])\n    self.assert_frame_equal(result, expected)",
                            "@pytest.mark.parametrize('box', [pd.Series, lambda x: x])\n@pytest.mark.parametrize('method', [lambda x: x.unique(), pd.unique])\ndef test_unique(self, data, box, method):\n    duplicated = box(data._from_sequence([data[0], data[0]]))\n    result = method(duplicated)\n    assert len(result) == 1\n    assert isinstance(result, type(data))\n    assert result[0] == duplicated[0]",
                            "@pytest.mark.parametrize('na_sentinel', [-1, -2])\ndef test_factorize(self, data_for_grouping, na_sentinel):\n    codes, uniques = pd.factorize(data_for_grouping, na_sentinel=na_sentinel)\n    expected_codes = np.array([0, 0, na_sentinel, na_sentinel, 1, 1, 0, 2], dtype=np.intp)\n    expected_uniques = data_for_grouping.take([0, 4, 7])\n    tm.assert_numpy_array_equal(codes, expected_codes)\n    self.assert_extension_array_equal(uniques, expected_uniques)",
                            "@pytest.mark.parametrize('na_sentinel', [-1, -2])\ndef test_factorize_equivalence(self, data_for_grouping, na_sentinel):\n    codes_1, uniques_1 = pd.factorize(data_for_grouping, na_sentinel=na_sentinel)\n    codes_2, uniques_2 = data_for_grouping.factorize(na_sentinel=na_sentinel)\n    tm.assert_numpy_array_equal(codes_1, codes_2)\n    self.assert_extension_array_equal(uniques_1, uniques_2)",
                            "def test_factorize_empty(self, data):\n    codes, uniques = pd.factorize(data[:0])\n    expected_codes = np.array([], dtype=np.intp)\n    expected_uniques = type(data)._from_sequence([], dtype=data[:0].dtype)\n    tm.assert_numpy_array_equal(codes, expected_codes)\n    self.assert_extension_array_equal(uniques, expected_uniques)",
                            "def test_fillna_copy_frame(self, data_missing):\n    arr = data_missing.take([1, 1])\n    df = pd.DataFrame({'A': arr})\n    filled_val = df.iloc[0, 0]\n    result = df.fillna(filled_val)\n    assert df.A.values is not result.A.values",
                            "def test_fillna_copy_series(self, data_missing):\n    arr = data_missing.take([1, 1])\n    ser = pd.Series(arr)\n    filled_val = ser[0]\n    result = ser.fillna(filled_val)\n    assert ser._values is not result._values\n    assert ser._values is arr",
                            "def test_fillna_length_mismatch(self, data_missing):\n    msg = \"Length of 'value' does not match.\"\n    with pytest.raises(ValueError, match=msg):\n        data_missing.fillna(data_missing.take([1]))",
                            "def test_combine_le(self, data_repeated):\n    orig_data1, orig_data2 = data_repeated(2)\n    s1 = pd.Series(orig_data1)\n    s2 = pd.Series(orig_data2)\n    result = s1.combine(s2, lambda x1, x2: x1 <= x2)\n    expected = pd.Series([a <= b for a, b in zip(list(orig_data1), list(orig_data2))])\n    self.assert_series_equal(result, expected)\n    val = s1.iloc[0]\n    result = s1.combine(val, lambda x1, x2: x1 <= x2)\n    expected = pd.Series([a <= val for a in list(orig_data1)])\n    self.assert_series_equal(result, expected)",
                            "def test_combine_add(self, data_repeated):\n    orig_data1, orig_data2 = data_repeated(2)\n    s1 = pd.Series(orig_data1)\n    s2 = pd.Series(orig_data2)\n    result = s1.combine(s2, lambda x1, x2: x1 + x2)\n    with np.errstate(over='ignore'):\n        expected = pd.Series(orig_data1._from_sequence([a + b for a, b in zip(list(orig_data1), list(orig_data2))]))\n    self.assert_series_equal(result, expected)\n    val = s1.iloc[0]\n    result = s1.combine(val, lambda x1, x2: x1 + x2)\n    expected = pd.Series(orig_data1._from_sequence([a + val for a in list(orig_data1)]))\n    self.assert_series_equal(result, expected)",
                            "def test_combine_first(self, data):\n    a = pd.Series(data[:3])\n    b = pd.Series(data[2:5], index=[2, 3, 4])\n    result = a.combine_first(b)\n    expected = pd.Series(data[:5])\n    self.assert_series_equal(result, expected)",
                            "@pytest.mark.parametrize('frame', [True, False])\n@pytest.mark.parametrize('periods, indices', [(-2, [2, 3, 4, -1, -1]), (0, [0, 1, 2, 3, 4]), (2, [-1, -1, 0, 1, 2])])\ndef test_container_shift(self, data, frame, periods, indices):\n    subset = data[:5]\n    data = pd.Series(subset, name='A')\n    expected = pd.Series(subset.take(indices, allow_fill=True), name='A')\n    if frame:\n        result = data.to_frame(name='A').assign(B=1).shift(periods)\n        expected = pd.concat([expected, pd.Series([1] * 5, name='B').shift(periods)], axis=1)\n        compare = self.assert_frame_equal\n    else:\n        result = data.shift(periods)\n        compare = self.assert_series_equal\n    compare(result, expected)",
                            "@pytest.mark.parametrize('periods', [1, -2])\ndef test_diff(self, data, periods):\n    data = data[:5]\n    if is_bool_dtype(data.dtype):\n        op = operator.xor\n    else:\n        op = operator.sub\n    try:\n        op(data, data)\n    except Exception:\n        pytest.skip(f'{type(data)} does not support diff')\n    s = pd.Series(data)\n    result = s.diff(periods)\n    expected = pd.Series(op(data, data.shift(periods)))\n    self.assert_series_equal(result, expected)\n    df = pd.DataFrame({'A': data, 'B': [1.0] * 5})\n    result = df.diff(periods)\n    if periods == 1:\n        b = [np.nan, 0, 0, 0, 0]\n    else:\n        b = [0, 0, 0, np.nan, np.nan]\n    expected = pd.DataFrame({'A': expected, 'B': b})\n    self.assert_frame_equal(result, expected)",
                            "@pytest.mark.parametrize('periods, indices', [[-4, [-1, -1]], [-1, [1, -1]], [0, [0, 1]], [1, [-1, 0]], [4, [-1, -1]]])\ndef test_shift_non_empty_array(self, data, periods, indices):\n    subset = data[:2]\n    result = subset.shift(periods)\n    expected = subset.take(indices, allow_fill=True)\n    self.assert_extension_array_equal(result, expected)",
                            "@pytest.mark.parametrize('periods', [-4, -1, 0, 1, 4])\ndef test_shift_empty_array(self, data, periods):\n    empty = data[:0]\n    result = empty.shift(periods)\n    expected = empty\n    self.assert_extension_array_equal(result, expected)",
                            "def test_shift_fill_value(self, data):\n    arr = data[:4]\n    fill_value = data[0]\n    result = arr.shift(1, fill_value=fill_value)\n    expected = data.take([0, 0, 1, 2])\n    self.assert_extension_array_equal(result, expected)\n    result = arr.shift(-2, fill_value=fill_value)\n    expected = data.take([2, 3, 0, 0])\n    self.assert_extension_array_equal(result, expected)",
                            "def test_not_hashable(self, data):\n    with pytest.raises(TypeError, match='unhashable type'):\n        hash(data)",
                            "def test_hash_pandas_object_works(self, data, as_frame):\n    data = pd.Series(data)\n    if as_frame:\n        data = data.to_frame()\n    a = pd.util.hash_pandas_object(data)\n    b = pd.util.hash_pandas_object(data)\n    self.assert_equal(a, b)",
                            "def test_searchsorted(self, data_for_sorting, as_series):\n    b, c, a = data_for_sorting\n    arr = type(data_for_sorting)._from_sequence([a, b, c])\n    if as_series:\n        arr = pd.Series(arr)\n    assert arr.searchsorted(a) == 0\n    assert arr.searchsorted(a, side='right') == 1\n    assert arr.searchsorted(b) == 1\n    assert arr.searchsorted(b, side='right') == 2\n    assert arr.searchsorted(c) == 2\n    assert arr.searchsorted(c, side='right') == 3\n    result = arr.searchsorted(arr.take([0, 2]))\n    expected = np.array([0, 2], dtype=np.intp)\n    tm.assert_numpy_array_equal(result, expected)\n    sorter = np.array([1, 2, 0])\n    assert data_for_sorting.searchsorted(a, sorter=sorter) == 0",
                            "def test_where_series(self, data, na_value, as_frame):\n    assert data[0] != data[1]\n    cls = type(data)\n    a, b = data[:2]\n    ser = pd.Series(cls._from_sequence([a, a, b, b], dtype=data.dtype))\n    cond = np.array([True, True, False, False])\n    if as_frame:\n        ser = ser.to_frame(name='a')\n        cond = cond.reshape(-1, 1)\n    result = ser.where(cond)\n    expected = pd.Series(cls._from_sequence([a, a, na_value, na_value], dtype=data.dtype))\n    if as_frame:\n        expected = expected.to_frame(name='a')\n    self.assert_equal(result, expected)\n    cond = np.array([True, False, True, True])\n    other = cls._from_sequence([a, b, a, b], dtype=data.dtype)\n    if as_frame:\n        other = pd.DataFrame({'a': other})\n        cond = pd.DataFrame({'a': cond})\n    result = ser.where(cond, other)\n    expected = pd.Series(cls._from_sequence([a, b, b, b], dtype=data.dtype))\n    if as_frame:\n        expected = expected.to_frame(name='a')\n    self.assert_equal(result, expected)",
                            "@pytest.mark.parametrize('repeats', [0, 1, 2, [1, 2, 3]])\ndef test_repeat(self, data, repeats, as_series, use_numpy):\n    arr = type(data)._from_sequence(data[:3], dtype=data.dtype)\n    if as_series:\n        arr = pd.Series(arr)\n    result = np.repeat(arr, repeats) if use_numpy else arr.repeat(repeats)\n    repeats = [repeats] * 3 if isinstance(repeats, int) else repeats\n    expected = [x for x, n in zip(arr, repeats) for _ in range(n)]\n    expected = type(data)._from_sequence(expected, dtype=data.dtype)\n    if as_series:\n        expected = pd.Series(expected, index=arr.index.repeat(repeats))\n    self.assert_equal(result, expected)",
                            "@pytest.mark.parametrize('repeats, kwargs, error, msg', [(2, dict(axis=1), ValueError, \"'axis\"), (-1, dict(), ValueError, 'negative'), ([1, 2], dict(), ValueError, 'shape'), (2, dict(foo='bar'), TypeError, \"'foo'\")])\ndef test_repeat_raises(self, data, repeats, kwargs, error, msg, use_numpy):\n    with pytest.raises(error, match=msg):\n        if use_numpy:\n            np.repeat(data, repeats, **kwargs)\n        else:\n            data.repeat(repeats, **kwargs)"
                        ],
                        "constructor_variables": [],
                        "class_level_variables": [],
                        "class_decorators": [],
                        "function_signatures": [
                            "test_value_counts(self, all_data, dropna)",
                            "test_count(self, data_missing)",
                            "test_series_count(self, data_missing)",
                            "test_apply_simple_series(self, data)",
                            "test_argsort(self, data_for_sorting)",
                            "test_argsort_missing_array(self, data_missing_for_sorting)",
                            "test_argsort_missing(self, data_missing_for_sorting)",
                            "test_nargsort(self, data_missing_for_sorting, na_position, expected)",
                            "test_sort_values(self, data_for_sorting, ascending)",
                            "test_sort_values_missing(self, data_missing_for_sorting, ascending)",
                            "test_sort_values_frame(self, data_for_sorting, ascending)",
                            "test_unique(self, data, box, method)",
                            "test_factorize(self, data_for_grouping, na_sentinel)",
                            "test_factorize_equivalence(self, data_for_grouping, na_sentinel)",
                            "test_factorize_empty(self, data)",
                            "test_fillna_copy_frame(self, data_missing)",
                            "test_fillna_copy_series(self, data_missing)",
                            "test_fillna_length_mismatch(self, data_missing)",
                            "test_combine_le(self, data_repeated)",
                            "test_combine_add(self, data_repeated)",
                            "test_combine_first(self, data)",
                            "test_container_shift(self, data, frame, periods, indices)",
                            "test_diff(self, data, periods)",
                            "test_shift_non_empty_array(self, data, periods, indices)",
                            "test_shift_empty_array(self, data, periods)",
                            "test_shift_fill_value(self, data)",
                            "test_not_hashable(self, data)",
                            "test_hash_pandas_object_works(self, data, as_frame)",
                            "test_searchsorted(self, data_for_sorting, as_series)",
                            "test_where_series(self, data, na_value, as_frame)",
                            "test_repeat(self, data, repeats, as_series, use_numpy)",
                            "test_repeat_raises(self, data, repeats, kwargs, error, msg, use_numpy)"
                        ]
                    },
                    "variable_values": [
                        [
                            {},
                            {}
                        ]
                    ]
                }
            ],
            "inscope_functions": [
                "@pytest.mark.parametrize(\"dropna\", [True, False])\ndef test_value_counts(self, all_data, dropna):\n    all_data = all_data[:10]\n    if dropna:\n        other = np.array(all_data[~all_data.isna()])\n    else:\n        other = all_data\n\n    result = pd.Series(all_data).value_counts(dropna=dropna).sort_index()\n    expected = pd.Series(other).value_counts(dropna=dropna).sort_index()\n\n    self.assert_series_equal(result, expected)",
                "def test_count(self, data_missing):\n    df = pd.DataFrame({\"A\": data_missing})\n    result = df.count(axis=\"columns\")\n    expected = pd.Series([0, 1])\n    self.assert_series_equal(result, expected)",
                "def test_series_count(self, data_missing):\n    # GH#26835\n    ser = pd.Series(data_missing)\n    result = ser.count()\n    expected = 1\n    assert result == expected",
                "def test_apply_simple_series(self, data):\n    result = pd.Series(data).apply(id)\n    assert isinstance(result, pd.Series)",
                "def test_argsort(self, data_for_sorting):\n    result = pd.Series(data_for_sorting).argsort()\n    expected = pd.Series(np.array([2, 0, 1], dtype=np.int64))\n    self.assert_series_equal(result, expected)",
                "def test_argsort_missing_array(self, data_missing_for_sorting):\n    result = data_missing_for_sorting.argsort()\n    expected = np.array([2, 0, 1], dtype=np.dtype(\"int\"))\n    # we don't care whether it's int32 or int64\n    result = result.astype(\"int64\", casting=\"safe\")\n    expected = expected.astype(\"int64\", casting=\"safe\")\n    tm.assert_numpy_array_equal(result, expected)",
                "def test_argsort_missing(self, data_missing_for_sorting):\n    result = pd.Series(data_missing_for_sorting).argsort()\n    expected = pd.Series(np.array([1, -1, 0], dtype=np.int64))\n    self.assert_series_equal(result, expected)",
                "@pytest.mark.parametrize(\n    \"na_position, expected\",\n    [\n        (\"last\", np.array([2, 0, 1], dtype=np.dtype(\"intp\"))),\n        (\"first\", np.array([1, 2, 0], dtype=np.dtype(\"intp\"))),\n    ],\n)\ndef test_nargsort(self, data_missing_for_sorting, na_position, expected):\n    # GH 25439\n    result = nargsort(data_missing_for_sorting, na_position=na_position)\n    tm.assert_numpy_array_equal(result, expected)",
                "@pytest.mark.parametrize(\"ascending\", [True, False])\ndef test_sort_values(self, data_for_sorting, ascending):\n    ser = pd.Series(data_for_sorting)\n    result = ser.sort_values(ascending=ascending)\n    expected = ser.iloc[[2, 0, 1]]\n    if not ascending:\n        expected = expected[::-1]\n\n    self.assert_series_equal(result, expected)",
                "@pytest.mark.parametrize(\"ascending\", [True, False])\ndef test_sort_values_missing(self, data_missing_for_sorting, ascending):\n    ser = pd.Series(data_missing_for_sorting)\n    result = ser.sort_values(ascending=ascending)\n    if ascending:\n        expected = ser.iloc[[2, 0, 1]]\n    else:\n        expected = ser.iloc[[0, 2, 1]]\n    self.assert_series_equal(result, expected)",
                "@pytest.mark.parametrize(\"ascending\", [True, False])\ndef test_sort_values_frame(self, data_for_sorting, ascending):\n    df = pd.DataFrame({\"A\": [1, 2, 1], \"B\": data_for_sorting})\n    result = df.sort_values([\"A\", \"B\"])\n    expected = pd.DataFrame(\n        {\"A\": [1, 1, 2], \"B\": data_for_sorting.take([2, 0, 1])}, index=[2, 0, 1]\n    )\n    self.assert_frame_equal(result, expected)",
                "@pytest.mark.parametrize(\"box\", [pd.Series, lambda x: x])\n@pytest.mark.parametrize(\"method\", [lambda x: x.unique(), pd.unique])\ndef test_unique(self, data, box, method):\n    duplicated = box(data._from_sequence([data[0], data[0]]))\n\n    result = method(duplicated)\n\n    assert len(result) == 1\n    assert isinstance(result, type(data))\n    assert result[0] == duplicated[0]",
                "@pytest.mark.parametrize(\"na_sentinel\", [-1, -2])\ndef test_factorize(self, data_for_grouping, na_sentinel):\n    codes, uniques = pd.factorize(data_for_grouping, na_sentinel=na_sentinel)\n    expected_codes = np.array(\n        [0, 0, na_sentinel, na_sentinel, 1, 1, 0, 2], dtype=np.intp\n    )\n    expected_uniques = data_for_grouping.take([0, 4, 7])\n\n    tm.assert_numpy_array_equal(codes, expected_codes)\n    self.assert_extension_array_equal(uniques, expected_uniques)",
                "@pytest.mark.parametrize(\"na_sentinel\", [-1, -2])\ndef test_factorize_equivalence(self, data_for_grouping, na_sentinel):\n    codes_1, uniques_1 = pd.factorize(data_for_grouping, na_sentinel=na_sentinel)\n    codes_2, uniques_2 = data_for_grouping.factorize(na_sentinel=na_sentinel)\n\n    tm.assert_numpy_array_equal(codes_1, codes_2)\n    self.assert_extension_array_equal(uniques_1, uniques_2)",
                "def test_factorize_empty(self, data):\n    codes, uniques = pd.factorize(data[:0])\n    expected_codes = np.array([], dtype=np.intp)\n    expected_uniques = type(data)._from_sequence([], dtype=data[:0].dtype)\n\n    tm.assert_numpy_array_equal(codes, expected_codes)\n    self.assert_extension_array_equal(uniques, expected_uniques)",
                "def test_fillna_copy_frame(self, data_missing):\n    arr = data_missing.take([1, 1])\n    df = pd.DataFrame({\"A\": arr})\n\n    filled_val = df.iloc[0, 0]\n    result = df.fillna(filled_val)\n\n    assert df.A.values is not result.A.values",
                "def test_fillna_copy_series(self, data_missing):\n    arr = data_missing.take([1, 1])\n    ser = pd.Series(arr)\n\n    filled_val = ser[0]\n    result = ser.fillna(filled_val)\n\n    assert ser._values is not result._values\n    assert ser._values is arr",
                "def test_fillna_length_mismatch(self, data_missing):\n    msg = \"Length of 'value' does not match.\"\n    with pytest.raises(ValueError, match=msg):\n        data_missing.fillna(data_missing.take([1]))",
                "def test_combine_le(self, data_repeated):\n    # GH 20825\n    # Test that combine works when doing a <= (le) comparison\n    orig_data1, orig_data2 = data_repeated(2)\n    s1 = pd.Series(orig_data1)\n    s2 = pd.Series(orig_data2)\n    result = s1.combine(s2, lambda x1, x2: x1 <= x2)\n    expected = pd.Series(\n        [a <= b for (a, b) in zip(list(orig_data1), list(orig_data2))]\n    )\n    self.assert_series_equal(result, expected)\n\n    val = s1.iloc[0]\n    result = s1.combine(val, lambda x1, x2: x1 <= x2)\n    expected = pd.Series([a <= val for a in list(orig_data1)])\n    self.assert_series_equal(result, expected)",
                "def test_combine_add(self, data_repeated):\n    # GH 20825\n    orig_data1, orig_data2 = data_repeated(2)\n    s1 = pd.Series(orig_data1)\n    s2 = pd.Series(orig_data2)\n    result = s1.combine(s2, lambda x1, x2: x1 + x2)\n    with np.errstate(over=\"ignore\"):\n        expected = pd.Series(\n            orig_data1._from_sequence(\n                [a + b for (a, b) in zip(list(orig_data1), list(orig_data2))]\n            )\n        )\n    self.assert_series_equal(result, expected)\n\n    val = s1.iloc[0]\n    result = s1.combine(val, lambda x1, x2: x1 + x2)\n    expected = pd.Series(\n        orig_data1._from_sequence([a + val for a in list(orig_data1)])\n    )\n    self.assert_series_equal(result, expected)",
                "def test_combine_first(self, data):\n    # https://github.com/pandas-dev/pandas/issues/24147\n    a = pd.Series(data[:3])\n    b = pd.Series(data[2:5], index=[2, 3, 4])\n    result = a.combine_first(b)\n    expected = pd.Series(data[:5])\n    self.assert_series_equal(result, expected)",
                "@pytest.mark.parametrize(\"frame\", [True, False])\n@pytest.mark.parametrize(\n    \"periods, indices\",\n    [(-2, [2, 3, 4, -1, -1]), (0, [0, 1, 2, 3, 4]), (2, [-1, -1, 0, 1, 2])],\n)\ndef test_container_shift(self, data, frame, periods, indices):\n    # https://github.com/pandas-dev/pandas/issues/22386\n    subset = data[:5]\n    data = pd.Series(subset, name=\"A\")\n    expected = pd.Series(subset.take(indices, allow_fill=True), name=\"A\")\n\n    if frame:\n        result = data.to_frame(name=\"A\").assign(B=1).shift(periods)\n        expected = pd.concat(\n            [expected, pd.Series([1] * 5, name=\"B\").shift(periods)], axis=1\n        )\n        compare = self.assert_frame_equal\n    else:\n        result = data.shift(periods)\n        compare = self.assert_series_equal\n\n    compare(result, expected)",
                "@pytest.mark.parametrize(\"periods\", [1, -2])\ndef test_diff(self, data, periods):\n    data = data[:5]\n    if is_bool_dtype(data.dtype):\n        op = operator.xor\n    else:\n        op = operator.sub\n    try:\n        # does this array implement ops?\n        op(data, data)\n    except Exception:\n        pytest.skip(f\"{type(data)} does not support diff\")\n    s = pd.Series(data)\n    result = s.diff(periods)\n    expected = pd.Series(op(data, data.shift(periods)))\n    self.assert_series_equal(result, expected)\n\n    df = pd.DataFrame({\"A\": data, \"B\": [1.0] * 5})\n    result = df.diff(periods)\n    if periods == 1:\n        b = [np.nan, 0, 0, 0, 0]\n    else:\n        b = [0, 0, 0, np.nan, np.nan]\n    expected = pd.DataFrame({\"A\": expected, \"B\": b})\n    self.assert_frame_equal(result, expected)",
                "@pytest.mark.parametrize(\n    \"periods, indices\",\n    [[-4, [-1, -1]], [-1, [1, -1]], [0, [0, 1]], [1, [-1, 0]], [4, [-1, -1]]],\n)\ndef test_shift_non_empty_array(self, data, periods, indices):\n    # https://github.com/pandas-dev/pandas/issues/23911\n    subset = data[:2]\n    result = subset.shift(periods)\n    expected = subset.take(indices, allow_fill=True)\n    self.assert_extension_array_equal(result, expected)",
                "@pytest.mark.parametrize(\"periods\", [-4, -1, 0, 1, 4])\ndef test_shift_empty_array(self, data, periods):\n    # https://github.com/pandas-dev/pandas/issues/23911\n    empty = data[:0]\n    result = empty.shift(periods)\n    expected = empty\n    self.assert_extension_array_equal(result, expected)",
                "def test_shift_fill_value(self, data):\n    arr = data[:4]\n    fill_value = data[0]\n    result = arr.shift(1, fill_value=fill_value)\n    expected = data.take([0, 0, 1, 2])\n    self.assert_extension_array_equal(result, expected)\n\n    result = arr.shift(-2, fill_value=fill_value)\n    expected = data.take([2, 3, 0, 0])\n    self.assert_extension_array_equal(result, expected)",
                "def test_not_hashable(self, data):\n    # We are in general mutable, so not hashable\n    with pytest.raises(TypeError, match=\"unhashable type\"):\n        hash(data)",
                "def test_hash_pandas_object_works(self, data, as_frame):\n    # https://github.com/pandas-dev/pandas/issues/23066\n    data = pd.Series(data)\n    if as_frame:\n        data = data.to_frame()\n    a = pd.util.hash_pandas_object(data)\n    b = pd.util.hash_pandas_object(data)\n    self.assert_equal(a, b)",
                "def test_searchsorted(self, data_for_sorting, as_series):\n    b, c, a = data_for_sorting\n    arr = type(data_for_sorting)._from_sequence([a, b, c])\n\n    if as_series:\n        arr = pd.Series(arr)\n    assert arr.searchsorted(a) == 0\n    assert arr.searchsorted(a, side=\"right\") == 1\n\n    assert arr.searchsorted(b) == 1\n    assert arr.searchsorted(b, side=\"right\") == 2\n\n    assert arr.searchsorted(c) == 2\n    assert arr.searchsorted(c, side=\"right\") == 3\n\n    result = arr.searchsorted(arr.take([0, 2]))\n    expected = np.array([0, 2], dtype=np.intp)\n\n    tm.assert_numpy_array_equal(result, expected)\n\n    # sorter\n    sorter = np.array([1, 2, 0])\n    assert data_for_sorting.searchsorted(a, sorter=sorter) == 0",
                "def test_where_series(self, data, na_value, as_frame):\n    assert data[0] != data[1]\n    cls = type(data)\n    a, b = data[:2]\n\n    ser = pd.Series(cls._from_sequence([a, a, b, b], dtype=data.dtype))\n    cond = np.array([True, True, False, False])\n\n    if as_frame:\n        ser = ser.to_frame(name=\"a\")\n        cond = cond.reshape(-1, 1)\n\n    result = ser.where(cond)\n    expected = pd.Series(\n        cls._from_sequence([a, a, na_value, na_value], dtype=data.dtype)\n    )\n\n    if as_frame:\n        expected = expected.to_frame(name=\"a\")\n    self.assert_equal(result, expected)\n\n    # array other\n    cond = np.array([True, False, True, True])\n    other = cls._from_sequence([a, b, a, b], dtype=data.dtype)\n    if as_frame:\n        other = pd.DataFrame({\"a\": other})\n        cond = pd.DataFrame({\"a\": cond})\n    result = ser.where(cond, other)\n    expected = pd.Series(cls._from_sequence([a, b, b, b], dtype=data.dtype))\n    if as_frame:\n        expected = expected.to_frame(name=\"a\")\n    self.assert_equal(result, expected)",
                "@pytest.mark.parametrize(\"repeats\", [0, 1, 2, [1, 2, 3]])\ndef test_repeat(self, data, repeats, as_series, use_numpy):\n    arr = type(data)._from_sequence(data[:3], dtype=data.dtype)\n    if as_series:\n        arr = pd.Series(arr)\n\n    result = np.repeat(arr, repeats) if use_numpy else arr.repeat(repeats)\n\n    repeats = [repeats] * 3 if isinstance(repeats, int) else repeats\n    expected = [x for x, n in zip(arr, repeats) for _ in range(n)]\n    expected = type(data)._from_sequence(expected, dtype=data.dtype)\n    if as_series:\n        expected = pd.Series(expected, index=arr.index.repeat(repeats))\n\n    self.assert_equal(result, expected)",
                "@pytest.mark.parametrize(\n    \"repeats, kwargs, error, msg\",\n    [\n        (2, dict(axis=1), ValueError, \"'axis\"),\n        (-1, dict(), ValueError, \"negative\"),\n        ([1, 2], dict(), ValueError, \"shape\"),\n        (2, dict(foo=\"bar\"), TypeError, \"'foo'\"),\n    ],\n)\ndef test_repeat_raises(self, data, repeats, kwargs, error, msg, use_numpy):\n    with pytest.raises(error, match=msg):\n        if use_numpy:\n            np.repeat(data, repeats, **kwargs)\n        else:\n            data.repeat(repeats, **kwargs)"
            ],
            "inscope_function_signatures": [
                "test_value_counts(self, all_data, dropna)",
                "test_count(self, data_missing)",
                "test_series_count(self, data_missing)",
                "test_apply_simple_series(self, data)",
                "test_argsort(self, data_for_sorting)",
                "test_argsort_missing_array(self, data_missing_for_sorting)",
                "test_argsort_missing(self, data_missing_for_sorting)",
                "test_nargsort(self, data_missing_for_sorting, na_position, expected)",
                "test_sort_values(self, data_for_sorting, ascending)",
                "test_sort_values_missing(self, data_missing_for_sorting, ascending)",
                "test_sort_values_frame(self, data_for_sorting, ascending)",
                "test_unique(self, data, box, method)",
                "test_factorize(self, data_for_grouping, na_sentinel)",
                "test_factorize_equivalence(self, data_for_grouping, na_sentinel)",
                "test_factorize_empty(self, data)",
                "test_fillna_copy_frame(self, data_missing)",
                "test_fillna_copy_series(self, data_missing)",
                "test_fillna_length_mismatch(self, data_missing)",
                "test_combine_le(self, data_repeated)",
                "test_combine_add(self, data_repeated)",
                "test_combine_first(self, data)",
                "test_container_shift(self, data, frame, periods, indices)",
                "test_diff(self, data, periods)",
                "test_shift_non_empty_array(self, data, periods, indices)",
                "test_shift_empty_array(self, data, periods)",
                "test_shift_fill_value(self, data)",
                "test_not_hashable(self, data)",
                "test_hash_pandas_object_works(self, data, as_frame)",
                "test_searchsorted(self, data_for_sorting, as_series)",
                "test_where_series(self, data, na_value, as_frame)",
                "test_repeat(self, data, repeats, as_series, use_numpy)",
                "test_repeat_raises(self, data, repeats, kwargs, error, msg, use_numpy)"
            ],
            "variables_in_file": {
                "BaseExtensionTests": [
                    15
                ],
                "all_data": [
                    24,
                    26,
                    20,
                    22
                ],
                "dropna": [
                    26,
                    27,
                    21
                ],
                "other": [
                    355,
                    357,
                    359,
                    22,
                    24,
                    27
                ],
                "np.array": [
                    354,
                    324,
                    69,
                    70,
                    329,
                    139,
                    50,
                    338,
                    22,
                    55,
                    121,
                    63
                ],
                "np": [
                    192,
                    258,
                    354,
                    260,
                    69,
                    70,
                    324,
                    329,
                    393,
                    139,
                    50,
                    338,
                    371,
                    22,
                    55,
                    121,
                    122,
                    63
                ],
                "all_data.isna": [
                    22
                ],
                "result": [
                    256,
                    262,
                    271,
                    273,
                    150,
                    279,
                    152,
                    281,
                    26,
                    29,
                    286,
                    159,
                    288,
                    33,
                    161,
                    35,
                    290,
                    292,
                    40,
                    42,
                    45,
                    46,
                    175,
                    49,
                    51,
                    179,
                    54,
                    182,
                    184,
                    57,
                    59,
                    62,
                    191,
                    64,
                    323,
                    198,
                    326,
                    201,
                    75,
                    76,
                    205,
                    81,
                    211,
                    213,
                    86,
                    344,
                    91,
                    351,
                    96,
                    227,
                    101,
                    359,
                    105,
                    233,
                    363,
                    236,
                    112,
                    114,
                    115,
                    116,
                    371,
                    379,
                    251,
                    253
                ],
                "sort_index": [
                    26,
                    27
                ],
                "value_counts": [
                    26,
                    27
                ],
                "pd.Series": [
                    26,
                    27,
                    156,
                    34,
                    39,
                    45,
                    46,
                    173,
                    174,
                    49,
                    50,
                    176,
                    301,
                    183,
                    313,
                    189,
                    62,
                    63,
                    190,
                    193,
                    202,
                    80,
                    209,
                    210,
                    337,
                    212,
                    345,
                    90,
                    223,
                    224,
                    229,
                    360,
                    107,
                    369,
                    377,
                    250,
                    252
                ],
                "pd": [
                    131,
                    261,
                    138,
                    147,
                    26,
                    27,
                    156,
                    32,
                    34,
                    39,
                    45,
                    46,
                    173,
                    174,
                    49,
                    50,
                    176,
                    301,
                    304,
                    305,
                    183,
                    313,
                    189,
                    62,
                    63,
                    190,
                    193,
                    202,
                    80,
                    209,
                    210,
                    337,
                    212,
                    345,
                    90,
                    223,
                    224,
                    100,
                    228,
                    102,
                    229,
                    357,
                    358,
                    360,
                    107,
                    108,
                    369,
                    120,
                    377,
                    250,
                    252,
                    255
                ],
                "expected": [
                    261,
                    262,
                    272,
                    273,
                    280,
                    281,
                    27,
                    29,
                    287,
                    288,
                    34,
                    35,
                    291,
                    292,
                    41,
                    42,
                    176,
                    50,
                    51,
                    179,
                    55,
                    183,
                    184,
                    58,
                    59,
                    63,
                    64,
                    193,
                    324,
                    198,
                    326,
                    202,
                    76,
                    205,
                    82,
                    84,
                    212,
                    86,
                    213,
                    345,
                    93,
                    350,
                    95,
                    96,
                    224,
                    351,
                    228,
                    229,
                    102,
                    360,
                    105,
                    362,
                    363,
                    236,
                    374,
                    375,
                    377,
                    379,
                    252,
                    253
                ],
                "self.assert_series_equal": [
                    64,
                    96,
                    35,
                    198,
                    234,
                    205,
                    51,
                    179,
                    213,
                    86,
                    184,
                    253,
                    29
                ],
                "self": [
                    262,
                    135,
                    143,
                    273,
                    281,
                    29,
                    288,
                    35,
                    292,
                    306,
                    51,
                    179,
                    184,
                    64,
                    198,
                    205,
                    213,
                    86,
                    351,
                    96,
                    231,
                    105,
                    234,
                    363,
                    379,
                    253,
                    127
                ],
                "pytest.mark.parametrize": [
                    129,
                    66,
                    98,
                    264,
                    107,
                    108,
                    365,
                    78,
                    238,
                    18,
                    275,
                    118,
                    215,
                    88,
                    381,
                    216
                ],
                "pytest.mark": [
                    129,
                    66,
                    98,
                    264,
                    107,
                    108,
                    365,
                    78,
                    238,
                    18,
                    275,
                    118,
                    215,
                    88,
                    381,
                    216
                ],
                "pytest": [
                    129,
                    391,
                    264,
                    18,
                    275,
                    166,
                    296,
                    66,
                    78,
                    215,
                    88,
                    216,
                    98,
                    107,
                    108,
                    365,
                    238,
                    118,
                    249,
                    381
                ],
                "df": [
                    32,
                    33,
                    256,
                    100,
                    101,
                    147,
                    149,
                    150,
                    152,
                    255
                ],
                "pd.DataFrame": [
                    32,
                    100,
                    261,
                    102,
                    357,
                    358,
                    147,
                    255
                ],
                "data_missing": [
                    32,
                    167,
                    39,
                    146,
                    155
                ],
                "df.count": [
                    33
                ],
                "ser": [
                    159,
                    161,
                    162,
                    39,
                    40,
                    359,
                    80,
                    81,
                    82,
                    337,
                    341,
                    344,
                    90,
                    91,
                    156,
                    93,
                    158,
                    95
                ],
                "ser.count": [
                    40
                ],
                "apply": [
                    45
                ],
                "data": [
                    393,
                    138,
                    395,
                    140,
                    270,
                    278,
                    284,
                    285,
                    287,
                    291,
                    297,
                    45,
                    301,
                    303,
                    304,
                    305,
                    333,
                    334,
                    335,
                    209,
                    210,
                    337,
                    212,
                    346,
                    222,
                    223,
                    375,
                    227,
                    355,
                    360,
                    233,
                    110,
                    367,
                    240,
                    241,
                    115,
                    247,
                    249,
                    250,
                    252,
                    255
                ],
                "id": [
                    45
                ],
                "isinstance": [
                    115,
                    373,
                    46
                ],
                "argsort": [
                    49,
                    62
                ],
                "data_for_sorting": [
                    100,
                    103,
                    330,
                    80,
                    49,
                    309,
                    310
                ],
                "np.int64": [
                    50,
                    63
                ],
                "data_missing_for_sorting.argsort": [
                    54
                ],
                "data_missing_for_sorting": [
                    62,
                    90,
                    75,
                    54
                ],
                "np.dtype": [
                    69,
                    70,
                    55
                ],
                "result.astype": [
                    57
                ],
                "expected.astype": [
                    58
                ],
                "tm.assert_numpy_array_equal": [
                    134,
                    326,
                    76,
                    142,
                    59,
                    126
                ],
                "tm": [
                    134,
                    326,
                    76,
                    142,
                    59,
                    126
                ],
                "nargsort": [
                    75
                ],
                "na_position": [
                    75
                ],
                "ser.sort_values": [
                    81,
                    91
                ],
                "ascending": [
                    81,
                    91,
                    83,
                    92
                ],
                "ser.iloc": [
                    82,
                    93,
                    95
                ],
                "df.sort_values": [
                    101
                ],
                "data_for_sorting.take": [
                    103
                ],
                "self.assert_frame_equal": [
                    105,
                    262,
                    231
                ],
                "duplicated": [
                    112,
                    116,
                    110
                ],
                "box": [
                    110
                ],
                "data._from_sequence": [
                    110
                ],
                "method": [
                    112
                ],
                "len": [
                    114
                ],
                "type": [
                    140,
                    334,
                    367,
                    115,
                    310,
                    375,
                    249
                ],
                "x": [
                    107,
                    108,
                    374
                ],
                "x.unique": [
                    108
                ],
                "pd.unique": [
                    108
                ],
                "codes": [
                    120,
                    138,
                    142,
                    126
                ],
                "uniques": [
                    120,
                    143,
                    138,
                    127
                ],
                "pd.factorize": [
                    120,
                    138,
                    131
                ],
                "data_for_grouping": [
                    120,
                    132,
                    131,
                    124
                ],
                "na_sentinel": [
                    120,
                    122,
                    131,
                    132
                ],
                "expected_codes": [
                    142,
                    121,
                    139,
                    126
                ],
                "np.intp": [
                    122,
                    139,
                    324
                ],
                "expected_uniques": [
                    143,
                    140,
                    124,
                    127
                ],
                "data_for_grouping.take": [
                    124
                ],
                "self.assert_extension_array_equal": [
                    288,
                    292,
                    135,
                    143,
                    273,
                    281,
                    127
                ],
                "codes_1": [
                    131,
                    134
                ],
                "uniques_1": [
                    131,
                    135
                ],
                "codes_2": [
                    132,
                    134
                ],
                "uniques_2": [
                    132,
                    135
                ],
                "data_for_grouping.factorize": [
                    132
                ],
                "_from_sequence": [
                    140,
                    375,
                    310,
                    367
                ],
                "dtype": [
                    140
                ],
                "arr": [
                    146,
                    147,
                    155,
                    284,
                    156,
                    286,
                    162,
                    290,
                    310,
                    313,
                    314,
                    315,
                    317,
                    318,
                    320,
                    321,
                    323,
                    367,
                    369,
                    371,
                    374,
                    377
                ],
                "data_missing.take": [
                    146,
                    155,
                    167
                ],
                "filled_val": [
                    158,
                    149,
                    150,
                    159
                ],
                "df.iloc": [
                    149
                ],
                "df.fillna": [
                    150
                ],
                "df.A.values": [
                    152
                ],
                "df.A": [
                    152
                ],
                "result.A.values": [
                    152
                ],
                "result.A": [
                    152
                ],
                "ser.fillna": [
                    159
                ],
                "ser._values": [
                    161,
                    162
                ],
                "result._values": [
                    161
                ],
                "msg": [
                    165,
                    166,
                    391
                ],
                "pytest.raises": [
                    296,
                    166,
                    391
                ],
                "ValueError": [
                    384,
                    385,
                    386,
                    166
                ],
                "data_missing.fillna": [
                    167
                ],
                "orig_data1": [
                    194,
                    195,
                    203,
                    172,
                    173,
                    177,
                    183,
                    188,
                    189
                ],
                "orig_data2": [
                    195,
                    172,
                    174,
                    177,
                    188,
                    190
                ],
                "data_repeated": [
                    188,
                    172
                ],
                "s1": [
                    200,
                    201,
                    173,
                    175,
                    181,
                    182,
                    189,
                    191
                ],
                "s2": [
                    191,
                    190,
                    174,
                    175
                ],
                "s1.combine": [
                    191,
                    201,
                    182,
                    175
                ],
                "x1": [
                    191,
                    201,
                    182,
                    175
                ],
                "x2": [
                    191,
                    201,
                    182,
                    175
                ],
                "a": [
                    195,
                    355,
                    360,
                    330,
                    203,
                    346,
                    335,
                    304,
                    177,
                    209,
                    211,
                    306,
                    309,
                    310,
                    183,
                    337,
                    314,
                    315
                ],
                "b": [
                    258,
                    195,
                    260,
                    261,
                    355,
                    360,
                    335,
                    177,
                    210,
                    211,
                    305,
                    306,
                    309,
                    310,
                    337,
                    317,
                    318
                ],
                "zip": [
                    177,
                    195,
                    374
                ],
                "list": [
                    177,
                    195,
                    203,
                    183
                ],
                "val": [
                    200,
                    201,
                    203,
                    181,
                    182,
                    183
                ],
                "s1.iloc": [
                    200,
                    181
                ],
                "np.errstate": [
                    192
                ],
                "orig_data1._from_sequence": [
                    194,
                    203
                ],
                "a.combine_first": [
                    211
                ],
                "subset": [
                    224,
                    270,
                    271,
                    272,
                    222,
                    223
                ],
                "subset.take": [
                    224,
                    272
                ],
                "indices": [
                    224,
                    272
                ],
                "frame": [
                    226
                ],
                "shift": [
                    227,
                    229
                ],
                "assign": [
                    227
                ],
                "data.to_frame": [
                    227,
                    303
                ],
                "periods": [
                    256,
                    257,
                    227,
                    229,
                    233,
                    271,
                    279,
                    251,
                    252
                ],
                "pd.concat": [
                    228
                ],
                "compare": [
                    234,
                    236,
                    231
                ],
                "data.shift": [
                    233,
                    252
                ],
                "is_bool_dtype": [
                    241
                ],
                "data.dtype": [
                    355,
                    360,
                    367,
                    337,
                    241,
                    375,
                    346
                ],
                "op": [
                    242,
                    244,
                    252,
                    247
                ],
                "operator.xor": [
                    242
                ],
                "operator": [
                    242,
                    244
                ],
                "operator.sub": [
                    244
                ],
                "Exception": [
                    248
                ],
                "pytest.skip": [
                    249
                ],
                "s": [
                    250,
                    251
                ],
                "s.diff": [
                    251
                ],
                "df.diff": [
                    256
                ],
                "np.nan": [
                    258,
                    260
                ],
                "subset.shift": [
                    271
                ],
                "empty": [
                    280,
                    278,
                    279
                ],
                "empty.shift": [
                    279
                ],
                "fill_value": [
                    290,
                    285,
                    286
                ],
                "arr.shift": [
                    290,
                    286
                ],
                "data.take": [
                    291,
                    287
                ],
                "TypeError": [
                    296,
                    387
                ],
                "hash": [
                    297
                ],
                "as_frame": [
                    356,
                    361,
                    302,
                    340,
                    349
                ],
                "pd.util.hash_pandas_object": [
                    304,
                    305
                ],
                "pd.util": [
                    304,
                    305
                ],
                "self.assert_equal": [
                    379,
                    306,
                    363,
                    351
                ],
                "c": [
                    320,
                    321,
                    309,
                    310
                ],
                "as_series": [
                    312,
                    368,
                    376
                ],
                "arr.searchsorted": [
                    320,
                    321,
                    323,
                    314,
                    315,
                    317,
                    318
                ],
                "arr.take": [
                    323
                ],
                "sorter": [
                    329,
                    330
                ],
                "data_for_sorting.searchsorted": [
                    330
                ],
                "cls": [
                    355,
                    360,
                    334,
                    337,
                    346
                ],
                "cls._from_sequence": [
                    360,
                    337,
                    346,
                    355
                ],
                "cond": [
                    354,
                    358,
                    359,
                    338,
                    342,
                    344
                ],
                "ser.to_frame": [
                    341
                ],
                "cond.reshape": [
                    342
                ],
                "ser.where": [
                    344,
                    359
                ],
                "na_value": [
                    346
                ],
                "expected.to_frame": [
                    362,
                    350
                ],
                "use_numpy": [
                    392,
                    371
                ],
                "np.repeat": [
                    393,
                    371
                ],
                "repeats": [
                    393,
                    395,
                    371,
                    373,
                    374,
                    377
                ],
                "arr.repeat": [
                    371
                ],
                "int": [
                    373
                ],
                "n": [
                    374
                ],
                "_": [
                    374
                ],
                "range": [
                    374
                ],
                "arr.index.repeat": [
                    377
                ],
                "arr.index": [
                    377
                ],
                "error": [
                    391
                ],
                "kwargs": [
                    393,
                    395
                ],
                "data.repeat": [
                    395
                ],
                "dict": [
                    384,
                    385,
                    386,
                    387
                ]
            },
            "filtered_variables_in_file": {
                "BaseExtensionTests": [
                    15
                ],
                "all_data": [
                    24,
                    26,
                    20,
                    22
                ],
                "dropna": [
                    26,
                    27,
                    21
                ],
                "other": [
                    355,
                    357,
                    359,
                    22,
                    24,
                    27
                ],
                "np.array": [
                    354,
                    324,
                    69,
                    70,
                    329,
                    139,
                    50,
                    338,
                    22,
                    55,
                    121,
                    63
                ],
                "np": [
                    192,
                    258,
                    354,
                    260,
                    69,
                    70,
                    324,
                    329,
                    393,
                    139,
                    50,
                    338,
                    371,
                    22,
                    55,
                    121,
                    122,
                    63
                ],
                "all_data.isna": [
                    22
                ],
                "result": [
                    256,
                    262,
                    271,
                    273,
                    150,
                    279,
                    152,
                    281,
                    26,
                    29,
                    286,
                    159,
                    288,
                    33,
                    161,
                    35,
                    290,
                    292,
                    40,
                    42,
                    45,
                    46,
                    175,
                    49,
                    51,
                    179,
                    54,
                    182,
                    184,
                    57,
                    59,
                    62,
                    191,
                    64,
                    323,
                    198,
                    326,
                    201,
                    75,
                    76,
                    205,
                    81,
                    211,
                    213,
                    86,
                    344,
                    91,
                    351,
                    96,
                    227,
                    101,
                    359,
                    105,
                    233,
                    363,
                    236,
                    112,
                    114,
                    115,
                    116,
                    371,
                    379,
                    251,
                    253
                ],
                "sort_index": [
                    26,
                    27
                ],
                "value_counts": [
                    26,
                    27
                ],
                "pd.Series": [
                    26,
                    27,
                    156,
                    34,
                    39,
                    45,
                    46,
                    173,
                    174,
                    49,
                    50,
                    176,
                    301,
                    183,
                    313,
                    189,
                    62,
                    63,
                    190,
                    193,
                    202,
                    80,
                    209,
                    210,
                    337,
                    212,
                    345,
                    90,
                    223,
                    224,
                    229,
                    360,
                    107,
                    369,
                    377,
                    250,
                    252
                ],
                "pd": [
                    131,
                    261,
                    138,
                    147,
                    26,
                    27,
                    156,
                    32,
                    34,
                    39,
                    45,
                    46,
                    173,
                    174,
                    49,
                    50,
                    176,
                    301,
                    304,
                    305,
                    183,
                    313,
                    189,
                    62,
                    63,
                    190,
                    193,
                    202,
                    80,
                    209,
                    210,
                    337,
                    212,
                    345,
                    90,
                    223,
                    224,
                    100,
                    228,
                    102,
                    229,
                    357,
                    358,
                    360,
                    107,
                    108,
                    369,
                    120,
                    377,
                    250,
                    252,
                    255
                ],
                "expected": [
                    261,
                    262,
                    272,
                    273,
                    280,
                    281,
                    27,
                    29,
                    287,
                    288,
                    34,
                    35,
                    291,
                    292,
                    41,
                    42,
                    176,
                    50,
                    51,
                    179,
                    55,
                    183,
                    184,
                    58,
                    59,
                    63,
                    64,
                    193,
                    324,
                    198,
                    326,
                    202,
                    76,
                    205,
                    82,
                    84,
                    212,
                    86,
                    213,
                    345,
                    93,
                    350,
                    95,
                    96,
                    224,
                    351,
                    228,
                    229,
                    102,
                    360,
                    105,
                    362,
                    363,
                    236,
                    374,
                    375,
                    377,
                    379,
                    252,
                    253
                ],
                "self.assert_series_equal": [
                    64,
                    96,
                    35,
                    198,
                    234,
                    205,
                    51,
                    179,
                    213,
                    86,
                    184,
                    253,
                    29
                ],
                "self": [
                    262,
                    135,
                    143,
                    273,
                    281,
                    29,
                    288,
                    35,
                    292,
                    306,
                    51,
                    179,
                    184,
                    64,
                    198,
                    205,
                    213,
                    86,
                    351,
                    96,
                    231,
                    105,
                    234,
                    363,
                    379,
                    253,
                    127
                ],
                "pytest.mark.parametrize": [
                    129,
                    66,
                    98,
                    264,
                    107,
                    108,
                    365,
                    78,
                    238,
                    18,
                    275,
                    118,
                    215,
                    88,
                    381,
                    216
                ],
                "pytest.mark": [
                    129,
                    66,
                    98,
                    264,
                    107,
                    108,
                    365,
                    78,
                    238,
                    18,
                    275,
                    118,
                    215,
                    88,
                    381,
                    216
                ],
                "pytest": [
                    129,
                    391,
                    264,
                    18,
                    275,
                    166,
                    296,
                    66,
                    78,
                    215,
                    88,
                    216,
                    98,
                    107,
                    108,
                    365,
                    238,
                    118,
                    249,
                    381
                ],
                "df": [
                    32,
                    33,
                    256,
                    100,
                    101,
                    147,
                    149,
                    150,
                    152,
                    255
                ],
                "pd.DataFrame": [
                    32,
                    100,
                    261,
                    102,
                    357,
                    358,
                    147,
                    255
                ],
                "data_missing": [
                    32,
                    167,
                    39,
                    146,
                    155
                ],
                "df.count": [
                    33
                ],
                "ser": [
                    159,
                    161,
                    162,
                    39,
                    40,
                    359,
                    80,
                    81,
                    82,
                    337,
                    341,
                    344,
                    90,
                    91,
                    156,
                    93,
                    158,
                    95
                ],
                "ser.count": [
                    40
                ],
                "apply": [
                    45
                ],
                "data": [
                    393,
                    138,
                    395,
                    140,
                    270,
                    278,
                    284,
                    285,
                    287,
                    291,
                    297,
                    45,
                    301,
                    303,
                    304,
                    305,
                    333,
                    334,
                    335,
                    209,
                    210,
                    337,
                    212,
                    346,
                    222,
                    223,
                    375,
                    227,
                    355,
                    360,
                    233,
                    110,
                    367,
                    240,
                    241,
                    115,
                    247,
                    249,
                    250,
                    252,
                    255
                ],
                "argsort": [
                    49,
                    62
                ],
                "data_for_sorting": [
                    100,
                    103,
                    330,
                    80,
                    49,
                    309,
                    310
                ],
                "np.int64": [
                    50,
                    63
                ],
                "data_missing_for_sorting.argsort": [
                    54
                ],
                "data_missing_for_sorting": [
                    62,
                    90,
                    75,
                    54
                ],
                "np.dtype": [
                    69,
                    70,
                    55
                ],
                "result.astype": [
                    57
                ],
                "expected.astype": [
                    58
                ],
                "tm.assert_numpy_array_equal": [
                    134,
                    326,
                    76,
                    142,
                    59,
                    126
                ],
                "tm": [
                    134,
                    326,
                    76,
                    142,
                    59,
                    126
                ],
                "nargsort": [
                    75
                ],
                "na_position": [
                    75
                ],
                "ser.sort_values": [
                    81,
                    91
                ],
                "ascending": [
                    81,
                    91,
                    83,
                    92
                ],
                "ser.iloc": [
                    82,
                    93,
                    95
                ],
                "df.sort_values": [
                    101
                ],
                "data_for_sorting.take": [
                    103
                ],
                "self.assert_frame_equal": [
                    105,
                    262,
                    231
                ],
                "duplicated": [
                    112,
                    116,
                    110
                ],
                "box": [
                    110
                ],
                "data._from_sequence": [
                    110
                ],
                "method": [
                    112
                ],
                "x": [
                    107,
                    108,
                    374
                ],
                "x.unique": [
                    108
                ],
                "pd.unique": [
                    108
                ],
                "codes": [
                    120,
                    138,
                    142,
                    126
                ],
                "uniques": [
                    120,
                    143,
                    138,
                    127
                ],
                "pd.factorize": [
                    120,
                    138,
                    131
                ],
                "data_for_grouping": [
                    120,
                    132,
                    131,
                    124
                ],
                "na_sentinel": [
                    120,
                    122,
                    131,
                    132
                ],
                "expected_codes": [
                    142,
                    121,
                    139,
                    126
                ],
                "np.intp": [
                    122,
                    139,
                    324
                ],
                "expected_uniques": [
                    143,
                    140,
                    124,
                    127
                ],
                "data_for_grouping.take": [
                    124
                ],
                "self.assert_extension_array_equal": [
                    288,
                    292,
                    135,
                    143,
                    273,
                    281,
                    127
                ],
                "codes_1": [
                    131,
                    134
                ],
                "uniques_1": [
                    131,
                    135
                ],
                "codes_2": [
                    132,
                    134
                ],
                "uniques_2": [
                    132,
                    135
                ],
                "data_for_grouping.factorize": [
                    132
                ],
                "_from_sequence": [
                    140,
                    375,
                    310,
                    367
                ],
                "dtype": [
                    140
                ],
                "arr": [
                    146,
                    147,
                    155,
                    284,
                    156,
                    286,
                    162,
                    290,
                    310,
                    313,
                    314,
                    315,
                    317,
                    318,
                    320,
                    321,
                    323,
                    367,
                    369,
                    371,
                    374,
                    377
                ],
                "data_missing.take": [
                    146,
                    155,
                    167
                ],
                "filled_val": [
                    158,
                    149,
                    150,
                    159
                ],
                "df.iloc": [
                    149
                ],
                "df.fillna": [
                    150
                ],
                "df.A.values": [
                    152
                ],
                "df.A": [
                    152
                ],
                "result.A.values": [
                    152
                ],
                "result.A": [
                    152
                ],
                "ser.fillna": [
                    159
                ],
                "ser._values": [
                    161,
                    162
                ],
                "result._values": [
                    161
                ],
                "msg": [
                    165,
                    166,
                    391
                ],
                "pytest.raises": [
                    296,
                    166,
                    391
                ],
                "data_missing.fillna": [
                    167
                ],
                "orig_data1": [
                    194,
                    195,
                    203,
                    172,
                    173,
                    177,
                    183,
                    188,
                    189
                ],
                "orig_data2": [
                    195,
                    172,
                    174,
                    177,
                    188,
                    190
                ],
                "data_repeated": [
                    188,
                    172
                ],
                "s1": [
                    200,
                    201,
                    173,
                    175,
                    181,
                    182,
                    189,
                    191
                ],
                "s2": [
                    191,
                    190,
                    174,
                    175
                ],
                "s1.combine": [
                    191,
                    201,
                    182,
                    175
                ],
                "x1": [
                    191,
                    201,
                    182,
                    175
                ],
                "x2": [
                    191,
                    201,
                    182,
                    175
                ],
                "a": [
                    195,
                    355,
                    360,
                    330,
                    203,
                    346,
                    335,
                    304,
                    177,
                    209,
                    211,
                    306,
                    309,
                    310,
                    183,
                    337,
                    314,
                    315
                ],
                "b": [
                    258,
                    195,
                    260,
                    261,
                    355,
                    360,
                    335,
                    177,
                    210,
                    211,
                    305,
                    306,
                    309,
                    310,
                    337,
                    317,
                    318
                ],
                "val": [
                    200,
                    201,
                    203,
                    181,
                    182,
                    183
                ],
                "s1.iloc": [
                    200,
                    181
                ],
                "np.errstate": [
                    192
                ],
                "orig_data1._from_sequence": [
                    194,
                    203
                ],
                "a.combine_first": [
                    211
                ],
                "subset": [
                    224,
                    270,
                    271,
                    272,
                    222,
                    223
                ],
                "subset.take": [
                    224,
                    272
                ],
                "indices": [
                    224,
                    272
                ],
                "frame": [
                    226
                ],
                "shift": [
                    227,
                    229
                ],
                "assign": [
                    227
                ],
                "data.to_frame": [
                    227,
                    303
                ],
                "periods": [
                    256,
                    257,
                    227,
                    229,
                    233,
                    271,
                    279,
                    251,
                    252
                ],
                "pd.concat": [
                    228
                ],
                "compare": [
                    234,
                    236,
                    231
                ],
                "data.shift": [
                    233,
                    252
                ],
                "is_bool_dtype": [
                    241
                ],
                "data.dtype": [
                    355,
                    360,
                    367,
                    337,
                    241,
                    375,
                    346
                ],
                "op": [
                    242,
                    244,
                    252,
                    247
                ],
                "operator.xor": [
                    242
                ],
                "operator": [
                    242,
                    244
                ],
                "operator.sub": [
                    244
                ],
                "pytest.skip": [
                    249
                ],
                "s": [
                    250,
                    251
                ],
                "s.diff": [
                    251
                ],
                "df.diff": [
                    256
                ],
                "np.nan": [
                    258,
                    260
                ],
                "subset.shift": [
                    271
                ],
                "empty": [
                    280,
                    278,
                    279
                ],
                "empty.shift": [
                    279
                ],
                "fill_value": [
                    290,
                    285,
                    286
                ],
                "arr.shift": [
                    290,
                    286
                ],
                "data.take": [
                    291,
                    287
                ],
                "as_frame": [
                    356,
                    361,
                    302,
                    340,
                    349
                ],
                "pd.util.hash_pandas_object": [
                    304,
                    305
                ],
                "pd.util": [
                    304,
                    305
                ],
                "self.assert_equal": [
                    379,
                    306,
                    363,
                    351
                ],
                "c": [
                    320,
                    321,
                    309,
                    310
                ],
                "as_series": [
                    312,
                    368,
                    376
                ],
                "arr.searchsorted": [
                    320,
                    321,
                    323,
                    314,
                    315,
                    317,
                    318
                ],
                "arr.take": [
                    323
                ],
                "sorter": [
                    329,
                    330
                ],
                "data_for_sorting.searchsorted": [
                    330
                ],
                "cls": [
                    355,
                    360,
                    334,
                    337,
                    346
                ],
                "cls._from_sequence": [
                    360,
                    337,
                    346,
                    355
                ],
                "cond": [
                    354,
                    358,
                    359,
                    338,
                    342,
                    344
                ],
                "ser.to_frame": [
                    341
                ],
                "cond.reshape": [
                    342
                ],
                "ser.where": [
                    344,
                    359
                ],
                "na_value": [
                    346
                ],
                "expected.to_frame": [
                    362,
                    350
                ],
                "use_numpy": [
                    392,
                    371
                ],
                "np.repeat": [
                    393,
                    371
                ],
                "repeats": [
                    393,
                    395,
                    371,
                    373,
                    374,
                    377
                ],
                "arr.repeat": [
                    371
                ],
                "n": [
                    374
                ],
                "_": [
                    374
                ],
                "arr.index.repeat": [
                    377
                ],
                "arr.index": [
                    377
                ],
                "error": [
                    391
                ],
                "kwargs": [
                    393,
                    395
                ],
                "data.repeat": [
                    395
                ]
            }
        },
        "test_data": [
            {
                "test_path": "/Volumes/JerrySSD/bgp_envs/repos/pandas_68/pandas/tests/arrays/interval/test_interval.py",
                "test_function": "test_shift",
                "test_function_code": "    def test_shift(self):\n        # https://github.com/pandas-dev/pandas/issues/31495\n        a = IntervalArray.from_breaks([1, 2, 3])\n        result = a.shift()\n        # int -> float\n        expected = IntervalArray.from_tuples([(np.nan, np.nan), (1.0, 2.0)])\n        tm.assert_interval_array_equal(result, expected)",
                "test_error": "ValueError: Cannot convert non-finite values (NA or inf) to integer",
                "full_test_error": "self = <pandas.tests.arrays.interval.test_interval.TestMethods object at 0x1169188b0>\n\n    def test_shift(self):\n        # https://github.com/pandas-dev/pandas/issues/31495\n        a = IntervalArray.from_breaks([1, 2, 3])\n>       result = a.shift()\n\npandas/tests/arrays/interval/test_interval.py:87: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \npandas/core/arrays/base.py:627: in shift\n    empty = self._from_sequence(\npandas/core/arrays/interval.py:245: in _from_sequence\n    return cls(scalars, dtype=dtype, copy=copy)\npandas/core/arrays/interval.py:178: in __new__\n    return cls._simple_new(\npandas/core/arrays/interval.py:204: in _simple_new\n    left = left.astype(dtype.subtype)\npandas/core/indexes/numeric.py:382: in astype\n    arr = astype_nansafe(self.values, dtype=dtype)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\narr = array([nan]), dtype = dtype('int64'), copy = True, skipna = False\n\n    def astype_nansafe(arr, dtype, copy: bool = True, skipna: bool = False):\n        \"\"\"\n        Cast the elements of an array to a given dtype a nan-safe manner.\n    \n        Parameters\n        ----------\n        arr : ndarray\n        dtype : np.dtype\n        copy : bool, default True\n            If False, a view will be attempted but may fail, if\n            e.g. the item sizes don't align.\n        skipna: bool, default False\n            Whether or not we should skip NaN when casting as a string-type.\n    \n        Raises\n        ------\n        ValueError\n            The dtype was a datetime64/timedelta64 dtype, but it had no unit.\n        \"\"\"\n    \n        # dispatch on extension dtype if needed\n        if is_extension_array_dtype(dtype):\n            return dtype.construct_array_type()._from_sequence(arr, dtype=dtype, copy=copy)\n    \n        if not isinstance(dtype, np.dtype):\n            dtype = pandas_dtype(dtype)\n    \n        if issubclass(dtype.type, str):\n            return lib.astype_str(arr.ravel(), skipna=skipna).reshape(arr.shape)\n    \n        elif is_datetime64_dtype(arr):\n            if is_object_dtype(dtype):\n                return tslib.ints_to_pydatetime(arr.view(np.int64))\n            elif dtype == np.int64:\n                if isna(arr).any():\n                    raise ValueError(\"Cannot convert NaT values to integer\")\n                return arr.view(dtype)\n    \n            # allow frequency conversions\n            if dtype.kind == \"M\":\n                return arr.astype(dtype)\n    \n            raise TypeError(f\"cannot astype a datetimelike from [{arr.dtype}] to [{dtype}]\")\n    \n        elif is_timedelta64_dtype(arr):\n            if is_object_dtype(dtype):\n                return tslibs.ints_to_pytimedelta(arr.view(np.int64))\n            elif dtype == np.int64:\n                if isna(arr).any():\n                    raise ValueError(\"Cannot convert NaT values to integer\")\n                return arr.view(dtype)\n    \n            if dtype not in [_INT64_DTYPE, _TD_DTYPE]:\n    \n                # allow frequency conversions\n                # we return a float here!\n                if dtype.kind == \"m\":\n                    mask = isna(arr)\n                    result = arr.astype(dtype).astype(np.float64)\n                    result[mask] = np.nan\n                    return result\n            elif dtype == _TD_DTYPE:\n                return arr.astype(_TD_DTYPE, copy=copy)\n    \n            raise TypeError(f\"cannot astype a timedelta from [{arr.dtype}] to [{dtype}]\")\n    \n        elif np.issubdtype(arr.dtype, np.floating) and np.issubdtype(dtype, np.integer):\n    \n            if not np.isfinite(arr).all():\n>               raise ValueError(\"Cannot convert non-finite values (NA or inf) to integer\")\nE               ValueError: Cannot convert non-finite values (NA or inf) to integer\n\npandas/core/dtypes/cast.py:868: ValueError",
                "traceback": "pandas/core/arrays/base.py:627: in shift\n    empty = self._from_sequence(\npandas/core/arrays/interval.py:245: in _from_sequence\n    return cls(scalars, dtype=dtype, copy=copy)\npandas/core/arrays/interval.py:178: in __new__\n    return cls._simple_new(\npandas/core/arrays/interval.py:204: in _simple_new\n    left = left.astype(dtype.subtype)\npandas/core/indexes/numeric.py:382: in astype\n    arr = astype_nansafe(self.values, dtype=dtype)",
                "test_error_location": "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\narr = array([nan]), dtype = dtype('int64'), copy = True, skipna = False\n\n    def astype_nansafe(arr, dtype, copy: bool = True, skipna: bool = False):\n        \"\"\"\n        Cast the elements of an array to a given dtype a nan-safe manner.\n    \n        Parameters\n        ----------\n        arr : ndarray\n        dtype : np.dtype\n        copy : bool, default True\n            If False, a view will be attempted but may fail, if\n            e.g. the item sizes don't align.\n        skipna: bool, default False\n            Whether or not we should skip NaN when casting as a string-type.\n    \n        Raises\n        ------\n        ValueError\n            The dtype was a datetime64/timedelta64 dtype, but it had no unit.\n        \"\"\"\n    \n        # dispatch on extension dtype if needed\n        if is_extension_array_dtype(dtype):\n            return dtype.construct_array_type()._from_sequence(arr, dtype=dtype, copy=copy)\n    \n        if not isinstance(dtype, np.dtype):\n            dtype = pandas_dtype(dtype)\n    \n        if issubclass(dtype.type, str):\n            return lib.astype_str(arr.ravel(), skipna=skipna).reshape(arr.shape)\n    \n        elif is_datetime64_dtype(arr):\n            if is_object_dtype(dtype):\n                return tslib.ints_to_pydatetime(arr.view(np.int64))\n            elif dtype == np.int64:\n                if isna(arr).any():\n                    raise ValueError(\"Cannot convert NaT values to integer\")\n                return arr.view(dtype)\n    \n            # allow frequency conversions\n            if dtype.kind == \"M\":\n                return arr.astype(dtype)\n    \n            raise TypeError(f\"cannot astype a datetimelike from [{arr.dtype}] to [{dtype}]\")\n    \n        elif is_timedelta64_dtype(arr):\n            if is_object_dtype(dtype):\n                return tslibs.ints_to_pytimedelta(arr.view(np.int64))\n            elif dtype == np.int64:\n                if isna(arr).any():\n                    raise ValueError(\"Cannot convert NaT values to integer\")\n                return arr.view(dtype)\n    \n            if dtype not in [_INT64_DTYPE, _TD_DTYPE]:\n    \n                # allow frequency conversions\n                # we return a float here!\n                if dtype.kind == \"m\":\n                    mask = isna(arr)\n                    result = arr.astype(dtype).astype(np.float64)\n                    result[mask] = np.nan\n                    return result\n            elif dtype == _TD_DTYPE:\n                return arr.astype(_TD_DTYPE, copy=copy)\n    \n            raise TypeError(f\"cannot astype a timedelta from [{arr.dtype}] to [{dtype}]\")\n    \n        elif np.issubdtype(arr.dtype, np.floating) and np.issubdtype(dtype, np.integer):\n    \n            if not np.isfinite(arr).all():\n>               raise ValueError(\"Cannot convert non-finite values (NA or inf) to integer\")\nE               ValueError: Cannot convert non-finite values (NA or inf) to integer\n\npandas/core/dtypes/cast.py:868: ValueError",
                "test_function_decorators": []
            }
        ]
    }
}