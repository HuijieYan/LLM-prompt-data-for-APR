{
    "pandas:154": {
        "/Volumes/JerrySSD/bgp_envs/repos/pandas_154/pandas/core/groupby/groupby.py": {
            "buggy_functions": [
                {
                    "function_name": "_get_cythonized_result",
                    "function_code": "def _get_cythonized_result(\n    self,\n    how,\n    grouper,\n    aggregate=False,\n    cython_dtype=None,\n    needs_values=False,\n    needs_mask=False,\n    needs_ngroups=False,\n    result_is_index=False,\n    pre_processing=None,\n    post_processing=None,\n    **kwargs\n):\n    \"\"\"\n    Get result for Cythonized functions.\n\n    Parameters\n    ----------\n    how : str, Cythonized function name to be called\n    grouper : Grouper object containing pertinent group info\n    aggregate : bool, default False\n        Whether the result should be aggregated to match the number of\n        groups\n    cython_dtype : default None\n        Type of the array that will be modified by the Cython call. If\n        `None`, the type will be inferred from the values of each slice\n    needs_values : bool, default False\n        Whether the values should be a part of the Cython call\n        signature\n    needs_mask : bool, default False\n        Whether boolean mask needs to be part of the Cython call\n        signature\n    needs_ngroups : bool, default False\n        Whether number of groups is part of the Cython call signature\n    result_is_index : bool, default False\n        Whether the result of the Cython operation is an index of\n        values to be retrieved, instead of the actual values themselves\n    pre_processing : function, default None\n        Function to be applied to `values` prior to passing to Cython.\n        Function should return a tuple where the first element is the\n        values to be passed to Cython and the second element is an optional\n        type which the values should be converted to after being returned\n        by the Cython operation. Raises if `needs_values` is False.\n    post_processing : function, default None\n        Function to be applied to result of Cython function. Should accept\n        an array of values as the first argument and type inferences as its\n        second argument, i.e. the signature should be\n        (ndarray, Type).\n    **kwargs : dict\n        Extra arguments to be passed back to Cython funcs\n\n    Returns\n    -------\n    `Series` or `DataFrame`  with filled values\n    \"\"\"\n    if result_is_index and aggregate:\n        raise ValueError(\"'result_is_index' and 'aggregate' cannot both be True!\")\n    if post_processing:\n        if not callable(pre_processing):\n            raise ValueError(\"'post_processing' must be a callable!\")\n    if pre_processing:\n        if not callable(pre_processing):\n            raise ValueError(\"'pre_processing' must be a callable!\")\n        if not needs_values:\n            raise ValueError(\n                \"Cannot use 'pre_processing' without specifying 'needs_values'!\"\n            )\n\n    labels, _, ngroups = grouper.group_info\n    output = collections.OrderedDict()\n    base_func = getattr(libgroupby, how)\n\n    for name, obj in self._iterate_slices():\n        if aggregate:\n            result_sz = ngroups\n        else:\n            result_sz = len(obj.values)\n\n        if not cython_dtype:\n            cython_dtype = obj.values.dtype\n\n        result = np.zeros(result_sz, dtype=cython_dtype)\n        func = partial(base_func, result, labels)\n        inferences = None\n\n        if needs_values:\n            vals = obj.values\n            if pre_processing:\n                vals, inferences = pre_processing(vals)\n            func = partial(func, vals)\n\n        if needs_mask:\n            mask = isna(obj.values).view(np.uint8)\n            func = partial(func, mask)\n\n        if needs_ngroups:\n            func = partial(func, ngroups)\n\n        func(**kwargs)  # Call func to modify indexer values in place\n\n        if result_is_index:\n            result = algorithms.take_nd(obj.values, result)\n\n        if post_processing:\n            result = post_processing(result, inferences)\n\n        output[name] = result\n\n    if aggregate:\n        return self._wrap_aggregated_output(output)\n    else:\n        return self._wrap_transformed_output(output)\n",
                    "decorators": [],
                    "docstring": "Get result for Cythonized functions.\n\nParameters\n----------\nhow : str, Cythonized function name to be called\ngrouper : Grouper object containing pertinent group info\naggregate : bool, default False\n    Whether the result should be aggregated to match the number of\n    groups\ncython_dtype : default None\n    Type of the array that will be modified by the Cython call. If\n    `None`, the type will be inferred from the values of each slice\nneeds_values : bool, default False\n    Whether the values should be a part of the Cython call\n    signature\nneeds_mask : bool, default False\n    Whether boolean mask needs to be part of the Cython call\n    signature\nneeds_ngroups : bool, default False\n    Whether number of groups is part of the Cython call signature\nresult_is_index : bool, default False\n    Whether the result of the Cython operation is an index of\n    values to be retrieved, instead of the actual values themselves\npre_processing : function, default None\n    Function to be applied to `values` prior to passing to Cython.\n    Function should return a tuple where the first element is the\n    values to be passed to Cython and the second element is an optional\n    type which the values should be converted to after being returned\n    by the Cython operation. Raises if `needs_values` is False.\npost_processing : function, default None\n    Function to be applied to result of Cython function. Should accept\n    an array of values as the first argument and type inferences as its\n    second argument, i.e. the signature should be\n    (ndarray, Type).\n**kwargs : dict\n    Extra arguments to be passed back to Cython funcs\n\nReturns\n-------\n`Series` or `DataFrame`  with filled values",
                    "start_line": 2192,
                    "variables": {
                        "result_is_index": [
                            2248,
                            2293
                        ],
                        "aggregate": [
                            2248,
                            2266,
                            2301
                        ],
                        "ValueError": [
                            2249,
                            2252,
                            2257,
                            2255
                        ],
                        "post_processing": [
                            2296,
                            2297,
                            2250
                        ],
                        "callable": [
                            2251,
                            2254
                        ],
                        "pre_processing": [
                            2280,
                            2281,
                            2251,
                            2253,
                            2254
                        ],
                        "needs_values": [
                            2256,
                            2278
                        ],
                        "labels": [
                            2275,
                            2261
                        ],
                        "_": [
                            2261
                        ],
                        "ngroups": [
                            2289,
                            2267,
                            2261
                        ],
                        "grouper.group_info": [
                            2261
                        ],
                        "grouper": [
                            2261
                        ],
                        "output": [
                            2304,
                            2302,
                            2299,
                            2262
                        ],
                        "collections.OrderedDict": [
                            2262
                        ],
                        "collections": [
                            2262
                        ],
                        "base_func": [
                            2275,
                            2263
                        ],
                        "getattr": [
                            2263
                        ],
                        "libgroupby": [
                            2263
                        ],
                        "how": [
                            2263
                        ],
                        "name": [
                            2265,
                            2299
                        ],
                        "obj": [
                            2272,
                            2279,
                            2285,
                            2294,
                            2265,
                            2269
                        ],
                        "self._iterate_slices": [
                            2265
                        ],
                        "self": [
                            2304,
                            2265,
                            2302
                        ],
                        "result_sz": [
                            2274,
                            2267,
                            2269
                        ],
                        "len": [
                            2269
                        ],
                        "obj.values": [
                            2272,
                            2279,
                            2285,
                            2294,
                            2269
                        ],
                        "cython_dtype": [
                            2272,
                            2274,
                            2271
                        ],
                        "obj.values.dtype": [
                            2272
                        ],
                        "result": [
                            2274,
                            2275,
                            2294,
                            2297,
                            2299
                        ],
                        "np.zeros": [
                            2274
                        ],
                        "np": [
                            2274,
                            2285
                        ],
                        "func": [
                            2275,
                            2282,
                            2286,
                            2289,
                            2291
                        ],
                        "partial": [
                            2289,
                            2282,
                            2275,
                            2286
                        ],
                        "inferences": [
                            2281,
                            2276,
                            2297
                        ],
                        "vals": [
                            2281,
                            2282,
                            2279
                        ],
                        "needs_mask": [
                            2284
                        ],
                        "mask": [
                            2285,
                            2286
                        ],
                        "view": [
                            2285
                        ],
                        "isna": [
                            2285
                        ],
                        "np.uint8": [
                            2285
                        ],
                        "needs_ngroups": [
                            2288
                        ],
                        "kwargs": [
                            2291
                        ],
                        "algorithms.take_nd": [
                            2294
                        ],
                        "algorithms": [
                            2294
                        ],
                        "self._wrap_aggregated_output": [
                            2302
                        ],
                        "self._wrap_transformed_output": [
                            2304
                        ]
                    },
                    "filtered_variables": {
                        "result_is_index": [
                            2248,
                            2293
                        ],
                        "aggregate": [
                            2248,
                            2266,
                            2301
                        ],
                        "post_processing": [
                            2296,
                            2297,
                            2250
                        ],
                        "pre_processing": [
                            2280,
                            2281,
                            2251,
                            2253,
                            2254
                        ],
                        "needs_values": [
                            2256,
                            2278
                        ],
                        "labels": [
                            2275,
                            2261
                        ],
                        "_": [
                            2261
                        ],
                        "ngroups": [
                            2289,
                            2267,
                            2261
                        ],
                        "grouper.group_info": [
                            2261
                        ],
                        "grouper": [
                            2261
                        ],
                        "output": [
                            2304,
                            2302,
                            2299,
                            2262
                        ],
                        "collections.OrderedDict": [
                            2262
                        ],
                        "collections": [
                            2262
                        ],
                        "base_func": [
                            2275,
                            2263
                        ],
                        "libgroupby": [
                            2263
                        ],
                        "how": [
                            2263
                        ],
                        "name": [
                            2265,
                            2299
                        ],
                        "obj": [
                            2272,
                            2279,
                            2285,
                            2294,
                            2265,
                            2269
                        ],
                        "self._iterate_slices": [
                            2265
                        ],
                        "self": [
                            2304,
                            2265,
                            2302
                        ],
                        "result_sz": [
                            2274,
                            2267,
                            2269
                        ],
                        "obj.values": [
                            2272,
                            2279,
                            2285,
                            2294,
                            2269
                        ],
                        "cython_dtype": [
                            2272,
                            2274,
                            2271
                        ],
                        "obj.values.dtype": [
                            2272
                        ],
                        "result": [
                            2274,
                            2275,
                            2294,
                            2297,
                            2299
                        ],
                        "np.zeros": [
                            2274
                        ],
                        "np": [
                            2274,
                            2285
                        ],
                        "func": [
                            2275,
                            2282,
                            2286,
                            2289,
                            2291
                        ],
                        "partial": [
                            2289,
                            2282,
                            2275,
                            2286
                        ],
                        "inferences": [
                            2281,
                            2276,
                            2297
                        ],
                        "vals": [
                            2281,
                            2282,
                            2279
                        ],
                        "needs_mask": [
                            2284
                        ],
                        "mask": [
                            2285,
                            2286
                        ],
                        "view": [
                            2285
                        ],
                        "isna": [
                            2285
                        ],
                        "np.uint8": [
                            2285
                        ],
                        "needs_ngroups": [
                            2288
                        ],
                        "kwargs": [
                            2291
                        ],
                        "algorithms.take_nd": [
                            2294
                        ],
                        "algorithms": [
                            2294
                        ],
                        "self._wrap_aggregated_output": [
                            2302
                        ],
                        "self._wrap_transformed_output": [
                            2304
                        ]
                    },
                    "diff_line_number": 2265,
                    "class_data": {
                        "signature": "class GroupBy(_GroupBy)",
                        "docstring": "Class for grouping and aggregating relational data.\n\nSee aggregate, transform, and apply functions on this object.\n\nIt's easiest to use obj.groupby(...) to use GroupBy, but you can also do:\n\n::\n\n    grouped = groupby(obj, ...)\n\nParameters\n----------\nobj : pandas object\naxis : int, default 0\nlevel : int, default None\n    Level of MultiIndex\ngroupings : list of Grouping objects\n    Most users should ignore this\nexclusions : array-like, optional\n    List of columns to exclude\nname : string\n    Most users should ignore this\n\nReturns\n-------\n**Attributes**\ngroups : dict\n    {group name -> group labels}\nlen(grouped) : int\n    Number of groups\n\nNotes\n-----\nAfter grouping, see aggregate, apply, and transform functions. Here are\nsome other brief notes about usage. When grouping by multiple groups, the\nresult index will be a MultiIndex (hierarchical) by default.\n\nIteration produces (key, group) tuples, i.e. chunking the data by group. So\nyou can write code like:\n\n::\n\n    grouped = obj.groupby(keys, axis=axis)\n    for key, group in grouped:\n        # do something with the data\n\nFunction calls on GroupBy, if not specially implemented, \"dispatch\" to the\ngrouped data. So if you group a DataFrame and wish to invoke the std()\nmethod on each group, you can simply do:\n\n::\n\n    df.groupby(mapper).std()\n\nrather than\n\n::\n\n    df.groupby(mapper).aggregate(np.std)\n\nYou can pass arguments to these \"wrapped\" functions, too.\n\nSee the online documentation for full exposition on these topics and much\nmore",
                        "constructor_docstring": null,
                        "functions": [
                            "def _bool_agg(self, val_test, skipna):\n    \"\"\"\n    Shared func to call any / all Cython GroupBy implementations.\n    \"\"\"\n\n    def objs_to_bool(vals: np.ndarray) -> Tuple[np.ndarray, Type]:\n        if is_object_dtype(vals):\n            vals = np.array([bool(x) for x in vals])\n        else:\n            vals = vals.astype(np.bool)\n        return (vals.view(np.uint8), np.bool)\n\n    def result_to_bool(result: np.ndarray, inference: Type) -> np.ndarray:\n        return result.astype(inference, copy=False)\n    return self._get_cythonized_result('group_any_all', self.grouper, aggregate=True, cython_dtype=np.uint8, needs_values=True, needs_mask=True, pre_processing=objs_to_bool, post_processing=result_to_bool, val_test=val_test, skipna=skipna)",
                            "@Substitution(name='groupby')\n@Appender(_common_see_also)\ndef any(self, skipna=True):\n    \"\"\"\n    Return True if any value in the group is truthful, else False.\n\n    Parameters\n    ----------\n    skipna : bool, default True\n        Flag to ignore nan values during truth testing\n\n    Returns\n    -------\n    bool\n    \"\"\"\n    return self._bool_agg('any', skipna)",
                            "@Substitution(name='groupby')\n@Appender(_common_see_also)\ndef all(self, skipna=True):\n    \"\"\"\n    Return True if all values in the group are truthful, else False.\n\n    Parameters\n    ----------\n    skipna : bool, default True\n        Flag to ignore nan values during truth testing\n\n    Returns\n    -------\n    bool\n    \"\"\"\n    return self._bool_agg('all', skipna)",
                            "@Substitution(name='groupby')\n@Appender(_common_see_also)\ndef count(self):\n    \"\"\"\n    Compute count of group, excluding missing values.\n\n    Returns\n    -------\n    Series or DataFrame\n        Count of values within each group.\n    \"\"\"\n    raise NotImplementedError",
                            "@Substitution(name='groupby')\n@Substitution(see_also=_common_see_also)\ndef mean(self, *args, **kwargs):\n    \"\"\"\n    Compute mean of groups, excluding missing values.\n\n    Returns\n    -------\n    pandas.Series or pandas.DataFrame\n    %(see_also)s\n    Examples\n    --------\n    >>> df = pd.DataFrame({'A': [1, 1, 2, 1, 2],\n    ...                    'B': [np.nan, 2, 3, 4, 5],\n    ...                    'C': [1, 2, 1, 1, 2]}, columns=['A', 'B', 'C'])\n\n    Groupby one column and return the mean of the remaining columns in\n    each group.\n\n    >>> df.groupby('A').mean()\n         B         C\n    A\n    1  3.0  1.333333\n    2  4.0  1.500000\n\n    Groupby two columns and return the mean of the remaining column.\n\n    >>> df.groupby(['A', 'B']).mean()\n           C\n    A B\n    1 2.0  2\n      4.0  1\n    2 3.0  1\n      5.0  2\n\n    Groupby one column and return the mean of only particular column in\n    the group.\n\n    >>> df.groupby('A')['B'].mean()\n    A\n    1    3.0\n    2    4.0\n    Name: B, dtype: float64\n    \"\"\"\n    nv.validate_groupby_func('mean', args, kwargs, ['numeric_only'])\n    try:\n        return self._cython_agg_general('mean', alt=lambda x, axis: Series(x).mean(**kwargs), **kwargs)\n    except GroupByError:\n        raise\n    except Exception:\n        with _group_selection_context(self):\n            f = lambda x: x.mean(axis=self.axis, **kwargs)\n            return self._python_agg_general(f)",
                            "@Substitution(name='groupby')\n@Appender(_common_see_also)\ndef median(self, **kwargs):\n    \"\"\"\n    Compute median of groups, excluding missing values.\n\n    For multiple groupings, the result index will be a MultiIndex\n\n    Returns\n    -------\n    Series or DataFrame\n        Median of values within each group.\n    \"\"\"\n    try:\n        return self._cython_agg_general('median', alt=lambda x, axis: Series(x).median(axis=axis, **kwargs), **kwargs)\n    except GroupByError:\n        raise\n    except Exception:\n\n        def f(x):\n            if isinstance(x, np.ndarray):\n                x = Series(x)\n            return x.median(axis=self.axis, **kwargs)\n        with _group_selection_context(self):\n            return self._python_agg_general(f)",
                            "@Substitution(name='groupby')\n@Appender(_common_see_also)\ndef std(self, ddof=1, *args, **kwargs):\n    \"\"\"\n    Compute standard deviation of groups, excluding missing values.\n\n    For multiple groupings, the result index will be a MultiIndex.\n\n    Parameters\n    ----------\n    ddof : integer, default 1\n        degrees of freedom\n\n    Returns\n    -------\n    Series or DataFrame\n        Standard deviation of values within each group.\n    \"\"\"\n    nv.validate_groupby_func('std', args, kwargs)\n    return np.sqrt(self.var(ddof=ddof, **kwargs))",
                            "@Substitution(name='groupby')\n@Appender(_common_see_also)\ndef var(self, ddof=1, *args, **kwargs):\n    \"\"\"\n    Compute variance of groups, excluding missing values.\n\n    For multiple groupings, the result index will be a MultiIndex.\n\n    Parameters\n    ----------\n    ddof : integer, default 1\n        degrees of freedom\n\n    Returns\n    -------\n    Series or DataFrame\n        Variance of values within each group.\n    \"\"\"\n    nv.validate_groupby_func('var', args, kwargs)\n    if ddof == 1:\n        try:\n            return self._cython_agg_general('var', alt=lambda x, axis: Series(x).var(ddof=ddof, **kwargs), **kwargs)\n        except Exception:\n            f = lambda x: x.var(ddof=ddof, **kwargs)\n            with _group_selection_context(self):\n                return self._python_agg_general(f)\n    else:\n        f = lambda x: x.var(ddof=ddof, **kwargs)\n        with _group_selection_context(self):\n            return self._python_agg_general(f)",
                            "@Substitution(name='groupby')\n@Appender(_common_see_also)\ndef sem(self, ddof=1):\n    \"\"\"\n    Compute standard error of the mean of groups, excluding missing values.\n\n    For multiple groupings, the result index will be a MultiIndex.\n\n    Parameters\n    ----------\n    ddof : integer, default 1\n        degrees of freedom\n\n    Returns\n    -------\n    Series or DataFrame\n        Standard error of the mean of values within each group.\n    \"\"\"\n    return self.std(ddof=ddof) / np.sqrt(self.count())",
                            "@Substitution(name='groupby')\n@Appender(_common_see_also)\ndef size(self):\n    \"\"\"\n    Compute group sizes.\n\n    Returns\n    -------\n    Series\n        Number of rows in each group.\n    \"\"\"\n    result = self.grouper.size()\n    if isinstance(self.obj, Series):\n        result.name = getattr(self.obj, 'name', None)\n    return result",
                            "@classmethod\ndef _add_numeric_operations(cls):\n    \"\"\"\n    Add numeric operations to the GroupBy generically.\n    \"\"\"\n\n    def groupby_function(name, alias, npfunc, numeric_only=True, min_count=-1):\n        _local_template = '\\n            Compute %(f)s of group values.\\n\\n            Returns\\n            -------\\n            Series or DataFrame\\n                Computed %(f)s of values within each group.\\n            '\n\n        @Substitution(name='groupby', f=name)\n        @Appender(_common_see_also)\n        @Appender(_local_template)\n        def f(self, **kwargs):\n            if 'numeric_only' not in kwargs:\n                kwargs['numeric_only'] = numeric_only\n            if 'min_count' not in kwargs:\n                kwargs['min_count'] = min_count\n            self._set_group_selection()\n            try:\n                return self._cython_agg_general(alias, alt=npfunc, **kwargs)\n            except AssertionError as e:\n                raise SpecificationError(str(e))\n            except Exception:\n                pass\n            result = self.aggregate(lambda x: npfunc(x, axis=self.axis))\n            if isinstance(result, DataFrame):\n                for col in result.columns:\n                    result[col] = self._try_cast(result[col], self.obj[col])\n            else:\n                result = self._try_cast(result, self.obj)\n            return result\n        set_function_name(f, name, cls)\n        return f\n\n    def first_compat(x, axis=0):\n\n        def first(x):\n            x = x.to_numpy()\n            x = x[notna(x)]\n            if len(x) == 0:\n                return np.nan\n            return x[0]\n        if isinstance(x, DataFrame):\n            return x.apply(first, axis=axis)\n        else:\n            return first(x)\n\n    def last_compat(x, axis=0):\n\n        def last(x):\n            x = x.to_numpy()\n            x = x[notna(x)]\n            if len(x) == 0:\n                return np.nan\n            return x[-1]\n        if isinstance(x, DataFrame):\n            return x.apply(last, axis=axis)\n        else:\n            return last(x)\n    cls.sum = groupby_function('sum', 'add', np.sum, min_count=0)\n    cls.prod = groupby_function('prod', 'prod', np.prod, min_count=0)\n    cls.min = groupby_function('min', 'min', np.min, numeric_only=False)\n    cls.max = groupby_function('max', 'max', np.max, numeric_only=False)\n    cls.first = groupby_function('first', 'first', first_compat, numeric_only=False)\n    cls.last = groupby_function('last', 'last', last_compat, numeric_only=False)",
                            "@Substitution(name='groupby')\n@Appender(_common_see_also)\ndef ohlc(self):\n    \"\"\"\n    Compute sum of values, excluding missing values.\n\n    For multiple groupings, the result index will be a MultiIndex\n\n    Returns\n    -------\n    DataFrame\n        Open, high, low and close values within each group.\n    \"\"\"\n    return self._apply_to_column_groupbys(lambda x: x._cython_agg_general('ohlc'))",
                            "@Appender(DataFrame.describe.__doc__)\ndef describe(self, **kwargs):\n    with _group_selection_context(self):\n        result = self.apply(lambda x: x.describe(**kwargs))\n        if self.axis == 1:\n            return result.T\n        return result.unstack()",
                            "def resample(self, rule, *args, **kwargs):\n    \"\"\"\n    Provide resampling when using a TimeGrouper.\n\n    Given a grouper, the function resamples it according to a string\n    \"string\" -> \"frequency\".\n\n    See the :ref:`frequency aliases <timeseries.offset_aliases>`\n    documentation for more details.\n\n    Parameters\n    ----------\n    rule : str or DateOffset\n        The offset string or object representing target grouper conversion.\n    *args, **kwargs\n        Possible arguments are `how`, `fill_method`, `limit`, `kind` and\n        `on`, and other arguments of `TimeGrouper`.\n\n    Returns\n    -------\n    Grouper\n        Return a new grouper with our resampler appended.\n\n    See Also\n    --------\n    Grouper : Specify a frequency to resample with when\n        grouping by a key.\n    DatetimeIndex.resample : Frequency conversion and resampling of\n        time series.\n\n    Examples\n    --------\n    >>> idx = pd.date_range('1/1/2000', periods=4, freq='T')\n    >>> df = pd.DataFrame(data=4 * [range(2)],\n    ...                   index=idx,\n    ...                   columns=['a', 'b'])\n    >>> df.iloc[2, 0] = 5\n    >>> df\n                        a  b\n    2000-01-01 00:00:00  0  1\n    2000-01-01 00:01:00  0  1\n    2000-01-01 00:02:00  5  1\n    2000-01-01 00:03:00  0  1\n\n    Downsample the DataFrame into 3 minute bins and sum the values of\n    the timestamps falling into a bin.\n\n    >>> df.groupby('a').resample('3T').sum()\n                             a  b\n    a\n    0   2000-01-01 00:00:00  0  2\n        2000-01-01 00:03:00  0  1\n    5   2000-01-01 00:00:00  5  1\n\n    Upsample the series into 30 second bins.\n\n    >>> df.groupby('a').resample('30S').sum()\n                        a  b\n    a\n    0   2000-01-01 00:00:00  0  1\n        2000-01-01 00:00:30  0  0\n        2000-01-01 00:01:00  0  1\n        2000-01-01 00:01:30  0  0\n        2000-01-01 00:02:00  0  0\n        2000-01-01 00:02:30  0  0\n        2000-01-01 00:03:00  0  1\n    5   2000-01-01 00:02:00  5  1\n\n    Resample by month. Values are assigned to the month of the period.\n\n    >>> df.groupby('a').resample('M').sum()\n                a  b\n    a\n    0   2000-01-31  0  3\n    5   2000-01-31  5  1\n\n    Downsample the series into 3 minute bins as above, but close the right\n    side of the bin interval.\n\n    >>> df.groupby('a').resample('3T', closed='right').sum()\n                             a  b\n    a\n    0   1999-12-31 23:57:00  0  1\n        2000-01-01 00:00:00  0  2\n    5   2000-01-01 00:00:00  5  1\n\n    Downsample the series into 3 minute bins and close the right side of\n    the bin interval, but label each bin using the right edge instead of\n    the left.\n\n    >>> df.groupby('a').resample('3T', closed='right', label='right').sum()\n                             a  b\n    a\n    0   2000-01-01 00:00:00  0  1\n        2000-01-01 00:03:00  0  2\n    5   2000-01-01 00:03:00  5  1\n\n    Add an offset of twenty seconds.\n\n    >>> df.groupby('a').resample('3T', loffset='20s').sum()\n                           a  b\n    a\n    0   2000-01-01 00:00:20  0  2\n        2000-01-01 00:03:20  0  1\n    5   2000-01-01 00:00:20  5  1\n    \"\"\"\n    from pandas.core.resample import get_resampler_for_grouping\n    return get_resampler_for_grouping(self, rule, *args, **kwargs)",
                            "@Substitution(name='groupby')\n@Appender(_common_see_also)\ndef rolling(self, *args, **kwargs):\n    \"\"\"\n    Return a rolling grouper, providing rolling functionality per group.\n    \"\"\"\n    from pandas.core.window import RollingGroupby\n    return RollingGroupby(self, *args, **kwargs)",
                            "@Substitution(name='groupby')\n@Appender(_common_see_also)\ndef expanding(self, *args, **kwargs):\n    \"\"\"\n    Return an expanding grouper, providing expanding\n    functionality per group.\n    \"\"\"\n    from pandas.core.window import ExpandingGroupby\n    return ExpandingGroupby(self, *args, **kwargs)",
                            "def _fill(self, direction, limit=None):\n    \"\"\"\n    Shared function for `pad` and `backfill` to call Cython method.\n\n    Parameters\n    ----------\n    direction : {'ffill', 'bfill'}\n        Direction passed to underlying Cython function. `bfill` will cause\n        values to be filled backwards. `ffill` and any other values will\n        default to a forward fill\n    limit : int, default None\n        Maximum number of consecutive values to fill. If `None`, this\n        method will convert to -1 prior to passing to Cython\n\n    Returns\n    -------\n    `Series` or `DataFrame` with filled values\n\n    See Also\n    --------\n    pad\n    backfill\n    \"\"\"\n    if limit is None:\n        limit = -1\n    return self._get_cythonized_result('group_fillna_indexer', self.grouper, needs_mask=True, cython_dtype=np.int64, result_is_index=True, direction=direction, limit=limit)",
                            "@Substitution(name='groupby')\ndef pad(self, limit=None):\n    \"\"\"\n    Forward fill the values.\n\n    Parameters\n    ----------\n    limit : integer, optional\n        limit of how many values to fill\n\n    Returns\n    -------\n    Series or DataFrame\n        Object with missing values filled.\n\n    See Also\n    --------\n    Series.pad\n    DataFrame.pad\n    Series.fillna\n    DataFrame.fillna\n    \"\"\"\n    return self._fill('ffill', limit=limit)",
                            "@Substitution(name='groupby')\ndef backfill(self, limit=None):\n    \"\"\"\n    Backward fill the values.\n\n    Parameters\n    ----------\n    limit : integer, optional\n        limit of how many values to fill\n\n    Returns\n    -------\n    Series or DataFrame\n        Object with missing values filled.\n\n    See Also\n    --------\n    Series.backfill\n    DataFrame.backfill\n    Series.fillna\n    DataFrame.fillna\n    \"\"\"\n    return self._fill('bfill', limit=limit)",
                            "@Substitution(name='groupby')\n@Substitution(see_also=_common_see_also)\ndef nth(self, n: Union[int, List[int]], dropna: Optional[str]=None) -> DataFrame:\n    \"\"\"\n    Take the nth row from each group if n is an int, or a subset of rows\n    if n is a list of ints.\n\n    If dropna, will take the nth non-null row, dropna is either\n    'all' or 'any'; this is equivalent to calling dropna(how=dropna)\n    before the groupby.\n\n    Parameters\n    ----------\n    n : int or list of ints\n        a single nth value for the row or a list of nth values\n    dropna : None or str, optional\n        apply the specified dropna operation before counting which row is\n        the nth row. Needs to be None, 'any' or 'all'\n\n    Returns\n    -------\n    Series or DataFrame\n        N-th value within each group.\n    %(see_also)s\n    Examples\n    --------\n\n    >>> df = pd.DataFrame({'A': [1, 1, 2, 1, 2],\n    ...                    'B': [np.nan, 2, 3, 4, 5]}, columns=['A', 'B'])\n    >>> g = df.groupby('A')\n    >>> g.nth(0)\n         B\n    A\n    1  NaN\n    2  3.0\n    >>> g.nth(1)\n         B\n    A\n    1  2.0\n    2  5.0\n    >>> g.nth(-1)\n         B\n    A\n    1  4.0\n    2  5.0\n    >>> g.nth([0, 1])\n         B\n    A\n    1  NaN\n    1  2.0\n    2  3.0\n    2  5.0\n\n    Specifying `dropna` allows count ignoring ``NaN``\n\n    >>> g.nth(0, dropna='any')\n         B\n    A\n    1  2.0\n    2  3.0\n\n    NaNs denote group exhausted when using dropna\n\n    >>> g.nth(3, dropna='any')\n        B\n    A\n    1 NaN\n    2 NaN\n\n    Specifying `as_index=False` in `groupby` keeps the original index.\n\n    >>> df.groupby('A', as_index=False).nth(1)\n       A    B\n    1  1  2.0\n    4  2  5.0\n    \"\"\"\n    valid_containers = (set, list, tuple)\n    if not isinstance(n, (valid_containers, int)):\n        raise TypeError('n needs to be an int or a list/set/tuple of ints')\n    if not dropna:\n        if isinstance(n, int):\n            nth_values = [n]\n        elif isinstance(n, valid_containers):\n            nth_values = list(set(n))\n        nth_array = np.array(nth_values, dtype=np.intp)\n        self._set_group_selection()\n        mask_left = np.in1d(self._cumcount_array(), nth_array)\n        mask_right = np.in1d(self._cumcount_array(ascending=False) + 1, -nth_array)\n        mask = mask_left | mask_right\n        ids, _, _ = self.grouper.group_info\n        mask = mask & (ids != -1)\n        out = self._selected_obj[mask]\n        if not self.as_index:\n            return out\n        result_index = self.grouper.result_index\n        out.index = result_index[ids[mask]]\n        if not self.observed and isinstance(result_index, CategoricalIndex):\n            out = out.reindex(result_index)\n        return out.sort_index() if self.sort else out\n    if isinstance(n, valid_containers):\n        raise ValueError('dropna option with a list of nth values is not supported')\n    if dropna not in ['any', 'all']:\n        raise ValueError(\"For a DataFrame groupby, dropna must be either None, 'any' or 'all', (was passed {dropna}).\".format(dropna=dropna))\n    max_len = n if n >= 0 else -1 - n\n    dropped = self.obj.dropna(how=dropna, axis=self.axis)\n    if self.keys is None and self.level is None:\n        axis = self.grouper.axis\n        grouper = axis[axis.isin(dropped.index)]\n    else:\n        from pandas.core.groupby.grouper import _get_grouper\n        grouper, _, _ = _get_grouper(dropped, key=self.keys, axis=self.axis, level=self.level, sort=self.sort, mutated=self.mutated)\n    grb = dropped.groupby(grouper, as_index=self.as_index, sort=self.sort)\n    sizes, result = (grb.size(), grb.nth(n))\n    mask = (sizes < max_len).values\n    if len(result) and mask.any():\n        result.loc[mask] = np.nan\n    if len(self.obj) == len(dropped) or len(result) == len(self.grouper.result_index):\n        result.index = self.grouper.result_index\n    else:\n        result = result.reindex(self.grouper.result_index)\n    return result",
                            "def quantile(self, q=0.5, interpolation='linear'):\n    \"\"\"\n    Return group values at the given quantile, a la numpy.percentile.\n\n    Parameters\n    ----------\n    q : float or array-like, default 0.5 (50% quantile)\n        Value(s) between 0 and 1 providing the quantile(s) to compute.\n    interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}\n        Method to use when the desired quantile falls between two points.\n\n    Returns\n    -------\n    Series or DataFrame\n        Return type determined by caller of GroupBy object.\n\n    See Also\n    --------\n    Series.quantile : Similar method for Series.\n    DataFrame.quantile : Similar method for DataFrame.\n    numpy.percentile : NumPy method to compute qth percentile.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame([\n    ...     ['a', 1], ['a', 2], ['a', 3],\n    ...     ['b', 1], ['b', 3], ['b', 5]\n    ... ], columns=['key', 'val'])\n    >>> df.groupby('key').quantile()\n        val\n    key\n    a    2.0\n    b    3.0\n    \"\"\"\n    from pandas import concat\n\n    def pre_processor(vals: np.ndarray) -> Tuple[np.ndarray, Optional[Type]]:\n        if is_object_dtype(vals):\n            raise TypeError(\"'quantile' cannot be performed against 'object' dtypes!\")\n        inference = None\n        if is_integer_dtype(vals):\n            inference = np.int64\n        elif is_datetime64_dtype(vals):\n            inference = 'datetime64[ns]'\n            vals = vals.astype(np.float)\n        return (vals, inference)\n\n    def post_processor(vals: np.ndarray, inference: Optional[Type]) -> np.ndarray:\n        if inference:\n            if not (is_integer_dtype(inference) and interpolation in {'linear', 'midpoint'}):\n                vals = vals.astype(inference)\n        return vals\n    if is_scalar(q):\n        return self._get_cythonized_result('group_quantile', self.grouper, aggregate=True, needs_values=True, needs_mask=True, cython_dtype=np.float64, pre_processing=pre_processor, post_processing=post_processor, q=q, interpolation=interpolation)\n    else:\n        results = [self._get_cythonized_result('group_quantile', self.grouper, aggregate=True, needs_values=True, needs_mask=True, cython_dtype=np.float64, pre_processing=pre_processor, post_processing=post_processor, q=qi, interpolation=interpolation) for qi in q]\n        result = concat(results, axis=0, keys=q)\n        order = np.roll(list(range(result.index.nlevels)), -1)\n        result = result.reorder_levels(order)\n        result = result.reindex(q, level=-1)\n        hi = len(q) * self.ngroups\n        arr = np.arange(0, hi, self.ngroups)\n        arrays = []\n        for i in range(self.ngroups):\n            arr2 = arr + i\n            arrays.append(arr2)\n        indices = np.concatenate(arrays)\n        assert len(indices) == len(result)\n        return result.take(indices)",
                            "@Substitution(name='groupby')\ndef ngroup(self, ascending=True):\n    \"\"\"\n    Number each group from 0 to the number of groups - 1.\n\n    This is the enumerative complement of cumcount.  Note that the\n    numbers given to the groups match the order in which the groups\n    would be seen when iterating over the groupby object, not the\n    order they are first observed.\n\n    .. versionadded:: 0.20.2\n\n    Parameters\n    ----------\n    ascending : bool, default True\n        If False, number in reverse, from number of group - 1 to 0.\n\n    Returns\n    -------\n    Series\n        Unique numbers for each group.\n\n    See Also\n    --------\n    .cumcount : Number the rows in each group.\n\n    Examples\n    --------\n\n    >>> df = pd.DataFrame({\"A\": list(\"aaabba\")})\n    >>> df\n       A\n    0  a\n    1  a\n    2  a\n    3  b\n    4  b\n    5  a\n    >>> df.groupby('A').ngroup()\n    0    0\n    1    0\n    2    0\n    3    1\n    4    1\n    5    0\n    dtype: int64\n    >>> df.groupby('A').ngroup(ascending=False)\n    0    1\n    1    1\n    2    1\n    3    0\n    4    0\n    5    1\n    dtype: int64\n    >>> df.groupby([\"A\", [1,1,2,3,2,1]]).ngroup()\n    0    0\n    1    0\n    2    1\n    3    3\n    4    2\n    5    0\n    dtype: int64\n    \"\"\"\n    with _group_selection_context(self):\n        index = self._selected_obj.index\n        result = Series(self.grouper.group_info[0], index)\n        if not ascending:\n            result = self.ngroups - 1 - result\n        return result",
                            "@Substitution(name='groupby')\ndef cumcount(self, ascending=True):\n    \"\"\"\n    Number each item in each group from 0 to the length of that group - 1.\n\n    Essentially this is equivalent to\n\n    >>> self.apply(lambda x: pd.Series(np.arange(len(x)), x.index))\n\n    Parameters\n    ----------\n    ascending : bool, default True\n        If False, number in reverse, from length of group - 1 to 0.\n\n    Returns\n    -------\n    Series\n        Sequence number of each element within each group.\n\n    See Also\n    --------\n    .ngroup : Number the groups themselves.\n\n    Examples\n    --------\n\n    >>> df = pd.DataFrame([['a'], ['a'], ['a'], ['b'], ['b'], ['a']],\n    ...                   columns=['A'])\n    >>> df\n       A\n    0  a\n    1  a\n    2  a\n    3  b\n    4  b\n    5  a\n    >>> df.groupby('A').cumcount()\n    0    0\n    1    1\n    2    2\n    3    0\n    4    1\n    5    3\n    dtype: int64\n    >>> df.groupby('A').cumcount(ascending=False)\n    0    3\n    1    2\n    2    1\n    3    1\n    4    0\n    5    0\n    dtype: int64\n    \"\"\"\n    with _group_selection_context(self):\n        index = self._selected_obj.index\n        cumcounts = self._cumcount_array(ascending=ascending)\n        return Series(cumcounts, index)",
                            "@Substitution(name='groupby')\n@Appender(_common_see_also)\ndef rank(self, method='average', ascending=True, na_option='keep', pct=False, axis=0):\n    \"\"\"\n    Provide the rank of values within each group.\n\n    Parameters\n    ----------\n    method : {'average', 'min', 'max', 'first', 'dense'}, default 'average'\n        * average: average rank of group\n        * min: lowest rank in group\n        * max: highest rank in group\n        * first: ranks assigned in order they appear in the array\n        * dense: like 'min', but rank always increases by 1 between groups\n    ascending : boolean, default True\n        False for ranks by high (1) to low (N)\n    na_option :  {'keep', 'top', 'bottom'}, default 'keep'\n        * keep: leave NA values where they are\n        * top: smallest rank if ascending\n        * bottom: smallest rank if descending\n    pct : boolean, default False\n        Compute percentage rank of data within each group\n    axis : int, default 0\n        The axis of the object over which to compute the rank.\n\n    Returns\n    -------\n    DataFrame with ranking of values within each group\n    \"\"\"\n    if na_option not in {'keep', 'top', 'bottom'}:\n        msg = \"na_option must be one of 'keep', 'top', or 'bottom'\"\n        raise ValueError(msg)\n    return self._cython_transform('rank', numeric_only=False, ties_method=method, ascending=ascending, na_option=na_option, pct=pct, axis=axis)",
                            "@Substitution(name='groupby')\n@Appender(_common_see_also)\ndef cumprod(self, axis=0, *args, **kwargs):\n    \"\"\"\n    Cumulative product for each group.\n\n    Returns\n    -------\n    Series or DataFrame\n    \"\"\"\n    nv.validate_groupby_func('cumprod', args, kwargs, ['numeric_only', 'skipna'])\n    if axis != 0:\n        return self.apply(lambda x: x.cumprod(axis=axis, **kwargs))\n    return self._cython_transform('cumprod', **kwargs)",
                            "@Substitution(name='groupby')\n@Appender(_common_see_also)\ndef cumsum(self, axis=0, *args, **kwargs):\n    \"\"\"\n    Cumulative sum for each group.\n\n    Returns\n    -------\n    Series or DataFrame\n    \"\"\"\n    nv.validate_groupby_func('cumsum', args, kwargs, ['numeric_only', 'skipna'])\n    if axis != 0:\n        return self.apply(lambda x: x.cumsum(axis=axis, **kwargs))\n    return self._cython_transform('cumsum', **kwargs)",
                            "@Substitution(name='groupby')\n@Appender(_common_see_also)\ndef cummin(self, axis=0, **kwargs):\n    \"\"\"\n    Cumulative min for each group.\n\n    Returns\n    -------\n    Series or DataFrame\n    \"\"\"\n    if axis != 0:\n        return self.apply(lambda x: np.minimum.accumulate(x, axis))\n    return self._cython_transform('cummin', numeric_only=False)",
                            "@Substitution(name='groupby')\n@Appender(_common_see_also)\ndef cummax(self, axis=0, **kwargs):\n    \"\"\"\n    Cumulative max for each group.\n\n    Returns\n    -------\n    Series or DataFrame\n    \"\"\"\n    if axis != 0:\n        return self.apply(lambda x: np.maximum.accumulate(x, axis))\n    return self._cython_transform('cummax', numeric_only=False)",
                            "def _get_cythonized_result(self, how, grouper, aggregate=False, cython_dtype=None, needs_values=False, needs_mask=False, needs_ngroups=False, result_is_index=False, pre_processing=None, post_processing=None, **kwargs):\n    \"\"\"\n    Get result for Cythonized functions.\n\n    Parameters\n    ----------\n    how : str, Cythonized function name to be called\n    grouper : Grouper object containing pertinent group info\n    aggregate : bool, default False\n        Whether the result should be aggregated to match the number of\n        groups\n    cython_dtype : default None\n        Type of the array that will be modified by the Cython call. If\n        `None`, the type will be inferred from the values of each slice\n    needs_values : bool, default False\n        Whether the values should be a part of the Cython call\n        signature\n    needs_mask : bool, default False\n        Whether boolean mask needs to be part of the Cython call\n        signature\n    needs_ngroups : bool, default False\n        Whether number of groups is part of the Cython call signature\n    result_is_index : bool, default False\n        Whether the result of the Cython operation is an index of\n        values to be retrieved, instead of the actual values themselves\n    pre_processing : function, default None\n        Function to be applied to `values` prior to passing to Cython.\n        Function should return a tuple where the first element is the\n        values to be passed to Cython and the second element is an optional\n        type which the values should be converted to after being returned\n        by the Cython operation. Raises if `needs_values` is False.\n    post_processing : function, default None\n        Function to be applied to result of Cython function. Should accept\n        an array of values as the first argument and type inferences as its\n        second argument, i.e. the signature should be\n        (ndarray, Type).\n    **kwargs : dict\n        Extra arguments to be passed back to Cython funcs\n\n    Returns\n    -------\n    `Series` or `DataFrame`  with filled values\n    \"\"\"\n    if result_is_index and aggregate:\n        raise ValueError(\"'result_is_index' and 'aggregate' cannot both be True!\")\n    if post_processing:\n        if not callable(pre_processing):\n            raise ValueError(\"'post_processing' must be a callable!\")\n    if pre_processing:\n        if not callable(pre_processing):\n            raise ValueError(\"'pre_processing' must be a callable!\")\n        if not needs_values:\n            raise ValueError(\"Cannot use 'pre_processing' without specifying 'needs_values'!\")\n    labels, _, ngroups = grouper.group_info\n    output = collections.OrderedDict()\n    base_func = getattr(libgroupby, how)\n    for name, obj in self._iterate_slices():\n        if aggregate:\n            result_sz = ngroups\n        else:\n            result_sz = len(obj.values)\n        if not cython_dtype:\n            cython_dtype = obj.values.dtype\n        result = np.zeros(result_sz, dtype=cython_dtype)\n        func = partial(base_func, result, labels)\n        inferences = None\n        if needs_values:\n            vals = obj.values\n            if pre_processing:\n                vals, inferences = pre_processing(vals)\n            func = partial(func, vals)\n        if needs_mask:\n            mask = isna(obj.values).view(np.uint8)\n            func = partial(func, mask)\n        if needs_ngroups:\n            func = partial(func, ngroups)\n        func(**kwargs)\n        if result_is_index:\n            result = algorithms.take_nd(obj.values, result)\n        if post_processing:\n            result = post_processing(result, inferences)\n        output[name] = result\n    if aggregate:\n        return self._wrap_aggregated_output(output)\n    else:\n        return self._wrap_transformed_output(output)",
                            "@Substitution(name='groupby')\n@Appender(_common_see_also)\ndef shift(self, periods=1, freq=None, axis=0, fill_value=None):\n    \"\"\"\n    Shift each group by periods observations.\n\n    Parameters\n    ----------\n    periods : integer, default 1\n        number of periods to shift\n    freq : frequency string\n    axis : axis to shift, default 0\n    fill_value : optional\n\n        .. versionadded:: 0.24.0\n\n    Returns\n    -------\n    Series or DataFrame\n        Object shifted within each group.\n    \"\"\"\n    if freq is not None or axis != 0 or (not isna(fill_value)):\n        return self.apply(lambda x: x.shift(periods, freq, axis, fill_value))\n    return self._get_cythonized_result('group_shift_indexer', self.grouper, cython_dtype=np.int64, needs_ngroups=True, result_is_index=True, periods=periods)",
                            "@Substitution(name='groupby')\n@Appender(_common_see_also)\ndef pct_change(self, periods=1, fill_method='pad', limit=None, freq=None, axis=0):\n    \"\"\"\n    Calculate pct_change of each value to previous entry in group.\n\n    Returns\n    -------\n    Series or DataFrame\n        Percentage changes within each group.\n    \"\"\"\n    if freq is not None or axis != 0:\n        return self.apply(lambda x: x.pct_change(periods=periods, fill_method=fill_method, limit=limit, freq=freq, axis=axis))\n    filled = getattr(self, fill_method)(limit=limit)\n    fill_grp = filled.groupby(self.grouper.labels)\n    shifted = fill_grp.shift(periods=periods, freq=freq)\n    return filled / shifted - 1",
                            "@Substitution(name='groupby')\n@Substitution(see_also=_common_see_also)\ndef head(self, n=5):\n    \"\"\"\n    Return first n rows of each group.\n\n    Similar to ``.apply(lambda x: x.head(n))``, but it returns a subset of rows\n    from the original DataFrame with original index and order preserved\n    (``as_index`` flag is ignored).\n\n    Returns\n    -------\n    Series or DataFrame\n    %(see_also)s\n    Examples\n    --------\n\n    >>> df = pd.DataFrame([[1, 2], [1, 4], [5, 6]],\n    ...                   columns=['A', 'B'])\n    >>> df.groupby('A').head(1)\n       A  B\n    0  1  2\n    2  5  6\n    \"\"\"\n    self._reset_group_selection()\n    mask = self._cumcount_array() < n\n    return self._selected_obj[mask]",
                            "@Substitution(name='groupby')\n@Substitution(see_also=_common_see_also)\ndef tail(self, n=5):\n    \"\"\"\n    Return last n rows of each group.\n\n    Similar to ``.apply(lambda x: x.tail(n))``, but it returns a subset of rows\n    from the original DataFrame with original index and order preserved\n    (``as_index`` flag is ignored).\n\n    Returns\n    -------\n    Series or DataFrame\n    %(see_also)s\n    Examples\n    --------\n\n    >>> df = pd.DataFrame([['a', 1], ['a', 2], ['b', 1], ['b', 2]],\n    ...                   columns=['A', 'B'])\n    >>> df.groupby('A').tail(1)\n       A  B\n    1  a  2\n    3  b  2\n    \"\"\"\n    self._reset_group_selection()\n    mask = self._cumcount_array(ascending=False) < n\n    return self._selected_obj[mask]",
                            "def _reindex_output(self, output):\n    \"\"\"\n    If we have categorical groupers, then we might want to make sure that\n    we have a fully re-indexed output to the levels. This means expanding\n    the output space to accommodate all values in the cartesian product of\n    our groups, regardless of whether they were observed in the data or\n    not. This will expand the output space if there are missing groups.\n\n    The method returns early without modifying the input if the number of\n    groupings is less than 2, self.observed == True or none of the groupers\n    are categorical.\n\n    Parameters\n    ----------\n    output: Series or DataFrame\n        Object resulting from grouping and applying an operation.\n\n    Returns\n    -------\n    Series or DataFrame\n        Object (potentially) re-indexed to include all possible groups.\n    \"\"\"\n    groupings = self.grouper.groupings\n    if groupings is None:\n        return output\n    elif len(groupings) == 1:\n        return output\n    elif self.observed:\n        return output\n    elif not any((isinstance(ping.grouper, (Categorical, CategoricalIndex)) for ping in groupings)):\n        return output\n    levels_list = [ping.group_index for ping in groupings]\n    index, _ = MultiIndex.from_product(levels_list, names=self.grouper.names).sortlevel()\n    if self.as_index:\n        d = {self.obj._get_axis_name(self.axis): index, 'copy': False}\n        return output.reindex(**d)\n    in_axis_grps = ((i, ping.name) for i, ping in enumerate(groupings) if ping.in_axis)\n    g_nums, g_names = zip(*in_axis_grps)\n    output = output.drop(labels=list(g_names), axis=1)\n    output = output.set_index(self.grouper.result_index).reindex(index, copy=False)\n    output = output.reset_index(level=g_nums)\n    return output.reset_index(drop=True)",
                            "def objs_to_bool(vals: np.ndarray) -> Tuple[np.ndarray, Type]:\n    if is_object_dtype(vals):\n        vals = np.array([bool(x) for x in vals])\n    else:\n        vals = vals.astype(np.bool)\n    return (vals.view(np.uint8), np.bool)",
                            "def result_to_bool(result: np.ndarray, inference: Type) -> np.ndarray:\n    return result.astype(inference, copy=False)",
                            "def groupby_function(name, alias, npfunc, numeric_only=True, min_count=-1):\n    _local_template = '\\n            Compute %(f)s of group values.\\n\\n            Returns\\n            -------\\n            Series or DataFrame\\n                Computed %(f)s of values within each group.\\n            '\n\n    @Substitution(name='groupby', f=name)\n    @Appender(_common_see_also)\n    @Appender(_local_template)\n    def f(self, **kwargs):\n        if 'numeric_only' not in kwargs:\n            kwargs['numeric_only'] = numeric_only\n        if 'min_count' not in kwargs:\n            kwargs['min_count'] = min_count\n        self._set_group_selection()\n        try:\n            return self._cython_agg_general(alias, alt=npfunc, **kwargs)\n        except AssertionError as e:\n            raise SpecificationError(str(e))\n        except Exception:\n            pass\n        result = self.aggregate(lambda x: npfunc(x, axis=self.axis))\n        if isinstance(result, DataFrame):\n            for col in result.columns:\n                result[col] = self._try_cast(result[col], self.obj[col])\n        else:\n            result = self._try_cast(result, self.obj)\n        return result\n    set_function_name(f, name, cls)\n    return f",
                            "def first_compat(x, axis=0):\n\n    def first(x):\n        x = x.to_numpy()\n        x = x[notna(x)]\n        if len(x) == 0:\n            return np.nan\n        return x[0]\n    if isinstance(x, DataFrame):\n        return x.apply(first, axis=axis)\n    else:\n        return first(x)",
                            "def last_compat(x, axis=0):\n\n    def last(x):\n        x = x.to_numpy()\n        x = x[notna(x)]\n        if len(x) == 0:\n            return np.nan\n        return x[-1]\n    if isinstance(x, DataFrame):\n        return x.apply(last, axis=axis)\n    else:\n        return last(x)",
                            "def pre_processor(vals: np.ndarray) -> Tuple[np.ndarray, Optional[Type]]:\n    if is_object_dtype(vals):\n        raise TypeError(\"'quantile' cannot be performed against 'object' dtypes!\")\n    inference = None\n    if is_integer_dtype(vals):\n        inference = np.int64\n    elif is_datetime64_dtype(vals):\n        inference = 'datetime64[ns]'\n        vals = vals.astype(np.float)\n    return (vals, inference)",
                            "def post_processor(vals: np.ndarray, inference: Optional[Type]) -> np.ndarray:\n    if inference:\n        if not (is_integer_dtype(inference) and interpolation in {'linear', 'midpoint'}):\n            vals = vals.astype(inference)\n    return vals",
                            "@Substitution(name='groupby', f=name)\n@Appender(_common_see_also)\n@Appender(_local_template)\ndef f(self, **kwargs):\n    if 'numeric_only' not in kwargs:\n        kwargs['numeric_only'] = numeric_only\n    if 'min_count' not in kwargs:\n        kwargs['min_count'] = min_count\n    self._set_group_selection()\n    try:\n        return self._cython_agg_general(alias, alt=npfunc, **kwargs)\n    except AssertionError as e:\n        raise SpecificationError(str(e))\n    except Exception:\n        pass\n    result = self.aggregate(lambda x: npfunc(x, axis=self.axis))\n    if isinstance(result, DataFrame):\n        for col in result.columns:\n            result[col] = self._try_cast(result[col], self.obj[col])\n    else:\n        result = self._try_cast(result, self.obj)\n    return result",
                            "def first(x):\n    x = x.to_numpy()\n    x = x[notna(x)]\n    if len(x) == 0:\n        return np.nan\n    return x[0]",
                            "def last(x):\n    x = x.to_numpy()\n    x = x[notna(x)]\n    if len(x) == 0:\n        return np.nan\n    return x[-1]",
                            "def f(x):\n    if isinstance(x, np.ndarray):\n        x = Series(x)\n    return x.median(axis=self.axis, **kwargs)"
                        ],
                        "constructor_variables": [],
                        "class_level_variables": [
                            "ffill",
                            "bfill"
                        ],
                        "class_decorators": [],
                        "function_signatures": [
                            "_bool_agg(self, val_test, skipna)",
                            "any(self, skipna=True)",
                            "all(self, skipna=True)",
                            "count(self)",
                            "mean(self, *args, **kwargs)",
                            "median(self, **kwargs)",
                            "std(self, ddof=1, *args, **kwargs)",
                            "var(self, ddof=1, *args, **kwargs)",
                            "sem(self, ddof=1)",
                            "size(self)",
                            "_add_numeric_operations(cls)",
                            "ohlc(self)",
                            "describe(self, **kwargs)",
                            "resample(self, rule, *args, **kwargs)",
                            "rolling(self, *args, **kwargs)",
                            "expanding(self, *args, **kwargs)",
                            "_fill(self, direction, limit=None)",
                            "pad(self, limit=None)",
                            "backfill(self, limit=None)",
                            "nth(self, n: Union[int, List[int]], dropna: Optional[str]=None) -> DataFrame",
                            "quantile(self, q=0.5, interpolation='linear')",
                            "ngroup(self, ascending=True)",
                            "cumcount(self, ascending=True)",
                            "rank(self, method='average', ascending=True, na_option='keep', pct=False, axis=0)",
                            "cumprod(self, axis=0, *args, **kwargs)",
                            "cumsum(self, axis=0, *args, **kwargs)",
                            "cummin(self, axis=0, **kwargs)",
                            "cummax(self, axis=0, **kwargs)",
                            "_get_cythonized_result(self, how, grouper, aggregate=False, cython_dtype=None, needs_values=False, needs_mask=False, needs_ngroups=False, result_is_index=False, pre_processing=None, post_processing=None, **kwargs)",
                            "shift(self, periods=1, freq=None, axis=0, fill_value=None)",
                            "pct_change(self, periods=1, fill_method='pad', limit=None, freq=None, axis=0)",
                            "head(self, n=5)",
                            "tail(self, n=5)",
                            "_reindex_output(self, output)",
                            "objs_to_bool(vals: np.ndarray) -> Tuple[np.ndarray, Type]",
                            "result_to_bool(result: np.ndarray, inference: Type) -> np.ndarray",
                            "groupby_function(name, alias, npfunc, numeric_only=True, min_count=-1)",
                            "first_compat(x, axis=0)",
                            "last_compat(x, axis=0)",
                            "pre_processor(vals: np.ndarray) -> Tuple[np.ndarray, Optional[Type]]",
                            "post_processor(vals: np.ndarray, inference: Optional[Type]) -> np.ndarray",
                            "f(self, **kwargs)",
                            "first(x)",
                            "last(x)",
                            "f(x)"
                        ]
                    },
                    "variable_values": [
                        [
                            {
                                "result_is_index": {
                                    "variable_value": "True",
                                    "variable_type": "bool",
                                    "variable_shape": null
                                },
                                "aggregate": {
                                    "variable_value": "False",
                                    "variable_type": "bool",
                                    "variable_shape": null
                                },
                                "post_processing": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "pre_processing": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "needs_values": {
                                    "variable_value": "False",
                                    "variable_type": "bool",
                                    "variable_shape": null
                                },
                                "labels": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "_": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "ngroups": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "grouper.group_info": {
                                    "variable_value": "(array([0, 1, 0, 1, 0, 1]), array([0, 1]), 2)",
                                    "variable_type": "tuple",
                                    "variable_shape": "3"
                                },
                                "grouper": {
                                    "variable_value": "<pandas.core.groupby.ops.BaseGrouper object at 0x11bbe9430>",
                                    "variable_type": "BaseGrouper",
                                    "variable_shape": "(2,)"
                                },
                                "output": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "collections.OrderedDict": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "collections": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "base_func": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "libgroupby": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "how": {
                                    "variable_value": "'group_fillna_indexer'",
                                    "variable_type": "str",
                                    "variable_shape": "20"
                                },
                                "name": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "obj": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self._iterate_slices": {
                                    "variable_value": "<bound method NDFrameGroupBy._iterate_slices of <pandas.core.groupby.generic.DataFrameGroupBy object at 0x11bbe9e20>>",
                                    "variable_type": "method",
                                    "variable_shape": null
                                },
                                "self": {
                                    "variable_value": "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x11bbe9e20>",
                                    "variable_type": "DataFrameGroupBy",
                                    "variable_shape": "2"
                                },
                                "result_sz": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "obj.values": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "cython_dtype": {
                                    "variable_value": "<class 'numpy.int64'>",
                                    "variable_type": "type",
                                    "variable_shape": "<attribute 'shape' of 'numpy.generic' objects>"
                                },
                                "obj.values.dtype": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "result": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "np.zeros": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "np": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "func": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "partial": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "inferences": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "vals": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "needs_mask": {
                                    "variable_value": "True",
                                    "variable_type": "bool",
                                    "variable_shape": null
                                },
                                "mask": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "view": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "isna": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "np.uint8": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "needs_ngroups": {
                                    "variable_value": "False",
                                    "variable_type": "bool",
                                    "variable_shape": null
                                },
                                "kwargs": {
                                    "variable_value": "{'direction': 'ffill', 'limit': -1}",
                                    "variable_type": "dict",
                                    "variable_shape": "2"
                                },
                                "algorithms.take_nd": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "algorithms": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self._wrap_aggregated_output": {
                                    "variable_value": "<bound method DataFrameGroupBy._wrap_aggregated_output of <pandas.core.groupby.generic.DataFrameGroupBy object at 0x11bbe9e20>>",
                                    "variable_type": "method",
                                    "variable_shape": null
                                },
                                "self._wrap_transformed_output": {
                                    "variable_value": "<bound method DataFrameGroupBy._wrap_transformed_output of <pandas.core.groupby.generic.DataFrameGroupBy object at 0x11bbe9e20>>",
                                    "variable_type": "method",
                                    "variable_shape": null
                                }
                            },
                            {}
                        ]
                    ],
                    "angelic_variable_values": [
                        [
                            {
                                "result_is_index": {
                                    "variable_value": "True",
                                    "variable_type": "bool",
                                    "variable_shape": null
                                },
                                "aggregate": {
                                    "variable_value": "False",
                                    "variable_type": "bool",
                                    "variable_shape": null
                                },
                                "post_processing": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "pre_processing": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "needs_values": {
                                    "variable_value": "False",
                                    "variable_type": "bool",
                                    "variable_shape": null
                                },
                                "labels": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "_": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "ngroups": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "grouper.group_info": {
                                    "variable_value": "(array([0, 1, 0, 1, 0, 1]), array([0, 1]), 2)",
                                    "variable_type": "tuple",
                                    "variable_shape": "3"
                                },
                                "grouper": {
                                    "variable_value": "<pandas.core.groupby.ops.BaseGrouper object at 0x11a42bd60>",
                                    "variable_type": "BaseGrouper",
                                    "variable_shape": "(2,)"
                                },
                                "output": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "collections.OrderedDict": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "collections": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "base_func": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "libgroupby": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "how": {
                                    "variable_value": "'group_fillna_indexer'",
                                    "variable_type": "str",
                                    "variable_shape": "20"
                                },
                                "name": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "obj": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self._iterate_slices": {
                                    "variable_value": "<bound method NDFrameGroupBy._iterate_slices of <pandas.core.groupby.generic.DataFrameGroupBy object at 0x11a42b310>>",
                                    "variable_type": "method",
                                    "variable_shape": null
                                },
                                "self": {
                                    "variable_value": "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x11a42b310>",
                                    "variable_type": "DataFrameGroupBy",
                                    "variable_shape": "2"
                                },
                                "values": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "obj._data._values": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "obj._data": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "result_sz": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "cython_dtype": {
                                    "variable_value": "<class 'numpy.int64'>",
                                    "variable_type": "type",
                                    "variable_shape": "<attribute 'shape' of 'numpy.generic' objects>"
                                },
                                "values.dtype": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "result": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "np.zeros": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "np": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "func": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "partial": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "inferences": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "vals": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "needs_mask": {
                                    "variable_value": "True",
                                    "variable_type": "bool",
                                    "variable_shape": null
                                },
                                "mask": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "view": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "isna": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "np.uint8": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "needs_ngroups": {
                                    "variable_value": "False",
                                    "variable_type": "bool",
                                    "variable_shape": null
                                },
                                "kwargs": {
                                    "variable_value": "{'direction': 'ffill', 'limit': -1}",
                                    "variable_type": "dict",
                                    "variable_shape": "2"
                                },
                                "algorithms.take_nd": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "algorithms": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self._wrap_aggregated_output": {
                                    "variable_value": "<bound method DataFrameGroupBy._wrap_aggregated_output of <pandas.core.groupby.generic.DataFrameGroupBy object at 0x11a42b310>>",
                                    "variable_type": "method",
                                    "variable_shape": null
                                },
                                "self._wrap_transformed_output": {
                                    "variable_value": "<bound method DataFrameGroupBy._wrap_transformed_output of <pandas.core.groupby.generic.DataFrameGroupBy object at 0x11a42b310>>",
                                    "variable_type": "method",
                                    "variable_shape": null
                                }
                            },
                            {}
                        ]
                    ]
                }
            ],
            "inscope_functions": [
                "@contextmanager\ndef _group_selection_context(groupby):\n    \"\"\"\n    Set / reset the _group_selection_context.\n    \"\"\"\n    groupby._set_group_selection()\n    yield groupby\n    groupby._reset_group_selection()",
                "@Appender(GroupBy.__doc__)\ndef groupby(obj, by, **kwds):\n    if isinstance(obj, Series):\n        from pandas.core.groupby.generic import SeriesGroupBy\n\n        klass = SeriesGroupBy\n    elif isinstance(obj, DataFrame):\n        from pandas.core.groupby.generic import DataFrameGroupBy\n\n        klass = DataFrameGroupBy\n    else:\n        raise TypeError(\"invalid type: {}\".format(obj))\n\n    return klass(obj, by, **kwds)",
                "def __init__(self, groupby):\n    self._groupby = groupby",
                "def __call__(self, *args, **kwargs):\n    def f(self):\n        return self.plot(*args, **kwargs)\n\n    f.__name__ = \"plot\"\n    return self._groupby.apply(f)",
                "def __getattr__(self, name):\n    def attr(*args, **kwargs):\n        def f(self):\n            return getattr(self.plot, name)(*args, **kwargs)\n\n        return self._groupby.apply(f)\n\n    return attr",
                "def __init__(\n    self,\n    obj: NDFrame,\n    keys=None,\n    axis=0,\n    level=None,\n    grouper=None,\n    exclusions=None,\n    selection=None,\n    as_index=True,\n    sort=True,\n    group_keys=True,\n    squeeze=False,\n    observed=False,\n    **kwargs\n):\n\n    self._selection = selection\n\n    assert isinstance(obj, NDFrame), type(obj)\n    obj._consolidate_inplace()\n\n    self.level = level\n\n    if not as_index:\n        if not isinstance(obj, DataFrame):\n            raise TypeError(\"as_index=False only valid with DataFrame\")\n        if axis != 0:\n            raise ValueError(\"as_index=False only valid for axis=0\")\n\n    self.as_index = as_index\n    self.keys = keys\n    self.sort = sort\n    self.group_keys = group_keys\n    self.squeeze = squeeze\n    self.observed = observed\n    self.mutated = kwargs.pop(\"mutated\", False)\n\n    if grouper is None:\n        from pandas.core.groupby.grouper import _get_grouper\n\n        grouper, exclusions, obj = _get_grouper(\n            obj,\n            keys,\n            axis=axis,\n            level=level,\n            sort=sort,\n            observed=observed,\n            mutated=self.mutated,\n        )\n\n    self.obj = obj\n    self.axis = obj._get_axis_number(axis)\n    self.grouper = grouper\n    self.exclusions = set(exclusions) if exclusions else set()\n\n    # we accept no other args\n    validate_kwargs(\"group\", kwargs, {})",
                "def __len__(self):\n    return len(self.groups)",
                "def __repr__(self):\n    # TODO: Better repr for GroupBy object\n    return object.__repr__(self)",
                "def _assure_grouper(self):\n    \"\"\"\n    We create the grouper on instantiation sub-classes may have a\n    different policy.\n    \"\"\"\n    pass",
                "@property\ndef groups(self):\n    \"\"\"\n    Dict {group name -> group labels}.\n    \"\"\"\n    self._assure_grouper()\n    return self.grouper.groups",
                "@property\ndef ngroups(self):\n    self._assure_grouper()\n    return self.grouper.ngroups",
                "@property\ndef indices(self):\n    \"\"\"\n    Dict {group name -> group indices}.\n    \"\"\"\n    self._assure_grouper()\n    return self.grouper.indices",
                "def _get_indices(self, names):\n    \"\"\"\n    Safe get multiple indices, translate keys for\n    datelike to underlying repr.\n    \"\"\"\n\n    def get_converter(s):\n        # possibly convert to the actual key types\n        # in the indices, could be a Timestamp or a np.datetime64\n        if isinstance(s, (Timestamp, datetime.datetime)):\n            return lambda key: Timestamp(key)\n        elif isinstance(s, np.datetime64):\n            return lambda key: Timestamp(key).asm8\n        else:\n            return lambda key: key\n\n    if len(names) == 0:\n        return []\n\n    if len(self.indices) > 0:\n        index_sample = next(iter(self.indices))\n    else:\n        index_sample = None  # Dummy sample\n\n    name_sample = names[0]\n    if isinstance(index_sample, tuple):\n        if not isinstance(name_sample, tuple):\n            msg = \"must supply a tuple to get_group with multiple grouping keys\"\n            raise ValueError(msg)\n        if not len(name_sample) == len(index_sample):\n            try:\n                # If the original grouper was a tuple\n                return [self.indices[name] for name in names]\n            except KeyError:\n                # turns out it wasn't a tuple\n                msg = (\n                    \"must supply a same-length tuple to get_group\"\n                    \" with multiple grouping keys\"\n                )\n                raise ValueError(msg)\n\n        converters = [get_converter(s) for s in index_sample]\n        names = (tuple(f(n) for f, n in zip(converters, name)) for name in names)\n\n    else:\n        converter = get_converter(index_sample)\n        names = (converter(name) for name in names)\n\n    return [self.indices.get(name, []) for name in names]",
                "def _get_index(self, name):\n    \"\"\"\n    Safe get index, translate keys for datelike to underlying repr.\n    \"\"\"\n    return self._get_indices([name])[0]",
                "@cache_readonly\ndef _selected_obj(self):\n\n    if self._selection is None or isinstance(self.obj, Series):\n        if self._group_selection is not None:\n            return self.obj[self._group_selection]\n        return self.obj\n    else:\n        return self.obj[self._selection]",
                "def _reset_group_selection(self):\n    \"\"\"\n    Clear group based selection.\n\n    Used for methods needing to return info on each group regardless of\n    whether a group selection was previously set.\n    \"\"\"\n    if self._group_selection is not None:\n        # GH12839 clear cached selection too when changing group selection\n        self._group_selection = None\n        self._reset_cache(\"_selected_obj\")",
                "def _set_group_selection(self):\n    \"\"\"\n    Create group based selection.\n\n    Used when selection is not passed directly but instead via a grouper.\n\n    NOTE: this should be paired with a call to _reset_group_selection\n    \"\"\"\n    grp = self.grouper\n    if not (\n        self.as_index\n        and getattr(grp, \"groupings\", None) is not None\n        and self.obj.ndim > 1\n        and self._group_selection is None\n    ):\n        return\n\n    ax = self.obj._info_axis\n    groupers = [g.name for g in grp.groupings if g.level is None and g.in_axis]\n\n    if len(groupers):\n        # GH12839 clear selected obj cache when group selection changes\n        self._group_selection = ax.difference(Index(groupers), sort=False).tolist()\n        self._reset_cache(\"_selected_obj\")",
                "def _set_result_index_ordered(self, result):\n    # set the result index on the passed values object and\n    # return the new object, xref 8046\n\n    # the values/counts are repeated according to the group index\n    # shortcut if we have an already ordered grouper\n    if not self.grouper.is_monotonic:\n        index = Index(np.concatenate(self._get_indices(self.grouper.result_index)))\n        result.set_axis(index, axis=self.axis, inplace=True)\n        result = result.sort_index(axis=self.axis)\n\n    result.set_axis(self.obj._get_axis(self.axis), axis=self.axis, inplace=True)\n    return result",
                "def _dir_additions(self):\n    return self.obj._dir_additions() | self._apply_whitelist",
                "def __getattr__(self, attr):\n    if attr in self._internal_names_set:\n        return object.__getattribute__(self, attr)\n    if attr in self.obj:\n        return self[attr]\n    if hasattr(self.obj, attr):\n        return self._make_wrapper(attr)\n\n    raise AttributeError(\n        \"%r object has no attribute %r\" % (type(self).__name__, attr)\n    )",
                "    @Substitution(\n        klass=\"GroupBy\",\n        versionadded=\".. versionadded:: 0.21.0\",\n        examples=\"\"\"\\\n>>> df = pd.DataFrame({'A': 'a b a b'.split(), 'B': [1, 2, 3, 4]})\n>>> df\n   A  B\n0  a  1\n1  b  2\n2  a  3\n3  b  4\n\nTo get the difference between each groups maximum and minimum value in one\npass, you can do\n\n>>> df.groupby('A').pipe(lambda x: x.max() - x.min())\n   B\nA\na  2\nb  2\"\"\",\n    )\n    @Appender(_pipe_template)\n    def pipe(self, func, *args, **kwargs):\n        return com.pipe(self, func, *args, **kwargs)",
                "def _make_wrapper(self, name):\n    if name not in self._apply_whitelist:\n        is_callable = callable(getattr(self._selected_obj, name, None))\n        kind = \" callable \" if is_callable else \" \"\n        msg = (\n            \"Cannot access{0}attribute {1!r} of {2!r} objects, try \"\n            \"using the 'apply' method\".format(kind, name, type(self).__name__)\n        )\n        raise AttributeError(msg)\n\n    self._set_group_selection()\n\n    # need to setup the selection\n    # as are not passed directly but in the grouper\n    f = getattr(self._selected_obj, name)\n    if not isinstance(f, types.MethodType):\n        return self.apply(lambda self: getattr(self, name))\n\n    f = getattr(type(self._selected_obj), name)\n\n    def wrapper(*args, **kwargs):\n        # a little trickery for aggregation functions that need an axis\n        # argument\n        kwargs_with_axis = kwargs.copy()\n        if \"axis\" not in kwargs_with_axis or kwargs_with_axis[\"axis\"] is None:\n            kwargs_with_axis[\"axis\"] = self.axis\n\n        def curried_with_axis(x):\n            return f(x, *args, **kwargs_with_axis)\n\n        def curried(x):\n            return f(x, *args, **kwargs)\n\n        # preserve the name so we can detect it when calling plot methods,\n        # to avoid duplicates\n        curried.__name__ = curried_with_axis.__name__ = name\n\n        # special case otherwise extra plots are created when catching the\n        # exception below\n        if name in base.plotting_methods:\n            return self.apply(curried)\n\n        try:\n            return self.apply(curried_with_axis)\n        except Exception:\n            try:\n                return self.apply(curried)\n            except Exception:\n\n                # related to : GH3688\n                # try item-by-item\n                # this can be called recursively, so need to raise\n                # ValueError\n                # if we don't have this method to indicated to aggregate to\n                # mark this column as an error\n                try:\n                    return self._aggregate_item_by_item(name, *args, **kwargs)\n                except AttributeError:\n                    # e.g. SparseArray has no flags attr\n                    raise ValueError\n\n    return wrapper",
                "def get_group(self, name, obj=None):\n    \"\"\"\n    Construct DataFrame from group with provided name.\n\n    Parameters\n    ----------\n    name : object\n        the name of the group to get as a DataFrame\n    obj : DataFrame, default None\n        the DataFrame to take the DataFrame out of.  If\n        it is None, the object groupby was called on will\n        be used\n\n    Returns\n    -------\n    group : same type as obj\n    \"\"\"\n    if obj is None:\n        obj = self._selected_obj\n\n    inds = self._get_index(name)\n    if not len(inds):\n        raise KeyError(name)\n\n    return obj.take(inds, axis=self.axis)",
                "def __iter__(self):\n    \"\"\"\n    Groupby iterator.\n\n    Returns\n    -------\n    Generator yielding sequence of (name, subsetted object)\n    for each group\n    \"\"\"\n    return self.grouper.get_iterator(self.obj, axis=self.axis)",
                "@Appender(\n    _apply_docs[\"template\"].format(\n        input=\"dataframe\", examples=_apply_docs[\"dataframe_examples\"]\n    )\n)\ndef apply(self, func, *args, **kwargs):\n\n    func = self._is_builtin_func(func)\n\n    # this is needed so we don't try and wrap strings. If we could\n    # resolve functions to their callable functions prior, this\n    # wouldn't be needed\n    if args or kwargs:\n        if callable(func):\n\n            @wraps(func)\n            def f(g):\n                with np.errstate(all=\"ignore\"):\n                    return func(g, *args, **kwargs)\n\n        else:\n            raise ValueError(\n                \"func must be a callable if args or kwargs are supplied\"\n            )\n    else:\n        f = func\n\n    # ignore SettingWithCopy here in case the user mutates\n    with option_context(\"mode.chained_assignment\", None):\n        try:\n            result = self._python_apply_general(f)\n        except TypeError:\n            # gh-20949\n            # try again, with .apply acting as a filtering\n            # operation, by excluding the grouping column\n            # This would normally not be triggered\n            # except if the udf is trying an operation that\n            # fails on *some* columns, e.g. a numeric operation\n            # on a string grouper column\n\n            with _group_selection_context(self):\n                return self._python_apply_general(f)\n\n    return result",
                "def _python_apply_general(self, f):\n    keys, values, mutated = self.grouper.apply(f, self._selected_obj, self.axis)\n\n    return self._wrap_applied_output(\n        keys, values, not_indexed_same=mutated or self.mutated\n    )",
                "def _iterate_slices(self):\n    yield self._selection_name, self._selected_obj",
                "def transform(self, func, *args, **kwargs):\n    raise AbstractMethodError(self)",
                "def _cumcount_array(self, ascending=True):\n    \"\"\"\n    Parameters\n    ----------\n    ascending : bool, default True\n        If False, number in reverse, from length of group - 1 to 0.\n\n    Notes\n    -----\n    this is currently implementing sort=False\n    (though the default is sort=True) for groupby in general\n    \"\"\"\n    ids, _, ngroups = self.grouper.group_info\n    sorter = get_group_index_sorter(ids, ngroups)\n    ids, count = ids[sorter], len(ids)\n\n    if count == 0:\n        return np.empty(0, dtype=np.int64)\n\n    run = np.r_[True, ids[:-1] != ids[1:]]\n    rep = np.diff(np.r_[np.nonzero(run)[0], count])\n    out = (~run).cumsum()\n\n    if ascending:\n        out -= np.repeat(out[run], rep)\n    else:\n        out = np.repeat(out[np.r_[run[1:], True]], rep) - out\n\n    rev = np.empty(count, dtype=np.intp)\n    rev[sorter] = np.arange(count, dtype=np.intp)\n    return out[rev].astype(np.int64, copy=False)",
                "def _try_cast(self, result, obj, numeric_only=False):\n    \"\"\"\n    Try to cast the result to our obj original type,\n    we may have roundtripped through object in the mean-time.\n\n    If numeric_only is True, then only try to cast numerics\n    and not datetimelikes.\n\n    \"\"\"\n    if obj.ndim > 1:\n        dtype = obj._values.dtype\n    else:\n        dtype = obj.dtype\n\n    if not is_scalar(result):\n        if is_datetime64tz_dtype(dtype):\n            # GH 23683\n            # Prior results _may_ have been generated in UTC.\n            # Ensure we localize to UTC first before converting\n            # to the target timezone\n            arr = extract_array(obj)\n            try:\n                result = arr._from_sequence(result, dtype=\"datetime64[ns, UTC]\")\n                result = result.astype(dtype)\n            except TypeError:\n                # _try_cast was called at a point where the result\n                # was already tz-aware\n                pass\n        elif is_extension_array_dtype(dtype):\n            # The function can return something of any type, so check\n            # if the type is compatible with the calling EA.\n\n            # return the same type (Series) as our caller\n            try:\n                result = obj._values._from_sequence(result, dtype=dtype)\n            except Exception:\n                # https://github.com/pandas-dev/pandas/issues/22850\n                # pandas has no control over what 3rd-party ExtensionArrays\n                # do in _values_from_sequence. We still want ops to work\n                # though, so we catch any regular Exception.\n                pass\n        elif numeric_only and is_numeric_dtype(dtype) or not numeric_only:\n            result = maybe_downcast_to_dtype(result, dtype)\n\n    return result",
                "def _transform_should_cast(self, func_nm):\n    \"\"\"\n    Parameters\n    ----------\n    func_nm: str\n        The name of the aggregation function being performed\n\n    Returns\n    -------\n    bool\n        Whether transform should attempt to cast the result of aggregation\n    \"\"\"\n    return (self.size().fillna(0) > 0).any() and (\n        func_nm not in base.cython_cast_blacklist\n    )",
                "def _cython_transform(self, how, numeric_only=True, **kwargs):\n    output = collections.OrderedDict()\n    for name, obj in self._iterate_slices():\n        is_numeric = is_numeric_dtype(obj.dtype)\n        if numeric_only and not is_numeric:\n            continue\n\n        try:\n            result, names = self.grouper.transform(obj.values, how, **kwargs)\n        except NotImplementedError:\n            continue\n        except AssertionError as e:\n            raise GroupByError(str(e))\n        if self._transform_should_cast(how):\n            output[name] = self._try_cast(result, obj)\n        else:\n            output[name] = result\n\n    if len(output) == 0:\n        raise DataError(\"No numeric types to aggregate\")\n\n    return self._wrap_transformed_output(output, names)",
                "def _cython_agg_general(self, how, alt=None, numeric_only=True, min_count=-1):\n    output = {}\n    for name, obj in self._iterate_slices():\n        is_numeric = is_numeric_dtype(obj.dtype)\n        if numeric_only and not is_numeric:\n            continue\n\n        try:\n            result, names = self.grouper.aggregate(\n                obj.values, how, min_count=min_count\n            )\n        except AssertionError as e:\n            raise GroupByError(str(e))\n        output[name] = self._try_cast(result, obj)\n\n    if len(output) == 0:\n        raise DataError(\"No numeric types to aggregate\")\n\n    return self._wrap_aggregated_output(output, names)",
                "def _python_agg_general(self, func, *args, **kwargs):\n    func = self._is_builtin_func(func)\n    f = lambda x: func(x, *args, **kwargs)\n\n    # iterate through \"columns\" ex exclusions to populate output dict\n    output = {}\n    for name, obj in self._iterate_slices():\n        try:\n            result, counts = self.grouper.agg_series(obj, f)\n            output[name] = self._try_cast(result, obj, numeric_only=True)\n        except TypeError:\n            continue\n\n    if len(output) == 0:\n        return self._python_apply_general(f)\n\n    if self.grouper._filter_empty_groups:\n\n        mask = counts.ravel() > 0\n        for name, result in output.items():\n\n            # since we are masking, make sure that we have a float object\n            values = result\n            if is_numeric_dtype(values.dtype):\n                values = ensure_float(values)\n\n            output[name] = self._try_cast(values[mask], result)\n\n    return self._wrap_aggregated_output(output)",
                "def _wrap_applied_output(self, *args, **kwargs):\n    raise AbstractMethodError(self)",
                "def _concat_objects(self, keys, values, not_indexed_same=False):\n    from pandas.core.reshape.concat import concat\n\n    def reset_identity(values):\n        # reset the identities of the components\n        # of the values to prevent aliasing\n        for v in com.not_none(*values):\n            ax = v._get_axis(self.axis)\n            ax._reset_identity()\n        return values\n\n    if not not_indexed_same:\n        result = concat(values, axis=self.axis)\n        ax = self._selected_obj._get_axis(self.axis)\n\n        if isinstance(result, Series):\n            result = result.reindex(ax)\n        else:\n\n            # this is a very unfortunate situation\n            # we have a multi-index that is NOT lexsorted\n            # and we have a result which is duplicated\n            # we can't reindex, so we resort to this\n            # GH 14776\n            if isinstance(ax, MultiIndex) and not ax.is_unique:\n                indexer = algorithms.unique1d(\n                    result.index.get_indexer_for(ax.values)\n                )\n                result = result.take(indexer, axis=self.axis)\n            else:\n                result = result.reindex(ax, axis=self.axis)\n\n    elif self.group_keys:\n\n        values = reset_identity(values)\n        if self.as_index:\n\n            # possible MI return case\n            group_keys = keys\n            group_levels = self.grouper.levels\n            group_names = self.grouper.names\n\n            result = concat(\n                values,\n                axis=self.axis,\n                keys=group_keys,\n                levels=group_levels,\n                names=group_names,\n                sort=False,\n            )\n        else:\n\n            # GH5610, returns a MI, with the first level being a\n            # range index\n            keys = list(range(len(values)))\n            result = concat(values, axis=self.axis, keys=keys)\n    else:\n        values = reset_identity(values)\n        result = concat(values, axis=self.axis)\n\n    if (\n        isinstance(result, Series)\n        and getattr(self, \"_selection_name\", None) is not None\n    ):\n\n        result.name = self._selection_name\n\n    return result",
                "def _apply_filter(self, indices, dropna):\n    if len(indices) == 0:\n        indices = np.array([], dtype=\"int64\")\n    else:\n        indices = np.sort(np.concatenate(indices))\n    if dropna:\n        filtered = self._selected_obj.take(indices, axis=self.axis)\n    else:\n        mask = np.empty(len(self._selected_obj.index), dtype=bool)\n        mask.fill(False)\n        mask[indices.astype(int)] = True\n        # mask fails to broadcast when passed to where; broadcast manually.\n        mask = np.tile(mask, list(self._selected_obj.shape[1:]) + [1]).T\n        filtered = self._selected_obj.where(mask)  # Fill with NaNs.\n    return filtered",
                "def _bool_agg(self, val_test, skipna):\n    \"\"\"\n    Shared func to call any / all Cython GroupBy implementations.\n    \"\"\"\n\n    def objs_to_bool(vals: np.ndarray) -> Tuple[np.ndarray, Type]:\n        if is_object_dtype(vals):\n            vals = np.array([bool(x) for x in vals])\n        else:\n            vals = vals.astype(np.bool)\n\n        return vals.view(np.uint8), np.bool\n\n    def result_to_bool(result: np.ndarray, inference: Type) -> np.ndarray:\n        return result.astype(inference, copy=False)\n\n    return self._get_cythonized_result(\n        \"group_any_all\",\n        self.grouper,\n        aggregate=True,\n        cython_dtype=np.uint8,\n        needs_values=True,\n        needs_mask=True,\n        pre_processing=objs_to_bool,\n        post_processing=result_to_bool,\n        val_test=val_test,\n        skipna=skipna,\n    )",
                "@Substitution(name=\"groupby\")\n@Appender(_common_see_also)\ndef any(self, skipna=True):\n    \"\"\"\n    Return True if any value in the group is truthful, else False.\n\n    Parameters\n    ----------\n    skipna : bool, default True\n        Flag to ignore nan values during truth testing\n\n    Returns\n    -------\n    bool\n    \"\"\"\n    return self._bool_agg(\"any\", skipna)",
                "@Substitution(name=\"groupby\")\n@Appender(_common_see_also)\ndef all(self, skipna=True):\n    \"\"\"\n    Return True if all values in the group are truthful, else False.\n\n    Parameters\n    ----------\n    skipna : bool, default True\n        Flag to ignore nan values during truth testing\n\n    Returns\n    -------\n    bool\n    \"\"\"\n    return self._bool_agg(\"all\", skipna)",
                "@Substitution(name=\"groupby\")\n@Appender(_common_see_also)\ndef count(self):\n    \"\"\"\n    Compute count of group, excluding missing values.\n\n    Returns\n    -------\n    Series or DataFrame\n        Count of values within each group.\n    \"\"\"\n\n    # defined here for API doc\n    raise NotImplementedError",
                "@Substitution(name=\"groupby\")\n@Substitution(see_also=_common_see_also)\ndef mean(self, *args, **kwargs):\n    \"\"\"\n    Compute mean of groups, excluding missing values.\n\n    Returns\n    -------\n    pandas.Series or pandas.DataFrame\n    %(see_also)s\n    Examples\n    --------\n    >>> df = pd.DataFrame({'A': [1, 1, 2, 1, 2],\n    ...                    'B': [np.nan, 2, 3, 4, 5],\n    ...                    'C': [1, 2, 1, 1, 2]}, columns=['A', 'B', 'C'])\n\n    Groupby one column and return the mean of the remaining columns in\n    each group.\n\n    >>> df.groupby('A').mean()\n         B         C\n    A\n    1  3.0  1.333333\n    2  4.0  1.500000\n\n    Groupby two columns and return the mean of the remaining column.\n\n    >>> df.groupby(['A', 'B']).mean()\n           C\n    A B\n    1 2.0  2\n      4.0  1\n    2 3.0  1\n      5.0  2\n\n    Groupby one column and return the mean of only particular column in\n    the group.\n\n    >>> df.groupby('A')['B'].mean()\n    A\n    1    3.0\n    2    4.0\n    Name: B, dtype: float64\n    \"\"\"\n    nv.validate_groupby_func(\"mean\", args, kwargs, [\"numeric_only\"])\n    try:\n        return self._cython_agg_general(\n            \"mean\", alt=lambda x, axis: Series(x).mean(**kwargs), **kwargs\n        )\n    except GroupByError:\n        raise\n    except Exception:\n        with _group_selection_context(self):\n            f = lambda x: x.mean(axis=self.axis, **kwargs)\n            return self._python_agg_general(f)",
                "@Substitution(name=\"groupby\")\n@Appender(_common_see_also)\ndef median(self, **kwargs):\n    \"\"\"\n    Compute median of groups, excluding missing values.\n\n    For multiple groupings, the result index will be a MultiIndex\n\n    Returns\n    -------\n    Series or DataFrame\n        Median of values within each group.\n    \"\"\"\n    try:\n        return self._cython_agg_general(\n            \"median\",\n            alt=lambda x, axis: Series(x).median(axis=axis, **kwargs),\n            **kwargs\n        )\n    except GroupByError:\n        raise\n    except Exception:\n\n        def f(x):\n            if isinstance(x, np.ndarray):\n                x = Series(x)\n            return x.median(axis=self.axis, **kwargs)\n\n        with _group_selection_context(self):\n            return self._python_agg_general(f)",
                "@Substitution(name=\"groupby\")\n@Appender(_common_see_also)\ndef std(self, ddof=1, *args, **kwargs):\n    \"\"\"\n    Compute standard deviation of groups, excluding missing values.\n\n    For multiple groupings, the result index will be a MultiIndex.\n\n    Parameters\n    ----------\n    ddof : integer, default 1\n        degrees of freedom\n\n    Returns\n    -------\n    Series or DataFrame\n        Standard deviation of values within each group.\n    \"\"\"\n\n    # TODO: implement at Cython level?\n    nv.validate_groupby_func(\"std\", args, kwargs)\n    return np.sqrt(self.var(ddof=ddof, **kwargs))",
                "@Substitution(name=\"groupby\")\n@Appender(_common_see_also)\ndef var(self, ddof=1, *args, **kwargs):\n    \"\"\"\n    Compute variance of groups, excluding missing values.\n\n    For multiple groupings, the result index will be a MultiIndex.\n\n    Parameters\n    ----------\n    ddof : integer, default 1\n        degrees of freedom\n\n    Returns\n    -------\n    Series or DataFrame\n        Variance of values within each group.\n    \"\"\"\n    nv.validate_groupby_func(\"var\", args, kwargs)\n    if ddof == 1:\n        try:\n            return self._cython_agg_general(\n                \"var\",\n                alt=lambda x, axis: Series(x).var(ddof=ddof, **kwargs),\n                **kwargs\n            )\n        except Exception:\n            f = lambda x: x.var(ddof=ddof, **kwargs)\n            with _group_selection_context(self):\n                return self._python_agg_general(f)\n    else:\n        f = lambda x: x.var(ddof=ddof, **kwargs)\n        with _group_selection_context(self):\n            return self._python_agg_general(f)",
                "@Substitution(name=\"groupby\")\n@Appender(_common_see_also)\ndef sem(self, ddof=1):\n    \"\"\"\n    Compute standard error of the mean of groups, excluding missing values.\n\n    For multiple groupings, the result index will be a MultiIndex.\n\n    Parameters\n    ----------\n    ddof : integer, default 1\n        degrees of freedom\n\n    Returns\n    -------\n    Series or DataFrame\n        Standard error of the mean of values within each group.\n    \"\"\"\n    return self.std(ddof=ddof) / np.sqrt(self.count())",
                "@Substitution(name=\"groupby\")\n@Appender(_common_see_also)\ndef size(self):\n    \"\"\"\n    Compute group sizes.\n\n    Returns\n    -------\n    Series\n        Number of rows in each group.\n    \"\"\"\n    result = self.grouper.size()\n\n    if isinstance(self.obj, Series):\n        result.name = getattr(self.obj, \"name\", None)\n    return result",
                "@classmethod\ndef _add_numeric_operations(cls):\n    \"\"\"\n    Add numeric operations to the GroupBy generically.\n    \"\"\"\n\n    def groupby_function(name, alias, npfunc, numeric_only=True, min_count=-1):\n\n        _local_template = \"\"\"\n        Compute %(f)s of group values.\n\n        Returns\n        -------\n        Series or DataFrame\n            Computed %(f)s of values within each group.\n        \"\"\"\n\n        @Substitution(name=\"groupby\", f=name)\n        @Appender(_common_see_also)\n        @Appender(_local_template)\n        def f(self, **kwargs):\n            if \"numeric_only\" not in kwargs:\n                kwargs[\"numeric_only\"] = numeric_only\n            if \"min_count\" not in kwargs:\n                kwargs[\"min_count\"] = min_count\n\n            self._set_group_selection()\n\n            # try a cython aggregation if we can\n            try:\n                return self._cython_agg_general(alias, alt=npfunc, **kwargs)\n            except AssertionError as e:\n                raise SpecificationError(str(e))\n            except Exception:\n                pass\n\n            # apply a non-cython aggregation\n            result = self.aggregate(lambda x: npfunc(x, axis=self.axis))\n\n            # coerce the resulting columns if we can\n            if isinstance(result, DataFrame):\n                for col in result.columns:\n                    result[col] = self._try_cast(result[col], self.obj[col])\n            else:\n                result = self._try_cast(result, self.obj)\n\n            return result\n\n        set_function_name(f, name, cls)\n\n        return f\n\n    def first_compat(x, axis=0):\n        def first(x):\n            x = x.to_numpy()\n\n            x = x[notna(x)]\n            if len(x) == 0:\n                return np.nan\n            return x[0]\n\n        if isinstance(x, DataFrame):\n            return x.apply(first, axis=axis)\n        else:\n            return first(x)\n\n    def last_compat(x, axis=0):\n        def last(x):\n            x = x.to_numpy()\n            x = x[notna(x)]\n            if len(x) == 0:\n                return np.nan\n            return x[-1]\n\n        if isinstance(x, DataFrame):\n            return x.apply(last, axis=axis)\n        else:\n            return last(x)\n\n    cls.sum = groupby_function(\"sum\", \"add\", np.sum, min_count=0)\n    cls.prod = groupby_function(\"prod\", \"prod\", np.prod, min_count=0)\n    cls.min = groupby_function(\"min\", \"min\", np.min, numeric_only=False)\n    cls.max = groupby_function(\"max\", \"max\", np.max, numeric_only=False)\n    cls.first = groupby_function(\"first\", \"first\", first_compat, numeric_only=False)\n    cls.last = groupby_function(\"last\", \"last\", last_compat, numeric_only=False)",
                "@Substitution(name=\"groupby\")\n@Appender(_common_see_also)\ndef ohlc(self):\n    \"\"\"\n    Compute sum of values, excluding missing values.\n\n    For multiple groupings, the result index will be a MultiIndex\n\n    Returns\n    -------\n    DataFrame\n        Open, high, low and close values within each group.\n    \"\"\"\n\n    return self._apply_to_column_groupbys(lambda x: x._cython_agg_general(\"ohlc\"))",
                "@Appender(DataFrame.describe.__doc__)\ndef describe(self, **kwargs):\n    with _group_selection_context(self):\n        result = self.apply(lambda x: x.describe(**kwargs))\n        if self.axis == 1:\n            return result.T\n        return result.unstack()",
                "def resample(self, rule, *args, **kwargs):\n    \"\"\"\n    Provide resampling when using a TimeGrouper.\n\n    Given a grouper, the function resamples it according to a string\n    \"string\" -> \"frequency\".\n\n    See the :ref:`frequency aliases <timeseries.offset_aliases>`\n    documentation for more details.\n\n    Parameters\n    ----------\n    rule : str or DateOffset\n        The offset string or object representing target grouper conversion.\n    *args, **kwargs\n        Possible arguments are `how`, `fill_method`, `limit`, `kind` and\n        `on`, and other arguments of `TimeGrouper`.\n\n    Returns\n    -------\n    Grouper\n        Return a new grouper with our resampler appended.\n\n    See Also\n    --------\n    Grouper : Specify a frequency to resample with when\n        grouping by a key.\n    DatetimeIndex.resample : Frequency conversion and resampling of\n        time series.\n\n    Examples\n    --------\n    >>> idx = pd.date_range('1/1/2000', periods=4, freq='T')\n    >>> df = pd.DataFrame(data=4 * [range(2)],\n    ...                   index=idx,\n    ...                   columns=['a', 'b'])\n    >>> df.iloc[2, 0] = 5\n    >>> df\n                        a  b\n    2000-01-01 00:00:00  0  1\n    2000-01-01 00:01:00  0  1\n    2000-01-01 00:02:00  5  1\n    2000-01-01 00:03:00  0  1\n\n    Downsample the DataFrame into 3 minute bins and sum the values of\n    the timestamps falling into a bin.\n\n    >>> df.groupby('a').resample('3T').sum()\n                             a  b\n    a\n    0   2000-01-01 00:00:00  0  2\n        2000-01-01 00:03:00  0  1\n    5   2000-01-01 00:00:00  5  1\n\n    Upsample the series into 30 second bins.\n\n    >>> df.groupby('a').resample('30S').sum()\n                        a  b\n    a\n    0   2000-01-01 00:00:00  0  1\n        2000-01-01 00:00:30  0  0\n        2000-01-01 00:01:00  0  1\n        2000-01-01 00:01:30  0  0\n        2000-01-01 00:02:00  0  0\n        2000-01-01 00:02:30  0  0\n        2000-01-01 00:03:00  0  1\n    5   2000-01-01 00:02:00  5  1\n\n    Resample by month. Values are assigned to the month of the period.\n\n    >>> df.groupby('a').resample('M').sum()\n                a  b\n    a\n    0   2000-01-31  0  3\n    5   2000-01-31  5  1\n\n    Downsample the series into 3 minute bins as above, but close the right\n    side of the bin interval.\n\n    >>> df.groupby('a').resample('3T', closed='right').sum()\n                             a  b\n    a\n    0   1999-12-31 23:57:00  0  1\n        2000-01-01 00:00:00  0  2\n    5   2000-01-01 00:00:00  5  1\n\n    Downsample the series into 3 minute bins and close the right side of\n    the bin interval, but label each bin using the right edge instead of\n    the left.\n\n    >>> df.groupby('a').resample('3T', closed='right', label='right').sum()\n                             a  b\n    a\n    0   2000-01-01 00:00:00  0  1\n        2000-01-01 00:03:00  0  2\n    5   2000-01-01 00:03:00  5  1\n\n    Add an offset of twenty seconds.\n\n    >>> df.groupby('a').resample('3T', loffset='20s').sum()\n                           a  b\n    a\n    0   2000-01-01 00:00:20  0  2\n        2000-01-01 00:03:20  0  1\n    5   2000-01-01 00:00:20  5  1\n    \"\"\"\n    from pandas.core.resample import get_resampler_for_grouping\n\n    return get_resampler_for_grouping(self, rule, *args, **kwargs)",
                "@Substitution(name=\"groupby\")\n@Appender(_common_see_also)\ndef rolling(self, *args, **kwargs):\n    \"\"\"\n    Return a rolling grouper, providing rolling functionality per group.\n    \"\"\"\n    from pandas.core.window import RollingGroupby\n\n    return RollingGroupby(self, *args, **kwargs)",
                "@Substitution(name=\"groupby\")\n@Appender(_common_see_also)\ndef expanding(self, *args, **kwargs):\n    \"\"\"\n    Return an expanding grouper, providing expanding\n    functionality per group.\n    \"\"\"\n    from pandas.core.window import ExpandingGroupby\n\n    return ExpandingGroupby(self, *args, **kwargs)",
                "def _fill(self, direction, limit=None):\n    \"\"\"\n    Shared function for `pad` and `backfill` to call Cython method.\n\n    Parameters\n    ----------\n    direction : {'ffill', 'bfill'}\n        Direction passed to underlying Cython function. `bfill` will cause\n        values to be filled backwards. `ffill` and any other values will\n        default to a forward fill\n    limit : int, default None\n        Maximum number of consecutive values to fill. If `None`, this\n        method will convert to -1 prior to passing to Cython\n\n    Returns\n    -------\n    `Series` or `DataFrame` with filled values\n\n    See Also\n    --------\n    pad\n    backfill\n    \"\"\"\n    # Need int value for Cython\n    if limit is None:\n        limit = -1\n\n    return self._get_cythonized_result(\n        \"group_fillna_indexer\",\n        self.grouper,\n        needs_mask=True,\n        cython_dtype=np.int64,\n        result_is_index=True,\n        direction=direction,\n        limit=limit,\n    )",
                "@Substitution(name=\"groupby\")\ndef pad(self, limit=None):\n    \"\"\"\n    Forward fill the values.\n\n    Parameters\n    ----------\n    limit : integer, optional\n        limit of how many values to fill\n\n    Returns\n    -------\n    Series or DataFrame\n        Object with missing values filled.\n\n    See Also\n    --------\n    Series.pad\n    DataFrame.pad\n    Series.fillna\n    DataFrame.fillna\n    \"\"\"\n    return self._fill(\"ffill\", limit=limit)",
                "@Substitution(name=\"groupby\")\ndef backfill(self, limit=None):\n    \"\"\"\n    Backward fill the values.\n\n    Parameters\n    ----------\n    limit : integer, optional\n        limit of how many values to fill\n\n    Returns\n    -------\n    Series or DataFrame\n        Object with missing values filled.\n\n    See Also\n    --------\n    Series.backfill\n    DataFrame.backfill\n    Series.fillna\n    DataFrame.fillna\n    \"\"\"\n    return self._fill(\"bfill\", limit=limit)",
                "@Substitution(name=\"groupby\")\n@Substitution(see_also=_common_see_also)\ndef nth(self, n: Union[int, List[int]], dropna: Optional[str] = None) -> DataFrame:\n    \"\"\"\n    Take the nth row from each group if n is an int, or a subset of rows\n    if n is a list of ints.\n\n    If dropna, will take the nth non-null row, dropna is either\n    'all' or 'any'; this is equivalent to calling dropna(how=dropna)\n    before the groupby.\n\n    Parameters\n    ----------\n    n : int or list of ints\n        a single nth value for the row or a list of nth values\n    dropna : None or str, optional\n        apply the specified dropna operation before counting which row is\n        the nth row. Needs to be None, 'any' or 'all'\n\n    Returns\n    -------\n    Series or DataFrame\n        N-th value within each group.\n    %(see_also)s\n    Examples\n    --------\n\n    >>> df = pd.DataFrame({'A': [1, 1, 2, 1, 2],\n    ...                    'B': [np.nan, 2, 3, 4, 5]}, columns=['A', 'B'])\n    >>> g = df.groupby('A')\n    >>> g.nth(0)\n         B\n    A\n    1  NaN\n    2  3.0\n    >>> g.nth(1)\n         B\n    A\n    1  2.0\n    2  5.0\n    >>> g.nth(-1)\n         B\n    A\n    1  4.0\n    2  5.0\n    >>> g.nth([0, 1])\n         B\n    A\n    1  NaN\n    1  2.0\n    2  3.0\n    2  5.0\n\n    Specifying `dropna` allows count ignoring ``NaN``\n\n    >>> g.nth(0, dropna='any')\n         B\n    A\n    1  2.0\n    2  3.0\n\n    NaNs denote group exhausted when using dropna\n\n    >>> g.nth(3, dropna='any')\n        B\n    A\n    1 NaN\n    2 NaN\n\n    Specifying `as_index=False` in `groupby` keeps the original index.\n\n    >>> df.groupby('A', as_index=False).nth(1)\n       A    B\n    1  1  2.0\n    4  2  5.0\n    \"\"\"\n\n    valid_containers = (set, list, tuple)\n    if not isinstance(n, (valid_containers, int)):\n        raise TypeError(\"n needs to be an int or a list/set/tuple of ints\")\n\n    if not dropna:\n\n        if isinstance(n, int):\n            nth_values = [n]\n        elif isinstance(n, valid_containers):\n            nth_values = list(set(n))\n\n        nth_array = np.array(nth_values, dtype=np.intp)\n        self._set_group_selection()\n\n        mask_left = np.in1d(self._cumcount_array(), nth_array)\n        mask_right = np.in1d(self._cumcount_array(ascending=False) + 1, -nth_array)\n        mask = mask_left | mask_right\n\n        ids, _, _ = self.grouper.group_info\n\n        # Drop NA values in grouping\n        mask = mask & (ids != -1)\n\n        out = self._selected_obj[mask]\n        if not self.as_index:\n            return out\n\n        result_index = self.grouper.result_index\n        out.index = result_index[ids[mask]]\n\n        if not self.observed and isinstance(result_index, CategoricalIndex):\n            out = out.reindex(result_index)\n\n        return out.sort_index() if self.sort else out\n\n    # dropna is truthy\n    if isinstance(n, valid_containers):\n        raise ValueError(\"dropna option with a list of nth values is not supported\")\n\n    if dropna not in [\"any\", \"all\"]:\n        # Note: when agg-ing picker doesn't raise this, just returns NaN\n        raise ValueError(\n            \"For a DataFrame groupby, dropna must be \"\n            \"either None, 'any' or 'all', \"\n            \"(was passed {dropna}).\".format(dropna=dropna)\n        )\n\n    # old behaviour, but with all and any support for DataFrames.\n    # modified in GH 7559 to have better perf\n    max_len = n if n >= 0 else -1 - n\n    dropped = self.obj.dropna(how=dropna, axis=self.axis)\n\n    # get a new grouper for our dropped obj\n    if self.keys is None and self.level is None:\n\n        # we don't have the grouper info available\n        # (e.g. we have selected out\n        # a column that is not in the current object)\n        axis = self.grouper.axis\n        grouper = axis[axis.isin(dropped.index)]\n\n    else:\n\n        # create a grouper with the original parameters, but on dropped\n        # object\n        from pandas.core.groupby.grouper import _get_grouper\n\n        grouper, _, _ = _get_grouper(\n            dropped,\n            key=self.keys,\n            axis=self.axis,\n            level=self.level,\n            sort=self.sort,\n            mutated=self.mutated,\n        )\n\n    grb = dropped.groupby(grouper, as_index=self.as_index, sort=self.sort)\n    sizes, result = grb.size(), grb.nth(n)\n    mask = (sizes < max_len).values\n\n    # set the results which don't meet the criteria\n    if len(result) and mask.any():\n        result.loc[mask] = np.nan\n\n    # reset/reindex to the original groups\n    if len(self.obj) == len(dropped) or len(result) == len(\n        self.grouper.result_index\n    ):\n        result.index = self.grouper.result_index\n    else:\n        result = result.reindex(self.grouper.result_index)\n\n    return result",
                "def quantile(self, q=0.5, interpolation=\"linear\"):\n    \"\"\"\n    Return group values at the given quantile, a la numpy.percentile.\n\n    Parameters\n    ----------\n    q : float or array-like, default 0.5 (50% quantile)\n        Value(s) between 0 and 1 providing the quantile(s) to compute.\n    interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}\n        Method to use when the desired quantile falls between two points.\n\n    Returns\n    -------\n    Series or DataFrame\n        Return type determined by caller of GroupBy object.\n\n    See Also\n    --------\n    Series.quantile : Similar method for Series.\n    DataFrame.quantile : Similar method for DataFrame.\n    numpy.percentile : NumPy method to compute qth percentile.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame([\n    ...     ['a', 1], ['a', 2], ['a', 3],\n    ...     ['b', 1], ['b', 3], ['b', 5]\n    ... ], columns=['key', 'val'])\n    >>> df.groupby('key').quantile()\n        val\n    key\n    a    2.0\n    b    3.0\n    \"\"\"\n    from pandas import concat\n\n    def pre_processor(vals: np.ndarray) -> Tuple[np.ndarray, Optional[Type]]:\n        if is_object_dtype(vals):\n            raise TypeError(\n                \"'quantile' cannot be performed against 'object' dtypes!\"\n            )\n\n        inference = None\n        if is_integer_dtype(vals):\n            inference = np.int64\n        elif is_datetime64_dtype(vals):\n            inference = \"datetime64[ns]\"\n            vals = vals.astype(np.float)\n\n        return vals, inference\n\n    def post_processor(vals: np.ndarray, inference: Optional[Type]) -> np.ndarray:\n        if inference:\n            # Check for edge case\n            if not (\n                is_integer_dtype(inference)\n                and interpolation in {\"linear\", \"midpoint\"}\n            ):\n                vals = vals.astype(inference)\n\n        return vals\n\n    if is_scalar(q):\n        return self._get_cythonized_result(\n            \"group_quantile\",\n            self.grouper,\n            aggregate=True,\n            needs_values=True,\n            needs_mask=True,\n            cython_dtype=np.float64,\n            pre_processing=pre_processor,\n            post_processing=post_processor,\n            q=q,\n            interpolation=interpolation,\n        )\n    else:\n        results = [\n            self._get_cythonized_result(\n                \"group_quantile\",\n                self.grouper,\n                aggregate=True,\n                needs_values=True,\n                needs_mask=True,\n                cython_dtype=np.float64,\n                pre_processing=pre_processor,\n                post_processing=post_processor,\n                q=qi,\n                interpolation=interpolation,\n            )\n            for qi in q\n        ]\n        result = concat(results, axis=0, keys=q)\n        # fix levels to place quantiles on the inside\n        # TODO(GH-10710): Ideally, we could write this as\n        #  >>> result.stack(0).loc[pd.IndexSlice[:, ..., q], :]\n        #  but this hits https://github.com/pandas-dev/pandas/issues/10710\n        #  which doesn't reorder the list-like `q` on the inner level.\n        order = np.roll(list(range(result.index.nlevels)), -1)\n        result = result.reorder_levels(order)\n        result = result.reindex(q, level=-1)\n\n        # fix order.\n        hi = len(q) * self.ngroups\n        arr = np.arange(0, hi, self.ngroups)\n        arrays = []\n\n        for i in range(self.ngroups):\n            arr2 = arr + i\n            arrays.append(arr2)\n\n        indices = np.concatenate(arrays)\n        assert len(indices) == len(result)\n        return result.take(indices)",
                "@Substitution(name=\"groupby\")\ndef ngroup(self, ascending=True):\n    \"\"\"\n    Number each group from 0 to the number of groups - 1.\n\n    This is the enumerative complement of cumcount.  Note that the\n    numbers given to the groups match the order in which the groups\n    would be seen when iterating over the groupby object, not the\n    order they are first observed.\n\n    .. versionadded:: 0.20.2\n\n    Parameters\n    ----------\n    ascending : bool, default True\n        If False, number in reverse, from number of group - 1 to 0.\n\n    Returns\n    -------\n    Series\n        Unique numbers for each group.\n\n    See Also\n    --------\n    .cumcount : Number the rows in each group.\n\n    Examples\n    --------\n\n    >>> df = pd.DataFrame({\"A\": list(\"aaabba\")})\n    >>> df\n       A\n    0  a\n    1  a\n    2  a\n    3  b\n    4  b\n    5  a\n    >>> df.groupby('A').ngroup()\n    0    0\n    1    0\n    2    0\n    3    1\n    4    1\n    5    0\n    dtype: int64\n    >>> df.groupby('A').ngroup(ascending=False)\n    0    1\n    1    1\n    2    1\n    3    0\n    4    0\n    5    1\n    dtype: int64\n    >>> df.groupby([\"A\", [1,1,2,3,2,1]]).ngroup()\n    0    0\n    1    0\n    2    1\n    3    3\n    4    2\n    5    0\n    dtype: int64\n    \"\"\"\n\n    with _group_selection_context(self):\n        index = self._selected_obj.index\n        result = Series(self.grouper.group_info[0], index)\n        if not ascending:\n            result = self.ngroups - 1 - result\n        return result",
                "@Substitution(name=\"groupby\")\ndef cumcount(self, ascending=True):\n    \"\"\"\n    Number each item in each group from 0 to the length of that group - 1.\n\n    Essentially this is equivalent to\n\n    >>> self.apply(lambda x: pd.Series(np.arange(len(x)), x.index))\n\n    Parameters\n    ----------\n    ascending : bool, default True\n        If False, number in reverse, from length of group - 1 to 0.\n\n    Returns\n    -------\n    Series\n        Sequence number of each element within each group.\n\n    See Also\n    --------\n    .ngroup : Number the groups themselves.\n\n    Examples\n    --------\n\n    >>> df = pd.DataFrame([['a'], ['a'], ['a'], ['b'], ['b'], ['a']],\n    ...                   columns=['A'])\n    >>> df\n       A\n    0  a\n    1  a\n    2  a\n    3  b\n    4  b\n    5  a\n    >>> df.groupby('A').cumcount()\n    0    0\n    1    1\n    2    2\n    3    0\n    4    1\n    5    3\n    dtype: int64\n    >>> df.groupby('A').cumcount(ascending=False)\n    0    3\n    1    2\n    2    1\n    3    1\n    4    0\n    5    0\n    dtype: int64\n    \"\"\"\n\n    with _group_selection_context(self):\n        index = self._selected_obj.index\n        cumcounts = self._cumcount_array(ascending=ascending)\n        return Series(cumcounts, index)",
                "@Substitution(name=\"groupby\")\n@Appender(_common_see_also)\ndef rank(\n    self, method=\"average\", ascending=True, na_option=\"keep\", pct=False, axis=0\n):\n    \"\"\"\n    Provide the rank of values within each group.\n\n    Parameters\n    ----------\n    method : {'average', 'min', 'max', 'first', 'dense'}, default 'average'\n        * average: average rank of group\n        * min: lowest rank in group\n        * max: highest rank in group\n        * first: ranks assigned in order they appear in the array\n        * dense: like 'min', but rank always increases by 1 between groups\n    ascending : boolean, default True\n        False for ranks by high (1) to low (N)\n    na_option :  {'keep', 'top', 'bottom'}, default 'keep'\n        * keep: leave NA values where they are\n        * top: smallest rank if ascending\n        * bottom: smallest rank if descending\n    pct : boolean, default False\n        Compute percentage rank of data within each group\n    axis : int, default 0\n        The axis of the object over which to compute the rank.\n\n    Returns\n    -------\n    DataFrame with ranking of values within each group\n    \"\"\"\n    if na_option not in {\"keep\", \"top\", \"bottom\"}:\n        msg = \"na_option must be one of 'keep', 'top', or 'bottom'\"\n        raise ValueError(msg)\n    return self._cython_transform(\n        \"rank\",\n        numeric_only=False,\n        ties_method=method,\n        ascending=ascending,\n        na_option=na_option,\n        pct=pct,\n        axis=axis,\n    )",
                "@Substitution(name=\"groupby\")\n@Appender(_common_see_also)\ndef cumprod(self, axis=0, *args, **kwargs):\n    \"\"\"\n    Cumulative product for each group.\n\n    Returns\n    -------\n    Series or DataFrame\n    \"\"\"\n    nv.validate_groupby_func(\"cumprod\", args, kwargs, [\"numeric_only\", \"skipna\"])\n    if axis != 0:\n        return self.apply(lambda x: x.cumprod(axis=axis, **kwargs))\n\n    return self._cython_transform(\"cumprod\", **kwargs)",
                "@Substitution(name=\"groupby\")\n@Appender(_common_see_also)\ndef cumsum(self, axis=0, *args, **kwargs):\n    \"\"\"\n    Cumulative sum for each group.\n\n    Returns\n    -------\n    Series or DataFrame\n    \"\"\"\n    nv.validate_groupby_func(\"cumsum\", args, kwargs, [\"numeric_only\", \"skipna\"])\n    if axis != 0:\n        return self.apply(lambda x: x.cumsum(axis=axis, **kwargs))\n\n    return self._cython_transform(\"cumsum\", **kwargs)",
                "@Substitution(name=\"groupby\")\n@Appender(_common_see_also)\ndef cummin(self, axis=0, **kwargs):\n    \"\"\"\n    Cumulative min for each group.\n\n    Returns\n    -------\n    Series or DataFrame\n    \"\"\"\n    if axis != 0:\n        return self.apply(lambda x: np.minimum.accumulate(x, axis))\n\n    return self._cython_transform(\"cummin\", numeric_only=False)",
                "@Substitution(name=\"groupby\")\n@Appender(_common_see_also)\ndef cummax(self, axis=0, **kwargs):\n    \"\"\"\n    Cumulative max for each group.\n\n    Returns\n    -------\n    Series or DataFrame\n    \"\"\"\n    if axis != 0:\n        return self.apply(lambda x: np.maximum.accumulate(x, axis))\n\n    return self._cython_transform(\"cummax\", numeric_only=False)",
                "def _get_cythonized_result(\n    self,\n    how,\n    grouper,\n    aggregate=False,\n    cython_dtype=None,\n    needs_values=False,\n    needs_mask=False,\n    needs_ngroups=False,\n    result_is_index=False,\n    pre_processing=None,\n    post_processing=None,\n    **kwargs\n):\n    \"\"\"\n    Get result for Cythonized functions.\n\n    Parameters\n    ----------\n    how : str, Cythonized function name to be called\n    grouper : Grouper object containing pertinent group info\n    aggregate : bool, default False\n        Whether the result should be aggregated to match the number of\n        groups\n    cython_dtype : default None\n        Type of the array that will be modified by the Cython call. If\n        `None`, the type will be inferred from the values of each slice\n    needs_values : bool, default False\n        Whether the values should be a part of the Cython call\n        signature\n    needs_mask : bool, default False\n        Whether boolean mask needs to be part of the Cython call\n        signature\n    needs_ngroups : bool, default False\n        Whether number of groups is part of the Cython call signature\n    result_is_index : bool, default False\n        Whether the result of the Cython operation is an index of\n        values to be retrieved, instead of the actual values themselves\n    pre_processing : function, default None\n        Function to be applied to `values` prior to passing to Cython.\n        Function should return a tuple where the first element is the\n        values to be passed to Cython and the second element is an optional\n        type which the values should be converted to after being returned\n        by the Cython operation. Raises if `needs_values` is False.\n    post_processing : function, default None\n        Function to be applied to result of Cython function. Should accept\n        an array of values as the first argument and type inferences as its\n        second argument, i.e. the signature should be\n        (ndarray, Type).\n    **kwargs : dict\n        Extra arguments to be passed back to Cython funcs\n\n    Returns\n    -------\n    `Series` or `DataFrame`  with filled values\n    \"\"\"\n    if result_is_index and aggregate:\n        raise ValueError(\"'result_is_index' and 'aggregate' cannot both be True!\")\n    if post_processing:\n        if not callable(pre_processing):\n            raise ValueError(\"'post_processing' must be a callable!\")\n    if pre_processing:\n        if not callable(pre_processing):\n            raise ValueError(\"'pre_processing' must be a callable!\")\n        if not needs_values:\n            raise ValueError(\n                \"Cannot use 'pre_processing' without specifying 'needs_values'!\"\n            )\n\n    labels, _, ngroups = grouper.group_info\n    output = collections.OrderedDict()\n    base_func = getattr(libgroupby, how)\n\n    for name, obj in self._iterate_slices():\n        if aggregate:\n            result_sz = ngroups\n        else:\n            result_sz = len(obj.values)\n\n        if not cython_dtype:\n            cython_dtype = obj.values.dtype\n\n        result = np.zeros(result_sz, dtype=cython_dtype)\n        func = partial(base_func, result, labels)\n        inferences = None\n\n        if needs_values:\n            vals = obj.values\n            if pre_processing:\n                vals, inferences = pre_processing(vals)\n            func = partial(func, vals)\n\n        if needs_mask:\n            mask = isna(obj.values).view(np.uint8)\n            func = partial(func, mask)\n\n        if needs_ngroups:\n            func = partial(func, ngroups)\n\n        func(**kwargs)  # Call func to modify indexer values in place\n\n        if result_is_index:\n            result = algorithms.take_nd(obj.values, result)\n\n        if post_processing:\n            result = post_processing(result, inferences)\n\n        output[name] = result\n\n    if aggregate:\n        return self._wrap_aggregated_output(output)\n    else:\n        return self._wrap_transformed_output(output)",
                "@Substitution(name=\"groupby\")\n@Appender(_common_see_also)\ndef shift(self, periods=1, freq=None, axis=0, fill_value=None):\n    \"\"\"\n    Shift each group by periods observations.\n\n    Parameters\n    ----------\n    periods : integer, default 1\n        number of periods to shift\n    freq : frequency string\n    axis : axis to shift, default 0\n    fill_value : optional\n\n        .. versionadded:: 0.24.0\n\n    Returns\n    -------\n    Series or DataFrame\n        Object shifted within each group.\n    \"\"\"\n\n    if freq is not None or axis != 0 or not isna(fill_value):\n        return self.apply(lambda x: x.shift(periods, freq, axis, fill_value))\n\n    return self._get_cythonized_result(\n        \"group_shift_indexer\",\n        self.grouper,\n        cython_dtype=np.int64,\n        needs_ngroups=True,\n        result_is_index=True,\n        periods=periods,\n    )",
                "@Substitution(name=\"groupby\")\n@Appender(_common_see_also)\ndef pct_change(self, periods=1, fill_method=\"pad\", limit=None, freq=None, axis=0):\n    \"\"\"\n    Calculate pct_change of each value to previous entry in group.\n\n    Returns\n    -------\n    Series or DataFrame\n        Percentage changes within each group.\n    \"\"\"\n    if freq is not None or axis != 0:\n        return self.apply(\n            lambda x: x.pct_change(\n                periods=periods,\n                fill_method=fill_method,\n                limit=limit,\n                freq=freq,\n                axis=axis,\n            )\n        )\n    filled = getattr(self, fill_method)(limit=limit)\n    fill_grp = filled.groupby(self.grouper.labels)\n    shifted = fill_grp.shift(periods=periods, freq=freq)\n    return (filled / shifted) - 1",
                "@Substitution(name=\"groupby\")\n@Substitution(see_also=_common_see_also)\ndef head(self, n=5):\n    \"\"\"\n    Return first n rows of each group.\n\n    Similar to ``.apply(lambda x: x.head(n))``, but it returns a subset of rows\n    from the original DataFrame with original index and order preserved\n    (``as_index`` flag is ignored).\n\n    Returns\n    -------\n    Series or DataFrame\n    %(see_also)s\n    Examples\n    --------\n\n    >>> df = pd.DataFrame([[1, 2], [1, 4], [5, 6]],\n    ...                   columns=['A', 'B'])\n    >>> df.groupby('A').head(1)\n       A  B\n    0  1  2\n    2  5  6\n    \"\"\"\n    self._reset_group_selection()\n    mask = self._cumcount_array() < n\n    return self._selected_obj[mask]",
                "@Substitution(name=\"groupby\")\n@Substitution(see_also=_common_see_also)\ndef tail(self, n=5):\n    \"\"\"\n    Return last n rows of each group.\n\n    Similar to ``.apply(lambda x: x.tail(n))``, but it returns a subset of rows\n    from the original DataFrame with original index and order preserved\n    (``as_index`` flag is ignored).\n\n    Returns\n    -------\n    Series or DataFrame\n    %(see_also)s\n    Examples\n    --------\n\n    >>> df = pd.DataFrame([['a', 1], ['a', 2], ['b', 1], ['b', 2]],\n    ...                   columns=['A', 'B'])\n    >>> df.groupby('A').tail(1)\n       A  B\n    1  a  2\n    3  b  2\n    \"\"\"\n    self._reset_group_selection()\n    mask = self._cumcount_array(ascending=False) < n\n    return self._selected_obj[mask]",
                "def _reindex_output(self, output):\n    \"\"\"\n    If we have categorical groupers, then we might want to make sure that\n    we have a fully re-indexed output to the levels. This means expanding\n    the output space to accommodate all values in the cartesian product of\n    our groups, regardless of whether they were observed in the data or\n    not. This will expand the output space if there are missing groups.\n\n    The method returns early without modifying the input if the number of\n    groupings is less than 2, self.observed == True or none of the groupers\n    are categorical.\n\n    Parameters\n    ----------\n    output: Series or DataFrame\n        Object resulting from grouping and applying an operation.\n\n    Returns\n    -------\n    Series or DataFrame\n        Object (potentially) re-indexed to include all possible groups.\n    \"\"\"\n    groupings = self.grouper.groupings\n    if groupings is None:\n        return output\n    elif len(groupings) == 1:\n        return output\n\n    # if we only care about the observed values\n    # we are done\n    elif self.observed:\n        return output\n\n    # reindexing only applies to a Categorical grouper\n    elif not any(\n        isinstance(ping.grouper, (Categorical, CategoricalIndex))\n        for ping in groupings\n    ):\n        return output\n\n    levels_list = [ping.group_index for ping in groupings]\n    index, _ = MultiIndex.from_product(\n        levels_list, names=self.grouper.names\n    ).sortlevel()\n\n    if self.as_index:\n        d = {self.obj._get_axis_name(self.axis): index, \"copy\": False}\n        return output.reindex(**d)\n\n    # GH 13204\n    # Here, the categorical in-axis groupers, which need to be fully\n    # expanded, are columns in `output`. An idea is to do:\n    # output = output.set_index(self.grouper.names)\n    #                .reindex(index).reset_index()\n    # but special care has to be taken because of possible not-in-axis\n    # groupers.\n    # So, we manually select and drop the in-axis grouper columns,\n    # reindex `output`, and then reset the in-axis grouper columns.\n\n    # Select in-axis groupers\n    in_axis_grps = (\n        (i, ping.name) for (i, ping) in enumerate(groupings) if ping.in_axis\n    )\n    g_nums, g_names = zip(*in_axis_grps)\n\n    output = output.drop(labels=list(g_names), axis=1)\n\n    # Set a temp index and reindex (possibly expanding)\n    output = output.set_index(self.grouper.result_index).reindex(index, copy=False)\n\n    # Reset in-axis grouper columns\n    # (using level numbers `g_nums` because level names may not be unique)\n    output = output.reset_index(level=g_nums)\n\n    return output.reset_index(drop=True)",
                "def f(self):\n    return self.plot(*args, **kwargs)",
                "def attr(*args, **kwargs):\n    def f(self):\n        return getattr(self.plot, name)(*args, **kwargs)\n\n    return self._groupby.apply(f)",
                "def get_converter(s):\n    # possibly convert to the actual key types\n    # in the indices, could be a Timestamp or a np.datetime64\n    if isinstance(s, (Timestamp, datetime.datetime)):\n        return lambda key: Timestamp(key)\n    elif isinstance(s, np.datetime64):\n        return lambda key: Timestamp(key).asm8\n    else:\n        return lambda key: key",
                "def wrapper(*args, **kwargs):\n    # a little trickery for aggregation functions that need an axis\n    # argument\n    kwargs_with_axis = kwargs.copy()\n    if \"axis\" not in kwargs_with_axis or kwargs_with_axis[\"axis\"] is None:\n        kwargs_with_axis[\"axis\"] = self.axis\n\n    def curried_with_axis(x):\n        return f(x, *args, **kwargs_with_axis)\n\n    def curried(x):\n        return f(x, *args, **kwargs)\n\n    # preserve the name so we can detect it when calling plot methods,\n    # to avoid duplicates\n    curried.__name__ = curried_with_axis.__name__ = name\n\n    # special case otherwise extra plots are created when catching the\n    # exception below\n    if name in base.plotting_methods:\n        return self.apply(curried)\n\n    try:\n        return self.apply(curried_with_axis)\n    except Exception:\n        try:\n            return self.apply(curried)\n        except Exception:\n\n            # related to : GH3688\n            # try item-by-item\n            # this can be called recursively, so need to raise\n            # ValueError\n            # if we don't have this method to indicated to aggregate to\n            # mark this column as an error\n            try:\n                return self._aggregate_item_by_item(name, *args, **kwargs)\n            except AttributeError:\n                # e.g. SparseArray has no flags attr\n                raise ValueError",
                "def reset_identity(values):\n    # reset the identities of the components\n    # of the values to prevent aliasing\n    for v in com.not_none(*values):\n        ax = v._get_axis(self.axis)\n        ax._reset_identity()\n    return values",
                "def objs_to_bool(vals: np.ndarray) -> Tuple[np.ndarray, Type]:\n    if is_object_dtype(vals):\n        vals = np.array([bool(x) for x in vals])\n    else:\n        vals = vals.astype(np.bool)\n\n    return vals.view(np.uint8), np.bool",
                "def result_to_bool(result: np.ndarray, inference: Type) -> np.ndarray:\n    return result.astype(inference, copy=False)",
                "def groupby_function(name, alias, npfunc, numeric_only=True, min_count=-1):\n\n    _local_template = \"\"\"\n    Compute %(f)s of group values.\n\n    Returns\n    -------\n    Series or DataFrame\n        Computed %(f)s of values within each group.\n    \"\"\"\n\n    @Substitution(name=\"groupby\", f=name)\n    @Appender(_common_see_also)\n    @Appender(_local_template)\n    def f(self, **kwargs):\n        if \"numeric_only\" not in kwargs:\n            kwargs[\"numeric_only\"] = numeric_only\n        if \"min_count\" not in kwargs:\n            kwargs[\"min_count\"] = min_count\n\n        self._set_group_selection()\n\n        # try a cython aggregation if we can\n        try:\n            return self._cython_agg_general(alias, alt=npfunc, **kwargs)\n        except AssertionError as e:\n            raise SpecificationError(str(e))\n        except Exception:\n            pass\n\n        # apply a non-cython aggregation\n        result = self.aggregate(lambda x: npfunc(x, axis=self.axis))\n\n        # coerce the resulting columns if we can\n        if isinstance(result, DataFrame):\n            for col in result.columns:\n                result[col] = self._try_cast(result[col], self.obj[col])\n        else:\n            result = self._try_cast(result, self.obj)\n\n        return result\n\n    set_function_name(f, name, cls)\n\n    return f",
                "def first_compat(x, axis=0):\n    def first(x):\n        x = x.to_numpy()\n\n        x = x[notna(x)]\n        if len(x) == 0:\n            return np.nan\n        return x[0]\n\n    if isinstance(x, DataFrame):\n        return x.apply(first, axis=axis)\n    else:\n        return first(x)",
                "def last_compat(x, axis=0):\n    def last(x):\n        x = x.to_numpy()\n        x = x[notna(x)]\n        if len(x) == 0:\n            return np.nan\n        return x[-1]\n\n    if isinstance(x, DataFrame):\n        return x.apply(last, axis=axis)\n    else:\n        return last(x)",
                "def pre_processor(vals: np.ndarray) -> Tuple[np.ndarray, Optional[Type]]:\n    if is_object_dtype(vals):\n        raise TypeError(\n            \"'quantile' cannot be performed against 'object' dtypes!\"\n        )\n\n    inference = None\n    if is_integer_dtype(vals):\n        inference = np.int64\n    elif is_datetime64_dtype(vals):\n        inference = \"datetime64[ns]\"\n        vals = vals.astype(np.float)\n\n    return vals, inference",
                "def post_processor(vals: np.ndarray, inference: Optional[Type]) -> np.ndarray:\n    if inference:\n        # Check for edge case\n        if not (\n            is_integer_dtype(inference)\n            and interpolation in {\"linear\", \"midpoint\"}\n        ):\n            vals = vals.astype(inference)\n\n    return vals",
                "def f(self):\n    return getattr(self.plot, name)(*args, **kwargs)",
                "def curried_with_axis(x):\n    return f(x, *args, **kwargs_with_axis)",
                "def curried(x):\n    return f(x, *args, **kwargs)",
                "@Substitution(name=\"groupby\", f=name)\n@Appender(_common_see_also)\n@Appender(_local_template)\ndef f(self, **kwargs):\n    if \"numeric_only\" not in kwargs:\n        kwargs[\"numeric_only\"] = numeric_only\n    if \"min_count\" not in kwargs:\n        kwargs[\"min_count\"] = min_count\n\n    self._set_group_selection()\n\n    # try a cython aggregation if we can\n    try:\n        return self._cython_agg_general(alias, alt=npfunc, **kwargs)\n    except AssertionError as e:\n        raise SpecificationError(str(e))\n    except Exception:\n        pass\n\n    # apply a non-cython aggregation\n    result = self.aggregate(lambda x: npfunc(x, axis=self.axis))\n\n    # coerce the resulting columns if we can\n    if isinstance(result, DataFrame):\n        for col in result.columns:\n            result[col] = self._try_cast(result[col], self.obj[col])\n    else:\n        result = self._try_cast(result, self.obj)\n\n    return result",
                "def first(x):\n    x = x.to_numpy()\n\n    x = x[notna(x)]\n    if len(x) == 0:\n        return np.nan\n    return x[0]",
                "def last(x):\n    x = x.to_numpy()\n    x = x[notna(x)]\n    if len(x) == 0:\n        return np.nan\n    return x[-1]",
                "@wraps(func)\ndef f(g):\n    with np.errstate(all=\"ignore\"):\n        return func(g, *args, **kwargs)",
                "def f(x):\n    if isinstance(x, np.ndarray):\n        x = Series(x)\n    return x.median(axis=self.axis, **kwargs)"
            ],
            "inscope_function_signatures": [
                "_group_selection_context(groupby)",
                "groupby(obj, by, **kwds)",
                "__init__(self, groupby)",
                "__call__(self, *args, **kwargs)",
                "__getattr__(self, name)",
                "__init__(self, obj: NDFrame, keys=None, axis=0, level=None, grouper=None, exclusions=None, selection=None, as_index=True, sort=True, group_keys=True, squeeze=False, observed=False, **kwargs)",
                "__len__(self)",
                "__repr__(self)",
                "_assure_grouper(self)",
                "groups(self)",
                "ngroups(self)",
                "indices(self)",
                "_get_indices(self, names)",
                "_get_index(self, name)",
                "_selected_obj(self)",
                "_reset_group_selection(self)",
                "_set_group_selection(self)",
                "_set_result_index_ordered(self, result)",
                "_dir_additions(self)",
                "__getattr__(self, attr)",
                "pipe(self, func, *args, **kwargs)",
                "_make_wrapper(self, name)",
                "get_group(self, name, obj=None)",
                "__iter__(self)",
                "apply(self, func, *args, **kwargs)",
                "_python_apply_general(self, f)",
                "_iterate_slices(self)",
                "transform(self, func, *args, **kwargs)",
                "_cumcount_array(self, ascending=True)",
                "_try_cast(self, result, obj, numeric_only=False)",
                "_transform_should_cast(self, func_nm)",
                "_cython_transform(self, how, numeric_only=True, **kwargs)",
                "_cython_agg_general(self, how, alt=None, numeric_only=True, min_count=-1)",
                "_python_agg_general(self, func, *args, **kwargs)",
                "_wrap_applied_output(self, *args, **kwargs)",
                "_concat_objects(self, keys, values, not_indexed_same=False)",
                "_apply_filter(self, indices, dropna)",
                "_bool_agg(self, val_test, skipna)",
                "any(self, skipna=True)",
                "all(self, skipna=True)",
                "count(self)",
                "mean(self, *args, **kwargs)",
                "median(self, **kwargs)",
                "std(self, ddof=1, *args, **kwargs)",
                "var(self, ddof=1, *args, **kwargs)",
                "sem(self, ddof=1)",
                "size(self)",
                "_add_numeric_operations(cls)",
                "ohlc(self)",
                "describe(self, **kwargs)",
                "resample(self, rule, *args, **kwargs)",
                "rolling(self, *args, **kwargs)",
                "expanding(self, *args, **kwargs)",
                "_fill(self, direction, limit=None)",
                "pad(self, limit=None)",
                "backfill(self, limit=None)",
                "nth(self, n: Union[int, List[int]], dropna: Optional[str]=None) -> DataFrame",
                "quantile(self, q=0.5, interpolation='linear')",
                "ngroup(self, ascending=True)",
                "cumcount(self, ascending=True)",
                "rank(self, method='average', ascending=True, na_option='keep', pct=False, axis=0)",
                "cumprod(self, axis=0, *args, **kwargs)",
                "cumsum(self, axis=0, *args, **kwargs)",
                "cummin(self, axis=0, **kwargs)",
                "cummax(self, axis=0, **kwargs)",
                "_get_cythonized_result(self, how, grouper, aggregate=False, cython_dtype=None, needs_values=False, needs_mask=False, needs_ngroups=False, result_is_index=False, pre_processing=None, post_processing=None, **kwargs)",
                "shift(self, periods=1, freq=None, axis=0, fill_value=None)",
                "pct_change(self, periods=1, fill_method='pad', limit=None, freq=None, axis=0)",
                "head(self, n=5)",
                "tail(self, n=5)",
                "_reindex_output(self, output)",
                "f(self)",
                "attr(*args, **kwargs)",
                "get_converter(s)",
                "wrapper(*args, **kwargs)",
                "reset_identity(values)",
                "objs_to_bool(vals: np.ndarray) -> Tuple[np.ndarray, Type]",
                "result_to_bool(result: np.ndarray, inference: Type) -> np.ndarray",
                "groupby_function(name, alias, npfunc, numeric_only=True, min_count=-1)",
                "first_compat(x, axis=0)",
                "last_compat(x, axis=0)",
                "pre_processor(vals: np.ndarray) -> Tuple[np.ndarray, Optional[Type]]",
                "post_processor(vals: np.ndarray, inference: Optional[Type]) -> np.ndarray",
                "f(self)",
                "curried_with_axis(x)",
                "curried(x)",
                "f(self, **kwargs)",
                "first(x)",
                "last(x)",
                "f(g)",
                "f(x)"
            ],
            "variables_in_file": {
                "_common_see_also": [
                    2178,
                    2307,
                    1160,
                    1672,
                    1428,
                    1305,
                    1562,
                    1572,
                    2341,
                    2087,
                    1325,
                    60,
                    2367,
                    1216,
                    1359,
                    2131,
                    1111,
                    2395,
                    1247,
                    2147,
                    1128,
                    2163,
                    1270,
                    1145
                ],
                "_apply_docs": [
                    67,
                    700,
                    701
                ],
                "dict": [
                    67
                ],
                "_pipe_template": [
                    593,
                    186
                ],
                "_transform_template": [
                    240
                ],
                "PandasObject": [
                    307,
                    342
                ],
                "self._groupby": [
                    320,
                    313,
                    327
                ],
                "self": [
                    513,
                    515,
                    516,
                    526,
                    528,
                    530,
                    531,
                    535,
                    1559,
                    540,
                    541,
                    1569,
                    2081,
                    2082,
                    2083,
                    549,
                    550,
                    551,
                    552,
                    554,
                    1580,
                    558,
                    561,
                    562,
                    563,
                    564,
                    565,
                    566,
                    569,
                    2120,
                    1097,
                    1609,
                    1099,
                    1611,
                    595,
                    600,
                    601,
                    605,
                    2142,
                    2144,
                    609,
                    613,
                    1125,
                    615,
                    617,
                    1641,
                    2158,
                    624,
                    2160,
                    1142,
                    2173,
                    639,
                    2175,
                    642,
                    1667,
                    645,
                    2188,
                    2190,
                    655,
                    680,
                    682,
                    686,
                    1205,
                    697,
                    1211,
                    1212,
                    1213,
                    706,
                    1229,
                    729,
                    1241,
                    1243,
                    1244,
                    2265,
                    1760,
                    1762,
                    739,
                    740,
                    1763,
                    1766,
                    745,
                    747,
                    748,
                    1771,
                    1772,
                    1775,
                    752,
                    1778,
                    755,
                    1267,
                    1781,
                    2302,
                    2304,
                    769,
                    1798,
                    1801,
                    1290,
                    1806,
                    1297,
                    1298,
                    1301,
                    1302,
                    1817,
                    1818,
                    1819,
                    1820,
                    1821,
                    2329,
                    2331,
                    1824,
                    2333,
                    1833,
                    1322,
                    1834,
                    1836,
                    1838,
                    2352,
                    1335,
                    313,
                    1337,
                    1338,
                    2361,
                    317,
                    2362,
                    320,
                    325,
                    327,
                    847,
                    853,
                    2390,
                    1367,
                    2391,
                    2392,
                    859,
                    1371,
                    864,
                    865,
                    1378,
                    1383,
                    872,
                    1385,
                    363,
                    876,
                    368,
                    1905,
                    882,
                    1907,
                    2418,
                    2419,
                    2420,
                    887,
                    376,
                    377,
                    378,
                    379,
                    380,
                    381,
                    382,
                    892,
                    895,
                    1919,
                    1921,
                    900,
                    902,
                    903,
                    394,
                    908,
                    397,
                    398,
                    399,
                    400,
                    910,
                    2444,
                    2452,
                    406,
                    920,
                    1944,
                    410,
                    922,
                    1945,
                    925,
                    1948,
                    2464,
                    1441,
                    2467,
                    2468,
                    1445,
                    934,
                    1446,
                    424,
                    425,
                    1447,
                    939,
                    940,
                    429,
                    430,
                    437,
                    438,
                    2490,
                    955,
                    957,
                    959,
                    962,
                    966,
                    967,
                    459,
                    460,
                    971,
                    982,
                    472,
                    985,
                    989,
                    992,
                    2020,
                    2021,
                    2022,
                    488,
                    2024,
                    1002,
                    1004,
                    494,
                    1008,
                    1009,
                    499,
                    500,
                    501,
                    502,
                    504
                ],
                "groupby": [
                    337,
                    313,
                    338,
                    339
                ],
                "self.plot": [
                    325,
                    317
                ],
                "args": [
                    896,
                    1569,
                    325,
                    711,
                    1287,
                    1580,
                    717,
                    2156,
                    655,
                    1266,
                    627,
                    595,
                    1203,
                    630,
                    1559,
                    2140,
                    317
                ],
                "kwargs": [
                    896,
                    1287,
                    1292,
                    1293,
                    655,
                    1296,
                    403,
                    1300,
                    1559,
                    1569,
                    1446,
                    1580,
                    1203,
                    1206,
                    1212,
                    317,
                    325,
                    711,
                    717,
                    1231,
                    1232,
                    1362,
                    595,
                    1363,
                    1364,
                    1365,
                    1241,
                    859,
                    1371,
                    2140,
                    2142,
                    2144,
                    2156,
                    622,
                    2158,
                    2160,
                    1266,
                    1267,
                    2291,
                    630,
                    382
                ],
                "f.__name__": [
                    319
                ],
                "f": [
                    896,
                    902,
                    908,
                    1296,
                    1298,
                    1300,
                    1302,
                    1212,
                    1213,
                    319,
                    320,
                    327,
                    724,
                    729,
                    1244,
                    482,
                    740,
                    613,
                    614,
                    617,
                    745,
                    1389,
                    1391,
                    627,
                    630
                ],
                "self._groupby.apply": [
                    320,
                    327
                ],
                "getattr": [
                    613,
                    325,
                    615,
                    2361,
                    617,
                    529,
                    2263,
                    601,
                    1338,
                    989
                ],
                "name": [
                    900,
                    903,
                    655,
                    913,
                    920,
                    682,
                    684,
                    325,
                    1358,
                    853,
                    600,
                    472,
                    601,
                    2265,
                    605,
                    865,
                    482,
                    867,
                    613,
                    486,
                    615,
                    488,
                    617,
                    876,
                    1389,
                    494,
                    887,
                    634,
                    2299,
                    638
                ],
                "attr": [
                    329,
                    561,
                    562,
                    563,
                    564,
                    565,
                    566,
                    569
                ],
                "groupby._set_group_selection": [
                    337
                ],
                "groupby._reset_group_selection": [
                    339
                ],
                "contextmanager": [
                    332
                ],
                "SelectionMixin": [
                    342
                ],
                "_group_selection": [
                    343
                ],
                "_apply_whitelist": [
                    344
                ],
                "frozenset": [
                    344
                ],
                "NDFrame": [
                    348,
                    365
                ],
                "self._selection": [
                    504,
                    363,
                    499
                ],
                "selection": [
                    363
                ],
                "isinstance": [
                    1415,
                    2457,
                    942,
                    951,
                    1337,
                    449,
                    451,
                    2504,
                    2508,
                    465,
                    466,
                    1749,
                    1239,
                    1754,
                    1756,
                    988,
                    1381,
                    614,
                    365,
                    1778,
                    371,
                    499,
                    1784,
                    1402
                ],
                "obj": [
                    387,
                    388,
                    900,
                    902,
                    903,
                    397,
                    398,
                    798,
                    799,
                    801,
                    679,
                    680,
                    809,
                    686,
                    823,
                    2504,
                    2508,
                    2513,
                    2515,
                    853,
                    854,
                    2265,
                    859,
                    2269,
                    2272,
                    865,
                    2279,
                    876,
                    365,
                    366,
                    877,
                    2285,
                    371,
                    883,
                    2294,
                    887
                ],
                "type": [
                    569,
                    605,
                    365,
                    617
                ],
                "obj._consolidate_inplace": [
                    366
                ],
                "self.level": [
                    368,
                    1801,
                    1819
                ],
                "level": [
                    368,
                    391
                ],
                "as_index": [
                    376,
                    370
                ],
                "DataFrame": [
                    1443,
                    1381,
                    1415,
                    1673,
                    2508,
                    371,
                    1402
                ],
                "TypeError": [
                    904,
                    813,
                    2513,
                    372,
                    1750,
                    1880,
                    730
                ],
                "axis": [
                    390,
                    1416,
                    2187,
                    2188,
                    398,
                    1806,
                    1807,
                    2328,
                    2329,
                    2351,
                    2358,
                    1231,
                    2127,
                    2141,
                    2142,
                    2157,
                    2158,
                    373,
                    1403,
                    2172,
                    2173
                ],
                "ValueError": [
                    2119,
                    2249,
                    2252,
                    2255,
                    720,
                    2257,
                    658,
                    468,
                    374,
                    1785,
                    1789,
                    479
                ],
                "self.as_index": [
                    1824,
                    962,
                    2467,
                    1772,
                    528,
                    376
                ],
                "self.keys": [
                    1817,
                    377,
                    1801
                ],
                "keys": [
                    965,
                    389,
                    745,
                    748,
                    981,
                    982,
                    377
                ],
                "self.sort": [
                    1824,
                    378,
                    1820,
                    1781
                ],
                "sort": [
                    392,
                    378
                ],
                "self.group_keys": [
                    379,
                    959
                ],
                "group_keys": [
                    379,
                    972,
                    965
                ],
                "self.squeeze": [
                    380
                ],
                "squeeze": [
                    380
                ],
                "self.observed": [
                    1778,
                    2452,
                    381
                ],
                "observed": [
                    393,
                    381
                ],
                "self.mutated": [
                    394,
                    748,
                    1821,
                    382
                ],
                "kwargs.pop": [
                    382
                ],
                "grouper": [
                    384,
                    1824,
                    387,
                    1807,
                    399,
                    2261,
                    1815
                ],
                "exclusions": [
                    400,
                    387
                ],
                "_get_grouper": [
                    387,
                    1815
                ],
                "self.obj": [
                    1798,
                    397,
                    530,
                    535,
                    2468,
                    1833,
                    554,
                    558,
                    563,
                    565,
                    1337,
                    1338,
                    697,
                    1383,
                    1385,
                    499,
                    501,
                    502,
                    504
                ],
                "self.axis": [
                    1798,
                    398,
                    1818,
                    2468,
                    934,
                    551,
                    552,
                    1447,
                    554,
                    939,
                    940,
                    686,
                    697,
                    955,
                    1212,
                    957,
                    971,
                    982,
                    1241,
                    985,
                    1378,
                    745,
                    1002,
                    624
                ],
                "obj._get_axis_number": [
                    398
                ],
                "self.grouper": [
                    769,
                    1921,
                    902,
                    2444,
                    526,
                    399,
                    910,
                    1806,
                    2333,
                    2464,
                    549,
                    550,
                    425,
                    1834,
                    1836,
                    430,
                    1838,
                    438,
                    1335,
                    697,
                    2362,
                    2490,
                    966,
                    967,
                    1099,
                    1611,
                    859,
                    1766,
                    2022,
                    745,
                    1775,
                    882,
                    1907
                ],
                "self.exclusions": [
                    400
                ],
                "set": [
                    400,
                    1748,
                    1757
                ],
                "validate_kwargs": [
                    403
                ],
                "len": [
                    771,
                    1411,
                    907,
                    2447,
                    406,
                    1944,
                    538,
                    1953,
                    1829,
                    1833,
                    683,
                    456,
                    459,
                    469,
                    981,
                    2269,
                    869,
                    997,
                    1004,
                    1398,
                    889
                ],
                "self.groups": [
                    406
                ],
                "object.__repr__": [
                    410
                ],
                "object": [
                    410,
                    562
                ],
                "self._assure_grouper": [
                    424,
                    429,
                    437
                ],
                "self.grouper.groups": [
                    425
                ],
                "property": [
                    432,
                    419,
                    597,
                    427
                ],
                "self.grouper.ngroups": [
                    430
                ],
                "self.grouper.indices": [
                    438
                ],
                "s": [
                    449,
                    451,
                    481
                ],
                "Timestamp": [
                    449,
                    450,
                    452
                ],
                "datetime.datetime": [
                    449
                ],
                "datetime": [
                    449
                ],
                "key": [
                    450,
                    452,
                    454
                ],
                "np.datetime64": [
                    451
                ],
                "np": [
                    2188,
                    1412,
                    1925,
                    774,
                    776,
                    777,
                    1420,
                    781,
                    1421,
                    783,
                    1422,
                    785,
                    786,
                    787,
                    1423,
                    1911,
                    1939,
                    1945,
                    2334,
                    1952,
                    550,
                    1830,
                    1322,
                    1086,
                    1088,
                    1090,
                    451,
                    1092,
                    1094,
                    716,
                    1101,
                    1613,
                    1878,
                    1239,
                    1886,
                    1759,
                    1889,
                    1762,
                    1763,
                    2274,
                    1893,
                    998,
                    1000,
                    1004,
                    2285,
                    1008,
                    1267,
                    1399,
                    2173
                ],
                "asm8": [
                    452
                ],
                "names": [
                    482,
                    486,
                    456,
                    488,
                    872,
                    464,
                    882,
                    472,
                    859,
                    892
                ],
                "self.indices": [
                    472,
                    488,
                    459,
                    460
                ],
                "index_sample": [
                    481,
                    485,
                    460,
                    462,
                    465,
                    469
                ],
                "next": [
                    460
                ],
                "iter": [
                    460
                ],
                "name_sample": [
                    464,
                    466,
                    469
                ],
                "tuple": [
                    465,
                    466,
                    482,
                    1748
                ],
                "msg": [
                    2118,
                    2119,
                    607,
                    467,
                    468,
                    475,
                    603,
                    479
                ],
                "KeyError": [
                    473,
                    684
                ],
                "converters": [
                    481,
                    482
                ],
                "get_converter": [
                    481,
                    485
                ],
                "n": [
                    1825,
                    482,
                    1797,
                    2419,
                    1749,
                    2391,
                    1784,
                    1754,
                    1755,
                    1756,
                    1757
                ],
                "zip": [
                    482,
                    2485
                ],
                "converter": [
                    485,
                    486
                ],
                "self.indices.get": [
                    488
                ],
                "self._get_indices": [
                    550,
                    494
                ],
                "Series": [
                    2084,
                    2022,
                    2504,
                    1292,
                    942,
                    1231,
                    499,
                    1206,
                    1240,
                    1337,
                    988
                ],
                "self._group_selection": [
                    513,
                    515,
                    531,
                    500,
                    501,
                    540
                ],
                "cache_readonly": [
                    496
                ],
                "self._reset_cache": [
                    516,
                    541
                ],
                "grp": [
                    536,
                    529,
                    526
                ],
                "self.obj.ndim": [
                    530
                ],
                "ax": [
                    934,
                    935,
                    940,
                    943,
                    951,
                    535,
                    953,
                    540,
                    957
                ],
                "self.obj._info_axis": [
                    535
                ],
                "groupers": [
                    536,
                    538,
                    540
                ],
                "g.name": [
                    536
                ],
                "g": [
                    536,
                    717
                ],
                "grp.groupings": [
                    536
                ],
                "g.level": [
                    536
                ],
                "g.in_axis": [
                    536
                ],
                "tolist": [
                    540
                ],
                "ax.difference": [
                    540
                ],
                "Index": [
                    540,
                    550
                ],
                "self.grouper.is_monotonic": [
                    549
                ],
                "index": [
                    2082,
                    2084,
                    2021,
                    2022,
                    550,
                    551,
                    2468,
                    2490,
                    2463
                ],
                "np.concatenate": [
                    1000,
                    1952,
                    550
                ],
                "self.grouper.result_index": [
                    550,
                    1834,
                    1836,
                    1838,
                    1775,
                    2490
                ],
                "result.set_axis": [
                    554,
                    551
                ],
                "result": [
                    902,
                    903,
                    1933,
                    913,
                    1939,
                    916,
                    1940,
                    1941,
                    920,
                    1825,
                    1953,
                    803,
                    1954,
                    1829,
                    1446,
                    551,
                    552,
                    1448,
                    554,
                    555,
                    811,
                    812,
                    939,
                    942,
                    943,
                    1449,
                    1833,
                    1836,
                    1838,
                    1840,
                    2274,
                    823,
                    1335,
                    953,
                    1338,
                    955,
                    1339,
                    957,
                    2275,
                    831,
                    833,
                    1095,
                    969,
                    982,
                    729,
                    985,
                    859,
                    988,
                    992,
                    865,
                    994,
                    867,
                    1378,
                    1381,
                    742,
                    1382,
                    1383,
                    1385,
                    2022,
                    1387,
                    2024,
                    2025,
                    882,
                    2294,
                    887,
                    1830,
                    2297,
                    2299
                ],
                "result.sort_index": [
                    552
                ],
                "self.obj._get_axis": [
                    554
                ],
                "self.obj._dir_additions": [
                    558
                ],
                "self._apply_whitelist": [
                    600,
                    558
                ],
                "self._internal_names_set": [
                    561
                ],
                "object.__getattribute__": [
                    562
                ],
                "hasattr": [
                    565
                ],
                "self._make_wrapper": [
                    566
                ],
                "AttributeError": [
                    568,
                    656,
                    607
                ],
                "__name__": [
                    569,
                    605
                ],
                "com.pipe": [
                    595
                ],
                "com": [
                    595,
                    933
                ],
                "func": [
                    896,
                    706,
                    2275,
                    712,
                    714,
                    2282,
                    717,
                    2286,
                    2289,
                    595,
                    724,
                    2291,
                    895
                ],
                "Substitution": [
                    2177,
                    2306,
                    1159,
                    1160,
                    1671,
                    1672,
                    1427,
                    1304,
                    1561,
                    1571,
                    1956,
                    2340,
                    2086,
                    1324,
                    572,
                    2366,
                    1215,
                    2367,
                    1358,
                    2130,
                    1619,
                    1110,
                    2394,
                    2395,
                    1246,
                    2146,
                    1127,
                    2027,
                    1645,
                    2162,
                    1269,
                    1144
                ],
                "Appender": [
                    2178,
                    2307,
                    1428,
                    1305,
                    1562,
                    1443,
                    1572,
                    2341,
                    2087,
                    1325,
                    699,
                    1216,
                    2502,
                    1359,
                    1360,
                    593,
                    2131,
                    1111,
                    1247,
                    2147,
                    1128,
                    2163,
                    1270,
                    1145
                ],
                "plot": [
                    597
                ],
                "GroupByPlot": [
                    597
                ],
                "is_callable": [
                    601,
                    602
                ],
                "callable": [
                    712,
                    601,
                    2251,
                    2254
                ],
                "self._selected_obj": [
                    2082,
                    613,
                    2021,
                    680,
                    745,
                    617,
                    1002,
                    940,
                    1004,
                    1771,
                    752,
                    1008,
                    1009,
                    2420,
                    2392,
                    601
                ],
                "kind": [
                    602,
                    605
                ],
                "format": [
                    2513,
                    700,
                    604,
                    1790
                ],
                "self._set_group_selection": [
                    1760,
                    609,
                    1367
                ],
                "types.MethodType": [
                    614
                ],
                "types": [
                    614
                ],
                "self.apply": [
                    642,
                    645,
                    1446,
                    615,
                    2188,
                    2158,
                    2352,
                    2329,
                    2173,
                    2142,
                    639
                ],
                "kwargs_with_axis": [
                    624,
                    627,
                    622,
                    623
                ],
                "kwargs.copy": [
                    622
                ],
                "x": [
                    896,
                    1409,
                    1410,
                    1411,
                    1413,
                    1415,
                    1416,
                    1418,
                    1292,
                    2188,
                    1296,
                    1300,
                    2329,
                    1441,
                    1446,
                    2353,
                    2173,
                    1206,
                    1212,
                    1088,
                    1231,
                    1239,
                    1240,
                    1241,
                    2142,
                    1378,
                    2158,
                    627,
                    1395,
                    1397,
                    630,
                    1398,
                    1400,
                    1402,
                    1403,
                    1405
                ],
                "curried.__name__": [
                    634
                ],
                "curried": [
                    634,
                    645,
                    639
                ],
                "curried_with_axis.__name__": [
                    634
                ],
                "curried_with_axis": [
                    634,
                    642
                ],
                "base.plotting_methods": [
                    638
                ],
                "base": [
                    848,
                    638
                ],
                "Exception": [
                    643,
                    646,
                    1295,
                    1236,
                    824,
                    1210,
                    1374
                ],
                "self._aggregate_item_by_item": [
                    655
                ],
                "wrapper": [
                    660
                ],
                "inds": [
                    682,
                    683,
                    686
                ],
                "self._get_index": [
                    682
                ],
                "obj.take": [
                    686
                ],
                "self.grouper.get_iterator": [
                    697
                ],
                "self._is_builtin_func": [
                    706,
                    895
                ],
                "np.errstate": [
                    716
                ],
                "wraps": [
                    714
                ],
                "option_context": [
                    727
                ],
                "self._python_apply_general": [
                    729,
                    740,
                    908
                ],
                "_group_selection_context": [
                    2081,
                    739,
                    2020,
                    1445,
                    1243,
                    1297,
                    1301,
                    1211
                ],
                "values": [
                    961,
                    1826,
                    933,
                    936,
                    745,
                    970,
                    939,
                    748,
                    916,
                    917,
                    918,
                    981,
                    920,
                    982,
                    984,
                    985
                ],
                "mutated": [
                    745,
                    748
                ],
                "self.grouper.apply": [
                    745
                ],
                "self._wrap_applied_output": [
                    747
                ],
                "self._selection_name": [
                    752,
                    992
                ],
                "AbstractMethodError": [
                    755,
                    925
                ],
                "ids": [
                    769,
                    770,
                    771,
                    1766,
                    776,
                    1769,
                    1776
                ],
                "_": [
                    769,
                    1766,
                    2261,
                    1815,
                    2463
                ],
                "ngroups": [
                    769,
                    770,
                    2289,
                    2261,
                    2267
                ],
                "self.grouper.group_info": [
                    2022,
                    769,
                    1766
                ],
                "sorter": [
                    786,
                    770,
                    771
                ],
                "get_group_index_sorter": [
                    770
                ],
                "count": [
                    771,
                    773,
                    777,
                    785,
                    786
                ],
                "np.empty": [
                    785,
                    1004,
                    774
                ],
                "np.int64": [
                    774,
                    1613,
                    787,
                    1886,
                    2334
                ],
                "run": [
                    776,
                    777,
                    778,
                    781,
                    783
                ],
                "np.r_": [
                    776,
                    777,
                    783
                ],
                "rep": [
                    777,
                    781,
                    783
                ],
                "np.diff": [
                    777
                ],
                "np.nonzero": [
                    777
                ],
                "out": [
                    778,
                    1771,
                    781,
                    1773,
                    783,
                    1776,
                    787,
                    1779,
                    1781
                ],
                "cumsum": [
                    778
                ],
                "ascending": [
                    2083,
                    780,
                    2124,
                    2023
                ],
                "np.repeat": [
                    781,
                    783
                ],
                "rev": [
                    785,
                    786,
                    787
                ],
                "np.intp": [
                    785,
                    786,
                    1759
                ],
                "np.arange": [
                    1945,
                    786
                ],
                "astype": [
                    787
                ],
                "obj.ndim": [
                    798
                ],
                "dtype": [
                    801,
                    804,
                    812,
                    817,
                    831,
                    823,
                    830,
                    799
                ],
                "obj._values.dtype": [
                    799
                ],
                "obj._values": [
                    823,
                    799
                ],
                "obj.dtype": [
                    801,
                    877,
                    854
                ],
                "is_scalar": [
                    1904,
                    803
                ],
                "is_datetime64tz_dtype": [
                    804
                ],
                "arr": [
                    809,
                    1945,
                    811,
                    1949
                ],
                "extract_array": [
                    809
                ],
                "arr._from_sequence": [
                    811
                ],
                "result.astype": [
                    812,
                    1095
                ],
                "is_extension_array_dtype": [
                    817
                ],
                "obj._values._from_sequence": [
                    823
                ],
                "numeric_only": [
                    878,
                    1363,
                    830,
                    855
                ],
                "is_numeric_dtype": [
                    854,
                    877,
                    830,
                    917
                ],
                "maybe_downcast_to_dtype": [
                    831
                ],
                "any": [
                    2456,
                    847
                ],
                "fillna": [
                    847
                ],
                "self.size": [
                    847
                ],
                "func_nm": [
                    848
                ],
                "base.cython_cast_blacklist": [
                    848
                ],
                "output": [
                    2304,
                    899,
                    903,
                    907,
                    2446,
                    2448,
                    913,
                    2453,
                    920,
                    922,
                    2460,
                    2469,
                    2487,
                    2490,
                    2494,
                    2496,
                    852,
                    2262,
                    865,
                    867,
                    869,
                    872,
                    875,
                    887,
                    889,
                    2299,
                    892,
                    2302
                ],
                "collections.OrderedDict": [
                    852,
                    2262
                ],
                "collections": [
                    852,
                    2262
                ],
                "self._iterate_slices": [
                    900,
                    876,
                    853,
                    2265
                ],
                "is_numeric": [
                    878,
                    877,
                    854,
                    855
                ],
                "self.grouper.transform": [
                    859
                ],
                "obj.values": [
                    2272,
                    2279,
                    2285,
                    883,
                    2294,
                    859,
                    2269
                ],
                "how": [
                    864,
                    883,
                    859,
                    2263
                ],
                "NotImplementedError": [
                    860,
                    1157
                ],
                "AssertionError": [
                    1372,
                    885,
                    862
                ],
                "GroupByError": [
                    1208,
                    1234,
                    886,
                    863
                ],
                "str": [
                    1673,
                    1373,
                    886,
                    863
                ],
                "e": [
                    1373,
                    886,
                    863
                ],
                "self._transform_should_cast": [
                    864
                ],
                "self._try_cast": [
                    865,
                    903,
                    1383,
                    1385,
                    887,
                    920
                ],
                "DataError": [
                    890,
                    870
                ],
                "self._wrap_transformed_output": [
                    872,
                    2304
                ],
                "self.grouper.aggregate": [
                    882
                ],
                "min_count": [
                    883,
                    1365
                ],
                "self._wrap_aggregated_output": [
                    922,
                    892,
                    2302
                ],
                "counts": [
                    912,
                    902
                ],
                "self.grouper.agg_series": [
                    902
                ],
                "self.grouper._filter_empty_groups": [
                    910
                ],
                "mask": [
                    912,
                    920,
                    1826,
                    1829,
                    1830,
                    2391,
                    2392,
                    1764,
                    1769,
                    1771,
                    1004,
                    1005,
                    1006,
                    2285,
                    1008,
                    1009,
                    1776,
                    2286,
                    2419,
                    2420
                ],
                "counts.ravel": [
                    912
                ],
                "output.items": [
                    913
                ],
                "values.dtype": [
                    917
                ],
                "ensure_float": [
                    918
                ],
                "v": [
                    933,
                    934
                ],
                "com.not_none": [
                    933
                ],
                "v._get_axis": [
                    934
                ],
                "ax._reset_identity": [
                    935
                ],
                "not_indexed_same": [
                    938
                ],
                "concat": [
                    969,
                    939,
                    1933,
                    982,
                    985
                ],
                "self._selected_obj._get_axis": [
                    940
                ],
                "result.reindex": [
                    1941,
                    957,
                    1838,
                    943
                ],
                "MultiIndex": [
                    2463,
                    951
                ],
                "ax.is_unique": [
                    951
                ],
                "indexer": [
                    952,
                    955
                ],
                "algorithms.unique1d": [
                    952
                ],
                "algorithms": [
                    952,
                    2294
                ],
                "result.index.get_indexer_for": [
                    953
                ],
                "result.index": [
                    953,
                    1939,
                    1836
                ],
                "ax.values": [
                    953
                ],
                "result.take": [
                    1954,
                    955
                ],
                "reset_identity": [
                    984,
                    961
                ],
                "group_levels": [
                    973,
                    966
                ],
                "self.grouper.levels": [
                    966
                ],
                "group_names": [
                    974,
                    967
                ],
                "self.grouper.names": [
                    2464,
                    967
                ],
                "list": [
                    1008,
                    1939,
                    1748,
                    981,
                    2487,
                    1757
                ],
                "range": [
                    1939,
                    1948,
                    981
                ],
                "result.name": [
                    992,
                    1338
                ],
                "indices": [
                    1952,
                    1953,
                    1954,
                    997,
                    998,
                    1000,
                    1002,
                    1006
                ],
                "np.array": [
                    1088,
                    998,
                    1759
                ],
                "np.sort": [
                    1000
                ],
                "dropna": [
                    1792,
                    1798,
                    1001,
                    1752,
                    1787
                ],
                "filtered": [
                    1009,
                    1002,
                    1010
                ],
                "self._selected_obj.take": [
                    1002
                ],
                "self._selected_obj.index": [
                    2082,
                    1004,
                    2021
                ],
                "bool": [
                    1088,
                    1004
                ],
                "mask.fill": [
                    1005
                ],
                "indices.astype": [
                    1006
                ],
                "int": [
                    1673,
                    1754,
                    1749,
                    1006
                ],
                "T": [
                    1008
                ],
                "np.tile": [
                    1008
                ],
                "self._selected_obj.shape": [
                    1008
                ],
                "self._selected_obj.where": [
                    1009
                ],
                "_GroupBy": [
                    1013
                ],
                "np.ndarray": [
                    1893,
                    1094,
                    1878,
                    1239,
                    1086
                ],
                "is_object_dtype": [
                    1879,
                    1087
                ],
                "vals": [
                    1088,
                    1889,
                    1090,
                    1891,
                    1092,
                    2279,
                    2281,
                    2282,
                    1900,
                    1902,
                    1887,
                    1879,
                    1885,
                    1087
                ],
                "vals.astype": [
                    1889,
                    1090,
                    1900
                ],
                "np.bool": [
                    1090,
                    1092
                ],
                "vals.view": [
                    1092
                ],
                "np.uint8": [
                    2285,
                    1092,
                    1101
                ],
                "Tuple": [
                    1878,
                    1086
                ],
                "Type": [
                    1094,
                    1893,
                    1086,
                    1878
                ],
                "inference": [
                    1888,
                    1891,
                    1894,
                    1095,
                    1897,
                    1900,
                    1884,
                    1886
                ],
                "self._get_cythonized_result": [
                    1609,
                    1097,
                    1905,
                    2331,
                    1919
                ],
                "objs_to_bool": [
                    1104
                ],
                "result_to_bool": [
                    1105
                ],
                "val_test": [
                    1106
                ],
                "skipna": [
                    1107,
                    1125,
                    1142
                ],
                "self._bool_agg": [
                    1125,
                    1142
                ],
                "nv.validate_groupby_func": [
                    1287,
                    2156,
                    1266,
                    1203,
                    2140
                ],
                "nv": [
                    1287,
                    2156,
                    1266,
                    1203,
                    2140
                ],
                "self._cython_agg_general": [
                    1229,
                    1290,
                    1371,
                    1205
                ],
                "mean": [
                    1206
                ],
                "x.mean": [
                    1212
                ],
                "self._python_agg_general": [
                    1298,
                    1244,
                    1213,
                    1302
                ],
                "median": [
                    1231
                ],
                "x.median": [
                    1241
                ],
                "np.sqrt": [
                    1322,
                    1267
                ],
                "self.var": [
                    1267
                ],
                "ddof": [
                    1288,
                    1322,
                    1292,
                    1296,
                    1267,
                    1300
                ],
                "var": [
                    1292
                ],
                "x.var": [
                    1296,
                    1300
                ],
                "self.std": [
                    1322
                ],
                "self.count": [
                    1322
                ],
                "self.grouper.size": [
                    1335
                ],
                "_local_template": [
                    1360,
                    1349
                ],
                "alias": [
                    1371
                ],
                "npfunc": [
                    1378,
                    1371
                ],
                "SpecificationError": [
                    1373
                ],
                "self.aggregate": [
                    1378
                ],
                "col": [
                    1382,
                    1383
                ],
                "result.columns": [
                    1382
                ],
                "set_function_name": [
                    1389
                ],
                "cls": [
                    1420,
                    1389,
                    1422,
                    1421,
                    1423,
                    1424,
                    1425
                ],
                "x.to_numpy": [
                    1409,
                    1395
                ],
                "notna": [
                    1410,
                    1397
                ],
                "np.nan": [
                    1412,
                    1830,
                    1399
                ],
                "x.apply": [
                    1416,
                    1403
                ],
                "first": [
                    1403,
                    1405
                ],
                "last": [
                    1416,
                    1418
                ],
                "cls.sum": [
                    1420
                ],
                "groupby_function": [
                    1420,
                    1421,
                    1422,
                    1423,
                    1424,
                    1425
                ],
                "np.sum": [
                    1420
                ],
                "cls.prod": [
                    1421
                ],
                "np.prod": [
                    1421
                ],
                "cls.min": [
                    1422
                ],
                "np.min": [
                    1422
                ],
                "cls.max": [
                    1423
                ],
                "np.max": [
                    1423
                ],
                "cls.first": [
                    1424
                ],
                "first_compat": [
                    1424
                ],
                "cls.last": [
                    1425
                ],
                "last_compat": [
                    1425
                ],
                "classmethod": [
                    1341
                ],
                "self._apply_to_column_groupbys": [
                    1441
                ],
                "x._cython_agg_general": [
                    1441
                ],
                "x.describe": [
                    1446
                ],
                "result.T": [
                    1448
                ],
                "result.unstack": [
                    1449
                ],
                "DataFrame.describe.__doc__": [
                    1443
                ],
                "DataFrame.describe": [
                    1443
                ],
                "get_resampler_for_grouping": [
                    1559
                ],
                "rule": [
                    1559
                ],
                "RollingGroupby": [
                    1569
                ],
                "ExpandingGroupby": [
                    1580
                ],
                "limit": [
                    1667,
                    1606,
                    1607,
                    1641,
                    1616,
                    2356,
                    2361
                ],
                "direction": [
                    1615
                ],
                "self._fill": [
                    1641,
                    1667
                ],
                "ffill": [
                    1643
                ],
                "pad": [
                    1643
                ],
                "bfill": [
                    1669
                ],
                "backfill": [
                    1669
                ],
                "Union": [
                    1673
                ],
                "List": [
                    1673
                ],
                "Optional": [
                    1673,
                    1893,
                    1878
                ],
                "valid_containers": [
                    1784,
                    1756,
                    1748,
                    1749
                ],
                "nth_values": [
                    1755,
                    1757,
                    1759
                ],
                "nth_array": [
                    1762,
                    1763,
                    1759
                ],
                "mask_left": [
                    1762,
                    1764
                ],
                "np.in1d": [
                    1762,
                    1763
                ],
                "self._cumcount_array": [
                    1762,
                    2083,
                    1763,
                    2419,
                    2391
                ],
                "mask_right": [
                    1763,
                    1764
                ],
                "result_index": [
                    1776,
                    1778,
                    1779,
                    1775
                ],
                "out.index": [
                    1776
                ],
                "CategoricalIndex": [
                    2457,
                    1778
                ],
                "out.reindex": [
                    1779
                ],
                "out.sort_index": [
                    1781
                ],
                "max_len": [
                    1826,
                    1797
                ],
                "dropped": [
                    1824,
                    1798,
                    1833,
                    1807,
                    1816
                ],
                "self.obj.dropna": [
                    1798
                ],
                "self.grouper.axis": [
                    1806
                ],
                "axis.isin": [
                    1807
                ],
                "dropped.index": [
                    1807
                ],
                "grb": [
                    1824,
                    1825
                ],
                "dropped.groupby": [
                    1824
                ],
                "sizes": [
                    1825,
                    1826
                ],
                "grb.size": [
                    1825
                ],
                "grb.nth": [
                    1825
                ],
                "mask.any": [
                    1829
                ],
                "result.loc": [
                    1830
                ],
                "is_integer_dtype": [
                    1897,
                    1885
                ],
                "is_datetime64_dtype": [
                    1887
                ],
                "np.float": [
                    1889
                ],
                "interpolation": [
                    1929,
                    1898,
                    1915
                ],
                "q": [
                    1931,
                    1933,
                    1904,
                    1941,
                    1944,
                    1914
                ],
                "np.float64": [
                    1925,
                    1911
                ],
                "pre_processor": [
                    1912,
                    1926
                ],
                "post_processor": [
                    1913,
                    1927
                ],
                "results": [
                    1933,
                    1918
                ],
                "qi": [
                    1928,
                    1931
                ],
                "order": [
                    1939,
                    1940
                ],
                "np.roll": [
                    1939
                ],
                "result.index.nlevels": [
                    1939
                ],
                "result.reorder_levels": [
                    1940
                ],
                "hi": [
                    1944,
                    1945
                ],
                "self.ngroups": [
                    1944,
                    1945,
                    2024,
                    1948
                ],
                "arrays": [
                    1952,
                    1946,
                    1950
                ],
                "i": [
                    2483,
                    1948,
                    1949
                ],
                "arr2": [
                    1949,
                    1950
                ],
                "arrays.append": [
                    1950
                ],
                "cumcounts": [
                    2083,
                    2084
                ],
                "na_option": [
                    2125,
                    2117
                ],
                "self._cython_transform": [
                    2144,
                    2120,
                    2190,
                    2160,
                    2175
                ],
                "method": [
                    2123
                ],
                "pct": [
                    2126
                ],
                "x.cumprod": [
                    2142
                ],
                "x.cumsum": [
                    2158
                ],
                "np.minimum.accumulate": [
                    2173
                ],
                "np.minimum": [
                    2173
                ],
                "np.maximum.accumulate": [
                    2188
                ],
                "np.maximum": [
                    2188
                ],
                "result_is_index": [
                    2248,
                    2293
                ],
                "aggregate": [
                    2248,
                    2266,
                    2301
                ],
                "post_processing": [
                    2296,
                    2297,
                    2250
                ],
                "pre_processing": [
                    2280,
                    2281,
                    2251,
                    2253,
                    2254
                ],
                "needs_values": [
                    2256,
                    2278
                ],
                "labels": [
                    2275,
                    2261
                ],
                "grouper.group_info": [
                    2261
                ],
                "base_func": [
                    2275,
                    2263
                ],
                "libgroupby": [
                    2263
                ],
                "result_sz": [
                    2274,
                    2267,
                    2269
                ],
                "cython_dtype": [
                    2272,
                    2274,
                    2271
                ],
                "obj.values.dtype": [
                    2272
                ],
                "np.zeros": [
                    2274
                ],
                "partial": [
                    2289,
                    2282,
                    2275,
                    2286
                ],
                "inferences": [
                    2281,
                    2276,
                    2297
                ],
                "needs_mask": [
                    2284
                ],
                "view": [
                    2285
                ],
                "isna": [
                    2328,
                    2285
                ],
                "needs_ngroups": [
                    2288
                ],
                "algorithms.take_nd": [
                    2294
                ],
                "freq": [
                    2351,
                    2357,
                    2328,
                    2329,
                    2363
                ],
                "fill_value": [
                    2328,
                    2329
                ],
                "x.shift": [
                    2329
                ],
                "periods": [
                    2329,
                    2354,
                    2363,
                    2337
                ],
                "x.pct_change": [
                    2353
                ],
                "fill_method": [
                    2361,
                    2355
                ],
                "filled": [
                    2361,
                    2362,
                    2364
                ],
                "fill_grp": [
                    2362,
                    2363
                ],
                "filled.groupby": [
                    2362
                ],
                "self.grouper.labels": [
                    2362
                ],
                "shifted": [
                    2363,
                    2364
                ],
                "fill_grp.shift": [
                    2363
                ],
                "self._reset_group_selection": [
                    2418,
                    2390
                ],
                "groupings": [
                    2444,
                    2445,
                    2447,
                    2483,
                    2458,
                    2462
                ],
                "self.grouper.groupings": [
                    2444
                ],
                "ping.grouper": [
                    2457
                ],
                "ping": [
                    2457,
                    2458,
                    2483,
                    2462
                ],
                "Categorical": [
                    2457
                ],
                "levels_list": [
                    2464,
                    2462
                ],
                "ping.group_index": [
                    2462
                ],
                "sortlevel": [
                    2463
                ],
                "MultiIndex.from_product": [
                    2463
                ],
                "d": [
                    2468,
                    2469
                ],
                "self.obj._get_axis_name": [
                    2468
                ],
                "output.reindex": [
                    2469
                ],
                "in_axis_grps": [
                    2482,
                    2485
                ],
                "ping.name": [
                    2483
                ],
                "enumerate": [
                    2483
                ],
                "ping.in_axis": [
                    2483
                ],
                "g_nums": [
                    2485,
                    2494
                ],
                "g_names": [
                    2485,
                    2487
                ],
                "output.drop": [
                    2487
                ],
                "reindex": [
                    2490
                ],
                "output.set_index": [
                    2490
                ],
                "output.reset_index": [
                    2496,
                    2494
                ],
                "GroupBy._add_numeric_operations": [
                    2499
                ],
                "GroupBy": [
                    2499,
                    2502
                ],
                "klass": [
                    2507,
                    2515,
                    2511
                ],
                "SeriesGroupBy": [
                    2507
                ],
                "DataFrameGroupBy": [
                    2511
                ],
                "by": [
                    2515
                ],
                "kwds": [
                    2515
                ],
                "GroupBy.__doc__": [
                    2502
                ]
            },
            "filtered_variables_in_file": {
                "_common_see_also": [
                    2178,
                    2307,
                    1160,
                    1672,
                    1428,
                    1305,
                    1562,
                    1572,
                    2341,
                    2087,
                    1325,
                    60,
                    2367,
                    1216,
                    1359,
                    2131,
                    1111,
                    2395,
                    1247,
                    2147,
                    1128,
                    2163,
                    1270,
                    1145
                ],
                "_apply_docs": [
                    67,
                    700,
                    701
                ],
                "_pipe_template": [
                    593,
                    186
                ],
                "_transform_template": [
                    240
                ],
                "PandasObject": [
                    307,
                    342
                ],
                "self._groupby": [
                    320,
                    313,
                    327
                ],
                "self": [
                    513,
                    515,
                    516,
                    526,
                    528,
                    530,
                    531,
                    535,
                    1559,
                    540,
                    541,
                    1569,
                    2081,
                    2082,
                    2083,
                    549,
                    550,
                    551,
                    552,
                    554,
                    1580,
                    558,
                    561,
                    562,
                    563,
                    564,
                    565,
                    566,
                    569,
                    2120,
                    1097,
                    1609,
                    1099,
                    1611,
                    595,
                    600,
                    601,
                    605,
                    2142,
                    2144,
                    609,
                    613,
                    1125,
                    615,
                    617,
                    1641,
                    2158,
                    624,
                    2160,
                    1142,
                    2173,
                    639,
                    2175,
                    642,
                    1667,
                    645,
                    2188,
                    2190,
                    655,
                    680,
                    682,
                    686,
                    1205,
                    697,
                    1211,
                    1212,
                    1213,
                    706,
                    1229,
                    729,
                    1241,
                    1243,
                    1244,
                    2265,
                    1760,
                    1762,
                    739,
                    740,
                    1763,
                    1766,
                    745,
                    747,
                    748,
                    1771,
                    1772,
                    1775,
                    752,
                    1778,
                    755,
                    1267,
                    1781,
                    2302,
                    2304,
                    769,
                    1798,
                    1801,
                    1290,
                    1806,
                    1297,
                    1298,
                    1301,
                    1302,
                    1817,
                    1818,
                    1819,
                    1820,
                    1821,
                    2329,
                    2331,
                    1824,
                    2333,
                    1833,
                    1322,
                    1834,
                    1836,
                    1838,
                    2352,
                    1335,
                    313,
                    1337,
                    1338,
                    2361,
                    317,
                    2362,
                    320,
                    325,
                    327,
                    847,
                    853,
                    2390,
                    1367,
                    2391,
                    2392,
                    859,
                    1371,
                    864,
                    865,
                    1378,
                    1383,
                    872,
                    1385,
                    363,
                    876,
                    368,
                    1905,
                    882,
                    1907,
                    2418,
                    2419,
                    2420,
                    887,
                    376,
                    377,
                    378,
                    379,
                    380,
                    381,
                    382,
                    892,
                    895,
                    1919,
                    1921,
                    900,
                    902,
                    903,
                    394,
                    908,
                    397,
                    398,
                    399,
                    400,
                    910,
                    2444,
                    2452,
                    406,
                    920,
                    1944,
                    410,
                    922,
                    1945,
                    925,
                    1948,
                    2464,
                    1441,
                    2467,
                    2468,
                    1445,
                    934,
                    1446,
                    424,
                    425,
                    1447,
                    939,
                    940,
                    429,
                    430,
                    437,
                    438,
                    2490,
                    955,
                    957,
                    959,
                    962,
                    966,
                    967,
                    459,
                    460,
                    971,
                    982,
                    472,
                    985,
                    989,
                    992,
                    2020,
                    2021,
                    2022,
                    488,
                    2024,
                    1002,
                    1004,
                    494,
                    1008,
                    1009,
                    499,
                    500,
                    501,
                    502,
                    504
                ],
                "groupby": [
                    337,
                    313,
                    338,
                    339
                ],
                "self.plot": [
                    325,
                    317
                ],
                "args": [
                    896,
                    1569,
                    325,
                    711,
                    1287,
                    1580,
                    717,
                    2156,
                    655,
                    1266,
                    627,
                    595,
                    1203,
                    630,
                    1559,
                    2140,
                    317
                ],
                "kwargs": [
                    896,
                    1287,
                    1292,
                    1293,
                    655,
                    1296,
                    403,
                    1300,
                    1559,
                    1569,
                    1446,
                    1580,
                    1203,
                    1206,
                    1212,
                    317,
                    325,
                    711,
                    717,
                    1231,
                    1232,
                    1362,
                    595,
                    1363,
                    1364,
                    1365,
                    1241,
                    859,
                    1371,
                    2140,
                    2142,
                    2144,
                    2156,
                    622,
                    2158,
                    2160,
                    1266,
                    1267,
                    2291,
                    630,
                    382
                ],
                "f.__name__": [
                    319
                ],
                "f": [
                    896,
                    902,
                    908,
                    1296,
                    1298,
                    1300,
                    1302,
                    1212,
                    1213,
                    319,
                    320,
                    327,
                    724,
                    729,
                    1244,
                    482,
                    740,
                    613,
                    614,
                    617,
                    745,
                    1389,
                    1391,
                    627,
                    630
                ],
                "self._groupby.apply": [
                    320,
                    327
                ],
                "name": [
                    900,
                    903,
                    655,
                    913,
                    920,
                    682,
                    684,
                    325,
                    1358,
                    853,
                    600,
                    472,
                    601,
                    2265,
                    605,
                    865,
                    482,
                    867,
                    613,
                    486,
                    615,
                    488,
                    617,
                    876,
                    1389,
                    494,
                    887,
                    634,
                    2299,
                    638
                ],
                "attr": [
                    329,
                    561,
                    562,
                    563,
                    564,
                    565,
                    566,
                    569
                ],
                "groupby._set_group_selection": [
                    337
                ],
                "groupby._reset_group_selection": [
                    339
                ],
                "contextmanager": [
                    332
                ],
                "SelectionMixin": [
                    342
                ],
                "_group_selection": [
                    343
                ],
                "_apply_whitelist": [
                    344
                ],
                "NDFrame": [
                    348,
                    365
                ],
                "self._selection": [
                    504,
                    363,
                    499
                ],
                "selection": [
                    363
                ],
                "obj": [
                    387,
                    388,
                    900,
                    902,
                    903,
                    397,
                    398,
                    798,
                    799,
                    801,
                    679,
                    680,
                    809,
                    686,
                    823,
                    2504,
                    2508,
                    2513,
                    2515,
                    853,
                    854,
                    2265,
                    859,
                    2269,
                    2272,
                    865,
                    2279,
                    876,
                    365,
                    366,
                    877,
                    2285,
                    371,
                    883,
                    2294,
                    887
                ],
                "obj._consolidate_inplace": [
                    366
                ],
                "self.level": [
                    368,
                    1801,
                    1819
                ],
                "level": [
                    368,
                    391
                ],
                "as_index": [
                    376,
                    370
                ],
                "DataFrame": [
                    1443,
                    1381,
                    1415,
                    1673,
                    2508,
                    371,
                    1402
                ],
                "axis": [
                    390,
                    1416,
                    2187,
                    2188,
                    398,
                    1806,
                    1807,
                    2328,
                    2329,
                    2351,
                    2358,
                    1231,
                    2127,
                    2141,
                    2142,
                    2157,
                    2158,
                    373,
                    1403,
                    2172,
                    2173
                ],
                "self.as_index": [
                    1824,
                    962,
                    2467,
                    1772,
                    528,
                    376
                ],
                "self.keys": [
                    1817,
                    377,
                    1801
                ],
                "keys": [
                    965,
                    389,
                    745,
                    748,
                    981,
                    982,
                    377
                ],
                "self.sort": [
                    1824,
                    378,
                    1820,
                    1781
                ],
                "sort": [
                    392,
                    378
                ],
                "self.group_keys": [
                    379,
                    959
                ],
                "group_keys": [
                    379,
                    972,
                    965
                ],
                "self.squeeze": [
                    380
                ],
                "squeeze": [
                    380
                ],
                "self.observed": [
                    1778,
                    2452,
                    381
                ],
                "observed": [
                    393,
                    381
                ],
                "self.mutated": [
                    394,
                    748,
                    1821,
                    382
                ],
                "kwargs.pop": [
                    382
                ],
                "grouper": [
                    384,
                    1824,
                    387,
                    1807,
                    399,
                    2261,
                    1815
                ],
                "exclusions": [
                    400,
                    387
                ],
                "_get_grouper": [
                    387,
                    1815
                ],
                "self.obj": [
                    1798,
                    397,
                    530,
                    535,
                    2468,
                    1833,
                    554,
                    558,
                    563,
                    565,
                    1337,
                    1338,
                    697,
                    1383,
                    1385,
                    499,
                    501,
                    502,
                    504
                ],
                "self.axis": [
                    1798,
                    398,
                    1818,
                    2468,
                    934,
                    551,
                    552,
                    1447,
                    554,
                    939,
                    940,
                    686,
                    697,
                    955,
                    1212,
                    957,
                    971,
                    982,
                    1241,
                    985,
                    1378,
                    745,
                    1002,
                    624
                ],
                "obj._get_axis_number": [
                    398
                ],
                "self.grouper": [
                    769,
                    1921,
                    902,
                    2444,
                    526,
                    399,
                    910,
                    1806,
                    2333,
                    2464,
                    549,
                    550,
                    425,
                    1834,
                    1836,
                    430,
                    1838,
                    438,
                    1335,
                    697,
                    2362,
                    2490,
                    966,
                    967,
                    1099,
                    1611,
                    859,
                    1766,
                    2022,
                    745,
                    1775,
                    882,
                    1907
                ],
                "self.exclusions": [
                    400
                ],
                "validate_kwargs": [
                    403
                ],
                "self.groups": [
                    406
                ],
                "object.__repr__": [
                    410
                ],
                "self._assure_grouper": [
                    424,
                    429,
                    437
                ],
                "self.grouper.groups": [
                    425
                ],
                "self.grouper.ngroups": [
                    430
                ],
                "self.grouper.indices": [
                    438
                ],
                "s": [
                    449,
                    451,
                    481
                ],
                "Timestamp": [
                    449,
                    450,
                    452
                ],
                "datetime.datetime": [
                    449
                ],
                "datetime": [
                    449
                ],
                "key": [
                    450,
                    452,
                    454
                ],
                "np.datetime64": [
                    451
                ],
                "np": [
                    2188,
                    1412,
                    1925,
                    774,
                    776,
                    777,
                    1420,
                    781,
                    1421,
                    783,
                    1422,
                    785,
                    786,
                    787,
                    1423,
                    1911,
                    1939,
                    1945,
                    2334,
                    1952,
                    550,
                    1830,
                    1322,
                    1086,
                    1088,
                    1090,
                    451,
                    1092,
                    1094,
                    716,
                    1101,
                    1613,
                    1878,
                    1239,
                    1886,
                    1759,
                    1889,
                    1762,
                    1763,
                    2274,
                    1893,
                    998,
                    1000,
                    1004,
                    2285,
                    1008,
                    1267,
                    1399,
                    2173
                ],
                "asm8": [
                    452
                ],
                "names": [
                    482,
                    486,
                    456,
                    488,
                    872,
                    464,
                    882,
                    472,
                    859,
                    892
                ],
                "self.indices": [
                    472,
                    488,
                    459,
                    460
                ],
                "index_sample": [
                    481,
                    485,
                    460,
                    462,
                    465,
                    469
                ],
                "name_sample": [
                    464,
                    466,
                    469
                ],
                "msg": [
                    2118,
                    2119,
                    607,
                    467,
                    468,
                    475,
                    603,
                    479
                ],
                "converters": [
                    481,
                    482
                ],
                "get_converter": [
                    481,
                    485
                ],
                "n": [
                    1825,
                    482,
                    1797,
                    2419,
                    1749,
                    2391,
                    1784,
                    1754,
                    1755,
                    1756,
                    1757
                ],
                "converter": [
                    485,
                    486
                ],
                "self.indices.get": [
                    488
                ],
                "self._get_indices": [
                    550,
                    494
                ],
                "Series": [
                    2084,
                    2022,
                    2504,
                    1292,
                    942,
                    1231,
                    499,
                    1206,
                    1240,
                    1337,
                    988
                ],
                "self._group_selection": [
                    513,
                    515,
                    531,
                    500,
                    501,
                    540
                ],
                "cache_readonly": [
                    496
                ],
                "self._reset_cache": [
                    516,
                    541
                ],
                "grp": [
                    536,
                    529,
                    526
                ],
                "self.obj.ndim": [
                    530
                ],
                "ax": [
                    934,
                    935,
                    940,
                    943,
                    951,
                    535,
                    953,
                    540,
                    957
                ],
                "self.obj._info_axis": [
                    535
                ],
                "groupers": [
                    536,
                    538,
                    540
                ],
                "g.name": [
                    536
                ],
                "g": [
                    536,
                    717
                ],
                "grp.groupings": [
                    536
                ],
                "g.level": [
                    536
                ],
                "g.in_axis": [
                    536
                ],
                "tolist": [
                    540
                ],
                "ax.difference": [
                    540
                ],
                "Index": [
                    540,
                    550
                ],
                "self.grouper.is_monotonic": [
                    549
                ],
                "index": [
                    2082,
                    2084,
                    2021,
                    2022,
                    550,
                    551,
                    2468,
                    2490,
                    2463
                ],
                "np.concatenate": [
                    1000,
                    1952,
                    550
                ],
                "self.grouper.result_index": [
                    550,
                    1834,
                    1836,
                    1838,
                    1775,
                    2490
                ],
                "result.set_axis": [
                    554,
                    551
                ],
                "result": [
                    902,
                    903,
                    1933,
                    913,
                    1939,
                    916,
                    1940,
                    1941,
                    920,
                    1825,
                    1953,
                    803,
                    1954,
                    1829,
                    1446,
                    551,
                    552,
                    1448,
                    554,
                    555,
                    811,
                    812,
                    939,
                    942,
                    943,
                    1449,
                    1833,
                    1836,
                    1838,
                    1840,
                    2274,
                    823,
                    1335,
                    953,
                    1338,
                    955,
                    1339,
                    957,
                    2275,
                    831,
                    833,
                    1095,
                    969,
                    982,
                    729,
                    985,
                    859,
                    988,
                    992,
                    865,
                    994,
                    867,
                    1378,
                    1381,
                    742,
                    1382,
                    1383,
                    1385,
                    2022,
                    1387,
                    2024,
                    2025,
                    882,
                    2294,
                    887,
                    1830,
                    2297,
                    2299
                ],
                "result.sort_index": [
                    552
                ],
                "self.obj._get_axis": [
                    554
                ],
                "self.obj._dir_additions": [
                    558
                ],
                "self._apply_whitelist": [
                    600,
                    558
                ],
                "self._internal_names_set": [
                    561
                ],
                "object.__getattribute__": [
                    562
                ],
                "self._make_wrapper": [
                    566
                ],
                "com.pipe": [
                    595
                ],
                "com": [
                    595,
                    933
                ],
                "func": [
                    896,
                    706,
                    2275,
                    712,
                    714,
                    2282,
                    717,
                    2286,
                    2289,
                    595,
                    724,
                    2291,
                    895
                ],
                "Substitution": [
                    2177,
                    2306,
                    1159,
                    1160,
                    1671,
                    1672,
                    1427,
                    1304,
                    1561,
                    1571,
                    1956,
                    2340,
                    2086,
                    1324,
                    572,
                    2366,
                    1215,
                    2367,
                    1358,
                    2130,
                    1619,
                    1110,
                    2394,
                    2395,
                    1246,
                    2146,
                    1127,
                    2027,
                    1645,
                    2162,
                    1269,
                    1144
                ],
                "Appender": [
                    2178,
                    2307,
                    1428,
                    1305,
                    1562,
                    1443,
                    1572,
                    2341,
                    2087,
                    1325,
                    699,
                    1216,
                    2502,
                    1359,
                    1360,
                    593,
                    2131,
                    1111,
                    1247,
                    2147,
                    1128,
                    2163,
                    1270,
                    1145
                ],
                "plot": [
                    597
                ],
                "GroupByPlot": [
                    597
                ],
                "is_callable": [
                    601,
                    602
                ],
                "self._selected_obj": [
                    2082,
                    613,
                    2021,
                    680,
                    745,
                    617,
                    1002,
                    940,
                    1004,
                    1771,
                    752,
                    1008,
                    1009,
                    2420,
                    2392,
                    601
                ],
                "kind": [
                    602,
                    605
                ],
                "self._set_group_selection": [
                    1760,
                    609,
                    1367
                ],
                "types.MethodType": [
                    614
                ],
                "types": [
                    614
                ],
                "self.apply": [
                    642,
                    645,
                    1446,
                    615,
                    2188,
                    2158,
                    2352,
                    2329,
                    2173,
                    2142,
                    639
                ],
                "kwargs_with_axis": [
                    624,
                    627,
                    622,
                    623
                ],
                "kwargs.copy": [
                    622
                ],
                "x": [
                    896,
                    1409,
                    1410,
                    1411,
                    1413,
                    1415,
                    1416,
                    1418,
                    1292,
                    2188,
                    1296,
                    1300,
                    2329,
                    1441,
                    1446,
                    2353,
                    2173,
                    1206,
                    1212,
                    1088,
                    1231,
                    1239,
                    1240,
                    1241,
                    2142,
                    1378,
                    2158,
                    627,
                    1395,
                    1397,
                    630,
                    1398,
                    1400,
                    1402,
                    1403,
                    1405
                ],
                "curried.__name__": [
                    634
                ],
                "curried": [
                    634,
                    645,
                    639
                ],
                "curried_with_axis.__name__": [
                    634
                ],
                "curried_with_axis": [
                    634,
                    642
                ],
                "base.plotting_methods": [
                    638
                ],
                "base": [
                    848,
                    638
                ],
                "self._aggregate_item_by_item": [
                    655
                ],
                "wrapper": [
                    660
                ],
                "inds": [
                    682,
                    683,
                    686
                ],
                "self._get_index": [
                    682
                ],
                "obj.take": [
                    686
                ],
                "self.grouper.get_iterator": [
                    697
                ],
                "self._is_builtin_func": [
                    706,
                    895
                ],
                "np.errstate": [
                    716
                ],
                "wraps": [
                    714
                ],
                "option_context": [
                    727
                ],
                "self._python_apply_general": [
                    729,
                    740,
                    908
                ],
                "_group_selection_context": [
                    2081,
                    739,
                    2020,
                    1445,
                    1243,
                    1297,
                    1301,
                    1211
                ],
                "values": [
                    961,
                    1826,
                    933,
                    936,
                    745,
                    970,
                    939,
                    748,
                    916,
                    917,
                    918,
                    981,
                    920,
                    982,
                    984,
                    985
                ],
                "mutated": [
                    745,
                    748
                ],
                "self.grouper.apply": [
                    745
                ],
                "self._wrap_applied_output": [
                    747
                ],
                "self._selection_name": [
                    752,
                    992
                ],
                "AbstractMethodError": [
                    755,
                    925
                ],
                "ids": [
                    769,
                    770,
                    771,
                    1766,
                    776,
                    1769,
                    1776
                ],
                "_": [
                    769,
                    1766,
                    2261,
                    1815,
                    2463
                ],
                "ngroups": [
                    769,
                    770,
                    2289,
                    2261,
                    2267
                ],
                "self.grouper.group_info": [
                    2022,
                    769,
                    1766
                ],
                "sorter": [
                    786,
                    770,
                    771
                ],
                "get_group_index_sorter": [
                    770
                ],
                "count": [
                    771,
                    773,
                    777,
                    785,
                    786
                ],
                "np.empty": [
                    785,
                    1004,
                    774
                ],
                "np.int64": [
                    774,
                    1613,
                    787,
                    1886,
                    2334
                ],
                "run": [
                    776,
                    777,
                    778,
                    781,
                    783
                ],
                "np.r_": [
                    776,
                    777,
                    783
                ],
                "rep": [
                    777,
                    781,
                    783
                ],
                "np.diff": [
                    777
                ],
                "np.nonzero": [
                    777
                ],
                "out": [
                    778,
                    1771,
                    781,
                    1773,
                    783,
                    1776,
                    787,
                    1779,
                    1781
                ],
                "cumsum": [
                    778
                ],
                "ascending": [
                    2083,
                    780,
                    2124,
                    2023
                ],
                "np.repeat": [
                    781,
                    783
                ],
                "rev": [
                    785,
                    786,
                    787
                ],
                "np.intp": [
                    785,
                    786,
                    1759
                ],
                "np.arange": [
                    1945,
                    786
                ],
                "astype": [
                    787
                ],
                "obj.ndim": [
                    798
                ],
                "dtype": [
                    801,
                    804,
                    812,
                    817,
                    831,
                    823,
                    830,
                    799
                ],
                "obj._values.dtype": [
                    799
                ],
                "obj._values": [
                    823,
                    799
                ],
                "obj.dtype": [
                    801,
                    877,
                    854
                ],
                "is_scalar": [
                    1904,
                    803
                ],
                "is_datetime64tz_dtype": [
                    804
                ],
                "arr": [
                    809,
                    1945,
                    811,
                    1949
                ],
                "extract_array": [
                    809
                ],
                "arr._from_sequence": [
                    811
                ],
                "result.astype": [
                    812,
                    1095
                ],
                "is_extension_array_dtype": [
                    817
                ],
                "obj._values._from_sequence": [
                    823
                ],
                "numeric_only": [
                    878,
                    1363,
                    830,
                    855
                ],
                "is_numeric_dtype": [
                    854,
                    877,
                    830,
                    917
                ],
                "maybe_downcast_to_dtype": [
                    831
                ],
                "fillna": [
                    847
                ],
                "self.size": [
                    847
                ],
                "func_nm": [
                    848
                ],
                "base.cython_cast_blacklist": [
                    848
                ],
                "output": [
                    2304,
                    899,
                    903,
                    907,
                    2446,
                    2448,
                    913,
                    2453,
                    920,
                    922,
                    2460,
                    2469,
                    2487,
                    2490,
                    2494,
                    2496,
                    852,
                    2262,
                    865,
                    867,
                    869,
                    872,
                    875,
                    887,
                    889,
                    2299,
                    892,
                    2302
                ],
                "collections.OrderedDict": [
                    852,
                    2262
                ],
                "collections": [
                    852,
                    2262
                ],
                "self._iterate_slices": [
                    900,
                    876,
                    853,
                    2265
                ],
                "is_numeric": [
                    878,
                    877,
                    854,
                    855
                ],
                "self.grouper.transform": [
                    859
                ],
                "obj.values": [
                    2272,
                    2279,
                    2285,
                    883,
                    2294,
                    859,
                    2269
                ],
                "how": [
                    864,
                    883,
                    859,
                    2263
                ],
                "GroupByError": [
                    1208,
                    1234,
                    886,
                    863
                ],
                "e": [
                    1373,
                    886,
                    863
                ],
                "self._transform_should_cast": [
                    864
                ],
                "self._try_cast": [
                    865,
                    903,
                    1383,
                    1385,
                    887,
                    920
                ],
                "DataError": [
                    890,
                    870
                ],
                "self._wrap_transformed_output": [
                    872,
                    2304
                ],
                "self.grouper.aggregate": [
                    882
                ],
                "min_count": [
                    883,
                    1365
                ],
                "self._wrap_aggregated_output": [
                    922,
                    892,
                    2302
                ],
                "counts": [
                    912,
                    902
                ],
                "self.grouper.agg_series": [
                    902
                ],
                "self.grouper._filter_empty_groups": [
                    910
                ],
                "mask": [
                    912,
                    920,
                    1826,
                    1829,
                    1830,
                    2391,
                    2392,
                    1764,
                    1769,
                    1771,
                    1004,
                    1005,
                    1006,
                    2285,
                    1008,
                    1009,
                    1776,
                    2286,
                    2419,
                    2420
                ],
                "counts.ravel": [
                    912
                ],
                "output.items": [
                    913
                ],
                "values.dtype": [
                    917
                ],
                "ensure_float": [
                    918
                ],
                "v": [
                    933,
                    934
                ],
                "com.not_none": [
                    933
                ],
                "v._get_axis": [
                    934
                ],
                "ax._reset_identity": [
                    935
                ],
                "not_indexed_same": [
                    938
                ],
                "concat": [
                    969,
                    939,
                    1933,
                    982,
                    985
                ],
                "self._selected_obj._get_axis": [
                    940
                ],
                "result.reindex": [
                    1941,
                    957,
                    1838,
                    943
                ],
                "MultiIndex": [
                    2463,
                    951
                ],
                "ax.is_unique": [
                    951
                ],
                "indexer": [
                    952,
                    955
                ],
                "algorithms.unique1d": [
                    952
                ],
                "algorithms": [
                    952,
                    2294
                ],
                "result.index.get_indexer_for": [
                    953
                ],
                "result.index": [
                    953,
                    1939,
                    1836
                ],
                "ax.values": [
                    953
                ],
                "result.take": [
                    1954,
                    955
                ],
                "reset_identity": [
                    984,
                    961
                ],
                "group_levels": [
                    973,
                    966
                ],
                "self.grouper.levels": [
                    966
                ],
                "group_names": [
                    974,
                    967
                ],
                "self.grouper.names": [
                    2464,
                    967
                ],
                "result.name": [
                    992,
                    1338
                ],
                "indices": [
                    1952,
                    1953,
                    1954,
                    997,
                    998,
                    1000,
                    1002,
                    1006
                ],
                "np.array": [
                    1088,
                    998,
                    1759
                ],
                "np.sort": [
                    1000
                ],
                "dropna": [
                    1792,
                    1798,
                    1001,
                    1752,
                    1787
                ],
                "filtered": [
                    1009,
                    1002,
                    1010
                ],
                "self._selected_obj.take": [
                    1002
                ],
                "self._selected_obj.index": [
                    2082,
                    1004,
                    2021
                ],
                "mask.fill": [
                    1005
                ],
                "indices.astype": [
                    1006
                ],
                "T": [
                    1008
                ],
                "np.tile": [
                    1008
                ],
                "self._selected_obj.shape": [
                    1008
                ],
                "self._selected_obj.where": [
                    1009
                ],
                "_GroupBy": [
                    1013
                ],
                "np.ndarray": [
                    1893,
                    1094,
                    1878,
                    1239,
                    1086
                ],
                "is_object_dtype": [
                    1879,
                    1087
                ],
                "vals": [
                    1088,
                    1889,
                    1090,
                    1891,
                    1092,
                    2279,
                    2281,
                    2282,
                    1900,
                    1902,
                    1887,
                    1879,
                    1885,
                    1087
                ],
                "vals.astype": [
                    1889,
                    1090,
                    1900
                ],
                "np.bool": [
                    1090,
                    1092
                ],
                "vals.view": [
                    1092
                ],
                "np.uint8": [
                    2285,
                    1092,
                    1101
                ],
                "Tuple": [
                    1878,
                    1086
                ],
                "Type": [
                    1094,
                    1893,
                    1086,
                    1878
                ],
                "inference": [
                    1888,
                    1891,
                    1894,
                    1095,
                    1897,
                    1900,
                    1884,
                    1886
                ],
                "self._get_cythonized_result": [
                    1609,
                    1097,
                    1905,
                    2331,
                    1919
                ],
                "objs_to_bool": [
                    1104
                ],
                "result_to_bool": [
                    1105
                ],
                "val_test": [
                    1106
                ],
                "skipna": [
                    1107,
                    1125,
                    1142
                ],
                "self._bool_agg": [
                    1125,
                    1142
                ],
                "nv.validate_groupby_func": [
                    1287,
                    2156,
                    1266,
                    1203,
                    2140
                ],
                "nv": [
                    1287,
                    2156,
                    1266,
                    1203,
                    2140
                ],
                "self._cython_agg_general": [
                    1229,
                    1290,
                    1371,
                    1205
                ],
                "mean": [
                    1206
                ],
                "x.mean": [
                    1212
                ],
                "self._python_agg_general": [
                    1298,
                    1244,
                    1213,
                    1302
                ],
                "median": [
                    1231
                ],
                "x.median": [
                    1241
                ],
                "np.sqrt": [
                    1322,
                    1267
                ],
                "self.var": [
                    1267
                ],
                "ddof": [
                    1288,
                    1322,
                    1292,
                    1296,
                    1267,
                    1300
                ],
                "var": [
                    1292
                ],
                "x.var": [
                    1296,
                    1300
                ],
                "self.std": [
                    1322
                ],
                "self.count": [
                    1322
                ],
                "self.grouper.size": [
                    1335
                ],
                "_local_template": [
                    1360,
                    1349
                ],
                "alias": [
                    1371
                ],
                "npfunc": [
                    1378,
                    1371
                ],
                "SpecificationError": [
                    1373
                ],
                "self.aggregate": [
                    1378
                ],
                "col": [
                    1382,
                    1383
                ],
                "result.columns": [
                    1382
                ],
                "set_function_name": [
                    1389
                ],
                "cls": [
                    1420,
                    1389,
                    1422,
                    1421,
                    1423,
                    1424,
                    1425
                ],
                "x.to_numpy": [
                    1409,
                    1395
                ],
                "notna": [
                    1410,
                    1397
                ],
                "np.nan": [
                    1412,
                    1830,
                    1399
                ],
                "x.apply": [
                    1416,
                    1403
                ],
                "first": [
                    1403,
                    1405
                ],
                "last": [
                    1416,
                    1418
                ],
                "cls.sum": [
                    1420
                ],
                "groupby_function": [
                    1420,
                    1421,
                    1422,
                    1423,
                    1424,
                    1425
                ],
                "np.sum": [
                    1420
                ],
                "cls.prod": [
                    1421
                ],
                "np.prod": [
                    1421
                ],
                "cls.min": [
                    1422
                ],
                "np.min": [
                    1422
                ],
                "cls.max": [
                    1423
                ],
                "np.max": [
                    1423
                ],
                "cls.first": [
                    1424
                ],
                "first_compat": [
                    1424
                ],
                "cls.last": [
                    1425
                ],
                "last_compat": [
                    1425
                ],
                "self._apply_to_column_groupbys": [
                    1441
                ],
                "x._cython_agg_general": [
                    1441
                ],
                "x.describe": [
                    1446
                ],
                "result.T": [
                    1448
                ],
                "result.unstack": [
                    1449
                ],
                "DataFrame.describe.__doc__": [
                    1443
                ],
                "DataFrame.describe": [
                    1443
                ],
                "get_resampler_for_grouping": [
                    1559
                ],
                "rule": [
                    1559
                ],
                "RollingGroupby": [
                    1569
                ],
                "ExpandingGroupby": [
                    1580
                ],
                "limit": [
                    1667,
                    1606,
                    1607,
                    1641,
                    1616,
                    2356,
                    2361
                ],
                "direction": [
                    1615
                ],
                "self._fill": [
                    1641,
                    1667
                ],
                "ffill": [
                    1643
                ],
                "pad": [
                    1643
                ],
                "bfill": [
                    1669
                ],
                "backfill": [
                    1669
                ],
                "Union": [
                    1673
                ],
                "List": [
                    1673
                ],
                "Optional": [
                    1673,
                    1893,
                    1878
                ],
                "valid_containers": [
                    1784,
                    1756,
                    1748,
                    1749
                ],
                "nth_values": [
                    1755,
                    1757,
                    1759
                ],
                "nth_array": [
                    1762,
                    1763,
                    1759
                ],
                "mask_left": [
                    1762,
                    1764
                ],
                "np.in1d": [
                    1762,
                    1763
                ],
                "self._cumcount_array": [
                    1762,
                    2083,
                    1763,
                    2419,
                    2391
                ],
                "mask_right": [
                    1763,
                    1764
                ],
                "result_index": [
                    1776,
                    1778,
                    1779,
                    1775
                ],
                "out.index": [
                    1776
                ],
                "CategoricalIndex": [
                    2457,
                    1778
                ],
                "out.reindex": [
                    1779
                ],
                "out.sort_index": [
                    1781
                ],
                "max_len": [
                    1826,
                    1797
                ],
                "dropped": [
                    1824,
                    1798,
                    1833,
                    1807,
                    1816
                ],
                "self.obj.dropna": [
                    1798
                ],
                "self.grouper.axis": [
                    1806
                ],
                "axis.isin": [
                    1807
                ],
                "dropped.index": [
                    1807
                ],
                "grb": [
                    1824,
                    1825
                ],
                "dropped.groupby": [
                    1824
                ],
                "sizes": [
                    1825,
                    1826
                ],
                "grb.size": [
                    1825
                ],
                "grb.nth": [
                    1825
                ],
                "mask.any": [
                    1829
                ],
                "result.loc": [
                    1830
                ],
                "is_integer_dtype": [
                    1897,
                    1885
                ],
                "is_datetime64_dtype": [
                    1887
                ],
                "np.float": [
                    1889
                ],
                "interpolation": [
                    1929,
                    1898,
                    1915
                ],
                "q": [
                    1931,
                    1933,
                    1904,
                    1941,
                    1944,
                    1914
                ],
                "np.float64": [
                    1925,
                    1911
                ],
                "pre_processor": [
                    1912,
                    1926
                ],
                "post_processor": [
                    1913,
                    1927
                ],
                "results": [
                    1933,
                    1918
                ],
                "qi": [
                    1928,
                    1931
                ],
                "order": [
                    1939,
                    1940
                ],
                "np.roll": [
                    1939
                ],
                "result.index.nlevels": [
                    1939
                ],
                "result.reorder_levels": [
                    1940
                ],
                "hi": [
                    1944,
                    1945
                ],
                "self.ngroups": [
                    1944,
                    1945,
                    2024,
                    1948
                ],
                "arrays": [
                    1952,
                    1946,
                    1950
                ],
                "i": [
                    2483,
                    1948,
                    1949
                ],
                "arr2": [
                    1949,
                    1950
                ],
                "arrays.append": [
                    1950
                ],
                "cumcounts": [
                    2083,
                    2084
                ],
                "na_option": [
                    2125,
                    2117
                ],
                "self._cython_transform": [
                    2144,
                    2120,
                    2190,
                    2160,
                    2175
                ],
                "method": [
                    2123
                ],
                "pct": [
                    2126
                ],
                "x.cumprod": [
                    2142
                ],
                "x.cumsum": [
                    2158
                ],
                "np.minimum.accumulate": [
                    2173
                ],
                "np.minimum": [
                    2173
                ],
                "np.maximum.accumulate": [
                    2188
                ],
                "np.maximum": [
                    2188
                ],
                "result_is_index": [
                    2248,
                    2293
                ],
                "aggregate": [
                    2248,
                    2266,
                    2301
                ],
                "post_processing": [
                    2296,
                    2297,
                    2250
                ],
                "pre_processing": [
                    2280,
                    2281,
                    2251,
                    2253,
                    2254
                ],
                "needs_values": [
                    2256,
                    2278
                ],
                "labels": [
                    2275,
                    2261
                ],
                "grouper.group_info": [
                    2261
                ],
                "base_func": [
                    2275,
                    2263
                ],
                "libgroupby": [
                    2263
                ],
                "result_sz": [
                    2274,
                    2267,
                    2269
                ],
                "cython_dtype": [
                    2272,
                    2274,
                    2271
                ],
                "obj.values.dtype": [
                    2272
                ],
                "np.zeros": [
                    2274
                ],
                "partial": [
                    2289,
                    2282,
                    2275,
                    2286
                ],
                "inferences": [
                    2281,
                    2276,
                    2297
                ],
                "needs_mask": [
                    2284
                ],
                "view": [
                    2285
                ],
                "isna": [
                    2328,
                    2285
                ],
                "needs_ngroups": [
                    2288
                ],
                "algorithms.take_nd": [
                    2294
                ],
                "freq": [
                    2351,
                    2357,
                    2328,
                    2329,
                    2363
                ],
                "fill_value": [
                    2328,
                    2329
                ],
                "x.shift": [
                    2329
                ],
                "periods": [
                    2329,
                    2354,
                    2363,
                    2337
                ],
                "x.pct_change": [
                    2353
                ],
                "fill_method": [
                    2361,
                    2355
                ],
                "filled": [
                    2361,
                    2362,
                    2364
                ],
                "fill_grp": [
                    2362,
                    2363
                ],
                "filled.groupby": [
                    2362
                ],
                "self.grouper.labels": [
                    2362
                ],
                "shifted": [
                    2363,
                    2364
                ],
                "fill_grp.shift": [
                    2363
                ],
                "self._reset_group_selection": [
                    2418,
                    2390
                ],
                "groupings": [
                    2444,
                    2445,
                    2447,
                    2483,
                    2458,
                    2462
                ],
                "self.grouper.groupings": [
                    2444
                ],
                "ping.grouper": [
                    2457
                ],
                "ping": [
                    2457,
                    2458,
                    2483,
                    2462
                ],
                "Categorical": [
                    2457
                ],
                "levels_list": [
                    2464,
                    2462
                ],
                "ping.group_index": [
                    2462
                ],
                "sortlevel": [
                    2463
                ],
                "MultiIndex.from_product": [
                    2463
                ],
                "d": [
                    2468,
                    2469
                ],
                "self.obj._get_axis_name": [
                    2468
                ],
                "output.reindex": [
                    2469
                ],
                "in_axis_grps": [
                    2482,
                    2485
                ],
                "ping.name": [
                    2483
                ],
                "ping.in_axis": [
                    2483
                ],
                "g_nums": [
                    2485,
                    2494
                ],
                "g_names": [
                    2485,
                    2487
                ],
                "output.drop": [
                    2487
                ],
                "reindex": [
                    2490
                ],
                "output.set_index": [
                    2490
                ],
                "output.reset_index": [
                    2496,
                    2494
                ],
                "GroupBy._add_numeric_operations": [
                    2499
                ],
                "GroupBy": [
                    2499,
                    2502
                ],
                "klass": [
                    2507,
                    2515,
                    2511
                ],
                "SeriesGroupBy": [
                    2507
                ],
                "DataFrameGroupBy": [
                    2511
                ],
                "by": [
                    2515
                ],
                "kwds": [
                    2515
                ],
                "GroupBy.__doc__": [
                    2502
                ]
            }
        },
        "test_data": [
            {
                "test_path": "/Volumes/JerrySSD/bgp_envs/repos/pandas_154/pandas/tests/groupby/test_groupby.py",
                "test_function": "test_shift_bfill_ffill_tz",
                "test_function_code": "@pytest.mark.parametrize(\n    \"op, expected\",\n    [\n        (\n            \"shift\",\n            {\n                \"time\": [\n                    None,\n                    None,\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    None,\n                    None,\n                ]\n            },\n        ),\n        (\n            \"bfill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n        (\n            \"ffill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n    ],\n)\ndef test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n    # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n    tz = tz_naive_fixture\n    data = {\n        \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n        \"time\": [\n            Timestamp(\"2019-01-01 12:00:00\"),\n            Timestamp(\"2019-01-01 12:30:00\"),\n            None,\n            None,\n            Timestamp(\"2019-01-01 14:00:00\"),\n            Timestamp(\"2019-01-01 14:30:00\"),\n        ],\n    }\n    df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n\n    grouped = df.groupby(\"id\")\n    result = getattr(grouped, op)()\n    expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    assert_frame_equal(result, expected)",
                "test_error": "AssertionError: Attributes are different  Attribute \"dtype\" are different [left]:  datetime64[ns] [right]: datetime64[ns, UTC]",
                "full_test_error": "tz_naive_fixture = 'UTC', op = 'shift'\nexpected =                        time\n0                       NaT\n1                       NaT\n2 2019-01-01 12:00:00+00:00\n3 2019-01-01 12:30:00+00:00\n4                       NaT\n5                       NaT\n\n    @pytest.mark.parametrize(\n        \"op, expected\",\n        [\n            (\n                \"shift\",\n                {\n                    \"time\": [\n                        None,\n                        None,\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        None,\n                        None,\n                    ]\n                },\n            ),\n            (\n                \"bfill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n            (\n                \"ffill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n        ],\n    )\n    def test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n        # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n        tz = tz_naive_fixture\n        data = {\n            \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n            \"time\": [\n                Timestamp(\"2019-01-01 12:00:00\"),\n                Timestamp(\"2019-01-01 12:30:00\"),\n                None,\n                None,\n                Timestamp(\"2019-01-01 14:00:00\"),\n                Timestamp(\"2019-01-01 14:30:00\"),\n            ],\n        }\n        df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    \n        grouped = df.groupby(\"id\")\n        result = getattr(grouped, op)()\n        expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n>       assert_frame_equal(result, expected)\nE       AssertionError: Attributes are different\nE       \nE       Attribute \"dtype\" are different\nE       [left]:  datetime64[ns]\nE       [right]: datetime64[ns, UTC]\n\npandas/tests/groupby/test_groupby.py:1950: AssertionError",
                "traceback": null,
                "test_error_location": null,
                "test_function_decorators": [
                    "pytest.mark.parametrize('op, expected', [('shift', {'time': [None, None, Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), None, None]}), ('bfill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]}), ('ffill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]})])"
                ]
            },
            {
                "test_path": "/Volumes/JerrySSD/bgp_envs/repos/pandas_154/pandas/tests/groupby/test_groupby.py",
                "test_function": "test_shift_bfill_ffill_tz",
                "test_function_code": "@pytest.mark.parametrize(\n    \"op, expected\",\n    [\n        (\n            \"shift\",\n            {\n                \"time\": [\n                    None,\n                    None,\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    None,\n                    None,\n                ]\n            },\n        ),\n        (\n            \"bfill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n        (\n            \"ffill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n    ],\n)\ndef test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n    # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n    tz = tz_naive_fixture\n    data = {\n        \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n        \"time\": [\n            Timestamp(\"2019-01-01 12:00:00\"),\n            Timestamp(\"2019-01-01 12:30:00\"),\n            None,\n            None,\n            Timestamp(\"2019-01-01 14:00:00\"),\n            Timestamp(\"2019-01-01 14:30:00\"),\n        ],\n    }\n    df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n\n    grouped = df.groupby(\"id\")\n    result = getattr(grouped, op)()\n    expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    assert_frame_equal(result, expected)",
                "test_error": "AssertionError: Attributes are different  Attribute \"dtype\" are different [left]:  datetime64[ns] [right]: datetime64[ns, UTC]",
                "full_test_error": "tz_naive_fixture = 'UTC', op = 'bfill'\nexpected =                        time\n0 2019-01-01 12:00:00+00:00\n1 2019-01-01 12:30:00+00:00\n2 2019-01-01 14:00:00+00:00\n3 2019-01-01 14:30:00+00:00\n4 2019-01-01 14:00:00+00:00\n5 2019-01-01 14:30:00+00:00\n\n    @pytest.mark.parametrize(\n        \"op, expected\",\n        [\n            (\n                \"shift\",\n                {\n                    \"time\": [\n                        None,\n                        None,\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        None,\n                        None,\n                    ]\n                },\n            ),\n            (\n                \"bfill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n            (\n                \"ffill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n        ],\n    )\n    def test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n        # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n        tz = tz_naive_fixture\n        data = {\n            \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n            \"time\": [\n                Timestamp(\"2019-01-01 12:00:00\"),\n                Timestamp(\"2019-01-01 12:30:00\"),\n                None,\n                None,\n                Timestamp(\"2019-01-01 14:00:00\"),\n                Timestamp(\"2019-01-01 14:30:00\"),\n            ],\n        }\n        df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    \n        grouped = df.groupby(\"id\")\n        result = getattr(grouped, op)()\n        expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n>       assert_frame_equal(result, expected)\nE       AssertionError: Attributes are different\nE       \nE       Attribute \"dtype\" are different\nE       [left]:  datetime64[ns]\nE       [right]: datetime64[ns, UTC]\n\npandas/tests/groupby/test_groupby.py:1950: AssertionError",
                "traceback": null,
                "test_error_location": null,
                "test_function_decorators": [
                    "pytest.mark.parametrize('op, expected', [('shift', {'time': [None, None, Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), None, None]}), ('bfill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]}), ('ffill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]})])"
                ]
            },
            {
                "test_path": "/Volumes/JerrySSD/bgp_envs/repos/pandas_154/pandas/tests/groupby/test_groupby.py",
                "test_function": "test_shift_bfill_ffill_tz",
                "test_function_code": "@pytest.mark.parametrize(\n    \"op, expected\",\n    [\n        (\n            \"shift\",\n            {\n                \"time\": [\n                    None,\n                    None,\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    None,\n                    None,\n                ]\n            },\n        ),\n        (\n            \"bfill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n        (\n            \"ffill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n    ],\n)\ndef test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n    # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n    tz = tz_naive_fixture\n    data = {\n        \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n        \"time\": [\n            Timestamp(\"2019-01-01 12:00:00\"),\n            Timestamp(\"2019-01-01 12:30:00\"),\n            None,\n            None,\n            Timestamp(\"2019-01-01 14:00:00\"),\n            Timestamp(\"2019-01-01 14:30:00\"),\n        ],\n    }\n    df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n\n    grouped = df.groupby(\"id\")\n    result = getattr(grouped, op)()\n    expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    assert_frame_equal(result, expected)",
                "test_error": "AssertionError: Attributes are different  Attribute \"dtype\" are different [left]:  datetime64[ns] [right]: datetime64[ns, UTC]",
                "full_test_error": "tz_naive_fixture = 'UTC', op = 'ffill'\nexpected =                        time\n0 2019-01-01 12:00:00+00:00\n1 2019-01-01 12:30:00+00:00\n2 2019-01-01 12:00:00+00:00\n3 2019-01-01 12:30:00+00:00\n4 2019-01-01 14:00:00+00:00\n5 2019-01-01 14:30:00+00:00\n\n    @pytest.mark.parametrize(\n        \"op, expected\",\n        [\n            (\n                \"shift\",\n                {\n                    \"time\": [\n                        None,\n                        None,\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        None,\n                        None,\n                    ]\n                },\n            ),\n            (\n                \"bfill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n            (\n                \"ffill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n        ],\n    )\n    def test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n        # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n        tz = tz_naive_fixture\n        data = {\n            \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n            \"time\": [\n                Timestamp(\"2019-01-01 12:00:00\"),\n                Timestamp(\"2019-01-01 12:30:00\"),\n                None,\n                None,\n                Timestamp(\"2019-01-01 14:00:00\"),\n                Timestamp(\"2019-01-01 14:30:00\"),\n            ],\n        }\n        df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    \n        grouped = df.groupby(\"id\")\n        result = getattr(grouped, op)()\n        expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n>       assert_frame_equal(result, expected)\nE       AssertionError: Attributes are different\nE       \nE       Attribute \"dtype\" are different\nE       [left]:  datetime64[ns]\nE       [right]: datetime64[ns, UTC]\n\npandas/tests/groupby/test_groupby.py:1950: AssertionError",
                "traceback": null,
                "test_error_location": null,
                "test_function_decorators": [
                    "pytest.mark.parametrize('op, expected', [('shift', {'time': [None, None, Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), None, None]}), ('bfill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]}), ('ffill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]})])"
                ]
            },
            {
                "test_path": "/Volumes/JerrySSD/bgp_envs/repos/pandas_154/pandas/tests/groupby/test_groupby.py",
                "test_function": "test_shift_bfill_ffill_tz",
                "test_function_code": "@pytest.mark.parametrize(\n    \"op, expected\",\n    [\n        (\n            \"shift\",\n            {\n                \"time\": [\n                    None,\n                    None,\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    None,\n                    None,\n                ]\n            },\n        ),\n        (\n            \"bfill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n        (\n            \"ffill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n    ],\n)\ndef test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n    # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n    tz = tz_naive_fixture\n    data = {\n        \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n        \"time\": [\n            Timestamp(\"2019-01-01 12:00:00\"),\n            Timestamp(\"2019-01-01 12:30:00\"),\n            None,\n            None,\n            Timestamp(\"2019-01-01 14:00:00\"),\n            Timestamp(\"2019-01-01 14:30:00\"),\n        ],\n    }\n    df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n\n    grouped = df.groupby(\"id\")\n    result = getattr(grouped, op)()\n    expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    assert_frame_equal(result, expected)",
                "test_error": "AssertionError: Attributes are different  Attribute \"dtype\" are different [left]:  datetime64[ns] [right]: datetime64[ns, US/Eastern]",
                "full_test_error": "tz_naive_fixture = 'US/Eastern', op = 'shift'\nexpected =                        time\n0                       NaT\n1                       NaT\n2 2019-01-01 12:00:00-05:00\n3 2019-01-01 12:30:00-05:00\n4                       NaT\n5                       NaT\n\n    @pytest.mark.parametrize(\n        \"op, expected\",\n        [\n            (\n                \"shift\",\n                {\n                    \"time\": [\n                        None,\n                        None,\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        None,\n                        None,\n                    ]\n                },\n            ),\n            (\n                \"bfill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n            (\n                \"ffill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n        ],\n    )\n    def test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n        # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n        tz = tz_naive_fixture\n        data = {\n            \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n            \"time\": [\n                Timestamp(\"2019-01-01 12:00:00\"),\n                Timestamp(\"2019-01-01 12:30:00\"),\n                None,\n                None,\n                Timestamp(\"2019-01-01 14:00:00\"),\n                Timestamp(\"2019-01-01 14:30:00\"),\n            ],\n        }\n        df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    \n        grouped = df.groupby(\"id\")\n        result = getattr(grouped, op)()\n        expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n>       assert_frame_equal(result, expected)\nE       AssertionError: Attributes are different\nE       \nE       Attribute \"dtype\" are different\nE       [left]:  datetime64[ns]\nE       [right]: datetime64[ns, US/Eastern]\n\npandas/tests/groupby/test_groupby.py:1950: AssertionError",
                "traceback": null,
                "test_error_location": null,
                "test_function_decorators": [
                    "pytest.mark.parametrize('op, expected', [('shift', {'time': [None, None, Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), None, None]}), ('bfill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]}), ('ffill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]})])"
                ]
            },
            {
                "test_path": "/Volumes/JerrySSD/bgp_envs/repos/pandas_154/pandas/tests/groupby/test_groupby.py",
                "test_function": "test_shift_bfill_ffill_tz",
                "test_function_code": "@pytest.mark.parametrize(\n    \"op, expected\",\n    [\n        (\n            \"shift\",\n            {\n                \"time\": [\n                    None,\n                    None,\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    None,\n                    None,\n                ]\n            },\n        ),\n        (\n            \"bfill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n        (\n            \"ffill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n    ],\n)\ndef test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n    # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n    tz = tz_naive_fixture\n    data = {\n        \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n        \"time\": [\n            Timestamp(\"2019-01-01 12:00:00\"),\n            Timestamp(\"2019-01-01 12:30:00\"),\n            None,\n            None,\n            Timestamp(\"2019-01-01 14:00:00\"),\n            Timestamp(\"2019-01-01 14:30:00\"),\n        ],\n    }\n    df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n\n    grouped = df.groupby(\"id\")\n    result = getattr(grouped, op)()\n    expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    assert_frame_equal(result, expected)",
                "test_error": "AssertionError: Attributes are different  Attribute \"dtype\" are different [left]:  datetime64[ns] [right]: datetime64[ns, US/Eastern]",
                "full_test_error": "tz_naive_fixture = 'US/Eastern', op = 'bfill'\nexpected =                        time\n0 2019-01-01 12:00:00-05:00\n1 2019-01-01 12:30:00-05:00\n2 2019-01-01 14:00:00-05:00\n3 2019-01-01 14:30:00-05:00\n4 2019-01-01 14:00:00-05:00\n5 2019-01-01 14:30:00-05:00\n\n    @pytest.mark.parametrize(\n        \"op, expected\",\n        [\n            (\n                \"shift\",\n                {\n                    \"time\": [\n                        None,\n                        None,\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        None,\n                        None,\n                    ]\n                },\n            ),\n            (\n                \"bfill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n            (\n                \"ffill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n        ],\n    )\n    def test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n        # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n        tz = tz_naive_fixture\n        data = {\n            \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n            \"time\": [\n                Timestamp(\"2019-01-01 12:00:00\"),\n                Timestamp(\"2019-01-01 12:30:00\"),\n                None,\n                None,\n                Timestamp(\"2019-01-01 14:00:00\"),\n                Timestamp(\"2019-01-01 14:30:00\"),\n            ],\n        }\n        df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    \n        grouped = df.groupby(\"id\")\n        result = getattr(grouped, op)()\n        expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n>       assert_frame_equal(result, expected)\nE       AssertionError: Attributes are different\nE       \nE       Attribute \"dtype\" are different\nE       [left]:  datetime64[ns]\nE       [right]: datetime64[ns, US/Eastern]\n\npandas/tests/groupby/test_groupby.py:1950: AssertionError",
                "traceback": null,
                "test_error_location": null,
                "test_function_decorators": [
                    "pytest.mark.parametrize('op, expected', [('shift', {'time': [None, None, Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), None, None]}), ('bfill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]}), ('ffill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]})])"
                ]
            },
            {
                "test_path": "/Volumes/JerrySSD/bgp_envs/repos/pandas_154/pandas/tests/groupby/test_groupby.py",
                "test_function": "test_shift_bfill_ffill_tz",
                "test_function_code": "@pytest.mark.parametrize(\n    \"op, expected\",\n    [\n        (\n            \"shift\",\n            {\n                \"time\": [\n                    None,\n                    None,\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    None,\n                    None,\n                ]\n            },\n        ),\n        (\n            \"bfill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n        (\n            \"ffill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n    ],\n)\ndef test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n    # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n    tz = tz_naive_fixture\n    data = {\n        \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n        \"time\": [\n            Timestamp(\"2019-01-01 12:00:00\"),\n            Timestamp(\"2019-01-01 12:30:00\"),\n            None,\n            None,\n            Timestamp(\"2019-01-01 14:00:00\"),\n            Timestamp(\"2019-01-01 14:30:00\"),\n        ],\n    }\n    df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n\n    grouped = df.groupby(\"id\")\n    result = getattr(grouped, op)()\n    expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    assert_frame_equal(result, expected)",
                "test_error": "AssertionError: Attributes are different  Attribute \"dtype\" are different [left]:  datetime64[ns] [right]: datetime64[ns, US/Eastern]",
                "full_test_error": "tz_naive_fixture = 'US/Eastern', op = 'ffill'\nexpected =                        time\n0 2019-01-01 12:00:00-05:00\n1 2019-01-01 12:30:00-05:00\n2 2019-01-01 12:00:00-05:00\n3 2019-01-01 12:30:00-05:00\n4 2019-01-01 14:00:00-05:00\n5 2019-01-01 14:30:00-05:00\n\n    @pytest.mark.parametrize(\n        \"op, expected\",\n        [\n            (\n                \"shift\",\n                {\n                    \"time\": [\n                        None,\n                        None,\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        None,\n                        None,\n                    ]\n                },\n            ),\n            (\n                \"bfill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n            (\n                \"ffill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n        ],\n    )\n    def test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n        # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n        tz = tz_naive_fixture\n        data = {\n            \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n            \"time\": [\n                Timestamp(\"2019-01-01 12:00:00\"),\n                Timestamp(\"2019-01-01 12:30:00\"),\n                None,\n                None,\n                Timestamp(\"2019-01-01 14:00:00\"),\n                Timestamp(\"2019-01-01 14:30:00\"),\n            ],\n        }\n        df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    \n        grouped = df.groupby(\"id\")\n        result = getattr(grouped, op)()\n        expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n>       assert_frame_equal(result, expected)\nE       AssertionError: Attributes are different\nE       \nE       Attribute \"dtype\" are different\nE       [left]:  datetime64[ns]\nE       [right]: datetime64[ns, US/Eastern]\n\npandas/tests/groupby/test_groupby.py:1950: AssertionError",
                "traceback": null,
                "test_error_location": null,
                "test_function_decorators": [
                    "pytest.mark.parametrize('op, expected', [('shift', {'time': [None, None, Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), None, None]}), ('bfill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]}), ('ffill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]})])"
                ]
            },
            {
                "test_path": "/Volumes/JerrySSD/bgp_envs/repos/pandas_154/pandas/tests/groupby/test_groupby.py",
                "test_function": "test_shift_bfill_ffill_tz",
                "test_function_code": "@pytest.mark.parametrize(\n    \"op, expected\",\n    [\n        (\n            \"shift\",\n            {\n                \"time\": [\n                    None,\n                    None,\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    None,\n                    None,\n                ]\n            },\n        ),\n        (\n            \"bfill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n        (\n            \"ffill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n    ],\n)\ndef test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n    # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n    tz = tz_naive_fixture\n    data = {\n        \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n        \"time\": [\n            Timestamp(\"2019-01-01 12:00:00\"),\n            Timestamp(\"2019-01-01 12:30:00\"),\n            None,\n            None,\n            Timestamp(\"2019-01-01 14:00:00\"),\n            Timestamp(\"2019-01-01 14:30:00\"),\n        ],\n    }\n    df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n\n    grouped = df.groupby(\"id\")\n    result = getattr(grouped, op)()\n    expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    assert_frame_equal(result, expected)",
                "test_error": "AssertionError: Attributes are different  Attribute \"dtype\" are different [left]:  datetime64[ns] [right]: datetime64[ns, Asia/Tokyo]",
                "full_test_error": "tz_naive_fixture = 'Asia/Tokyo', op = 'shift'\nexpected =                        time\n0                       NaT\n1                       NaT\n2 2019-01-01 12:00:00+09:00\n3 2019-01-01 12:30:00+09:00\n4                       NaT\n5                       NaT\n\n    @pytest.mark.parametrize(\n        \"op, expected\",\n        [\n            (\n                \"shift\",\n                {\n                    \"time\": [\n                        None,\n                        None,\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        None,\n                        None,\n                    ]\n                },\n            ),\n            (\n                \"bfill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n            (\n                \"ffill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n        ],\n    )\n    def test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n        # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n        tz = tz_naive_fixture\n        data = {\n            \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n            \"time\": [\n                Timestamp(\"2019-01-01 12:00:00\"),\n                Timestamp(\"2019-01-01 12:30:00\"),\n                None,\n                None,\n                Timestamp(\"2019-01-01 14:00:00\"),\n                Timestamp(\"2019-01-01 14:30:00\"),\n            ],\n        }\n        df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    \n        grouped = df.groupby(\"id\")\n        result = getattr(grouped, op)()\n        expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n>       assert_frame_equal(result, expected)\nE       AssertionError: Attributes are different\nE       \nE       Attribute \"dtype\" are different\nE       [left]:  datetime64[ns]\nE       [right]: datetime64[ns, Asia/Tokyo]\n\npandas/tests/groupby/test_groupby.py:1950: AssertionError",
                "traceback": null,
                "test_error_location": null,
                "test_function_decorators": [
                    "pytest.mark.parametrize('op, expected', [('shift', {'time': [None, None, Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), None, None]}), ('bfill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]}), ('ffill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]})])"
                ]
            },
            {
                "test_path": "/Volumes/JerrySSD/bgp_envs/repos/pandas_154/pandas/tests/groupby/test_groupby.py",
                "test_function": "test_shift_bfill_ffill_tz",
                "test_function_code": "@pytest.mark.parametrize(\n    \"op, expected\",\n    [\n        (\n            \"shift\",\n            {\n                \"time\": [\n                    None,\n                    None,\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    None,\n                    None,\n                ]\n            },\n        ),\n        (\n            \"bfill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n        (\n            \"ffill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n    ],\n)\ndef test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n    # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n    tz = tz_naive_fixture\n    data = {\n        \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n        \"time\": [\n            Timestamp(\"2019-01-01 12:00:00\"),\n            Timestamp(\"2019-01-01 12:30:00\"),\n            None,\n            None,\n            Timestamp(\"2019-01-01 14:00:00\"),\n            Timestamp(\"2019-01-01 14:30:00\"),\n        ],\n    }\n    df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n\n    grouped = df.groupby(\"id\")\n    result = getattr(grouped, op)()\n    expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    assert_frame_equal(result, expected)",
                "test_error": "AssertionError: Attributes are different  Attribute \"dtype\" are different [left]:  datetime64[ns] [right]: datetime64[ns, Asia/Tokyo]",
                "full_test_error": "tz_naive_fixture = 'Asia/Tokyo', op = 'bfill'\nexpected =                        time\n0 2019-01-01 12:00:00+09:00\n1 2019-01-01 12:30:00+09:00\n2 2019-01-01 14:00:00+09:00\n3 2019-01-01 14:30:00+09:00\n4 2019-01-01 14:00:00+09:00\n5 2019-01-01 14:30:00+09:00\n\n    @pytest.mark.parametrize(\n        \"op, expected\",\n        [\n            (\n                \"shift\",\n                {\n                    \"time\": [\n                        None,\n                        None,\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        None,\n                        None,\n                    ]\n                },\n            ),\n            (\n                \"bfill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n            (\n                \"ffill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n        ],\n    )\n    def test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n        # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n        tz = tz_naive_fixture\n        data = {\n            \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n            \"time\": [\n                Timestamp(\"2019-01-01 12:00:00\"),\n                Timestamp(\"2019-01-01 12:30:00\"),\n                None,\n                None,\n                Timestamp(\"2019-01-01 14:00:00\"),\n                Timestamp(\"2019-01-01 14:30:00\"),\n            ],\n        }\n        df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    \n        grouped = df.groupby(\"id\")\n        result = getattr(grouped, op)()\n        expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n>       assert_frame_equal(result, expected)\nE       AssertionError: Attributes are different\nE       \nE       Attribute \"dtype\" are different\nE       [left]:  datetime64[ns]\nE       [right]: datetime64[ns, Asia/Tokyo]\n\npandas/tests/groupby/test_groupby.py:1950: AssertionError",
                "traceback": null,
                "test_error_location": null,
                "test_function_decorators": [
                    "pytest.mark.parametrize('op, expected', [('shift', {'time': [None, None, Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), None, None]}), ('bfill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]}), ('ffill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]})])"
                ]
            },
            {
                "test_path": "/Volumes/JerrySSD/bgp_envs/repos/pandas_154/pandas/tests/groupby/test_groupby.py",
                "test_function": "test_shift_bfill_ffill_tz",
                "test_function_code": "@pytest.mark.parametrize(\n    \"op, expected\",\n    [\n        (\n            \"shift\",\n            {\n                \"time\": [\n                    None,\n                    None,\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    None,\n                    None,\n                ]\n            },\n        ),\n        (\n            \"bfill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n        (\n            \"ffill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n    ],\n)\ndef test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n    # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n    tz = tz_naive_fixture\n    data = {\n        \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n        \"time\": [\n            Timestamp(\"2019-01-01 12:00:00\"),\n            Timestamp(\"2019-01-01 12:30:00\"),\n            None,\n            None,\n            Timestamp(\"2019-01-01 14:00:00\"),\n            Timestamp(\"2019-01-01 14:30:00\"),\n        ],\n    }\n    df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n\n    grouped = df.groupby(\"id\")\n    result = getattr(grouped, op)()\n    expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    assert_frame_equal(result, expected)",
                "test_error": "AssertionError: Attributes are different  Attribute \"dtype\" are different [left]:  datetime64[ns] [right]: datetime64[ns, Asia/Tokyo]",
                "full_test_error": "tz_naive_fixture = 'Asia/Tokyo', op = 'ffill'\nexpected =                        time\n0 2019-01-01 12:00:00+09:00\n1 2019-01-01 12:30:00+09:00\n2 2019-01-01 12:00:00+09:00\n3 2019-01-01 12:30:00+09:00\n4 2019-01-01 14:00:00+09:00\n5 2019-01-01 14:30:00+09:00\n\n    @pytest.mark.parametrize(\n        \"op, expected\",\n        [\n            (\n                \"shift\",\n                {\n                    \"time\": [\n                        None,\n                        None,\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        None,\n                        None,\n                    ]\n                },\n            ),\n            (\n                \"bfill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n            (\n                \"ffill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n        ],\n    )\n    def test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n        # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n        tz = tz_naive_fixture\n        data = {\n            \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n            \"time\": [\n                Timestamp(\"2019-01-01 12:00:00\"),\n                Timestamp(\"2019-01-01 12:30:00\"),\n                None,\n                None,\n                Timestamp(\"2019-01-01 14:00:00\"),\n                Timestamp(\"2019-01-01 14:30:00\"),\n            ],\n        }\n        df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    \n        grouped = df.groupby(\"id\")\n        result = getattr(grouped, op)()\n        expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n>       assert_frame_equal(result, expected)\nE       AssertionError: Attributes are different\nE       \nE       Attribute \"dtype\" are different\nE       [left]:  datetime64[ns]\nE       [right]: datetime64[ns, Asia/Tokyo]\n\npandas/tests/groupby/test_groupby.py:1950: AssertionError",
                "traceback": null,
                "test_error_location": null,
                "test_function_decorators": [
                    "pytest.mark.parametrize('op, expected', [('shift', {'time': [None, None, Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), None, None]}), ('bfill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]}), ('ffill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]})])"
                ]
            },
            {
                "test_path": "/Volumes/JerrySSD/bgp_envs/repos/pandas_154/pandas/tests/groupby/test_groupby.py",
                "test_function": "test_shift_bfill_ffill_tz",
                "test_function_code": "@pytest.mark.parametrize(\n    \"op, expected\",\n    [\n        (\n            \"shift\",\n            {\n                \"time\": [\n                    None,\n                    None,\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    None,\n                    None,\n                ]\n            },\n        ),\n        (\n            \"bfill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n        (\n            \"ffill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n    ],\n)\ndef test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n    # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n    tz = tz_naive_fixture\n    data = {\n        \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n        \"time\": [\n            Timestamp(\"2019-01-01 12:00:00\"),\n            Timestamp(\"2019-01-01 12:30:00\"),\n            None,\n            None,\n            Timestamp(\"2019-01-01 14:00:00\"),\n            Timestamp(\"2019-01-01 14:30:00\"),\n        ],\n    }\n    df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n\n    grouped = df.groupby(\"id\")\n    result = getattr(grouped, op)()\n    expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    assert_frame_equal(result, expected)",
                "test_error": "AssertionError: Attributes are different  Attribute \"dtype\" are different [left]:  datetime64[ns] [right]: datetime64[ns, tzfile('/usr/share/zoneinfo/US/Pacific')]",
                "full_test_error": "tz_naive_fixture = 'dateutil/US/Pacific', op = 'shift'\nexpected =                        time\n0                       NaT\n1                       NaT\n2 2019-01-01 12:00:00-08:00\n3 2019-01-01 12:30:00-08:00\n4                       NaT\n5                       NaT\n\n    @pytest.mark.parametrize(\n        \"op, expected\",\n        [\n            (\n                \"shift\",\n                {\n                    \"time\": [\n                        None,\n                        None,\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        None,\n                        None,\n                    ]\n                },\n            ),\n            (\n                \"bfill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n            (\n                \"ffill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n        ],\n    )\n    def test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n        # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n        tz = tz_naive_fixture\n        data = {\n            \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n            \"time\": [\n                Timestamp(\"2019-01-01 12:00:00\"),\n                Timestamp(\"2019-01-01 12:30:00\"),\n                None,\n                None,\n                Timestamp(\"2019-01-01 14:00:00\"),\n                Timestamp(\"2019-01-01 14:30:00\"),\n            ],\n        }\n        df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    \n        grouped = df.groupby(\"id\")\n        result = getattr(grouped, op)()\n        expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n>       assert_frame_equal(result, expected)\nE       AssertionError: Attributes are different\nE       \nE       Attribute \"dtype\" are different\nE       [left]:  datetime64[ns]\nE       [right]: datetime64[ns, tzfile('/usr/share/zoneinfo/US/Pacific')]\n\npandas/tests/groupby/test_groupby.py:1950: AssertionError",
                "traceback": null,
                "test_error_location": null,
                "test_function_decorators": [
                    "pytest.mark.parametrize('op, expected', [('shift', {'time': [None, None, Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), None, None]}), ('bfill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]}), ('ffill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]})])"
                ]
            },
            {
                "test_path": "/Volumes/JerrySSD/bgp_envs/repos/pandas_154/pandas/tests/groupby/test_groupby.py",
                "test_function": "test_shift_bfill_ffill_tz",
                "test_function_code": "@pytest.mark.parametrize(\n    \"op, expected\",\n    [\n        (\n            \"shift\",\n            {\n                \"time\": [\n                    None,\n                    None,\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    None,\n                    None,\n                ]\n            },\n        ),\n        (\n            \"bfill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n        (\n            \"ffill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n    ],\n)\ndef test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n    # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n    tz = tz_naive_fixture\n    data = {\n        \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n        \"time\": [\n            Timestamp(\"2019-01-01 12:00:00\"),\n            Timestamp(\"2019-01-01 12:30:00\"),\n            None,\n            None,\n            Timestamp(\"2019-01-01 14:00:00\"),\n            Timestamp(\"2019-01-01 14:30:00\"),\n        ],\n    }\n    df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n\n    grouped = df.groupby(\"id\")\n    result = getattr(grouped, op)()\n    expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    assert_frame_equal(result, expected)",
                "test_error": "AssertionError: Attributes are different  Attribute \"dtype\" are different [left]:  datetime64[ns] [right]: datetime64[ns, tzfile('/usr/share/zoneinfo/US/Pacific')]",
                "full_test_error": "tz_naive_fixture = 'dateutil/US/Pacific', op = 'bfill'\nexpected =                        time\n0 2019-01-01 12:00:00-08:00\n1 2019-01-01 12:30:00-08:00\n2 2019-01-01 14:00:00-08:00\n3 2019-01-01 14:30:00-08:00\n4 2019-01-01 14:00:00-08:00\n5 2019-01-01 14:30:00-08:00\n\n    @pytest.mark.parametrize(\n        \"op, expected\",\n        [\n            (\n                \"shift\",\n                {\n                    \"time\": [\n                        None,\n                        None,\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        None,\n                        None,\n                    ]\n                },\n            ),\n            (\n                \"bfill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n            (\n                \"ffill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n        ],\n    )\n    def test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n        # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n        tz = tz_naive_fixture\n        data = {\n            \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n            \"time\": [\n                Timestamp(\"2019-01-01 12:00:00\"),\n                Timestamp(\"2019-01-01 12:30:00\"),\n                None,\n                None,\n                Timestamp(\"2019-01-01 14:00:00\"),\n                Timestamp(\"2019-01-01 14:30:00\"),\n            ],\n        }\n        df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    \n        grouped = df.groupby(\"id\")\n        result = getattr(grouped, op)()\n        expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n>       assert_frame_equal(result, expected)\nE       AssertionError: Attributes are different\nE       \nE       Attribute \"dtype\" are different\nE       [left]:  datetime64[ns]\nE       [right]: datetime64[ns, tzfile('/usr/share/zoneinfo/US/Pacific')]\n\npandas/tests/groupby/test_groupby.py:1950: AssertionError",
                "traceback": null,
                "test_error_location": null,
                "test_function_decorators": [
                    "pytest.mark.parametrize('op, expected', [('shift', {'time': [None, None, Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), None, None]}), ('bfill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]}), ('ffill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]})])"
                ]
            },
            {
                "test_path": "/Volumes/JerrySSD/bgp_envs/repos/pandas_154/pandas/tests/groupby/test_groupby.py",
                "test_function": "test_shift_bfill_ffill_tz",
                "test_function_code": "@pytest.mark.parametrize(\n    \"op, expected\",\n    [\n        (\n            \"shift\",\n            {\n                \"time\": [\n                    None,\n                    None,\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    None,\n                    None,\n                ]\n            },\n        ),\n        (\n            \"bfill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n        (\n            \"ffill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n    ],\n)\ndef test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n    # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n    tz = tz_naive_fixture\n    data = {\n        \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n        \"time\": [\n            Timestamp(\"2019-01-01 12:00:00\"),\n            Timestamp(\"2019-01-01 12:30:00\"),\n            None,\n            None,\n            Timestamp(\"2019-01-01 14:00:00\"),\n            Timestamp(\"2019-01-01 14:30:00\"),\n        ],\n    }\n    df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n\n    grouped = df.groupby(\"id\")\n    result = getattr(grouped, op)()\n    expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    assert_frame_equal(result, expected)",
                "test_error": "AssertionError: Attributes are different  Attribute \"dtype\" are different [left]:  datetime64[ns] [right]: datetime64[ns, tzfile('/usr/share/zoneinfo/US/Pacific')]",
                "full_test_error": "tz_naive_fixture = 'dateutil/US/Pacific', op = 'ffill'\nexpected =                        time\n0 2019-01-01 12:00:00-08:00\n1 2019-01-01 12:30:00-08:00\n2 2019-01-01 12:00:00-08:00\n3 2019-01-01 12:30:00-08:00\n4 2019-01-01 14:00:00-08:00\n5 2019-01-01 14:30:00-08:00\n\n    @pytest.mark.parametrize(\n        \"op, expected\",\n        [\n            (\n                \"shift\",\n                {\n                    \"time\": [\n                        None,\n                        None,\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        None,\n                        None,\n                    ]\n                },\n            ),\n            (\n                \"bfill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n            (\n                \"ffill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n        ],\n    )\n    def test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n        # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n        tz = tz_naive_fixture\n        data = {\n            \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n            \"time\": [\n                Timestamp(\"2019-01-01 12:00:00\"),\n                Timestamp(\"2019-01-01 12:30:00\"),\n                None,\n                None,\n                Timestamp(\"2019-01-01 14:00:00\"),\n                Timestamp(\"2019-01-01 14:30:00\"),\n            ],\n        }\n        df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    \n        grouped = df.groupby(\"id\")\n        result = getattr(grouped, op)()\n        expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n>       assert_frame_equal(result, expected)\nE       AssertionError: Attributes are different\nE       \nE       Attribute \"dtype\" are different\nE       [left]:  datetime64[ns]\nE       [right]: datetime64[ns, tzfile('/usr/share/zoneinfo/US/Pacific')]\n\npandas/tests/groupby/test_groupby.py:1950: AssertionError",
                "traceback": null,
                "test_error_location": null,
                "test_function_decorators": [
                    "pytest.mark.parametrize('op, expected', [('shift', {'time': [None, None, Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), None, None]}), ('bfill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]}), ('ffill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]})])"
                ]
            },
            {
                "test_path": "/Volumes/JerrySSD/bgp_envs/repos/pandas_154/pandas/tests/groupby/test_groupby.py",
                "test_function": "test_shift_bfill_ffill_tz",
                "test_function_code": "@pytest.mark.parametrize(\n    \"op, expected\",\n    [\n        (\n            \"shift\",\n            {\n                \"time\": [\n                    None,\n                    None,\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    None,\n                    None,\n                ]\n            },\n        ),\n        (\n            \"bfill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n        (\n            \"ffill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n    ],\n)\ndef test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n    # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n    tz = tz_naive_fixture\n    data = {\n        \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n        \"time\": [\n            Timestamp(\"2019-01-01 12:00:00\"),\n            Timestamp(\"2019-01-01 12:30:00\"),\n            None,\n            None,\n            Timestamp(\"2019-01-01 14:00:00\"),\n            Timestamp(\"2019-01-01 14:30:00\"),\n        ],\n    }\n    df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n\n    grouped = df.groupby(\"id\")\n    result = getattr(grouped, op)()\n    expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    assert_frame_equal(result, expected)",
                "test_error": "AssertionError: Attributes are different  Attribute \"dtype\" are different [left]:  datetime64[ns] [right]: datetime64[ns, tzfile('/usr/share/zoneinfo/Asia/Singapore')]",
                "full_test_error": "tz_naive_fixture = 'dateutil/Asia/Singapore', op = 'shift'\nexpected =                        time\n0                       NaT\n1                       NaT\n2 2019-01-01 12:00:00+08:00\n3 2019-01-01 12:30:00+08:00\n4                       NaT\n5                       NaT\n\n    @pytest.mark.parametrize(\n        \"op, expected\",\n        [\n            (\n                \"shift\",\n                {\n                    \"time\": [\n                        None,\n                        None,\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        None,\n                        None,\n                    ]\n                },\n            ),\n            (\n                \"bfill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n            (\n                \"ffill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n        ],\n    )\n    def test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n        # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n        tz = tz_naive_fixture\n        data = {\n            \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n            \"time\": [\n                Timestamp(\"2019-01-01 12:00:00\"),\n                Timestamp(\"2019-01-01 12:30:00\"),\n                None,\n                None,\n                Timestamp(\"2019-01-01 14:00:00\"),\n                Timestamp(\"2019-01-01 14:30:00\"),\n            ],\n        }\n        df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    \n        grouped = df.groupby(\"id\")\n        result = getattr(grouped, op)()\n        expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n>       assert_frame_equal(result, expected)\nE       AssertionError: Attributes are different\nE       \nE       Attribute \"dtype\" are different\nE       [left]:  datetime64[ns]\nE       [right]: datetime64[ns, tzfile('/usr/share/zoneinfo/Asia/Singapore')]\n\npandas/tests/groupby/test_groupby.py:1950: AssertionError",
                "traceback": null,
                "test_error_location": null,
                "test_function_decorators": [
                    "pytest.mark.parametrize('op, expected', [('shift', {'time': [None, None, Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), None, None]}), ('bfill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]}), ('ffill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]})])"
                ]
            },
            {
                "test_path": "/Volumes/JerrySSD/bgp_envs/repos/pandas_154/pandas/tests/groupby/test_groupby.py",
                "test_function": "test_shift_bfill_ffill_tz",
                "test_function_code": "@pytest.mark.parametrize(\n    \"op, expected\",\n    [\n        (\n            \"shift\",\n            {\n                \"time\": [\n                    None,\n                    None,\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    None,\n                    None,\n                ]\n            },\n        ),\n        (\n            \"bfill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n        (\n            \"ffill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n    ],\n)\ndef test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n    # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n    tz = tz_naive_fixture\n    data = {\n        \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n        \"time\": [\n            Timestamp(\"2019-01-01 12:00:00\"),\n            Timestamp(\"2019-01-01 12:30:00\"),\n            None,\n            None,\n            Timestamp(\"2019-01-01 14:00:00\"),\n            Timestamp(\"2019-01-01 14:30:00\"),\n        ],\n    }\n    df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n\n    grouped = df.groupby(\"id\")\n    result = getattr(grouped, op)()\n    expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    assert_frame_equal(result, expected)",
                "test_error": "AssertionError: Attributes are different  Attribute \"dtype\" are different [left]:  datetime64[ns] [right]: datetime64[ns, tzfile('/usr/share/zoneinfo/Asia/Singapore')]",
                "full_test_error": "tz_naive_fixture = 'dateutil/Asia/Singapore', op = 'bfill'\nexpected =                        time\n0 2019-01-01 12:00:00+08:00\n1 2019-01-01 12:30:00+08:00\n2 2019-01-01 14:00:00+08:00\n3 2019-01-01 14:30:00+08:00\n4 2019-01-01 14:00:00+08:00\n5 2019-01-01 14:30:00+08:00\n\n    @pytest.mark.parametrize(\n        \"op, expected\",\n        [\n            (\n                \"shift\",\n                {\n                    \"time\": [\n                        None,\n                        None,\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        None,\n                        None,\n                    ]\n                },\n            ),\n            (\n                \"bfill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n            (\n                \"ffill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n        ],\n    )\n    def test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n        # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n        tz = tz_naive_fixture\n        data = {\n            \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n            \"time\": [\n                Timestamp(\"2019-01-01 12:00:00\"),\n                Timestamp(\"2019-01-01 12:30:00\"),\n                None,\n                None,\n                Timestamp(\"2019-01-01 14:00:00\"),\n                Timestamp(\"2019-01-01 14:30:00\"),\n            ],\n        }\n        df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    \n        grouped = df.groupby(\"id\")\n        result = getattr(grouped, op)()\n        expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n>       assert_frame_equal(result, expected)\nE       AssertionError: Attributes are different\nE       \nE       Attribute \"dtype\" are different\nE       [left]:  datetime64[ns]\nE       [right]: datetime64[ns, tzfile('/usr/share/zoneinfo/Asia/Singapore')]\n\npandas/tests/groupby/test_groupby.py:1950: AssertionError",
                "traceback": null,
                "test_error_location": null,
                "test_function_decorators": [
                    "pytest.mark.parametrize('op, expected', [('shift', {'time': [None, None, Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), None, None]}), ('bfill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]}), ('ffill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]})])"
                ]
            },
            {
                "test_path": "/Volumes/JerrySSD/bgp_envs/repos/pandas_154/pandas/tests/groupby/test_groupby.py",
                "test_function": "test_shift_bfill_ffill_tz",
                "test_function_code": "@pytest.mark.parametrize(\n    \"op, expected\",\n    [\n        (\n            \"shift\",\n            {\n                \"time\": [\n                    None,\n                    None,\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    None,\n                    None,\n                ]\n            },\n        ),\n        (\n            \"bfill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n        (\n            \"ffill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n    ],\n)\ndef test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n    # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n    tz = tz_naive_fixture\n    data = {\n        \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n        \"time\": [\n            Timestamp(\"2019-01-01 12:00:00\"),\n            Timestamp(\"2019-01-01 12:30:00\"),\n            None,\n            None,\n            Timestamp(\"2019-01-01 14:00:00\"),\n            Timestamp(\"2019-01-01 14:30:00\"),\n        ],\n    }\n    df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n\n    grouped = df.groupby(\"id\")\n    result = getattr(grouped, op)()\n    expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    assert_frame_equal(result, expected)",
                "test_error": "AssertionError: Attributes are different  Attribute \"dtype\" are different [left]:  datetime64[ns] [right]: datetime64[ns, tzfile('/usr/share/zoneinfo/Asia/Singapore')]",
                "full_test_error": "tz_naive_fixture = 'dateutil/Asia/Singapore', op = 'ffill'\nexpected =                        time\n0 2019-01-01 12:00:00+08:00\n1 2019-01-01 12:30:00+08:00\n2 2019-01-01 12:00:00+08:00\n3 2019-01-01 12:30:00+08:00\n4 2019-01-01 14:00:00+08:00\n5 2019-01-01 14:30:00+08:00\n\n    @pytest.mark.parametrize(\n        \"op, expected\",\n        [\n            (\n                \"shift\",\n                {\n                    \"time\": [\n                        None,\n                        None,\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        None,\n                        None,\n                    ]\n                },\n            ),\n            (\n                \"bfill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n            (\n                \"ffill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n        ],\n    )\n    def test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n        # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n        tz = tz_naive_fixture\n        data = {\n            \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n            \"time\": [\n                Timestamp(\"2019-01-01 12:00:00\"),\n                Timestamp(\"2019-01-01 12:30:00\"),\n                None,\n                None,\n                Timestamp(\"2019-01-01 14:00:00\"),\n                Timestamp(\"2019-01-01 14:30:00\"),\n            ],\n        }\n        df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    \n        grouped = df.groupby(\"id\")\n        result = getattr(grouped, op)()\n        expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n>       assert_frame_equal(result, expected)\nE       AssertionError: Attributes are different\nE       \nE       Attribute \"dtype\" are different\nE       [left]:  datetime64[ns]\nE       [right]: datetime64[ns, tzfile('/usr/share/zoneinfo/Asia/Singapore')]\n\npandas/tests/groupby/test_groupby.py:1950: AssertionError",
                "traceback": null,
                "test_error_location": null,
                "test_function_decorators": [
                    "pytest.mark.parametrize('op, expected', [('shift', {'time': [None, None, Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), None, None]}), ('bfill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]}), ('ffill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]})])"
                ]
            },
            {
                "test_path": "/Volumes/JerrySSD/bgp_envs/repos/pandas_154/pandas/tests/groupby/test_groupby.py",
                "test_function": "test_shift_bfill_ffill_tz",
                "test_function_code": "@pytest.mark.parametrize(\n    \"op, expected\",\n    [\n        (\n            \"shift\",\n            {\n                \"time\": [\n                    None,\n                    None,\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    None,\n                    None,\n                ]\n            },\n        ),\n        (\n            \"bfill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n        (\n            \"ffill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n    ],\n)\ndef test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n    # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n    tz = tz_naive_fixture\n    data = {\n        \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n        \"time\": [\n            Timestamp(\"2019-01-01 12:00:00\"),\n            Timestamp(\"2019-01-01 12:30:00\"),\n            None,\n            None,\n            Timestamp(\"2019-01-01 14:00:00\"),\n            Timestamp(\"2019-01-01 14:30:00\"),\n        ],\n    }\n    df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n\n    grouped = df.groupby(\"id\")\n    result = getattr(grouped, op)()\n    expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    assert_frame_equal(result, expected)",
                "test_error": "AssertionError: Attributes are different  Attribute \"dtype\" are different [left]:  datetime64[ns] [right]: datetime64[ns, tzutc()]",
                "full_test_error": "tz_naive_fixture = tzutc(), op = 'shift'\nexpected =                        time\n0                       NaT\n1                       NaT\n2 2019-01-01 12:00:00+00:00\n3 2019-01-01 12:30:00+00:00\n4                       NaT\n5                       NaT\n\n    @pytest.mark.parametrize(\n        \"op, expected\",\n        [\n            (\n                \"shift\",\n                {\n                    \"time\": [\n                        None,\n                        None,\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        None,\n                        None,\n                    ]\n                },\n            ),\n            (\n                \"bfill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n            (\n                \"ffill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n        ],\n    )\n    def test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n        # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n        tz = tz_naive_fixture\n        data = {\n            \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n            \"time\": [\n                Timestamp(\"2019-01-01 12:00:00\"),\n                Timestamp(\"2019-01-01 12:30:00\"),\n                None,\n                None,\n                Timestamp(\"2019-01-01 14:00:00\"),\n                Timestamp(\"2019-01-01 14:30:00\"),\n            ],\n        }\n        df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    \n        grouped = df.groupby(\"id\")\n        result = getattr(grouped, op)()\n        expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n>       assert_frame_equal(result, expected)\nE       AssertionError: Attributes are different\nE       \nE       Attribute \"dtype\" are different\nE       [left]:  datetime64[ns]\nE       [right]: datetime64[ns, tzutc()]\n\npandas/tests/groupby/test_groupby.py:1950: AssertionError",
                "traceback": null,
                "test_error_location": null,
                "test_function_decorators": [
                    "pytest.mark.parametrize('op, expected', [('shift', {'time': [None, None, Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), None, None]}), ('bfill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]}), ('ffill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]})])"
                ]
            },
            {
                "test_path": "/Volumes/JerrySSD/bgp_envs/repos/pandas_154/pandas/tests/groupby/test_groupby.py",
                "test_function": "test_shift_bfill_ffill_tz",
                "test_function_code": "@pytest.mark.parametrize(\n    \"op, expected\",\n    [\n        (\n            \"shift\",\n            {\n                \"time\": [\n                    None,\n                    None,\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    None,\n                    None,\n                ]\n            },\n        ),\n        (\n            \"bfill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n        (\n            \"ffill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n    ],\n)\ndef test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n    # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n    tz = tz_naive_fixture\n    data = {\n        \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n        \"time\": [\n            Timestamp(\"2019-01-01 12:00:00\"),\n            Timestamp(\"2019-01-01 12:30:00\"),\n            None,\n            None,\n            Timestamp(\"2019-01-01 14:00:00\"),\n            Timestamp(\"2019-01-01 14:30:00\"),\n        ],\n    }\n    df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n\n    grouped = df.groupby(\"id\")\n    result = getattr(grouped, op)()\n    expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    assert_frame_equal(result, expected)",
                "test_error": "AssertionError: Attributes are different  Attribute \"dtype\" are different [left]:  datetime64[ns] [right]: datetime64[ns, tzutc()]",
                "full_test_error": "tz_naive_fixture = tzutc(), op = 'bfill'\nexpected =                        time\n0 2019-01-01 12:00:00+00:00\n1 2019-01-01 12:30:00+00:00\n2 2019-01-01 14:00:00+00:00\n3 2019-01-01 14:30:00+00:00\n4 2019-01-01 14:00:00+00:00\n5 2019-01-01 14:30:00+00:00\n\n    @pytest.mark.parametrize(\n        \"op, expected\",\n        [\n            (\n                \"shift\",\n                {\n                    \"time\": [\n                        None,\n                        None,\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        None,\n                        None,\n                    ]\n                },\n            ),\n            (\n                \"bfill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n            (\n                \"ffill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n        ],\n    )\n    def test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n        # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n        tz = tz_naive_fixture\n        data = {\n            \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n            \"time\": [\n                Timestamp(\"2019-01-01 12:00:00\"),\n                Timestamp(\"2019-01-01 12:30:00\"),\n                None,\n                None,\n                Timestamp(\"2019-01-01 14:00:00\"),\n                Timestamp(\"2019-01-01 14:30:00\"),\n            ],\n        }\n        df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    \n        grouped = df.groupby(\"id\")\n        result = getattr(grouped, op)()\n        expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n>       assert_frame_equal(result, expected)\nE       AssertionError: Attributes are different\nE       \nE       Attribute \"dtype\" are different\nE       [left]:  datetime64[ns]\nE       [right]: datetime64[ns, tzutc()]\n\npandas/tests/groupby/test_groupby.py:1950: AssertionError",
                "traceback": null,
                "test_error_location": null,
                "test_function_decorators": [
                    "pytest.mark.parametrize('op, expected', [('shift', {'time': [None, None, Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), None, None]}), ('bfill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]}), ('ffill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]})])"
                ]
            },
            {
                "test_path": "/Volumes/JerrySSD/bgp_envs/repos/pandas_154/pandas/tests/groupby/test_groupby.py",
                "test_function": "test_shift_bfill_ffill_tz",
                "test_function_code": "@pytest.mark.parametrize(\n    \"op, expected\",\n    [\n        (\n            \"shift\",\n            {\n                \"time\": [\n                    None,\n                    None,\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    None,\n                    None,\n                ]\n            },\n        ),\n        (\n            \"bfill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n        (\n            \"ffill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n    ],\n)\ndef test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n    # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n    tz = tz_naive_fixture\n    data = {\n        \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n        \"time\": [\n            Timestamp(\"2019-01-01 12:00:00\"),\n            Timestamp(\"2019-01-01 12:30:00\"),\n            None,\n            None,\n            Timestamp(\"2019-01-01 14:00:00\"),\n            Timestamp(\"2019-01-01 14:30:00\"),\n        ],\n    }\n    df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n\n    grouped = df.groupby(\"id\")\n    result = getattr(grouped, op)()\n    expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    assert_frame_equal(result, expected)",
                "test_error": "AssertionError: Attributes are different  Attribute \"dtype\" are different [left]:  datetime64[ns] [right]: datetime64[ns, tzutc()]",
                "full_test_error": "tz_naive_fixture = tzutc(), op = 'ffill'\nexpected =                        time\n0 2019-01-01 12:00:00+00:00\n1 2019-01-01 12:30:00+00:00\n2 2019-01-01 12:00:00+00:00\n3 2019-01-01 12:30:00+00:00\n4 2019-01-01 14:00:00+00:00\n5 2019-01-01 14:30:00+00:00\n\n    @pytest.mark.parametrize(\n        \"op, expected\",\n        [\n            (\n                \"shift\",\n                {\n                    \"time\": [\n                        None,\n                        None,\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        None,\n                        None,\n                    ]\n                },\n            ),\n            (\n                \"bfill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n            (\n                \"ffill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n        ],\n    )\n    def test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n        # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n        tz = tz_naive_fixture\n        data = {\n            \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n            \"time\": [\n                Timestamp(\"2019-01-01 12:00:00\"),\n                Timestamp(\"2019-01-01 12:30:00\"),\n                None,\n                None,\n                Timestamp(\"2019-01-01 14:00:00\"),\n                Timestamp(\"2019-01-01 14:30:00\"),\n            ],\n        }\n        df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    \n        grouped = df.groupby(\"id\")\n        result = getattr(grouped, op)()\n        expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n>       assert_frame_equal(result, expected)\nE       AssertionError: Attributes are different\nE       \nE       Attribute \"dtype\" are different\nE       [left]:  datetime64[ns]\nE       [right]: datetime64[ns, tzutc()]\n\npandas/tests/groupby/test_groupby.py:1950: AssertionError",
                "traceback": null,
                "test_error_location": null,
                "test_function_decorators": [
                    "pytest.mark.parametrize('op, expected', [('shift', {'time': [None, None, Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), None, None]}), ('bfill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]}), ('ffill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]})])"
                ]
            },
            {
                "test_path": "/Volumes/JerrySSD/bgp_envs/repos/pandas_154/pandas/tests/groupby/test_groupby.py",
                "test_function": "test_shift_bfill_ffill_tz",
                "test_function_code": "@pytest.mark.parametrize(\n    \"op, expected\",\n    [\n        (\n            \"shift\",\n            {\n                \"time\": [\n                    None,\n                    None,\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    None,\n                    None,\n                ]\n            },\n        ),\n        (\n            \"bfill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n        (\n            \"ffill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n    ],\n)\ndef test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n    # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n    tz = tz_naive_fixture\n    data = {\n        \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n        \"time\": [\n            Timestamp(\"2019-01-01 12:00:00\"),\n            Timestamp(\"2019-01-01 12:30:00\"),\n            None,\n            None,\n            Timestamp(\"2019-01-01 14:00:00\"),\n            Timestamp(\"2019-01-01 14:30:00\"),\n        ],\n    }\n    df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n\n    grouped = df.groupby(\"id\")\n    result = getattr(grouped, op)()\n    expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    assert_frame_equal(result, expected)",
                "test_error": "AssertionError: Attributes are different  Attribute \"dtype\" are different [left]:  datetime64[ns] [right]: datetime64[ns, tzlocal()]",
                "full_test_error": "tz_naive_fixture = tzlocal(), op = 'shift'\nexpected =                        time\n0                       NaT\n1                       NaT\n2 2019-01-01 12:00:00+00:00\n3 2019-01-01 12:30:00+00:00\n4                       NaT\n5                       NaT\n\n    @pytest.mark.parametrize(\n        \"op, expected\",\n        [\n            (\n                \"shift\",\n                {\n                    \"time\": [\n                        None,\n                        None,\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        None,\n                        None,\n                    ]\n                },\n            ),\n            (\n                \"bfill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n            (\n                \"ffill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n        ],\n    )\n    def test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n        # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n        tz = tz_naive_fixture\n        data = {\n            \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n            \"time\": [\n                Timestamp(\"2019-01-01 12:00:00\"),\n                Timestamp(\"2019-01-01 12:30:00\"),\n                None,\n                None,\n                Timestamp(\"2019-01-01 14:00:00\"),\n                Timestamp(\"2019-01-01 14:30:00\"),\n            ],\n        }\n        df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    \n        grouped = df.groupby(\"id\")\n        result = getattr(grouped, op)()\n        expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n>       assert_frame_equal(result, expected)\nE       AssertionError: Attributes are different\nE       \nE       Attribute \"dtype\" are different\nE       [left]:  datetime64[ns]\nE       [right]: datetime64[ns, tzlocal()]\n\npandas/tests/groupby/test_groupby.py:1950: AssertionError",
                "traceback": null,
                "test_error_location": null,
                "test_function_decorators": [
                    "pytest.mark.parametrize('op, expected', [('shift', {'time': [None, None, Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), None, None]}), ('bfill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]}), ('ffill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]})])"
                ]
            },
            {
                "test_path": "/Volumes/JerrySSD/bgp_envs/repos/pandas_154/pandas/tests/groupby/test_groupby.py",
                "test_function": "test_shift_bfill_ffill_tz",
                "test_function_code": "@pytest.mark.parametrize(\n    \"op, expected\",\n    [\n        (\n            \"shift\",\n            {\n                \"time\": [\n                    None,\n                    None,\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    None,\n                    None,\n                ]\n            },\n        ),\n        (\n            \"bfill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n        (\n            \"ffill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n    ],\n)\ndef test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n    # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n    tz = tz_naive_fixture\n    data = {\n        \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n        \"time\": [\n            Timestamp(\"2019-01-01 12:00:00\"),\n            Timestamp(\"2019-01-01 12:30:00\"),\n            None,\n            None,\n            Timestamp(\"2019-01-01 14:00:00\"),\n            Timestamp(\"2019-01-01 14:30:00\"),\n        ],\n    }\n    df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n\n    grouped = df.groupby(\"id\")\n    result = getattr(grouped, op)()\n    expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    assert_frame_equal(result, expected)",
                "test_error": "AssertionError: Attributes are different  Attribute \"dtype\" are different [left]:  datetime64[ns] [right]: datetime64[ns, tzlocal()]",
                "full_test_error": "tz_naive_fixture = tzlocal(), op = 'bfill'\nexpected =                        time\n0 2019-01-01 12:00:00+00:00\n1 2019-01-01 12:30:00+00:00\n2 2019-01-01 14:00:00+00:00\n3 2019-01-01 14:30:00+00:00\n4 2019-01-01 14:00:00+00:00\n5 2019-01-01 14:30:00+00:00\n\n    @pytest.mark.parametrize(\n        \"op, expected\",\n        [\n            (\n                \"shift\",\n                {\n                    \"time\": [\n                        None,\n                        None,\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        None,\n                        None,\n                    ]\n                },\n            ),\n            (\n                \"bfill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n            (\n                \"ffill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n        ],\n    )\n    def test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n        # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n        tz = tz_naive_fixture\n        data = {\n            \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n            \"time\": [\n                Timestamp(\"2019-01-01 12:00:00\"),\n                Timestamp(\"2019-01-01 12:30:00\"),\n                None,\n                None,\n                Timestamp(\"2019-01-01 14:00:00\"),\n                Timestamp(\"2019-01-01 14:30:00\"),\n            ],\n        }\n        df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    \n        grouped = df.groupby(\"id\")\n        result = getattr(grouped, op)()\n        expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n>       assert_frame_equal(result, expected)\nE       AssertionError: Attributes are different\nE       \nE       Attribute \"dtype\" are different\nE       [left]:  datetime64[ns]\nE       [right]: datetime64[ns, tzlocal()]\n\npandas/tests/groupby/test_groupby.py:1950: AssertionError",
                "traceback": null,
                "test_error_location": null,
                "test_function_decorators": [
                    "pytest.mark.parametrize('op, expected', [('shift', {'time': [None, None, Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), None, None]}), ('bfill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]}), ('ffill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]})])"
                ]
            },
            {
                "test_path": "/Volumes/JerrySSD/bgp_envs/repos/pandas_154/pandas/tests/groupby/test_groupby.py",
                "test_function": "test_shift_bfill_ffill_tz",
                "test_function_code": "@pytest.mark.parametrize(\n    \"op, expected\",\n    [\n        (\n            \"shift\",\n            {\n                \"time\": [\n                    None,\n                    None,\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    None,\n                    None,\n                ]\n            },\n        ),\n        (\n            \"bfill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n        (\n            \"ffill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n    ],\n)\ndef test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n    # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n    tz = tz_naive_fixture\n    data = {\n        \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n        \"time\": [\n            Timestamp(\"2019-01-01 12:00:00\"),\n            Timestamp(\"2019-01-01 12:30:00\"),\n            None,\n            None,\n            Timestamp(\"2019-01-01 14:00:00\"),\n            Timestamp(\"2019-01-01 14:30:00\"),\n        ],\n    }\n    df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n\n    grouped = df.groupby(\"id\")\n    result = getattr(grouped, op)()\n    expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    assert_frame_equal(result, expected)",
                "test_error": "AssertionError: Attributes are different  Attribute \"dtype\" are different [left]:  datetime64[ns] [right]: datetime64[ns, tzlocal()]",
                "full_test_error": "tz_naive_fixture = tzlocal(), op = 'ffill'\nexpected =                        time\n0 2019-01-01 12:00:00+00:00\n1 2019-01-01 12:30:00+00:00\n2 2019-01-01 12:00:00+00:00\n3 2019-01-01 12:30:00+00:00\n4 2019-01-01 14:00:00+00:00\n5 2019-01-01 14:30:00+00:00\n\n    @pytest.mark.parametrize(\n        \"op, expected\",\n        [\n            (\n                \"shift\",\n                {\n                    \"time\": [\n                        None,\n                        None,\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        None,\n                        None,\n                    ]\n                },\n            ),\n            (\n                \"bfill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n            (\n                \"ffill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n        ],\n    )\n    def test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n        # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n        tz = tz_naive_fixture\n        data = {\n            \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n            \"time\": [\n                Timestamp(\"2019-01-01 12:00:00\"),\n                Timestamp(\"2019-01-01 12:30:00\"),\n                None,\n                None,\n                Timestamp(\"2019-01-01 14:00:00\"),\n                Timestamp(\"2019-01-01 14:30:00\"),\n            ],\n        }\n        df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    \n        grouped = df.groupby(\"id\")\n        result = getattr(grouped, op)()\n        expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n>       assert_frame_equal(result, expected)\nE       AssertionError: Attributes are different\nE       \nE       Attribute \"dtype\" are different\nE       [left]:  datetime64[ns]\nE       [right]: datetime64[ns, tzlocal()]\n\npandas/tests/groupby/test_groupby.py:1950: AssertionError",
                "traceback": null,
                "test_error_location": null,
                "test_function_decorators": [
                    "pytest.mark.parametrize('op, expected', [('shift', {'time': [None, None, Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), None, None]}), ('bfill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]}), ('ffill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]})])"
                ]
            },
            {
                "test_path": "/Volumes/JerrySSD/bgp_envs/repos/pandas_154/pandas/tests/groupby/test_groupby.py",
                "test_function": "test_shift_bfill_ffill_tz",
                "test_function_code": "@pytest.mark.parametrize(\n    \"op, expected\",\n    [\n        (\n            \"shift\",\n            {\n                \"time\": [\n                    None,\n                    None,\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    None,\n                    None,\n                ]\n            },\n        ),\n        (\n            \"bfill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n        (\n            \"ffill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n    ],\n)\ndef test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n    # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n    tz = tz_naive_fixture\n    data = {\n        \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n        \"time\": [\n            Timestamp(\"2019-01-01 12:00:00\"),\n            Timestamp(\"2019-01-01 12:30:00\"),\n            None,\n            None,\n            Timestamp(\"2019-01-01 14:00:00\"),\n            Timestamp(\"2019-01-01 14:30:00\"),\n        ],\n    }\n    df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n\n    grouped = df.groupby(\"id\")\n    result = getattr(grouped, op)()\n    expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    assert_frame_equal(result, expected)",
                "test_error": "AssertionError: Attributes are different  Attribute \"dtype\" are different [left]:  datetime64[ns] [right]: datetime64[ns, pytz.FixedOffset(300)]",
                "full_test_error": "tz_naive_fixture = pytz.FixedOffset(300), op = 'shift'\nexpected =                        time\n0                       NaT\n1                       NaT\n2 2019-01-01 12:00:00+05:00\n3 2019-01-01 12:30:00+05:00\n4                       NaT\n5                       NaT\n\n    @pytest.mark.parametrize(\n        \"op, expected\",\n        [\n            (\n                \"shift\",\n                {\n                    \"time\": [\n                        None,\n                        None,\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        None,\n                        None,\n                    ]\n                },\n            ),\n            (\n                \"bfill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n            (\n                \"ffill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n        ],\n    )\n    def test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n        # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n        tz = tz_naive_fixture\n        data = {\n            \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n            \"time\": [\n                Timestamp(\"2019-01-01 12:00:00\"),\n                Timestamp(\"2019-01-01 12:30:00\"),\n                None,\n                None,\n                Timestamp(\"2019-01-01 14:00:00\"),\n                Timestamp(\"2019-01-01 14:30:00\"),\n            ],\n        }\n        df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    \n        grouped = df.groupby(\"id\")\n        result = getattr(grouped, op)()\n        expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n>       assert_frame_equal(result, expected)\nE       AssertionError: Attributes are different\nE       \nE       Attribute \"dtype\" are different\nE       [left]:  datetime64[ns]\nE       [right]: datetime64[ns, pytz.FixedOffset(300)]\n\npandas/tests/groupby/test_groupby.py:1950: AssertionError",
                "traceback": null,
                "test_error_location": null,
                "test_function_decorators": [
                    "pytest.mark.parametrize('op, expected', [('shift', {'time': [None, None, Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), None, None]}), ('bfill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]}), ('ffill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]})])"
                ]
            },
            {
                "test_path": "/Volumes/JerrySSD/bgp_envs/repos/pandas_154/pandas/tests/groupby/test_groupby.py",
                "test_function": "test_shift_bfill_ffill_tz",
                "test_function_code": "@pytest.mark.parametrize(\n    \"op, expected\",\n    [\n        (\n            \"shift\",\n            {\n                \"time\": [\n                    None,\n                    None,\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    None,\n                    None,\n                ]\n            },\n        ),\n        (\n            \"bfill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n        (\n            \"ffill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n    ],\n)\ndef test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n    # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n    tz = tz_naive_fixture\n    data = {\n        \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n        \"time\": [\n            Timestamp(\"2019-01-01 12:00:00\"),\n            Timestamp(\"2019-01-01 12:30:00\"),\n            None,\n            None,\n            Timestamp(\"2019-01-01 14:00:00\"),\n            Timestamp(\"2019-01-01 14:30:00\"),\n        ],\n    }\n    df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n\n    grouped = df.groupby(\"id\")\n    result = getattr(grouped, op)()\n    expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    assert_frame_equal(result, expected)",
                "test_error": "AssertionError: Attributes are different  Attribute \"dtype\" are different [left]:  datetime64[ns] [right]: datetime64[ns, pytz.FixedOffset(300)]",
                "full_test_error": "tz_naive_fixture = pytz.FixedOffset(300), op = 'bfill'\nexpected =                        time\n0 2019-01-01 12:00:00+05:00\n1 2019-01-01 12:30:00+05:00\n2 2019-01-01 14:00:00+05:00\n3 2019-01-01 14:30:00+05:00\n4 2019-01-01 14:00:00+05:00\n5 2019-01-01 14:30:00+05:00\n\n    @pytest.mark.parametrize(\n        \"op, expected\",\n        [\n            (\n                \"shift\",\n                {\n                    \"time\": [\n                        None,\n                        None,\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        None,\n                        None,\n                    ]\n                },\n            ),\n            (\n                \"bfill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n            (\n                \"ffill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n        ],\n    )\n    def test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n        # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n        tz = tz_naive_fixture\n        data = {\n            \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n            \"time\": [\n                Timestamp(\"2019-01-01 12:00:00\"),\n                Timestamp(\"2019-01-01 12:30:00\"),\n                None,\n                None,\n                Timestamp(\"2019-01-01 14:00:00\"),\n                Timestamp(\"2019-01-01 14:30:00\"),\n            ],\n        }\n        df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    \n        grouped = df.groupby(\"id\")\n        result = getattr(grouped, op)()\n        expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n>       assert_frame_equal(result, expected)\nE       AssertionError: Attributes are different\nE       \nE       Attribute \"dtype\" are different\nE       [left]:  datetime64[ns]\nE       [right]: datetime64[ns, pytz.FixedOffset(300)]\n\npandas/tests/groupby/test_groupby.py:1950: AssertionError",
                "traceback": null,
                "test_error_location": null,
                "test_function_decorators": [
                    "pytest.mark.parametrize('op, expected', [('shift', {'time': [None, None, Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), None, None]}), ('bfill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]}), ('ffill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]})])"
                ]
            },
            {
                "test_path": "/Volumes/JerrySSD/bgp_envs/repos/pandas_154/pandas/tests/groupby/test_groupby.py",
                "test_function": "test_shift_bfill_ffill_tz",
                "test_function_code": "@pytest.mark.parametrize(\n    \"op, expected\",\n    [\n        (\n            \"shift\",\n            {\n                \"time\": [\n                    None,\n                    None,\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    None,\n                    None,\n                ]\n            },\n        ),\n        (\n            \"bfill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n        (\n            \"ffill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n    ],\n)\ndef test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n    # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n    tz = tz_naive_fixture\n    data = {\n        \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n        \"time\": [\n            Timestamp(\"2019-01-01 12:00:00\"),\n            Timestamp(\"2019-01-01 12:30:00\"),\n            None,\n            None,\n            Timestamp(\"2019-01-01 14:00:00\"),\n            Timestamp(\"2019-01-01 14:30:00\"),\n        ],\n    }\n    df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n\n    grouped = df.groupby(\"id\")\n    result = getattr(grouped, op)()\n    expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    assert_frame_equal(result, expected)",
                "test_error": "AssertionError: Attributes are different  Attribute \"dtype\" are different [left]:  datetime64[ns] [right]: datetime64[ns, pytz.FixedOffset(300)]",
                "full_test_error": "tz_naive_fixture = pytz.FixedOffset(300), op = 'ffill'\nexpected =                        time\n0 2019-01-01 12:00:00+05:00\n1 2019-01-01 12:30:00+05:00\n2 2019-01-01 12:00:00+05:00\n3 2019-01-01 12:30:00+05:00\n4 2019-01-01 14:00:00+05:00\n5 2019-01-01 14:30:00+05:00\n\n    @pytest.mark.parametrize(\n        \"op, expected\",\n        [\n            (\n                \"shift\",\n                {\n                    \"time\": [\n                        None,\n                        None,\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        None,\n                        None,\n                    ]\n                },\n            ),\n            (\n                \"bfill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n            (\n                \"ffill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n        ],\n    )\n    def test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n        # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n        tz = tz_naive_fixture\n        data = {\n            \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n            \"time\": [\n                Timestamp(\"2019-01-01 12:00:00\"),\n                Timestamp(\"2019-01-01 12:30:00\"),\n                None,\n                None,\n                Timestamp(\"2019-01-01 14:00:00\"),\n                Timestamp(\"2019-01-01 14:30:00\"),\n            ],\n        }\n        df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    \n        grouped = df.groupby(\"id\")\n        result = getattr(grouped, op)()\n        expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n>       assert_frame_equal(result, expected)\nE       AssertionError: Attributes are different\nE       \nE       Attribute \"dtype\" are different\nE       [left]:  datetime64[ns]\nE       [right]: datetime64[ns, pytz.FixedOffset(300)]\n\npandas/tests/groupby/test_groupby.py:1950: AssertionError",
                "traceback": null,
                "test_error_location": null,
                "test_function_decorators": [
                    "pytest.mark.parametrize('op, expected', [('shift', {'time': [None, None, Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), None, None]}), ('bfill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]}), ('ffill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]})])"
                ]
            },
            {
                "test_path": "/Volumes/JerrySSD/bgp_envs/repos/pandas_154/pandas/tests/groupby/test_groupby.py",
                "test_function": "test_shift_bfill_ffill_tz",
                "test_function_code": "@pytest.mark.parametrize(\n    \"op, expected\",\n    [\n        (\n            \"shift\",\n            {\n                \"time\": [\n                    None,\n                    None,\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    None,\n                    None,\n                ]\n            },\n        ),\n        (\n            \"bfill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n        (\n            \"ffill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n    ],\n)\ndef test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n    # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n    tz = tz_naive_fixture\n    data = {\n        \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n        \"time\": [\n            Timestamp(\"2019-01-01 12:00:00\"),\n            Timestamp(\"2019-01-01 12:30:00\"),\n            None,\n            None,\n            Timestamp(\"2019-01-01 14:00:00\"),\n            Timestamp(\"2019-01-01 14:30:00\"),\n        ],\n    }\n    df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n\n    grouped = df.groupby(\"id\")\n    result = getattr(grouped, op)()\n    expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    assert_frame_equal(result, expected)",
                "test_error": "AssertionError: Attributes are different  Attribute \"dtype\" are different [left]:  datetime64[ns] [right]: datetime64[ns, UTC]",
                "full_test_error": "tz_naive_fixture = <UTC>, op = 'shift'\nexpected =                        time\n0                       NaT\n1                       NaT\n2 2019-01-01 12:00:00+00:00\n3 2019-01-01 12:30:00+00:00\n4                       NaT\n5                       NaT\n\n    @pytest.mark.parametrize(\n        \"op, expected\",\n        [\n            (\n                \"shift\",\n                {\n                    \"time\": [\n                        None,\n                        None,\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        None,\n                        None,\n                    ]\n                },\n            ),\n            (\n                \"bfill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n            (\n                \"ffill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n        ],\n    )\n    def test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n        # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n        tz = tz_naive_fixture\n        data = {\n            \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n            \"time\": [\n                Timestamp(\"2019-01-01 12:00:00\"),\n                Timestamp(\"2019-01-01 12:30:00\"),\n                None,\n                None,\n                Timestamp(\"2019-01-01 14:00:00\"),\n                Timestamp(\"2019-01-01 14:30:00\"),\n            ],\n        }\n        df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    \n        grouped = df.groupby(\"id\")\n        result = getattr(grouped, op)()\n        expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n>       assert_frame_equal(result, expected)\nE       AssertionError: Attributes are different\nE       \nE       Attribute \"dtype\" are different\nE       [left]:  datetime64[ns]\nE       [right]: datetime64[ns, UTC]\n\npandas/tests/groupby/test_groupby.py:1950: AssertionError",
                "traceback": null,
                "test_error_location": null,
                "test_function_decorators": [
                    "pytest.mark.parametrize('op, expected', [('shift', {'time': [None, None, Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), None, None]}), ('bfill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]}), ('ffill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]})])"
                ]
            },
            {
                "test_path": "/Volumes/JerrySSD/bgp_envs/repos/pandas_154/pandas/tests/groupby/test_groupby.py",
                "test_function": "test_shift_bfill_ffill_tz",
                "test_function_code": "@pytest.mark.parametrize(\n    \"op, expected\",\n    [\n        (\n            \"shift\",\n            {\n                \"time\": [\n                    None,\n                    None,\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    None,\n                    None,\n                ]\n            },\n        ),\n        (\n            \"bfill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n        (\n            \"ffill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n    ],\n)\ndef test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n    # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n    tz = tz_naive_fixture\n    data = {\n        \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n        \"time\": [\n            Timestamp(\"2019-01-01 12:00:00\"),\n            Timestamp(\"2019-01-01 12:30:00\"),\n            None,\n            None,\n            Timestamp(\"2019-01-01 14:00:00\"),\n            Timestamp(\"2019-01-01 14:30:00\"),\n        ],\n    }\n    df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n\n    grouped = df.groupby(\"id\")\n    result = getattr(grouped, op)()\n    expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    assert_frame_equal(result, expected)",
                "test_error": "AssertionError: Attributes are different  Attribute \"dtype\" are different [left]:  datetime64[ns] [right]: datetime64[ns, UTC]",
                "full_test_error": "tz_naive_fixture = <UTC>, op = 'bfill'\nexpected =                        time\n0 2019-01-01 12:00:00+00:00\n1 2019-01-01 12:30:00+00:00\n2 2019-01-01 14:00:00+00:00\n3 2019-01-01 14:30:00+00:00\n4 2019-01-01 14:00:00+00:00\n5 2019-01-01 14:30:00+00:00\n\n    @pytest.mark.parametrize(\n        \"op, expected\",\n        [\n            (\n                \"shift\",\n                {\n                    \"time\": [\n                        None,\n                        None,\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        None,\n                        None,\n                    ]\n                },\n            ),\n            (\n                \"bfill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n            (\n                \"ffill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n        ],\n    )\n    def test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n        # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n        tz = tz_naive_fixture\n        data = {\n            \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n            \"time\": [\n                Timestamp(\"2019-01-01 12:00:00\"),\n                Timestamp(\"2019-01-01 12:30:00\"),\n                None,\n                None,\n                Timestamp(\"2019-01-01 14:00:00\"),\n                Timestamp(\"2019-01-01 14:30:00\"),\n            ],\n        }\n        df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    \n        grouped = df.groupby(\"id\")\n        result = getattr(grouped, op)()\n        expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n>       assert_frame_equal(result, expected)\nE       AssertionError: Attributes are different\nE       \nE       Attribute \"dtype\" are different\nE       [left]:  datetime64[ns]\nE       [right]: datetime64[ns, UTC]\n\npandas/tests/groupby/test_groupby.py:1950: AssertionError",
                "traceback": null,
                "test_error_location": null,
                "test_function_decorators": [
                    "pytest.mark.parametrize('op, expected', [('shift', {'time': [None, None, Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), None, None]}), ('bfill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]}), ('ffill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]})])"
                ]
            },
            {
                "test_path": "/Volumes/JerrySSD/bgp_envs/repos/pandas_154/pandas/tests/groupby/test_groupby.py",
                "test_function": "test_shift_bfill_ffill_tz",
                "test_function_code": "@pytest.mark.parametrize(\n    \"op, expected\",\n    [\n        (\n            \"shift\",\n            {\n                \"time\": [\n                    None,\n                    None,\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    None,\n                    None,\n                ]\n            },\n        ),\n        (\n            \"bfill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n        (\n            \"ffill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n    ],\n)\ndef test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n    # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n    tz = tz_naive_fixture\n    data = {\n        \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n        \"time\": [\n            Timestamp(\"2019-01-01 12:00:00\"),\n            Timestamp(\"2019-01-01 12:30:00\"),\n            None,\n            None,\n            Timestamp(\"2019-01-01 14:00:00\"),\n            Timestamp(\"2019-01-01 14:30:00\"),\n        ],\n    }\n    df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n\n    grouped = df.groupby(\"id\")\n    result = getattr(grouped, op)()\n    expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    assert_frame_equal(result, expected)",
                "test_error": "AssertionError: Attributes are different  Attribute \"dtype\" are different [left]:  datetime64[ns] [right]: datetime64[ns, UTC]",
                "full_test_error": "tz_naive_fixture = <UTC>, op = 'ffill'\nexpected =                        time\n0 2019-01-01 12:00:00+00:00\n1 2019-01-01 12:30:00+00:00\n2 2019-01-01 12:00:00+00:00\n3 2019-01-01 12:30:00+00:00\n4 2019-01-01 14:00:00+00:00\n5 2019-01-01 14:30:00+00:00\n\n    @pytest.mark.parametrize(\n        \"op, expected\",\n        [\n            (\n                \"shift\",\n                {\n                    \"time\": [\n                        None,\n                        None,\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        None,\n                        None,\n                    ]\n                },\n            ),\n            (\n                \"bfill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n            (\n                \"ffill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n        ],\n    )\n    def test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n        # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n        tz = tz_naive_fixture\n        data = {\n            \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n            \"time\": [\n                Timestamp(\"2019-01-01 12:00:00\"),\n                Timestamp(\"2019-01-01 12:30:00\"),\n                None,\n                None,\n                Timestamp(\"2019-01-01 14:00:00\"),\n                Timestamp(\"2019-01-01 14:30:00\"),\n            ],\n        }\n        df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    \n        grouped = df.groupby(\"id\")\n        result = getattr(grouped, op)()\n        expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n>       assert_frame_equal(result, expected)\nE       AssertionError: Attributes are different\nE       \nE       Attribute \"dtype\" are different\nE       [left]:  datetime64[ns]\nE       [right]: datetime64[ns, UTC]\n\npandas/tests/groupby/test_groupby.py:1950: AssertionError",
                "traceback": null,
                "test_error_location": null,
                "test_function_decorators": [
                    "pytest.mark.parametrize('op, expected', [('shift', {'time': [None, None, Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), None, None]}), ('bfill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]}), ('ffill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]})])"
                ]
            },
            {
                "test_path": "/Volumes/JerrySSD/bgp_envs/repos/pandas_154/pandas/tests/groupby/test_groupby.py",
                "test_function": "test_shift_bfill_ffill_tz",
                "test_function_code": "@pytest.mark.parametrize(\n    \"op, expected\",\n    [\n        (\n            \"shift\",\n            {\n                \"time\": [\n                    None,\n                    None,\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    None,\n                    None,\n                ]\n            },\n        ),\n        (\n            \"bfill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n        (\n            \"ffill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n    ],\n)\ndef test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n    # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n    tz = tz_naive_fixture\n    data = {\n        \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n        \"time\": [\n            Timestamp(\"2019-01-01 12:00:00\"),\n            Timestamp(\"2019-01-01 12:30:00\"),\n            None,\n            None,\n            Timestamp(\"2019-01-01 14:00:00\"),\n            Timestamp(\"2019-01-01 14:30:00\"),\n        ],\n    }\n    df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n\n    grouped = df.groupby(\"id\")\n    result = getattr(grouped, op)()\n    expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    assert_frame_equal(result, expected)",
                "test_error": "AssertionError: Attributes are different  Attribute \"dtype\" are different [left]:  datetime64[ns] [right]: datetime64[ns, pytz.FixedOffset(-300)]",
                "full_test_error": "tz_naive_fixture = pytz.FixedOffset(-300), op = 'shift'\nexpected =                        time\n0                       NaT\n1                       NaT\n2 2019-01-01 12:00:00-05:00\n3 2019-01-01 12:30:00-05:00\n4                       NaT\n5                       NaT\n\n    @pytest.mark.parametrize(\n        \"op, expected\",\n        [\n            (\n                \"shift\",\n                {\n                    \"time\": [\n                        None,\n                        None,\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        None,\n                        None,\n                    ]\n                },\n            ),\n            (\n                \"bfill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n            (\n                \"ffill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n        ],\n    )\n    def test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n        # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n        tz = tz_naive_fixture\n        data = {\n            \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n            \"time\": [\n                Timestamp(\"2019-01-01 12:00:00\"),\n                Timestamp(\"2019-01-01 12:30:00\"),\n                None,\n                None,\n                Timestamp(\"2019-01-01 14:00:00\"),\n                Timestamp(\"2019-01-01 14:30:00\"),\n            ],\n        }\n        df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    \n        grouped = df.groupby(\"id\")\n        result = getattr(grouped, op)()\n        expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n>       assert_frame_equal(result, expected)\nE       AssertionError: Attributes are different\nE       \nE       Attribute \"dtype\" are different\nE       [left]:  datetime64[ns]\nE       [right]: datetime64[ns, pytz.FixedOffset(-300)]\n\npandas/tests/groupby/test_groupby.py:1950: AssertionError",
                "traceback": null,
                "test_error_location": null,
                "test_function_decorators": [
                    "pytest.mark.parametrize('op, expected', [('shift', {'time': [None, None, Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), None, None]}), ('bfill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]}), ('ffill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]})])"
                ]
            },
            {
                "test_path": "/Volumes/JerrySSD/bgp_envs/repos/pandas_154/pandas/tests/groupby/test_groupby.py",
                "test_function": "test_shift_bfill_ffill_tz",
                "test_function_code": "@pytest.mark.parametrize(\n    \"op, expected\",\n    [\n        (\n            \"shift\",\n            {\n                \"time\": [\n                    None,\n                    None,\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    None,\n                    None,\n                ]\n            },\n        ),\n        (\n            \"bfill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n        (\n            \"ffill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n    ],\n)\ndef test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n    # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n    tz = tz_naive_fixture\n    data = {\n        \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n        \"time\": [\n            Timestamp(\"2019-01-01 12:00:00\"),\n            Timestamp(\"2019-01-01 12:30:00\"),\n            None,\n            None,\n            Timestamp(\"2019-01-01 14:00:00\"),\n            Timestamp(\"2019-01-01 14:30:00\"),\n        ],\n    }\n    df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n\n    grouped = df.groupby(\"id\")\n    result = getattr(grouped, op)()\n    expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    assert_frame_equal(result, expected)",
                "test_error": "AssertionError: Attributes are different  Attribute \"dtype\" are different [left]:  datetime64[ns] [right]: datetime64[ns, pytz.FixedOffset(-300)]",
                "full_test_error": "tz_naive_fixture = pytz.FixedOffset(-300), op = 'bfill'\nexpected =                        time\n0 2019-01-01 12:00:00-05:00\n1 2019-01-01 12:30:00-05:00\n2 2019-01-01 14:00:00-05:00\n3 2019-01-01 14:30:00-05:00\n4 2019-01-01 14:00:00-05:00\n5 2019-01-01 14:30:00-05:00\n\n    @pytest.mark.parametrize(\n        \"op, expected\",\n        [\n            (\n                \"shift\",\n                {\n                    \"time\": [\n                        None,\n                        None,\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        None,\n                        None,\n                    ]\n                },\n            ),\n            (\n                \"bfill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n            (\n                \"ffill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n        ],\n    )\n    def test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n        # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n        tz = tz_naive_fixture\n        data = {\n            \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n            \"time\": [\n                Timestamp(\"2019-01-01 12:00:00\"),\n                Timestamp(\"2019-01-01 12:30:00\"),\n                None,\n                None,\n                Timestamp(\"2019-01-01 14:00:00\"),\n                Timestamp(\"2019-01-01 14:30:00\"),\n            ],\n        }\n        df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    \n        grouped = df.groupby(\"id\")\n        result = getattr(grouped, op)()\n        expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n>       assert_frame_equal(result, expected)\nE       AssertionError: Attributes are different\nE       \nE       Attribute \"dtype\" are different\nE       [left]:  datetime64[ns]\nE       [right]: datetime64[ns, pytz.FixedOffset(-300)]\n\npandas/tests/groupby/test_groupby.py:1950: AssertionError",
                "traceback": null,
                "test_error_location": null,
                "test_function_decorators": [
                    "pytest.mark.parametrize('op, expected', [('shift', {'time': [None, None, Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), None, None]}), ('bfill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]}), ('ffill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]})])"
                ]
            },
            {
                "test_path": "/Volumes/JerrySSD/bgp_envs/repos/pandas_154/pandas/tests/groupby/test_groupby.py",
                "test_function": "test_shift_bfill_ffill_tz",
                "test_function_code": "@pytest.mark.parametrize(\n    \"op, expected\",\n    [\n        (\n            \"shift\",\n            {\n                \"time\": [\n                    None,\n                    None,\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    None,\n                    None,\n                ]\n            },\n        ),\n        (\n            \"bfill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n        (\n            \"ffill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n    ],\n)\ndef test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n    # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n    tz = tz_naive_fixture\n    data = {\n        \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n        \"time\": [\n            Timestamp(\"2019-01-01 12:00:00\"),\n            Timestamp(\"2019-01-01 12:30:00\"),\n            None,\n            None,\n            Timestamp(\"2019-01-01 14:00:00\"),\n            Timestamp(\"2019-01-01 14:30:00\"),\n        ],\n    }\n    df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n\n    grouped = df.groupby(\"id\")\n    result = getattr(grouped, op)()\n    expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    assert_frame_equal(result, expected)",
                "test_error": "AssertionError: Attributes are different  Attribute \"dtype\" are different [left]:  datetime64[ns] [right]: datetime64[ns, pytz.FixedOffset(-300)]",
                "full_test_error": "tz_naive_fixture = pytz.FixedOffset(-300), op = 'ffill'\nexpected =                        time\n0 2019-01-01 12:00:00-05:00\n1 2019-01-01 12:30:00-05:00\n2 2019-01-01 12:00:00-05:00\n3 2019-01-01 12:30:00-05:00\n4 2019-01-01 14:00:00-05:00\n5 2019-01-01 14:30:00-05:00\n\n    @pytest.mark.parametrize(\n        \"op, expected\",\n        [\n            (\n                \"shift\",\n                {\n                    \"time\": [\n                        None,\n                        None,\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        None,\n                        None,\n                    ]\n                },\n            ),\n            (\n                \"bfill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n            (\n                \"ffill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n        ],\n    )\n    def test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n        # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n        tz = tz_naive_fixture\n        data = {\n            \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n            \"time\": [\n                Timestamp(\"2019-01-01 12:00:00\"),\n                Timestamp(\"2019-01-01 12:30:00\"),\n                None,\n                None,\n                Timestamp(\"2019-01-01 14:00:00\"),\n                Timestamp(\"2019-01-01 14:30:00\"),\n            ],\n        }\n        df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    \n        grouped = df.groupby(\"id\")\n        result = getattr(grouped, op)()\n        expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n>       assert_frame_equal(result, expected)\nE       AssertionError: Attributes are different\nE       \nE       Attribute \"dtype\" are different\nE       [left]:  datetime64[ns]\nE       [right]: datetime64[ns, pytz.FixedOffset(-300)]\n\npandas/tests/groupby/test_groupby.py:1950: AssertionError",
                "traceback": null,
                "test_error_location": null,
                "test_function_decorators": [
                    "pytest.mark.parametrize('op, expected', [('shift', {'time': [None, None, Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), None, None]}), ('bfill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]}), ('ffill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]})])"
                ]
            },
            {
                "test_path": "/Volumes/JerrySSD/bgp_envs/repos/pandas_154/pandas/tests/groupby/test_groupby.py",
                "test_function": "test_shift_bfill_ffill_tz",
                "test_function_code": "@pytest.mark.parametrize(\n    \"op, expected\",\n    [\n        (\n            \"shift\",\n            {\n                \"time\": [\n                    None,\n                    None,\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    None,\n                    None,\n                ]\n            },\n        ),\n        (\n            \"bfill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n        (\n            \"ffill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n    ],\n)\ndef test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n    # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n    tz = tz_naive_fixture\n    data = {\n        \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n        \"time\": [\n            Timestamp(\"2019-01-01 12:00:00\"),\n            Timestamp(\"2019-01-01 12:30:00\"),\n            None,\n            None,\n            Timestamp(\"2019-01-01 14:00:00\"),\n            Timestamp(\"2019-01-01 14:30:00\"),\n        ],\n    }\n    df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n\n    grouped = df.groupby(\"id\")\n    result = getattr(grouped, op)()\n    expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    assert_frame_equal(result, expected)",
                "test_error": "AssertionError: Attributes are different  Attribute \"dtype\" are different [left]:  datetime64[ns] [right]: datetime64[ns, UTC]",
                "full_test_error": "tz_naive_fixture = datetime.timezone.utc, op = 'shift'\nexpected =                        time\n0                       NaT\n1                       NaT\n2 2019-01-01 12:00:00+00:00\n3 2019-01-01 12:30:00+00:00\n4                       NaT\n5                       NaT\n\n    @pytest.mark.parametrize(\n        \"op, expected\",\n        [\n            (\n                \"shift\",\n                {\n                    \"time\": [\n                        None,\n                        None,\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        None,\n                        None,\n                    ]\n                },\n            ),\n            (\n                \"bfill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n            (\n                \"ffill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n        ],\n    )\n    def test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n        # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n        tz = tz_naive_fixture\n        data = {\n            \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n            \"time\": [\n                Timestamp(\"2019-01-01 12:00:00\"),\n                Timestamp(\"2019-01-01 12:30:00\"),\n                None,\n                None,\n                Timestamp(\"2019-01-01 14:00:00\"),\n                Timestamp(\"2019-01-01 14:30:00\"),\n            ],\n        }\n        df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    \n        grouped = df.groupby(\"id\")\n        result = getattr(grouped, op)()\n        expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n>       assert_frame_equal(result, expected)\nE       AssertionError: Attributes are different\nE       \nE       Attribute \"dtype\" are different\nE       [left]:  datetime64[ns]\nE       [right]: datetime64[ns, UTC]\n\npandas/tests/groupby/test_groupby.py:1950: AssertionError",
                "traceback": null,
                "test_error_location": null,
                "test_function_decorators": [
                    "pytest.mark.parametrize('op, expected', [('shift', {'time': [None, None, Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), None, None]}), ('bfill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]}), ('ffill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]})])"
                ]
            },
            {
                "test_path": "/Volumes/JerrySSD/bgp_envs/repos/pandas_154/pandas/tests/groupby/test_groupby.py",
                "test_function": "test_shift_bfill_ffill_tz",
                "test_function_code": "@pytest.mark.parametrize(\n    \"op, expected\",\n    [\n        (\n            \"shift\",\n            {\n                \"time\": [\n                    None,\n                    None,\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    None,\n                    None,\n                ]\n            },\n        ),\n        (\n            \"bfill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n        (\n            \"ffill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n    ],\n)\ndef test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n    # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n    tz = tz_naive_fixture\n    data = {\n        \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n        \"time\": [\n            Timestamp(\"2019-01-01 12:00:00\"),\n            Timestamp(\"2019-01-01 12:30:00\"),\n            None,\n            None,\n            Timestamp(\"2019-01-01 14:00:00\"),\n            Timestamp(\"2019-01-01 14:30:00\"),\n        ],\n    }\n    df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n\n    grouped = df.groupby(\"id\")\n    result = getattr(grouped, op)()\n    expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    assert_frame_equal(result, expected)",
                "test_error": "AssertionError: Attributes are different  Attribute \"dtype\" are different [left]:  datetime64[ns] [right]: datetime64[ns, UTC]",
                "full_test_error": "tz_naive_fixture = datetime.timezone.utc, op = 'bfill'\nexpected =                        time\n0 2019-01-01 12:00:00+00:00\n1 2019-01-01 12:30:00+00:00\n2 2019-01-01 14:00:00+00:00\n3 2019-01-01 14:30:00+00:00\n4 2019-01-01 14:00:00+00:00\n5 2019-01-01 14:30:00+00:00\n\n    @pytest.mark.parametrize(\n        \"op, expected\",\n        [\n            (\n                \"shift\",\n                {\n                    \"time\": [\n                        None,\n                        None,\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        None,\n                        None,\n                    ]\n                },\n            ),\n            (\n                \"bfill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n            (\n                \"ffill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n        ],\n    )\n    def test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n        # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n        tz = tz_naive_fixture\n        data = {\n            \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n            \"time\": [\n                Timestamp(\"2019-01-01 12:00:00\"),\n                Timestamp(\"2019-01-01 12:30:00\"),\n                None,\n                None,\n                Timestamp(\"2019-01-01 14:00:00\"),\n                Timestamp(\"2019-01-01 14:30:00\"),\n            ],\n        }\n        df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    \n        grouped = df.groupby(\"id\")\n        result = getattr(grouped, op)()\n        expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n>       assert_frame_equal(result, expected)\nE       AssertionError: Attributes are different\nE       \nE       Attribute \"dtype\" are different\nE       [left]:  datetime64[ns]\nE       [right]: datetime64[ns, UTC]\n\npandas/tests/groupby/test_groupby.py:1950: AssertionError",
                "traceback": null,
                "test_error_location": null,
                "test_function_decorators": [
                    "pytest.mark.parametrize('op, expected', [('shift', {'time': [None, None, Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), None, None]}), ('bfill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]}), ('ffill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]})])"
                ]
            },
            {
                "test_path": "/Volumes/JerrySSD/bgp_envs/repos/pandas_154/pandas/tests/groupby/test_groupby.py",
                "test_function": "test_shift_bfill_ffill_tz",
                "test_function_code": "@pytest.mark.parametrize(\n    \"op, expected\",\n    [\n        (\n            \"shift\",\n            {\n                \"time\": [\n                    None,\n                    None,\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    None,\n                    None,\n                ]\n            },\n        ),\n        (\n            \"bfill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n        (\n            \"ffill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n    ],\n)\ndef test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n    # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n    tz = tz_naive_fixture\n    data = {\n        \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n        \"time\": [\n            Timestamp(\"2019-01-01 12:00:00\"),\n            Timestamp(\"2019-01-01 12:30:00\"),\n            None,\n            None,\n            Timestamp(\"2019-01-01 14:00:00\"),\n            Timestamp(\"2019-01-01 14:30:00\"),\n        ],\n    }\n    df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n\n    grouped = df.groupby(\"id\")\n    result = getattr(grouped, op)()\n    expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    assert_frame_equal(result, expected)",
                "test_error": "AssertionError: Attributes are different  Attribute \"dtype\" are different [left]:  datetime64[ns] [right]: datetime64[ns, UTC]",
                "full_test_error": "tz_naive_fixture = datetime.timezone.utc, op = 'ffill'\nexpected =                        time\n0 2019-01-01 12:00:00+00:00\n1 2019-01-01 12:30:00+00:00\n2 2019-01-01 12:00:00+00:00\n3 2019-01-01 12:30:00+00:00\n4 2019-01-01 14:00:00+00:00\n5 2019-01-01 14:30:00+00:00\n\n    @pytest.mark.parametrize(\n        \"op, expected\",\n        [\n            (\n                \"shift\",\n                {\n                    \"time\": [\n                        None,\n                        None,\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        None,\n                        None,\n                    ]\n                },\n            ),\n            (\n                \"bfill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n            (\n                \"ffill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n        ],\n    )\n    def test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n        # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n        tz = tz_naive_fixture\n        data = {\n            \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n            \"time\": [\n                Timestamp(\"2019-01-01 12:00:00\"),\n                Timestamp(\"2019-01-01 12:30:00\"),\n                None,\n                None,\n                Timestamp(\"2019-01-01 14:00:00\"),\n                Timestamp(\"2019-01-01 14:30:00\"),\n            ],\n        }\n        df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    \n        grouped = df.groupby(\"id\")\n        result = getattr(grouped, op)()\n        expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n>       assert_frame_equal(result, expected)\nE       AssertionError: Attributes are different\nE       \nE       Attribute \"dtype\" are different\nE       [left]:  datetime64[ns]\nE       [right]: datetime64[ns, UTC]\n\npandas/tests/groupby/test_groupby.py:1950: AssertionError",
                "traceback": null,
                "test_error_location": null,
                "test_function_decorators": [
                    "pytest.mark.parametrize('op, expected', [('shift', {'time': [None, None, Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), None, None]}), ('bfill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]}), ('ffill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]})])"
                ]
            },
            {
                "test_path": "/Volumes/JerrySSD/bgp_envs/repos/pandas_154/pandas/tests/groupby/test_groupby.py",
                "test_function": "test_shift_bfill_ffill_tz",
                "test_function_code": "@pytest.mark.parametrize(\n    \"op, expected\",\n    [\n        (\n            \"shift\",\n            {\n                \"time\": [\n                    None,\n                    None,\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    None,\n                    None,\n                ]\n            },\n        ),\n        (\n            \"bfill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n        (\n            \"ffill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n    ],\n)\ndef test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n    # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n    tz = tz_naive_fixture\n    data = {\n        \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n        \"time\": [\n            Timestamp(\"2019-01-01 12:00:00\"),\n            Timestamp(\"2019-01-01 12:30:00\"),\n            None,\n            None,\n            Timestamp(\"2019-01-01 14:00:00\"),\n            Timestamp(\"2019-01-01 14:30:00\"),\n        ],\n    }\n    df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n\n    grouped = df.groupby(\"id\")\n    result = getattr(grouped, op)()\n    expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    assert_frame_equal(result, expected)",
                "test_error": "AssertionError: Attributes are different  Attribute \"dtype\" are different [left]:  datetime64[ns] [right]: datetime64[ns, UTC+01:00]",
                "full_test_error": "tz_naive_fixture = datetime.timezone(datetime.timedelta(seconds=3600))\nop = 'shift'\nexpected =                        time\n0                       NaT\n1                       NaT\n2 2019-01-01 12:00:00+01:00\n3 2019-01-01 12:30:00+01:00\n4                       NaT\n5                       NaT\n\n    @pytest.mark.parametrize(\n        \"op, expected\",\n        [\n            (\n                \"shift\",\n                {\n                    \"time\": [\n                        None,\n                        None,\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        None,\n                        None,\n                    ]\n                },\n            ),\n            (\n                \"bfill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n            (\n                \"ffill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n        ],\n    )\n    def test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n        # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n        tz = tz_naive_fixture\n        data = {\n            \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n            \"time\": [\n                Timestamp(\"2019-01-01 12:00:00\"),\n                Timestamp(\"2019-01-01 12:30:00\"),\n                None,\n                None,\n                Timestamp(\"2019-01-01 14:00:00\"),\n                Timestamp(\"2019-01-01 14:30:00\"),\n            ],\n        }\n        df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    \n        grouped = df.groupby(\"id\")\n        result = getattr(grouped, op)()\n        expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n>       assert_frame_equal(result, expected)\nE       AssertionError: Attributes are different\nE       \nE       Attribute \"dtype\" are different\nE       [left]:  datetime64[ns]\nE       [right]: datetime64[ns, UTC+01:00]\n\npandas/tests/groupby/test_groupby.py:1950: AssertionError",
                "traceback": null,
                "test_error_location": null,
                "test_function_decorators": [
                    "pytest.mark.parametrize('op, expected', [('shift', {'time': [None, None, Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), None, None]}), ('bfill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]}), ('ffill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]})])"
                ]
            },
            {
                "test_path": "/Volumes/JerrySSD/bgp_envs/repos/pandas_154/pandas/tests/groupby/test_groupby.py",
                "test_function": "test_shift_bfill_ffill_tz",
                "test_function_code": "@pytest.mark.parametrize(\n    \"op, expected\",\n    [\n        (\n            \"shift\",\n            {\n                \"time\": [\n                    None,\n                    None,\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    None,\n                    None,\n                ]\n            },\n        ),\n        (\n            \"bfill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n        (\n            \"ffill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n    ],\n)\ndef test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n    # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n    tz = tz_naive_fixture\n    data = {\n        \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n        \"time\": [\n            Timestamp(\"2019-01-01 12:00:00\"),\n            Timestamp(\"2019-01-01 12:30:00\"),\n            None,\n            None,\n            Timestamp(\"2019-01-01 14:00:00\"),\n            Timestamp(\"2019-01-01 14:30:00\"),\n        ],\n    }\n    df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n\n    grouped = df.groupby(\"id\")\n    result = getattr(grouped, op)()\n    expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    assert_frame_equal(result, expected)",
                "test_error": "AssertionError: Attributes are different  Attribute \"dtype\" are different [left]:  datetime64[ns] [right]: datetime64[ns, UTC+01:00]",
                "full_test_error": "tz_naive_fixture = datetime.timezone(datetime.timedelta(seconds=3600))\nop = 'bfill'\nexpected =                        time\n0 2019-01-01 12:00:00+01:00\n1 2019-01-01 12:30:00+01:00\n2 2019-01-01 14:00:00+01:00\n3 2019-01-01 14:30:00+01:00\n4 2019-01-01 14:00:00+01:00\n5 2019-01-01 14:30:00+01:00\n\n    @pytest.mark.parametrize(\n        \"op, expected\",\n        [\n            (\n                \"shift\",\n                {\n                    \"time\": [\n                        None,\n                        None,\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        None,\n                        None,\n                    ]\n                },\n            ),\n            (\n                \"bfill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n            (\n                \"ffill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n        ],\n    )\n    def test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n        # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n        tz = tz_naive_fixture\n        data = {\n            \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n            \"time\": [\n                Timestamp(\"2019-01-01 12:00:00\"),\n                Timestamp(\"2019-01-01 12:30:00\"),\n                None,\n                None,\n                Timestamp(\"2019-01-01 14:00:00\"),\n                Timestamp(\"2019-01-01 14:30:00\"),\n            ],\n        }\n        df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    \n        grouped = df.groupby(\"id\")\n        result = getattr(grouped, op)()\n        expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n>       assert_frame_equal(result, expected)\nE       AssertionError: Attributes are different\nE       \nE       Attribute \"dtype\" are different\nE       [left]:  datetime64[ns]\nE       [right]: datetime64[ns, UTC+01:00]\n\npandas/tests/groupby/test_groupby.py:1950: AssertionError",
                "traceback": null,
                "test_error_location": null,
                "test_function_decorators": [
                    "pytest.mark.parametrize('op, expected', [('shift', {'time': [None, None, Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), None, None]}), ('bfill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]}), ('ffill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]})])"
                ]
            },
            {
                "test_path": "/Volumes/JerrySSD/bgp_envs/repos/pandas_154/pandas/tests/groupby/test_groupby.py",
                "test_function": "test_shift_bfill_ffill_tz",
                "test_function_code": "@pytest.mark.parametrize(\n    \"op, expected\",\n    [\n        (\n            \"shift\",\n            {\n                \"time\": [\n                    None,\n                    None,\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    None,\n                    None,\n                ]\n            },\n        ),\n        (\n            \"bfill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n        (\n            \"ffill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n    ],\n)\ndef test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n    # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n    tz = tz_naive_fixture\n    data = {\n        \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n        \"time\": [\n            Timestamp(\"2019-01-01 12:00:00\"),\n            Timestamp(\"2019-01-01 12:30:00\"),\n            None,\n            None,\n            Timestamp(\"2019-01-01 14:00:00\"),\n            Timestamp(\"2019-01-01 14:30:00\"),\n        ],\n    }\n    df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n\n    grouped = df.groupby(\"id\")\n    result = getattr(grouped, op)()\n    expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    assert_frame_equal(result, expected)",
                "test_error": "AssertionError: Attributes are different  Attribute \"dtype\" are different [left]:  datetime64[ns] [right]: datetime64[ns, UTC+01:00]",
                "full_test_error": "tz_naive_fixture = datetime.timezone(datetime.timedelta(seconds=3600))\nop = 'ffill'\nexpected =                        time\n0 2019-01-01 12:00:00+01:00\n1 2019-01-01 12:30:00+01:00\n2 2019-01-01 12:00:00+01:00\n3 2019-01-01 12:30:00+01:00\n4 2019-01-01 14:00:00+01:00\n5 2019-01-01 14:30:00+01:00\n\n    @pytest.mark.parametrize(\n        \"op, expected\",\n        [\n            (\n                \"shift\",\n                {\n                    \"time\": [\n                        None,\n                        None,\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        None,\n                        None,\n                    ]\n                },\n            ),\n            (\n                \"bfill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n            (\n                \"ffill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n        ],\n    )\n    def test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n        # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n        tz = tz_naive_fixture\n        data = {\n            \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n            \"time\": [\n                Timestamp(\"2019-01-01 12:00:00\"),\n                Timestamp(\"2019-01-01 12:30:00\"),\n                None,\n                None,\n                Timestamp(\"2019-01-01 14:00:00\"),\n                Timestamp(\"2019-01-01 14:30:00\"),\n            ],\n        }\n        df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    \n        grouped = df.groupby(\"id\")\n        result = getattr(grouped, op)()\n        expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n>       assert_frame_equal(result, expected)\nE       AssertionError: Attributes are different\nE       \nE       Attribute \"dtype\" are different\nE       [left]:  datetime64[ns]\nE       [right]: datetime64[ns, UTC+01:00]\n\npandas/tests/groupby/test_groupby.py:1950: AssertionError",
                "traceback": null,
                "test_error_location": null,
                "test_function_decorators": [
                    "pytest.mark.parametrize('op, expected', [('shift', {'time': [None, None, Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), None, None]}), ('bfill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]}), ('ffill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]})])"
                ]
            },
            {
                "test_path": "/Volumes/JerrySSD/bgp_envs/repos/pandas_154/pandas/tests/groupby/test_groupby.py",
                "test_function": "test_shift_bfill_ffill_tz",
                "test_function_code": "@pytest.mark.parametrize(\n    \"op, expected\",\n    [\n        (\n            \"shift\",\n            {\n                \"time\": [\n                    None,\n                    None,\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    None,\n                    None,\n                ]\n            },\n        ),\n        (\n            \"bfill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n        (\n            \"ffill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n    ],\n)\ndef test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n    # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n    tz = tz_naive_fixture\n    data = {\n        \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n        \"time\": [\n            Timestamp(\"2019-01-01 12:00:00\"),\n            Timestamp(\"2019-01-01 12:30:00\"),\n            None,\n            None,\n            Timestamp(\"2019-01-01 14:00:00\"),\n            Timestamp(\"2019-01-01 14:30:00\"),\n        ],\n    }\n    df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n\n    grouped = df.groupby(\"id\")\n    result = getattr(grouped, op)()\n    expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    assert_frame_equal(result, expected)",
                "test_error": "AssertionError: Attributes are different  Attribute \"dtype\" are different [left]:  datetime64[ns] [right]: datetime64[ns, foo]",
                "full_test_error": "tz_naive_fixture = datetime.timezone(datetime.timedelta(days=-1, seconds=82800), 'foo')\nop = 'shift'\nexpected =                        time\n0                       NaT\n1                       NaT\n2 2019-01-01 12:00:00-01:00\n3 2019-01-01 12:30:00-01:00\n4                       NaT\n5                       NaT\n\n    @pytest.mark.parametrize(\n        \"op, expected\",\n        [\n            (\n                \"shift\",\n                {\n                    \"time\": [\n                        None,\n                        None,\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        None,\n                        None,\n                    ]\n                },\n            ),\n            (\n                \"bfill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n            (\n                \"ffill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n        ],\n    )\n    def test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n        # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n        tz = tz_naive_fixture\n        data = {\n            \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n            \"time\": [\n                Timestamp(\"2019-01-01 12:00:00\"),\n                Timestamp(\"2019-01-01 12:30:00\"),\n                None,\n                None,\n                Timestamp(\"2019-01-01 14:00:00\"),\n                Timestamp(\"2019-01-01 14:30:00\"),\n            ],\n        }\n        df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    \n        grouped = df.groupby(\"id\")\n        result = getattr(grouped, op)()\n        expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n>       assert_frame_equal(result, expected)\nE       AssertionError: Attributes are different\nE       \nE       Attribute \"dtype\" are different\nE       [left]:  datetime64[ns]\nE       [right]: datetime64[ns, foo]\n\npandas/tests/groupby/test_groupby.py:1950: AssertionError",
                "traceback": null,
                "test_error_location": null,
                "test_function_decorators": [
                    "pytest.mark.parametrize('op, expected', [('shift', {'time': [None, None, Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), None, None]}), ('bfill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]}), ('ffill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]})])"
                ]
            },
            {
                "test_path": "/Volumes/JerrySSD/bgp_envs/repos/pandas_154/pandas/tests/groupby/test_groupby.py",
                "test_function": "test_shift_bfill_ffill_tz",
                "test_function_code": "@pytest.mark.parametrize(\n    \"op, expected\",\n    [\n        (\n            \"shift\",\n            {\n                \"time\": [\n                    None,\n                    None,\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    None,\n                    None,\n                ]\n            },\n        ),\n        (\n            \"bfill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n        (\n            \"ffill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n    ],\n)\ndef test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n    # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n    tz = tz_naive_fixture\n    data = {\n        \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n        \"time\": [\n            Timestamp(\"2019-01-01 12:00:00\"),\n            Timestamp(\"2019-01-01 12:30:00\"),\n            None,\n            None,\n            Timestamp(\"2019-01-01 14:00:00\"),\n            Timestamp(\"2019-01-01 14:30:00\"),\n        ],\n    }\n    df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n\n    grouped = df.groupby(\"id\")\n    result = getattr(grouped, op)()\n    expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    assert_frame_equal(result, expected)",
                "test_error": "AssertionError: Attributes are different  Attribute \"dtype\" are different [left]:  datetime64[ns] [right]: datetime64[ns, foo]",
                "full_test_error": "tz_naive_fixture = datetime.timezone(datetime.timedelta(days=-1, seconds=82800), 'foo')\nop = 'bfill'\nexpected =                        time\n0 2019-01-01 12:00:00-01:00\n1 2019-01-01 12:30:00-01:00\n2 2019-01-01 14:00:00-01:00\n3 2019-01-01 14:30:00-01:00\n4 2019-01-01 14:00:00-01:00\n5 2019-01-01 14:30:00-01:00\n\n    @pytest.mark.parametrize(\n        \"op, expected\",\n        [\n            (\n                \"shift\",\n                {\n                    \"time\": [\n                        None,\n                        None,\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        None,\n                        None,\n                    ]\n                },\n            ),\n            (\n                \"bfill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n            (\n                \"ffill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n        ],\n    )\n    def test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n        # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n        tz = tz_naive_fixture\n        data = {\n            \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n            \"time\": [\n                Timestamp(\"2019-01-01 12:00:00\"),\n                Timestamp(\"2019-01-01 12:30:00\"),\n                None,\n                None,\n                Timestamp(\"2019-01-01 14:00:00\"),\n                Timestamp(\"2019-01-01 14:30:00\"),\n            ],\n        }\n        df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    \n        grouped = df.groupby(\"id\")\n        result = getattr(grouped, op)()\n        expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n>       assert_frame_equal(result, expected)\nE       AssertionError: Attributes are different\nE       \nE       Attribute \"dtype\" are different\nE       [left]:  datetime64[ns]\nE       [right]: datetime64[ns, foo]\n\npandas/tests/groupby/test_groupby.py:1950: AssertionError",
                "traceback": null,
                "test_error_location": null,
                "test_function_decorators": [
                    "pytest.mark.parametrize('op, expected', [('shift', {'time': [None, None, Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), None, None]}), ('bfill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]}), ('ffill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]})])"
                ]
            },
            {
                "test_path": "/Volumes/JerrySSD/bgp_envs/repos/pandas_154/pandas/tests/groupby/test_groupby.py",
                "test_function": "test_shift_bfill_ffill_tz",
                "test_function_code": "@pytest.mark.parametrize(\n    \"op, expected\",\n    [\n        (\n            \"shift\",\n            {\n                \"time\": [\n                    None,\n                    None,\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    None,\n                    None,\n                ]\n            },\n        ),\n        (\n            \"bfill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n        (\n            \"ffill\",\n            {\n                \"time\": [\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 12:00:00\"),\n                    Timestamp(\"2019-01-01 12:30:00\"),\n                    Timestamp(\"2019-01-01 14:00:00\"),\n                    Timestamp(\"2019-01-01 14:30:00\"),\n                ]\n            },\n        ),\n    ],\n)\ndef test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n    # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n    tz = tz_naive_fixture\n    data = {\n        \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n        \"time\": [\n            Timestamp(\"2019-01-01 12:00:00\"),\n            Timestamp(\"2019-01-01 12:30:00\"),\n            None,\n            None,\n            Timestamp(\"2019-01-01 14:00:00\"),\n            Timestamp(\"2019-01-01 14:30:00\"),\n        ],\n    }\n    df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n\n    grouped = df.groupby(\"id\")\n    result = getattr(grouped, op)()\n    expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    assert_frame_equal(result, expected)",
                "test_error": "AssertionError: Attributes are different  Attribute \"dtype\" are different [left]:  datetime64[ns] [right]: datetime64[ns, foo]",
                "full_test_error": "tz_naive_fixture = datetime.timezone(datetime.timedelta(days=-1, seconds=82800), 'foo')\nop = 'ffill'\nexpected =                        time\n0 2019-01-01 12:00:00-01:00\n1 2019-01-01 12:30:00-01:00\n2 2019-01-01 12:00:00-01:00\n3 2019-01-01 12:30:00-01:00\n4 2019-01-01 14:00:00-01:00\n5 2019-01-01 14:30:00-01:00\n\n    @pytest.mark.parametrize(\n        \"op, expected\",\n        [\n            (\n                \"shift\",\n                {\n                    \"time\": [\n                        None,\n                        None,\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        None,\n                        None,\n                    ]\n                },\n            ),\n            (\n                \"bfill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n            (\n                \"ffill\",\n                {\n                    \"time\": [\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 12:00:00\"),\n                        Timestamp(\"2019-01-01 12:30:00\"),\n                        Timestamp(\"2019-01-01 14:00:00\"),\n                        Timestamp(\"2019-01-01 14:30:00\"),\n                    ]\n                },\n            ),\n        ],\n    )\n    def test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):\n        # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill\n        tz = tz_naive_fixture\n        data = {\n            \"id\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n            \"time\": [\n                Timestamp(\"2019-01-01 12:00:00\"),\n                Timestamp(\"2019-01-01 12:30:00\"),\n                None,\n                None,\n                Timestamp(\"2019-01-01 14:00:00\"),\n                Timestamp(\"2019-01-01 14:30:00\"),\n            ],\n        }\n        df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))\n    \n        grouped = df.groupby(\"id\")\n        result = getattr(grouped, op)()\n        expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))\n>       assert_frame_equal(result, expected)\nE       AssertionError: Attributes are different\nE       \nE       Attribute \"dtype\" are different\nE       [left]:  datetime64[ns]\nE       [right]: datetime64[ns, foo]\n\npandas/tests/groupby/test_groupby.py:1950: AssertionError",
                "traceback": null,
                "test_error_location": null,
                "test_function_decorators": [
                    "pytest.mark.parametrize('op, expected', [('shift', {'time': [None, None, Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), None, None]}), ('bfill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]}), ('ffill', {'time': [Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 12:00:00'), Timestamp('2019-01-01 12:30:00'), Timestamp('2019-01-01 14:00:00'), Timestamp('2019-01-01 14:30:00')]})])"
                ]
            }
        ]
    }
}