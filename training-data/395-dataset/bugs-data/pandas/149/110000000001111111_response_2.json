{
    "pandas": [
        {
            "bugID": 149,
            "bitvector": {
                "1.1.1": 1,
                "1.1.2": 1,
                "1.2.1": 0,
                "1.2.2": 0,
                "1.2.3": 0,
                "1.3.1": 0,
                "1.3.2": 0,
                "1.4.1": 0,
                "1.4.2": 0,
                "2.1.1": 0,
                "2.1.2": 0,
                "2.1.3": 1,
                "2.1.4": 1,
                "2.1.5": 1,
                "2.1.6": 1,
                "3.1.1": 1,
                "3.1.2": 1,
                "cot": 1
            },
            "strata": {
                "1": 1,
                "2": 0,
                "3": 0,
                "4": 0,
                "5": 1,
                "6": 1,
                "7": 1
            },
            "available_bitvector": {
                "1.1.1": 1,
                "1.1.2": 0,
                "1.2.1": 0,
                "1.2.2": 0,
                "1.2.3": 0,
                "1.3.1": 0,
                "1.3.2": 0,
                "1.4.1": 0,
                "1.4.2": 0,
                "2.1.1": 0,
                "2.1.2": 0,
                "2.1.3": 0,
                "2.1.4": 0,
                "2.1.5": 1,
                "2.1.6": 1,
                "3.1.1": 0,
                "3.1.2": 0,
                "cot": 1
            },
            "available_strata": {
                "1": 1,
                "2": 0,
                "3": 0,
                "4": 0,
                "5": 1,
                "6": 0,
                "7": 1
            },
            "start_line": 142,
            "file_name": "pandas/io/parquet.py",
            "replace_code": "def write(self, df, path, compression=\"snappy\", index=None, partition_cols=None, **kwargs):\n\n    self.validate_dataframe(df)\n    \n    # Check if 'partition_on' is present in kwargs and handle it consistently\n    if \"partition_on\" in kwargs:\n        if partition_cols:\n            raise ValueError(\"Cannot use both partition_on and partition_cols. Use partition_cols for partitioning data\")\n        else:\n            partition_cols = kwargs.pop(\"partition_on\")\n    \n    if partition_cols is not None:\n        # Set file_scheme to \"hive\" if partition_cols is not None\n        kwargs[\"file_scheme\"] = \"hive\"\n    \n    if is_s3_url(path):\n        # Handle 's3://' path\n        with get_filepath_or_buffer(path, mode=\"wb\") as s3file:\n            # Pass the opened s3file to the fastparquet internal impl\n            kwargs[\"open_with\"] = lambda path, _: s3file\n    else:\n        # Handle non-s3 paths\n        with get_filepath_or_buffer(path) as file:\n            with catch_warnings(record=True):\n                self.api.write(\n                    file,\n                    df,\n                    compression=compression,\n                    write_index=index,\n                    partition_on=partition_cols,\n                    **kwargs\n                )"
        }
    ]
}