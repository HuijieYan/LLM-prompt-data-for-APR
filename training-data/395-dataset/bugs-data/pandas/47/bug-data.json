{
    "pandas:47": {
        "/Volumes/JerrySSD/bgp_envs/repos/pandas_47/pandas/core/frame.py": {
            "buggy_functions": [
                {
                    "function_name": "_setitem_array",
                    "function_code": "def _setitem_array(self, key, value):\n    # also raises Exception if object array with NA values\n    if com.is_bool_indexer(key):\n        if len(key) != len(self.index):\n            raise ValueError(\n                f\"Item wrong length {len(key)} instead of {len(self.index)}!\"\n            )\n        key = check_bool_indexer(self.index, key)\n        indexer = key.nonzero()[0]\n        self._check_setitem_copy()\n        self.iloc._setitem_with_indexer(indexer, value)\n    else:\n        if isinstance(value, DataFrame):\n            if len(value.columns) != len(key):\n                raise ValueError(\"Columns must be same length as key\")\n            for k1, k2 in zip(key, value.columns):\n                self[k1] = value[k2]\n        else:\n            indexer = self.loc._get_listlike_indexer(\n                key, axis=1, raise_missing=False\n            )[1]\n            self._check_setitem_copy()\n            self.iloc._setitem_with_indexer((slice(None), indexer), value)\n",
                    "decorators": [],
                    "docstring": null,
                    "start_line": 2672,
                    "variables": {
                        "com.is_bool_indexer": [
                            2674
                        ],
                        "com": [
                            2674
                        ],
                        "key": [
                            2691,
                            2674,
                            2675,
                            2677,
                            2679,
                            2680,
                            2685,
                            2687
                        ],
                        "len": [
                            2675,
                            2685,
                            2677
                        ],
                        "self.index": [
                            2675,
                            2677,
                            2679
                        ],
                        "self": [
                            2688,
                            2690,
                            2693,
                            2694,
                            2675,
                            2677,
                            2679,
                            2681,
                            2682
                        ],
                        "ValueError": [
                            2676,
                            2686
                        ],
                        "check_bool_indexer": [
                            2679
                        ],
                        "indexer": [
                            2680,
                            2682,
                            2694,
                            2690
                        ],
                        "key.nonzero": [
                            2680
                        ],
                        "self._check_setitem_copy": [
                            2681,
                            2693
                        ],
                        "self.iloc._setitem_with_indexer": [
                            2682,
                            2694
                        ],
                        "self.iloc": [
                            2682,
                            2694
                        ],
                        "value": [
                            2688,
                            2694,
                            2682,
                            2684,
                            2685,
                            2687
                        ],
                        "isinstance": [
                            2684
                        ],
                        "DataFrame": [
                            2684
                        ],
                        "value.columns": [
                            2685,
                            2687
                        ],
                        "k1": [
                            2688,
                            2687
                        ],
                        "k2": [
                            2688,
                            2687
                        ],
                        "zip": [
                            2687
                        ],
                        "self.loc._get_listlike_indexer": [
                            2690
                        ],
                        "self.loc": [
                            2690
                        ],
                        "slice": [
                            2694
                        ]
                    },
                    "filtered_variables": {
                        "com.is_bool_indexer": [
                            2674
                        ],
                        "com": [
                            2674
                        ],
                        "key": [
                            2691,
                            2674,
                            2675,
                            2677,
                            2679,
                            2680,
                            2685,
                            2687
                        ],
                        "self.index": [
                            2675,
                            2677,
                            2679
                        ],
                        "self": [
                            2688,
                            2690,
                            2693,
                            2694,
                            2675,
                            2677,
                            2679,
                            2681,
                            2682
                        ],
                        "check_bool_indexer": [
                            2679
                        ],
                        "indexer": [
                            2680,
                            2682,
                            2694,
                            2690
                        ],
                        "key.nonzero": [
                            2680
                        ],
                        "self._check_setitem_copy": [
                            2681,
                            2693
                        ],
                        "self.iloc._setitem_with_indexer": [
                            2682,
                            2694
                        ],
                        "self.iloc": [
                            2682,
                            2694
                        ],
                        "value": [
                            2688,
                            2694,
                            2682,
                            2684,
                            2685,
                            2687
                        ],
                        "DataFrame": [
                            2684
                        ],
                        "value.columns": [
                            2685,
                            2687
                        ],
                        "k1": [
                            2688,
                            2687
                        ],
                        "k2": [
                            2688,
                            2687
                        ],
                        "self.loc._get_listlike_indexer": [
                            2690
                        ],
                        "self.loc": [
                            2690
                        ]
                    },
                    "diff_line_number": 2689,
                    "class_data": {
                        "signature": "class DataFrame(NDFrame)",
                        "docstring": "Two-dimensional, size-mutable, potentially heterogeneous tabular data.\n\nData structure also contains labeled axes (rows and columns).\nArithmetic operations align on both row and column labels. Can be\nthought of as a dict-like container for Series objects. The primary\npandas data structure.\n\nParameters\n----------\ndata : ndarray (structured or homogeneous), Iterable, dict, or DataFrame\n    Dict can contain Series, arrays, constants, or list-like objects.\n\n    .. versionchanged:: 0.23.0\n       If data is a dict, column order follows insertion-order for\n       Python 3.6 and later.\n\n    .. versionchanged:: 0.25.0\n       If data is a list of dicts, column order follows insertion-order\n       for Python 3.6 and later.\n\nindex : Index or array-like\n    Index to use for resulting frame. Will default to RangeIndex if\n    no indexing information part of input data and no index provided.\ncolumns : Index or array-like\n    Column labels to use for resulting frame. Will default to\n    RangeIndex (0, 1, 2, ..., n) if no column labels are provided.\ndtype : dtype, default None\n    Data type to force. Only a single dtype is allowed. If None, infer.\ncopy : bool, default False\n    Copy data from inputs. Only affects DataFrame / 2d ndarray input.\n\nSee Also\n--------\nDataFrame.from_records : Constructor from tuples, also record arrays.\nDataFrame.from_dict : From dicts of Series, arrays, or dicts.\nread_csv : Read a comma-separated values (csv) file into DataFrame.\nread_table : Read general delimited file into DataFrame.\nread_clipboard : Read text from clipboard into DataFrame.\n\nExamples\n--------\nConstructing DataFrame from a dictionary.\n\n>>> d = {'col1': [1, 2], 'col2': [3, 4]}\n>>> df = pd.DataFrame(data=d)\n>>> df\n   col1  col2\n0     1     3\n1     2     4\n\nNotice that the inferred dtype is int64.\n\n>>> df.dtypes\ncol1    int64\ncol2    int64\ndtype: object\n\nTo enforce a single dtype:\n\n>>> df = pd.DataFrame(data=d, dtype=np.int8)\n>>> df.dtypes\ncol1    int8\ncol2    int8\ndtype: object\n\nConstructing DataFrame from numpy ndarray:\n\n>>> df2 = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]),\n...                    columns=['a', 'b', 'c'])\n>>> df2\n   a  b  c\n0  1  2  3\n1  4  5  6\n2  7  8  9",
                        "constructor_docstring": null,
                        "functions": [
                            "@property\ndef _constructor(self) -> Type['DataFrame']:\n    return DataFrame",
                            "@property\ndef _constructor_expanddim(self):\n    raise NotImplementedError('Not supported for DataFrames!')",
                            "def __init__(self, data=None, index: Optional[Axes]=None, columns: Optional[Axes]=None, dtype: Optional[Dtype]=None, copy: bool=False):\n    if data is None:\n        data = {}\n    if dtype is not None:\n        dtype = self._validate_dtype(dtype)\n    if isinstance(data, DataFrame):\n        data = data._data\n    if isinstance(data, BlockManager):\n        mgr = self._init_mgr(data, axes=dict(index=index, columns=columns), dtype=dtype, copy=copy)\n    elif isinstance(data, dict):\n        mgr = init_dict(data, index, columns, dtype=dtype)\n    elif isinstance(data, ma.MaskedArray):\n        import numpy.ma.mrecords as mrecords\n        if isinstance(data, mrecords.MaskedRecords):\n            mgr = masked_rec_array_to_mgr(data, index, columns, dtype, copy)\n        else:\n            mask = ma.getmaskarray(data)\n            if mask.any():\n                data, fill_value = maybe_upcast(data, copy=True)\n                data.soften_mask()\n                data[mask] = fill_value\n            else:\n                data = data.copy()\n            mgr = init_ndarray(data, index, columns, dtype=dtype, copy=copy)\n    elif isinstance(data, (np.ndarray, Series, Index)):\n        if data.dtype.names:\n            data_columns = list(data.dtype.names)\n            data = {k: data[k] for k in data_columns}\n            if columns is None:\n                columns = data_columns\n            mgr = init_dict(data, index, columns, dtype=dtype)\n        elif getattr(data, 'name', None) is not None:\n            mgr = init_dict({data.name: data}, index, columns, dtype=dtype)\n        else:\n            mgr = init_ndarray(data, index, columns, dtype=dtype, copy=copy)\n    elif isinstance(data, abc.Iterable) and (not isinstance(data, (str, bytes))):\n        if not isinstance(data, (abc.Sequence, ExtensionArray)):\n            data = list(data)\n        if len(data) > 0:\n            if is_list_like(data[0]) and getattr(data[0], 'ndim', 1) == 1:\n                if is_named_tuple(data[0]) and columns is None:\n                    columns = data[0]._fields\n                arrays, columns = to_arrays(data, columns, dtype=dtype)\n                columns = ensure_index(columns)\n                if index is None:\n                    if isinstance(data[0], Series):\n                        index = get_names_from_index(data)\n                    elif isinstance(data[0], Categorical):\n                        index = ibase.default_index(len(data[0]))\n                    else:\n                        index = ibase.default_index(len(data))\n                mgr = arrays_to_mgr(arrays, columns, index, columns, dtype=dtype)\n            else:\n                mgr = init_ndarray(data, index, columns, dtype=dtype, copy=copy)\n        else:\n            mgr = init_dict({}, index, columns, dtype=dtype)\n    else:\n        try:\n            arr = np.array(data, dtype=dtype, copy=copy)\n        except (ValueError, TypeError) as err:\n            exc = TypeError(f'DataFrame constructor called with incompatible data and dtype: {err}')\n            raise exc from err\n        if arr.ndim == 0 and index is not None and (columns is not None):\n            values = cast_scalar_to_array((len(index), len(columns)), data, dtype=dtype)\n            mgr = init_ndarray(values, index, columns, dtype=values.dtype, copy=False)\n        else:\n            raise ValueError('DataFrame constructor not properly called!')\n    NDFrame.__init__(self, mgr)",
                            "@property\ndef axes(self) -> List[Index]:\n    \"\"\"\n    Return a list representing the axes of the DataFrame.\n\n    It has the row axis labels and column axis labels as the only members.\n    They are returned in that order.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n    >>> df.axes\n    [RangeIndex(start=0, stop=2, step=1), Index(['col1', 'col2'],\n    dtype='object')]\n    \"\"\"\n    return [self.index, self.columns]",
                            "@property\ndef shape(self) -> Tuple[int, int]:\n    \"\"\"\n    Return a tuple representing the dimensionality of the DataFrame.\n\n    See Also\n    --------\n    ndarray.shape\n\n    Examples\n    --------\n    >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n    >>> df.shape\n    (2, 2)\n\n    >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4],\n    ...                    'col3': [5, 6]})\n    >>> df.shape\n    (2, 3)\n    \"\"\"\n    return (len(self.index), len(self.columns))",
                            "@property\ndef _is_homogeneous_type(self) -> bool:\n    \"\"\"\n    Whether all the columns in a DataFrame have the same type.\n\n    Returns\n    -------\n    bool\n\n    See Also\n    --------\n    Index._is_homogeneous_type : Whether the object has a single\n        dtype.\n    MultiIndex._is_homogeneous_type : Whether all the levels of a\n        MultiIndex have the same dtype.\n\n    Examples\n    --------\n    >>> DataFrame({\"A\": [1, 2], \"B\": [3, 4]})._is_homogeneous_type\n    True\n    >>> DataFrame({\"A\": [1, 2], \"B\": [3.0, 4.0]})._is_homogeneous_type\n    False\n\n    Items with the same type but different sizes are considered\n    different types.\n\n    >>> DataFrame({\n    ...    \"A\": np.array([1, 2], dtype=np.int32),\n    ...    \"B\": np.array([1, 2], dtype=np.int64)})._is_homogeneous_type\n    False\n    \"\"\"\n    if self._data.any_extension_types:\n        return len({block.dtype for block in self._data.blocks}) == 1\n    else:\n        return not self._data.is_mixed_type",
                            "def _repr_fits_vertical_(self) -> bool:\n    \"\"\"\n    Check length against max_rows.\n    \"\"\"\n    max_rows = get_option('display.max_rows')\n    return len(self) <= max_rows",
                            "def _repr_fits_horizontal_(self, ignore_width: bool=False) -> bool:\n    \"\"\"\n    Check if full repr fits in horizontal boundaries imposed by the display\n    options width and max_columns.\n\n    In case of non-interactive session, no boundaries apply.\n\n    `ignore_width` is here so ipnb+HTML output can behave the way\n    users expect. display.max_columns remains in effect.\n    GH3541, GH3573\n    \"\"\"\n    width, height = console.get_console_size()\n    max_columns = get_option('display.max_columns')\n    nb_columns = len(self.columns)\n    if max_columns and nb_columns > max_columns or (not ignore_width and width and (nb_columns > width // 2)):\n        return False\n    if ignore_width or not console.in_interactive_session():\n        return True\n    if get_option('display.width') is not None or console.in_ipython_frontend():\n        max_rows = 1\n    else:\n        max_rows = get_option('display.max_rows')\n    buf = StringIO()\n    d = self\n    if not max_rows is None:\n        d = d.iloc[:min(max_rows, len(d))]\n    else:\n        return True\n    d.to_string(buf=buf)\n    value = buf.getvalue()\n    repr_width = max((len(l) for l in value.split('\\n')))\n    return repr_width < width",
                            "def _info_repr(self) -> bool:\n    \"\"\"\n    True if the repr should show the info view.\n    \"\"\"\n    info_repr_option = get_option('display.large_repr') == 'info'\n    return info_repr_option and (not (self._repr_fits_horizontal_() and self._repr_fits_vertical_()))",
                            "def __repr__(self) -> str:\n    \"\"\"\n    Return a string representation for a particular DataFrame.\n    \"\"\"\n    buf = StringIO('')\n    if self._info_repr():\n        self.info(buf=buf)\n        return buf.getvalue()\n    max_rows = get_option('display.max_rows')\n    min_rows = get_option('display.min_rows')\n    max_cols = get_option('display.max_columns')\n    max_colwidth = get_option('display.max_colwidth')\n    show_dimensions = get_option('display.show_dimensions')\n    if get_option('display.expand_frame_repr'):\n        width, _ = console.get_console_size()\n    else:\n        width = None\n    self.to_string(buf=buf, max_rows=max_rows, min_rows=min_rows, max_cols=max_cols, line_width=width, max_colwidth=max_colwidth, show_dimensions=show_dimensions)\n    return buf.getvalue()",
                            "def _repr_html_(self) -> Optional[str]:\n    \"\"\"\n    Return a html representation for a particular DataFrame.\n\n    Mainly for IPython notebook.\n    \"\"\"\n    if self._info_repr():\n        buf = StringIO('')\n        self.info(buf=buf)\n        val = buf.getvalue().replace('<', '&lt;', 1)\n        val = val.replace('>', '&gt;', 1)\n        return '<pre>' + val + '</pre>'\n    if get_option('display.notebook_repr_html'):\n        max_rows = get_option('display.max_rows')\n        min_rows = get_option('display.min_rows')\n        max_cols = get_option('display.max_columns')\n        show_dimensions = get_option('display.show_dimensions')\n        formatter = fmt.DataFrameFormatter(self, columns=None, col_space=None, na_rep='NaN', formatters=None, float_format=None, sparsify=None, justify=None, index_names=True, header=True, index=True, bold_rows=True, escape=True, max_rows=max_rows, min_rows=min_rows, max_cols=max_cols, show_dimensions=show_dimensions, decimal='.', table_id=None, render_links=False)\n        return formatter.to_html(notebook=True)\n    else:\n        return None",
                            "@Substitution(header_type='bool or sequence', header='Write out the column names. If a list of strings is given, it is assumed to be aliases for the column names', col_space_type='int', col_space='The minimum width of each column')\n@Substitution(shared_params=fmt.common_docstring, returns=fmt.return_docstring)\ndef to_string(self, buf: Optional[FilePathOrBuffer[str]]=None, columns: Optional[Sequence[str]]=None, col_space: Optional[int]=None, header: Union[bool, Sequence[str]]=True, index: bool=True, na_rep: str='NaN', formatters: Optional[fmt.FormattersType]=None, float_format: Optional[fmt.FloatFormatType]=None, sparsify: Optional[bool]=None, index_names: bool=True, justify: Optional[str]=None, max_rows: Optional[int]=None, min_rows: Optional[int]=None, max_cols: Optional[int]=None, show_dimensions: bool=False, decimal: str='.', line_width: Optional[int]=None, max_colwidth: Optional[int]=None, encoding: Optional[str]=None) -> Optional[str]:\n    \"\"\"\n    Render a DataFrame to a console-friendly tabular output.\n    %(shared_params)s\n    line_width : int, optional\n        Width to wrap a line in characters.\n    max_colwidth : int, optional\n        Max width to truncate each column in characters. By default, no limit.\n\n        .. versionadded:: 1.0.0\n    encoding : str, default \"utf-8\"\n        Set character encoding.\n\n        .. versionadded:: 1.0\n    %(returns)s\n    See Also\n    --------\n    to_html : Convert DataFrame to HTML.\n\n    Examples\n    --------\n    >>> d = {'col1': [1, 2, 3], 'col2': [4, 5, 6]}\n    >>> df = pd.DataFrame(d)\n    >>> print(df.to_string())\n       col1  col2\n    0     1     4\n    1     2     5\n    2     3     6\n    \"\"\"\n    from pandas import option_context\n    with option_context('display.max_colwidth', max_colwidth):\n        formatter = fmt.DataFrameFormatter(self, columns=columns, col_space=col_space, na_rep=na_rep, formatters=formatters, float_format=float_format, sparsify=sparsify, justify=justify, index_names=index_names, header=header, index=index, min_rows=min_rows, max_rows=max_rows, max_cols=max_cols, show_dimensions=show_dimensions, decimal=decimal, line_width=line_width)\n        return formatter.to_string(buf=buf, encoding=encoding)",
                            "@property\ndef style(self) -> 'Styler':\n    \"\"\"\n    Returns a Styler object.\n\n    Contains methods for building a styled HTML representation of the DataFrame.\n\n    See Also\n    --------\n    io.formats.style.Styler\n    \"\"\"\n    from pandas.io.formats.style import Styler\n    return Styler(self)",
                            "@Appender(_shared_docs['items'])\ndef items(self) -> Iterable[Tuple[Label, Series]]:\n    if self.columns.is_unique and hasattr(self, '_item_cache'):\n        for k in self.columns:\n            yield (k, self._get_item_cache(k))\n    else:\n        for i, k in enumerate(self.columns):\n            yield (k, self._ixs(i, axis=1))",
                            "@Appender(_shared_docs['items'])\ndef iteritems(self) -> Iterable[Tuple[Label, Series]]:\n    yield from self.items()",
                            "def iterrows(self) -> Iterable[Tuple[Label, Series]]:\n    \"\"\"\n    Iterate over DataFrame rows as (index, Series) pairs.\n\n    Yields\n    ------\n    index : label or tuple of label\n        The index of the row. A tuple for a `MultiIndex`.\n    data : Series\n        The data of the row as a Series.\n\n    it : generator\n        A generator that iterates over the rows of the frame.\n\n    See Also\n    --------\n    DataFrame.itertuples : Iterate over DataFrame rows as namedtuples of the values.\n    DataFrame.items : Iterate over (column name, Series) pairs.\n\n    Notes\n    -----\n    1. Because ``iterrows`` returns a Series for each row,\n       it does **not** preserve dtypes across the rows (dtypes are\n       preserved across columns for DataFrames). For example,\n\n       >>> df = pd.DataFrame([[1, 1.5]], columns=['int', 'float'])\n       >>> row = next(df.iterrows())[1]\n       >>> row\n       int      1.0\n       float    1.5\n       Name: 0, dtype: float64\n       >>> print(row['int'].dtype)\n       float64\n       >>> print(df['int'].dtype)\n       int64\n\n       To preserve dtypes while iterating over the rows, it is better\n       to use :meth:`itertuples` which returns namedtuples of the values\n       and which is generally faster than ``iterrows``.\n\n    2. You should **never modify** something you are iterating over.\n       This is not guaranteed to work in all cases. Depending on the\n       data types, the iterator returns a copy and not a view, and writing\n       to it will have no effect.\n    \"\"\"\n    columns = self.columns\n    klass = self._constructor_sliced\n    for k, v in zip(self.index, self.values):\n        s = klass(v, index=columns, name=k)\n        yield (k, s)",
                            "def itertuples(self, index=True, name='Pandas'):\n    \"\"\"\n    Iterate over DataFrame rows as namedtuples.\n\n    Parameters\n    ----------\n    index : bool, default True\n        If True, return the index as the first element of the tuple.\n    name : str or None, default \"Pandas\"\n        The name of the returned namedtuples or None to return regular\n        tuples.\n\n    Returns\n    -------\n    iterator\n        An object to iterate over namedtuples for each row in the\n        DataFrame with the first field possibly being the index and\n        following fields being the column values.\n\n    See Also\n    --------\n    DataFrame.iterrows : Iterate over DataFrame rows as (index, Series)\n        pairs.\n    DataFrame.items : Iterate over (column name, Series) pairs.\n\n    Notes\n    -----\n    The column names will be renamed to positional names if they are\n    invalid Python identifiers, repeated, or start with an underscore.\n    On python versions < 3.7 regular tuples are returned for DataFrames\n    with a large number of columns (>254).\n\n    Examples\n    --------\n    >>> df = pd.DataFrame({'num_legs': [4, 2], 'num_wings': [0, 2]},\n    ...                   index=['dog', 'hawk'])\n    >>> df\n          num_legs  num_wings\n    dog          4          0\n    hawk         2          2\n    >>> for row in df.itertuples():\n    ...     print(row)\n    ...\n    Pandas(Index='dog', num_legs=4, num_wings=0)\n    Pandas(Index='hawk', num_legs=2, num_wings=2)\n\n    By setting the `index` parameter to False we can remove the index\n    as the first element of the tuple:\n\n    >>> for row in df.itertuples(index=False):\n    ...     print(row)\n    ...\n    Pandas(num_legs=4, num_wings=0)\n    Pandas(num_legs=2, num_wings=2)\n\n    With the `name` parameter set we set a custom name for the yielded\n    namedtuples:\n\n    >>> for row in df.itertuples(name='Animal'):\n    ...     print(row)\n    ...\n    Animal(Index='dog', num_legs=4, num_wings=0)\n    Animal(Index='hawk', num_legs=2, num_wings=2)\n    \"\"\"\n    arrays = []\n    fields = list(self.columns)\n    if index:\n        arrays.append(self.index)\n        fields.insert(0, 'Index')\n    arrays.extend((self.iloc[:, k] for k in range(len(self.columns))))\n    can_return_named_tuples = PY37 or len(self.columns) + index < 255\n    if name is not None and can_return_named_tuples:\n        itertuple = collections.namedtuple(name, fields, rename=True)\n        return map(itertuple._make, zip(*arrays))\n    return zip(*arrays)",
                            "def __len__(self) -> int:\n    \"\"\"\n    Returns length of info axis, but here we use the index.\n    \"\"\"\n    return len(self.index)",
                            "def dot(self, other):\n    \"\"\"\n    Compute the matrix multiplication between the DataFrame and other.\n\n    This method computes the matrix product between the DataFrame and the\n    values of an other Series, DataFrame or a numpy array.\n\n    It can also be called using ``self @ other`` in Python >= 3.5.\n\n    Parameters\n    ----------\n    other : Series, DataFrame or array-like\n        The other object to compute the matrix product with.\n\n    Returns\n    -------\n    Series or DataFrame\n        If other is a Series, return the matrix product between self and\n        other as a Serie. If other is a DataFrame or a numpy.array, return\n        the matrix product of self and other in a DataFrame of a np.array.\n\n    See Also\n    --------\n    Series.dot: Similar method for Series.\n\n    Notes\n    -----\n    The dimensions of DataFrame and other must be compatible in order to\n    compute the matrix multiplication. In addition, the column names of\n    DataFrame and the index of other must contain the same values, as they\n    will be aligned prior to the multiplication.\n\n    The dot method for Series computes the inner product, instead of the\n    matrix product here.\n\n    Examples\n    --------\n    Here we multiply a DataFrame with a Series.\n\n    >>> df = pd.DataFrame([[0, 1, -2, -1], [1, 1, 1, 1]])\n    >>> s = pd.Series([1, 1, 2, 1])\n    >>> df.dot(s)\n    0    -4\n    1     5\n    dtype: int64\n\n    Here we multiply a DataFrame with another DataFrame.\n\n    >>> other = pd.DataFrame([[0, 1], [1, 2], [-1, -1], [2, 0]])\n    >>> df.dot(other)\n        0   1\n    0   1   4\n    1   2   2\n\n    Note that the dot method give the same result as @\n\n    >>> df @ other\n        0   1\n    0   1   4\n    1   2   2\n\n    The dot method works also if other is an np.array.\n\n    >>> arr = np.array([[0, 1], [1, 2], [-1, -1], [2, 0]])\n    >>> df.dot(arr)\n        0   1\n    0   1   4\n    1   2   2\n\n    Note how shuffling of the objects does not change the result.\n\n    >>> s2 = s.reindex([1, 0, 2, 3])\n    >>> df.dot(s2)\n    0    -4\n    1     5\n    dtype: int64\n    \"\"\"\n    if isinstance(other, (Series, DataFrame)):\n        common = self.columns.union(other.index)\n        if len(common) > len(self.columns) or len(common) > len(other.index):\n            raise ValueError('matrices are not aligned')\n        left = self.reindex(columns=common, copy=False)\n        right = other.reindex(index=common, copy=False)\n        lvals = left.values\n        rvals = right.values\n    else:\n        left = self\n        lvals = self.values\n        rvals = np.asarray(other)\n        if lvals.shape[1] != rvals.shape[0]:\n            raise ValueError(f'Dot product shape mismatch, {lvals.shape} vs {rvals.shape}')\n    if isinstance(other, DataFrame):\n        return self._constructor(np.dot(lvals, rvals), index=left.index, columns=other.columns)\n    elif isinstance(other, Series):\n        return Series(np.dot(lvals, rvals), index=left.index)\n    elif isinstance(rvals, (np.ndarray, Index)):\n        result = np.dot(lvals, rvals)\n        if result.ndim == 2:\n            return self._constructor(result, index=left.index)\n        else:\n            return Series(result, index=left.index)\n    else:\n        raise TypeError(f'unsupported type: {type(other)}')",
                            "def __matmul__(self, other):\n    \"\"\"\n    Matrix multiplication using binary `@` operator in Python>=3.5.\n    \"\"\"\n    return self.dot(other)",
                            "def __rmatmul__(self, other):\n    \"\"\"\n    Matrix multiplication using binary `@` operator in Python>=3.5.\n    \"\"\"\n    return self.T.dot(np.transpose(other)).T",
                            "@classmethod\ndef from_dict(cls, data, orient='columns', dtype=None, columns=None) -> 'DataFrame':\n    \"\"\"\n    Construct DataFrame from dict of array-like or dicts.\n\n    Creates DataFrame object from dictionary by columns or by index\n    allowing dtype specification.\n\n    Parameters\n    ----------\n    data : dict\n        Of the form {field : array-like} or {field : dict}.\n    orient : {'columns', 'index'}, default 'columns'\n        The \"orientation\" of the data. If the keys of the passed dict\n        should be the columns of the resulting DataFrame, pass 'columns'\n        (default). Otherwise if the keys should be rows, pass 'index'.\n    dtype : dtype, default None\n        Data type to force, otherwise infer.\n    columns : list, default None\n        Column labels to use when ``orient='index'``. Raises a ValueError\n        if used with ``orient='columns'``.\n\n        .. versionadded:: 0.23.0\n\n    Returns\n    -------\n    DataFrame\n\n    See Also\n    --------\n    DataFrame.from_records : DataFrame from ndarray (structured\n        dtype), list of tuples, dict, or DataFrame.\n    DataFrame : DataFrame object creation using constructor.\n\n    Examples\n    --------\n    By default the keys of the dict become the DataFrame columns:\n\n    >>> data = {'col_1': [3, 2, 1, 0], 'col_2': ['a', 'b', 'c', 'd']}\n    >>> pd.DataFrame.from_dict(data)\n       col_1 col_2\n    0      3     a\n    1      2     b\n    2      1     c\n    3      0     d\n\n    Specify ``orient='index'`` to create the DataFrame using dictionary\n    keys as rows:\n\n    >>> data = {'row_1': [3, 2, 1, 0], 'row_2': ['a', 'b', 'c', 'd']}\n    >>> pd.DataFrame.from_dict(data, orient='index')\n           0  1  2  3\n    row_1  3  2  1  0\n    row_2  a  b  c  d\n\n    When using the 'index' orientation, the column names can be\n    specified manually:\n\n    >>> pd.DataFrame.from_dict(data, orient='index',\n    ...                        columns=['A', 'B', 'C', 'D'])\n           A  B  C  D\n    row_1  3  2  1  0\n    row_2  a  b  c  d\n    \"\"\"\n    index = None\n    orient = orient.lower()\n    if orient == 'index':\n        if len(data) > 0:\n            if isinstance(list(data.values())[0], (Series, dict)):\n                data = _from_nested_dict(data)\n            else:\n                data, index = (list(data.values()), list(data.keys()))\n    elif orient == 'columns':\n        if columns is not None:\n            raise ValueError(\"cannot use columns parameter with orient='columns'\")\n    else:\n        raise ValueError('only recognize index or columns for orient')\n    return cls(data, index=index, columns=columns, dtype=dtype)",
                            "def to_numpy(self, dtype=None, copy=False) -> np.ndarray:\n    \"\"\"\n    Convert the DataFrame to a NumPy array.\n\n    .. versionadded:: 0.24.0\n\n    By default, the dtype of the returned array will be the common NumPy\n    dtype of all types in the DataFrame. For example, if the dtypes are\n    ``float16`` and ``float32``, the results dtype will be ``float32``.\n    This may require copying data and coercing values, which may be\n    expensive.\n\n    Parameters\n    ----------\n    dtype : str or numpy.dtype, optional\n        The dtype to pass to :meth:`numpy.asarray`.\n    copy : bool, default False\n        Whether to ensure that the returned value is a not a view on\n        another array. Note that ``copy=False`` does not *ensure* that\n        ``to_numpy()`` is no-copy. Rather, ``copy=True`` ensure that\n        a copy is made, even if not strictly necessary.\n\n    Returns\n    -------\n    numpy.ndarray\n\n    See Also\n    --------\n    Series.to_numpy : Similar method for Series.\n\n    Examples\n    --------\n    >>> pd.DataFrame({\"A\": [1, 2], \"B\": [3, 4]}).to_numpy()\n    array([[1, 3],\n           [2, 4]])\n\n    With heterogeneous data, the lowest common type will have to\n    be used.\n\n    >>> df = pd.DataFrame({\"A\": [1, 2], \"B\": [3.0, 4.5]})\n    >>> df.to_numpy()\n    array([[1. , 3. ],\n           [2. , 4.5]])\n\n    For a mix of numeric and non-numeric types, the output array will\n    have object dtype.\n\n    >>> df['C'] = pd.date_range('2000', periods=2)\n    >>> df.to_numpy()\n    array([[1, 3.0, Timestamp('2000-01-01 00:00:00')],\n           [2, 4.5, Timestamp('2000-01-02 00:00:00')]], dtype=object)\n    \"\"\"\n    result = np.array(self.values, dtype=dtype, copy=copy)\n    return result",
                            "def to_dict(self, orient='dict', into=dict):\n    \"\"\"\n    Convert the DataFrame to a dictionary.\n\n    The type of the key-value pairs can be customized with the parameters\n    (see below).\n\n    Parameters\n    ----------\n    orient : str {'dict', 'list', 'series', 'split', 'records', 'index'}\n        Determines the type of the values of the dictionary.\n\n        - 'dict' (default) : dict like {column -> {index -> value}}\n        - 'list' : dict like {column -> [values]}\n        - 'series' : dict like {column -> Series(values)}\n        - 'split' : dict like\n          {'index' -> [index], 'columns' -> [columns], 'data' -> [values]}\n        - 'records' : list like\n          [{column -> value}, ... , {column -> value}]\n        - 'index' : dict like {index -> {column -> value}}\n\n        Abbreviations are allowed. `s` indicates `series` and `sp`\n        indicates `split`.\n\n    into : class, default dict\n        The collections.abc.Mapping subclass used for all Mappings\n        in the return value.  Can be the actual class or an empty\n        instance of the mapping type you want.  If you want a\n        collections.defaultdict, you must pass it initialized.\n\n        .. versionadded:: 0.21.0\n\n    Returns\n    -------\n    dict, list or collections.abc.Mapping\n        Return a collections.abc.Mapping object representing the DataFrame.\n        The resulting transformation depends on the `orient` parameter.\n\n    See Also\n    --------\n    DataFrame.from_dict: Create a DataFrame from a dictionary.\n    DataFrame.to_json: Convert a DataFrame to JSON format.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame({'col1': [1, 2],\n    ...                    'col2': [0.5, 0.75]},\n    ...                   index=['row1', 'row2'])\n    >>> df\n          col1  col2\n    row1     1  0.50\n    row2     2  0.75\n    >>> df.to_dict()\n    {'col1': {'row1': 1, 'row2': 2}, 'col2': {'row1': 0.5, 'row2': 0.75}}\n\n    You can specify the return orientation.\n\n    >>> df.to_dict('series')\n    {'col1': row1    1\n             row2    2\n    Name: col1, dtype: int64,\n    'col2': row1    0.50\n            row2    0.75\n    Name: col2, dtype: float64}\n\n    >>> df.to_dict('split')\n    {'index': ['row1', 'row2'], 'columns': ['col1', 'col2'],\n     'data': [[1, 0.5], [2, 0.75]]}\n\n    >>> df.to_dict('records')\n    [{'col1': 1, 'col2': 0.5}, {'col1': 2, 'col2': 0.75}]\n\n    >>> df.to_dict('index')\n    {'row1': {'col1': 1, 'col2': 0.5}, 'row2': {'col1': 2, 'col2': 0.75}}\n\n    You can also specify the mapping type.\n\n    >>> from collections import OrderedDict, defaultdict\n    >>> df.to_dict(into=OrderedDict)\n    OrderedDict([('col1', OrderedDict([('row1', 1), ('row2', 2)])),\n                 ('col2', OrderedDict([('row1', 0.5), ('row2', 0.75)]))])\n\n    If you want a `defaultdict`, you need to initialize it:\n\n    >>> dd = defaultdict(list)\n    >>> df.to_dict('records', into=dd)\n    [defaultdict(<class 'list'>, {'col1': 1, 'col2': 0.5}),\n     defaultdict(<class 'list'>, {'col1': 2, 'col2': 0.75})]\n    \"\"\"\n    if not self.columns.is_unique:\n        warnings.warn('DataFrame columns are not unique, some columns will be omitted.', UserWarning, stacklevel=2)\n    into_c = com.standardize_mapping(into)\n    if orient.lower().startswith('d'):\n        return into_c(((k, v.to_dict(into)) for k, v in self.items()))\n    elif orient.lower().startswith('l'):\n        return into_c(((k, v.tolist()) for k, v in self.items()))\n    elif orient.lower().startswith('sp'):\n        return into_c((('index', self.index.tolist()), ('columns', self.columns.tolist()), ('data', [list(map(com.maybe_box_datetimelike, t)) for t in self.itertuples(index=False, name=None)])))\n    elif orient.lower().startswith('s'):\n        return into_c(((k, com.maybe_box_datetimelike(v)) for k, v in self.items()))\n    elif orient.lower().startswith('r'):\n        columns = self.columns.tolist()\n        rows = (dict(zip(columns, row)) for row in self.itertuples(index=False, name=None))\n        return [into_c(((k, com.maybe_box_datetimelike(v)) for k, v in row.items())) for row in rows]\n    elif orient.lower().startswith('i'):\n        if not self.index.is_unique:\n            raise ValueError(\"DataFrame index must be unique for orient='index'.\")\n        return into_c(((t[0], dict(zip(self.columns, t[1:]))) for t in self.itertuples(name=None)))\n    else:\n        raise ValueError(f\"orient '{orient}' not understood\")",
                            "def to_gbq(self, destination_table, project_id=None, chunksize=None, reauth=False, if_exists='fail', auth_local_webserver=False, table_schema=None, location=None, progress_bar=True, credentials=None) -> None:\n    \"\"\"\n    Write a DataFrame to a Google BigQuery table.\n\n    This function requires the `pandas-gbq package\n    <https://pandas-gbq.readthedocs.io>`__.\n\n    See the `How to authenticate with Google BigQuery\n    <https://pandas-gbq.readthedocs.io/en/latest/howto/authentication.html>`__\n    guide for authentication instructions.\n\n    Parameters\n    ----------\n    destination_table : str\n        Name of table to be written, in the form ``dataset.tablename``.\n    project_id : str, optional\n        Google BigQuery Account project ID. Optional when available from\n        the environment.\n    chunksize : int, optional\n        Number of rows to be inserted in each chunk from the dataframe.\n        Set to ``None`` to load the whole dataframe at once.\n    reauth : bool, default False\n        Force Google BigQuery to re-authenticate the user. This is useful\n        if multiple accounts are used.\n    if_exists : str, default 'fail'\n        Behavior when the destination table exists. Value can be one of:\n\n        ``'fail'``\n            If table exists raise pandas_gbq.gbq.TableCreationError.\n        ``'replace'``\n            If table exists, drop it, recreate it, and insert data.\n        ``'append'``\n            If table exists, insert data. Create if does not exist.\n    auth_local_webserver : bool, default False\n        Use the `local webserver flow`_ instead of the `console flow`_\n        when getting user credentials.\n\n        .. _local webserver flow:\n            https://google-auth-oauthlib.readthedocs.io/en/latest/reference/google_auth_oauthlib.flow.html#google_auth_oauthlib.flow.InstalledAppFlow.run_local_server\n        .. _console flow:\n            https://google-auth-oauthlib.readthedocs.io/en/latest/reference/google_auth_oauthlib.flow.html#google_auth_oauthlib.flow.InstalledAppFlow.run_console\n\n        *New in version 0.2.0 of pandas-gbq*.\n    table_schema : list of dicts, optional\n        List of BigQuery table fields to which according DataFrame\n        columns conform to, e.g. ``[{'name': 'col1', 'type':\n        'STRING'},...]``. If schema is not provided, it will be\n        generated according to dtypes of DataFrame columns. See\n        BigQuery API documentation on available names of a field.\n\n        *New in version 0.3.1 of pandas-gbq*.\n    location : str, optional\n        Location where the load job should run. See the `BigQuery locations\n        documentation\n        <https://cloud.google.com/bigquery/docs/dataset-locations>`__ for a\n        list of available locations. The location must match that of the\n        target dataset.\n\n        *New in version 0.5.0 of pandas-gbq*.\n    progress_bar : bool, default True\n        Use the library `tqdm` to show the progress bar for the upload,\n        chunk by chunk.\n\n        *New in version 0.5.0 of pandas-gbq*.\n    credentials : google.auth.credentials.Credentials, optional\n        Credentials for accessing Google APIs. Use this parameter to\n        override default credentials, such as to use Compute Engine\n        :class:`google.auth.compute_engine.Credentials` or Service\n        Account :class:`google.oauth2.service_account.Credentials`\n        directly.\n\n        *New in version 0.8.0 of pandas-gbq*.\n\n        .. versionadded:: 0.24.0\n\n    See Also\n    --------\n    pandas_gbq.to_gbq : This function in the pandas-gbq library.\n    read_gbq : Read a DataFrame from Google BigQuery.\n    \"\"\"\n    from pandas.io import gbq\n    gbq.to_gbq(self, destination_table, project_id=project_id, chunksize=chunksize, reauth=reauth, if_exists=if_exists, auth_local_webserver=auth_local_webserver, table_schema=table_schema, location=location, progress_bar=progress_bar, credentials=credentials)",
                            "@classmethod\ndef from_records(cls, data, index=None, exclude=None, columns=None, coerce_float=False, nrows=None) -> 'DataFrame':\n    \"\"\"\n    Convert structured or record ndarray to DataFrame.\n\n    Parameters\n    ----------\n    data : ndarray (structured dtype), list of tuples, dict, or DataFrame\n    index : str, list of fields, array-like\n        Field of array to use as the index, alternately a specific set of\n        input labels to use.\n    exclude : sequence, default None\n        Columns or fields to exclude.\n    columns : sequence, default None\n        Column names to use. If the passed data do not have names\n        associated with them, this argument provides names for the\n        columns. Otherwise this argument indicates the order of the columns\n        in the result (any names not found in the data will become all-NA\n        columns).\n    coerce_float : bool, default False\n        Attempt to convert values of non-string, non-numeric objects (like\n        decimal.Decimal) to floating point, useful for SQL result sets.\n    nrows : int, default None\n        Number of rows to read if data is an iterator.\n\n    Returns\n    -------\n    DataFrame\n    \"\"\"\n    if columns is not None:\n        columns = ensure_index(columns)\n    if is_iterator(data):\n        if nrows == 0:\n            return cls()\n        try:\n            first_row = next(data)\n        except StopIteration:\n            return cls(index=index, columns=columns)\n        dtype = None\n        if hasattr(first_row, 'dtype') and first_row.dtype.names:\n            dtype = first_row.dtype\n        values = [first_row]\n        if nrows is None:\n            values += data\n        else:\n            values.extend(itertools.islice(data, nrows - 1))\n        if dtype is not None:\n            data = np.array(values, dtype=dtype)\n        else:\n            data = values\n    if isinstance(data, dict):\n        if columns is None:\n            columns = arr_columns = ensure_index(sorted(data))\n            arrays = [data[k] for k in columns]\n        else:\n            arrays = []\n            arr_columns = []\n            for k, v in data.items():\n                if k in columns:\n                    arr_columns.append(k)\n                    arrays.append(v)\n            arrays, arr_columns = reorder_arrays(arrays, arr_columns, columns)\n    elif isinstance(data, (np.ndarray, DataFrame)):\n        arrays, columns = to_arrays(data, columns)\n        if columns is not None:\n            columns = ensure_index(columns)\n        arr_columns = columns\n    else:\n        arrays, arr_columns = to_arrays(data, columns, coerce_float=coerce_float)\n        arr_columns = ensure_index(arr_columns)\n        if columns is not None:\n            columns = ensure_index(columns)\n        else:\n            columns = arr_columns\n    if exclude is None:\n        exclude = set()\n    else:\n        exclude = set(exclude)\n    result_index = None\n    if index is not None:\n        if isinstance(index, str) or not hasattr(index, '__iter__'):\n            i = columns.get_loc(index)\n            exclude.add(index)\n            if len(arrays) > 0:\n                result_index = Index(arrays[i], name=index)\n            else:\n                result_index = Index([], name=index)\n        else:\n            try:\n                index_data = [arrays[arr_columns.get_loc(field)] for field in index]\n            except (KeyError, TypeError):\n                result_index = index\n            else:\n                result_index = ensure_index_from_sequences(index_data, names=index)\n                exclude.update(index)\n    if any(exclude):\n        arr_exclude = [x for x in exclude if x in arr_columns]\n        to_remove = [arr_columns.get_loc(col) for col in arr_exclude]\n        arrays = [v for i, v in enumerate(arrays) if i not in to_remove]\n        arr_columns = arr_columns.drop(arr_exclude)\n        columns = columns.drop(exclude)\n    mgr = arrays_to_mgr(arrays, arr_columns, result_index, columns)\n    return cls(mgr)",
                            "def to_records(self, index=True, column_dtypes=None, index_dtypes=None) -> np.recarray:\n    \"\"\"\n    Convert DataFrame to a NumPy record array.\n\n    Index will be included as the first field of the record array if\n    requested.\n\n    Parameters\n    ----------\n    index : bool, default True\n        Include index in resulting record array, stored in 'index'\n        field or using the index label, if set.\n    column_dtypes : str, type, dict, default None\n        .. versionadded:: 0.24.0\n\n        If a string or type, the data type to store all columns. If\n        a dictionary, a mapping of column names and indices (zero-indexed)\n        to specific data types.\n    index_dtypes : str, type, dict, default None\n        .. versionadded:: 0.24.0\n\n        If a string or type, the data type to store all index levels. If\n        a dictionary, a mapping of index level names and indices\n        (zero-indexed) to specific data types.\n\n        This mapping is applied only if `index=True`.\n\n    Returns\n    -------\n    numpy.recarray\n        NumPy ndarray with the DataFrame labels as fields and each row\n        of the DataFrame as entries.\n\n    See Also\n    --------\n    DataFrame.from_records: Convert structured or record ndarray\n        to DataFrame.\n    numpy.recarray: An ndarray that allows field access using\n        attributes, analogous to typed columns in a\n        spreadsheet.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame({'A': [1, 2], 'B': [0.5, 0.75]},\n    ...                   index=['a', 'b'])\n    >>> df\n       A     B\n    a  1  0.50\n    b  2  0.75\n    >>> df.to_records()\n    rec.array([('a', 1, 0.5 ), ('b', 2, 0.75)],\n              dtype=[('index', 'O'), ('A', '<i8'), ('B', '<f8')])\n\n    If the DataFrame index has no label then the recarray field name\n    is set to 'index'. If the index has a label then this is used as the\n    field name:\n\n    >>> df.index = df.index.rename(\"I\")\n    >>> df.to_records()\n    rec.array([('a', 1, 0.5 ), ('b', 2, 0.75)],\n              dtype=[('I', 'O'), ('A', '<i8'), ('B', '<f8')])\n\n    The index can be excluded from the record array:\n\n    >>> df.to_records(index=False)\n    rec.array([(1, 0.5 ), (2, 0.75)],\n              dtype=[('A', '<i8'), ('B', '<f8')])\n\n    Data types can be specified for the columns:\n\n    >>> df.to_records(column_dtypes={\"A\": \"int32\"})\n    rec.array([('a', 1, 0.5 ), ('b', 2, 0.75)],\n              dtype=[('I', 'O'), ('A', '<i4'), ('B', '<f8')])\n\n    As well as for the index:\n\n    >>> df.to_records(index_dtypes=\"<S2\")\n    rec.array([(b'a', 1, 0.5 ), (b'b', 2, 0.75)],\n              dtype=[('I', 'S2'), ('A', '<i8'), ('B', '<f8')])\n\n    >>> index_dtypes = f\"<S{df.index.str.len().max()}\"\n    >>> df.to_records(index_dtypes=index_dtypes)\n    rec.array([(b'a', 1, 0.5 ), (b'b', 2, 0.75)],\n              dtype=[('I', 'S1'), ('A', '<i8'), ('B', '<f8')])\n    \"\"\"\n    if index:\n        if isinstance(self.index, ABCMultiIndex):\n            ix_vals = list(map(np.array, zip(*self.index.values)))\n        else:\n            ix_vals = [self.index.values]\n        arrays = ix_vals + [self[c]._internal_get_values() for c in self.columns]\n        count = 0\n        index_names = list(self.index.names)\n        if isinstance(self.index, ABCMultiIndex):\n            for i, n in enumerate(index_names):\n                if n is None:\n                    index_names[i] = f'level_{count}'\n                    count += 1\n        elif index_names[0] is None:\n            index_names = ['index']\n        names = [str(name) for name in itertools.chain(index_names, self.columns)]\n    else:\n        arrays = [self[c]._internal_get_values() for c in self.columns]\n        names = [str(c) for c in self.columns]\n        index_names = []\n    index_len = len(index_names)\n    formats = []\n    for i, v in enumerate(arrays):\n        index = i\n        if index < index_len:\n            dtype_mapping = index_dtypes\n            name = index_names[index]\n        else:\n            index -= index_len\n            dtype_mapping = column_dtypes\n            name = self.columns[index]\n        if is_dict_like(dtype_mapping):\n            if name in dtype_mapping:\n                dtype_mapping = dtype_mapping[name]\n            elif index in dtype_mapping:\n                dtype_mapping = dtype_mapping[index]\n            else:\n                dtype_mapping = None\n        if dtype_mapping is None:\n            formats.append(v.dtype)\n        elif isinstance(dtype_mapping, (type, np.dtype, str)):\n            formats.append(dtype_mapping)\n        else:\n            element = 'row' if i < index_len else 'column'\n            msg = f'Invalid dtype {dtype_mapping} specified for {element} {name}'\n            raise ValueError(msg)\n    return np.rec.fromarrays(arrays, dtype={'names': names, 'formats': formats})",
                            "@classmethod\ndef _from_arrays(cls, arrays, columns, index, dtype=None) -> 'DataFrame':\n    mgr = arrays_to_mgr(arrays, columns, index, columns, dtype=dtype)\n    return cls(mgr)",
                            "@deprecate_kwarg(old_arg_name='fname', new_arg_name='path')\ndef to_stata(self, path: FilePathOrBuffer, convert_dates: Optional[Dict[Label, str]]=None, write_index: bool=True, byteorder: Optional[str]=None, time_stamp: Optional[datetime.datetime]=None, data_label: Optional[str]=None, variable_labels: Optional[Dict[Label, str]]=None, version: Optional[int]=114, convert_strl: Optional[Sequence[Label]]=None) -> None:\n    \"\"\"\n    Export DataFrame object to Stata dta format.\n\n    Writes the DataFrame to a Stata dataset file.\n    \"dta\" files contain a Stata dataset.\n\n    Parameters\n    ----------\n    path : str, buffer or path object\n        String, path object (pathlib.Path or py._path.local.LocalPath) or\n        object implementing a binary write() function. If using a buffer\n        then the buffer will not be automatically closed after the file\n        data has been written.\n\n        .. versionchanged:: 1.0.0\n\n        Previously this was \"fname\"\n\n    convert_dates : dict\n        Dictionary mapping columns containing datetime types to stata\n        internal format to use when writing the dates. Options are 'tc',\n        'td', 'tm', 'tw', 'th', 'tq', 'ty'. Column can be either an integer\n        or a name. Datetime columns that do not have a conversion type\n        specified will be converted to 'tc'. Raises NotImplementedError if\n        a datetime column has timezone information.\n    write_index : bool\n        Write the index to Stata dataset.\n    byteorder : str\n        Can be \">\", \"<\", \"little\", or \"big\". default is `sys.byteorder`.\n    time_stamp : datetime\n        A datetime to use as file creation date.  Default is the current\n        time.\n    data_label : str, optional\n        A label for the data set.  Must be 80 characters or smaller.\n    variable_labels : dict\n        Dictionary containing columns as keys and variable labels as\n        values. Each label must be 80 characters or smaller.\n    version : {114, 117, 118, 119, None}, default 114\n        Version to use in the output dta file. Set to None to let pandas\n        decide between 118 or 119 formats depending on the number of\n        columns in the frame. Version 114 can be read by Stata 10 and\n        later. Version 117 can be read by Stata 13 or later. Version 118\n        is supported in Stata 14 and later. Version 119 is supported in\n        Stata 15 and later. Version 114 limits string variables to 244\n        characters or fewer while versions 117 and later allow strings\n        with lengths up to 2,000,000 characters. Versions 118 and 119\n        support Unicode characters, and version 119 supports more than\n        32,767 variables.\n\n        .. versionadded:: 0.23.0\n        .. versionchanged:: 1.0.0\n\n            Added support for formats 118 and 119.\n\n    convert_strl : list, optional\n        List of column names to convert to string columns to Stata StrL\n        format. Only available if version is 117.  Storing strings in the\n        StrL format can produce smaller dta files if strings have more than\n        8 characters and values are repeated.\n\n        .. versionadded:: 0.23.0\n\n    Raises\n    ------\n    NotImplementedError\n        * If datetimes contain timezone information\n        * Column dtype is not representable in Stata\n    ValueError\n        * Columns listed in convert_dates are neither datetime64[ns]\n          or datetime.datetime\n        * Column listed in convert_dates is not in DataFrame\n        * Categorical label contains more than 32,000 characters\n\n    See Also\n    --------\n    read_stata : Import Stata data files.\n    io.stata.StataWriter : Low-level writer for Stata data files.\n    io.stata.StataWriter117 : Low-level writer for version 117 files.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame({'animal': ['falcon', 'parrot', 'falcon',\n    ...                               'parrot'],\n    ...                    'speed': [350, 18, 361, 15]})\n    >>> df.to_stata('animals.dta')  # doctest: +SKIP\n    \"\"\"\n    if version not in (114, 117, 118, 119, None):\n        raise ValueError('Only formats 114, 117, 118 and 119 are supported.')\n    if version == 114:\n        if convert_strl is not None:\n            raise ValueError('strl is not supported in format 114')\n        from pandas.io.stata import StataWriter as statawriter\n    elif version == 117:\n        from pandas.io.stata import StataWriter117 as statawriter\n    else:\n        from pandas.io.stata import StataWriterUTF8 as statawriter\n    kwargs: Dict[str, Any] = {}\n    if version is None or version >= 117:\n        kwargs['convert_strl'] = convert_strl\n    if version is None or version >= 118:\n        kwargs['version'] = version\n    writer = statawriter(path, self, convert_dates=convert_dates, byteorder=byteorder, time_stamp=time_stamp, data_label=data_label, write_index=write_index, variable_labels=variable_labels, **kwargs)\n    writer.write_file()",
                            "@deprecate_kwarg(old_arg_name='fname', new_arg_name='path')\ndef to_feather(self, path) -> None:\n    \"\"\"\n    Write out the binary feather-format for DataFrames.\n\n    Parameters\n    ----------\n    path : str\n        String file path.\n    \"\"\"\n    from pandas.io.feather_format import to_feather\n    to_feather(self, path)",
                            "@Appender('\\n        Examples\\n        --------\\n        >>> df = pd.DataFrame(\\n        ...     data={\"animal_1\": [\"elk\", \"pig\"], \"animal_2\": [\"dog\", \"quetzal\"]}\\n        ... )\\n        >>> print(df.to_markdown())\\n        |    | animal_1   | animal_2   |\\n        |---:|:-----------|:-----------|\\n        |  0 | elk        | dog        |\\n        |  1 | pig        | quetzal    |\\n        ')\n@Substitution(klass='DataFrame')\n@Appender(_shared_docs['to_markdown'])\ndef to_markdown(self, buf: Optional[IO[str]]=None, mode: Optional[str]=None, **kwargs) -> Optional[str]:\n    kwargs.setdefault('headers', 'keys')\n    kwargs.setdefault('tablefmt', 'pipe')\n    tabulate = import_optional_dependency('tabulate')\n    result = tabulate.tabulate(self, **kwargs)\n    if buf is None:\n        return result\n    buf, _, _, _ = get_filepath_or_buffer(buf, mode=mode)\n    assert buf is not None\n    buf.writelines(result)\n    return None",
                            "@deprecate_kwarg(old_arg_name='fname', new_arg_name='path')\ndef to_parquet(self, path, engine='auto', compression='snappy', index=None, partition_cols=None, **kwargs) -> None:\n    \"\"\"\n    Write a DataFrame to the binary parquet format.\n\n    .. versionadded:: 0.21.0\n\n    This function writes the dataframe as a `parquet file\n    <https://parquet.apache.org/>`_. You can choose different parquet\n    backends, and have the option of compression. See\n    :ref:`the user guide <io.parquet>` for more details.\n\n    Parameters\n    ----------\n    path : str\n        File path or Root Directory path. Will be used as Root Directory\n        path while writing a partitioned dataset.\n\n        .. versionchanged:: 1.0.0\n\n        Previously this was \"fname\"\n\n    engine : {'auto', 'pyarrow', 'fastparquet'}, default 'auto'\n        Parquet library to use. If 'auto', then the option\n        ``io.parquet.engine`` is used. The default ``io.parquet.engine``\n        behavior is to try 'pyarrow', falling back to 'fastparquet' if\n        'pyarrow' is unavailable.\n    compression : {'snappy', 'gzip', 'brotli', None}, default 'snappy'\n        Name of the compression to use. Use ``None`` for no compression.\n    index : bool, default None\n        If ``True``, include the dataframe's index(es) in the file output.\n        If ``False``, they will not be written to the file.\n        If ``None``, similar to ``True`` the dataframe's index(es)\n        will be saved. However, instead of being saved as values,\n        the RangeIndex will be stored as a range in the metadata so it\n        doesn't require much space and is faster. Other indexes will\n        be included as columns in the file output.\n\n        .. versionadded:: 0.24.0\n\n    partition_cols : list, optional, default None\n        Column names by which to partition the dataset.\n        Columns are partitioned in the order they are given.\n\n        .. versionadded:: 0.24.0\n\n    **kwargs\n        Additional arguments passed to the parquet library. See\n        :ref:`pandas io <io.parquet>` for more details.\n\n    See Also\n    --------\n    read_parquet : Read a parquet file.\n    DataFrame.to_csv : Write a csv file.\n    DataFrame.to_sql : Write to a sql table.\n    DataFrame.to_hdf : Write to hdf.\n\n    Notes\n    -----\n    This function requires either the `fastparquet\n    <https://pypi.org/project/fastparquet>`_ or `pyarrow\n    <https://arrow.apache.org/docs/python/>`_ library.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame(data={'col1': [1, 2], 'col2': [3, 4]})\n    >>> df.to_parquet('df.parquet.gzip',\n    ...               compression='gzip')  # doctest: +SKIP\n    >>> pd.read_parquet('df.parquet.gzip')  # doctest: +SKIP\n       col1  col2\n    0     1     3\n    1     2     4\n    \"\"\"\n    from pandas.io.parquet import to_parquet\n    to_parquet(self, path, engine, compression=compression, index=index, partition_cols=partition_cols, **kwargs)",
                            "@Substitution(header_type='bool', header='Whether to print column labels, default True', col_space_type='str or int', col_space='The minimum width of each column in CSS length units.  An int is assumed to be px units.\\n\\n            .. versionadded:: 0.25.0\\n                Ability to use str')\n@Substitution(shared_params=fmt.common_docstring, returns=fmt.return_docstring)\ndef to_html(self, buf=None, columns=None, col_space=None, header=True, index=True, na_rep='NaN', formatters=None, float_format=None, sparsify=None, index_names=True, justify=None, max_rows=None, max_cols=None, show_dimensions=False, decimal='.', bold_rows=True, classes=None, escape=True, notebook=False, border=None, table_id=None, render_links=False, encoding=None):\n    \"\"\"\n    Render a DataFrame as an HTML table.\n    %(shared_params)s\n    bold_rows : bool, default True\n        Make the row labels bold in the output.\n    classes : str or list or tuple, default None\n        CSS class(es) to apply to the resulting html table.\n    escape : bool, default True\n        Convert the characters <, >, and & to HTML-safe sequences.\n    notebook : {True, False}, default False\n        Whether the generated HTML is for IPython Notebook.\n    border : int\n        A ``border=border`` attribute is included in the opening\n        `<table>` tag. Default ``pd.options.display.html.border``.\n    encoding : str, default \"utf-8\"\n        Set character encoding.\n\n        .. versionadded:: 1.0\n\n    table_id : str, optional\n        A css id is included in the opening `<table>` tag if specified.\n\n        .. versionadded:: 0.23.0\n\n    render_links : bool, default False\n        Convert URLs to HTML links.\n\n        .. versionadded:: 0.24.0\n    %(returns)s\n    See Also\n    --------\n    to_string : Convert DataFrame to a string.\n    \"\"\"\n    if justify is not None and justify not in fmt._VALID_JUSTIFY_PARAMETERS:\n        raise ValueError('Invalid value for justify parameter')\n    formatter = fmt.DataFrameFormatter(self, columns=columns, col_space=col_space, na_rep=na_rep, formatters=formatters, float_format=float_format, sparsify=sparsify, justify=justify, index_names=index_names, header=header, index=index, bold_rows=bold_rows, escape=escape, max_rows=max_rows, max_cols=max_cols, show_dimensions=show_dimensions, decimal=decimal, table_id=table_id, render_links=render_links)\n    return formatter.to_html(buf=buf, classes=classes, notebook=notebook, border=border, encoding=encoding)",
                            "@Appender(info.__doc__)\ndef info(self, verbose=None, buf=None, max_cols=None, memory_usage=None, null_counts=None) -> None:\n    return info(self, verbose, buf, max_cols, memory_usage, null_counts)",
                            "def memory_usage(self, index=True, deep=False) -> Series:\n    \"\"\"\n    Return the memory usage of each column in bytes.\n\n    The memory usage can optionally include the contribution of\n    the index and elements of `object` dtype.\n\n    This value is displayed in `DataFrame.info` by default. This can be\n    suppressed by setting ``pandas.options.display.memory_usage`` to False.\n\n    Parameters\n    ----------\n    index : bool, default True\n        Specifies whether to include the memory usage of the DataFrame's\n        index in returned Series. If ``index=True``, the memory usage of\n        the index is the first item in the output.\n    deep : bool, default False\n        If True, introspect the data deeply by interrogating\n        `object` dtypes for system-level memory consumption, and include\n        it in the returned values.\n\n    Returns\n    -------\n    Series\n        A Series whose index is the original column names and whose values\n        is the memory usage of each column in bytes.\n\n    See Also\n    --------\n    numpy.ndarray.nbytes : Total bytes consumed by the elements of an\n        ndarray.\n    Series.memory_usage : Bytes consumed by a Series.\n    Categorical : Memory-efficient array for string values with\n        many repeated values.\n    DataFrame.info : Concise summary of a DataFrame.\n\n    Examples\n    --------\n    >>> dtypes = ['int64', 'float64', 'complex128', 'object', 'bool']\n    >>> data = dict([(t, np.ones(shape=5000).astype(t))\n    ...              for t in dtypes])\n    >>> df = pd.DataFrame(data)\n    >>> df.head()\n       int64  float64            complex128  object  bool\n    0      1      1.0    1.000000+0.000000j       1  True\n    1      1      1.0    1.000000+0.000000j       1  True\n    2      1      1.0    1.000000+0.000000j       1  True\n    3      1      1.0    1.000000+0.000000j       1  True\n    4      1      1.0    1.000000+0.000000j       1  True\n\n    >>> df.memory_usage()\n    Index           128\n    int64         40000\n    float64       40000\n    complex128    80000\n    object        40000\n    bool           5000\n    dtype: int64\n\n    >>> df.memory_usage(index=False)\n    int64         40000\n    float64       40000\n    complex128    80000\n    object        40000\n    bool           5000\n    dtype: int64\n\n    The memory footprint of `object` dtype columns is ignored by default:\n\n    >>> df.memory_usage(deep=True)\n    Index            128\n    int64          40000\n    float64        40000\n    complex128     80000\n    object        160000\n    bool            5000\n    dtype: int64\n\n    Use a Categorical for efficient storage of an object-dtype column with\n    many repeated values.\n\n    >>> df['object'].astype('category').memory_usage(deep=True)\n    5216\n    \"\"\"\n    result = Series([c.memory_usage(index=False, deep=deep) for col, c in self.items()], index=self.columns)\n    if index:\n        result = Series(self.index.memory_usage(deep=deep), index=['Index']).append(result)\n    return result",
                            "def transpose(self, *args, copy: bool=False) -> 'DataFrame':\n    \"\"\"\n    Transpose index and columns.\n\n    Reflect the DataFrame over its main diagonal by writing rows as columns\n    and vice-versa. The property :attr:`.T` is an accessor to the method\n    :meth:`transpose`.\n\n    Parameters\n    ----------\n    *args : tuple, optional\n        Accepted for compatibility with NumPy.\n    copy : bool, default False\n        Whether to copy the data after transposing, even for DataFrames\n        with a single dtype.\n\n        Note that a copy is always required for mixed dtype DataFrames,\n        or for DataFrames with any extension types.\n\n    Returns\n    -------\n    DataFrame\n        The transposed DataFrame.\n\n    See Also\n    --------\n    numpy.transpose : Permute the dimensions of a given array.\n\n    Notes\n    -----\n    Transposing a DataFrame with mixed dtypes will result in a homogeneous\n    DataFrame with the `object` dtype. In such a case, a copy of the data\n    is always made.\n\n    Examples\n    --------\n    **Square DataFrame with homogeneous dtype**\n\n    >>> d1 = {'col1': [1, 2], 'col2': [3, 4]}\n    >>> df1 = pd.DataFrame(data=d1)\n    >>> df1\n       col1  col2\n    0     1     3\n    1     2     4\n\n    >>> df1_transposed = df1.T # or df1.transpose()\n    >>> df1_transposed\n          0  1\n    col1  1  2\n    col2  3  4\n\n    When the dtype is homogeneous in the original DataFrame, we get a\n    transposed DataFrame with the same dtype:\n\n    >>> df1.dtypes\n    col1    int64\n    col2    int64\n    dtype: object\n    >>> df1_transposed.dtypes\n    0    int64\n    1    int64\n    dtype: object\n\n    **Non-square DataFrame with mixed dtypes**\n\n    >>> d2 = {'name': ['Alice', 'Bob'],\n    ...       'score': [9.5, 8],\n    ...       'employed': [False, True],\n    ...       'kids': [0, 0]}\n    >>> df2 = pd.DataFrame(data=d2)\n    >>> df2\n        name  score  employed  kids\n    0  Alice    9.5     False     0\n    1    Bob    8.0      True     0\n\n    >>> df2_transposed = df2.T # or df2.transpose()\n    >>> df2_transposed\n                  0     1\n    name      Alice   Bob\n    score       9.5     8\n    employed  False  True\n    kids          0     0\n\n    When the DataFrame has mixed dtypes, we get a transposed DataFrame with\n    the `object` dtype:\n\n    >>> df2.dtypes\n    name         object\n    score       float64\n    employed       bool\n    kids          int64\n    dtype: object\n    >>> df2_transposed.dtypes\n    0    object\n    1    object\n    dtype: object\n    \"\"\"\n    nv.validate_transpose(args, dict())\n    dtypes = list(self.dtypes)\n    if self._is_homogeneous_type and dtypes and is_extension_array_dtype(dtypes[0]):\n        dtype = dtypes[0]\n        arr_type = dtype.construct_array_type()\n        values = self.values\n        new_values = [arr_type._from_sequence(row, dtype=dtype) for row in values]\n        result = self._constructor(dict(zip(self.index, new_values)), index=self.columns)\n    else:\n        new_values = self.values.T\n        if copy:\n            new_values = new_values.copy()\n        result = self._constructor(new_values, index=self.columns, columns=self.index)\n    return result.__finalize__(self)",
                            "@property\ndef T(self) -> 'DataFrame':\n    return self.transpose()",
                            "def _ixs(self, i: int, axis: int=0):\n    \"\"\"\n    Parameters\n    ----------\n    i : int\n    axis : int\n\n    Notes\n    -----\n    If slice passed, the resulting data will be a view.\n    \"\"\"\n    if axis == 0:\n        new_values = self._data.fast_xs(i)\n        copy = isinstance(new_values, np.ndarray) and new_values.base is None\n        result = self._constructor_sliced(new_values, index=self.columns, name=self.index[i], dtype=new_values.dtype)\n        result._set_is_copy(self, copy=copy)\n        return result\n    else:\n        label = self.columns[i]\n        values = self._data.iget(i)\n        result = self._box_col_values(values, label)\n        result._set_as_cached(label, self)\n        return result",
                            "def __getitem__(self, key):\n    key = lib.item_from_zerodim(key)\n    key = com.apply_if_callable(key, self)\n    if is_hashable(key):\n        if self.columns.is_unique and key in self.columns:\n            if self.columns.nlevels > 1:\n                return self._getitem_multilevel(key)\n            return self._get_item_cache(key)\n    indexer = convert_to_index_sliceable(self, key)\n    if indexer is not None:\n        return self._slice(indexer, axis=0)\n    if isinstance(key, DataFrame):\n        return self.where(key)\n    if com.is_bool_indexer(key):\n        return self._getitem_bool_array(key)\n    is_single_key = isinstance(key, tuple) or not is_list_like(key)\n    if is_single_key:\n        if self.columns.nlevels > 1:\n            return self._getitem_multilevel(key)\n        indexer = self.columns.get_loc(key)\n        if is_integer(indexer):\n            indexer = [indexer]\n    else:\n        if is_iterator(key):\n            key = list(key)\n        indexer = self.loc._get_listlike_indexer(key, axis=1, raise_missing=True)[1]\n    if getattr(indexer, 'dtype', None) == bool:\n        indexer = np.where(indexer)[0]\n    data = self._take_with_is_copy(indexer, axis=1)\n    if is_single_key:\n        if data.shape[1] == 1 and (not isinstance(self.columns, ABCMultiIndex)):\n            data = data[key]\n    return data",
                            "def _getitem_bool_array(self, key):\n    if isinstance(key, Series) and (not key.index.equals(self.index)):\n        warnings.warn('Boolean Series key will be reindexed to match DataFrame index.', UserWarning, stacklevel=3)\n    elif len(key) != len(self.index):\n        raise ValueError(f'Item wrong length {len(key)} instead of {len(self.index)}.')\n    key = check_bool_indexer(self.index, key)\n    indexer = key.nonzero()[0]\n    return self._take_with_is_copy(indexer, axis=0)",
                            "def _getitem_multilevel(self, key):\n    loc = self.columns.get_loc(key)\n    if isinstance(loc, (slice, Series, np.ndarray, Index)):\n        new_columns = self.columns[loc]\n        result_columns = maybe_droplevels(new_columns, key)\n        if self._is_mixed_type:\n            result = self.reindex(columns=new_columns)\n            result.columns = result_columns\n        else:\n            new_values = self.values[:, loc]\n            result = self._constructor(new_values, index=self.index, columns=result_columns)\n            result = result.__finalize__(self)\n        if len(result.columns) == 1:\n            top = result.columns[0]\n            if isinstance(top, tuple):\n                top = top[0]\n            if top == '':\n                result = result['']\n                if isinstance(result, Series):\n                    result = self._constructor_sliced(result, index=self.index, name=key)\n        result._set_is_copy(self)\n        return result\n    else:\n        return self._get_item_cache(key)",
                            "def _get_value(self, index, col, takeable: bool=False):\n    \"\"\"\n    Quickly retrieve single value at passed column and index.\n\n    Parameters\n    ----------\n    index : row label\n    col : column label\n    takeable : interpret the index/col as indexers, default False\n\n    Returns\n    -------\n    scalar\n    \"\"\"\n    if takeable:\n        series = self._ixs(col, axis=1)\n        return series._values[index]\n    series = self._get_item_cache(col)\n    engine = self.index._engine\n    try:\n        loc = engine.get_loc(index)\n        return series._values[loc]\n    except KeyError:\n        if self.index.nlevels > 1:\n            raise\n    col = self.columns.get_loc(col)\n    index = self.index.get_loc(index)\n    return self._get_value(index, col, takeable=True)",
                            "def __setitem__(self, key, value):\n    key = com.apply_if_callable(key, self)\n    indexer = convert_to_index_sliceable(self, key)\n    if indexer is not None:\n        return self._setitem_slice(indexer, value)\n    if isinstance(key, DataFrame) or getattr(key, 'ndim', None) == 2:\n        self._setitem_frame(key, value)\n    elif isinstance(key, (Series, np.ndarray, list, Index)):\n        self._setitem_array(key, value)\n    else:\n        self._set_item(key, value)",
                            "def _setitem_slice(self, key: slice, value):\n    self._check_setitem_copy()\n    self.iloc._setitem_with_indexer(key, value)",
                            "def _setitem_array(self, key, value):\n    if com.is_bool_indexer(key):\n        if len(key) != len(self.index):\n            raise ValueError(f'Item wrong length {len(key)} instead of {len(self.index)}!')\n        key = check_bool_indexer(self.index, key)\n        indexer = key.nonzero()[0]\n        self._check_setitem_copy()\n        self.iloc._setitem_with_indexer(indexer, value)\n    elif isinstance(value, DataFrame):\n        if len(value.columns) != len(key):\n            raise ValueError('Columns must be same length as key')\n        for k1, k2 in zip(key, value.columns):\n            self[k1] = value[k2]\n    else:\n        indexer = self.loc._get_listlike_indexer(key, axis=1, raise_missing=False)[1]\n        self._check_setitem_copy()\n        self.iloc._setitem_with_indexer((slice(None), indexer), value)",
                            "def _setitem_frame(self, key, value):\n    if isinstance(key, np.ndarray):\n        if key.shape != self.shape:\n            raise ValueError('Array conditional must be same shape as self')\n        key = self._constructor(key, **self._construct_axes_dict())\n    if key.values.size and (not is_bool_dtype(key.values)):\n        raise TypeError('Must pass DataFrame or 2-d ndarray with boolean values only')\n    self._check_inplace_setting(value)\n    self._check_setitem_copy()\n    self._where(-key, value, inplace=True)",
                            "def _iset_item(self, loc: int, value):\n    self._ensure_valid_index(value)\n    value = self._sanitize_column(loc, value, broadcast=False)\n    NDFrame._iset_item(self, loc, value)\n    if len(self):\n        self._check_setitem_copy()",
                            "def _set_item(self, key, value):\n    \"\"\"\n    Add series to DataFrame in specified column.\n\n    If series is a numpy-array (not a Series/TimeSeries), it must be the\n    same length as the DataFrames index or an error will be thrown.\n\n    Series/TimeSeries will be conformed to the DataFrames index to\n    ensure homogeneity.\n    \"\"\"\n    self._ensure_valid_index(value)\n    value = self._sanitize_column(key, value)\n    NDFrame._set_item(self, key, value)\n    if len(self):\n        self._check_setitem_copy()",
                            "def _set_value(self, index, col, value, takeable: bool=False):\n    \"\"\"\n    Put single value at passed column and index.\n\n    Parameters\n    ----------\n    index : row label\n    col : column label\n    value : scalar\n    takeable : interpret the index/col as indexers, default False\n    \"\"\"\n    try:\n        if takeable is True:\n            series = self._ixs(col, axis=1)\n            series._set_value(index, value, takeable=True)\n            return\n        series = self._get_item_cache(col)\n        engine = self.index._engine\n        loc = engine.get_loc(index)\n        validate_numeric_casting(series.dtype, value)\n        series._values[loc] = value\n    except (KeyError, TypeError):\n        if takeable:\n            self.iloc[index, col] = value\n        else:\n            self.loc[index, col] = value\n        self._item_cache.pop(col, None)",
                            "def _ensure_valid_index(self, value):\n    \"\"\"\n    Ensure that if we don't have an index, that we can create one from the\n    passed value.\n    \"\"\"\n    if not len(self.index) and is_list_like(value) and len(value):\n        try:\n            value = Series(value)\n        except (ValueError, NotImplementedError, TypeError) as err:\n            raise ValueError('Cannot set a frame with no defined index and a value that cannot be converted to a Series') from err\n        self._data = self._data.reindex_axis(value.index.copy(), axis=1, fill_value=np.nan)",
                            "def _box_item_values(self, key, values):\n    items = self.columns[self.columns.get_loc(key)]\n    if values.ndim == 2:\n        return self._constructor(values.T, columns=items, index=self.index)\n    else:\n        return self._box_col_values(values, items)",
                            "def _box_col_values(self, values, items):\n    \"\"\"\n    Provide boxed values for a column.\n    \"\"\"\n    klass = self._constructor_sliced\n    return klass(values, index=self.index, name=items, fastpath=True)",
                            "def query(self, expr, inplace=False, **kwargs):\n    \"\"\"\n    Query the columns of a DataFrame with a boolean expression.\n\n    Parameters\n    ----------\n    expr : str\n        The query string to evaluate.\n\n        You can refer to variables\n        in the environment by prefixing them with an '@' character like\n        ``@a + b``.\n\n        You can refer to column names that contain spaces or operators by\n        surrounding them in backticks. This way you can also escape\n        names that start with a digit, or those that  are a Python keyword.\n        Basically when it is not valid Python identifier. See notes down\n        for more details.\n\n        For example, if one of your columns is called ``a a`` and you want\n        to sum it with ``b``, your query should be ```a a` + b``.\n\n        .. versionadded:: 0.25.0\n            Backtick quoting introduced.\n\n        .. versionadded:: 1.0.0\n            Expanding functionality of backtick quoting for more than only spaces.\n\n    inplace : bool\n        Whether the query should modify the data in place or return\n        a modified copy.\n    **kwargs\n        See the documentation for :func:`eval` for complete details\n        on the keyword arguments accepted by :meth:`DataFrame.query`.\n\n    Returns\n    -------\n    DataFrame\n        DataFrame resulting from the provided query expression.\n\n    See Also\n    --------\n    eval : Evaluate a string describing operations on\n        DataFrame columns.\n    DataFrame.eval : Evaluate a string describing operations on\n        DataFrame columns.\n\n    Notes\n    -----\n    The result of the evaluation of this expression is first passed to\n    :attr:`DataFrame.loc` and if that fails because of a\n    multidimensional key (e.g., a DataFrame) then the result will be passed\n    to :meth:`DataFrame.__getitem__`.\n\n    This method uses the top-level :func:`eval` function to\n    evaluate the passed query.\n\n    The :meth:`~pandas.DataFrame.query` method uses a slightly\n    modified Python syntax by default. For example, the ``&`` and ``|``\n    (bitwise) operators have the precedence of their boolean cousins,\n    :keyword:`and` and :keyword:`or`. This *is* syntactically valid Python,\n    however the semantics are different.\n\n    You can change the semantics of the expression by passing the keyword\n    argument ``parser='python'``. This enforces the same semantics as\n    evaluation in Python space. Likewise, you can pass ``engine='python'``\n    to evaluate an expression using Python itself as a backend. This is not\n    recommended as it is inefficient compared to using ``numexpr`` as the\n    engine.\n\n    The :attr:`DataFrame.index` and\n    :attr:`DataFrame.columns` attributes of the\n    :class:`~pandas.DataFrame` instance are placed in the query namespace\n    by default, which allows you to treat both the index and columns of the\n    frame as a column in the frame.\n    The identifier ``index`` is used for the frame index; you can also\n    use the name of the index to identify it in a query. Please note that\n    Python keywords may not be used as identifiers.\n\n    For further details and examples see the ``query`` documentation in\n    :ref:`indexing <indexing.query>`.\n\n    *Backtick quoted variables*\n\n    Backtick quoted variables are parsed as literal Python code and\n    are converted internally to a Python valid identifier.\n    This can lead to the following problems.\n\n    During parsing a number of disallowed characters inside the backtick\n    quoted string are replaced by strings that are allowed as a Python identifier.\n    These characters include all operators in Python, the space character, the\n    question mark, the exclamation mark, the dollar sign, and the euro sign.\n    For other characters that fall outside the ASCII range (U+0001..U+007F)\n    and those that are not further specified in PEP 3131,\n    the query parser will raise an error.\n    This excludes whitespace different than the space character,\n    but also the hashtag (as it is used for comments) and the backtick\n    itself (backtick can also not be escaped).\n\n    In a special case, quotes that make a pair around a backtick can\n    confuse the parser.\n    For example, ```it's` > `that's``` will raise an error,\n    as it forms a quoted string (``'s > `that'``) with a backtick inside.\n\n    See also the Python documentation about lexical analysis\n    (https://docs.python.org/3/reference/lexical_analysis.html)\n    in combination with the source code in :mod:`pandas.core.computation.parsing`.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame({'A': range(1, 6),\n    ...                    'B': range(10, 0, -2),\n    ...                    'C C': range(10, 5, -1)})\n    >>> df\n       A   B  C C\n    0  1  10   10\n    1  2   8    9\n    2  3   6    8\n    3  4   4    7\n    4  5   2    6\n    >>> df.query('A > B')\n       A  B  C C\n    4  5  2    6\n\n    The previous expression is equivalent to\n\n    >>> df[df.A > df.B]\n       A  B  C C\n    4  5  2    6\n\n    For columns with spaces in their name, you can use backtick quoting.\n\n    >>> df.query('B == `C C`')\n       A   B  C C\n    0  1  10   10\n\n    The previous expression is equivalent to\n\n    >>> df[df.B == df['C C']]\n       A   B  C C\n    0  1  10   10\n    \"\"\"\n    inplace = validate_bool_kwarg(inplace, 'inplace')\n    if not isinstance(expr, str):\n        msg = f'expr must be a string to be evaluated, {type(expr)} given'\n        raise ValueError(msg)\n    kwargs['level'] = kwargs.pop('level', 0) + 1\n    kwargs['target'] = None\n    res = self.eval(expr, **kwargs)\n    try:\n        new_data = self.loc[res]\n    except ValueError:\n        new_data = self[res]\n    if inplace:\n        self._update_inplace(new_data)\n    else:\n        return new_data",
                            "def eval(self, expr, inplace=False, **kwargs):\n    \"\"\"\n    Evaluate a string describing operations on DataFrame columns.\n\n    Operates on columns only, not specific rows or elements.  This allows\n    `eval` to run arbitrary code, which can make you vulnerable to code\n    injection if you pass user input to this function.\n\n    Parameters\n    ----------\n    expr : str\n        The expression string to evaluate.\n    inplace : bool, default False\n        If the expression contains an assignment, whether to perform the\n        operation inplace and mutate the existing DataFrame. Otherwise,\n        a new DataFrame is returned.\n    **kwargs\n        See the documentation for :func:`eval` for complete details\n        on the keyword arguments accepted by\n        :meth:`~pandas.DataFrame.query`.\n\n    Returns\n    -------\n    ndarray, scalar, or pandas object\n        The result of the evaluation.\n\n    See Also\n    --------\n    DataFrame.query : Evaluates a boolean expression to query the columns\n        of a frame.\n    DataFrame.assign : Can evaluate an expression or function to create new\n        values for a column.\n    eval : Evaluate a Python expression as a string using various\n        backends.\n\n    Notes\n    -----\n    For more details see the API documentation for :func:`~eval`.\n    For detailed examples see :ref:`enhancing performance with eval\n    <enhancingperf.eval>`.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame({'A': range(1, 6), 'B': range(10, 0, -2)})\n    >>> df\n       A   B\n    0  1  10\n    1  2   8\n    2  3   6\n    3  4   4\n    4  5   2\n    >>> df.eval('A + B')\n    0    11\n    1    10\n    2     9\n    3     8\n    4     7\n    dtype: int64\n\n    Assignment is allowed though by default the original DataFrame is not\n    modified.\n\n    >>> df.eval('C = A + B')\n       A   B   C\n    0  1  10  11\n    1  2   8  10\n    2  3   6   9\n    3  4   4   8\n    4  5   2   7\n    >>> df\n       A   B\n    0  1  10\n    1  2   8\n    2  3   6\n    3  4   4\n    4  5   2\n\n    Use ``inplace=True`` to modify the original DataFrame.\n\n    >>> df.eval('C = A + B', inplace=True)\n    >>> df\n       A   B   C\n    0  1  10  11\n    1  2   8  10\n    2  3   6   9\n    3  4   4   8\n    4  5   2   7\n\n    Multiple columns can be assigned to using multi-line expressions:\n\n    >>> df.eval(\n    ...     '''\n    ... C = A + B\n    ... D = A - B\n    ... '''\n    ... )\n       A   B   C  D\n    0  1  10  11 -9\n    1  2   8  10 -6\n    2  3   6   9 -3\n    3  4   4   8  0\n    4  5   2   7  3\n    \"\"\"\n    from pandas.core.computation.eval import eval as _eval\n    inplace = validate_bool_kwarg(inplace, 'inplace')\n    resolvers = kwargs.pop('resolvers', None)\n    kwargs['level'] = kwargs.pop('level', 0) + 1\n    if resolvers is None:\n        index_resolvers = self._get_index_resolvers()\n        column_resolvers = self._get_cleaned_column_resolvers()\n        resolvers = (column_resolvers, index_resolvers)\n    if 'target' not in kwargs:\n        kwargs['target'] = self\n    kwargs['resolvers'] = kwargs.get('resolvers', ()) + tuple(resolvers)\n    return _eval(expr, inplace=inplace, **kwargs)",
                            "def select_dtypes(self, include=None, exclude=None) -> 'DataFrame':\n    \"\"\"\n    Return a subset of the DataFrame's columns based on the column dtypes.\n\n    Parameters\n    ----------\n    include, exclude : scalar or list-like\n        A selection of dtypes or strings to be included/excluded. At least\n        one of these parameters must be supplied.\n\n    Returns\n    -------\n    DataFrame\n        The subset of the frame including the dtypes in ``include`` and\n        excluding the dtypes in ``exclude``.\n\n    Raises\n    ------\n    ValueError\n        * If both of ``include`` and ``exclude`` are empty\n        * If ``include`` and ``exclude`` have overlapping elements\n        * If any kind of string dtype is passed in.\n\n    Notes\n    -----\n    * To select all *numeric* types, use ``np.number`` or ``'number'``\n    * To select strings you must use the ``object`` dtype, but note that\n      this will return *all* object dtype columns\n    * See the `numpy dtype hierarchy\n      <https://docs.scipy.org/doc/numpy/reference/arrays.scalars.html>`__\n    * To select datetimes, use ``np.datetime64``, ``'datetime'`` or\n      ``'datetime64'``\n    * To select timedeltas, use ``np.timedelta64``, ``'timedelta'`` or\n      ``'timedelta64'``\n    * To select Pandas categorical dtypes, use ``'category'``\n    * To select Pandas datetimetz dtypes, use ``'datetimetz'`` (new in\n      0.20.0) or ``'datetime64[ns, tz]'``\n\n    Examples\n    --------\n    >>> df = pd.DataFrame({'a': [1, 2] * 3,\n    ...                    'b': [True, False] * 3,\n    ...                    'c': [1.0, 2.0] * 3})\n    >>> df\n            a      b  c\n    0       1   True  1.0\n    1       2  False  2.0\n    2       1   True  1.0\n    3       2  False  2.0\n    4       1   True  1.0\n    5       2  False  2.0\n\n    >>> df.select_dtypes(include='bool')\n       b\n    0  True\n    1  False\n    2  True\n    3  False\n    4  True\n    5  False\n\n    >>> df.select_dtypes(include=['float64'])\n       c\n    0  1.0\n    1  2.0\n    2  1.0\n    3  2.0\n    4  1.0\n    5  2.0\n\n    >>> df.select_dtypes(exclude=['int'])\n           b    c\n    0   True  1.0\n    1  False  2.0\n    2   True  1.0\n    3  False  2.0\n    4   True  1.0\n    5  False  2.0\n    \"\"\"\n    if not is_list_like(include):\n        include = (include,) if include is not None else ()\n    if not is_list_like(exclude):\n        exclude = (exclude,) if exclude is not None else ()\n    selection = (frozenset(include), frozenset(exclude))\n    if not any(selection):\n        raise ValueError('at least one of include or exclude must be nonempty')\n    include = frozenset((infer_dtype_from_object(x) for x in include))\n    exclude = frozenset((infer_dtype_from_object(x) for x in exclude))\n    for dtypes in (include, exclude):\n        invalidate_string_dtypes(dtypes)\n    if not include.isdisjoint(exclude):\n        raise ValueError(f'include and exclude overlap on {include & exclude}')\n    keep_these = np.full(self.shape[1], True)\n\n    def extract_unique_dtypes_from_dtypes_set(dtypes_set: FrozenSet[Dtype], unique_dtypes: np.ndarray) -> List[Dtype]:\n        extracted_dtypes = [unique_dtype for unique_dtype in unique_dtypes if issubclass(unique_dtype.type, tuple(dtypes_set))]\n        return extracted_dtypes\n    unique_dtypes = self.dtypes.unique()\n    if include:\n        included_dtypes = extract_unique_dtypes_from_dtypes_set(include, unique_dtypes)\n        keep_these &= self.dtypes.isin(included_dtypes)\n    if exclude:\n        excluded_dtypes = extract_unique_dtypes_from_dtypes_set(exclude, unique_dtypes)\n        keep_these &= ~self.dtypes.isin(excluded_dtypes)\n    return self.iloc[:, keep_these.values]",
                            "def insert(self, loc, column, value, allow_duplicates=False) -> None:\n    \"\"\"\n    Insert column into DataFrame at specified location.\n\n    Raises a ValueError if `column` is already contained in the DataFrame,\n    unless `allow_duplicates` is set to True.\n\n    Parameters\n    ----------\n    loc : int\n        Insertion index. Must verify 0 <= loc <= len(columns).\n    column : str, number, or hashable object\n        Label of the inserted column.\n    value : int, Series, or array-like\n    allow_duplicates : bool, optional\n    \"\"\"\n    self._ensure_valid_index(value)\n    value = self._sanitize_column(column, value, broadcast=False)\n    self._data.insert(loc, column, value, allow_duplicates=allow_duplicates)",
                            "def assign(self, **kwargs) -> 'DataFrame':\n    \"\"\"\n    Assign new columns to a DataFrame.\n\n    Returns a new object with all original columns in addition to new ones.\n    Existing columns that are re-assigned will be overwritten.\n\n    Parameters\n    ----------\n    **kwargs : dict of {str: callable or Series}\n        The column names are keywords. If the values are\n        callable, they are computed on the DataFrame and\n        assigned to the new columns. The callable must not\n        change input DataFrame (though pandas doesn't check it).\n        If the values are not callable, (e.g. a Series, scalar, or array),\n        they are simply assigned.\n\n    Returns\n    -------\n    DataFrame\n        A new DataFrame with the new columns in addition to\n        all the existing columns.\n\n    Notes\n    -----\n    Assigning multiple columns within the same ``assign`` is possible.\n    Later items in '\\\\*\\\\*kwargs' may refer to newly created or modified\n    columns in 'df'; items are computed and assigned into 'df' in order.\n\n    .. versionchanged:: 0.23.0\n\n       Keyword argument order is maintained.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame({'temp_c': [17.0, 25.0]},\n    ...                   index=['Portland', 'Berkeley'])\n    >>> df\n              temp_c\n    Portland    17.0\n    Berkeley    25.0\n\n    Where the value is a callable, evaluated on `df`:\n\n    >>> df.assign(temp_f=lambda x: x.temp_c * 9 / 5 + 32)\n              temp_c  temp_f\n    Portland    17.0    62.6\n    Berkeley    25.0    77.0\n\n    Alternatively, the same behavior can be achieved by directly\n    referencing an existing Series or sequence:\n\n    >>> df.assign(temp_f=df['temp_c'] * 9 / 5 + 32)\n              temp_c  temp_f\n    Portland    17.0    62.6\n    Berkeley    25.0    77.0\n\n    You can create multiple columns within the same assign where one\n    of the columns depends on another one defined within the same assign:\n\n    >>> df.assign(temp_f=lambda x: x['temp_c'] * 9 / 5 + 32,\n    ...           temp_k=lambda x: (x['temp_f'] +  459.67) * 5 / 9)\n              temp_c  temp_f  temp_k\n    Portland    17.0    62.6  290.15\n    Berkeley    25.0    77.0  298.15\n    \"\"\"\n    data = self.copy()\n    for k, v in kwargs.items():\n        data[k] = com.apply_if_callable(v, data)\n    return data",
                            "def _sanitize_column(self, key, value, broadcast=True):\n    \"\"\"\n    Ensures new columns (which go into the BlockManager as new blocks) are\n    always copied and converted into an array.\n\n    Parameters\n    ----------\n    key : object\n    value : scalar, Series, or array-like\n    broadcast : bool, default True\n        If ``key`` matches multiple duplicate column names in the\n        DataFrame, this parameter indicates whether ``value`` should be\n        tiled so that the returned array contains a (duplicated) column for\n        each occurrence of the key. If False, ``value`` will not be tiled.\n\n    Returns\n    -------\n    numpy.ndarray\n    \"\"\"\n\n    def reindexer(value):\n        if value.index.equals(self.index) or not len(self.index):\n            value = value._values.copy()\n        else:\n            try:\n                value = value.reindex(self.index)._values\n            except ValueError as err:\n                if not value.index.is_unique:\n                    raise err\n                raise TypeError('incompatible index of inserted column with frame index') from err\n        return value\n    if isinstance(value, Series):\n        value = reindexer(value)\n    elif isinstance(value, DataFrame):\n        if isinstance(self.columns, ABCMultiIndex) and key in self.columns:\n            loc = self.columns.get_loc(key)\n            if isinstance(loc, (slice, Series, np.ndarray, Index)):\n                cols = maybe_droplevels(self.columns[loc], key)\n                if len(cols) and (not cols.equals(value.columns)):\n                    value = value.reindex(cols, axis=1)\n        value = reindexer(value).T\n    elif isinstance(value, ExtensionArray):\n        value = value.copy()\n        value = sanitize_index(value, self.index)\n    elif isinstance(value, Index) or is_sequence(value):\n        value = sanitize_index(value, self.index)\n        if not isinstance(value, (np.ndarray, Index)):\n            if isinstance(value, list) and len(value) > 0:\n                value = maybe_convert_platform(value)\n            else:\n                value = com.asarray_tuplesafe(value)\n        elif value.ndim == 2:\n            value = value.copy().T\n        elif isinstance(value, Index):\n            value = value.copy(deep=True)\n        else:\n            value = value.copy()\n        if is_object_dtype(value.dtype):\n            value = maybe_infer_to_datetimelike(value)\n    else:\n        infer_dtype, _ = infer_dtype_from_scalar(value, pandas_dtype=True)\n        value = cast_scalar_to_array(len(self.index), value)\n        value = maybe_cast_to_datetime(value, infer_dtype)\n    if is_extension_array_dtype(value):\n        return value\n    if broadcast and key in self.columns and (value.ndim == 1):\n        if not self.columns.is_unique or isinstance(self.columns, ABCMultiIndex):\n            existing_piece = self[key]\n            if isinstance(existing_piece, DataFrame):\n                value = np.tile(value, (len(existing_piece.columns), 1))\n    return np.atleast_2d(np.asarray(value))",
                            "@property\ndef _series(self):\n    return {item: Series(self._data.iget(idx), index=self.index, name=item) for idx, item in enumerate(self.columns)}",
                            "def lookup(self, row_labels, col_labels) -> np.ndarray:\n    \"\"\"\n    Label-based \"fancy indexing\" function for DataFrame.\n\n    Given equal-length arrays of row and column labels, return an\n    array of the values corresponding to each (row, col) pair.\n\n    Parameters\n    ----------\n    row_labels : sequence\n        The row labels to use for lookup.\n    col_labels : sequence\n        The column labels to use for lookup.\n\n    Returns\n    -------\n    numpy.ndarray\n        The found values.\n    \"\"\"\n    n = len(row_labels)\n    if n != len(col_labels):\n        raise ValueError('Row labels must have same size as column labels')\n    thresh = 1000\n    if not self._is_mixed_type or n > thresh:\n        values = self.values\n        ridx = self.index.get_indexer(row_labels)\n        cidx = self.columns.get_indexer(col_labels)\n        if (ridx == -1).any():\n            raise KeyError('One or more row labels was not found')\n        if (cidx == -1).any():\n            raise KeyError('One or more column labels was not found')\n        flat_index = ridx * len(self.columns) + cidx\n        result = values.flat[flat_index]\n    else:\n        result = np.empty(n, dtype='O')\n        for i, (r, c) in enumerate(zip(row_labels, col_labels)):\n            result[i] = self._get_value(r, c)\n    if is_object_dtype(result):\n        result = lib.maybe_convert_objects(result)\n    return result",
                            "def _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy):\n    frame = self\n    columns = axes['columns']\n    if columns is not None:\n        frame = frame._reindex_columns(columns, method, copy, level, fill_value, limit, tolerance)\n    index = axes['index']\n    if index is not None:\n        frame = frame._reindex_index(index, method, copy, level, fill_value, limit, tolerance)\n    return frame",
                            "def _reindex_index(self, new_index, method, copy, level, fill_value=np.nan, limit=None, tolerance=None):\n    new_index, indexer = self.index.reindex(new_index, method=method, level=level, limit=limit, tolerance=tolerance)\n    return self._reindex_with_indexers({0: [new_index, indexer]}, copy=copy, fill_value=fill_value, allow_dups=False)",
                            "def _reindex_columns(self, new_columns, method, copy, level, fill_value=None, limit=None, tolerance=None):\n    new_columns, indexer = self.columns.reindex(new_columns, method=method, level=level, limit=limit, tolerance=tolerance)\n    return self._reindex_with_indexers({1: [new_columns, indexer]}, copy=copy, fill_value=fill_value, allow_dups=False)",
                            "def _reindex_multi(self, axes, copy, fill_value) -> 'DataFrame':\n    \"\"\"\n    We are guaranteed non-Nones in the axes.\n    \"\"\"\n    new_index, row_indexer = self.index.reindex(axes['index'])\n    new_columns, col_indexer = self.columns.reindex(axes['columns'])\n    if row_indexer is not None and col_indexer is not None:\n        indexer = (row_indexer, col_indexer)\n        new_values = algorithms.take_2d_multi(self.values, indexer, fill_value=fill_value)\n        return self._constructor(new_values, index=new_index, columns=new_columns)\n    else:\n        return self._reindex_with_indexers({0: [new_index, row_indexer], 1: [new_columns, col_indexer]}, copy=copy, fill_value=fill_value)",
                            "@Appender(_shared_docs['align'] % _shared_doc_kwargs)\ndef align(self, other, join='outer', axis=None, level=None, copy=True, fill_value=None, method=None, limit=None, fill_axis=0, broadcast_axis=None) -> 'DataFrame':\n    return super().align(other, join=join, axis=axis, level=level, copy=copy, fill_value=fill_value, method=method, limit=limit, fill_axis=fill_axis, broadcast_axis=broadcast_axis)",
                            "@Appender('\\n        Examples\\n        --------\\n        >>> df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\\n\\n        Change the row labels.\\n\\n        >>> df.set_axis([\\'a\\', \\'b\\', \\'c\\'], axis=\\'index\\')\\n           A  B\\n        a  1  4\\n        b  2  5\\n        c  3  6\\n\\n        Change the column labels.\\n\\n        >>> df.set_axis([\\'I\\', \\'II\\'], axis=\\'columns\\')\\n           I  II\\n        0  1   4\\n        1  2   5\\n        2  3   6\\n\\n        Now, update the labels inplace.\\n\\n        >>> df.set_axis([\\'i\\', \\'ii\\'], axis=\\'columns\\', inplace=True)\\n        >>> df\\n           i  ii\\n        0  1   4\\n        1  2   5\\n        2  3   6\\n        ')\n@Substitution(**_shared_doc_kwargs, extended_summary_sub=' column or', axis_description_sub=', and 1 identifies the columns', see_also_sub=' or columns')\n@Appender(NDFrame.set_axis.__doc__)\ndef set_axis(self, labels, axis: Axis=0, inplace: bool=False):\n    return super().set_axis(labels, axis=axis, inplace=inplace)",
                            "@Substitution(**_shared_doc_kwargs)\n@Appender(NDFrame.reindex.__doc__)\n@rewrite_axis_style_signature('labels', [('method', None), ('copy', True), ('level', None), ('fill_value', np.nan), ('limit', None), ('tolerance', None)])\ndef reindex(self, *args, **kwargs) -> 'DataFrame':\n    axes = validate_axis_style_args(self, args, kwargs, 'labels', 'reindex')\n    kwargs.update(axes)\n    kwargs.pop('axis', None)\n    kwargs.pop('labels', None)\n    return super().reindex(**kwargs)",
                            "def drop(self, labels=None, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise'):\n    \"\"\"\n    Drop specified labels from rows or columns.\n\n    Remove rows or columns by specifying label names and corresponding\n    axis, or by specifying directly index or column names. When using a\n    multi-index, labels on different levels can be removed by specifying\n    the level.\n\n    Parameters\n    ----------\n    labels : single label or list-like\n        Index or column labels to drop.\n    axis : {0 or 'index', 1 or 'columns'}, default 0\n        Whether to drop labels from the index (0 or 'index') or\n        columns (1 or 'columns').\n    index : single label or list-like\n        Alternative to specifying axis (``labels, axis=0``\n        is equivalent to ``index=labels``).\n\n        .. versionadded:: 0.21.0\n    columns : single label or list-like\n        Alternative to specifying axis (``labels, axis=1``\n        is equivalent to ``columns=labels``).\n\n        .. versionadded:: 0.21.0\n    level : int or level name, optional\n        For MultiIndex, level from which the labels will be removed.\n    inplace : bool, default False\n        If True, do operation inplace and return None.\n    errors : {'ignore', 'raise'}, default 'raise'\n        If 'ignore', suppress error and only existing labels are\n        dropped.\n\n    Returns\n    -------\n    DataFrame\n        DataFrame without the removed index or column labels.\n\n    Raises\n    ------\n    KeyError\n        If any of the labels is not found in the selected axis.\n\n    See Also\n    --------\n    DataFrame.loc : Label-location based indexer for selection by label.\n    DataFrame.dropna : Return DataFrame with labels on given axis omitted\n        where (all or any) data are missing.\n    DataFrame.drop_duplicates : Return DataFrame with duplicate rows\n        removed, optionally only considering certain columns.\n    Series.drop : Return Series with specified index labels removed.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame(np.arange(12).reshape(3, 4),\n    ...                   columns=['A', 'B', 'C', 'D'])\n    >>> df\n       A  B   C   D\n    0  0  1   2   3\n    1  4  5   6   7\n    2  8  9  10  11\n\n    Drop columns\n\n    >>> df.drop(['B', 'C'], axis=1)\n       A   D\n    0  0   3\n    1  4   7\n    2  8  11\n\n    >>> df.drop(columns=['B', 'C'])\n       A   D\n    0  0   3\n    1  4   7\n    2  8  11\n\n    Drop a row by index\n\n    >>> df.drop([0, 1])\n       A  B   C   D\n    2  8  9  10  11\n\n    Drop columns and/or rows of MultiIndex DataFrame\n\n    >>> midx = pd.MultiIndex(levels=[['lama', 'cow', 'falcon'],\n    ...                              ['speed', 'weight', 'length']],\n    ...                      codes=[[0, 0, 0, 1, 1, 1, 2, 2, 2],\n    ...                             [0, 1, 2, 0, 1, 2, 0, 1, 2]])\n    >>> df = pd.DataFrame(index=midx, columns=['big', 'small'],\n    ...                   data=[[45, 30], [200, 100], [1.5, 1], [30, 20],\n    ...                         [250, 150], [1.5, 0.8], [320, 250],\n    ...                         [1, 0.8], [0.3, 0.2]])\n    >>> df\n                    big     small\n    lama    speed   45.0    30.0\n            weight  200.0   100.0\n            length  1.5     1.0\n    cow     speed   30.0    20.0\n            weight  250.0   150.0\n            length  1.5     0.8\n    falcon  speed   320.0   250.0\n            weight  1.0     0.8\n            length  0.3     0.2\n\n    >>> df.drop(index='cow', columns='small')\n                    big\n    lama    speed   45.0\n            weight  200.0\n            length  1.5\n    falcon  speed   320.0\n            weight  1.0\n            length  0.3\n\n    >>> df.drop(index='length', level=1)\n                    big     small\n    lama    speed   45.0    30.0\n            weight  200.0   100.0\n    cow     speed   30.0    20.0\n            weight  250.0   150.0\n    falcon  speed   320.0   250.0\n            weight  1.0     0.8\n    \"\"\"\n    return super().drop(labels=labels, axis=axis, index=index, columns=columns, level=level, inplace=inplace, errors=errors)",
                            "@rewrite_axis_style_signature('mapper', [('copy', True), ('inplace', False), ('level', None), ('errors', 'ignore')])\ndef rename(self, mapper: Optional[Renamer]=None, *, index: Optional[Renamer]=None, columns: Optional[Renamer]=None, axis: Optional[Axis]=None, copy: bool=True, inplace: bool=False, level: Optional[Level]=None, errors: str='ignore') -> Optional['DataFrame']:\n    \"\"\"\n    Alter axes labels.\n\n    Function / dict values must be unique (1-to-1). Labels not contained in\n    a dict / Series will be left as-is. Extra labels listed don't throw an\n    error.\n\n    See the :ref:`user guide <basics.rename>` for more.\n\n    Parameters\n    ----------\n    mapper : dict-like or function\n        Dict-like or functions transformations to apply to\n        that axis' values. Use either ``mapper`` and ``axis`` to\n        specify the axis to target with ``mapper``, or ``index`` and\n        ``columns``.\n    index : dict-like or function\n        Alternative to specifying axis (``mapper, axis=0``\n        is equivalent to ``index=mapper``).\n    columns : dict-like or function\n        Alternative to specifying axis (``mapper, axis=1``\n        is equivalent to ``columns=mapper``).\n    axis : int or str\n        Axis to target with ``mapper``. Can be either the axis name\n        ('index', 'columns') or number (0, 1). The default is 'index'.\n    copy : bool, default True\n        Also copy underlying data.\n    inplace : bool, default False\n        Whether to return a new DataFrame. If True then value of copy is\n        ignored.\n    level : int or level name, default None\n        In case of a MultiIndex, only rename labels in the specified\n        level.\n    errors : {'ignore', 'raise'}, default 'ignore'\n        If 'raise', raise a `KeyError` when a dict-like `mapper`, `index`,\n        or `columns` contains labels that are not present in the Index\n        being transformed.\n        If 'ignore', existing keys will be renamed and extra keys will be\n        ignored.\n\n    Returns\n    -------\n    DataFrame\n        DataFrame with the renamed axis labels.\n\n    Raises\n    ------\n    KeyError\n        If any of the labels is not found in the selected axis and\n        \"errors='raise'\".\n\n    See Also\n    --------\n    DataFrame.rename_axis : Set the name of the axis.\n\n    Examples\n    --------\n    ``DataFrame.rename`` supports two calling conventions\n\n    * ``(index=index_mapper, columns=columns_mapper, ...)``\n    * ``(mapper, axis={'index', 'columns'}, ...)``\n\n    We *highly* recommend using keyword arguments to clarify your\n    intent.\n\n    Rename columns using a mapping:\n\n    >>> df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n    >>> df.rename(columns={\"A\": \"a\", \"B\": \"c\"})\n       a  c\n    0  1  4\n    1  2  5\n    2  3  6\n\n    Rename index using a mapping:\n\n    >>> df.rename(index={0: \"x\", 1: \"y\", 2: \"z\"})\n       A  B\n    x  1  4\n    y  2  5\n    z  3  6\n\n    Cast index labels to a different type:\n\n    >>> df.index\n    RangeIndex(start=0, stop=3, step=1)\n    >>> df.rename(index=str).index\n    Index(['0', '1', '2'], dtype='object')\n\n    >>> df.rename(columns={\"A\": \"a\", \"B\": \"b\", \"C\": \"c\"}, errors=\"raise\")\n    Traceback (most recent call last):\n    KeyError: ['C'] not found in axis\n\n    Using axis-style parameters\n\n    >>> df.rename(str.lower, axis='columns')\n       a  b\n    0  1  4\n    1  2  5\n    2  3  6\n\n    >>> df.rename({1: 2, 2: 4}, axis='index')\n       A  B\n    0  1  4\n    2  2  5\n    4  3  6\n    \"\"\"\n    return super().rename(mapper=mapper, index=index, columns=columns, axis=axis, copy=copy, inplace=inplace, level=level, errors=errors)",
                            "@doc(NDFrame.fillna, **_shared_doc_kwargs)\ndef fillna(self, value=None, method=None, axis=None, inplace=False, limit=None, downcast=None) -> Optional['DataFrame']:\n    return super().fillna(value=value, method=method, axis=axis, inplace=inplace, limit=limit, downcast=downcast)",
                            "@Appender(_shared_docs['replace'] % _shared_doc_kwargs)\ndef replace(self, to_replace=None, value=None, inplace=False, limit=None, regex=False, method='pad'):\n    return super().replace(to_replace=to_replace, value=value, inplace=inplace, limit=limit, regex=regex, method=method)",
                            "@Appender(_shared_docs['shift'] % _shared_doc_kwargs)\ndef shift(self, periods=1, freq=None, axis=0, fill_value=None) -> 'DataFrame':\n    return super().shift(periods=periods, freq=freq, axis=axis, fill_value=fill_value)",
                            "def set_index(self, keys, drop=True, append=False, inplace=False, verify_integrity=False):\n    \"\"\"\n    Set the DataFrame index using existing columns.\n\n    Set the DataFrame index (row labels) using one or more existing\n    columns or arrays (of the correct length). The index can replace the\n    existing index or expand on it.\n\n    Parameters\n    ----------\n    keys : label or array-like or list of labels/arrays\n        This parameter can be either a single column key, a single array of\n        the same length as the calling DataFrame, or a list containing an\n        arbitrary combination of column keys and arrays. Here, \"array\"\n        encompasses :class:`Series`, :class:`Index`, ``np.ndarray``, and\n        instances of :class:`~collections.abc.Iterator`.\n    drop : bool, default True\n        Delete columns to be used as the new index.\n    append : bool, default False\n        Whether to append columns to existing index.\n    inplace : bool, default False\n        Modify the DataFrame in place (do not create a new object).\n    verify_integrity : bool, default False\n        Check the new index for duplicates. Otherwise defer the check until\n        necessary. Setting to False will improve the performance of this\n        method.\n\n    Returns\n    -------\n    DataFrame\n        Changed row labels.\n\n    See Also\n    --------\n    DataFrame.reset_index : Opposite of set_index.\n    DataFrame.reindex : Change to new indices or expand indices.\n    DataFrame.reindex_like : Change to same indices as other DataFrame.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame({'month': [1, 4, 7, 10],\n    ...                    'year': [2012, 2014, 2013, 2014],\n    ...                    'sale': [55, 40, 84, 31]})\n    >>> df\n       month  year  sale\n    0      1  2012    55\n    1      4  2014    40\n    2      7  2013    84\n    3     10  2014    31\n\n    Set the index to become the 'month' column:\n\n    >>> df.set_index('month')\n           year  sale\n    month\n    1      2012    55\n    4      2014    40\n    7      2013    84\n    10     2014    31\n\n    Create a MultiIndex using columns 'year' and 'month':\n\n    >>> df.set_index(['year', 'month'])\n                sale\n    year  month\n    2012  1     55\n    2014  4     40\n    2013  7     84\n    2014  10    31\n\n    Create a MultiIndex using an Index and a column:\n\n    >>> df.set_index([pd.Index([1, 2, 3, 4]), 'year'])\n             month  sale\n       year\n    1  2012  1      55\n    2  2014  4      40\n    3  2013  7      84\n    4  2014  10     31\n\n    Create a MultiIndex using two Series:\n\n    >>> s = pd.Series([1, 2, 3, 4])\n    >>> df.set_index([s, s**2])\n          month  year  sale\n    1 1       1  2012    55\n    2 4       4  2014    40\n    3 9       7  2013    84\n    4 16     10  2014    31\n    \"\"\"\n    inplace = validate_bool_kwarg(inplace, 'inplace')\n    if not isinstance(keys, list):\n        keys = [keys]\n    err_msg = 'The parameter \"keys\" may be a column key, one-dimensional array, or a list containing only valid column keys and one-dimensional arrays.'\n    missing: List[Label] = []\n    for col in keys:\n        if isinstance(col, (ABCIndexClass, ABCSeries, np.ndarray, list, abc.Iterator)):\n            if getattr(col, 'ndim', 1) != 1:\n                raise ValueError(err_msg)\n        else:\n            try:\n                found = col in self.columns\n            except TypeError as err:\n                raise TypeError(f'{err_msg}. Received column of type {type(col)}') from err\n            else:\n                if not found:\n                    missing.append(col)\n    if missing:\n        raise KeyError(f'None of {missing} are in the columns')\n    if inplace:\n        frame = self\n    else:\n        frame = self.copy()\n    arrays = []\n    names = []\n    if append:\n        names = list(self.index.names)\n        if isinstance(self.index, ABCMultiIndex):\n            for i in range(self.index.nlevels):\n                arrays.append(self.index._get_level_values(i))\n        else:\n            arrays.append(self.index)\n    to_remove: List[Label] = []\n    for col in keys:\n        if isinstance(col, ABCMultiIndex):\n            for n in range(col.nlevels):\n                arrays.append(col._get_level_values(n))\n            names.extend(col.names)\n        elif isinstance(col, (ABCIndexClass, ABCSeries)):\n            arrays.append(col)\n            names.append(col.name)\n        elif isinstance(col, (list, np.ndarray)):\n            arrays.append(col)\n            names.append(None)\n        elif isinstance(col, abc.Iterator):\n            arrays.append(list(col))\n            names.append(None)\n        else:\n            arrays.append(frame[col]._values)\n            names.append(col)\n            if drop:\n                to_remove.append(col)\n        if len(arrays[-1]) != len(self):\n            raise ValueError(f'Length mismatch: Expected {len(self)} rows, received array of length {len(arrays[-1])}')\n    index = ensure_index_from_sequences(arrays, names)\n    if verify_integrity and (not index.is_unique):\n        duplicates = index[index.duplicated()].unique()\n        raise ValueError(f'Index has duplicate keys: {duplicates}')\n    for c in set(to_remove):\n        del frame[c]\n    index._cleanup()\n    frame.index = index\n    if not inplace:\n        return frame",
                            "def reset_index(self, level: Optional[Union[Hashable, Sequence[Hashable]]]=None, drop: bool=False, inplace: bool=False, col_level: Hashable=0, col_fill: Label='') -> Optional['DataFrame']:\n    \"\"\"\n    Reset the index, or a level of it.\n\n    Reset the index of the DataFrame, and use the default one instead.\n    If the DataFrame has a MultiIndex, this method can remove one or more\n    levels.\n\n    Parameters\n    ----------\n    level : int, str, tuple, or list, default None\n        Only remove the given levels from the index. Removes all levels by\n        default.\n    drop : bool, default False\n        Do not try to insert index into dataframe columns. This resets\n        the index to the default integer index.\n    inplace : bool, default False\n        Modify the DataFrame in place (do not create a new object).\n    col_level : int or str, default 0\n        If the columns have multiple levels, determines which level the\n        labels are inserted into. By default it is inserted into the first\n        level.\n    col_fill : object, default ''\n        If the columns have multiple levels, determines how the other\n        levels are named. If None then the index name is repeated.\n\n    Returns\n    -------\n    DataFrame or None\n        DataFrame with the new index or None if ``inplace=True``.\n\n    See Also\n    --------\n    DataFrame.set_index : Opposite of reset_index.\n    DataFrame.reindex : Change to new indices or expand indices.\n    DataFrame.reindex_like : Change to same indices as other DataFrame.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame([('bird', 389.0),\n    ...                    ('bird', 24.0),\n    ...                    ('mammal', 80.5),\n    ...                    ('mammal', np.nan)],\n    ...                   index=['falcon', 'parrot', 'lion', 'monkey'],\n    ...                   columns=('class', 'max_speed'))\n    >>> df\n             class  max_speed\n    falcon    bird      389.0\n    parrot    bird       24.0\n    lion    mammal       80.5\n    monkey  mammal        NaN\n\n    When we reset the index, the old index is added as a column, and a\n    new sequential index is used:\n\n    >>> df.reset_index()\n        index   class  max_speed\n    0  falcon    bird      389.0\n    1  parrot    bird       24.0\n    2    lion  mammal       80.5\n    3  monkey  mammal        NaN\n\n    We can use the `drop` parameter to avoid the old index being added as\n    a column:\n\n    >>> df.reset_index(drop=True)\n        class  max_speed\n    0    bird      389.0\n    1    bird       24.0\n    2  mammal       80.5\n    3  mammal        NaN\n\n    You can also use `reset_index` with `MultiIndex`.\n\n    >>> index = pd.MultiIndex.from_tuples([('bird', 'falcon'),\n    ...                                    ('bird', 'parrot'),\n    ...                                    ('mammal', 'lion'),\n    ...                                    ('mammal', 'monkey')],\n    ...                                   names=['class', 'name'])\n    >>> columns = pd.MultiIndex.from_tuples([('speed', 'max'),\n    ...                                      ('species', 'type')])\n    >>> df = pd.DataFrame([(389.0, 'fly'),\n    ...                    ( 24.0, 'fly'),\n    ...                    ( 80.5, 'run'),\n    ...                    (np.nan, 'jump')],\n    ...                   index=index,\n    ...                   columns=columns)\n    >>> df\n                   speed species\n                     max    type\n    class  name\n    bird   falcon  389.0     fly\n           parrot   24.0     fly\n    mammal lion     80.5     run\n           monkey    NaN    jump\n\n    If the index has multiple levels, we can reset a subset of them:\n\n    >>> df.reset_index(level='class')\n             class  speed species\n                      max    type\n    name\n    falcon    bird  389.0     fly\n    parrot    bird   24.0     fly\n    lion    mammal   80.5     run\n    monkey  mammal    NaN    jump\n\n    If we are not dropping the index, by default, it is placed in the top\n    level. We can place it in another level:\n\n    >>> df.reset_index(level='class', col_level=1)\n                    speed species\n             class    max    type\n    name\n    falcon    bird  389.0     fly\n    parrot    bird   24.0     fly\n    lion    mammal   80.5     run\n    monkey  mammal    NaN    jump\n\n    When the index is inserted under another level, we can specify under\n    which one with the parameter `col_fill`:\n\n    >>> df.reset_index(level='class', col_level=1, col_fill='species')\n                  species  speed species\n                    class    max    type\n    name\n    falcon           bird  389.0     fly\n    parrot           bird   24.0     fly\n    lion           mammal   80.5     run\n    monkey         mammal    NaN    jump\n\n    If we specify a nonexistent level for `col_fill`, it is created:\n\n    >>> df.reset_index(level='class', col_level=1, col_fill='genus')\n                    genus  speed species\n                    class    max    type\n    name\n    falcon           bird  389.0     fly\n    parrot           bird   24.0     fly\n    lion           mammal   80.5     run\n    monkey         mammal    NaN    jump\n    \"\"\"\n    inplace = validate_bool_kwarg(inplace, 'inplace')\n    if inplace:\n        new_obj = self\n    else:\n        new_obj = self.copy()\n\n    def _maybe_casted_values(index, labels=None):\n        values = index._values\n        if not isinstance(index, (PeriodIndex, DatetimeIndex)):\n            if values.dtype == np.object_:\n                values = lib.maybe_convert_objects(values)\n        if labels is not None:\n            mask = labels == -1\n            if mask.all():\n                values = np.empty(len(mask))\n                values.fill(np.nan)\n            else:\n                values = values.take(labels)\n                values_type = type(values)\n                values_dtype = values.dtype\n                if issubclass(values_type, DatetimeLikeArray):\n                    values = values._data\n                if mask.any():\n                    values, _ = maybe_upcast_putmask(values, mask, np.nan)\n                if issubclass(values_type, DatetimeLikeArray):\n                    values = values_type(values, dtype=values_dtype)\n        return values\n    new_index = ibase.default_index(len(new_obj))\n    if level is not None:\n        if not isinstance(level, (tuple, list)):\n            level = [level]\n        level = [self.index._get_level_number(lev) for lev in level]\n        if len(level) < self.index.nlevels:\n            new_index = self.index.droplevel(level)\n    if not drop:\n        to_insert: Iterable[Tuple[Any, Optional[Any]]]\n        if isinstance(self.index, ABCMultiIndex):\n            names = [n if n is not None else f'level_{i}' for i, n in enumerate(self.index.names)]\n            to_insert = zip(self.index.levels, self.index.codes)\n        else:\n            default = 'index' if 'index' not in self else 'level_0'\n            names = [default] if self.index.name is None else [self.index.name]\n            to_insert = ((self.index, None),)\n        multi_col = isinstance(self.columns, ABCMultiIndex)\n        for i, (lev, lab) in reversed(list(enumerate(to_insert))):\n            if not (level is None or i in level):\n                continue\n            name = names[i]\n            if multi_col:\n                col_name = list(name) if isinstance(name, tuple) else [name]\n                if col_fill is None:\n                    if len(col_name) not in (1, self.columns.nlevels):\n                        raise ValueError(f'col_fill=None is incompatible with incomplete column name {name}')\n                    col_fill = col_name[0]\n                lev_num = self.columns._get_level_number(col_level)\n                name_lst = [col_fill] * lev_num + col_name\n                missing = self.columns.nlevels - len(name_lst)\n                name_lst += [col_fill] * missing\n                name = tuple(name_lst)\n            level_values = _maybe_casted_values(lev, lab)\n            new_obj.insert(0, name, level_values)\n    new_obj.index = new_index\n    if not inplace:\n        return new_obj\n    return None",
                            "@Appender(_shared_docs['isna'] % _shared_doc_kwargs)\ndef isna(self) -> 'DataFrame':\n    return super().isna()",
                            "@Appender(_shared_docs['isna'] % _shared_doc_kwargs)\ndef isnull(self) -> 'DataFrame':\n    return super().isnull()",
                            "@Appender(_shared_docs['notna'] % _shared_doc_kwargs)\ndef notna(self) -> 'DataFrame':\n    return super().notna()",
                            "@Appender(_shared_docs['notna'] % _shared_doc_kwargs)\ndef notnull(self) -> 'DataFrame':\n    return super().notnull()",
                            "def dropna(self, axis=0, how='any', thresh=None, subset=None, inplace=False):\n    \"\"\"\n    Remove missing values.\n\n    See the :ref:`User Guide <missing_data>` for more on which values are\n    considered missing, and how to work with missing data.\n\n    Parameters\n    ----------\n    axis : {0 or 'index', 1 or 'columns'}, default 0\n        Determine if rows or columns which contain missing values are\n        removed.\n\n        * 0, or 'index' : Drop rows which contain missing values.\n        * 1, or 'columns' : Drop columns which contain missing value.\n\n        .. versionchanged:: 1.0.0\n\n           Pass tuple or list to drop on multiple axes.\n           Only a single axis is allowed.\n\n    how : {'any', 'all'}, default 'any'\n        Determine if row or column is removed from DataFrame, when we have\n        at least one NA or all NA.\n\n        * 'any' : If any NA values are present, drop that row or column.\n        * 'all' : If all values are NA, drop that row or column.\n\n    thresh : int, optional\n        Require that many non-NA values.\n    subset : array-like, optional\n        Labels along other axis to consider, e.g. if you are dropping rows\n        these would be a list of columns to include.\n    inplace : bool, default False\n        If True, do operation inplace and return None.\n\n    Returns\n    -------\n    DataFrame\n        DataFrame with NA entries dropped from it.\n\n    See Also\n    --------\n    DataFrame.isna: Indicate missing values.\n    DataFrame.notna : Indicate existing (non-missing) values.\n    DataFrame.fillna : Replace missing values.\n    Series.dropna : Drop missing values.\n    Index.dropna : Drop missing indices.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame({\"name\": ['Alfred', 'Batman', 'Catwoman'],\n    ...                    \"toy\": [np.nan, 'Batmobile', 'Bullwhip'],\n    ...                    \"born\": [pd.NaT, pd.Timestamp(\"1940-04-25\"),\n    ...                             pd.NaT]})\n    >>> df\n           name        toy       born\n    0    Alfred        NaN        NaT\n    1    Batman  Batmobile 1940-04-25\n    2  Catwoman   Bullwhip        NaT\n\n    Drop the rows where at least one element is missing.\n\n    >>> df.dropna()\n         name        toy       born\n    1  Batman  Batmobile 1940-04-25\n\n    Drop the columns where at least one element is missing.\n\n    >>> df.dropna(axis='columns')\n           name\n    0    Alfred\n    1    Batman\n    2  Catwoman\n\n    Drop the rows where all elements are missing.\n\n    >>> df.dropna(how='all')\n           name        toy       born\n    0    Alfred        NaN        NaT\n    1    Batman  Batmobile 1940-04-25\n    2  Catwoman   Bullwhip        NaT\n\n    Keep only the rows with at least 2 non-NA values.\n\n    >>> df.dropna(thresh=2)\n           name        toy       born\n    1    Batman  Batmobile 1940-04-25\n    2  Catwoman   Bullwhip        NaT\n\n    Define in which columns to look for missing values.\n\n    >>> df.dropna(subset=['name', 'born'])\n           name        toy       born\n    1    Batman  Batmobile 1940-04-25\n\n    Keep the DataFrame with valid entries in the same variable.\n\n    >>> df.dropna(inplace=True)\n    >>> df\n         name        toy       born\n    1  Batman  Batmobile 1940-04-25\n    \"\"\"\n    inplace = validate_bool_kwarg(inplace, 'inplace')\n    if isinstance(axis, (tuple, list)):\n        raise TypeError('supplying multiple axes to axis is no longer supported.')\n    axis = self._get_axis_number(axis)\n    agg_axis = 1 - axis\n    agg_obj = self\n    if subset is not None:\n        ax = self._get_axis(agg_axis)\n        indices = ax.get_indexer_for(subset)\n        check = indices == -1\n        if check.any():\n            raise KeyError(list(np.compress(check, subset)))\n        agg_obj = self.take(indices, axis=agg_axis)\n    count = agg_obj.count(axis=agg_axis)\n    if thresh is not None:\n        mask = count >= thresh\n    elif how == 'any':\n        mask = count == len(agg_obj._get_axis(agg_axis))\n    elif how == 'all':\n        mask = count > 0\n    elif how is not None:\n        raise ValueError(f'invalid how option: {how}')\n    else:\n        raise TypeError('must specify how or thresh')\n    result = self.loc(axis=axis)[mask]\n    if inplace:\n        self._update_inplace(result)\n    else:\n        return result",
                            "def drop_duplicates(self, subset: Optional[Union[Hashable, Sequence[Hashable]]]=None, keep: Union[str, bool]='first', inplace: bool=False, ignore_index: bool=False) -> Optional['DataFrame']:\n    \"\"\"\n    Return DataFrame with duplicate rows removed.\n\n    Considering certain columns is optional. Indexes, including time indexes\n    are ignored.\n\n    Parameters\n    ----------\n    subset : column label or sequence of labels, optional\n        Only consider certain columns for identifying duplicates, by\n        default use all of the columns.\n    keep : {'first', 'last', False}, default 'first'\n        Determines which duplicates (if any) to keep.\n        - ``first`` : Drop duplicates except for the first occurrence.\n        - ``last`` : Drop duplicates except for the last occurrence.\n        - False : Drop all duplicates.\n    inplace : bool, default False\n        Whether to drop duplicates in place or to return a copy.\n    ignore_index : bool, default False\n        If True, the resulting axis will be labeled 0, 1, \u2026, n - 1.\n\n        .. versionadded:: 1.0.0\n\n    Returns\n    -------\n    DataFrame\n        DataFrame with duplicates removed or None if ``inplace=True``.\n\n    See Also\n    --------\n    DataFrame.value_counts: Count unique combinations of columns.\n    \"\"\"\n    if self.empty:\n        return self.copy()\n    inplace = validate_bool_kwarg(inplace, 'inplace')\n    duplicated = self.duplicated(subset, keep=keep)\n    if inplace:\n        inds, = np.asarray(-duplicated).nonzero()\n        new_data = self._data.take(inds)\n        if ignore_index:\n            new_data.axes[1] = ibase.default_index(len(inds))\n        self._update_inplace(new_data)\n    else:\n        result = self[-duplicated]\n        if ignore_index:\n            result.index = ibase.default_index(len(result))\n        return result\n    return None",
                            "def duplicated(self, subset: Optional[Union[Hashable, Sequence[Hashable]]]=None, keep: Union[str, bool]='first') -> 'Series':\n    \"\"\"\n    Return boolean Series denoting duplicate rows.\n\n    Considering certain columns is optional.\n\n    Parameters\n    ----------\n    subset : column label or sequence of labels, optional\n        Only consider certain columns for identifying duplicates, by\n        default use all of the columns.\n    keep : {'first', 'last', False}, default 'first'\n        Determines which duplicates (if any) to mark.\n\n        - ``first`` : Mark duplicates as ``True`` except for the first occurrence.\n        - ``last`` : Mark duplicates as ``True`` except for the last occurrence.\n        - False : Mark all duplicates as ``True``.\n\n    Returns\n    -------\n    Series\n    \"\"\"\n    from pandas.core.sorting import get_group_index\n    from pandas._libs.hashtable import duplicated_int64, _SIZE_HINT_LIMIT\n    if self.empty:\n        return Series(dtype=bool)\n\n    def f(vals):\n        labels, shape = algorithms.factorize(vals, size_hint=min(len(self), _SIZE_HINT_LIMIT))\n        return (labels.astype('i8', copy=False), len(shape))\n    if subset is None:\n        subset = self.columns\n    elif not np.iterable(subset) or isinstance(subset, str) or (isinstance(subset, tuple) and subset in self.columns):\n        subset = (subset,)\n    subset = cast(Iterable, subset)\n    diff = Index(subset).difference(self.columns)\n    if not diff.empty:\n        raise KeyError(diff)\n    vals = (col.values for name, col in self.items() if name in subset)\n    labels, shape = map(list, zip(*map(f, vals)))\n    ids = get_group_index(labels, shape, sort=False, xnull=False)\n    return Series(duplicated_int64(ids, keep), index=self.index)",
                            "@Substitution(**_shared_doc_kwargs)\n@Appender(NDFrame.sort_values.__doc__)\ndef sort_values(self, by, axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last', ignore_index=False):\n    inplace = validate_bool_kwarg(inplace, 'inplace')\n    axis = self._get_axis_number(axis)\n    if not isinstance(by, list):\n        by = [by]\n    if is_sequence(ascending) and len(by) != len(ascending):\n        raise ValueError(f'Length of ascending ({len(ascending)}) != length of by ({len(by)})')\n    if len(by) > 1:\n        from pandas.core.sorting import lexsort_indexer\n        keys = [self._get_label_or_level_values(x, axis=axis) for x in by]\n        indexer = lexsort_indexer(keys, orders=ascending, na_position=na_position)\n        indexer = ensure_platform_int(indexer)\n    else:\n        from pandas.core.sorting import nargsort\n        by = by[0]\n        k = self._get_label_or_level_values(by, axis=axis)\n        if isinstance(ascending, (tuple, list)):\n            ascending = ascending[0]\n        indexer = nargsort(k, kind=kind, ascending=ascending, na_position=na_position)\n    new_data = self._data.take(indexer, axis=self._get_block_manager_axis(axis), verify=False)\n    if ignore_index:\n        new_data.axes[1] = ibase.default_index(len(indexer))\n    if inplace:\n        return self._update_inplace(new_data)\n    else:\n        return self._constructor(new_data).__finalize__(self)",
                            "def sort_index(self, axis=0, level=None, ascending: bool=True, inplace: bool=False, kind: str='quicksort', na_position: str='last', sort_remaining: bool=True, ignore_index: bool=False):\n    \"\"\"\n    Sort object by labels (along an axis).\n\n    Parameters\n    ----------\n    axis : {0 or 'index', 1 or 'columns'}, default 0\n        The axis along which to sort.  The value 0 identifies the rows,\n        and 1 identifies the columns.\n    level : int or level name or list of ints or list of level names\n        If not None, sort on values in specified index level(s).\n    ascending : bool or list of bools, default True\n        Sort ascending vs. descending. When the index is a MultiIndex the\n        sort direction can be controlled for each level individually.\n    inplace : bool, default False\n        If True, perform operation in-place.\n    kind : {'quicksort', 'mergesort', 'heapsort'}, default 'quicksort'\n        Choice of sorting algorithm. See also ndarray.np.sort for more\n        information.  `mergesort` is the only stable algorithm. For\n        DataFrames, this option is only applied when sorting on a single\n        column or label.\n    na_position : {'first', 'last'}, default 'last'\n        Puts NaNs at the beginning if `first`; `last` puts NaNs at the end.\n        Not implemented for MultiIndex.\n    sort_remaining : bool, default True\n        If True and sorting by level and index is multilevel, sort by other\n        levels too (in order) after sorting by specified level.\n    ignore_index : bool, default False\n        If True, the resulting axis will be labeled 0, 1, \u2026, n - 1.\n\n        .. versionadded:: 1.0.0\n\n    Returns\n    -------\n    sorted_obj : DataFrame or None\n        DataFrame with sorted index if inplace=False, None otherwise.\n    \"\"\"\n    inplace = validate_bool_kwarg(inplace, 'inplace')\n    axis = self._get_axis_number(axis)\n    labels = self._get_axis(axis)\n    labels = labels._sort_levels_monotonic()\n    if level is not None:\n        new_axis, indexer = labels.sortlevel(level, ascending=ascending, sort_remaining=sort_remaining)\n    elif isinstance(labels, ABCMultiIndex):\n        from pandas.core.sorting import lexsort_indexer\n        indexer = lexsort_indexer(labels._get_codes_for_sorting(), orders=ascending, na_position=na_position)\n    else:\n        from pandas.core.sorting import nargsort\n        if ascending and labels.is_monotonic_increasing or (not ascending and labels.is_monotonic_decreasing):\n            if inplace:\n                return\n            else:\n                return self.copy()\n        indexer = nargsort(labels, kind=kind, ascending=ascending, na_position=na_position)\n    baxis = self._get_block_manager_axis(axis)\n    new_data = self._data.take(indexer, axis=baxis, verify=False)\n    new_data.axes[baxis] = new_data.axes[baxis]._sort_levels_monotonic()\n    if ignore_index:\n        new_data.axes[1] = ibase.default_index(len(indexer))\n    if inplace:\n        return self._update_inplace(new_data)\n    else:\n        return self._constructor(new_data).__finalize__(self)",
                            "def value_counts(self, subset: Optional[Sequence[Label]]=None, normalize: bool=False, sort: bool=True, ascending: bool=False):\n    \"\"\"\n    Return a Series containing counts of unique rows in the DataFrame.\n\n    .. versionadded:: 1.1.0\n\n    Parameters\n    ----------\n    subset : list-like, optional\n        Columns to use when counting unique combinations.\n    normalize : bool, default False\n        Return proportions rather than frequencies.\n    sort : bool, default True\n        Sort by frequencies.\n    ascending : bool, default False\n        Sort in ascending order.\n\n    Returns\n    -------\n    Series\n\n    See Also\n    --------\n    Series.value_counts: Equivalent method on Series.\n\n    Notes\n    -----\n    The returned Series will have a MultiIndex with one level per input\n    column. By default, rows that contain any NA values are omitted from\n    the result. By default, the resulting Series will be in descending\n    order so that the first element is the most frequently-occurring row.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame({'num_legs': [2, 4, 4, 6],\n    ...                    'num_wings': [2, 0, 0, 0]},\n    ...                   index=['falcon', 'dog', 'cat', 'ant'])\n    >>> df\n            num_legs  num_wings\n    falcon         2          2\n    dog            4          0\n    cat            4          0\n    ant            6          0\n\n    >>> df.value_counts()\n    num_legs  num_wings\n    4         0            2\n    6         0            1\n    2         2            1\n    dtype: int64\n\n    >>> df.value_counts(sort=False)\n    num_legs  num_wings\n    2         2            1\n    4         0            2\n    6         0            1\n    dtype: int64\n\n    >>> df.value_counts(ascending=True)\n    num_legs  num_wings\n    2         2            1\n    6         0            1\n    4         0            2\n    dtype: int64\n\n    >>> df.value_counts(normalize=True)\n    num_legs  num_wings\n    4         0            0.50\n    6         0            0.25\n    2         2            0.25\n    dtype: float64\n    \"\"\"\n    if subset is None:\n        subset = self.columns.tolist()\n    counts = self.groupby(subset).size()\n    if sort:\n        counts = counts.sort_values(ascending=ascending)\n    if normalize:\n        counts /= counts.sum()\n    if len(subset) == 1:\n        counts.index = MultiIndex.from_arrays([counts.index], names=[counts.index.name])\n    return counts",
                            "def nlargest(self, n, columns, keep='first') -> 'DataFrame':\n    \"\"\"\n    Return the first `n` rows ordered by `columns` in descending order.\n\n    Return the first `n` rows with the largest values in `columns`, in\n    descending order. The columns that are not specified are returned as\n    well, but not used for ordering.\n\n    This method is equivalent to\n    ``df.sort_values(columns, ascending=False).head(n)``, but more\n    performant.\n\n    Parameters\n    ----------\n    n : int\n        Number of rows to return.\n    columns : label or list of labels\n        Column label(s) to order by.\n    keep : {'first', 'last', 'all'}, default 'first'\n        Where there are duplicate values:\n\n        - `first` : prioritize the first occurrence(s)\n        - `last` : prioritize the last occurrence(s)\n        - ``all`` : do not drop any duplicates, even it means\n                    selecting more than `n` items.\n\n        .. versionadded:: 0.24.0\n\n    Returns\n    -------\n    DataFrame\n        The first `n` rows ordered by the given columns in descending\n        order.\n\n    See Also\n    --------\n    DataFrame.nsmallest : Return the first `n` rows ordered by `columns` in\n        ascending order.\n    DataFrame.sort_values : Sort DataFrame by the values.\n    DataFrame.head : Return the first `n` rows without re-ordering.\n\n    Notes\n    -----\n    This function cannot be used with all column types. For example, when\n    specifying columns with `object` or `category` dtypes, ``TypeError`` is\n    raised.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame({'population': [59000000, 65000000, 434000,\n    ...                                   434000, 434000, 337000, 11300,\n    ...                                   11300, 11300],\n    ...                    'GDP': [1937894, 2583560 , 12011, 4520, 12128,\n    ...                            17036, 182, 38, 311],\n    ...                    'alpha-2': [\"IT\", \"FR\", \"MT\", \"MV\", \"BN\",\n    ...                                \"IS\", \"NR\", \"TV\", \"AI\"]},\n    ...                   index=[\"Italy\", \"France\", \"Malta\",\n    ...                          \"Maldives\", \"Brunei\", \"Iceland\",\n    ...                          \"Nauru\", \"Tuvalu\", \"Anguilla\"])\n    >>> df\n              population      GDP alpha-2\n    Italy       59000000  1937894      IT\n    France      65000000  2583560      FR\n    Malta         434000    12011      MT\n    Maldives      434000     4520      MV\n    Brunei        434000    12128      BN\n    Iceland       337000    17036      IS\n    Nauru          11300      182      NR\n    Tuvalu         11300       38      TV\n    Anguilla       11300      311      AI\n\n    In the following example, we will use ``nlargest`` to select the three\n    rows having the largest values in column \"population\".\n\n    >>> df.nlargest(3, 'population')\n            population      GDP alpha-2\n    France    65000000  2583560      FR\n    Italy     59000000  1937894      IT\n    Malta       434000    12011      MT\n\n    When using ``keep='last'``, ties are resolved in reverse order:\n\n    >>> df.nlargest(3, 'population', keep='last')\n            population      GDP alpha-2\n    France    65000000  2583560      FR\n    Italy     59000000  1937894      IT\n    Brunei      434000    12128      BN\n\n    When using ``keep='all'``, all duplicate items are maintained:\n\n    >>> df.nlargest(3, 'population', keep='all')\n              population      GDP alpha-2\n    France      65000000  2583560      FR\n    Italy       59000000  1937894      IT\n    Malta         434000    12011      MT\n    Maldives      434000     4520      MV\n    Brunei        434000    12128      BN\n\n    To order by the largest values in column \"population\" and then \"GDP\",\n    we can specify multiple columns like in the next example.\n\n    >>> df.nlargest(3, ['population', 'GDP'])\n            population      GDP alpha-2\n    France    65000000  2583560      FR\n    Italy     59000000  1937894      IT\n    Brunei      434000    12128      BN\n    \"\"\"\n    return algorithms.SelectNFrame(self, n=n, keep=keep, columns=columns).nlargest()",
                            "def nsmallest(self, n, columns, keep='first') -> 'DataFrame':\n    \"\"\"\n    Return the first `n` rows ordered by `columns` in ascending order.\n\n    Return the first `n` rows with the smallest values in `columns`, in\n    ascending order. The columns that are not specified are returned as\n    well, but not used for ordering.\n\n    This method is equivalent to\n    ``df.sort_values(columns, ascending=True).head(n)``, but more\n    performant.\n\n    Parameters\n    ----------\n    n : int\n        Number of items to retrieve.\n    columns : list or str\n        Column name or names to order by.\n    keep : {'first', 'last', 'all'}, default 'first'\n        Where there are duplicate values:\n\n        - ``first`` : take the first occurrence.\n        - ``last`` : take the last occurrence.\n        - ``all`` : do not drop any duplicates, even it means\n          selecting more than `n` items.\n\n        .. versionadded:: 0.24.0\n\n    Returns\n    -------\n    DataFrame\n\n    See Also\n    --------\n    DataFrame.nlargest : Return the first `n` rows ordered by `columns` in\n        descending order.\n    DataFrame.sort_values : Sort DataFrame by the values.\n    DataFrame.head : Return the first `n` rows without re-ordering.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame({'population': [59000000, 65000000, 434000,\n    ...                                   434000, 434000, 337000, 337000,\n    ...                                   11300, 11300],\n    ...                    'GDP': [1937894, 2583560 , 12011, 4520, 12128,\n    ...                            17036, 182, 38, 311],\n    ...                    'alpha-2': [\"IT\", \"FR\", \"MT\", \"MV\", \"BN\",\n    ...                                \"IS\", \"NR\", \"TV\", \"AI\"]},\n    ...                   index=[\"Italy\", \"France\", \"Malta\",\n    ...                          \"Maldives\", \"Brunei\", \"Iceland\",\n    ...                          \"Nauru\", \"Tuvalu\", \"Anguilla\"])\n    >>> df\n              population      GDP alpha-2\n    Italy       59000000  1937894      IT\n    France      65000000  2583560      FR\n    Malta         434000    12011      MT\n    Maldives      434000     4520      MV\n    Brunei        434000    12128      BN\n    Iceland       337000    17036      IS\n    Nauru         337000      182      NR\n    Tuvalu         11300       38      TV\n    Anguilla       11300      311      AI\n\n    In the following example, we will use ``nsmallest`` to select the\n    three rows having the smallest values in column \"population\".\n\n    >>> df.nsmallest(3, 'population')\n              population    GDP alpha-2\n    Tuvalu         11300     38      TV\n    Anguilla       11300    311      AI\n    Iceland       337000  17036\t     IS\n\n    When using ``keep='last'``, ties are resolved in reverse order:\n\n    >>> df.nsmallest(3, 'population', keep='last')\n              population  GDP alpha-2\n    Anguilla       11300  311      AI\n    Tuvalu         11300   38      TV\n    Nauru         337000  182      NR\n\n    When using ``keep='all'``, all duplicate items are maintained:\n\n    >>> df.nsmallest(3, 'population', keep='all')\n              population    GDP alpha-2\n    Tuvalu         11300     38      TV\n    Anguilla       11300    311      AI\n    Iceland       337000  17036      IS\n    Nauru         337000    182      NR\n\n    To order by the smallest values in column \"population\" and then \"GDP\", we can\n    specify multiple columns like in the next example.\n\n    >>> df.nsmallest(3, ['population', 'GDP'])\n              population  GDP alpha-2\n    Tuvalu         11300   38      TV\n    Anguilla       11300  311      AI\n    Nauru         337000  182      NR\n    \"\"\"\n    return algorithms.SelectNFrame(self, n=n, keep=keep, columns=columns).nsmallest()",
                            "def swaplevel(self, i=-2, j=-1, axis=0) -> 'DataFrame':\n    \"\"\"\n    Swap levels i and j in a MultiIndex on a particular axis.\n\n    Parameters\n    ----------\n    i, j : int or str\n        Levels of the indices to be swapped. Can pass level name as string.\n\n    Returns\n    -------\n    DataFrame\n    \"\"\"\n    result = self.copy()\n    axis = self._get_axis_number(axis)\n    if not isinstance(result._get_axis(axis), ABCMultiIndex):\n        raise TypeError('Can only swap levels on a hierarchical axis.')\n    if axis == 0:\n        assert isinstance(result.index, ABCMultiIndex)\n        result.index = result.index.swaplevel(i, j)\n    else:\n        assert isinstance(result.columns, ABCMultiIndex)\n        result.columns = result.columns.swaplevel(i, j)\n    return result",
                            "def reorder_levels(self, order, axis=0) -> 'DataFrame':\n    \"\"\"\n    Rearrange index levels using input order. May not drop or duplicate levels.\n\n    Parameters\n    ----------\n    order : list of int or list of str\n        List representing new level order. Reference level by number\n        (position) or by key (label).\n    axis : int\n        Where to reorder levels.\n\n    Returns\n    -------\n    DataFrame\n    \"\"\"\n    axis = self._get_axis_number(axis)\n    if not isinstance(self._get_axis(axis), ABCMultiIndex):\n        raise TypeError('Can only reorder levels on a hierarchical axis.')\n    result = self.copy()\n    if axis == 0:\n        assert isinstance(result.index, ABCMultiIndex)\n        result.index = result.index.reorder_levels(order)\n    else:\n        assert isinstance(result.columns, ABCMultiIndex)\n        result.columns = result.columns.reorder_levels(order)\n    return result",
                            "def _combine_frame(self, other: 'DataFrame', func, fill_value=None):\n    if fill_value is None:\n        _arith_op = func\n    else:\n\n        def _arith_op(left, right):\n            left, right = ops.fill_binop(left, right, fill_value)\n            return func(left, right)\n    if ops.should_series_dispatch(self, other, func):\n        new_data = ops.dispatch_to_series(self, other, _arith_op)\n    else:\n        with np.errstate(all='ignore'):\n            res_values = _arith_op(self.values, other.values)\n        new_data = dispatch_fill_zeros(func, self.values, other.values, res_values)\n    return new_data",
                            "def _construct_result(self, result) -> 'DataFrame':\n    \"\"\"\n    Wrap the result of an arithmetic, comparison, or logical operation.\n\n    Parameters\n    ----------\n    result : DataFrame\n\n    Returns\n    -------\n    DataFrame\n    \"\"\"\n    out = self._constructor(result, index=self.index, copy=False)\n    out.columns = self.columns\n    return out",
                            "def combine(self, other: 'DataFrame', func, fill_value=None, overwrite=True) -> 'DataFrame':\n    \"\"\"\n    Perform column-wise combine with another DataFrame.\n\n    Combines a DataFrame with `other` DataFrame using `func`\n    to element-wise combine columns. The row and column indexes of the\n    resulting DataFrame will be the union of the two.\n\n    Parameters\n    ----------\n    other : DataFrame\n        The DataFrame to merge column-wise.\n    func : function\n        Function that takes two series as inputs and return a Series or a\n        scalar. Used to merge the two dataframes column by columns.\n    fill_value : scalar value, default None\n        The value to fill NaNs with prior to passing any column to the\n        merge func.\n    overwrite : bool, default True\n        If True, columns in `self` that do not exist in `other` will be\n        overwritten with NaNs.\n\n    Returns\n    -------\n    DataFrame\n        Combination of the provided DataFrames.\n\n    See Also\n    --------\n    DataFrame.combine_first : Combine two DataFrame objects and default to\n        non-null values in frame calling the method.\n\n    Examples\n    --------\n    Combine using a simple function that chooses the smaller column.\n\n    >>> df1 = pd.DataFrame({'A': [0, 0], 'B': [4, 4]})\n    >>> df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})\n    >>> take_smaller = lambda s1, s2: s1 if s1.sum() < s2.sum() else s2\n    >>> df1.combine(df2, take_smaller)\n       A  B\n    0  0  3\n    1  0  3\n\n    Example using a true element-wise combine function.\n\n    >>> df1 = pd.DataFrame({'A': [5, 0], 'B': [2, 4]})\n    >>> df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})\n    >>> df1.combine(df2, np.minimum)\n       A  B\n    0  1  2\n    1  0  3\n\n    Using `fill_value` fills Nones prior to passing the column to the\n    merge function.\n\n    >>> df1 = pd.DataFrame({'A': [0, 0], 'B': [None, 4]})\n    >>> df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})\n    >>> df1.combine(df2, take_smaller, fill_value=-5)\n       A    B\n    0  0 -5.0\n    1  0  4.0\n\n    However, if the same element in both dataframes is None, that None\n    is preserved\n\n    >>> df1 = pd.DataFrame({'A': [0, 0], 'B': [None, 4]})\n    >>> df2 = pd.DataFrame({'A': [1, 1], 'B': [None, 3]})\n    >>> df1.combine(df2, take_smaller, fill_value=-5)\n        A    B\n    0  0 -5.0\n    1  0  3.0\n\n    Example that demonstrates the use of `overwrite` and behavior when\n    the axis differ between the dataframes.\n\n    >>> df1 = pd.DataFrame({'A': [0, 0], 'B': [4, 4]})\n    >>> df2 = pd.DataFrame({'B': [3, 3], 'C': [-10, 1], }, index=[1, 2])\n    >>> df1.combine(df2, take_smaller)\n         A    B     C\n    0  NaN  NaN   NaN\n    1  NaN  3.0 -10.0\n    2  NaN  3.0   1.0\n\n    >>> df1.combine(df2, take_smaller, overwrite=False)\n         A    B     C\n    0  0.0  NaN   NaN\n    1  0.0  3.0 -10.0\n    2  NaN  3.0   1.0\n\n    Demonstrating the preference of the passed in dataframe.\n\n    >>> df2 = pd.DataFrame({'B': [3, 3], 'C': [1, 1], }, index=[1, 2])\n    >>> df2.combine(df1, take_smaller)\n       A    B   C\n    0  0.0  NaN NaN\n    1  0.0  3.0 NaN\n    2  NaN  3.0 NaN\n\n    >>> df2.combine(df1, take_smaller, overwrite=False)\n         A    B   C\n    0  0.0  NaN NaN\n    1  0.0  3.0 1.0\n    2  NaN  3.0 1.0\n    \"\"\"\n    other_idxlen = len(other.index)\n    this, other = self.align(other, copy=False)\n    new_index = this.index\n    if other.empty and len(new_index) == len(self.index):\n        return self.copy()\n    if self.empty and len(other) == other_idxlen:\n        return other.copy()\n    new_columns = this.columns.union(other.columns)\n    do_fill = fill_value is not None\n    result = {}\n    for col in new_columns:\n        series = this[col]\n        otherSeries = other[col]\n        this_dtype = series.dtype\n        other_dtype = otherSeries.dtype\n        this_mask = isna(series)\n        other_mask = isna(otherSeries)\n        if not overwrite and other_mask.all():\n            result[col] = this[col].copy()\n            continue\n        if do_fill:\n            series = series.copy()\n            otherSeries = otherSeries.copy()\n            series[this_mask] = fill_value\n            otherSeries[other_mask] = fill_value\n        if col not in self.columns:\n            new_dtype = other_dtype\n            try:\n                series = series.astype(new_dtype, copy=False)\n            except ValueError:\n                pass\n        else:\n            new_dtype = find_common_type([this_dtype, other_dtype])\n            if not is_dtype_equal(this_dtype, new_dtype):\n                series = series.astype(new_dtype)\n            if not is_dtype_equal(other_dtype, new_dtype):\n                otherSeries = otherSeries.astype(new_dtype)\n        arr = func(series, otherSeries)\n        arr = maybe_downcast_to_dtype(arr, this_dtype)\n        result[col] = arr\n    return self._constructor(result, index=new_index, columns=new_columns)",
                            "def combine_first(self, other: 'DataFrame') -> 'DataFrame':\n    \"\"\"\n    Update null elements with value in the same location in `other`.\n\n    Combine two DataFrame objects by filling null values in one DataFrame\n    with non-null values from other DataFrame. The row and column indexes\n    of the resulting DataFrame will be the union of the two.\n\n    Parameters\n    ----------\n    other : DataFrame\n        Provided DataFrame to use to fill null values.\n\n    Returns\n    -------\n    DataFrame\n\n    See Also\n    --------\n    DataFrame.combine : Perform series-wise operation on two DataFrames\n        using a given function.\n\n    Examples\n    --------\n    >>> df1 = pd.DataFrame({'A': [None, 0], 'B': [None, 4]})\n    >>> df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})\n    >>> df1.combine_first(df2)\n         A    B\n    0  1.0  3.0\n    1  0.0  4.0\n\n    Null values still persist if the location of that null value\n    does not exist in `other`\n\n    >>> df1 = pd.DataFrame({'A': [None, 0], 'B': [4, None]})\n    >>> df2 = pd.DataFrame({'B': [3, 3], 'C': [1, 1]}, index=[1, 2])\n    >>> df1.combine_first(df2)\n         A    B    C\n    0  NaN  4.0  NaN\n    1  0.0  3.0  1.0\n    2  NaN  3.0  1.0\n    \"\"\"\n    import pandas.core.computation.expressions as expressions\n\n    def extract_values(arr):\n        if isinstance(arr, (ABCIndexClass, ABCSeries)):\n            arr = arr._values\n        if needs_i8_conversion(arr):\n            if is_extension_array_dtype(arr.dtype):\n                arr = arr.asi8\n            else:\n                arr = arr.view('i8')\n        return arr\n\n    def combiner(x, y):\n        mask = isna(x)\n        if isinstance(mask, (ABCIndexClass, ABCSeries)):\n            mask = mask._values\n        x_values = extract_values(x)\n        y_values = extract_values(y)\n        if y.name not in self.columns:\n            return y_values\n        return expressions.where(mask, y_values, x_values)\n    return self.combine(other, combiner, overwrite=False)",
                            "def update(self, other, join='left', overwrite=True, filter_func=None, errors='ignore') -> None:\n    \"\"\"\n    Modify in place using non-NA values from another DataFrame.\n\n    Aligns on indices. There is no return value.\n\n    Parameters\n    ----------\n    other : DataFrame, or object coercible into a DataFrame\n        Should have at least one matching index/column label\n        with the original DataFrame. If a Series is passed,\n        its name attribute must be set, and that will be\n        used as the column name to align with the original DataFrame.\n    join : {'left'}, default 'left'\n        Only left join is implemented, keeping the index and columns of the\n        original object.\n    overwrite : bool, default True\n        How to handle non-NA values for overlapping keys:\n\n        * True: overwrite original DataFrame's values\n          with values from `other`.\n        * False: only update values that are NA in\n          the original DataFrame.\n\n    filter_func : callable(1d-array) -> bool 1d-array, optional\n        Can choose to replace values other than NA. Return True for values\n        that should be updated.\n    errors : {'raise', 'ignore'}, default 'ignore'\n        If 'raise', will raise a ValueError if the DataFrame and `other`\n        both contain non-NA data in the same place.\n\n        .. versionchanged:: 0.24.0\n           Changed from `raise_conflict=False|True`\n           to `errors='ignore'|'raise'`.\n\n    Returns\n    -------\n    None : method directly changes calling object\n\n    Raises\n    ------\n    ValueError\n        * When `errors='raise'` and there's overlapping non-NA data.\n        * When `errors` is not either `'ignore'` or `'raise'`\n    NotImplementedError\n        * If `join != 'left'`\n\n    See Also\n    --------\n    dict.update : Similar method for dictionaries.\n    DataFrame.merge : For column(s)-on-columns(s) operations.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame({'A': [1, 2, 3],\n    ...                    'B': [400, 500, 600]})\n    >>> new_df = pd.DataFrame({'B': [4, 5, 6],\n    ...                        'C': [7, 8, 9]})\n    >>> df.update(new_df)\n    >>> df\n       A  B\n    0  1  4\n    1  2  5\n    2  3  6\n\n    The DataFrame's length does not increase as a result of the update,\n    only values at matching index/column labels are updated.\n\n    >>> df = pd.DataFrame({'A': ['a', 'b', 'c'],\n    ...                    'B': ['x', 'y', 'z']})\n    >>> new_df = pd.DataFrame({'B': ['d', 'e', 'f', 'g', 'h', 'i']})\n    >>> df.update(new_df)\n    >>> df\n       A  B\n    0  a  d\n    1  b  e\n    2  c  f\n\n    For Series, it's name attribute must be set.\n\n    >>> df = pd.DataFrame({'A': ['a', 'b', 'c'],\n    ...                    'B': ['x', 'y', 'z']})\n    >>> new_column = pd.Series(['d', 'e'], name='B', index=[0, 2])\n    >>> df.update(new_column)\n    >>> df\n       A  B\n    0  a  d\n    1  b  y\n    2  c  e\n    >>> df = pd.DataFrame({'A': ['a', 'b', 'c'],\n    ...                    'B': ['x', 'y', 'z']})\n    >>> new_df = pd.DataFrame({'B': ['d', 'e']}, index=[1, 2])\n    >>> df.update(new_df)\n    >>> df\n       A  B\n    0  a  x\n    1  b  d\n    2  c  e\n\n    If `other` contains NaNs the corresponding values are not updated\n    in the original dataframe.\n\n    >>> df = pd.DataFrame({'A': [1, 2, 3],\n    ...                    'B': [400, 500, 600]})\n    >>> new_df = pd.DataFrame({'B': [4, np.nan, 6]})\n    >>> df.update(new_df)\n    >>> df\n       A      B\n    0  1    4.0\n    1  2  500.0\n    2  3    6.0\n    \"\"\"\n    import pandas.core.computation.expressions as expressions\n    if join != 'left':\n        raise NotImplementedError('Only left join is supported')\n    if errors not in ['ignore', 'raise']:\n        raise ValueError(\"The parameter errors must be either 'ignore' or 'raise'\")\n    if not isinstance(other, DataFrame):\n        other = DataFrame(other)\n    other = other.reindex_like(self)\n    for col in self.columns:\n        this = self[col]._values\n        that = other[col]._values\n        if filter_func is not None:\n            with np.errstate(all='ignore'):\n                mask = ~filter_func(this) | isna(that)\n        else:\n            if errors == 'raise':\n                mask_this = notna(that)\n                mask_that = notna(this)\n                if any(mask_this & mask_that):\n                    raise ValueError('Data overlaps.')\n            if overwrite:\n                mask = isna(that)\n            else:\n                mask = notna(this)\n        if mask.all():\n            continue\n        self[col] = expressions.where(mask, this, that)",
                            "@Appender('\\nExamples\\n--------\\n>>> df = pd.DataFrame({\\'Animal\\': [\\'Falcon\\', \\'Falcon\\',\\n...                               \\'Parrot\\', \\'Parrot\\'],\\n...                    \\'Max Speed\\': [380., 370., 24., 26.]})\\n>>> df\\n   Animal  Max Speed\\n0  Falcon      380.0\\n1  Falcon      370.0\\n2  Parrot       24.0\\n3  Parrot       26.0\\n>>> df.groupby([\\'Animal\\']).mean()\\n        Max Speed\\nAnimal\\nFalcon      375.0\\nParrot       25.0\\n\\n**Hierarchical Indexes**\\n\\nWe can groupby different levels of a hierarchical index\\nusing the `level` parameter:\\n\\n>>> arrays = [[\\'Falcon\\', \\'Falcon\\', \\'Parrot\\', \\'Parrot\\'],\\n...           [\\'Captive\\', \\'Wild\\', \\'Captive\\', \\'Wild\\']]\\n>>> index = pd.MultiIndex.from_arrays(arrays, names=(\\'Animal\\', \\'Type\\'))\\n>>> df = pd.DataFrame({\\'Max Speed\\': [390., 350., 30., 20.]},\\n...                   index=index)\\n>>> df\\n                Max Speed\\nAnimal Type\\nFalcon Captive      390.0\\n       Wild         350.0\\nParrot Captive       30.0\\n       Wild          20.0\\n>>> df.groupby(level=0).mean()\\n        Max Speed\\nAnimal\\nFalcon      370.0\\nParrot       25.0\\n>>> df.groupby(level=\"Type\").mean()\\n         Max Speed\\nType\\nCaptive      210.0\\nWild         185.0\\n')\n@Appender(_shared_docs['groupby'] % _shared_doc_kwargs)\ndef groupby(self, by=None, axis=0, level=None, as_index: bool=True, sort: bool=True, group_keys: bool=True, squeeze: bool=False, observed: bool=False) -> 'DataFrameGroupBy':\n    from pandas.core.groupby.generic import DataFrameGroupBy\n    if level is None and by is None:\n        raise TypeError(\"You have to supply one of 'by' and 'level'\")\n    axis = self._get_axis_number(axis)\n    return DataFrameGroupBy(obj=self, keys=by, axis=axis, level=level, as_index=as_index, sort=sort, group_keys=group_keys, squeeze=squeeze, observed=observed)",
                            "@Substitution('')\n@Appender(_shared_docs['pivot'])\ndef pivot(self, index=None, columns=None, values=None) -> 'DataFrame':\n    from pandas.core.reshape.pivot import pivot\n    return pivot(self, index=index, columns=columns, values=values)",
                            "@Substitution('')\n@Appender(_shared_docs['pivot_table'])\ndef pivot_table(self, values=None, index=None, columns=None, aggfunc='mean', fill_value=None, margins=False, dropna=True, margins_name='All', observed=False) -> 'DataFrame':\n    from pandas.core.reshape.pivot import pivot_table\n    return pivot_table(self, values=values, index=index, columns=columns, aggfunc=aggfunc, fill_value=fill_value, margins=margins, dropna=dropna, margins_name=margins_name, observed=observed)",
                            "def stack(self, level=-1, dropna=True):\n    \"\"\"\n    Stack the prescribed level(s) from columns to index.\n\n    Return a reshaped DataFrame or Series having a multi-level\n    index with one or more new inner-most levels compared to the current\n    DataFrame. The new inner-most levels are created by pivoting the\n    columns of the current dataframe:\n\n      - if the columns have a single level, the output is a Series;\n      - if the columns have multiple levels, the new index\n        level(s) is (are) taken from the prescribed level(s) and\n        the output is a DataFrame.\n\n    The new index levels are sorted.\n\n    Parameters\n    ----------\n    level : int, str, list, default -1\n        Level(s) to stack from the column axis onto the index\n        axis, defined as one index or label, or a list of indices\n        or labels.\n    dropna : bool, default True\n        Whether to drop rows in the resulting Frame/Series with\n        missing values. Stacking a column level onto the index\n        axis can create combinations of index and column values\n        that are missing from the original dataframe. See Examples\n        section.\n\n    Returns\n    -------\n    DataFrame or Series\n        Stacked dataframe or series.\n\n    See Also\n    --------\n    DataFrame.unstack : Unstack prescribed level(s) from index axis\n         onto column axis.\n    DataFrame.pivot : Reshape dataframe from long format to wide\n         format.\n    DataFrame.pivot_table : Create a spreadsheet-style pivot table\n         as a DataFrame.\n\n    Notes\n    -----\n    The function is named by analogy with a collection of books\n    being reorganized from being side by side on a horizontal\n    position (the columns of the dataframe) to being stacked\n    vertically on top of each other (in the index of the\n    dataframe).\n\n    Examples\n    --------\n    **Single level columns**\n\n    >>> df_single_level_cols = pd.DataFrame([[0, 1], [2, 3]],\n    ...                                     index=['cat', 'dog'],\n    ...                                     columns=['weight', 'height'])\n\n    Stacking a dataframe with a single level column axis returns a Series:\n\n    >>> df_single_level_cols\n         weight height\n    cat       0      1\n    dog       2      3\n    >>> df_single_level_cols.stack()\n    cat  weight    0\n         height    1\n    dog  weight    2\n         height    3\n    dtype: int64\n\n    **Multi level columns: simple case**\n\n    >>> multicol1 = pd.MultiIndex.from_tuples([('weight', 'kg'),\n    ...                                        ('weight', 'pounds')])\n    >>> df_multi_level_cols1 = pd.DataFrame([[1, 2], [2, 4]],\n    ...                                     index=['cat', 'dog'],\n    ...                                     columns=multicol1)\n\n    Stacking a dataframe with a multi-level column axis:\n\n    >>> df_multi_level_cols1\n         weight\n             kg    pounds\n    cat       1        2\n    dog       2        4\n    >>> df_multi_level_cols1.stack()\n                weight\n    cat kg           1\n        pounds       2\n    dog kg           2\n        pounds       4\n\n    **Missing values**\n\n    >>> multicol2 = pd.MultiIndex.from_tuples([('weight', 'kg'),\n    ...                                        ('height', 'm')])\n    >>> df_multi_level_cols2 = pd.DataFrame([[1.0, 2.0], [3.0, 4.0]],\n    ...                                     index=['cat', 'dog'],\n    ...                                     columns=multicol2)\n\n    It is common to have missing values when stacking a dataframe\n    with multi-level columns, as the stacked dataframe typically\n    has more values than the original dataframe. Missing values\n    are filled with NaNs:\n\n    >>> df_multi_level_cols2\n        weight height\n            kg      m\n    cat    1.0    2.0\n    dog    3.0    4.0\n    >>> df_multi_level_cols2.stack()\n            height  weight\n    cat kg     NaN     1.0\n        m      2.0     NaN\n    dog kg     NaN     3.0\n        m      4.0     NaN\n\n    **Prescribing the level(s) to be stacked**\n\n    The first parameter controls which level or levels are stacked:\n\n    >>> df_multi_level_cols2.stack(0)\n                 kg    m\n    cat height  NaN  2.0\n        weight  1.0  NaN\n    dog height  NaN  4.0\n        weight  3.0  NaN\n    >>> df_multi_level_cols2.stack([0, 1])\n    cat  height  m     2.0\n         weight  kg    1.0\n    dog  height  m     4.0\n         weight  kg    3.0\n    dtype: float64\n\n    **Dropping missing values**\n\n    >>> df_multi_level_cols3 = pd.DataFrame([[None, 1.0], [2.0, 3.0]],\n    ...                                     index=['cat', 'dog'],\n    ...                                     columns=multicol2)\n\n    Note that rows where all values are missing are dropped by\n    default but this behaviour can be controlled via the dropna\n    keyword parameter:\n\n    >>> df_multi_level_cols3\n        weight height\n            kg      m\n    cat    NaN    1.0\n    dog    2.0    3.0\n    >>> df_multi_level_cols3.stack(dropna=False)\n            height  weight\n    cat kg     NaN     NaN\n        m      1.0     NaN\n    dog kg     NaN     2.0\n        m      3.0     NaN\n    >>> df_multi_level_cols3.stack(dropna=True)\n            height  weight\n    cat m      1.0     NaN\n    dog kg     NaN     2.0\n        m      3.0     NaN\n    \"\"\"\n    from pandas.core.reshape.reshape import stack, stack_multiple\n    if isinstance(level, (tuple, list)):\n        return stack_multiple(self, level, dropna=dropna)\n    else:\n        return stack(self, level, dropna=dropna)",
                            "def explode(self, column: Union[str, Tuple]) -> 'DataFrame':\n    \"\"\"\n    Transform each element of a list-like to a row, replicating index values.\n\n    .. versionadded:: 0.25.0\n\n    Parameters\n    ----------\n    column : str or tuple\n        Column to explode.\n\n    Returns\n    -------\n    DataFrame\n        Exploded lists to rows of the subset columns;\n        index will be duplicated for these rows.\n\n    Raises\n    ------\n    ValueError :\n        if columns of the frame are not unique.\n\n    See Also\n    --------\n    DataFrame.unstack : Pivot a level of the (necessarily hierarchical)\n        index labels.\n    DataFrame.melt : Unpivot a DataFrame from wide format to long format.\n    Series.explode : Explode a DataFrame from list-like columns to long format.\n\n    Notes\n    -----\n    This routine will explode list-likes including lists, tuples,\n    Series, and np.ndarray. The result dtype of the subset rows will\n    be object. Scalars will be returned unchanged. Empty list-likes will\n    result in a np.nan for that row.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame({'A': [[1, 2, 3], 'foo', [], [3, 4]], 'B': 1})\n    >>> df\n               A  B\n    0  [1, 2, 3]  1\n    1        foo  1\n    2         []  1\n    3     [3, 4]  1\n\n    >>> df.explode('A')\n         A  B\n    0    1  1\n    0    2  1\n    0    3  1\n    1  foo  1\n    2  NaN  1\n    3    3  1\n    3    4  1\n    \"\"\"\n    if not (is_scalar(column) or isinstance(column, tuple)):\n        raise ValueError('column must be a scalar')\n    if not self.columns.is_unique:\n        raise ValueError('columns must be unique')\n    df = self.reset_index(drop=True)\n    assert df is not None\n    result = df[column].explode()\n    result = df.drop([column], axis=1).join(result)\n    result.index = self.index.take(result.index)\n    result = result.reindex(columns=self.columns, copy=False)\n    return result",
                            "def unstack(self, level=-1, fill_value=None):\n    \"\"\"\n    Pivot a level of the (necessarily hierarchical) index labels.\n\n    Returns a DataFrame having a new level of column labels whose inner-most level\n    consists of the pivoted index labels.\n\n    If the index is not a MultiIndex, the output will be a Series\n    (the analogue of stack when the columns are not a MultiIndex).\n\n    The level involved will automatically get sorted.\n\n    Parameters\n    ----------\n    level : int, str, or list of these, default -1 (last level)\n        Level(s) of index to unstack, can pass level name.\n    fill_value : int, str or dict\n        Replace NaN with this value if the unstack produces missing values.\n\n    Returns\n    -------\n    Series or DataFrame\n\n    See Also\n    --------\n    DataFrame.pivot : Pivot a table based on column values.\n    DataFrame.stack : Pivot a level of the column labels (inverse operation\n        from `unstack`).\n\n    Examples\n    --------\n    >>> index = pd.MultiIndex.from_tuples([('one', 'a'), ('one', 'b'),\n    ...                                    ('two', 'a'), ('two', 'b')])\n    >>> s = pd.Series(np.arange(1.0, 5.0), index=index)\n    >>> s\n    one  a   1.0\n         b   2.0\n    two  a   3.0\n         b   4.0\n    dtype: float64\n\n    >>> s.unstack(level=-1)\n         a   b\n    one  1.0  2.0\n    two  3.0  4.0\n\n    >>> s.unstack(level=0)\n       one  two\n    a  1.0   3.0\n    b  2.0   4.0\n\n    >>> df = s.unstack(level=0)\n    >>> df.unstack()\n    one  a  1.0\n         b  2.0\n    two  a  3.0\n         b  4.0\n    dtype: float64\n    \"\"\"\n    from pandas.core.reshape.reshape import unstack\n    return unstack(self, level, fill_value)",
                            "@Appender(_shared_docs['melt'] % dict(caller='df.melt(', versionadded='\\n    .. versionadded:: 0.20.0\\n', other='melt'))\ndef melt(self, id_vars=None, value_vars=None, var_name=None, value_name='value', col_level=None) -> 'DataFrame':\n    from pandas.core.reshape.melt import melt\n    return melt(self, id_vars=id_vars, value_vars=value_vars, var_name=var_name, value_name=value_name, col_level=col_level)",
                            "def diff(self, periods=1, axis=0) -> 'DataFrame':\n    \"\"\"\n    First discrete difference of element.\n\n    Calculates the difference of a DataFrame element compared with another\n    element in the DataFrame (default is the element in the same column\n    of the previous row).\n\n    Parameters\n    ----------\n    periods : int, default 1\n        Periods to shift for calculating difference, accepts negative\n        values.\n    axis : {0 or 'index', 1 or 'columns'}, default 0\n        Take difference over rows (0) or columns (1).\n\n    Returns\n    -------\n    DataFrame\n\n    See Also\n    --------\n    Series.diff: First discrete difference for a Series.\n    DataFrame.pct_change: Percent change over given number of periods.\n    DataFrame.shift: Shift index by desired number of periods with an\n        optional time freq.\n\n    Notes\n    -----\n    For boolean dtypes, this uses :meth:`operator.xor` rather than\n    :meth:`operator.sub`.\n\n    Examples\n    --------\n    Difference with previous row\n\n    >>> df = pd.DataFrame({'a': [1, 2, 3, 4, 5, 6],\n    ...                    'b': [1, 1, 2, 3, 5, 8],\n    ...                    'c': [1, 4, 9, 16, 25, 36]})\n    >>> df\n       a  b   c\n    0  1  1   1\n    1  2  1   4\n    2  3  2   9\n    3  4  3  16\n    4  5  5  25\n    5  6  8  36\n\n    >>> df.diff()\n         a    b     c\n    0  NaN  NaN   NaN\n    1  1.0  0.0   3.0\n    2  1.0  1.0   5.0\n    3  1.0  1.0   7.0\n    4  1.0  2.0   9.0\n    5  1.0  3.0  11.0\n\n    Difference with previous column\n\n    >>> df.diff(axis=1)\n        a    b     c\n    0 NaN  0.0   0.0\n    1 NaN -1.0   3.0\n    2 NaN -1.0   7.0\n    3 NaN -1.0  13.0\n    4 NaN  0.0  20.0\n    5 NaN  2.0  28.0\n\n    Difference with 3rd previous row\n\n    >>> df.diff(periods=3)\n         a    b     c\n    0  NaN  NaN   NaN\n    1  NaN  NaN   NaN\n    2  NaN  NaN   NaN\n    3  3.0  2.0  15.0\n    4  3.0  4.0  21.0\n    5  3.0  6.0  27.0\n\n    Difference with following row\n\n    >>> df.diff(periods=-1)\n         a    b     c\n    0 -1.0  0.0  -3.0\n    1 -1.0 -1.0  -5.0\n    2 -1.0 -1.0  -7.0\n    3 -1.0 -2.0  -9.0\n    4 -1.0 -3.0 -11.0\n    5  NaN  NaN   NaN\n    \"\"\"\n    bm_axis = self._get_block_manager_axis(axis)\n    new_data = self._data.diff(n=periods, axis=bm_axis)\n    return self._constructor(new_data)",
                            "def _gotitem(self, key: Union[str, List[str]], ndim: int, subset: Optional[Union[Series, ABCDataFrame]]=None) -> Union[Series, ABCDataFrame]:\n    \"\"\"\n    Sub-classes to define. Return a sliced object.\n\n    Parameters\n    ----------\n    key : string / list of selections\n    ndim : 1,2\n        requested ndim of result\n    subset : object, default None\n        subset to act on\n    \"\"\"\n    if subset is None:\n        subset = self\n    elif subset.ndim == 1:\n        return subset\n    return subset[key]",
                            "@Substitution(see_also=_agg_summary_and_see_also_doc, examples=_agg_examples_doc, versionadded='\\n.. versionadded:: 0.20.0\\n', **_shared_doc_kwargs)\n@Appender(_shared_docs['aggregate'])\ndef aggregate(self, func, axis=0, *args, **kwargs):\n    axis = self._get_axis_number(axis)\n    result = None\n    try:\n        result, how = self._aggregate(func, *args, axis=axis, **kwargs)\n    except TypeError:\n        pass\n    if result is None:\n        return self.apply(func, axis=axis, args=args, **kwargs)\n    return result",
                            "def _aggregate(self, arg, axis=0, *args, **kwargs):\n    if axis == 1:\n        result, how = self.T._aggregate(arg, *args, **kwargs)\n        result = result.T if result is not None else result\n        return (result, how)\n    return super()._aggregate(arg, *args, **kwargs)",
                            "@Appender(_shared_docs['transform'] % _shared_doc_kwargs)\ndef transform(self, func, axis=0, *args, **kwargs) -> 'DataFrame':\n    axis = self._get_axis_number(axis)\n    if axis == 1:\n        return self.T.transform(func, *args, **kwargs).T\n    return super().transform(func, *args, **kwargs)",
                            "def apply(self, func, axis=0, raw=False, result_type=None, args=(), **kwds):\n    \"\"\"\n    Apply a function along an axis of the DataFrame.\n\n    Objects passed to the function are Series objects whose index is\n    either the DataFrame's index (``axis=0``) or the DataFrame's columns\n    (``axis=1``). By default (``result_type=None``), the final return type\n    is inferred from the return type of the applied function. Otherwise,\n    it depends on the `result_type` argument.\n\n    Parameters\n    ----------\n    func : function\n        Function to apply to each column or row.\n    axis : {0 or 'index', 1 or 'columns'}, default 0\n        Axis along which the function is applied:\n\n        * 0 or 'index': apply function to each column.\n        * 1 or 'columns': apply function to each row.\n\n    raw : bool, default False\n        Determines if row or column is passed as a Series or ndarray object:\n\n        * ``False`` : passes each row or column as a Series to the\n          function.\n        * ``True`` : the passed function will receive ndarray objects\n          instead.\n          If you are just applying a NumPy reduction function this will\n          achieve much better performance.\n\n    result_type : {'expand', 'reduce', 'broadcast', None}, default None\n        These only act when ``axis=1`` (columns):\n\n        * 'expand' : list-like results will be turned into columns.\n        * 'reduce' : returns a Series if possible rather than expanding\n          list-like results. This is the opposite of 'expand'.\n        * 'broadcast' : results will be broadcast to the original shape\n          of the DataFrame, the original index and columns will be\n          retained.\n\n        The default behaviour (None) depends on the return value of the\n        applied function: list-like results will be returned as a Series\n        of those. However if the apply function returns a Series these\n        are expanded to columns.\n\n        .. versionadded:: 0.23.0\n\n    args : tuple\n        Positional arguments to pass to `func` in addition to the\n        array/series.\n    **kwds\n        Additional keyword arguments to pass as keywords arguments to\n        `func`.\n\n    Returns\n    -------\n    Series or DataFrame\n        Result of applying ``func`` along the given axis of the\n        DataFrame.\n\n    See Also\n    --------\n    DataFrame.applymap: For elementwise operations.\n    DataFrame.aggregate: Only perform aggregating type operations.\n    DataFrame.transform: Only perform transforming type operations.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame([[4, 9]] * 3, columns=['A', 'B'])\n    >>> df\n       A  B\n    0  4  9\n    1  4  9\n    2  4  9\n\n    Using a numpy universal function (in this case the same as\n    ``np.sqrt(df)``):\n\n    >>> df.apply(np.sqrt)\n         A    B\n    0  2.0  3.0\n    1  2.0  3.0\n    2  2.0  3.0\n\n    Using a reducing function on either axis\n\n    >>> df.apply(np.sum, axis=0)\n    A    12\n    B    27\n    dtype: int64\n\n    >>> df.apply(np.sum, axis=1)\n    0    13\n    1    13\n    2    13\n    dtype: int64\n\n    Returning a list-like will result in a Series\n\n    >>> df.apply(lambda x: [1, 2], axis=1)\n    0    [1, 2]\n    1    [1, 2]\n    2    [1, 2]\n    dtype: object\n\n    Passing result_type='expand' will expand list-like results\n    to columns of a Dataframe\n\n    >>> df.apply(lambda x: [1, 2], axis=1, result_type='expand')\n       0  1\n    0  1  2\n    1  1  2\n    2  1  2\n\n    Returning a Series inside the function is similar to passing\n    ``result_type='expand'``. The resulting column names\n    will be the Series index.\n\n    >>> df.apply(lambda x: pd.Series([1, 2], index=['foo', 'bar']), axis=1)\n       foo  bar\n    0    1    2\n    1    1    2\n    2    1    2\n\n    Passing ``result_type='broadcast'`` will ensure the same shape\n    result, whether list-like or scalar is returned by the function,\n    and broadcast it along the axis. The resulting column names will\n    be the originals.\n\n    >>> df.apply(lambda x: [1, 2], axis=1, result_type='broadcast')\n       A  B\n    0  1  2\n    1  1  2\n    2  1  2\n    \"\"\"\n    from pandas.core.apply import frame_apply\n    op = frame_apply(self, func=func, axis=axis, raw=raw, result_type=result_type, args=args, kwds=kwds)\n    return op.get_result()",
                            "def applymap(self, func) -> 'DataFrame':\n    \"\"\"\n    Apply a function to a Dataframe elementwise.\n\n    This method applies a function that accepts and returns a scalar\n    to every element of a DataFrame.\n\n    Parameters\n    ----------\n    func : callable\n        Python function, returns a single value from a single value.\n\n    Returns\n    -------\n    DataFrame\n        Transformed DataFrame.\n\n    See Also\n    --------\n    DataFrame.apply : Apply a function along input axis of DataFrame.\n\n    Notes\n    -----\n    In the current implementation applymap calls `func` twice on the\n    first column/row to decide whether it can take a fast or slow\n    code path. This can lead to unexpected behavior if `func` has\n    side-effects, as they will take effect twice for the first\n    column/row.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame([[1, 2.12], [3.356, 4.567]])\n    >>> df\n           0      1\n    0  1.000  2.120\n    1  3.356  4.567\n\n    >>> df.applymap(lambda x: len(str(x)))\n       0  1\n    0  3  4\n    1  5  5\n\n    Note that a vectorized version of `func` often exists, which will\n    be much faster. You could square each number elementwise.\n\n    >>> df.applymap(lambda x: x**2)\n               0          1\n    0   1.000000   4.494400\n    1  11.262736  20.857489\n\n    But it's better to avoid applymap in that case.\n\n    >>> df ** 2\n               0          1\n    0   1.000000   4.494400\n    1  11.262736  20.857489\n    \"\"\"\n\n    def infer(x):\n        if x.empty:\n            return lib.map_infer(x, func)\n        return lib.map_infer(x.astype(object).values, func)\n    return self.apply(infer)",
                            "def append(self, other, ignore_index=False, verify_integrity=False, sort=False) -> 'DataFrame':\n    \"\"\"\n    Append rows of `other` to the end of caller, returning a new object.\n\n    Columns in `other` that are not in the caller are added as new columns.\n\n    Parameters\n    ----------\n    other : DataFrame or Series/dict-like object, or list of these\n        The data to append.\n    ignore_index : bool, default False\n        If True, do not use the index labels.\n    verify_integrity : bool, default False\n        If True, raise ValueError on creating index with duplicates.\n    sort : bool, default False\n        Sort columns if the columns of `self` and `other` are not aligned.\n\n        .. versionadded:: 0.23.0\n        .. versionchanged:: 1.0.0\n\n            Changed to not sort by default.\n\n    Returns\n    -------\n    DataFrame\n\n    See Also\n    --------\n    concat : General function to concatenate DataFrame or Series objects.\n\n    Notes\n    -----\n    If a list of dict/series is passed and the keys are all contained in\n    the DataFrame's index, the order of the columns in the resulting\n    DataFrame will be unchanged.\n\n    Iteratively appending rows to a DataFrame can be more computationally\n    intensive than a single concatenate. A better solution is to append\n    those rows to a list and then concatenate the list with the original\n    DataFrame all at once.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame([[1, 2], [3, 4]], columns=list('AB'))\n    >>> df\n       A  B\n    0  1  2\n    1  3  4\n    >>> df2 = pd.DataFrame([[5, 6], [7, 8]], columns=list('AB'))\n    >>> df.append(df2)\n       A  B\n    0  1  2\n    1  3  4\n    0  5  6\n    1  7  8\n\n    With `ignore_index` set to True:\n\n    >>> df.append(df2, ignore_index=True)\n       A  B\n    0  1  2\n    1  3  4\n    2  5  6\n    3  7  8\n\n    The following, while not recommended methods for generating DataFrames,\n    show two ways to generate a DataFrame from multiple data sources.\n\n    Less efficient:\n\n    >>> df = pd.DataFrame(columns=['A'])\n    >>> for i in range(5):\n    ...     df = df.append({'A': i}, ignore_index=True)\n    >>> df\n       A\n    0  0\n    1  1\n    2  2\n    3  3\n    4  4\n\n    More efficient:\n\n    >>> pd.concat([pd.DataFrame([i], columns=['A']) for i in range(5)],\n    ...           ignore_index=True)\n       A\n    0  0\n    1  1\n    2  2\n    3  3\n    4  4\n    \"\"\"\n    if isinstance(other, (Series, dict)):\n        if isinstance(other, dict):\n            if not ignore_index:\n                raise TypeError('Can only append a dict if ignore_index=True')\n            other = Series(other)\n        if other.name is None and (not ignore_index):\n            raise TypeError('Can only append a Series if ignore_index=True or if the Series has a name')\n        index = Index([other.name], name=self.index.name)\n        idx_diff = other.index.difference(self.columns)\n        try:\n            combined_columns = self.columns.append(idx_diff)\n        except TypeError:\n            combined_columns = self.columns.astype(object).append(idx_diff)\n        other = other.reindex(combined_columns, copy=False).to_frame().T.infer_objects().rename_axis(index.names, copy=False)\n        if not self.columns.equals(combined_columns):\n            self = self.reindex(columns=combined_columns)\n    elif isinstance(other, list):\n        if not other:\n            pass\n        elif not isinstance(other[0], DataFrame):\n            other = DataFrame(other)\n            if (self.columns.get_indexer(other.columns) >= 0).all():\n                other = other.reindex(columns=self.columns)\n    from pandas.core.reshape.concat import concat\n    if isinstance(other, (list, tuple)):\n        to_concat = [self, *other]\n    else:\n        to_concat = [self, other]\n    return concat(to_concat, ignore_index=ignore_index, verify_integrity=verify_integrity, sort=sort)",
                            "def join(self, other, on=None, how='left', lsuffix='', rsuffix='', sort=False) -> 'DataFrame':\n    \"\"\"\n    Join columns of another DataFrame.\n\n    Join columns with `other` DataFrame either on index or on a key\n    column. Efficiently join multiple DataFrame objects by index at once by\n    passing a list.\n\n    Parameters\n    ----------\n    other : DataFrame, Series, or list of DataFrame\n        Index should be similar to one of the columns in this one. If a\n        Series is passed, its name attribute must be set, and that will be\n        used as the column name in the resulting joined DataFrame.\n    on : str, list of str, or array-like, optional\n        Column or index level name(s) in the caller to join on the index\n        in `other`, otherwise joins index-on-index. If multiple\n        values given, the `other` DataFrame must have a MultiIndex. Can\n        pass an array as the join key if it is not already contained in\n        the calling DataFrame. Like an Excel VLOOKUP operation.\n    how : {'left', 'right', 'outer', 'inner'}, default 'left'\n        How to handle the operation of the two objects.\n\n        * left: use calling frame's index (or column if on is specified)\n        * right: use `other`'s index.\n        * outer: form union of calling frame's index (or column if on is\n          specified) with `other`'s index, and sort it.\n          lexicographically.\n        * inner: form intersection of calling frame's index (or column if\n          on is specified) with `other`'s index, preserving the order\n          of the calling's one.\n    lsuffix : str, default ''\n        Suffix to use from left frame's overlapping columns.\n    rsuffix : str, default ''\n        Suffix to use from right frame's overlapping columns.\n    sort : bool, default False\n        Order result DataFrame lexicographically by the join key. If False,\n        the order of the join key depends on the join type (how keyword).\n\n    Returns\n    -------\n    DataFrame\n        A dataframe containing columns from both the caller and `other`.\n\n    See Also\n    --------\n    DataFrame.merge : For column(s)-on-columns(s) operations.\n\n    Notes\n    -----\n    Parameters `on`, `lsuffix`, and `rsuffix` are not supported when\n    passing a list of `DataFrame` objects.\n\n    Support for specifying index levels as the `on` parameter was added\n    in version 0.23.0.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3', 'K4', 'K5'],\n    ...                    'A': ['A0', 'A1', 'A2', 'A3', 'A4', 'A5']})\n\n    >>> df\n      key   A\n    0  K0  A0\n    1  K1  A1\n    2  K2  A2\n    3  K3  A3\n    4  K4  A4\n    5  K5  A5\n\n    >>> other = pd.DataFrame({'key': ['K0', 'K1', 'K2'],\n    ...                       'B': ['B0', 'B1', 'B2']})\n\n    >>> other\n      key   B\n    0  K0  B0\n    1  K1  B1\n    2  K2  B2\n\n    Join DataFrames using their indexes.\n\n    >>> df.join(other, lsuffix='_caller', rsuffix='_other')\n      key_caller   A key_other    B\n    0         K0  A0        K0   B0\n    1         K1  A1        K1   B1\n    2         K2  A2        K2   B2\n    3         K3  A3       NaN  NaN\n    4         K4  A4       NaN  NaN\n    5         K5  A5       NaN  NaN\n\n    If we want to join using the key columns, we need to set key to be\n    the index in both `df` and `other`. The joined DataFrame will have\n    key as its index.\n\n    >>> df.set_index('key').join(other.set_index('key'))\n          A    B\n    key\n    K0   A0   B0\n    K1   A1   B1\n    K2   A2   B2\n    K3   A3  NaN\n    K4   A4  NaN\n    K5   A5  NaN\n\n    Another option to join using the key columns is to use the `on`\n    parameter. DataFrame.join always uses `other`'s index but we can use\n    any column in `df`. This method preserves the original DataFrame's\n    index in the result.\n\n    >>> df.join(other.set_index('key'), on='key')\n      key   A    B\n    0  K0  A0   B0\n    1  K1  A1   B1\n    2  K2  A2   B2\n    3  K3  A3  NaN\n    4  K4  A4  NaN\n    5  K5  A5  NaN\n    \"\"\"\n    return self._join_compat(other, on=on, how=how, lsuffix=lsuffix, rsuffix=rsuffix, sort=sort)",
                            "def _join_compat(self, other, on=None, how='left', lsuffix='', rsuffix='', sort=False):\n    from pandas.core.reshape.merge import merge\n    from pandas.core.reshape.concat import concat\n    if isinstance(other, Series):\n        if other.name is None:\n            raise ValueError('Other Series must have a name')\n        other = DataFrame({other.name: other})\n    if isinstance(other, DataFrame):\n        return merge(self, other, left_on=on, how=how, left_index=on is None, right_index=True, suffixes=(lsuffix, rsuffix), sort=sort)\n    else:\n        if on is not None:\n            raise ValueError('Joining multiple DataFrames only supported for joining on index')\n        frames = [self] + list(other)\n        can_concat = all((df.index.is_unique for df in frames))\n        if can_concat:\n            if how == 'left':\n                res = concat(frames, axis=1, join='outer', verify_integrity=True, sort=sort)\n                return res.reindex(self.index, copy=False)\n            else:\n                return concat(frames, axis=1, join=how, verify_integrity=True, sort=sort)\n        joined = frames[0]\n        for frame in frames[1:]:\n            joined = merge(joined, frame, how=how, left_index=True, right_index=True)\n        return joined",
                            "@Substitution('')\n@Appender(_merge_doc, indents=2)\ndef merge(self, right, how='inner', on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=False, suffixes=('_x', '_y'), copy=True, indicator=False, validate=None) -> 'DataFrame':\n    from pandas.core.reshape.merge import merge\n    return merge(self, right, how=how, on=on, left_on=left_on, right_on=right_on, left_index=left_index, right_index=right_index, sort=sort, suffixes=suffixes, copy=copy, indicator=indicator, validate=validate)",
                            "def round(self, decimals=0, *args, **kwargs) -> 'DataFrame':\n    \"\"\"\n    Round a DataFrame to a variable number of decimal places.\n\n    Parameters\n    ----------\n    decimals : int, dict, Series\n        Number of decimal places to round each column to. If an int is\n        given, round each column to the same number of places.\n        Otherwise dict and Series round to variable numbers of places.\n        Column names should be in the keys if `decimals` is a\n        dict-like, or in the index if `decimals` is a Series. Any\n        columns not included in `decimals` will be left as is. Elements\n        of `decimals` which are not columns of the input will be\n        ignored.\n    *args\n        Additional keywords have no effect but might be accepted for\n        compatibility with numpy.\n    **kwargs\n        Additional keywords have no effect but might be accepted for\n        compatibility with numpy.\n\n    Returns\n    -------\n    DataFrame\n        A DataFrame with the affected columns rounded to the specified\n        number of decimal places.\n\n    See Also\n    --------\n    numpy.around : Round a numpy array to the given number of decimals.\n    Series.round : Round a Series to the given number of decimals.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame([(.21, .32), (.01, .67), (.66, .03), (.21, .18)],\n    ...                   columns=['dogs', 'cats'])\n    >>> df\n        dogs  cats\n    0  0.21  0.32\n    1  0.01  0.67\n    2  0.66  0.03\n    3  0.21  0.18\n\n    By providing an integer each column is rounded to the same number\n    of decimal places\n\n    >>> df.round(1)\n        dogs  cats\n    0   0.2   0.3\n    1   0.0   0.7\n    2   0.7   0.0\n    3   0.2   0.2\n\n    With a dict, the number of places for specific columns can be\n    specified with the column names as key and the number of decimal\n    places as value\n\n    >>> df.round({'dogs': 1, 'cats': 0})\n        dogs  cats\n    0   0.2   0.0\n    1   0.0   1.0\n    2   0.7   0.0\n    3   0.2   0.0\n\n    Using a Series, the number of places for specific columns can be\n    specified with the column names as index and the number of\n    decimal places as value\n\n    >>> decimals = pd.Series([0, 1], index=['cats', 'dogs'])\n    >>> df.round(decimals)\n        dogs  cats\n    0   0.2   0.0\n    1   0.0   1.0\n    2   0.7   0.0\n    3   0.2   0.0\n    \"\"\"\n    from pandas.core.reshape.concat import concat\n\n    def _dict_round(df, decimals):\n        for col, vals in df.items():\n            try:\n                yield _series_round(vals, decimals[col])\n            except KeyError:\n                yield vals\n\n    def _series_round(s, decimals):\n        if is_integer_dtype(s) or is_float_dtype(s):\n            return s.round(decimals)\n        return s\n    nv.validate_round(args, kwargs)\n    if isinstance(decimals, (dict, Series)):\n        if isinstance(decimals, Series):\n            if not decimals.index.is_unique:\n                raise ValueError('Index of decimals must be unique')\n        new_cols = list(_dict_round(self, decimals))\n    elif is_integer(decimals):\n        new_cols = [_series_round(v, decimals) for _, v in self.items()]\n    else:\n        raise TypeError('decimals must be an integer, a dict-like or a Series')\n    if len(new_cols) > 0:\n        return self._constructor(concat(new_cols, axis=1), index=self.index, columns=self.columns)\n    else:\n        return self",
                            "def corr(self, method='pearson', min_periods=1) -> 'DataFrame':\n    \"\"\"\n    Compute pairwise correlation of columns, excluding NA/null values.\n\n    Parameters\n    ----------\n    method : {'pearson', 'kendall', 'spearman'} or callable\n        Method of correlation:\n\n        * pearson : standard correlation coefficient\n        * kendall : Kendall Tau correlation coefficient\n        * spearman : Spearman rank correlation\n        * callable: callable with input two 1d ndarrays\n            and returning a float. Note that the returned matrix from corr\n            will have 1 along the diagonals and will be symmetric\n            regardless of the callable's behavior.\n\n            .. versionadded:: 0.24.0\n\n    min_periods : int, optional\n        Minimum number of observations required per pair of columns\n        to have a valid result. Currently only available for Pearson\n        and Spearman correlation.\n\n    Returns\n    -------\n    DataFrame\n        Correlation matrix.\n\n    See Also\n    --------\n    DataFrame.corrwith : Compute pairwise correlation with another\n        DataFrame or Series.\n    Series.corr : Compute the correlation between two Series.\n\n    Examples\n    --------\n    >>> def histogram_intersection(a, b):\n    ...     v = np.minimum(a, b).sum().round(decimals=1)\n    ...     return v\n    >>> df = pd.DataFrame([(.2, .3), (.0, .6), (.6, .0), (.2, .1)],\n    ...                   columns=['dogs', 'cats'])\n    >>> df.corr(method=histogram_intersection)\n          dogs  cats\n    dogs   1.0   0.3\n    cats   0.3   1.0\n    \"\"\"\n    numeric_df = self._get_numeric_data()\n    cols = numeric_df.columns\n    idx = cols.copy()\n    mat = numeric_df.values\n    if method == 'pearson':\n        correl = libalgos.nancorr(ensure_float64(mat), minp=min_periods)\n    elif method == 'spearman':\n        correl = libalgos.nancorr_spearman(ensure_float64(mat), minp=min_periods)\n    elif method == 'kendall' or callable(method):\n        if min_periods is None:\n            min_periods = 1\n        mat = ensure_float64(mat).T\n        corrf = nanops.get_corr_func(method)\n        K = len(cols)\n        correl = np.empty((K, K), dtype=float)\n        mask = np.isfinite(mat)\n        for i, ac in enumerate(mat):\n            for j, bc in enumerate(mat):\n                if i > j:\n                    continue\n                valid = mask[i] & mask[j]\n                if valid.sum() < min_periods:\n                    c = np.nan\n                elif i == j:\n                    c = 1.0\n                elif not valid.all():\n                    c = corrf(ac[valid], bc[valid])\n                else:\n                    c = corrf(ac, bc)\n                correl[i, j] = c\n                correl[j, i] = c\n    else:\n        raise ValueError(f\"method must be either 'pearson', 'spearman', 'kendall', or a callable, '{method}' was supplied\")\n    return self._constructor(correl, index=idx, columns=cols)",
                            "def cov(self, min_periods=None) -> 'DataFrame':\n    \"\"\"\n    Compute pairwise covariance of columns, excluding NA/null values.\n\n    Compute the pairwise covariance among the series of a DataFrame.\n    The returned data frame is the `covariance matrix\n    <https://en.wikipedia.org/wiki/Covariance_matrix>`__ of the columns\n    of the DataFrame.\n\n    Both NA and null values are automatically excluded from the\n    calculation. (See the note below about bias from missing values.)\n    A threshold can be set for the minimum number of\n    observations for each value created. Comparisons with observations\n    below this threshold will be returned as ``NaN``.\n\n    This method is generally used for the analysis of time series data to\n    understand the relationship between different measures\n    across time.\n\n    Parameters\n    ----------\n    min_periods : int, optional\n        Minimum number of observations required per pair of columns\n        to have a valid result.\n\n    Returns\n    -------\n    DataFrame\n        The covariance matrix of the series of the DataFrame.\n\n    See Also\n    --------\n    Series.cov : Compute covariance with another Series.\n    core.window.EWM.cov: Exponential weighted sample covariance.\n    core.window.Expanding.cov : Expanding sample covariance.\n    core.window.Rolling.cov : Rolling sample covariance.\n\n    Notes\n    -----\n    Returns the covariance matrix of the DataFrame's time series.\n    The covariance is normalized by N-1.\n\n    For DataFrames that have Series that are missing data (assuming that\n    data is `missing at random\n    <https://en.wikipedia.org/wiki/Missing_data#Missing_at_random>`__)\n    the returned covariance matrix will be an unbiased estimate\n    of the variance and covariance between the member Series.\n\n    However, for many applications this estimate may not be acceptable\n    because the estimate covariance matrix is not guaranteed to be positive\n    semi-definite. This could lead to estimate correlations having\n    absolute values which are greater than one, and/or a non-invertible\n    covariance matrix. See `Estimation of covariance matrices\n    <https://en.wikipedia.org/w/index.php?title=Estimation_of_covariance_\n    matrices>`__ for more details.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame([(1, 2), (0, 3), (2, 0), (1, 1)],\n    ...                   columns=['dogs', 'cats'])\n    >>> df.cov()\n              dogs      cats\n    dogs  0.666667 -1.000000\n    cats -1.000000  1.666667\n\n    >>> np.random.seed(42)\n    >>> df = pd.DataFrame(np.random.randn(1000, 5),\n    ...                   columns=['a', 'b', 'c', 'd', 'e'])\n    >>> df.cov()\n              a         b         c         d         e\n    a  0.998438 -0.020161  0.059277 -0.008943  0.014144\n    b -0.020161  1.059352 -0.008543 -0.024738  0.009826\n    c  0.059277 -0.008543  1.010670 -0.001486 -0.000271\n    d -0.008943 -0.024738 -0.001486  0.921297 -0.013692\n    e  0.014144  0.009826 -0.000271 -0.013692  0.977795\n\n    **Minimum number of periods**\n\n    This method also supports an optional ``min_periods`` keyword\n    that specifies the required minimum number of non-NA observations for\n    each column pair in order to have a valid result:\n\n    >>> np.random.seed(42)\n    >>> df = pd.DataFrame(np.random.randn(20, 3),\n    ...                   columns=['a', 'b', 'c'])\n    >>> df.loc[df.index[:5], 'a'] = np.nan\n    >>> df.loc[df.index[5:10], 'b'] = np.nan\n    >>> df.cov(min_periods=12)\n              a         b         c\n    a  0.316741       NaN -0.150812\n    b       NaN  1.248003  0.191417\n    c -0.150812  0.191417  0.895202\n    \"\"\"\n    numeric_df = self._get_numeric_data()\n    cols = numeric_df.columns\n    idx = cols.copy()\n    mat = numeric_df.values\n    if notna(mat).all():\n        if min_periods is not None and min_periods > len(mat):\n            baseCov = np.empty((mat.shape[1], mat.shape[1]))\n            baseCov.fill(np.nan)\n        else:\n            baseCov = np.cov(mat.T)\n        baseCov = baseCov.reshape((len(cols), len(cols)))\n    else:\n        baseCov = libalgos.nancorr(ensure_float64(mat), cov=True, minp=min_periods)\n    return self._constructor(baseCov, index=idx, columns=cols)",
                            "def corrwith(self, other, axis=0, drop=False, method='pearson') -> Series:\n    \"\"\"\n    Compute pairwise correlation.\n\n    Pairwise correlation is computed between rows or columns of\n    DataFrame with rows or columns of Series or DataFrame. DataFrames\n    are first aligned along both axes before computing the\n    correlations.\n\n    Parameters\n    ----------\n    other : DataFrame, Series\n        Object with which to compute correlations.\n    axis : {0 or 'index', 1 or 'columns'}, default 0\n        The axis to use. 0 or 'index' to compute column-wise, 1 or 'columns' for\n        row-wise.\n    drop : bool, default False\n        Drop missing indices from result.\n    method : {'pearson', 'kendall', 'spearman'} or callable\n        Method of correlation:\n\n        * pearson : standard correlation coefficient\n        * kendall : Kendall Tau correlation coefficient\n        * spearman : Spearman rank correlation\n        * callable: callable with input two 1d ndarrays\n            and returning a float.\n\n        .. versionadded:: 0.24.0\n\n    Returns\n    -------\n    Series\n        Pairwise correlations.\n\n    See Also\n    --------\n    DataFrame.corr : Compute pairwise correlation of columns.\n    \"\"\"\n    axis = self._get_axis_number(axis)\n    this = self._get_numeric_data()\n    if isinstance(other, Series):\n        return this.apply(lambda x: other.corr(x, method=method), axis=axis)\n    other = other._get_numeric_data()\n    left, right = this.align(other, join='inner', copy=False)\n    if axis == 1:\n        left = left.T\n        right = right.T\n    if method == 'pearson':\n        left = left + right * 0\n        right = right + left * 0\n        ldem = left - left.mean()\n        rdem = right - right.mean()\n        num = (ldem * rdem).sum()\n        dom = (left.count() - 1) * left.std() * right.std()\n        correl = num / dom\n    elif method in ['kendall', 'spearman'] or callable(method):\n\n        def c(x):\n            return nanops.nancorr(x[0], x[1], method=method)\n        correl = Series(map(c, zip(left.values.T, right.values.T)), index=left.columns)\n    else:\n        raise ValueError(f\"Invalid method {method} was passed, valid methods are: 'pearson', 'kendall', 'spearman', or callable\")\n    if not drop:\n        raxis = 1 if axis == 0 else 0\n        result_index = this._get_axis(raxis).union(other._get_axis(raxis))\n        idx_diff = result_index.difference(correl.index)\n        if len(idx_diff) > 0:\n            correl = correl.append(Series([np.nan] * len(idx_diff), index=idx_diff))\n    return correl",
                            "def count(self, axis=0, level=None, numeric_only=False):\n    \"\"\"\n    Count non-NA cells for each column or row.\n\n    The values `None`, `NaN`, `NaT`, and optionally `numpy.inf` (depending\n    on `pandas.options.mode.use_inf_as_na`) are considered NA.\n\n    Parameters\n    ----------\n    axis : {0 or 'index', 1 or 'columns'}, default 0\n        If 0 or 'index' counts are generated for each column.\n        If 1 or 'columns' counts are generated for each **row**.\n    level : int or str, optional\n        If the axis is a `MultiIndex` (hierarchical), count along a\n        particular `level`, collapsing into a `DataFrame`.\n        A `str` specifies the level name.\n    numeric_only : bool, default False\n        Include only `float`, `int` or `boolean` data.\n\n    Returns\n    -------\n    Series or DataFrame\n        For each column/row the number of non-NA/null entries.\n        If `level` is specified returns a `DataFrame`.\n\n    See Also\n    --------\n    Series.count: Number of non-NA elements in a Series.\n    DataFrame.shape: Number of DataFrame rows and columns (including NA\n        elements).\n    DataFrame.isna: Boolean same-sized DataFrame showing places of NA\n        elements.\n\n    Examples\n    --------\n    Constructing DataFrame from a dictionary:\n\n    >>> df = pd.DataFrame({\"Person\":\n    ...                    [\"John\", \"Myla\", \"Lewis\", \"John\", \"Myla\"],\n    ...                    \"Age\": [24., np.nan, 21., 33, 26],\n    ...                    \"Single\": [False, True, True, True, False]})\n    >>> df\n       Person   Age  Single\n    0    John  24.0   False\n    1    Myla   NaN    True\n    2   Lewis  21.0    True\n    3    John  33.0    True\n    4    Myla  26.0   False\n\n    Notice the uncounted NA values:\n\n    >>> df.count()\n    Person    5\n    Age       4\n    Single    5\n    dtype: int64\n\n    Counts for each **row**:\n\n    >>> df.count(axis='columns')\n    0    3\n    1    2\n    2    3\n    3    3\n    4    3\n    dtype: int64\n\n    Counts for one level of a `MultiIndex`:\n\n    >>> df.set_index([\"Person\", \"Single\"]).count(level=\"Person\")\n            Age\n    Person\n    John      2\n    Lewis     1\n    Myla      1\n    \"\"\"\n    axis = self._get_axis_number(axis)\n    if level is not None:\n        return self._count_level(level, axis=axis, numeric_only=numeric_only)\n    if numeric_only:\n        frame = self._get_numeric_data()\n    else:\n        frame = self\n    if len(frame._get_axis(axis)) == 0:\n        result = Series(0, index=frame._get_agg_axis(axis))\n    elif frame._is_mixed_type or frame._data.any_extension_types:\n        result = notna(frame).sum(axis=axis)\n    else:\n        series_counts = notna(frame).sum(axis=axis)\n        counts = series_counts.values\n        result = Series(counts, index=frame._get_agg_axis(axis))\n    return result.astype('int64')",
                            "def _count_level(self, level, axis=0, numeric_only=False):\n    if numeric_only:\n        frame = self._get_numeric_data()\n    else:\n        frame = self\n    count_axis = frame._get_axis(axis)\n    agg_axis = frame._get_agg_axis(axis)\n    if not isinstance(count_axis, ABCMultiIndex):\n        raise TypeError(f'Can only count levels on hierarchical {self._get_axis_name(axis)}.')\n    if frame._is_mixed_type:\n        mask = notna(frame).values\n    else:\n        mask = notna(frame.values)\n    if axis == 1:\n        mask = mask.T\n    if isinstance(level, str):\n        level = count_axis._get_level_number(level)\n    level_name = count_axis._names[level]\n    level_index = count_axis.levels[level]._shallow_copy(name=level_name)\n    level_codes = ensure_int64(count_axis.codes[level])\n    counts = lib.count_level_2d(mask, level_codes, len(level_index), axis=0)\n    result = DataFrame(counts, index=level_index, columns=agg_axis)\n    if axis == 1:\n        return result.T\n    else:\n        return result",
                            "def _reduce(self, op, name, axis=0, skipna=True, numeric_only=None, filter_type=None, **kwds):\n    assert filter_type is None or filter_type == 'bool', filter_type\n    dtype_is_dt = self.dtypes.apply(lambda x: is_datetime64_any_dtype(x) or is_period_dtype(x))\n    if numeric_only is None and name in ['mean', 'median'] and dtype_is_dt.any():\n        warnings.warn('DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64, datetime64tz, and PeriodDtype columns in a future version.', FutureWarning, stacklevel=3)\n        cols = self.columns[~dtype_is_dt]\n        self = self[cols]\n    if axis is None and filter_type == 'bool':\n        labels = None\n        constructor = None\n    else:\n        axis = self._get_axis_number(axis)\n        labels = self._get_agg_axis(axis)\n        constructor = self._constructor\n\n    def f(x):\n        return op(x, axis=axis, skipna=skipna, **kwds)\n\n    def _get_data(axis_matters):\n        if filter_type is None:\n            data = self._get_numeric_data()\n        elif filter_type == 'bool':\n            if axis_matters:\n                data = self._get_bool_data() if axis == 0 else self\n            else:\n                data = self._get_bool_data()\n        else:\n            msg = f'Generating numeric_only data with filter_type {filter_type} not supported.'\n            raise NotImplementedError(msg)\n        return data\n    if numeric_only is not None and axis in [0, 1]:\n        df = self\n        if numeric_only is True:\n            df = _get_data(axis_matters=True)\n        if axis == 1:\n            df = df.T\n            axis = 0\n        out_dtype = 'bool' if filter_type == 'bool' else None\n\n        def blk_func(values):\n            if values.ndim == 1 and (not isinstance(values, np.ndarray)):\n                return op(values, axis=0, skipna=skipna, **kwds)\n            return op(values, axis=1, skipna=skipna, **kwds)\n        res = df._data.reduce(blk_func)\n        assert isinstance(res, dict)\n        if len(res):\n            assert len(res) == max(list(res.keys())) + 1, res.keys()\n        out = df._constructor_sliced(res, index=range(len(res)), dtype=out_dtype)\n        out.index = df.columns\n        if axis == 0 and df.dtypes.apply(needs_i8_conversion).any():\n            out[:] = coerce_to_dtypes(out.values, df.dtypes)\n        return out\n    if numeric_only is None:\n        data = self\n        values = data.values\n        try:\n            result = f(values)\n        except TypeError:\n            if filter_type is None and axis == 0:\n                from pandas.core.apply import frame_apply\n                opa = frame_apply(self, func=f, result_type='expand', ignore_failures=True)\n                result = opa.get_result()\n                if result.ndim == self.ndim:\n                    result = result.iloc[0]\n                return result\n            data = _get_data(axis_matters=False)\n            labels = data._get_agg_axis(axis)\n            values = data.values\n            with np.errstate(all='ignore'):\n                result = f(values)\n    else:\n        if numeric_only:\n            data = _get_data(axis_matters=True)\n            labels = data._get_agg_axis(axis)\n            values = data.values\n        else:\n            data = self\n            values = data.values\n        result = f(values)\n    if filter_type == 'bool' and is_object_dtype(values) and (axis is None):\n        result = np.bool_(result)\n    elif hasattr(result, 'dtype') and is_object_dtype(result.dtype):\n        try:\n            if filter_type is None:\n                result = result.astype(np.float64)\n            elif filter_type == 'bool' and notna(result).all():\n                result = result.astype(np.bool_)\n        except (ValueError, TypeError):\n            if axis == 0:\n                result = coerce_to_dtypes(result, data.dtypes)\n    if constructor is not None:\n        result = self._constructor_sliced(result, index=labels)\n    return result",
                            "def nunique(self, axis=0, dropna=True) -> Series:\n    \"\"\"\n    Count distinct observations over requested axis.\n\n    Return Series with number of distinct observations. Can ignore NaN\n    values.\n\n    Parameters\n    ----------\n    axis : {0 or 'index', 1 or 'columns'}, default 0\n        The axis to use. 0 or 'index' for row-wise, 1 or 'columns' for\n        column-wise.\n    dropna : bool, default True\n        Don't include NaN in the counts.\n\n    Returns\n    -------\n    Series\n\n    See Also\n    --------\n    Series.nunique: Method nunique for Series.\n    DataFrame.count: Count non-NA cells for each column or row.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame({'A': [1, 2, 3], 'B': [1, 1, 1]})\n    >>> df.nunique()\n    A    3\n    B    1\n    dtype: int64\n\n    >>> df.nunique(axis=1)\n    0    1\n    1    2\n    2    2\n    dtype: int64\n    \"\"\"\n    return self.apply(Series.nunique, axis=axis, dropna=dropna)",
                            "def idxmin(self, axis=0, skipna=True) -> Series:\n    \"\"\"\n    Return index of first occurrence of minimum over requested axis.\n\n    NA/null values are excluded.\n\n    Parameters\n    ----------\n    axis : {0 or 'index', 1 or 'columns'}, default 0\n        The axis to use. 0 or 'index' for row-wise, 1 or 'columns' for column-wise.\n    skipna : bool, default True\n        Exclude NA/null values. If an entire row/column is NA, the result\n        will be NA.\n\n    Returns\n    -------\n    Series\n        Indexes of minima along the specified axis.\n\n    Raises\n    ------\n    ValueError\n        * If the row/column is empty\n\n    See Also\n    --------\n    Series.idxmin : Return index of the minimum element.\n\n    Notes\n    -----\n    This method is the DataFrame version of ``ndarray.argmin``.\n\n    Examples\n    --------\n    Consider a dataset containing food consumption in Argentina.\n\n    >>> df = pd.DataFrame({'consumption': [10.51, 103.11, 55.48],\n    ...                    'co2_emissions': [37.2, 19.66, 1712]},\n    ...                    index=['Pork', 'Wheat Products', 'Beef'])\n\n    >>> df\n                    consumption  co2_emissions\n    Pork                  10.51         37.20\n    Wheat Products       103.11         19.66\n    Beef                  55.48       1712.00\n\n    By default, it returns the index for the minimum value in each column.\n\n    >>> df.idxmin()\n    consumption                Pork\n    co2_emissions    Wheat Products\n    dtype: object\n\n    To return the index for the minimum value in each row, use ``axis=\"columns\"``.\n\n    >>> df.idxmin(axis=\"columns\")\n    Pork                consumption\n    Wheat Products    co2_emissions\n    Beef                consumption\n    dtype: object\n    \"\"\"\n    axis = self._get_axis_number(axis)\n    indices = nanops.nanargmin(self.values, axis=axis, skipna=skipna)\n    index = self._get_axis(axis)\n    result = [index[i] if i >= 0 else np.nan for i in indices]\n    return Series(result, index=self._get_agg_axis(axis))",
                            "def idxmax(self, axis=0, skipna=True) -> Series:\n    \"\"\"\n    Return index of first occurrence of maximum over requested axis.\n\n    NA/null values are excluded.\n\n    Parameters\n    ----------\n    axis : {0 or 'index', 1 or 'columns'}, default 0\n        The axis to use. 0 or 'index' for row-wise, 1 or 'columns' for column-wise.\n    skipna : bool, default True\n        Exclude NA/null values. If an entire row/column is NA, the result\n        will be NA.\n\n    Returns\n    -------\n    Series\n        Indexes of maxima along the specified axis.\n\n    Raises\n    ------\n    ValueError\n        * If the row/column is empty\n\n    See Also\n    --------\n    Series.idxmax : Return index of the maximum element.\n\n    Notes\n    -----\n    This method is the DataFrame version of ``ndarray.argmax``.\n\n    Examples\n    --------\n    Consider a dataset containing food consumption in Argentina.\n\n    >>> df = pd.DataFrame({'consumption': [10.51, 103.11, 55.48],\n    ...                    'co2_emissions': [37.2, 19.66, 1712]},\n    ...                    index=['Pork', 'Wheat Products', 'Beef'])\n\n    >>> df\n                    consumption  co2_emissions\n    Pork                  10.51         37.20\n    Wheat Products       103.11         19.66\n    Beef                  55.48       1712.00\n\n    By default, it returns the index for the maximum value in each column.\n\n    >>> df.idxmax()\n    consumption     Wheat Products\n    co2_emissions             Beef\n    dtype: object\n\n    To return the index for the maximum value in each row, use ``axis=\"columns\"``.\n\n    >>> df.idxmax(axis=\"columns\")\n    Pork              co2_emissions\n    Wheat Products     consumption\n    Beef              co2_emissions\n    dtype: object\n    \"\"\"\n    axis = self._get_axis_number(axis)\n    indices = nanops.nanargmax(self.values, axis=axis, skipna=skipna)\n    index = self._get_axis(axis)\n    result = [index[i] if i >= 0 else np.nan for i in indices]\n    return Series(result, index=self._get_agg_axis(axis))",
                            "def _get_agg_axis(self, axis_num):\n    \"\"\"\n    Let's be explicit about this.\n    \"\"\"\n    if axis_num == 0:\n        return self.columns\n    elif axis_num == 1:\n        return self.index\n    else:\n        raise ValueError(f'Axis must be 0 or 1 (got {repr(axis_num)})')",
                            "def mode(self, axis=0, numeric_only=False, dropna=True) -> 'DataFrame':\n    \"\"\"\n    Get the mode(s) of each element along the selected axis.\n\n    The mode of a set of values is the value that appears most often.\n    It can be multiple values.\n\n    Parameters\n    ----------\n    axis : {0 or 'index', 1 or 'columns'}, default 0\n        The axis to iterate over while searching for the mode:\n\n        * 0 or 'index' : get mode of each column\n        * 1 or 'columns' : get mode of each row.\n\n    numeric_only : bool, default False\n        If True, only apply to numeric columns.\n    dropna : bool, default True\n        Don't consider counts of NaN/NaT.\n\n        .. versionadded:: 0.24.0\n\n    Returns\n    -------\n    DataFrame\n        The modes of each column or row.\n\n    See Also\n    --------\n    Series.mode : Return the highest frequency value in a Series.\n    Series.value_counts : Return the counts of values in a Series.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame([('bird', 2, 2),\n    ...                    ('mammal', 4, np.nan),\n    ...                    ('arthropod', 8, 0),\n    ...                    ('bird', 2, np.nan)],\n    ...                   index=('falcon', 'horse', 'spider', 'ostrich'),\n    ...                   columns=('species', 'legs', 'wings'))\n    >>> df\n               species  legs  wings\n    falcon        bird     2    2.0\n    horse       mammal     4    NaN\n    spider   arthropod     8    0.0\n    ostrich       bird     2    NaN\n\n    By default, missing values are not considered, and the mode of wings\n    are both 0 and 2. The second row of species and legs contains ``NaN``,\n    because they have only one mode, but the DataFrame has two rows.\n\n    >>> df.mode()\n      species  legs  wings\n    0    bird   2.0    0.0\n    1     NaN   NaN    2.0\n\n    Setting ``dropna=False`` ``NaN`` values are considered and they can be\n    the mode (like for wings).\n\n    >>> df.mode(dropna=False)\n      species  legs  wings\n    0    bird     2    NaN\n\n    Setting ``numeric_only=True``, only the mode of numeric columns is\n    computed, and columns of other types are ignored.\n\n    >>> df.mode(numeric_only=True)\n       legs  wings\n    0   2.0    0.0\n    1   NaN    2.0\n\n    To compute the mode over columns and not rows, use the axis parameter:\n\n    >>> df.mode(axis='columns', numeric_only=True)\n               0    1\n    falcon   2.0  NaN\n    horse    4.0  NaN\n    spider   0.0  8.0\n    ostrich  2.0  NaN\n    \"\"\"\n    data = self if not numeric_only else self._get_numeric_data()\n\n    def f(s):\n        return s.mode(dropna=dropna)\n    return data.apply(f, axis=axis)",
                            "def quantile(self, q=0.5, axis=0, numeric_only=True, interpolation='linear'):\n    \"\"\"\n    Return values at the given quantile over requested axis.\n\n    Parameters\n    ----------\n    q : float or array-like, default 0.5 (50% quantile)\n        Value between 0 <= q <= 1, the quantile(s) to compute.\n    axis : {0, 1, 'index', 'columns'} (default 0)\n        Equals 0 or 'index' for row-wise, 1 or 'columns' for column-wise.\n    numeric_only : bool, default True\n        If False, the quantile of datetime and timedelta data will be\n        computed as well.\n    interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}\n        This optional parameter specifies the interpolation method to use,\n        when the desired quantile lies between two data points `i` and `j`:\n\n        * linear: `i + (j - i) * fraction`, where `fraction` is the\n          fractional part of the index surrounded by `i` and `j`.\n        * lower: `i`.\n        * higher: `j`.\n        * nearest: `i` or `j` whichever is nearest.\n        * midpoint: (`i` + `j`) / 2.\n\n    Returns\n    -------\n    Series or DataFrame\n\n        If ``q`` is an array, a DataFrame will be returned where the\n          index is ``q``, the columns are the columns of self, and the\n          values are the quantiles.\n        If ``q`` is a float, a Series will be returned where the\n          index is the columns of self and the values are the quantiles.\n\n    See Also\n    --------\n    core.window.Rolling.quantile: Rolling quantile.\n    numpy.percentile: Numpy function to compute the percentile.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame(np.array([[1, 1], [2, 10], [3, 100], [4, 100]]),\n    ...                   columns=['a', 'b'])\n    >>> df.quantile(.1)\n    a    1.3\n    b    3.7\n    Name: 0.1, dtype: float64\n    >>> df.quantile([.1, .5])\n           a     b\n    0.1  1.3   3.7\n    0.5  2.5  55.0\n\n    Specifying `numeric_only=False` will also compute the quantile of\n    datetime and timedelta data.\n\n    >>> df = pd.DataFrame({'A': [1, 2],\n    ...                    'B': [pd.Timestamp('2010'),\n    ...                          pd.Timestamp('2011')],\n    ...                    'C': [pd.Timedelta('1 days'),\n    ...                          pd.Timedelta('2 days')]})\n    >>> df.quantile(0.5, numeric_only=False)\n    A                    1.5\n    B    2010-07-02 12:00:00\n    C        1 days 12:00:00\n    Name: 0.5, dtype: object\n    \"\"\"\n    validate_percentile(q)\n    data = self._get_numeric_data() if numeric_only else self\n    axis = self._get_axis_number(axis)\n    is_transposed = axis == 1\n    if is_transposed:\n        data = data.T\n    if len(data.columns) == 0:\n        cols = Index([], name=self.columns.name)\n        if is_list_like(q):\n            return self._constructor([], index=q, columns=cols)\n        return self._constructor_sliced([], index=cols, name=q, dtype=np.float64)\n    result = data._data.quantile(qs=q, axis=1, interpolation=interpolation, transposed=is_transposed)\n    if result.ndim == 2:\n        result = self._constructor(result)\n    else:\n        result = self._constructor_sliced(result, name=q)\n    if is_transposed:\n        result = result.T\n    return result",
                            "def to_timestamp(self, freq=None, how: str='start', axis: Axis=0, copy: bool=True) -> 'DataFrame':\n    \"\"\"\n    Cast to DatetimeIndex of timestamps, at *beginning* of period.\n\n    Parameters\n    ----------\n    freq : str, default frequency of PeriodIndex\n        Desired frequency.\n    how : {'s', 'e', 'start', 'end'}\n        Convention for converting period to timestamp; start of period\n        vs. end.\n    axis : {0 or 'index', 1 or 'columns'}, default 0\n        The axis to convert (the index by default).\n    copy : bool, default True\n        If False then underlying input data is not copied.\n\n    Returns\n    -------\n    DataFrame with DatetimeIndex\n    \"\"\"\n    new_obj = self.copy(deep=copy)\n    axis_name = self._get_axis_name(axis)\n    old_ax = getattr(self, axis_name)\n    new_ax = old_ax.to_timestamp(freq=freq, how=how)\n    setattr(new_obj, axis_name, new_ax)\n    return new_obj",
                            "def to_period(self, freq=None, axis: Axis=0, copy: bool=True) -> 'DataFrame':\n    \"\"\"\n    Convert DataFrame from DatetimeIndex to PeriodIndex.\n\n    Convert DataFrame from DatetimeIndex to PeriodIndex with desired\n    frequency (inferred from index if not passed).\n\n    Parameters\n    ----------\n    freq : str, default\n        Frequency of the PeriodIndex.\n    axis : {0 or 'index', 1 or 'columns'}, default 0\n        The axis to convert (the index by default).\n    copy : bool, default True\n        If False then underlying input data is not copied.\n\n    Returns\n    -------\n    DataFrame with PeriodIndex\n    \"\"\"\n    new_obj = self.copy(deep=copy)\n    axis_name = self._get_axis_name(axis)\n    old_ax = getattr(self, axis_name)\n    new_ax = old_ax.to_period(freq=freq)\n    setattr(new_obj, axis_name, new_ax)\n    return new_obj",
                            "def isin(self, values) -> 'DataFrame':\n    \"\"\"\n    Whether each element in the DataFrame is contained in values.\n\n    Parameters\n    ----------\n    values : iterable, Series, DataFrame or dict\n        The result will only be true at a location if all the\n        labels match. If `values` is a Series, that's the index. If\n        `values` is a dict, the keys must be the column names,\n        which must match. If `values` is a DataFrame,\n        then both the index and column labels must match.\n\n    Returns\n    -------\n    DataFrame\n        DataFrame of booleans showing whether each element in the DataFrame\n        is contained in values.\n\n    See Also\n    --------\n    DataFrame.eq: Equality test for DataFrame.\n    Series.isin: Equivalent method on Series.\n    Series.str.contains: Test if pattern or regex is contained within a\n        string of a Series or Index.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame({'num_legs': [2, 4], 'num_wings': [2, 0]},\n    ...                   index=['falcon', 'dog'])\n    >>> df\n            num_legs  num_wings\n    falcon         2          2\n    dog            4          0\n\n    When ``values`` is a list check whether every value in the DataFrame\n    is present in the list (which animals have 0 or 2 legs or wings)\n\n    >>> df.isin([0, 2])\n            num_legs  num_wings\n    falcon      True       True\n    dog        False       True\n\n    When ``values`` is a dict, we can pass values to check for each\n    column separately:\n\n    >>> df.isin({'num_wings': [0, 3]})\n            num_legs  num_wings\n    falcon     False      False\n    dog        False       True\n\n    When ``values`` is a Series or DataFrame the index and column must\n    match. Note that 'falcon' does not match based on the number of legs\n    in df2.\n\n    >>> other = pd.DataFrame({'num_legs': [8, 2], 'num_wings': [0, 2]},\n    ...                      index=['spider', 'falcon'])\n    >>> df.isin(other)\n            num_legs  num_wings\n    falcon      True       True\n    dog        False      False\n    \"\"\"\n    if isinstance(values, dict):\n        from pandas.core.reshape.concat import concat\n        values = collections.defaultdict(list, values)\n        return concat((self.iloc[:, [i]].isin(values[col]) for i, col in enumerate(self.columns)), axis=1)\n    elif isinstance(values, Series):\n        if not values.index.is_unique:\n            raise ValueError('cannot compute isin with a duplicate axis.')\n        return self.eq(values.reindex_like(self), axis='index')\n    elif isinstance(values, DataFrame):\n        if not (values.columns.is_unique and values.index.is_unique):\n            raise ValueError('cannot compute isin with a duplicate axis.')\n        return self.eq(values.reindex_like(self))\n    else:\n        if not is_list_like(values):\n            raise TypeError(f\"only list-like or dict-like objects are allowed to be passed to DataFrame.isin(), you passed a '{type(values).__name__}'\")\n        return DataFrame(algorithms.isin(self.values.ravel(), values).reshape(self.shape), self.index, self.columns)",
                            "def extract_unique_dtypes_from_dtypes_set(dtypes_set: FrozenSet[Dtype], unique_dtypes: np.ndarray) -> List[Dtype]:\n    extracted_dtypes = [unique_dtype for unique_dtype in unique_dtypes if issubclass(unique_dtype.type, tuple(dtypes_set))]\n    return extracted_dtypes",
                            "def reindexer(value):\n    if value.index.equals(self.index) or not len(self.index):\n        value = value._values.copy()\n    else:\n        try:\n            value = value.reindex(self.index)._values\n        except ValueError as err:\n            if not value.index.is_unique:\n                raise err\n            raise TypeError('incompatible index of inserted column with frame index') from err\n    return value",
                            "def _maybe_casted_values(index, labels=None):\n    values = index._values\n    if not isinstance(index, (PeriodIndex, DatetimeIndex)):\n        if values.dtype == np.object_:\n            values = lib.maybe_convert_objects(values)\n    if labels is not None:\n        mask = labels == -1\n        if mask.all():\n            values = np.empty(len(mask))\n            values.fill(np.nan)\n        else:\n            values = values.take(labels)\n            values_type = type(values)\n            values_dtype = values.dtype\n            if issubclass(values_type, DatetimeLikeArray):\n                values = values._data\n            if mask.any():\n                values, _ = maybe_upcast_putmask(values, mask, np.nan)\n            if issubclass(values_type, DatetimeLikeArray):\n                values = values_type(values, dtype=values_dtype)\n    return values",
                            "def f(vals):\n    labels, shape = algorithms.factorize(vals, size_hint=min(len(self), _SIZE_HINT_LIMIT))\n    return (labels.astype('i8', copy=False), len(shape))",
                            "def extract_values(arr):\n    if isinstance(arr, (ABCIndexClass, ABCSeries)):\n        arr = arr._values\n    if needs_i8_conversion(arr):\n        if is_extension_array_dtype(arr.dtype):\n            arr = arr.asi8\n        else:\n            arr = arr.view('i8')\n    return arr",
                            "def combiner(x, y):\n    mask = isna(x)\n    if isinstance(mask, (ABCIndexClass, ABCSeries)):\n        mask = mask._values\n    x_values = extract_values(x)\n    y_values = extract_values(y)\n    if y.name not in self.columns:\n        return y_values\n    return expressions.where(mask, y_values, x_values)",
                            "def infer(x):\n    if x.empty:\n        return lib.map_infer(x, func)\n    return lib.map_infer(x.astype(object).values, func)",
                            "def _dict_round(df, decimals):\n    for col, vals in df.items():\n        try:\n            yield _series_round(vals, decimals[col])\n        except KeyError:\n            yield vals",
                            "def _series_round(s, decimals):\n    if is_integer_dtype(s) or is_float_dtype(s):\n        return s.round(decimals)\n    return s",
                            "def f(x):\n    return op(x, axis=axis, skipna=skipna, **kwds)",
                            "def _get_data(axis_matters):\n    if filter_type is None:\n        data = self._get_numeric_data()\n    elif filter_type == 'bool':\n        if axis_matters:\n            data = self._get_bool_data() if axis == 0 else self\n        else:\n            data = self._get_bool_data()\n    else:\n        msg = f'Generating numeric_only data with filter_type {filter_type} not supported.'\n        raise NotImplementedError(msg)\n    return data",
                            "def f(s):\n    return s.mode(dropna=dropna)",
                            "def _arith_op(left, right):\n    left, right = ops.fill_binop(left, right, fill_value)\n    return func(left, right)",
                            "def blk_func(values):\n    if values.ndim == 1 and (not isinstance(values, np.ndarray)):\n        return op(values, axis=0, skipna=skipna, **kwds)\n    return op(values, axis=1, skipna=skipna, **kwds)",
                            "def c(x):\n    return nanops.nancorr(x[0], x[1], method=method)"
                        ],
                        "constructor_variables": [
                            "exc",
                            "mask",
                            "data_columns",
                            "dtype",
                            "values",
                            "mgr",
                            "index",
                            "arr",
                            "data",
                            "columns"
                        ],
                        "class_level_variables": [
                            "_internal_names_set",
                            "_typ",
                            "_constructor_sliced",
                            "_deprecations",
                            "_accessors",
                            "_agg_summary_and_see_also_doc",
                            "_agg_examples_doc",
                            "agg",
                            "_AXIS_ORDERS",
                            "_AXIS_NUMBERS",
                            "_AXIS_NAMES",
                            "_AXIS_REVERSED",
                            "_AXIS_LEN",
                            "_info_axis_number",
                            "_info_axis_name",
                            "index",
                            "columns",
                            "plot",
                            "hist",
                            "boxplot",
                            "sparse"
                        ],
                        "class_decorators": [],
                        "function_signatures": [
                            "_constructor(self) -> Type['DataFrame']",
                            "_constructor_expanddim(self)",
                            "__init__(self, data=None, index: Optional[Axes]=None, columns: Optional[Axes]=None, dtype: Optional[Dtype]=None, copy: bool=False)",
                            "axes(self) -> List[Index]",
                            "shape(self) -> Tuple[int, int]",
                            "_is_homogeneous_type(self) -> bool",
                            "_repr_fits_vertical_(self) -> bool",
                            "_repr_fits_horizontal_(self, ignore_width: bool=False) -> bool",
                            "_info_repr(self) -> bool",
                            "__repr__(self) -> str",
                            "_repr_html_(self) -> Optional[str]",
                            "to_string(self, buf: Optional[FilePathOrBuffer[str]]=None, columns: Optional[Sequence[str]]=None, col_space: Optional[int]=None, header: Union[bool, Sequence[str]]=True, index: bool=True, na_rep: str='NaN', formatters: Optional[fmt.FormattersType]=None, float_format: Optional[fmt.FloatFormatType]=None, sparsify: Optional[bool]=None, index_names: bool=True, justify: Optional[str]=None, max_rows: Optional[int]=None, min_rows: Optional[int]=None, max_cols: Optional[int]=None, show_dimensions: bool=False, decimal: str='.', line_width: Optional[int]=None, max_colwidth: Optional[int]=None, encoding: Optional[str]=None) -> Optional[str]",
                            "style(self) -> 'Styler'",
                            "items(self) -> Iterable[Tuple[Label, Series]]",
                            "iteritems(self) -> Iterable[Tuple[Label, Series]]",
                            "iterrows(self) -> Iterable[Tuple[Label, Series]]",
                            "itertuples(self, index=True, name='Pandas')",
                            "__len__(self) -> int",
                            "dot(self, other)",
                            "__matmul__(self, other)",
                            "__rmatmul__(self, other)",
                            "from_dict(cls, data, orient='columns', dtype=None, columns=None) -> 'DataFrame'",
                            "to_numpy(self, dtype=None, copy=False) -> np.ndarray",
                            "to_dict(self, orient='dict', into=dict)",
                            "to_gbq(self, destination_table, project_id=None, chunksize=None, reauth=False, if_exists='fail', auth_local_webserver=False, table_schema=None, location=None, progress_bar=True, credentials=None) -> None",
                            "from_records(cls, data, index=None, exclude=None, columns=None, coerce_float=False, nrows=None) -> 'DataFrame'",
                            "to_records(self, index=True, column_dtypes=None, index_dtypes=None) -> np.recarray",
                            "_from_arrays(cls, arrays, columns, index, dtype=None) -> 'DataFrame'",
                            "to_stata(self, path: FilePathOrBuffer, convert_dates: Optional[Dict[Label, str]]=None, write_index: bool=True, byteorder: Optional[str]=None, time_stamp: Optional[datetime.datetime]=None, data_label: Optional[str]=None, variable_labels: Optional[Dict[Label, str]]=None, version: Optional[int]=114, convert_strl: Optional[Sequence[Label]]=None) -> None",
                            "to_feather(self, path) -> None",
                            "to_markdown(self, buf: Optional[IO[str]]=None, mode: Optional[str]=None, **kwargs) -> Optional[str]",
                            "to_parquet(self, path, engine='auto', compression='snappy', index=None, partition_cols=None, **kwargs) -> None",
                            "to_html(self, buf=None, columns=None, col_space=None, header=True, index=True, na_rep='NaN', formatters=None, float_format=None, sparsify=None, index_names=True, justify=None, max_rows=None, max_cols=None, show_dimensions=False, decimal='.', bold_rows=True, classes=None, escape=True, notebook=False, border=None, table_id=None, render_links=False, encoding=None)",
                            "info(self, verbose=None, buf=None, max_cols=None, memory_usage=None, null_counts=None) -> None",
                            "memory_usage(self, index=True, deep=False) -> Series",
                            "transpose(self, *args) -> 'DataFrame'",
                            "T(self) -> 'DataFrame'",
                            "_ixs(self, i: int, axis: int=0)",
                            "__getitem__(self, key)",
                            "_getitem_bool_array(self, key)",
                            "_getitem_multilevel(self, key)",
                            "_get_value(self, index, col, takeable: bool=False)",
                            "__setitem__(self, key, value)",
                            "_setitem_slice(self, key: slice, value)",
                            "_setitem_array(self, key, value)",
                            "_setitem_frame(self, key, value)",
                            "_iset_item(self, loc: int, value)",
                            "_set_item(self, key, value)",
                            "_set_value(self, index, col, value, takeable: bool=False)",
                            "_ensure_valid_index(self, value)",
                            "_box_item_values(self, key, values)",
                            "_box_col_values(self, values, items)",
                            "query(self, expr, inplace=False, **kwargs)",
                            "eval(self, expr, inplace=False, **kwargs)",
                            "select_dtypes(self, include=None, exclude=None) -> 'DataFrame'",
                            "insert(self, loc, column, value, allow_duplicates=False) -> None",
                            "assign(self, **kwargs) -> 'DataFrame'",
                            "_sanitize_column(self, key, value, broadcast=True)",
                            "_series(self)",
                            "lookup(self, row_labels, col_labels) -> np.ndarray",
                            "_reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy)",
                            "_reindex_index(self, new_index, method, copy, level, fill_value=np.nan, limit=None, tolerance=None)",
                            "_reindex_columns(self, new_columns, method, copy, level, fill_value=None, limit=None, tolerance=None)",
                            "_reindex_multi(self, axes, copy, fill_value) -> 'DataFrame'",
                            "align(self, other, join='outer', axis=None, level=None, copy=True, fill_value=None, method=None, limit=None, fill_axis=0, broadcast_axis=None) -> 'DataFrame'",
                            "set_axis(self, labels, axis: Axis=0, inplace: bool=False)",
                            "reindex(self, *args, **kwargs) -> 'DataFrame'",
                            "drop(self, labels=None, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise')",
                            "rename(self, mapper: Optional[Renamer]=None) -> Optional['DataFrame']",
                            "fillna(self, value=None, method=None, axis=None, inplace=False, limit=None, downcast=None) -> Optional['DataFrame']",
                            "replace(self, to_replace=None, value=None, inplace=False, limit=None, regex=False, method='pad')",
                            "shift(self, periods=1, freq=None, axis=0, fill_value=None) -> 'DataFrame'",
                            "set_index(self, keys, drop=True, append=False, inplace=False, verify_integrity=False)",
                            "reset_index(self, level: Optional[Union[Hashable, Sequence[Hashable]]]=None, drop: bool=False, inplace: bool=False, col_level: Hashable=0, col_fill: Label='') -> Optional['DataFrame']",
                            "isna(self) -> 'DataFrame'",
                            "isnull(self) -> 'DataFrame'",
                            "notna(self) -> 'DataFrame'",
                            "notnull(self) -> 'DataFrame'",
                            "dropna(self, axis=0, how='any', thresh=None, subset=None, inplace=False)",
                            "drop_duplicates(self, subset: Optional[Union[Hashable, Sequence[Hashable]]]=None, keep: Union[str, bool]='first', inplace: bool=False, ignore_index: bool=False) -> Optional['DataFrame']",
                            "duplicated(self, subset: Optional[Union[Hashable, Sequence[Hashable]]]=None, keep: Union[str, bool]='first') -> 'Series'",
                            "sort_values(self, by, axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last', ignore_index=False)",
                            "sort_index(self, axis=0, level=None, ascending: bool=True, inplace: bool=False, kind: str='quicksort', na_position: str='last', sort_remaining: bool=True, ignore_index: bool=False)",
                            "value_counts(self, subset: Optional[Sequence[Label]]=None, normalize: bool=False, sort: bool=True, ascending: bool=False)",
                            "nlargest(self, n, columns, keep='first') -> 'DataFrame'",
                            "nsmallest(self, n, columns, keep='first') -> 'DataFrame'",
                            "swaplevel(self, i=-2, j=-1, axis=0) -> 'DataFrame'",
                            "reorder_levels(self, order, axis=0) -> 'DataFrame'",
                            "_combine_frame(self, other: 'DataFrame', func, fill_value=None)",
                            "_construct_result(self, result) -> 'DataFrame'",
                            "combine(self, other: 'DataFrame', func, fill_value=None, overwrite=True) -> 'DataFrame'",
                            "combine_first(self, other: 'DataFrame') -> 'DataFrame'",
                            "update(self, other, join='left', overwrite=True, filter_func=None, errors='ignore') -> None",
                            "groupby(self, by=None, axis=0, level=None, as_index: bool=True, sort: bool=True, group_keys: bool=True, squeeze: bool=False, observed: bool=False) -> 'DataFrameGroupBy'",
                            "pivot(self, index=None, columns=None, values=None) -> 'DataFrame'",
                            "pivot_table(self, values=None, index=None, columns=None, aggfunc='mean', fill_value=None, margins=False, dropna=True, margins_name='All', observed=False) -> 'DataFrame'",
                            "stack(self, level=-1, dropna=True)",
                            "explode(self, column: Union[str, Tuple]) -> 'DataFrame'",
                            "unstack(self, level=-1, fill_value=None)",
                            "melt(self, id_vars=None, value_vars=None, var_name=None, value_name='value', col_level=None) -> 'DataFrame'",
                            "diff(self, periods=1, axis=0) -> 'DataFrame'",
                            "_gotitem(self, key: Union[str, List[str]], ndim: int, subset: Optional[Union[Series, ABCDataFrame]]=None) -> Union[Series, ABCDataFrame]",
                            "aggregate(self, func, axis=0, *args, **kwargs)",
                            "_aggregate(self, arg, axis=0, *args, **kwargs)",
                            "transform(self, func, axis=0, *args, **kwargs) -> 'DataFrame'",
                            "apply(self, func, axis=0, raw=False, result_type=None, args=(), **kwds)",
                            "applymap(self, func) -> 'DataFrame'",
                            "append(self, other, ignore_index=False, verify_integrity=False, sort=False) -> 'DataFrame'",
                            "join(self, other, on=None, how='left', lsuffix='', rsuffix='', sort=False) -> 'DataFrame'",
                            "_join_compat(self, other, on=None, how='left', lsuffix='', rsuffix='', sort=False)",
                            "merge(self, right, how='inner', on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=False, suffixes=('_x', '_y'), copy=True, indicator=False, validate=None) -> 'DataFrame'",
                            "round(self, decimals=0, *args, **kwargs) -> 'DataFrame'",
                            "corr(self, method='pearson', min_periods=1) -> 'DataFrame'",
                            "cov(self, min_periods=None) -> 'DataFrame'",
                            "corrwith(self, other, axis=0, drop=False, method='pearson') -> Series",
                            "count(self, axis=0, level=None, numeric_only=False)",
                            "_count_level(self, level, axis=0, numeric_only=False)",
                            "_reduce(self, op, name, axis=0, skipna=True, numeric_only=None, filter_type=None, **kwds)",
                            "nunique(self, axis=0, dropna=True) -> Series",
                            "idxmin(self, axis=0, skipna=True) -> Series",
                            "idxmax(self, axis=0, skipna=True) -> Series",
                            "_get_agg_axis(self, axis_num)",
                            "mode(self, axis=0, numeric_only=False, dropna=True) -> 'DataFrame'",
                            "quantile(self, q=0.5, axis=0, numeric_only=True, interpolation='linear')",
                            "to_timestamp(self, freq=None, how: str='start', axis: Axis=0, copy: bool=True) -> 'DataFrame'",
                            "to_period(self, freq=None, axis: Axis=0, copy: bool=True) -> 'DataFrame'",
                            "isin(self, values) -> 'DataFrame'",
                            "extract_unique_dtypes_from_dtypes_set(dtypes_set: FrozenSet[Dtype], unique_dtypes: np.ndarray) -> List[Dtype]",
                            "reindexer(value)",
                            "_maybe_casted_values(index, labels=None)",
                            "f(vals)",
                            "extract_values(arr)",
                            "combiner(x, y)",
                            "infer(x)",
                            "_dict_round(df, decimals)",
                            "_series_round(s, decimals)",
                            "f(x)",
                            "_get_data(axis_matters)",
                            "f(s)",
                            "_arith_op(left, right)",
                            "blk_func(values)",
                            "c(x)"
                        ]
                    },
                    "variable_values": [
                        [
                            {
                                "com.is_bool_indexer": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "com": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "key": {
                                    "variable_value": "['A', 'C']",
                                    "variable_type": "list",
                                    "variable_shape": "2"
                                },
                                "self.index": {
                                    "variable_value": "RangeIndex(start=0, stop=3, step=1)",
                                    "variable_type": "RangeIndex",
                                    "variable_shape": "3"
                                },
                                "self": {
                                    "variable_value": "   A  B\n0  1  2\n1  3  4\n2  5  6",
                                    "variable_type": "DataFrame",
                                    "variable_shape": "3"
                                },
                                "check_bool_indexer": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "indexer": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "key.nonzero": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self._check_setitem_copy": {
                                    "variable_value": "<bound method NDFrame._check_setitem_copy of    A  B\n0  1  2\n1  3  4\n2  5  6>",
                                    "variable_type": "method",
                                    "variable_shape": null
                                },
                                "self.iloc._setitem_with_indexer": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self.iloc": {
                                    "variable_value": "<pandas.core.indexing._iLocIndexer object at 0x115e30f40>",
                                    "variable_type": "_iLocIndexer",
                                    "variable_shape": null
                                },
                                "value": {
                                    "variable_value": "    A   C\n0   7   8\n1   9  10\n2  11  12",
                                    "variable_type": "DataFrame",
                                    "variable_shape": "3"
                                },
                                "DataFrame": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "value.columns": {
                                    "variable_value": "Index(['A', 'C'], dtype='object')",
                                    "variable_type": "Index",
                                    "variable_shape": "2"
                                },
                                "k1": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "k2": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.loc._get_listlike_indexer": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self.loc": {
                                    "variable_value": "<pandas.core.indexing._LocIndexer object at 0x115ebeb80>",
                                    "variable_type": "_LocIndexer",
                                    "variable_shape": null
                                }
                            },
                            {
                                "com.is_bool_indexer": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "com": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "key": {
                                    "variable_value": "['A', 'C']",
                                    "variable_type": "list",
                                    "variable_shape": "2"
                                },
                                "self.index": {
                                    "variable_value": "RangeIndex(start=0, stop=3, step=1)",
                                    "variable_type": "RangeIndex",
                                    "variable_shape": "3"
                                },
                                "self": {
                                    "variable_value": "    A  B   C\n0   7  2   8\n1   9  4  10\n2  11  6  12",
                                    "variable_type": "DataFrame",
                                    "variable_shape": "3"
                                },
                                "check_bool_indexer": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "indexer": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "key.nonzero": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self._check_setitem_copy": {
                                    "variable_value": "<bound method NDFrame._check_setitem_copy of     A  B   C\n0   7  2   8\n1   9  4  10\n2  11  6  12>",
                                    "variable_type": "method",
                                    "variable_shape": null
                                },
                                "self.iloc._setitem_with_indexer": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self.iloc": {
                                    "variable_value": "<pandas.core.indexing._iLocIndexer object at 0x115ebe270>",
                                    "variable_type": "_iLocIndexer",
                                    "variable_shape": null
                                },
                                "value": {
                                    "variable_value": "    A   C\n0   7   8\n1   9  10\n2  11  12",
                                    "variable_type": "DataFrame",
                                    "variable_shape": "3"
                                },
                                "DataFrame": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "value.columns": {
                                    "variable_value": "Index(['A', 'C'], dtype='object')",
                                    "variable_type": "Index",
                                    "variable_shape": "2"
                                },
                                "k1": {
                                    "variable_value": "'C'",
                                    "variable_type": "str",
                                    "variable_shape": "1"
                                },
                                "k2": {
                                    "variable_value": "'C'",
                                    "variable_type": "str",
                                    "variable_shape": "1"
                                },
                                "self.loc._get_listlike_indexer": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self.loc": {
                                    "variable_value": "<pandas.core.indexing._LocIndexer object at 0x115ebef40>",
                                    "variable_type": "_LocIndexer",
                                    "variable_shape": null
                                }
                            }
                        ]
                    ],
                    "angelic_variable_values": [
                        [
                            {
                                "com.is_bool_indexer": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "com": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "key": {
                                    "variable_value": "['A', 'B', 'C', 'D']",
                                    "variable_type": "list",
                                    "variable_shape": "4"
                                },
                                "self.index": {
                                    "variable_value": "RangeIndex(start=0, stop=3, step=1)",
                                    "variable_type": "RangeIndex",
                                    "variable_shape": "3"
                                },
                                "self": {
                                    "variable_value": "   A  B\n0  1  2\n1  3  4\n2  5  6",
                                    "variable_type": "DataFrame",
                                    "variable_shape": "3"
                                },
                                "check_bool_indexer": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "indexer": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "key.nonzero": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self._check_setitem_copy": {
                                    "variable_value": "<bound method NDFrame._check_setitem_copy of    A  B\n0  1  2\n1  3  4\n2  5  6>",
                                    "variable_type": "method",
                                    "variable_shape": null
                                },
                                "self.iloc._setitem_with_indexer": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self.iloc": {
                                    "variable_value": "<pandas.core.indexing._iLocIndexer object at 0x127346400>",
                                    "variable_type": "_iLocIndexer",
                                    "variable_shape": null
                                },
                                "value": {
                                    "variable_value": "7",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "DataFrame": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "value.columns": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "k1": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "k2": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.loc._ensure_listlike_indexer": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self.loc": {
                                    "variable_value": "<pandas.core.indexing._LocIndexer object at 0x127346400>",
                                    "variable_type": "_LocIndexer",
                                    "variable_shape": null
                                },
                                "self.loc._get_listlike_indexer": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                }
                            },
                            {
                                "com.is_bool_indexer": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "com": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "key": {
                                    "variable_value": "['A', 'B', 'C', 'D']",
                                    "variable_type": "list",
                                    "variable_shape": "4"
                                },
                                "self.index": {
                                    "variable_value": "RangeIndex(start=0, stop=3, step=1)",
                                    "variable_type": "RangeIndex",
                                    "variable_shape": "3"
                                },
                                "self": {
                                    "variable_value": "   A  B  C  D\n0  7  7  7  7\n1  7  7  7  7\n2  7  7  7  7",
                                    "variable_type": "DataFrame",
                                    "variable_shape": "3"
                                },
                                "check_bool_indexer": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "indexer": {
                                    "variable_value": "array([0, 1, 2, 3])",
                                    "variable_type": "ndarray",
                                    "variable_shape": "4"
                                },
                                "key.nonzero": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self._check_setitem_copy": {
                                    "variable_value": "<bound method NDFrame._check_setitem_copy of    A  B  C  D\n0  7  7  7  7\n1  7  7  7  7\n2  7  7  7  7>",
                                    "variable_type": "method",
                                    "variable_shape": null
                                },
                                "self.iloc._setitem_with_indexer": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self.iloc": {
                                    "variable_value": "<pandas.core.indexing._iLocIndexer object at 0x127346cc0>",
                                    "variable_type": "_iLocIndexer",
                                    "variable_shape": null
                                },
                                "value": {
                                    "variable_value": "7",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "DataFrame": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "value.columns": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "k1": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "k2": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.loc._ensure_listlike_indexer": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self.loc": {
                                    "variable_value": "<pandas.core.indexing._LocIndexer object at 0x127346cc0>",
                                    "variable_type": "_LocIndexer",
                                    "variable_shape": null
                                },
                                "self.loc._get_listlike_indexer": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                }
                            }
                        ],
                        [
                            {
                                "com.is_bool_indexer": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "com": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "key": {
                                    "variable_value": "['C', 'D']",
                                    "variable_type": "list",
                                    "variable_shape": "2"
                                },
                                "self.index": {
                                    "variable_value": "RangeIndex(start=0, stop=3, step=1)",
                                    "variable_type": "RangeIndex",
                                    "variable_shape": "3"
                                },
                                "self": {
                                    "variable_value": "   A  B\n0  1  2\n1  3  4\n2  5  6",
                                    "variable_type": "DataFrame",
                                    "variable_shape": "3"
                                },
                                "check_bool_indexer": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "indexer": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "key.nonzero": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self._check_setitem_copy": {
                                    "variable_value": "<bound method NDFrame._check_setitem_copy of    A  B\n0  1  2\n1  3  4\n2  5  6>",
                                    "variable_type": "method",
                                    "variable_shape": null
                                },
                                "self.iloc._setitem_with_indexer": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self.iloc": {
                                    "variable_value": "<pandas.core.indexing._iLocIndexer object at 0x127346040>",
                                    "variable_type": "_iLocIndexer",
                                    "variable_shape": null
                                },
                                "value": {
                                    "variable_value": "[7, 8]",
                                    "variable_type": "list",
                                    "variable_shape": "2"
                                },
                                "DataFrame": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "value.columns": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "k1": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "k2": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.loc._ensure_listlike_indexer": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self.loc": {
                                    "variable_value": "<pandas.core.indexing._LocIndexer object at 0x127346040>",
                                    "variable_type": "_LocIndexer",
                                    "variable_shape": null
                                },
                                "self.loc._get_listlike_indexer": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                }
                            },
                            {
                                "com.is_bool_indexer": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "com": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "key": {
                                    "variable_value": "['C', 'D']",
                                    "variable_type": "list",
                                    "variable_shape": "2"
                                },
                                "self.index": {
                                    "variable_value": "RangeIndex(start=0, stop=3, step=1)",
                                    "variable_type": "RangeIndex",
                                    "variable_shape": "3"
                                },
                                "self": {
                                    "variable_value": "   A  B  C  D\n0  1  2  7  8\n1  3  4  7  8\n2  5  6  7  8",
                                    "variable_type": "DataFrame",
                                    "variable_shape": "3"
                                },
                                "check_bool_indexer": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "indexer": {
                                    "variable_value": "array([2, 3])",
                                    "variable_type": "ndarray",
                                    "variable_shape": "2"
                                },
                                "key.nonzero": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self._check_setitem_copy": {
                                    "variable_value": "<bound method NDFrame._check_setitem_copy of    A  B  C  D\n0  1  2  7  8\n1  3  4  7  8\n2  5  6  7  8>",
                                    "variable_type": "method",
                                    "variable_shape": null
                                },
                                "self.iloc._setitem_with_indexer": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self.iloc": {
                                    "variable_value": "<pandas.core.indexing._iLocIndexer object at 0x1273469a0>",
                                    "variable_type": "_iLocIndexer",
                                    "variable_shape": null
                                },
                                "value": {
                                    "variable_value": "[7, 8]",
                                    "variable_type": "list",
                                    "variable_shape": "2"
                                },
                                "DataFrame": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "value.columns": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "k1": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "k2": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.loc._ensure_listlike_indexer": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self.loc": {
                                    "variable_value": "<pandas.core.indexing._LocIndexer object at 0x1273469a0>",
                                    "variable_type": "_LocIndexer",
                                    "variable_shape": null
                                },
                                "self.loc._get_listlike_indexer": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                }
                            }
                        ],
                        [
                            {
                                "com.is_bool_indexer": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "com": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "key": {
                                    "variable_value": "['A', 'B', 'C']",
                                    "variable_type": "list",
                                    "variable_shape": "3"
                                },
                                "self.index": {
                                    "variable_value": "RangeIndex(start=0, stop=3, step=1)",
                                    "variable_type": "RangeIndex",
                                    "variable_shape": "3"
                                },
                                "self": {
                                    "variable_value": "   A  B\n0  1  2\n1  3  4\n2  5  6",
                                    "variable_type": "DataFrame",
                                    "variable_shape": "3"
                                },
                                "check_bool_indexer": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "indexer": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "key.nonzero": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self._check_setitem_copy": {
                                    "variable_value": "<bound method NDFrame._check_setitem_copy of    A  B\n0  1  2\n1  3  4\n2  5  6>",
                                    "variable_type": "method",
                                    "variable_shape": null
                                },
                                "self.iloc._setitem_with_indexer": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self.iloc": {
                                    "variable_value": "<pandas.core.indexing._iLocIndexer object at 0x11f293400>",
                                    "variable_type": "_iLocIndexer",
                                    "variable_shape": null
                                },
                                "value": {
                                    "variable_value": "array([7, 8, 9])",
                                    "variable_type": "ndarray",
                                    "variable_shape": "3"
                                },
                                "DataFrame": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "value.columns": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "k1": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "k2": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.loc._ensure_listlike_indexer": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self.loc": {
                                    "variable_value": "<pandas.core.indexing._LocIndexer object at 0x11f293400>",
                                    "variable_type": "_LocIndexer",
                                    "variable_shape": null
                                },
                                "self.loc._get_listlike_indexer": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                }
                            },
                            {
                                "com.is_bool_indexer": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "com": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "key": {
                                    "variable_value": "['A', 'B', 'C']",
                                    "variable_type": "list",
                                    "variable_shape": "3"
                                },
                                "self.index": {
                                    "variable_value": "RangeIndex(start=0, stop=3, step=1)",
                                    "variable_type": "RangeIndex",
                                    "variable_shape": "3"
                                },
                                "self": {
                                    "variable_value": "   A  B  C\n0  7  8  9\n1  7  8  9\n2  7  8  9",
                                    "variable_type": "DataFrame",
                                    "variable_shape": "3"
                                },
                                "check_bool_indexer": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "indexer": {
                                    "variable_value": "array([0, 1, 2])",
                                    "variable_type": "ndarray",
                                    "variable_shape": "3"
                                },
                                "key.nonzero": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self._check_setitem_copy": {
                                    "variable_value": "<bound method NDFrame._check_setitem_copy of    A  B  C\n0  7  8  9\n1  7  8  9\n2  7  8  9>",
                                    "variable_type": "method",
                                    "variable_shape": null
                                },
                                "self.iloc._setitem_with_indexer": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self.iloc": {
                                    "variable_value": "<pandas.core.indexing._iLocIndexer object at 0x11f293d60>",
                                    "variable_type": "_iLocIndexer",
                                    "variable_shape": null
                                },
                                "value": {
                                    "variable_value": "array([7, 8, 9])",
                                    "variable_type": "ndarray",
                                    "variable_shape": "3"
                                },
                                "DataFrame": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "value.columns": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "k1": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "k2": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.loc._ensure_listlike_indexer": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self.loc": {
                                    "variable_value": "<pandas.core.indexing._LocIndexer object at 0x11f293d60>",
                                    "variable_type": "_LocIndexer",
                                    "variable_shape": null
                                },
                                "self.loc._get_listlike_indexer": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                }
                            }
                        ],
                        [
                            {
                                "com.is_bool_indexer": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "com": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "key": {
                                    "variable_value": "['B', 'C', 'D']",
                                    "variable_type": "list",
                                    "variable_shape": "3"
                                },
                                "self.index": {
                                    "variable_value": "RangeIndex(start=0, stop=3, step=1)",
                                    "variable_type": "RangeIndex",
                                    "variable_shape": "3"
                                },
                                "self": {
                                    "variable_value": "   A  B\n0  1  2\n1  3  4\n2  5  6",
                                    "variable_type": "DataFrame",
                                    "variable_shape": "3"
                                },
                                "check_bool_indexer": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "indexer": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "key.nonzero": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self._check_setitem_copy": {
                                    "variable_value": "<bound method NDFrame._check_setitem_copy of    A  B\n0  1  2\n1  3  4\n2  5  6>",
                                    "variable_type": "method",
                                    "variable_shape": null
                                },
                                "self.iloc._setitem_with_indexer": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self.iloc": {
                                    "variable_value": "<pandas.core.indexing._iLocIndexer object at 0x11f293e00>",
                                    "variable_type": "_iLocIndexer",
                                    "variable_shape": null
                                },
                                "value": {
                                    "variable_value": "[[7, 8, 9], [10, 11, 12], [13, 14, 15]]",
                                    "variable_type": "list",
                                    "variable_shape": "3"
                                },
                                "DataFrame": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "value.columns": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "k1": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "k2": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.loc._ensure_listlike_indexer": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self.loc": {
                                    "variable_value": "<pandas.core.indexing._LocIndexer object at 0x11f293e00>",
                                    "variable_type": "_LocIndexer",
                                    "variable_shape": null
                                },
                                "self.loc._get_listlike_indexer": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                }
                            },
                            {
                                "com.is_bool_indexer": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "com": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "key": {
                                    "variable_value": "['B', 'C', 'D']",
                                    "variable_type": "list",
                                    "variable_shape": "3"
                                },
                                "self.index": {
                                    "variable_value": "RangeIndex(start=0, stop=3, step=1)",
                                    "variable_type": "RangeIndex",
                                    "variable_shape": "3"
                                },
                                "self": {
                                    "variable_value": "   A   B   C   D\n0  1   7   8   9\n1  3  10  11  12\n2  5  13  14  15",
                                    "variable_type": "DataFrame",
                                    "variable_shape": "3"
                                },
                                "check_bool_indexer": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "indexer": {
                                    "variable_value": "array([1, 2, 3])",
                                    "variable_type": "ndarray",
                                    "variable_shape": "3"
                                },
                                "key.nonzero": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self._check_setitem_copy": {
                                    "variable_value": "<bound method NDFrame._check_setitem_copy of    A   B   C   D\n0  1   7   8   9\n1  3  10  11  12\n2  5  13  14  15>",
                                    "variable_type": "method",
                                    "variable_shape": null
                                },
                                "self.iloc._setitem_with_indexer": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self.iloc": {
                                    "variable_value": "<pandas.core.indexing._iLocIndexer object at 0x11f2934a0>",
                                    "variable_type": "_iLocIndexer",
                                    "variable_shape": null
                                },
                                "value": {
                                    "variable_value": "[[7, 8, 9], [10, 11, 12], [13, 14, 15]]",
                                    "variable_type": "list",
                                    "variable_shape": "3"
                                },
                                "DataFrame": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "value.columns": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "k1": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "k2": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.loc._ensure_listlike_indexer": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self.loc": {
                                    "variable_value": "<pandas.core.indexing._LocIndexer object at 0x11f2934a0>",
                                    "variable_type": "_LocIndexer",
                                    "variable_shape": null
                                },
                                "self.loc._get_listlike_indexer": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                }
                            }
                        ],
                        [
                            {
                                "com.is_bool_indexer": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "com": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "key": {
                                    "variable_value": "['C', 'A', 'D']",
                                    "variable_type": "list",
                                    "variable_shape": "3"
                                },
                                "self.index": {
                                    "variable_value": "RangeIndex(start=0, stop=3, step=1)",
                                    "variable_type": "RangeIndex",
                                    "variable_shape": "3"
                                },
                                "self": {
                                    "variable_value": "   A  B\n0  1  2\n1  3  4\n2  5  6",
                                    "variable_type": "DataFrame",
                                    "variable_shape": "3"
                                },
                                "check_bool_indexer": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "indexer": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "key.nonzero": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self._check_setitem_copy": {
                                    "variable_value": "<bound method NDFrame._check_setitem_copy of    A  B\n0  1  2\n1  3  4\n2  5  6>",
                                    "variable_type": "method",
                                    "variable_shape": null
                                },
                                "self.iloc._setitem_with_indexer": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self.iloc": {
                                    "variable_value": "<pandas.core.indexing._iLocIndexer object at 0x127346090>",
                                    "variable_type": "_iLocIndexer",
                                    "variable_shape": null
                                },
                                "value": {
                                    "variable_value": "array([[ 7,  8,  9],\n       [10, 11, 12],\n       [13, 14, 15]])",
                                    "variable_type": "ndarray",
                                    "variable_shape": "3"
                                },
                                "DataFrame": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "value.columns": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "k1": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "k2": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.loc._ensure_listlike_indexer": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self.loc": {
                                    "variable_value": "<pandas.core.indexing._LocIndexer object at 0x127346040>",
                                    "variable_type": "_LocIndexer",
                                    "variable_shape": null
                                },
                                "self.loc._get_listlike_indexer": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                }
                            },
                            {
                                "com.is_bool_indexer": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "com": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "key": {
                                    "variable_value": "['C', 'A', 'D']",
                                    "variable_type": "list",
                                    "variable_shape": "3"
                                },
                                "self.index": {
                                    "variable_value": "RangeIndex(start=0, stop=3, step=1)",
                                    "variable_type": "RangeIndex",
                                    "variable_shape": "3"
                                },
                                "self": {
                                    "variable_value": "    A  B   C   D\n0   8  2   7   9\n1  11  4  10  12\n2  14  6  13  15",
                                    "variable_type": "DataFrame",
                                    "variable_shape": "3"
                                },
                                "check_bool_indexer": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "indexer": {
                                    "variable_value": "array([2, 0, 3])",
                                    "variable_type": "ndarray",
                                    "variable_shape": "3"
                                },
                                "key.nonzero": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self._check_setitem_copy": {
                                    "variable_value": "<bound method NDFrame._check_setitem_copy of     A  B   C   D\n0   8  2   7   9\n1  11  4  10  12\n2  14  6  13  15>",
                                    "variable_type": "method",
                                    "variable_shape": null
                                },
                                "self.iloc._setitem_with_indexer": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self.iloc": {
                                    "variable_value": "<pandas.core.indexing._iLocIndexer object at 0x11f2932c0>",
                                    "variable_type": "_iLocIndexer",
                                    "variable_shape": null
                                },
                                "value": {
                                    "variable_value": "array([[ 7,  8,  9],\n       [10, 11, 12],\n       [13, 14, 15]])",
                                    "variable_type": "ndarray",
                                    "variable_shape": "3"
                                },
                                "DataFrame": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "value.columns": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "k1": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "k2": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.loc._ensure_listlike_indexer": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self.loc": {
                                    "variable_value": "<pandas.core.indexing._LocIndexer object at 0x11f293b80>",
                                    "variable_type": "_LocIndexer",
                                    "variable_shape": null
                                },
                                "self.loc._get_listlike_indexer": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                }
                            }
                        ],
                        [
                            {
                                "com.is_bool_indexer": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "com": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "key": {
                                    "variable_value": "['A', 'C']",
                                    "variable_type": "list",
                                    "variable_shape": "2"
                                },
                                "self.index": {
                                    "variable_value": "RangeIndex(start=0, stop=3, step=1)",
                                    "variable_type": "RangeIndex",
                                    "variable_shape": "3"
                                },
                                "self": {
                                    "variable_value": "   A  B\n0  1  2\n1  3  4\n2  5  6",
                                    "variable_type": "DataFrame",
                                    "variable_shape": "3"
                                },
                                "check_bool_indexer": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "indexer": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "key.nonzero": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self._check_setitem_copy": {
                                    "variable_value": "<bound method NDFrame._check_setitem_copy of    A  B\n0  1  2\n1  3  4\n2  5  6>",
                                    "variable_type": "method",
                                    "variable_shape": null
                                },
                                "self.iloc._setitem_with_indexer": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self.iloc": {
                                    "variable_value": "<pandas.core.indexing._iLocIndexer object at 0x11f293db0>",
                                    "variable_type": "_iLocIndexer",
                                    "variable_shape": null
                                },
                                "value": {
                                    "variable_value": "    A   C\n0   7   8\n1   9  10\n2  11  12",
                                    "variable_type": "DataFrame",
                                    "variable_shape": "3"
                                },
                                "DataFrame": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "value.columns": {
                                    "variable_value": "Index(['A', 'C'], dtype='object')",
                                    "variable_type": "Index",
                                    "variable_shape": "2"
                                },
                                "k1": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "k2": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.loc._ensure_listlike_indexer": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self.loc": {
                                    "variable_value": "<pandas.core.indexing._LocIndexer object at 0x11f289450>",
                                    "variable_type": "_LocIndexer",
                                    "variable_shape": null
                                },
                                "self.loc._get_listlike_indexer": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                }
                            },
                            {
                                "com.is_bool_indexer": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "com": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "key": {
                                    "variable_value": "['A', 'C']",
                                    "variable_type": "list",
                                    "variable_shape": "2"
                                },
                                "self.index": {
                                    "variable_value": "RangeIndex(start=0, stop=3, step=1)",
                                    "variable_type": "RangeIndex",
                                    "variable_shape": "3"
                                },
                                "self": {
                                    "variable_value": "    A  B   C\n0   7  2   8\n1   9  4  10\n2  11  6  12",
                                    "variable_type": "DataFrame",
                                    "variable_shape": "3"
                                },
                                "check_bool_indexer": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "indexer": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "key.nonzero": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self._check_setitem_copy": {
                                    "variable_value": "<bound method NDFrame._check_setitem_copy of     A  B   C\n0   7  2   8\n1   9  4  10\n2  11  6  12>",
                                    "variable_type": "method",
                                    "variable_shape": null
                                },
                                "self.iloc._setitem_with_indexer": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self.iloc": {
                                    "variable_value": "<pandas.core.indexing._iLocIndexer object at 0x11f293540>",
                                    "variable_type": "_iLocIndexer",
                                    "variable_shape": null
                                },
                                "value": {
                                    "variable_value": "    A   C\n0   7   8\n1   9  10\n2  11  12",
                                    "variable_type": "DataFrame",
                                    "variable_shape": "3"
                                },
                                "DataFrame": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "value.columns": {
                                    "variable_value": "Index(['A', 'C'], dtype='object')",
                                    "variable_type": "Index",
                                    "variable_shape": "2"
                                },
                                "k1": {
                                    "variable_value": "'C'",
                                    "variable_type": "str",
                                    "variable_shape": "1"
                                },
                                "k2": {
                                    "variable_value": "'C'",
                                    "variable_type": "str",
                                    "variable_shape": "1"
                                },
                                "self.loc._ensure_listlike_indexer": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self.loc": {
                                    "variable_value": "<pandas.core.indexing._LocIndexer object at 0x11f293d60>",
                                    "variable_type": "_LocIndexer",
                                    "variable_shape": null
                                },
                                "self.loc._get_listlike_indexer": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                }
                            }
                        ]
                    ]
                }
            ],
            "inscope_functions": [
                "def _from_nested_dict(data):\n    # TODO: this should be seriously cythonized\n    new_data = collections.defaultdict(dict)\n    for index, s in data.items():\n        for col, v in s.items():\n            new_data[col][index] = v\n    return new_data",
                "@property\ndef _constructor(self) -> Type[\"DataFrame\"]:\n    return DataFrame",
                "@property\ndef _constructor_expanddim(self):\n    raise NotImplementedError(\"Not supported for DataFrames!\")",
                "def __init__(\n    self,\n    data=None,\n    index: Optional[Axes] = None,\n    columns: Optional[Axes] = None,\n    dtype: Optional[Dtype] = None,\n    copy: bool = False,\n):\n    if data is None:\n        data = {}\n    if dtype is not None:\n        dtype = self._validate_dtype(dtype)\n\n    if isinstance(data, DataFrame):\n        data = data._data\n\n    if isinstance(data, BlockManager):\n        mgr = self._init_mgr(\n            data, axes=dict(index=index, columns=columns), dtype=dtype, copy=copy\n        )\n    elif isinstance(data, dict):\n        mgr = init_dict(data, index, columns, dtype=dtype)\n    elif isinstance(data, ma.MaskedArray):\n        import numpy.ma.mrecords as mrecords\n\n        # masked recarray\n        if isinstance(data, mrecords.MaskedRecords):\n            mgr = masked_rec_array_to_mgr(data, index, columns, dtype, copy)\n\n        # a masked array\n        else:\n            mask = ma.getmaskarray(data)\n            if mask.any():\n                data, fill_value = maybe_upcast(data, copy=True)\n                data.soften_mask()  # set hardmask False if it was True\n                data[mask] = fill_value\n            else:\n                data = data.copy()\n            mgr = init_ndarray(data, index, columns, dtype=dtype, copy=copy)\n\n    elif isinstance(data, (np.ndarray, Series, Index)):\n        if data.dtype.names:\n            data_columns = list(data.dtype.names)\n            data = {k: data[k] for k in data_columns}\n            if columns is None:\n                columns = data_columns\n            mgr = init_dict(data, index, columns, dtype=dtype)\n        elif getattr(data, \"name\", None) is not None:\n            mgr = init_dict({data.name: data}, index, columns, dtype=dtype)\n        else:\n            mgr = init_ndarray(data, index, columns, dtype=dtype, copy=copy)\n\n    # For data is list-like, or Iterable (will consume into list)\n    elif isinstance(data, abc.Iterable) and not isinstance(data, (str, bytes)):\n        if not isinstance(data, (abc.Sequence, ExtensionArray)):\n            data = list(data)\n        if len(data) > 0:\n            if is_list_like(data[0]) and getattr(data[0], \"ndim\", 1) == 1:\n                if is_named_tuple(data[0]) and columns is None:\n                    columns = data[0]._fields\n                arrays, columns = to_arrays(data, columns, dtype=dtype)\n                columns = ensure_index(columns)\n\n                # set the index\n                if index is None:\n                    if isinstance(data[0], Series):\n                        index = get_names_from_index(data)\n                    elif isinstance(data[0], Categorical):\n                        index = ibase.default_index(len(data[0]))\n                    else:\n                        index = ibase.default_index(len(data))\n\n                mgr = arrays_to_mgr(arrays, columns, index, columns, dtype=dtype)\n            else:\n                mgr = init_ndarray(data, index, columns, dtype=dtype, copy=copy)\n        else:\n            mgr = init_dict({}, index, columns, dtype=dtype)\n    else:\n        try:\n            arr = np.array(data, dtype=dtype, copy=copy)\n        except (ValueError, TypeError) as err:\n            exc = TypeError(\n                \"DataFrame constructor called with \"\n                f\"incompatible data and dtype: {err}\"\n            )\n            raise exc from err\n\n        if arr.ndim == 0 and index is not None and columns is not None:\n            values = cast_scalar_to_array(\n                (len(index), len(columns)), data, dtype=dtype\n            )\n            mgr = init_ndarray(\n                values, index, columns, dtype=values.dtype, copy=False\n            )\n        else:\n            raise ValueError(\"DataFrame constructor not properly called!\")\n\n    NDFrame.__init__(self, mgr)",
                "@property\ndef axes(self) -> List[Index]:\n    \"\"\"\n    Return a list representing the axes of the DataFrame.\n\n    It has the row axis labels and column axis labels as the only members.\n    They are returned in that order.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n    >>> df.axes\n    [RangeIndex(start=0, stop=2, step=1), Index(['col1', 'col2'],\n    dtype='object')]\n    \"\"\"\n    return [self.index, self.columns]",
                "@property\ndef shape(self) -> Tuple[int, int]:\n    \"\"\"\n    Return a tuple representing the dimensionality of the DataFrame.\n\n    See Also\n    --------\n    ndarray.shape\n\n    Examples\n    --------\n    >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n    >>> df.shape\n    (2, 2)\n\n    >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4],\n    ...                    'col3': [5, 6]})\n    >>> df.shape\n    (2, 3)\n    \"\"\"\n    return len(self.index), len(self.columns)",
                "@property\ndef _is_homogeneous_type(self) -> bool:\n    \"\"\"\n    Whether all the columns in a DataFrame have the same type.\n\n    Returns\n    -------\n    bool\n\n    See Also\n    --------\n    Index._is_homogeneous_type : Whether the object has a single\n        dtype.\n    MultiIndex._is_homogeneous_type : Whether all the levels of a\n        MultiIndex have the same dtype.\n\n    Examples\n    --------\n    >>> DataFrame({\"A\": [1, 2], \"B\": [3, 4]})._is_homogeneous_type\n    True\n    >>> DataFrame({\"A\": [1, 2], \"B\": [3.0, 4.0]})._is_homogeneous_type\n    False\n\n    Items with the same type but different sizes are considered\n    different types.\n\n    >>> DataFrame({\n    ...    \"A\": np.array([1, 2], dtype=np.int32),\n    ...    \"B\": np.array([1, 2], dtype=np.int64)})._is_homogeneous_type\n    False\n    \"\"\"\n    if self._data.any_extension_types:\n        return len({block.dtype for block in self._data.blocks}) == 1\n    else:\n        return not self._data.is_mixed_type",
                "def _repr_fits_vertical_(self) -> bool:\n    \"\"\"\n    Check length against max_rows.\n    \"\"\"\n    max_rows = get_option(\"display.max_rows\")\n    return len(self) <= max_rows",
                "def _repr_fits_horizontal_(self, ignore_width: bool = False) -> bool:\n    \"\"\"\n    Check if full repr fits in horizontal boundaries imposed by the display\n    options width and max_columns.\n\n    In case of non-interactive session, no boundaries apply.\n\n    `ignore_width` is here so ipnb+HTML output can behave the way\n    users expect. display.max_columns remains in effect.\n    GH3541, GH3573\n    \"\"\"\n    width, height = console.get_console_size()\n    max_columns = get_option(\"display.max_columns\")\n    nb_columns = len(self.columns)\n\n    # exceed max columns\n    if (max_columns and nb_columns > max_columns) or (\n        (not ignore_width) and width and nb_columns > (width // 2)\n    ):\n        return False\n\n    # used by repr_html under IPython notebook or scripts ignore terminal\n    # dims\n    if ignore_width or not console.in_interactive_session():\n        return True\n\n    if get_option(\"display.width\") is not None or console.in_ipython_frontend():\n        # check at least the column row for excessive width\n        max_rows = 1\n    else:\n        max_rows = get_option(\"display.max_rows\")\n\n    # when auto-detecting, so width=None and not in ipython front end\n    # check whether repr fits horizontal by actually checking\n    # the width of the rendered repr\n    buf = StringIO()\n\n    # only care about the stuff we'll actually print out\n    # and to_string on entire frame may be expensive\n    d = self\n\n    if not (max_rows is None):  # unlimited rows\n        # min of two, where one may be None\n        d = d.iloc[: min(max_rows, len(d))]\n    else:\n        return True\n\n    d.to_string(buf=buf)\n    value = buf.getvalue()\n    repr_width = max(len(l) for l in value.split(\"\\n\"))\n\n    return repr_width < width",
                "def _info_repr(self) -> bool:\n    \"\"\"\n    True if the repr should show the info view.\n    \"\"\"\n    info_repr_option = get_option(\"display.large_repr\") == \"info\"\n    return info_repr_option and not (\n        self._repr_fits_horizontal_() and self._repr_fits_vertical_()\n    )",
                "def __repr__(self) -> str:\n    \"\"\"\n    Return a string representation for a particular DataFrame.\n    \"\"\"\n    buf = StringIO(\"\")\n    if self._info_repr():\n        self.info(buf=buf)\n        return buf.getvalue()\n\n    max_rows = get_option(\"display.max_rows\")\n    min_rows = get_option(\"display.min_rows\")\n    max_cols = get_option(\"display.max_columns\")\n    max_colwidth = get_option(\"display.max_colwidth\")\n    show_dimensions = get_option(\"display.show_dimensions\")\n    if get_option(\"display.expand_frame_repr\"):\n        width, _ = console.get_console_size()\n    else:\n        width = None\n    self.to_string(\n        buf=buf,\n        max_rows=max_rows,\n        min_rows=min_rows,\n        max_cols=max_cols,\n        line_width=width,\n        max_colwidth=max_colwidth,\n        show_dimensions=show_dimensions,\n    )\n\n    return buf.getvalue()",
                "def _repr_html_(self) -> Optional[str]:\n    \"\"\"\n    Return a html representation for a particular DataFrame.\n\n    Mainly for IPython notebook.\n    \"\"\"\n    if self._info_repr():\n        buf = StringIO(\"\")\n        self.info(buf=buf)\n        # need to escape the <class>, should be the first line.\n        val = buf.getvalue().replace(\"<\", r\"&lt;\", 1)\n        val = val.replace(\">\", r\"&gt;\", 1)\n        return \"<pre>\" + val + \"</pre>\"\n\n    if get_option(\"display.notebook_repr_html\"):\n        max_rows = get_option(\"display.max_rows\")\n        min_rows = get_option(\"display.min_rows\")\n        max_cols = get_option(\"display.max_columns\")\n        show_dimensions = get_option(\"display.show_dimensions\")\n\n        formatter = fmt.DataFrameFormatter(\n            self,\n            columns=None,\n            col_space=None,\n            na_rep=\"NaN\",\n            formatters=None,\n            float_format=None,\n            sparsify=None,\n            justify=None,\n            index_names=True,\n            header=True,\n            index=True,\n            bold_rows=True,\n            escape=True,\n            max_rows=max_rows,\n            min_rows=min_rows,\n            max_cols=max_cols,\n            show_dimensions=show_dimensions,\n            decimal=\".\",\n            table_id=None,\n            render_links=False,\n        )\n        return formatter.to_html(notebook=True)\n    else:\n        return None",
                "@Substitution(\n    header_type=\"bool or sequence\",\n    header=\"Write out the column names. If a list of strings \"\n    \"is given, it is assumed to be aliases for the \"\n    \"column names\",\n    col_space_type=\"int\",\n    col_space=\"The minimum width of each column\",\n)\n@Substitution(shared_params=fmt.common_docstring, returns=fmt.return_docstring)\ndef to_string(\n    self,\n    buf: Optional[FilePathOrBuffer[str]] = None,\n    columns: Optional[Sequence[str]] = None,\n    col_space: Optional[int] = None,\n    header: Union[bool, Sequence[str]] = True,\n    index: bool = True,\n    na_rep: str = \"NaN\",\n    formatters: Optional[fmt.FormattersType] = None,\n    float_format: Optional[fmt.FloatFormatType] = None,\n    sparsify: Optional[bool] = None,\n    index_names: bool = True,\n    justify: Optional[str] = None,\n    max_rows: Optional[int] = None,\n    min_rows: Optional[int] = None,\n    max_cols: Optional[int] = None,\n    show_dimensions: bool = False,\n    decimal: str = \".\",\n    line_width: Optional[int] = None,\n    max_colwidth: Optional[int] = None,\n    encoding: Optional[str] = None,\n) -> Optional[str]:\n    \"\"\"\n    Render a DataFrame to a console-friendly tabular output.\n    %(shared_params)s\n    line_width : int, optional\n        Width to wrap a line in characters.\n    max_colwidth : int, optional\n        Max width to truncate each column in characters. By default, no limit.\n\n        .. versionadded:: 1.0.0\n    encoding : str, default \"utf-8\"\n        Set character encoding.\n\n        .. versionadded:: 1.0\n    %(returns)s\n    See Also\n    --------\n    to_html : Convert DataFrame to HTML.\n\n    Examples\n    --------\n    >>> d = {'col1': [1, 2, 3], 'col2': [4, 5, 6]}\n    >>> df = pd.DataFrame(d)\n    >>> print(df.to_string())\n       col1  col2\n    0     1     4\n    1     2     5\n    2     3     6\n    \"\"\"\n    from pandas import option_context\n\n    with option_context(\"display.max_colwidth\", max_colwidth):\n        formatter = fmt.DataFrameFormatter(\n            self,\n            columns=columns,\n            col_space=col_space,\n            na_rep=na_rep,\n            formatters=formatters,\n            float_format=float_format,\n            sparsify=sparsify,\n            justify=justify,\n            index_names=index_names,\n            header=header,\n            index=index,\n            min_rows=min_rows,\n            max_rows=max_rows,\n            max_cols=max_cols,\n            show_dimensions=show_dimensions,\n            decimal=decimal,\n            line_width=line_width,\n        )\n        return formatter.to_string(buf=buf, encoding=encoding)",
                "@property\ndef style(self) -> \"Styler\":\n    \"\"\"\n    Returns a Styler object.\n\n    Contains methods for building a styled HTML representation of the DataFrame.\n\n    See Also\n    --------\n    io.formats.style.Styler\n    \"\"\"\n    from pandas.io.formats.style import Styler\n\n    return Styler(self)",
                "@Appender(_shared_docs[\"items\"])\ndef items(self) -> Iterable[Tuple[Label, Series]]:\n    if self.columns.is_unique and hasattr(self, \"_item_cache\"):\n        for k in self.columns:\n            yield k, self._get_item_cache(k)\n    else:\n        for i, k in enumerate(self.columns):\n            yield k, self._ixs(i, axis=1)",
                "@Appender(_shared_docs[\"items\"])\ndef iteritems(self) -> Iterable[Tuple[Label, Series]]:\n    yield from self.items()",
                "def iterrows(self) -> Iterable[Tuple[Label, Series]]:\n    \"\"\"\n    Iterate over DataFrame rows as (index, Series) pairs.\n\n    Yields\n    ------\n    index : label or tuple of label\n        The index of the row. A tuple for a `MultiIndex`.\n    data : Series\n        The data of the row as a Series.\n\n    it : generator\n        A generator that iterates over the rows of the frame.\n\n    See Also\n    --------\n    DataFrame.itertuples : Iterate over DataFrame rows as namedtuples of the values.\n    DataFrame.items : Iterate over (column name, Series) pairs.\n\n    Notes\n    -----\n    1. Because ``iterrows`` returns a Series for each row,\n       it does **not** preserve dtypes across the rows (dtypes are\n       preserved across columns for DataFrames). For example,\n\n       >>> df = pd.DataFrame([[1, 1.5]], columns=['int', 'float'])\n       >>> row = next(df.iterrows())[1]\n       >>> row\n       int      1.0\n       float    1.5\n       Name: 0, dtype: float64\n       >>> print(row['int'].dtype)\n       float64\n       >>> print(df['int'].dtype)\n       int64\n\n       To preserve dtypes while iterating over the rows, it is better\n       to use :meth:`itertuples` which returns namedtuples of the values\n       and which is generally faster than ``iterrows``.\n\n    2. You should **never modify** something you are iterating over.\n       This is not guaranteed to work in all cases. Depending on the\n       data types, the iterator returns a copy and not a view, and writing\n       to it will have no effect.\n    \"\"\"\n    columns = self.columns\n    klass = self._constructor_sliced\n    for k, v in zip(self.index, self.values):\n        s = klass(v, index=columns, name=k)\n        yield k, s",
                "def itertuples(self, index=True, name=\"Pandas\"):\n    \"\"\"\n    Iterate over DataFrame rows as namedtuples.\n\n    Parameters\n    ----------\n    index : bool, default True\n        If True, return the index as the first element of the tuple.\n    name : str or None, default \"Pandas\"\n        The name of the returned namedtuples or None to return regular\n        tuples.\n\n    Returns\n    -------\n    iterator\n        An object to iterate over namedtuples for each row in the\n        DataFrame with the first field possibly being the index and\n        following fields being the column values.\n\n    See Also\n    --------\n    DataFrame.iterrows : Iterate over DataFrame rows as (index, Series)\n        pairs.\n    DataFrame.items : Iterate over (column name, Series) pairs.\n\n    Notes\n    -----\n    The column names will be renamed to positional names if they are\n    invalid Python identifiers, repeated, or start with an underscore.\n    On python versions < 3.7 regular tuples are returned for DataFrames\n    with a large number of columns (>254).\n\n    Examples\n    --------\n    >>> df = pd.DataFrame({'num_legs': [4, 2], 'num_wings': [0, 2]},\n    ...                   index=['dog', 'hawk'])\n    >>> df\n          num_legs  num_wings\n    dog          4          0\n    hawk         2          2\n    >>> for row in df.itertuples():\n    ...     print(row)\n    ...\n    Pandas(Index='dog', num_legs=4, num_wings=0)\n    Pandas(Index='hawk', num_legs=2, num_wings=2)\n\n    By setting the `index` parameter to False we can remove the index\n    as the first element of the tuple:\n\n    >>> for row in df.itertuples(index=False):\n    ...     print(row)\n    ...\n    Pandas(num_legs=4, num_wings=0)\n    Pandas(num_legs=2, num_wings=2)\n\n    With the `name` parameter set we set a custom name for the yielded\n    namedtuples:\n\n    >>> for row in df.itertuples(name='Animal'):\n    ...     print(row)\n    ...\n    Animal(Index='dog', num_legs=4, num_wings=0)\n    Animal(Index='hawk', num_legs=2, num_wings=2)\n    \"\"\"\n    arrays = []\n    fields = list(self.columns)\n    if index:\n        arrays.append(self.index)\n        fields.insert(0, \"Index\")\n\n    # use integer indexing because of possible duplicate column names\n    arrays.extend(self.iloc[:, k] for k in range(len(self.columns)))\n\n    # Python versions before 3.7 support at most 255 arguments to constructors\n    can_return_named_tuples = PY37 or len(self.columns) + index < 255\n    if name is not None and can_return_named_tuples:\n        itertuple = collections.namedtuple(name, fields, rename=True)\n        return map(itertuple._make, zip(*arrays))\n\n    # fallback to regular tuples\n    return zip(*arrays)",
                "def __len__(self) -> int:\n    \"\"\"\n    Returns length of info axis, but here we use the index.\n    \"\"\"\n    return len(self.index)",
                "def dot(self, other):\n    \"\"\"\n    Compute the matrix multiplication between the DataFrame and other.\n\n    This method computes the matrix product between the DataFrame and the\n    values of an other Series, DataFrame or a numpy array.\n\n    It can also be called using ``self @ other`` in Python >= 3.5.\n\n    Parameters\n    ----------\n    other : Series, DataFrame or array-like\n        The other object to compute the matrix product with.\n\n    Returns\n    -------\n    Series or DataFrame\n        If other is a Series, return the matrix product between self and\n        other as a Serie. If other is a DataFrame or a numpy.array, return\n        the matrix product of self and other in a DataFrame of a np.array.\n\n    See Also\n    --------\n    Series.dot: Similar method for Series.\n\n    Notes\n    -----\n    The dimensions of DataFrame and other must be compatible in order to\n    compute the matrix multiplication. In addition, the column names of\n    DataFrame and the index of other must contain the same values, as they\n    will be aligned prior to the multiplication.\n\n    The dot method for Series computes the inner product, instead of the\n    matrix product here.\n\n    Examples\n    --------\n    Here we multiply a DataFrame with a Series.\n\n    >>> df = pd.DataFrame([[0, 1, -2, -1], [1, 1, 1, 1]])\n    >>> s = pd.Series([1, 1, 2, 1])\n    >>> df.dot(s)\n    0    -4\n    1     5\n    dtype: int64\n\n    Here we multiply a DataFrame with another DataFrame.\n\n    >>> other = pd.DataFrame([[0, 1], [1, 2], [-1, -1], [2, 0]])\n    >>> df.dot(other)\n        0   1\n    0   1   4\n    1   2   2\n\n    Note that the dot method give the same result as @\n\n    >>> df @ other\n        0   1\n    0   1   4\n    1   2   2\n\n    The dot method works also if other is an np.array.\n\n    >>> arr = np.array([[0, 1], [1, 2], [-1, -1], [2, 0]])\n    >>> df.dot(arr)\n        0   1\n    0   1   4\n    1   2   2\n\n    Note how shuffling of the objects does not change the result.\n\n    >>> s2 = s.reindex([1, 0, 2, 3])\n    >>> df.dot(s2)\n    0    -4\n    1     5\n    dtype: int64\n    \"\"\"\n    if isinstance(other, (Series, DataFrame)):\n        common = self.columns.union(other.index)\n        if len(common) > len(self.columns) or len(common) > len(other.index):\n            raise ValueError(\"matrices are not aligned\")\n\n        left = self.reindex(columns=common, copy=False)\n        right = other.reindex(index=common, copy=False)\n        lvals = left.values\n        rvals = right.values\n    else:\n        left = self\n        lvals = self.values\n        rvals = np.asarray(other)\n        if lvals.shape[1] != rvals.shape[0]:\n            raise ValueError(\n                f\"Dot product shape mismatch, {lvals.shape} vs {rvals.shape}\"\n            )\n\n    if isinstance(other, DataFrame):\n        return self._constructor(\n            np.dot(lvals, rvals), index=left.index, columns=other.columns\n        )\n    elif isinstance(other, Series):\n        return Series(np.dot(lvals, rvals), index=left.index)\n    elif isinstance(rvals, (np.ndarray, Index)):\n        result = np.dot(lvals, rvals)\n        if result.ndim == 2:\n            return self._constructor(result, index=left.index)\n        else:\n            return Series(result, index=left.index)\n    else:  # pragma: no cover\n        raise TypeError(f\"unsupported type: {type(other)}\")",
                "def __matmul__(self, other):\n    \"\"\"\n    Matrix multiplication using binary `@` operator in Python>=3.5.\n    \"\"\"\n    return self.dot(other)",
                "def __rmatmul__(self, other):\n    \"\"\"\n    Matrix multiplication using binary `@` operator in Python>=3.5.\n    \"\"\"\n    return self.T.dot(np.transpose(other)).T",
                "@classmethod\ndef from_dict(cls, data, orient=\"columns\", dtype=None, columns=None) -> \"DataFrame\":\n    \"\"\"\n    Construct DataFrame from dict of array-like or dicts.\n\n    Creates DataFrame object from dictionary by columns or by index\n    allowing dtype specification.\n\n    Parameters\n    ----------\n    data : dict\n        Of the form {field : array-like} or {field : dict}.\n    orient : {'columns', 'index'}, default 'columns'\n        The \"orientation\" of the data. If the keys of the passed dict\n        should be the columns of the resulting DataFrame, pass 'columns'\n        (default). Otherwise if the keys should be rows, pass 'index'.\n    dtype : dtype, default None\n        Data type to force, otherwise infer.\n    columns : list, default None\n        Column labels to use when ``orient='index'``. Raises a ValueError\n        if used with ``orient='columns'``.\n\n        .. versionadded:: 0.23.0\n\n    Returns\n    -------\n    DataFrame\n\n    See Also\n    --------\n    DataFrame.from_records : DataFrame from ndarray (structured\n        dtype), list of tuples, dict, or DataFrame.\n    DataFrame : DataFrame object creation using constructor.\n\n    Examples\n    --------\n    By default the keys of the dict become the DataFrame columns:\n\n    >>> data = {'col_1': [3, 2, 1, 0], 'col_2': ['a', 'b', 'c', 'd']}\n    >>> pd.DataFrame.from_dict(data)\n       col_1 col_2\n    0      3     a\n    1      2     b\n    2      1     c\n    3      0     d\n\n    Specify ``orient='index'`` to create the DataFrame using dictionary\n    keys as rows:\n\n    >>> data = {'row_1': [3, 2, 1, 0], 'row_2': ['a', 'b', 'c', 'd']}\n    >>> pd.DataFrame.from_dict(data, orient='index')\n           0  1  2  3\n    row_1  3  2  1  0\n    row_2  a  b  c  d\n\n    When using the 'index' orientation, the column names can be\n    specified manually:\n\n    >>> pd.DataFrame.from_dict(data, orient='index',\n    ...                        columns=['A', 'B', 'C', 'D'])\n           A  B  C  D\n    row_1  3  2  1  0\n    row_2  a  b  c  d\n    \"\"\"\n    index = None\n    orient = orient.lower()\n    if orient == \"index\":\n        if len(data) > 0:\n            # TODO speed up Series case\n            if isinstance(list(data.values())[0], (Series, dict)):\n                data = _from_nested_dict(data)\n            else:\n                data, index = list(data.values()), list(data.keys())\n    elif orient == \"columns\":\n        if columns is not None:\n            raise ValueError(\"cannot use columns parameter with orient='columns'\")\n    else:  # pragma: no cover\n        raise ValueError(\"only recognize index or columns for orient\")\n\n    return cls(data, index=index, columns=columns, dtype=dtype)",
                "def to_numpy(self, dtype=None, copy=False) -> np.ndarray:\n    \"\"\"\n    Convert the DataFrame to a NumPy array.\n\n    .. versionadded:: 0.24.0\n\n    By default, the dtype of the returned array will be the common NumPy\n    dtype of all types in the DataFrame. For example, if the dtypes are\n    ``float16`` and ``float32``, the results dtype will be ``float32``.\n    This may require copying data and coercing values, which may be\n    expensive.\n\n    Parameters\n    ----------\n    dtype : str or numpy.dtype, optional\n        The dtype to pass to :meth:`numpy.asarray`.\n    copy : bool, default False\n        Whether to ensure that the returned value is a not a view on\n        another array. Note that ``copy=False`` does not *ensure* that\n        ``to_numpy()`` is no-copy. Rather, ``copy=True`` ensure that\n        a copy is made, even if not strictly necessary.\n\n    Returns\n    -------\n    numpy.ndarray\n\n    See Also\n    --------\n    Series.to_numpy : Similar method for Series.\n\n    Examples\n    --------\n    >>> pd.DataFrame({\"A\": [1, 2], \"B\": [3, 4]}).to_numpy()\n    array([[1, 3],\n           [2, 4]])\n\n    With heterogeneous data, the lowest common type will have to\n    be used.\n\n    >>> df = pd.DataFrame({\"A\": [1, 2], \"B\": [3.0, 4.5]})\n    >>> df.to_numpy()\n    array([[1. , 3. ],\n           [2. , 4.5]])\n\n    For a mix of numeric and non-numeric types, the output array will\n    have object dtype.\n\n    >>> df['C'] = pd.date_range('2000', periods=2)\n    >>> df.to_numpy()\n    array([[1, 3.0, Timestamp('2000-01-01 00:00:00')],\n           [2, 4.5, Timestamp('2000-01-02 00:00:00')]], dtype=object)\n    \"\"\"\n    result = np.array(self.values, dtype=dtype, copy=copy)\n    return result",
                "def to_dict(self, orient=\"dict\", into=dict):\n    \"\"\"\n    Convert the DataFrame to a dictionary.\n\n    The type of the key-value pairs can be customized with the parameters\n    (see below).\n\n    Parameters\n    ----------\n    orient : str {'dict', 'list', 'series', 'split', 'records', 'index'}\n        Determines the type of the values of the dictionary.\n\n        - 'dict' (default) : dict like {column -> {index -> value}}\n        - 'list' : dict like {column -> [values]}\n        - 'series' : dict like {column -> Series(values)}\n        - 'split' : dict like\n          {'index' -> [index], 'columns' -> [columns], 'data' -> [values]}\n        - 'records' : list like\n          [{column -> value}, ... , {column -> value}]\n        - 'index' : dict like {index -> {column -> value}}\n\n        Abbreviations are allowed. `s` indicates `series` and `sp`\n        indicates `split`.\n\n    into : class, default dict\n        The collections.abc.Mapping subclass used for all Mappings\n        in the return value.  Can be the actual class or an empty\n        instance of the mapping type you want.  If you want a\n        collections.defaultdict, you must pass it initialized.\n\n        .. versionadded:: 0.21.0\n\n    Returns\n    -------\n    dict, list or collections.abc.Mapping\n        Return a collections.abc.Mapping object representing the DataFrame.\n        The resulting transformation depends on the `orient` parameter.\n\n    See Also\n    --------\n    DataFrame.from_dict: Create a DataFrame from a dictionary.\n    DataFrame.to_json: Convert a DataFrame to JSON format.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame({'col1': [1, 2],\n    ...                    'col2': [0.5, 0.75]},\n    ...                   index=['row1', 'row2'])\n    >>> df\n          col1  col2\n    row1     1  0.50\n    row2     2  0.75\n    >>> df.to_dict()\n    {'col1': {'row1': 1, 'row2': 2}, 'col2': {'row1': 0.5, 'row2': 0.75}}\n\n    You can specify the return orientation.\n\n    >>> df.to_dict('series')\n    {'col1': row1    1\n             row2    2\n    Name: col1, dtype: int64,\n    'col2': row1    0.50\n            row2    0.75\n    Name: col2, dtype: float64}\n\n    >>> df.to_dict('split')\n    {'index': ['row1', 'row2'], 'columns': ['col1', 'col2'],\n     'data': [[1, 0.5], [2, 0.75]]}\n\n    >>> df.to_dict('records')\n    [{'col1': 1, 'col2': 0.5}, {'col1': 2, 'col2': 0.75}]\n\n    >>> df.to_dict('index')\n    {'row1': {'col1': 1, 'col2': 0.5}, 'row2': {'col1': 2, 'col2': 0.75}}\n\n    You can also specify the mapping type.\n\n    >>> from collections import OrderedDict, defaultdict\n    >>> df.to_dict(into=OrderedDict)\n    OrderedDict([('col1', OrderedDict([('row1', 1), ('row2', 2)])),\n                 ('col2', OrderedDict([('row1', 0.5), ('row2', 0.75)]))])\n\n    If you want a `defaultdict`, you need to initialize it:\n\n    >>> dd = defaultdict(list)\n    >>> df.to_dict('records', into=dd)\n    [defaultdict(<class 'list'>, {'col1': 1, 'col2': 0.5}),\n     defaultdict(<class 'list'>, {'col1': 2, 'col2': 0.75})]\n    \"\"\"\n    if not self.columns.is_unique:\n        warnings.warn(\n            \"DataFrame columns are not unique, some columns will be omitted.\",\n            UserWarning,\n            stacklevel=2,\n        )\n    # GH16122\n    into_c = com.standardize_mapping(into)\n    if orient.lower().startswith(\"d\"):\n        return into_c((k, v.to_dict(into)) for k, v in self.items())\n    elif orient.lower().startswith(\"l\"):\n        return into_c((k, v.tolist()) for k, v in self.items())\n    elif orient.lower().startswith(\"sp\"):\n        return into_c(\n            (\n                (\"index\", self.index.tolist()),\n                (\"columns\", self.columns.tolist()),\n                (\n                    \"data\",\n                    [\n                        list(map(com.maybe_box_datetimelike, t))\n                        for t in self.itertuples(index=False, name=None)\n                    ],\n                ),\n            )\n        )\n    elif orient.lower().startswith(\"s\"):\n        return into_c((k, com.maybe_box_datetimelike(v)) for k, v in self.items())\n    elif orient.lower().startswith(\"r\"):\n        columns = self.columns.tolist()\n        rows = (\n            dict(zip(columns, row))\n            for row in self.itertuples(index=False, name=None)\n        )\n        return [\n            into_c((k, com.maybe_box_datetimelike(v)) for k, v in row.items())\n            for row in rows\n        ]\n    elif orient.lower().startswith(\"i\"):\n        if not self.index.is_unique:\n            raise ValueError(\"DataFrame index must be unique for orient='index'.\")\n        return into_c(\n            (t[0], dict(zip(self.columns, t[1:])))\n            for t in self.itertuples(name=None)\n        )\n    else:\n        raise ValueError(f\"orient '{orient}' not understood\")",
                "def to_gbq(\n    self,\n    destination_table,\n    project_id=None,\n    chunksize=None,\n    reauth=False,\n    if_exists=\"fail\",\n    auth_local_webserver=False,\n    table_schema=None,\n    location=None,\n    progress_bar=True,\n    credentials=None,\n) -> None:\n    \"\"\"\n    Write a DataFrame to a Google BigQuery table.\n\n    This function requires the `pandas-gbq package\n    <https://pandas-gbq.readthedocs.io>`__.\n\n    See the `How to authenticate with Google BigQuery\n    <https://pandas-gbq.readthedocs.io/en/latest/howto/authentication.html>`__\n    guide for authentication instructions.\n\n    Parameters\n    ----------\n    destination_table : str\n        Name of table to be written, in the form ``dataset.tablename``.\n    project_id : str, optional\n        Google BigQuery Account project ID. Optional when available from\n        the environment.\n    chunksize : int, optional\n        Number of rows to be inserted in each chunk from the dataframe.\n        Set to ``None`` to load the whole dataframe at once.\n    reauth : bool, default False\n        Force Google BigQuery to re-authenticate the user. This is useful\n        if multiple accounts are used.\n    if_exists : str, default 'fail'\n        Behavior when the destination table exists. Value can be one of:\n\n        ``'fail'``\n            If table exists raise pandas_gbq.gbq.TableCreationError.\n        ``'replace'``\n            If table exists, drop it, recreate it, and insert data.\n        ``'append'``\n            If table exists, insert data. Create if does not exist.\n    auth_local_webserver : bool, default False\n        Use the `local webserver flow`_ instead of the `console flow`_\n        when getting user credentials.\n\n        .. _local webserver flow:\n            https://google-auth-oauthlib.readthedocs.io/en/latest/reference/google_auth_oauthlib.flow.html#google_auth_oauthlib.flow.InstalledAppFlow.run_local_server\n        .. _console flow:\n            https://google-auth-oauthlib.readthedocs.io/en/latest/reference/google_auth_oauthlib.flow.html#google_auth_oauthlib.flow.InstalledAppFlow.run_console\n\n        *New in version 0.2.0 of pandas-gbq*.\n    table_schema : list of dicts, optional\n        List of BigQuery table fields to which according DataFrame\n        columns conform to, e.g. ``[{'name': 'col1', 'type':\n        'STRING'},...]``. If schema is not provided, it will be\n        generated according to dtypes of DataFrame columns. See\n        BigQuery API documentation on available names of a field.\n\n        *New in version 0.3.1 of pandas-gbq*.\n    location : str, optional\n        Location where the load job should run. See the `BigQuery locations\n        documentation\n        <https://cloud.google.com/bigquery/docs/dataset-locations>`__ for a\n        list of available locations. The location must match that of the\n        target dataset.\n\n        *New in version 0.5.0 of pandas-gbq*.\n    progress_bar : bool, default True\n        Use the library `tqdm` to show the progress bar for the upload,\n        chunk by chunk.\n\n        *New in version 0.5.0 of pandas-gbq*.\n    credentials : google.auth.credentials.Credentials, optional\n        Credentials for accessing Google APIs. Use this parameter to\n        override default credentials, such as to use Compute Engine\n        :class:`google.auth.compute_engine.Credentials` or Service\n        Account :class:`google.oauth2.service_account.Credentials`\n        directly.\n\n        *New in version 0.8.0 of pandas-gbq*.\n\n        .. versionadded:: 0.24.0\n\n    See Also\n    --------\n    pandas_gbq.to_gbq : This function in the pandas-gbq library.\n    read_gbq : Read a DataFrame from Google BigQuery.\n    \"\"\"\n    from pandas.io import gbq\n\n    gbq.to_gbq(\n        self,\n        destination_table,\n        project_id=project_id,\n        chunksize=chunksize,\n        reauth=reauth,\n        if_exists=if_exists,\n        auth_local_webserver=auth_local_webserver,\n        table_schema=table_schema,\n        location=location,\n        progress_bar=progress_bar,\n        credentials=credentials,\n    )",
                "@classmethod\ndef from_records(\n    cls,\n    data,\n    index=None,\n    exclude=None,\n    columns=None,\n    coerce_float=False,\n    nrows=None,\n) -> \"DataFrame\":\n    \"\"\"\n    Convert structured or record ndarray to DataFrame.\n\n    Parameters\n    ----------\n    data : ndarray (structured dtype), list of tuples, dict, or DataFrame\n    index : str, list of fields, array-like\n        Field of array to use as the index, alternately a specific set of\n        input labels to use.\n    exclude : sequence, default None\n        Columns or fields to exclude.\n    columns : sequence, default None\n        Column names to use. If the passed data do not have names\n        associated with them, this argument provides names for the\n        columns. Otherwise this argument indicates the order of the columns\n        in the result (any names not found in the data will become all-NA\n        columns).\n    coerce_float : bool, default False\n        Attempt to convert values of non-string, non-numeric objects (like\n        decimal.Decimal) to floating point, useful for SQL result sets.\n    nrows : int, default None\n        Number of rows to read if data is an iterator.\n\n    Returns\n    -------\n    DataFrame\n    \"\"\"\n    # Make a copy of the input columns so we can modify it\n    if columns is not None:\n        columns = ensure_index(columns)\n\n    if is_iterator(data):\n        if nrows == 0:\n            return cls()\n\n        try:\n            first_row = next(data)\n        except StopIteration:\n            return cls(index=index, columns=columns)\n\n        dtype = None\n        if hasattr(first_row, \"dtype\") and first_row.dtype.names:\n            dtype = first_row.dtype\n\n        values = [first_row]\n\n        if nrows is None:\n            values += data\n        else:\n            values.extend(itertools.islice(data, nrows - 1))\n\n        if dtype is not None:\n            data = np.array(values, dtype=dtype)\n        else:\n            data = values\n\n    if isinstance(data, dict):\n        if columns is None:\n            columns = arr_columns = ensure_index(sorted(data))\n            arrays = [data[k] for k in columns]\n        else:\n            arrays = []\n            arr_columns = []\n            for k, v in data.items():\n                if k in columns:\n                    arr_columns.append(k)\n                    arrays.append(v)\n\n            arrays, arr_columns = reorder_arrays(arrays, arr_columns, columns)\n\n    elif isinstance(data, (np.ndarray, DataFrame)):\n        arrays, columns = to_arrays(data, columns)\n        if columns is not None:\n            columns = ensure_index(columns)\n        arr_columns = columns\n    else:\n        arrays, arr_columns = to_arrays(data, columns, coerce_float=coerce_float)\n\n        arr_columns = ensure_index(arr_columns)\n        if columns is not None:\n            columns = ensure_index(columns)\n        else:\n            columns = arr_columns\n\n    if exclude is None:\n        exclude = set()\n    else:\n        exclude = set(exclude)\n\n    result_index = None\n    if index is not None:\n        if isinstance(index, str) or not hasattr(index, \"__iter__\"):\n            i = columns.get_loc(index)\n            exclude.add(index)\n            if len(arrays) > 0:\n                result_index = Index(arrays[i], name=index)\n            else:\n                result_index = Index([], name=index)\n        else:\n            try:\n                index_data = [arrays[arr_columns.get_loc(field)] for field in index]\n            except (KeyError, TypeError):\n                # raised by get_loc, see GH#29258\n                result_index = index\n            else:\n                result_index = ensure_index_from_sequences(index_data, names=index)\n                exclude.update(index)\n\n    if any(exclude):\n        arr_exclude = [x for x in exclude if x in arr_columns]\n        to_remove = [arr_columns.get_loc(col) for col in arr_exclude]\n        arrays = [v for i, v in enumerate(arrays) if i not in to_remove]\n\n        arr_columns = arr_columns.drop(arr_exclude)\n        columns = columns.drop(exclude)\n\n    mgr = arrays_to_mgr(arrays, arr_columns, result_index, columns)\n\n    return cls(mgr)",
                "def to_records(\n    self, index=True, column_dtypes=None, index_dtypes=None\n) -> np.recarray:\n    \"\"\"\n    Convert DataFrame to a NumPy record array.\n\n    Index will be included as the first field of the record array if\n    requested.\n\n    Parameters\n    ----------\n    index : bool, default True\n        Include index in resulting record array, stored in 'index'\n        field or using the index label, if set.\n    column_dtypes : str, type, dict, default None\n        .. versionadded:: 0.24.0\n\n        If a string or type, the data type to store all columns. If\n        a dictionary, a mapping of column names and indices (zero-indexed)\n        to specific data types.\n    index_dtypes : str, type, dict, default None\n        .. versionadded:: 0.24.0\n\n        If a string or type, the data type to store all index levels. If\n        a dictionary, a mapping of index level names and indices\n        (zero-indexed) to specific data types.\n\n        This mapping is applied only if `index=True`.\n\n    Returns\n    -------\n    numpy.recarray\n        NumPy ndarray with the DataFrame labels as fields and each row\n        of the DataFrame as entries.\n\n    See Also\n    --------\n    DataFrame.from_records: Convert structured or record ndarray\n        to DataFrame.\n    numpy.recarray: An ndarray that allows field access using\n        attributes, analogous to typed columns in a\n        spreadsheet.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame({'A': [1, 2], 'B': [0.5, 0.75]},\n    ...                   index=['a', 'b'])\n    >>> df\n       A     B\n    a  1  0.50\n    b  2  0.75\n    >>> df.to_records()\n    rec.array([('a', 1, 0.5 ), ('b', 2, 0.75)],\n              dtype=[('index', 'O'), ('A', '<i8'), ('B', '<f8')])\n\n    If the DataFrame index has no label then the recarray field name\n    is set to 'index'. If the index has a label then this is used as the\n    field name:\n\n    >>> df.index = df.index.rename(\"I\")\n    >>> df.to_records()\n    rec.array([('a', 1, 0.5 ), ('b', 2, 0.75)],\n              dtype=[('I', 'O'), ('A', '<i8'), ('B', '<f8')])\n\n    The index can be excluded from the record array:\n\n    >>> df.to_records(index=False)\n    rec.array([(1, 0.5 ), (2, 0.75)],\n              dtype=[('A', '<i8'), ('B', '<f8')])\n\n    Data types can be specified for the columns:\n\n    >>> df.to_records(column_dtypes={\"A\": \"int32\"})\n    rec.array([('a', 1, 0.5 ), ('b', 2, 0.75)],\n              dtype=[('I', 'O'), ('A', '<i4'), ('B', '<f8')])\n\n    As well as for the index:\n\n    >>> df.to_records(index_dtypes=\"<S2\")\n    rec.array([(b'a', 1, 0.5 ), (b'b', 2, 0.75)],\n              dtype=[('I', 'S2'), ('A', '<i8'), ('B', '<f8')])\n\n    >>> index_dtypes = f\"<S{df.index.str.len().max()}\"\n    >>> df.to_records(index_dtypes=index_dtypes)\n    rec.array([(b'a', 1, 0.5 ), (b'b', 2, 0.75)],\n              dtype=[('I', 'S1'), ('A', '<i8'), ('B', '<f8')])\n    \"\"\"\n    if index:\n        if isinstance(self.index, ABCMultiIndex):\n            # array of tuples to numpy cols. copy copy copy\n            ix_vals = list(map(np.array, zip(*self.index.values)))\n        else:\n            ix_vals = [self.index.values]\n\n        arrays = ix_vals + [self[c]._internal_get_values() for c in self.columns]\n\n        count = 0\n        index_names = list(self.index.names)\n\n        if isinstance(self.index, ABCMultiIndex):\n            for i, n in enumerate(index_names):\n                if n is None:\n                    index_names[i] = f\"level_{count}\"\n                    count += 1\n        elif index_names[0] is None:\n            index_names = [\"index\"]\n\n        names = [str(name) for name in itertools.chain(index_names, self.columns)]\n    else:\n        arrays = [self[c]._internal_get_values() for c in self.columns]\n        names = [str(c) for c in self.columns]\n        index_names = []\n\n    index_len = len(index_names)\n    formats = []\n\n    for i, v in enumerate(arrays):\n        index = i\n\n        # When the names and arrays are collected, we\n        # first collect those in the DataFrame's index,\n        # followed by those in its columns.\n        #\n        # Thus, the total length of the array is:\n        # len(index_names) + len(DataFrame.columns).\n        #\n        # This check allows us to see whether we are\n        # handling a name / array in the index or column.\n        if index < index_len:\n            dtype_mapping = index_dtypes\n            name = index_names[index]\n        else:\n            index -= index_len\n            dtype_mapping = column_dtypes\n            name = self.columns[index]\n\n        # We have a dictionary, so we get the data type\n        # associated with the index or column (which can\n        # be denoted by its name in the DataFrame or its\n        # position in DataFrame's array of indices or\n        # columns, whichever is applicable.\n        if is_dict_like(dtype_mapping):\n            if name in dtype_mapping:\n                dtype_mapping = dtype_mapping[name]\n            elif index in dtype_mapping:\n                dtype_mapping = dtype_mapping[index]\n            else:\n                dtype_mapping = None\n\n        # If no mapping can be found, use the array's\n        # dtype attribute for formatting.\n        #\n        # A valid dtype must either be a type or\n        # string naming a type.\n        if dtype_mapping is None:\n            formats.append(v.dtype)\n        elif isinstance(dtype_mapping, (type, np.dtype, str)):\n            formats.append(dtype_mapping)\n        else:\n            element = \"row\" if i < index_len else \"column\"\n            msg = f\"Invalid dtype {dtype_mapping} specified for {element} {name}\"\n            raise ValueError(msg)\n\n    return np.rec.fromarrays(arrays, dtype={\"names\": names, \"formats\": formats})",
                "@classmethod\ndef _from_arrays(cls, arrays, columns, index, dtype=None) -> \"DataFrame\":\n    mgr = arrays_to_mgr(arrays, columns, index, columns, dtype=dtype)\n    return cls(mgr)",
                "@deprecate_kwarg(old_arg_name=\"fname\", new_arg_name=\"path\")\ndef to_stata(\n    self,\n    path: FilePathOrBuffer,\n    convert_dates: Optional[Dict[Label, str]] = None,\n    write_index: bool = True,\n    byteorder: Optional[str] = None,\n    time_stamp: Optional[datetime.datetime] = None,\n    data_label: Optional[str] = None,\n    variable_labels: Optional[Dict[Label, str]] = None,\n    version: Optional[int] = 114,\n    convert_strl: Optional[Sequence[Label]] = None,\n) -> None:\n    \"\"\"\n    Export DataFrame object to Stata dta format.\n\n    Writes the DataFrame to a Stata dataset file.\n    \"dta\" files contain a Stata dataset.\n\n    Parameters\n    ----------\n    path : str, buffer or path object\n        String, path object (pathlib.Path or py._path.local.LocalPath) or\n        object implementing a binary write() function. If using a buffer\n        then the buffer will not be automatically closed after the file\n        data has been written.\n\n        .. versionchanged:: 1.0.0\n\n        Previously this was \"fname\"\n\n    convert_dates : dict\n        Dictionary mapping columns containing datetime types to stata\n        internal format to use when writing the dates. Options are 'tc',\n        'td', 'tm', 'tw', 'th', 'tq', 'ty'. Column can be either an integer\n        or a name. Datetime columns that do not have a conversion type\n        specified will be converted to 'tc'. Raises NotImplementedError if\n        a datetime column has timezone information.\n    write_index : bool\n        Write the index to Stata dataset.\n    byteorder : str\n        Can be \">\", \"<\", \"little\", or \"big\". default is `sys.byteorder`.\n    time_stamp : datetime\n        A datetime to use as file creation date.  Default is the current\n        time.\n    data_label : str, optional\n        A label for the data set.  Must be 80 characters or smaller.\n    variable_labels : dict\n        Dictionary containing columns as keys and variable labels as\n        values. Each label must be 80 characters or smaller.\n    version : {114, 117, 118, 119, None}, default 114\n        Version to use in the output dta file. Set to None to let pandas\n        decide between 118 or 119 formats depending on the number of\n        columns in the frame. Version 114 can be read by Stata 10 and\n        later. Version 117 can be read by Stata 13 or later. Version 118\n        is supported in Stata 14 and later. Version 119 is supported in\n        Stata 15 and later. Version 114 limits string variables to 244\n        characters or fewer while versions 117 and later allow strings\n        with lengths up to 2,000,000 characters. Versions 118 and 119\n        support Unicode characters, and version 119 supports more than\n        32,767 variables.\n\n        .. versionadded:: 0.23.0\n        .. versionchanged:: 1.0.0\n\n            Added support for formats 118 and 119.\n\n    convert_strl : list, optional\n        List of column names to convert to string columns to Stata StrL\n        format. Only available if version is 117.  Storing strings in the\n        StrL format can produce smaller dta files if strings have more than\n        8 characters and values are repeated.\n\n        .. versionadded:: 0.23.0\n\n    Raises\n    ------\n    NotImplementedError\n        * If datetimes contain timezone information\n        * Column dtype is not representable in Stata\n    ValueError\n        * Columns listed in convert_dates are neither datetime64[ns]\n          or datetime.datetime\n        * Column listed in convert_dates is not in DataFrame\n        * Categorical label contains more than 32,000 characters\n\n    See Also\n    --------\n    read_stata : Import Stata data files.\n    io.stata.StataWriter : Low-level writer for Stata data files.\n    io.stata.StataWriter117 : Low-level writer for version 117 files.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame({'animal': ['falcon', 'parrot', 'falcon',\n    ...                               'parrot'],\n    ...                    'speed': [350, 18, 361, 15]})\n    >>> df.to_stata('animals.dta')  # doctest: +SKIP\n    \"\"\"\n    if version not in (114, 117, 118, 119, None):\n        raise ValueError(\"Only formats 114, 117, 118 and 119 are supported.\")\n    if version == 114:\n        if convert_strl is not None:\n            raise ValueError(\"strl is not supported in format 114\")\n        from pandas.io.stata import StataWriter as statawriter\n    elif version == 117:\n        # mypy: Name 'statawriter' already defined (possibly by an import)\n        from pandas.io.stata import StataWriter117 as statawriter  # type: ignore\n    else:  # versions 118 and 119\n        # mypy: Name 'statawriter' already defined (possibly by an import)\n        from pandas.io.stata import StataWriterUTF8 as statawriter  # type:ignore\n\n    kwargs: Dict[str, Any] = {}\n    if version is None or version >= 117:\n        # strl conversion is only supported >= 117\n        kwargs[\"convert_strl\"] = convert_strl\n    if version is None or version >= 118:\n        # Specifying the version is only supported for UTF8 (118 or 119)\n        kwargs[\"version\"] = version\n\n    # mypy: Too many arguments for \"StataWriter\"\n    writer = statawriter(  # type: ignore\n        path,\n        self,\n        convert_dates=convert_dates,\n        byteorder=byteorder,\n        time_stamp=time_stamp,\n        data_label=data_label,\n        write_index=write_index,\n        variable_labels=variable_labels,\n        **kwargs,\n    )\n    writer.write_file()",
                "@deprecate_kwarg(old_arg_name=\"fname\", new_arg_name=\"path\")\ndef to_feather(self, path) -> None:\n    \"\"\"\n    Write out the binary feather-format for DataFrames.\n\n    Parameters\n    ----------\n    path : str\n        String file path.\n    \"\"\"\n    from pandas.io.feather_format import to_feather\n\n    to_feather(self, path)",
                "@Appender(\n    \"\"\"\n    Examples\n    --------\n    >>> df = pd.DataFrame(\n    ...     data={\"animal_1\": [\"elk\", \"pig\"], \"animal_2\": [\"dog\", \"quetzal\"]}\n    ... )\n    >>> print(df.to_markdown())\n    |    | animal_1   | animal_2   |\n    |---:|:-----------|:-----------|\n    |  0 | elk        | dog        |\n    |  1 | pig        | quetzal    |\n    \"\"\"\n)\n@Substitution(klass=\"DataFrame\")\n@Appender(_shared_docs[\"to_markdown\"])\ndef to_markdown(\n    self, buf: Optional[IO[str]] = None, mode: Optional[str] = None, **kwargs\n) -> Optional[str]:\n    kwargs.setdefault(\"headers\", \"keys\")\n    kwargs.setdefault(\"tablefmt\", \"pipe\")\n    tabulate = import_optional_dependency(\"tabulate\")\n    result = tabulate.tabulate(self, **kwargs)\n    if buf is None:\n        return result\n    buf, _, _, _ = get_filepath_or_buffer(buf, mode=mode)\n    assert buf is not None  # Help mypy.\n    buf.writelines(result)\n    return None",
                "@deprecate_kwarg(old_arg_name=\"fname\", new_arg_name=\"path\")\ndef to_parquet(\n    self,\n    path,\n    engine=\"auto\",\n    compression=\"snappy\",\n    index=None,\n    partition_cols=None,\n    **kwargs,\n) -> None:\n    \"\"\"\n    Write a DataFrame to the binary parquet format.\n\n    .. versionadded:: 0.21.0\n\n    This function writes the dataframe as a `parquet file\n    <https://parquet.apache.org/>`_. You can choose different parquet\n    backends, and have the option of compression. See\n    :ref:`the user guide <io.parquet>` for more details.\n\n    Parameters\n    ----------\n    path : str\n        File path or Root Directory path. Will be used as Root Directory\n        path while writing a partitioned dataset.\n\n        .. versionchanged:: 1.0.0\n\n        Previously this was \"fname\"\n\n    engine : {'auto', 'pyarrow', 'fastparquet'}, default 'auto'\n        Parquet library to use. If 'auto', then the option\n        ``io.parquet.engine`` is used. The default ``io.parquet.engine``\n        behavior is to try 'pyarrow', falling back to 'fastparquet' if\n        'pyarrow' is unavailable.\n    compression : {'snappy', 'gzip', 'brotli', None}, default 'snappy'\n        Name of the compression to use. Use ``None`` for no compression.\n    index : bool, default None\n        If ``True``, include the dataframe's index(es) in the file output.\n        If ``False``, they will not be written to the file.\n        If ``None``, similar to ``True`` the dataframe's index(es)\n        will be saved. However, instead of being saved as values,\n        the RangeIndex will be stored as a range in the metadata so it\n        doesn't require much space and is faster. Other indexes will\n        be included as columns in the file output.\n\n        .. versionadded:: 0.24.0\n\n    partition_cols : list, optional, default None\n        Column names by which to partition the dataset.\n        Columns are partitioned in the order they are given.\n\n        .. versionadded:: 0.24.0\n\n    **kwargs\n        Additional arguments passed to the parquet library. See\n        :ref:`pandas io <io.parquet>` for more details.\n\n    See Also\n    --------\n    read_parquet : Read a parquet file.\n    DataFrame.to_csv : Write a csv file.\n    DataFrame.to_sql : Write to a sql table.\n    DataFrame.to_hdf : Write to hdf.\n\n    Notes\n    -----\n    This function requires either the `fastparquet\n    <https://pypi.org/project/fastparquet>`_ or `pyarrow\n    <https://arrow.apache.org/docs/python/>`_ library.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame(data={'col1': [1, 2], 'col2': [3, 4]})\n    >>> df.to_parquet('df.parquet.gzip',\n    ...               compression='gzip')  # doctest: +SKIP\n    >>> pd.read_parquet('df.parquet.gzip')  # doctest: +SKIP\n       col1  col2\n    0     1     3\n    1     2     4\n    \"\"\"\n    from pandas.io.parquet import to_parquet\n\n    to_parquet(\n        self,\n        path,\n        engine,\n        compression=compression,\n        index=index,\n        partition_cols=partition_cols,\n        **kwargs,\n    )",
                "@Substitution(\n    header_type=\"bool\",\n    header=\"Whether to print column labels, default True\",\n    col_space_type=\"str or int\",\n    col_space=\"The minimum width of each column in CSS length \"\n    \"units.  An int is assumed to be px units.\\n\\n\"\n    \"            .. versionadded:: 0.25.0\\n\"\n    \"                Ability to use str\",\n)\n@Substitution(shared_params=fmt.common_docstring, returns=fmt.return_docstring)\ndef to_html(\n    self,\n    buf=None,\n    columns=None,\n    col_space=None,\n    header=True,\n    index=True,\n    na_rep=\"NaN\",\n    formatters=None,\n    float_format=None,\n    sparsify=None,\n    index_names=True,\n    justify=None,\n    max_rows=None,\n    max_cols=None,\n    show_dimensions=False,\n    decimal=\".\",\n    bold_rows=True,\n    classes=None,\n    escape=True,\n    notebook=False,\n    border=None,\n    table_id=None,\n    render_links=False,\n    encoding=None,\n):\n    \"\"\"\n    Render a DataFrame as an HTML table.\n    %(shared_params)s\n    bold_rows : bool, default True\n        Make the row labels bold in the output.\n    classes : str or list or tuple, default None\n        CSS class(es) to apply to the resulting html table.\n    escape : bool, default True\n        Convert the characters <, >, and & to HTML-safe sequences.\n    notebook : {True, False}, default False\n        Whether the generated HTML is for IPython Notebook.\n    border : int\n        A ``border=border`` attribute is included in the opening\n        `<table>` tag. Default ``pd.options.display.html.border``.\n    encoding : str, default \"utf-8\"\n        Set character encoding.\n\n        .. versionadded:: 1.0\n\n    table_id : str, optional\n        A css id is included in the opening `<table>` tag if specified.\n\n        .. versionadded:: 0.23.0\n\n    render_links : bool, default False\n        Convert URLs to HTML links.\n\n        .. versionadded:: 0.24.0\n    %(returns)s\n    See Also\n    --------\n    to_string : Convert DataFrame to a string.\n    \"\"\"\n    if justify is not None and justify not in fmt._VALID_JUSTIFY_PARAMETERS:\n        raise ValueError(\"Invalid value for justify parameter\")\n\n    formatter = fmt.DataFrameFormatter(\n        self,\n        columns=columns,\n        col_space=col_space,\n        na_rep=na_rep,\n        formatters=formatters,\n        float_format=float_format,\n        sparsify=sparsify,\n        justify=justify,\n        index_names=index_names,\n        header=header,\n        index=index,\n        bold_rows=bold_rows,\n        escape=escape,\n        max_rows=max_rows,\n        max_cols=max_cols,\n        show_dimensions=show_dimensions,\n        decimal=decimal,\n        table_id=table_id,\n        render_links=render_links,\n    )\n    # TODO: a generic formatter wld b in DataFrameFormatter\n    return formatter.to_html(\n        buf=buf,\n        classes=classes,\n        notebook=notebook,\n        border=border,\n        encoding=encoding,\n    )",
                "@Appender(info.__doc__)\ndef info(\n    self, verbose=None, buf=None, max_cols=None, memory_usage=None, null_counts=None\n) -> None:\n    return info(self, verbose, buf, max_cols, memory_usage, null_counts)",
                "def memory_usage(self, index=True, deep=False) -> Series:\n    \"\"\"\n    Return the memory usage of each column in bytes.\n\n    The memory usage can optionally include the contribution of\n    the index and elements of `object` dtype.\n\n    This value is displayed in `DataFrame.info` by default. This can be\n    suppressed by setting ``pandas.options.display.memory_usage`` to False.\n\n    Parameters\n    ----------\n    index : bool, default True\n        Specifies whether to include the memory usage of the DataFrame's\n        index in returned Series. If ``index=True``, the memory usage of\n        the index is the first item in the output.\n    deep : bool, default False\n        If True, introspect the data deeply by interrogating\n        `object` dtypes for system-level memory consumption, and include\n        it in the returned values.\n\n    Returns\n    -------\n    Series\n        A Series whose index is the original column names and whose values\n        is the memory usage of each column in bytes.\n\n    See Also\n    --------\n    numpy.ndarray.nbytes : Total bytes consumed by the elements of an\n        ndarray.\n    Series.memory_usage : Bytes consumed by a Series.\n    Categorical : Memory-efficient array for string values with\n        many repeated values.\n    DataFrame.info : Concise summary of a DataFrame.\n\n    Examples\n    --------\n    >>> dtypes = ['int64', 'float64', 'complex128', 'object', 'bool']\n    >>> data = dict([(t, np.ones(shape=5000).astype(t))\n    ...              for t in dtypes])\n    >>> df = pd.DataFrame(data)\n    >>> df.head()\n       int64  float64            complex128  object  bool\n    0      1      1.0    1.000000+0.000000j       1  True\n    1      1      1.0    1.000000+0.000000j       1  True\n    2      1      1.0    1.000000+0.000000j       1  True\n    3      1      1.0    1.000000+0.000000j       1  True\n    4      1      1.0    1.000000+0.000000j       1  True\n\n    >>> df.memory_usage()\n    Index           128\n    int64         40000\n    float64       40000\n    complex128    80000\n    object        40000\n    bool           5000\n    dtype: int64\n\n    >>> df.memory_usage(index=False)\n    int64         40000\n    float64       40000\n    complex128    80000\n    object        40000\n    bool           5000\n    dtype: int64\n\n    The memory footprint of `object` dtype columns is ignored by default:\n\n    >>> df.memory_usage(deep=True)\n    Index            128\n    int64          40000\n    float64        40000\n    complex128     80000\n    object        160000\n    bool            5000\n    dtype: int64\n\n    Use a Categorical for efficient storage of an object-dtype column with\n    many repeated values.\n\n    >>> df['object'].astype('category').memory_usage(deep=True)\n    5216\n    \"\"\"\n    result = Series(\n        [c.memory_usage(index=False, deep=deep) for col, c in self.items()],\n        index=self.columns,\n    )\n    if index:\n        result = Series(self.index.memory_usage(deep=deep), index=[\"Index\"]).append(\n            result\n        )\n    return result",
                "def transpose(self, *args, copy: bool = False) -> \"DataFrame\":\n    \"\"\"\n    Transpose index and columns.\n\n    Reflect the DataFrame over its main diagonal by writing rows as columns\n    and vice-versa. The property :attr:`.T` is an accessor to the method\n    :meth:`transpose`.\n\n    Parameters\n    ----------\n    *args : tuple, optional\n        Accepted for compatibility with NumPy.\n    copy : bool, default False\n        Whether to copy the data after transposing, even for DataFrames\n        with a single dtype.\n\n        Note that a copy is always required for mixed dtype DataFrames,\n        or for DataFrames with any extension types.\n\n    Returns\n    -------\n    DataFrame\n        The transposed DataFrame.\n\n    See Also\n    --------\n    numpy.transpose : Permute the dimensions of a given array.\n\n    Notes\n    -----\n    Transposing a DataFrame with mixed dtypes will result in a homogeneous\n    DataFrame with the `object` dtype. In such a case, a copy of the data\n    is always made.\n\n    Examples\n    --------\n    **Square DataFrame with homogeneous dtype**\n\n    >>> d1 = {'col1': [1, 2], 'col2': [3, 4]}\n    >>> df1 = pd.DataFrame(data=d1)\n    >>> df1\n       col1  col2\n    0     1     3\n    1     2     4\n\n    >>> df1_transposed = df1.T # or df1.transpose()\n    >>> df1_transposed\n          0  1\n    col1  1  2\n    col2  3  4\n\n    When the dtype is homogeneous in the original DataFrame, we get a\n    transposed DataFrame with the same dtype:\n\n    >>> df1.dtypes\n    col1    int64\n    col2    int64\n    dtype: object\n    >>> df1_transposed.dtypes\n    0    int64\n    1    int64\n    dtype: object\n\n    **Non-square DataFrame with mixed dtypes**\n\n    >>> d2 = {'name': ['Alice', 'Bob'],\n    ...       'score': [9.5, 8],\n    ...       'employed': [False, True],\n    ...       'kids': [0, 0]}\n    >>> df2 = pd.DataFrame(data=d2)\n    >>> df2\n        name  score  employed  kids\n    0  Alice    9.5     False     0\n    1    Bob    8.0      True     0\n\n    >>> df2_transposed = df2.T # or df2.transpose()\n    >>> df2_transposed\n                  0     1\n    name      Alice   Bob\n    score       9.5     8\n    employed  False  True\n    kids          0     0\n\n    When the DataFrame has mixed dtypes, we get a transposed DataFrame with\n    the `object` dtype:\n\n    >>> df2.dtypes\n    name         object\n    score       float64\n    employed       bool\n    kids          int64\n    dtype: object\n    >>> df2_transposed.dtypes\n    0    object\n    1    object\n    dtype: object\n    \"\"\"\n    nv.validate_transpose(args, dict())\n    # construct the args\n\n    dtypes = list(self.dtypes)\n    if self._is_homogeneous_type and dtypes and is_extension_array_dtype(dtypes[0]):\n        # We have EAs with the same dtype. We can preserve that dtype in transpose.\n        dtype = dtypes[0]\n        arr_type = dtype.construct_array_type()\n        values = self.values\n\n        new_values = [arr_type._from_sequence(row, dtype=dtype) for row in values]\n        result = self._constructor(\n            dict(zip(self.index, new_values)), index=self.columns\n        )\n\n    else:\n        new_values = self.values.T\n        if copy:\n            new_values = new_values.copy()\n        result = self._constructor(\n            new_values, index=self.columns, columns=self.index\n        )\n\n    return result.__finalize__(self)",
                "@property\ndef T(self) -> \"DataFrame\":\n    return self.transpose()",
                "def _ixs(self, i: int, axis: int = 0):\n    \"\"\"\n    Parameters\n    ----------\n    i : int\n    axis : int\n\n    Notes\n    -----\n    If slice passed, the resulting data will be a view.\n    \"\"\"\n    # irow\n    if axis == 0:\n        new_values = self._data.fast_xs(i)\n\n        # if we are a copy, mark as such\n        copy = isinstance(new_values, np.ndarray) and new_values.base is None\n        result = self._constructor_sliced(\n            new_values,\n            index=self.columns,\n            name=self.index[i],\n            dtype=new_values.dtype,\n        )\n        result._set_is_copy(self, copy=copy)\n        return result\n\n    # icol\n    else:\n        label = self.columns[i]\n\n        values = self._data.iget(i)\n        result = self._box_col_values(values, label)\n\n        # this is a cached value, mark it so\n        result._set_as_cached(label, self)\n\n        return result",
                "def __getitem__(self, key):\n    key = lib.item_from_zerodim(key)\n    key = com.apply_if_callable(key, self)\n\n    if is_hashable(key):\n        # shortcut if the key is in columns\n        if self.columns.is_unique and key in self.columns:\n            if self.columns.nlevels > 1:\n                return self._getitem_multilevel(key)\n            return self._get_item_cache(key)\n\n    # Do we have a slicer (on rows)?\n    indexer = convert_to_index_sliceable(self, key)\n    if indexer is not None:\n        # either we have a slice or we have a string that can be converted\n        #  to a slice for partial-string date indexing\n        return self._slice(indexer, axis=0)\n\n    # Do we have a (boolean) DataFrame?\n    if isinstance(key, DataFrame):\n        return self.where(key)\n\n    # Do we have a (boolean) 1d indexer?\n    if com.is_bool_indexer(key):\n        return self._getitem_bool_array(key)\n\n    # We are left with two options: a single key, and a collection of keys,\n    # We interpret tuples as collections only for non-MultiIndex\n    is_single_key = isinstance(key, tuple) or not is_list_like(key)\n\n    if is_single_key:\n        if self.columns.nlevels > 1:\n            return self._getitem_multilevel(key)\n        indexer = self.columns.get_loc(key)\n        if is_integer(indexer):\n            indexer = [indexer]\n    else:\n        if is_iterator(key):\n            key = list(key)\n        indexer = self.loc._get_listlike_indexer(key, axis=1, raise_missing=True)[1]\n\n    # take() does not accept boolean indexers\n    if getattr(indexer, \"dtype\", None) == bool:\n        indexer = np.where(indexer)[0]\n\n    data = self._take_with_is_copy(indexer, axis=1)\n\n    if is_single_key:\n        # What does looking for a single key in a non-unique index return?\n        # The behavior is inconsistent. It returns a Series, except when\n        # - the key itself is repeated (test on data.shape, #9519), or\n        # - we have a MultiIndex on columns (test on self.columns, #21309)\n        if data.shape[1] == 1 and not isinstance(self.columns, ABCMultiIndex):\n            data = data[key]\n\n    return data",
                "def _getitem_bool_array(self, key):\n    # also raises Exception if object array with NA values\n    # warning here just in case -- previously __setitem__ was\n    # reindexing but __getitem__ was not; it seems more reasonable to\n    # go with the __setitem__ behavior since that is more consistent\n    # with all other indexing behavior\n    if isinstance(key, Series) and not key.index.equals(self.index):\n        warnings.warn(\n            \"Boolean Series key will be reindexed to match DataFrame index.\",\n            UserWarning,\n            stacklevel=3,\n        )\n    elif len(key) != len(self.index):\n        raise ValueError(\n            f\"Item wrong length {len(key)} instead of {len(self.index)}.\"\n        )\n\n    # check_bool_indexer will throw exception if Series key cannot\n    # be reindexed to match DataFrame rows\n    key = check_bool_indexer(self.index, key)\n    indexer = key.nonzero()[0]\n    return self._take_with_is_copy(indexer, axis=0)",
                "def _getitem_multilevel(self, key):\n    # self.columns is a MultiIndex\n    loc = self.columns.get_loc(key)\n    if isinstance(loc, (slice, Series, np.ndarray, Index)):\n        new_columns = self.columns[loc]\n        result_columns = maybe_droplevels(new_columns, key)\n        if self._is_mixed_type:\n            result = self.reindex(columns=new_columns)\n            result.columns = result_columns\n        else:\n            new_values = self.values[:, loc]\n            result = self._constructor(\n                new_values, index=self.index, columns=result_columns\n            )\n            result = result.__finalize__(self)\n\n        # If there is only one column being returned, and its name is\n        # either an empty string, or a tuple with an empty string as its\n        # first element, then treat the empty string as a placeholder\n        # and return the column as if the user had provided that empty\n        # string in the key. If the result is a Series, exclude the\n        # implied empty string from its name.\n        if len(result.columns) == 1:\n            top = result.columns[0]\n            if isinstance(top, tuple):\n                top = top[0]\n            if top == \"\":\n                result = result[\"\"]\n                if isinstance(result, Series):\n                    result = self._constructor_sliced(\n                        result, index=self.index, name=key\n                    )\n\n        result._set_is_copy(self)\n        return result\n    else:\n        return self._get_item_cache(key)",
                "def _get_value(self, index, col, takeable: bool = False):\n    \"\"\"\n    Quickly retrieve single value at passed column and index.\n\n    Parameters\n    ----------\n    index : row label\n    col : column label\n    takeable : interpret the index/col as indexers, default False\n\n    Returns\n    -------\n    scalar\n    \"\"\"\n    if takeable:\n        series = self._ixs(col, axis=1)\n        return series._values[index]\n\n    series = self._get_item_cache(col)\n    engine = self.index._engine\n\n    try:\n        loc = engine.get_loc(index)\n        return series._values[loc]\n    except KeyError:\n        # GH 20629\n        if self.index.nlevels > 1:\n            # partial indexing forbidden\n            raise\n\n    # we cannot handle direct indexing\n    # use positional\n    col = self.columns.get_loc(col)\n    index = self.index.get_loc(index)\n    return self._get_value(index, col, takeable=True)",
                "def __setitem__(self, key, value):\n    key = com.apply_if_callable(key, self)\n\n    # see if we can slice the rows\n    indexer = convert_to_index_sliceable(self, key)\n    if indexer is not None:\n        # either we have a slice or we have a string that can be converted\n        #  to a slice for partial-string date indexing\n        return self._setitem_slice(indexer, value)\n\n    if isinstance(key, DataFrame) or getattr(key, \"ndim\", None) == 2:\n        self._setitem_frame(key, value)\n    elif isinstance(key, (Series, np.ndarray, list, Index)):\n        self._setitem_array(key, value)\n    else:\n        # set column\n        self._set_item(key, value)",
                "def _setitem_slice(self, key: slice, value):\n    # NB: we can't just use self.loc[key] = value because that\n    #  operates on labels and we need to operate positional for\n    #  backwards-compat, xref GH#31469\n    self._check_setitem_copy()\n    self.iloc._setitem_with_indexer(key, value)",
                "def _setitem_array(self, key, value):\n    # also raises Exception if object array with NA values\n    if com.is_bool_indexer(key):\n        if len(key) != len(self.index):\n            raise ValueError(\n                f\"Item wrong length {len(key)} instead of {len(self.index)}!\"\n            )\n        key = check_bool_indexer(self.index, key)\n        indexer = key.nonzero()[0]\n        self._check_setitem_copy()\n        self.iloc._setitem_with_indexer(indexer, value)\n    else:\n        if isinstance(value, DataFrame):\n            if len(value.columns) != len(key):\n                raise ValueError(\"Columns must be same length as key\")\n            for k1, k2 in zip(key, value.columns):\n                self[k1] = value[k2]\n        else:\n            indexer = self.loc._get_listlike_indexer(\n                key, axis=1, raise_missing=False\n            )[1]\n            self._check_setitem_copy()\n            self.iloc._setitem_with_indexer((slice(None), indexer), value)",
                "def _setitem_frame(self, key, value):\n    # support boolean setting with DataFrame input, e.g.\n    # df[df > df2] = 0\n    if isinstance(key, np.ndarray):\n        if key.shape != self.shape:\n            raise ValueError(\"Array conditional must be same shape as self\")\n        key = self._constructor(key, **self._construct_axes_dict())\n\n    if key.values.size and not is_bool_dtype(key.values):\n        raise TypeError(\n            \"Must pass DataFrame or 2-d ndarray with boolean values only\"\n        )\n\n    self._check_inplace_setting(value)\n    self._check_setitem_copy()\n    self._where(-key, value, inplace=True)",
                "def _iset_item(self, loc: int, value):\n    self._ensure_valid_index(value)\n\n    # technically _sanitize_column expects a label, not a position,\n    #  but the behavior is the same as long as we pass broadcast=False\n    value = self._sanitize_column(loc, value, broadcast=False)\n    NDFrame._iset_item(self, loc, value)\n\n    # check if we are modifying a copy\n    # try to set first as we want an invalid\n    # value exception to occur first\n    if len(self):\n        self._check_setitem_copy()",
                "def _set_item(self, key, value):\n    \"\"\"\n    Add series to DataFrame in specified column.\n\n    If series is a numpy-array (not a Series/TimeSeries), it must be the\n    same length as the DataFrames index or an error will be thrown.\n\n    Series/TimeSeries will be conformed to the DataFrames index to\n    ensure homogeneity.\n    \"\"\"\n    self._ensure_valid_index(value)\n    value = self._sanitize_column(key, value)\n    NDFrame._set_item(self, key, value)\n\n    # check if we are modifying a copy\n    # try to set first as we want an invalid\n    # value exception to occur first\n    if len(self):\n        self._check_setitem_copy()",
                "def _set_value(self, index, col, value, takeable: bool = False):\n    \"\"\"\n    Put single value at passed column and index.\n\n    Parameters\n    ----------\n    index : row label\n    col : column label\n    value : scalar\n    takeable : interpret the index/col as indexers, default False\n    \"\"\"\n    try:\n        if takeable is True:\n            series = self._ixs(col, axis=1)\n            series._set_value(index, value, takeable=True)\n            return\n\n        series = self._get_item_cache(col)\n        engine = self.index._engine\n        loc = engine.get_loc(index)\n        validate_numeric_casting(series.dtype, value)\n\n        series._values[loc] = value\n        # Note: trying to use series._set_value breaks tests in\n        #  tests.frame.indexing.test_indexing and tests.indexing.test_partial\n    except (KeyError, TypeError):\n        # set using a non-recursive method & reset the cache\n        if takeable:\n            self.iloc[index, col] = value\n        else:\n            self.loc[index, col] = value\n        self._item_cache.pop(col, None)",
                "def _ensure_valid_index(self, value):\n    \"\"\"\n    Ensure that if we don't have an index, that we can create one from the\n    passed value.\n    \"\"\"\n    # GH5632, make sure that we are a Series convertible\n    if not len(self.index) and is_list_like(value) and len(value):\n        try:\n            value = Series(value)\n        except (ValueError, NotImplementedError, TypeError) as err:\n            raise ValueError(\n                \"Cannot set a frame with no defined index \"\n                \"and a value that cannot be converted to a Series\"\n            ) from err\n\n        self._data = self._data.reindex_axis(\n            value.index.copy(), axis=1, fill_value=np.nan\n        )",
                "def _box_item_values(self, key, values):\n    items = self.columns[self.columns.get_loc(key)]\n    if values.ndim == 2:\n        return self._constructor(values.T, columns=items, index=self.index)\n    else:\n        return self._box_col_values(values, items)",
                "def _box_col_values(self, values, items):\n    \"\"\"\n    Provide boxed values for a column.\n    \"\"\"\n    klass = self._constructor_sliced\n    return klass(values, index=self.index, name=items, fastpath=True)",
                "def query(self, expr, inplace=False, **kwargs):\n    \"\"\"\n    Query the columns of a DataFrame with a boolean expression.\n\n    Parameters\n    ----------\n    expr : str\n        The query string to evaluate.\n\n        You can refer to variables\n        in the environment by prefixing them with an '@' character like\n        ``@a + b``.\n\n        You can refer to column names that contain spaces or operators by\n        surrounding them in backticks. This way you can also escape\n        names that start with a digit, or those that  are a Python keyword.\n        Basically when it is not valid Python identifier. See notes down\n        for more details.\n\n        For example, if one of your columns is called ``a a`` and you want\n        to sum it with ``b``, your query should be ```a a` + b``.\n\n        .. versionadded:: 0.25.0\n            Backtick quoting introduced.\n\n        .. versionadded:: 1.0.0\n            Expanding functionality of backtick quoting for more than only spaces.\n\n    inplace : bool\n        Whether the query should modify the data in place or return\n        a modified copy.\n    **kwargs\n        See the documentation for :func:`eval` for complete details\n        on the keyword arguments accepted by :meth:`DataFrame.query`.\n\n    Returns\n    -------\n    DataFrame\n        DataFrame resulting from the provided query expression.\n\n    See Also\n    --------\n    eval : Evaluate a string describing operations on\n        DataFrame columns.\n    DataFrame.eval : Evaluate a string describing operations on\n        DataFrame columns.\n\n    Notes\n    -----\n    The result of the evaluation of this expression is first passed to\n    :attr:`DataFrame.loc` and if that fails because of a\n    multidimensional key (e.g., a DataFrame) then the result will be passed\n    to :meth:`DataFrame.__getitem__`.\n\n    This method uses the top-level :func:`eval` function to\n    evaluate the passed query.\n\n    The :meth:`~pandas.DataFrame.query` method uses a slightly\n    modified Python syntax by default. For example, the ``&`` and ``|``\n    (bitwise) operators have the precedence of their boolean cousins,\n    :keyword:`and` and :keyword:`or`. This *is* syntactically valid Python,\n    however the semantics are different.\n\n    You can change the semantics of the expression by passing the keyword\n    argument ``parser='python'``. This enforces the same semantics as\n    evaluation in Python space. Likewise, you can pass ``engine='python'``\n    to evaluate an expression using Python itself as a backend. This is not\n    recommended as it is inefficient compared to using ``numexpr`` as the\n    engine.\n\n    The :attr:`DataFrame.index` and\n    :attr:`DataFrame.columns` attributes of the\n    :class:`~pandas.DataFrame` instance are placed in the query namespace\n    by default, which allows you to treat both the index and columns of the\n    frame as a column in the frame.\n    The identifier ``index`` is used for the frame index; you can also\n    use the name of the index to identify it in a query. Please note that\n    Python keywords may not be used as identifiers.\n\n    For further details and examples see the ``query`` documentation in\n    :ref:`indexing <indexing.query>`.\n\n    *Backtick quoted variables*\n\n    Backtick quoted variables are parsed as literal Python code and\n    are converted internally to a Python valid identifier.\n    This can lead to the following problems.\n\n    During parsing a number of disallowed characters inside the backtick\n    quoted string are replaced by strings that are allowed as a Python identifier.\n    These characters include all operators in Python, the space character, the\n    question mark, the exclamation mark, the dollar sign, and the euro sign.\n    For other characters that fall outside the ASCII range (U+0001..U+007F)\n    and those that are not further specified in PEP 3131,\n    the query parser will raise an error.\n    This excludes whitespace different than the space character,\n    but also the hashtag (as it is used for comments) and the backtick\n    itself (backtick can also not be escaped).\n\n    In a special case, quotes that make a pair around a backtick can\n    confuse the parser.\n    For example, ```it's` > `that's``` will raise an error,\n    as it forms a quoted string (``'s > `that'``) with a backtick inside.\n\n    See also the Python documentation about lexical analysis\n    (https://docs.python.org/3/reference/lexical_analysis.html)\n    in combination with the source code in :mod:`pandas.core.computation.parsing`.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame({'A': range(1, 6),\n    ...                    'B': range(10, 0, -2),\n    ...                    'C C': range(10, 5, -1)})\n    >>> df\n       A   B  C C\n    0  1  10   10\n    1  2   8    9\n    2  3   6    8\n    3  4   4    7\n    4  5   2    6\n    >>> df.query('A > B')\n       A  B  C C\n    4  5  2    6\n\n    The previous expression is equivalent to\n\n    >>> df[df.A > df.B]\n       A  B  C C\n    4  5  2    6\n\n    For columns with spaces in their name, you can use backtick quoting.\n\n    >>> df.query('B == `C C`')\n       A   B  C C\n    0  1  10   10\n\n    The previous expression is equivalent to\n\n    >>> df[df.B == df['C C']]\n       A   B  C C\n    0  1  10   10\n    \"\"\"\n    inplace = validate_bool_kwarg(inplace, \"inplace\")\n    if not isinstance(expr, str):\n        msg = f\"expr must be a string to be evaluated, {type(expr)} given\"\n        raise ValueError(msg)\n    kwargs[\"level\"] = kwargs.pop(\"level\", 0) + 1\n    kwargs[\"target\"] = None\n    res = self.eval(expr, **kwargs)\n\n    try:\n        new_data = self.loc[res]\n    except ValueError:\n        # when res is multi-dimensional loc raises, but this is sometimes a\n        # valid query\n        new_data = self[res]\n\n    if inplace:\n        self._update_inplace(new_data)\n    else:\n        return new_data",
                "def eval(self, expr, inplace=False, **kwargs):\n    \"\"\"\n    Evaluate a string describing operations on DataFrame columns.\n\n    Operates on columns only, not specific rows or elements.  This allows\n    `eval` to run arbitrary code, which can make you vulnerable to code\n    injection if you pass user input to this function.\n\n    Parameters\n    ----------\n    expr : str\n        The expression string to evaluate.\n    inplace : bool, default False\n        If the expression contains an assignment, whether to perform the\n        operation inplace and mutate the existing DataFrame. Otherwise,\n        a new DataFrame is returned.\n    **kwargs\n        See the documentation for :func:`eval` for complete details\n        on the keyword arguments accepted by\n        :meth:`~pandas.DataFrame.query`.\n\n    Returns\n    -------\n    ndarray, scalar, or pandas object\n        The result of the evaluation.\n\n    See Also\n    --------\n    DataFrame.query : Evaluates a boolean expression to query the columns\n        of a frame.\n    DataFrame.assign : Can evaluate an expression or function to create new\n        values for a column.\n    eval : Evaluate a Python expression as a string using various\n        backends.\n\n    Notes\n    -----\n    For more details see the API documentation for :func:`~eval`.\n    For detailed examples see :ref:`enhancing performance with eval\n    <enhancingperf.eval>`.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame({'A': range(1, 6), 'B': range(10, 0, -2)})\n    >>> df\n       A   B\n    0  1  10\n    1  2   8\n    2  3   6\n    3  4   4\n    4  5   2\n    >>> df.eval('A + B')\n    0    11\n    1    10\n    2     9\n    3     8\n    4     7\n    dtype: int64\n\n    Assignment is allowed though by default the original DataFrame is not\n    modified.\n\n    >>> df.eval('C = A + B')\n       A   B   C\n    0  1  10  11\n    1  2   8  10\n    2  3   6   9\n    3  4   4   8\n    4  5   2   7\n    >>> df\n       A   B\n    0  1  10\n    1  2   8\n    2  3   6\n    3  4   4\n    4  5   2\n\n    Use ``inplace=True`` to modify the original DataFrame.\n\n    >>> df.eval('C = A + B', inplace=True)\n    >>> df\n       A   B   C\n    0  1  10  11\n    1  2   8  10\n    2  3   6   9\n    3  4   4   8\n    4  5   2   7\n\n    Multiple columns can be assigned to using multi-line expressions:\n\n    >>> df.eval(\n    ...     '''\n    ... C = A + B\n    ... D = A - B\n    ... '''\n    ... )\n       A   B   C  D\n    0  1  10  11 -9\n    1  2   8  10 -6\n    2  3   6   9 -3\n    3  4   4   8  0\n    4  5   2   7  3\n    \"\"\"\n    from pandas.core.computation.eval import eval as _eval\n\n    inplace = validate_bool_kwarg(inplace, \"inplace\")\n    resolvers = kwargs.pop(\"resolvers\", None)\n    kwargs[\"level\"] = kwargs.pop(\"level\", 0) + 1\n    if resolvers is None:\n        index_resolvers = self._get_index_resolvers()\n        column_resolvers = self._get_cleaned_column_resolvers()\n        resolvers = column_resolvers, index_resolvers\n    if \"target\" not in kwargs:\n        kwargs[\"target\"] = self\n    kwargs[\"resolvers\"] = kwargs.get(\"resolvers\", ()) + tuple(resolvers)\n\n    return _eval(expr, inplace=inplace, **kwargs)",
                "def select_dtypes(self, include=None, exclude=None) -> \"DataFrame\":\n    \"\"\"\n    Return a subset of the DataFrame's columns based on the column dtypes.\n\n    Parameters\n    ----------\n    include, exclude : scalar or list-like\n        A selection of dtypes or strings to be included/excluded. At least\n        one of these parameters must be supplied.\n\n    Returns\n    -------\n    DataFrame\n        The subset of the frame including the dtypes in ``include`` and\n        excluding the dtypes in ``exclude``.\n\n    Raises\n    ------\n    ValueError\n        * If both of ``include`` and ``exclude`` are empty\n        * If ``include`` and ``exclude`` have overlapping elements\n        * If any kind of string dtype is passed in.\n\n    Notes\n    -----\n    * To select all *numeric* types, use ``np.number`` or ``'number'``\n    * To select strings you must use the ``object`` dtype, but note that\n      this will return *all* object dtype columns\n    * See the `numpy dtype hierarchy\n      <https://docs.scipy.org/doc/numpy/reference/arrays.scalars.html>`__\n    * To select datetimes, use ``np.datetime64``, ``'datetime'`` or\n      ``'datetime64'``\n    * To select timedeltas, use ``np.timedelta64``, ``'timedelta'`` or\n      ``'timedelta64'``\n    * To select Pandas categorical dtypes, use ``'category'``\n    * To select Pandas datetimetz dtypes, use ``'datetimetz'`` (new in\n      0.20.0) or ``'datetime64[ns, tz]'``\n\n    Examples\n    --------\n    >>> df = pd.DataFrame({'a': [1, 2] * 3,\n    ...                    'b': [True, False] * 3,\n    ...                    'c': [1.0, 2.0] * 3})\n    >>> df\n            a      b  c\n    0       1   True  1.0\n    1       2  False  2.0\n    2       1   True  1.0\n    3       2  False  2.0\n    4       1   True  1.0\n    5       2  False  2.0\n\n    >>> df.select_dtypes(include='bool')\n       b\n    0  True\n    1  False\n    2  True\n    3  False\n    4  True\n    5  False\n\n    >>> df.select_dtypes(include=['float64'])\n       c\n    0  1.0\n    1  2.0\n    2  1.0\n    3  2.0\n    4  1.0\n    5  2.0\n\n    >>> df.select_dtypes(exclude=['int'])\n           b    c\n    0   True  1.0\n    1  False  2.0\n    2   True  1.0\n    3  False  2.0\n    4   True  1.0\n    5  False  2.0\n    \"\"\"\n    if not is_list_like(include):\n        include = (include,) if include is not None else ()\n    if not is_list_like(exclude):\n        exclude = (exclude,) if exclude is not None else ()\n\n    selection = (frozenset(include), frozenset(exclude))\n\n    if not any(selection):\n        raise ValueError(\"at least one of include or exclude must be nonempty\")\n\n    # convert the myriad valid dtypes object to a single representation\n    include = frozenset(infer_dtype_from_object(x) for x in include)\n    exclude = frozenset(infer_dtype_from_object(x) for x in exclude)\n    for dtypes in (include, exclude):\n        invalidate_string_dtypes(dtypes)\n\n    # can't both include AND exclude!\n    if not include.isdisjoint(exclude):\n        raise ValueError(f\"include and exclude overlap on {(include & exclude)}\")\n\n    # We raise when both include and exclude are empty\n    # Hence, we can just shrink the columns we want to keep\n    keep_these = np.full(self.shape[1], True)\n\n    def extract_unique_dtypes_from_dtypes_set(\n        dtypes_set: FrozenSet[Dtype], unique_dtypes: np.ndarray\n    ) -> List[Dtype]:\n        extracted_dtypes = [\n            unique_dtype\n            for unique_dtype in unique_dtypes\n            if issubclass(unique_dtype.type, tuple(dtypes_set))  # type: ignore\n        ]\n        return extracted_dtypes\n\n    unique_dtypes = self.dtypes.unique()\n\n    if include:\n        included_dtypes = extract_unique_dtypes_from_dtypes_set(\n            include, unique_dtypes\n        )\n        keep_these &= self.dtypes.isin(included_dtypes)\n\n    if exclude:\n        excluded_dtypes = extract_unique_dtypes_from_dtypes_set(\n            exclude, unique_dtypes\n        )\n        keep_these &= ~self.dtypes.isin(excluded_dtypes)\n\n    return self.iloc[:, keep_these.values]",
                "def insert(self, loc, column, value, allow_duplicates=False) -> None:\n    \"\"\"\n    Insert column into DataFrame at specified location.\n\n    Raises a ValueError if `column` is already contained in the DataFrame,\n    unless `allow_duplicates` is set to True.\n\n    Parameters\n    ----------\n    loc : int\n        Insertion index. Must verify 0 <= loc <= len(columns).\n    column : str, number, or hashable object\n        Label of the inserted column.\n    value : int, Series, or array-like\n    allow_duplicates : bool, optional\n    \"\"\"\n    self._ensure_valid_index(value)\n    value = self._sanitize_column(column, value, broadcast=False)\n    self._data.insert(loc, column, value, allow_duplicates=allow_duplicates)",
                "def assign(self, **kwargs) -> \"DataFrame\":\n    r\"\"\"\n    Assign new columns to a DataFrame.\n\n    Returns a new object with all original columns in addition to new ones.\n    Existing columns that are re-assigned will be overwritten.\n\n    Parameters\n    ----------\n    **kwargs : dict of {str: callable or Series}\n        The column names are keywords. If the values are\n        callable, they are computed on the DataFrame and\n        assigned to the new columns. The callable must not\n        change input DataFrame (though pandas doesn't check it).\n        If the values are not callable, (e.g. a Series, scalar, or array),\n        they are simply assigned.\n\n    Returns\n    -------\n    DataFrame\n        A new DataFrame with the new columns in addition to\n        all the existing columns.\n\n    Notes\n    -----\n    Assigning multiple columns within the same ``assign`` is possible.\n    Later items in '\\*\\*kwargs' may refer to newly created or modified\n    columns in 'df'; items are computed and assigned into 'df' in order.\n\n    .. versionchanged:: 0.23.0\n\n       Keyword argument order is maintained.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame({'temp_c': [17.0, 25.0]},\n    ...                   index=['Portland', 'Berkeley'])\n    >>> df\n              temp_c\n    Portland    17.0\n    Berkeley    25.0\n\n    Where the value is a callable, evaluated on `df`:\n\n    >>> df.assign(temp_f=lambda x: x.temp_c * 9 / 5 + 32)\n              temp_c  temp_f\n    Portland    17.0    62.6\n    Berkeley    25.0    77.0\n\n    Alternatively, the same behavior can be achieved by directly\n    referencing an existing Series or sequence:\n\n    >>> df.assign(temp_f=df['temp_c'] * 9 / 5 + 32)\n              temp_c  temp_f\n    Portland    17.0    62.6\n    Berkeley    25.0    77.0\n\n    You can create multiple columns within the same assign where one\n    of the columns depends on another one defined within the same assign:\n\n    >>> df.assign(temp_f=lambda x: x['temp_c'] * 9 / 5 + 32,\n    ...           temp_k=lambda x: (x['temp_f'] +  459.67) * 5 / 9)\n              temp_c  temp_f  temp_k\n    Portland    17.0    62.6  290.15\n    Berkeley    25.0    77.0  298.15\n    \"\"\"\n    data = self.copy()\n\n    for k, v in kwargs.items():\n        data[k] = com.apply_if_callable(v, data)\n    return data",
                "def _sanitize_column(self, key, value, broadcast=True):\n    \"\"\"\n    Ensures new columns (which go into the BlockManager as new blocks) are\n    always copied and converted into an array.\n\n    Parameters\n    ----------\n    key : object\n    value : scalar, Series, or array-like\n    broadcast : bool, default True\n        If ``key`` matches multiple duplicate column names in the\n        DataFrame, this parameter indicates whether ``value`` should be\n        tiled so that the returned array contains a (duplicated) column for\n        each occurrence of the key. If False, ``value`` will not be tiled.\n\n    Returns\n    -------\n    numpy.ndarray\n    \"\"\"\n\n    def reindexer(value):\n        # reindex if necessary\n\n        if value.index.equals(self.index) or not len(self.index):\n            value = value._values.copy()\n        else:\n\n            # GH 4107\n            try:\n                value = value.reindex(self.index)._values\n            except ValueError as err:\n                # raised in MultiIndex.from_tuples, see test_insert_error_msmgs\n                if not value.index.is_unique:\n                    # duplicate axis\n                    raise err\n\n                # other\n                raise TypeError(\n                    \"incompatible index of inserted column with frame index\"\n                ) from err\n        return value\n\n    if isinstance(value, Series):\n        value = reindexer(value)\n\n    elif isinstance(value, DataFrame):\n        # align right-hand-side columns if self.columns\n        # is multi-index and self[key] is a sub-frame\n        if isinstance(self.columns, ABCMultiIndex) and key in self.columns:\n            loc = self.columns.get_loc(key)\n            if isinstance(loc, (slice, Series, np.ndarray, Index)):\n                cols = maybe_droplevels(self.columns[loc], key)\n                if len(cols) and not cols.equals(value.columns):\n                    value = value.reindex(cols, axis=1)\n        # now align rows\n        value = reindexer(value).T\n\n    elif isinstance(value, ExtensionArray):\n        # Explicitly copy here, instead of in sanitize_index,\n        # as sanitize_index won't copy an EA, even with copy=True\n        value = value.copy()\n        value = sanitize_index(value, self.index)\n\n    elif isinstance(value, Index) or is_sequence(value):\n\n        # turn me into an ndarray\n        value = sanitize_index(value, self.index)\n        if not isinstance(value, (np.ndarray, Index)):\n            if isinstance(value, list) and len(value) > 0:\n                value = maybe_convert_platform(value)\n            else:\n                value = com.asarray_tuplesafe(value)\n        elif value.ndim == 2:\n            value = value.copy().T\n        elif isinstance(value, Index):\n            value = value.copy(deep=True)\n        else:\n            value = value.copy()\n\n        # possibly infer to datetimelike\n        if is_object_dtype(value.dtype):\n            value = maybe_infer_to_datetimelike(value)\n\n    else:\n        # cast ignores pandas dtypes. so save the dtype first\n        infer_dtype, _ = infer_dtype_from_scalar(value, pandas_dtype=True)\n\n        # upcast\n        value = cast_scalar_to_array(len(self.index), value)\n        value = maybe_cast_to_datetime(value, infer_dtype)\n\n    # return internal types directly\n    if is_extension_array_dtype(value):\n        return value\n\n    # broadcast across multiple columns if necessary\n    if broadcast and key in self.columns and value.ndim == 1:\n        if not self.columns.is_unique or isinstance(self.columns, ABCMultiIndex):\n            existing_piece = self[key]\n            if isinstance(existing_piece, DataFrame):\n                value = np.tile(value, (len(existing_piece.columns), 1))\n\n    return np.atleast_2d(np.asarray(value))",
                "@property\ndef _series(self):\n    return {\n        item: Series(self._data.iget(idx), index=self.index, name=item)\n        for idx, item in enumerate(self.columns)\n    }",
                "def lookup(self, row_labels, col_labels) -> np.ndarray:\n    \"\"\"\n    Label-based \"fancy indexing\" function for DataFrame.\n\n    Given equal-length arrays of row and column labels, return an\n    array of the values corresponding to each (row, col) pair.\n\n    Parameters\n    ----------\n    row_labels : sequence\n        The row labels to use for lookup.\n    col_labels : sequence\n        The column labels to use for lookup.\n\n    Returns\n    -------\n    numpy.ndarray\n        The found values.\n    \"\"\"\n    n = len(row_labels)\n    if n != len(col_labels):\n        raise ValueError(\"Row labels must have same size as column labels\")\n\n    thresh = 1000\n    if not self._is_mixed_type or n > thresh:\n        values = self.values\n        ridx = self.index.get_indexer(row_labels)\n        cidx = self.columns.get_indexer(col_labels)\n        if (ridx == -1).any():\n            raise KeyError(\"One or more row labels was not found\")\n        if (cidx == -1).any():\n            raise KeyError(\"One or more column labels was not found\")\n        flat_index = ridx * len(self.columns) + cidx\n        result = values.flat[flat_index]\n    else:\n        result = np.empty(n, dtype=\"O\")\n        for i, (r, c) in enumerate(zip(row_labels, col_labels)):\n            result[i] = self._get_value(r, c)\n\n    if is_object_dtype(result):\n        result = lib.maybe_convert_objects(result)\n\n    return result",
                "def _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy):\n    frame = self\n\n    columns = axes[\"columns\"]\n    if columns is not None:\n        frame = frame._reindex_columns(\n            columns, method, copy, level, fill_value, limit, tolerance\n        )\n\n    index = axes[\"index\"]\n    if index is not None:\n        frame = frame._reindex_index(\n            index, method, copy, level, fill_value, limit, tolerance\n        )\n\n    return frame",
                "def _reindex_index(\n    self,\n    new_index,\n    method,\n    copy,\n    level,\n    fill_value=np.nan,\n    limit=None,\n    tolerance=None,\n):\n    new_index, indexer = self.index.reindex(\n        new_index, method=method, level=level, limit=limit, tolerance=tolerance\n    )\n    return self._reindex_with_indexers(\n        {0: [new_index, indexer]},\n        copy=copy,\n        fill_value=fill_value,\n        allow_dups=False,\n    )",
                "def _reindex_columns(\n    self,\n    new_columns,\n    method,\n    copy,\n    level,\n    fill_value=None,\n    limit=None,\n    tolerance=None,\n):\n    new_columns, indexer = self.columns.reindex(\n        new_columns, method=method, level=level, limit=limit, tolerance=tolerance\n    )\n    return self._reindex_with_indexers(\n        {1: [new_columns, indexer]},\n        copy=copy,\n        fill_value=fill_value,\n        allow_dups=False,\n    )",
                "def _reindex_multi(self, axes, copy, fill_value) -> \"DataFrame\":\n    \"\"\"\n    We are guaranteed non-Nones in the axes.\n    \"\"\"\n    new_index, row_indexer = self.index.reindex(axes[\"index\"])\n    new_columns, col_indexer = self.columns.reindex(axes[\"columns\"])\n\n    if row_indexer is not None and col_indexer is not None:\n        indexer = row_indexer, col_indexer\n        new_values = algorithms.take_2d_multi(\n            self.values, indexer, fill_value=fill_value\n        )\n        return self._constructor(new_values, index=new_index, columns=new_columns)\n    else:\n        return self._reindex_with_indexers(\n            {0: [new_index, row_indexer], 1: [new_columns, col_indexer]},\n            copy=copy,\n            fill_value=fill_value,\n        )",
                "@Appender(_shared_docs[\"align\"] % _shared_doc_kwargs)\ndef align(\n    self,\n    other,\n    join=\"outer\",\n    axis=None,\n    level=None,\n    copy=True,\n    fill_value=None,\n    method=None,\n    limit=None,\n    fill_axis=0,\n    broadcast_axis=None,\n) -> \"DataFrame\":\n    return super().align(\n        other,\n        join=join,\n        axis=axis,\n        level=level,\n        copy=copy,\n        fill_value=fill_value,\n        method=method,\n        limit=limit,\n        fill_axis=fill_axis,\n        broadcast_axis=broadcast_axis,\n    )",
                "@Appender(\n    \"\"\"\n    Examples\n    --------\n    >>> df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n\n    Change the row labels.\n\n    >>> df.set_axis(['a', 'b', 'c'], axis='index')\n       A  B\n    a  1  4\n    b  2  5\n    c  3  6\n\n    Change the column labels.\n\n    >>> df.set_axis(['I', 'II'], axis='columns')\n       I  II\n    0  1   4\n    1  2   5\n    2  3   6\n\n    Now, update the labels inplace.\n\n    >>> df.set_axis(['i', 'ii'], axis='columns', inplace=True)\n    >>> df\n       i  ii\n    0  1   4\n    1  2   5\n    2  3   6\n    \"\"\"\n)\n@Substitution(\n    **_shared_doc_kwargs,\n    extended_summary_sub=\" column or\",\n    axis_description_sub=\", and 1 identifies the columns\",\n    see_also_sub=\" or columns\",\n)\n@Appender(NDFrame.set_axis.__doc__)\ndef set_axis(self, labels, axis: Axis = 0, inplace: bool = False):\n    return super().set_axis(labels, axis=axis, inplace=inplace)",
                "@Substitution(**_shared_doc_kwargs)\n@Appender(NDFrame.reindex.__doc__)\n@rewrite_axis_style_signature(\n    \"labels\",\n    [\n        (\"method\", None),\n        (\"copy\", True),\n        (\"level\", None),\n        (\"fill_value\", np.nan),\n        (\"limit\", None),\n        (\"tolerance\", None),\n    ],\n)\ndef reindex(self, *args, **kwargs) -> \"DataFrame\":\n    axes = validate_axis_style_args(self, args, kwargs, \"labels\", \"reindex\")\n    kwargs.update(axes)\n    # Pop these, since the values are in `kwargs` under different names\n    kwargs.pop(\"axis\", None)\n    kwargs.pop(\"labels\", None)\n    return super().reindex(**kwargs)",
                "def drop(\n    self,\n    labels=None,\n    axis=0,\n    index=None,\n    columns=None,\n    level=None,\n    inplace=False,\n    errors=\"raise\",\n):\n    \"\"\"\n    Drop specified labels from rows or columns.\n\n    Remove rows or columns by specifying label names and corresponding\n    axis, or by specifying directly index or column names. When using a\n    multi-index, labels on different levels can be removed by specifying\n    the level.\n\n    Parameters\n    ----------\n    labels : single label or list-like\n        Index or column labels to drop.\n    axis : {0 or 'index', 1 or 'columns'}, default 0\n        Whether to drop labels from the index (0 or 'index') or\n        columns (1 or 'columns').\n    index : single label or list-like\n        Alternative to specifying axis (``labels, axis=0``\n        is equivalent to ``index=labels``).\n\n        .. versionadded:: 0.21.0\n    columns : single label or list-like\n        Alternative to specifying axis (``labels, axis=1``\n        is equivalent to ``columns=labels``).\n\n        .. versionadded:: 0.21.0\n    level : int or level name, optional\n        For MultiIndex, level from which the labels will be removed.\n    inplace : bool, default False\n        If True, do operation inplace and return None.\n    errors : {'ignore', 'raise'}, default 'raise'\n        If 'ignore', suppress error and only existing labels are\n        dropped.\n\n    Returns\n    -------\n    DataFrame\n        DataFrame without the removed index or column labels.\n\n    Raises\n    ------\n    KeyError\n        If any of the labels is not found in the selected axis.\n\n    See Also\n    --------\n    DataFrame.loc : Label-location based indexer for selection by label.\n    DataFrame.dropna : Return DataFrame with labels on given axis omitted\n        where (all or any) data are missing.\n    DataFrame.drop_duplicates : Return DataFrame with duplicate rows\n        removed, optionally only considering certain columns.\n    Series.drop : Return Series with specified index labels removed.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame(np.arange(12).reshape(3, 4),\n    ...                   columns=['A', 'B', 'C', 'D'])\n    >>> df\n       A  B   C   D\n    0  0  1   2   3\n    1  4  5   6   7\n    2  8  9  10  11\n\n    Drop columns\n\n    >>> df.drop(['B', 'C'], axis=1)\n       A   D\n    0  0   3\n    1  4   7\n    2  8  11\n\n    >>> df.drop(columns=['B', 'C'])\n       A   D\n    0  0   3\n    1  4   7\n    2  8  11\n\n    Drop a row by index\n\n    >>> df.drop([0, 1])\n       A  B   C   D\n    2  8  9  10  11\n\n    Drop columns and/or rows of MultiIndex DataFrame\n\n    >>> midx = pd.MultiIndex(levels=[['lama', 'cow', 'falcon'],\n    ...                              ['speed', 'weight', 'length']],\n    ...                      codes=[[0, 0, 0, 1, 1, 1, 2, 2, 2],\n    ...                             [0, 1, 2, 0, 1, 2, 0, 1, 2]])\n    >>> df = pd.DataFrame(index=midx, columns=['big', 'small'],\n    ...                   data=[[45, 30], [200, 100], [1.5, 1], [30, 20],\n    ...                         [250, 150], [1.5, 0.8], [320, 250],\n    ...                         [1, 0.8], [0.3, 0.2]])\n    >>> df\n                    big     small\n    lama    speed   45.0    30.0\n            weight  200.0   100.0\n            length  1.5     1.0\n    cow     speed   30.0    20.0\n            weight  250.0   150.0\n            length  1.5     0.8\n    falcon  speed   320.0   250.0\n            weight  1.0     0.8\n            length  0.3     0.2\n\n    >>> df.drop(index='cow', columns='small')\n                    big\n    lama    speed   45.0\n            weight  200.0\n            length  1.5\n    falcon  speed   320.0\n            weight  1.0\n            length  0.3\n\n    >>> df.drop(index='length', level=1)\n                    big     small\n    lama    speed   45.0    30.0\n            weight  200.0   100.0\n    cow     speed   30.0    20.0\n            weight  250.0   150.0\n    falcon  speed   320.0   250.0\n            weight  1.0     0.8\n    \"\"\"\n    return super().drop(\n        labels=labels,\n        axis=axis,\n        index=index,\n        columns=columns,\n        level=level,\n        inplace=inplace,\n        errors=errors,\n    )",
                "@rewrite_axis_style_signature(\n    \"mapper\",\n    [(\"copy\", True), (\"inplace\", False), (\"level\", None), (\"errors\", \"ignore\")],\n)\ndef rename(\n    self,\n    mapper: Optional[Renamer] = None,\n    *,\n    index: Optional[Renamer] = None,\n    columns: Optional[Renamer] = None,\n    axis: Optional[Axis] = None,\n    copy: bool = True,\n    inplace: bool = False,\n    level: Optional[Level] = None,\n    errors: str = \"ignore\",\n) -> Optional[\"DataFrame\"]:\n    \"\"\"\n    Alter axes labels.\n\n    Function / dict values must be unique (1-to-1). Labels not contained in\n    a dict / Series will be left as-is. Extra labels listed don't throw an\n    error.\n\n    See the :ref:`user guide <basics.rename>` for more.\n\n    Parameters\n    ----------\n    mapper : dict-like or function\n        Dict-like or functions transformations to apply to\n        that axis' values. Use either ``mapper`` and ``axis`` to\n        specify the axis to target with ``mapper``, or ``index`` and\n        ``columns``.\n    index : dict-like or function\n        Alternative to specifying axis (``mapper, axis=0``\n        is equivalent to ``index=mapper``).\n    columns : dict-like or function\n        Alternative to specifying axis (``mapper, axis=1``\n        is equivalent to ``columns=mapper``).\n    axis : int or str\n        Axis to target with ``mapper``. Can be either the axis name\n        ('index', 'columns') or number (0, 1). The default is 'index'.\n    copy : bool, default True\n        Also copy underlying data.\n    inplace : bool, default False\n        Whether to return a new DataFrame. If True then value of copy is\n        ignored.\n    level : int or level name, default None\n        In case of a MultiIndex, only rename labels in the specified\n        level.\n    errors : {'ignore', 'raise'}, default 'ignore'\n        If 'raise', raise a `KeyError` when a dict-like `mapper`, `index`,\n        or `columns` contains labels that are not present in the Index\n        being transformed.\n        If 'ignore', existing keys will be renamed and extra keys will be\n        ignored.\n\n    Returns\n    -------\n    DataFrame\n        DataFrame with the renamed axis labels.\n\n    Raises\n    ------\n    KeyError\n        If any of the labels is not found in the selected axis and\n        \"errors='raise'\".\n\n    See Also\n    --------\n    DataFrame.rename_axis : Set the name of the axis.\n\n    Examples\n    --------\n    ``DataFrame.rename`` supports two calling conventions\n\n    * ``(index=index_mapper, columns=columns_mapper, ...)``\n    * ``(mapper, axis={'index', 'columns'}, ...)``\n\n    We *highly* recommend using keyword arguments to clarify your\n    intent.\n\n    Rename columns using a mapping:\n\n    >>> df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n    >>> df.rename(columns={\"A\": \"a\", \"B\": \"c\"})\n       a  c\n    0  1  4\n    1  2  5\n    2  3  6\n\n    Rename index using a mapping:\n\n    >>> df.rename(index={0: \"x\", 1: \"y\", 2: \"z\"})\n       A  B\n    x  1  4\n    y  2  5\n    z  3  6\n\n    Cast index labels to a different type:\n\n    >>> df.index\n    RangeIndex(start=0, stop=3, step=1)\n    >>> df.rename(index=str).index\n    Index(['0', '1', '2'], dtype='object')\n\n    >>> df.rename(columns={\"A\": \"a\", \"B\": \"b\", \"C\": \"c\"}, errors=\"raise\")\n    Traceback (most recent call last):\n    KeyError: ['C'] not found in axis\n\n    Using axis-style parameters\n\n    >>> df.rename(str.lower, axis='columns')\n       a  b\n    0  1  4\n    1  2  5\n    2  3  6\n\n    >>> df.rename({1: 2, 2: 4}, axis='index')\n       A  B\n    0  1  4\n    2  2  5\n    4  3  6\n    \"\"\"\n    return super().rename(\n        mapper=mapper,\n        index=index,\n        columns=columns,\n        axis=axis,\n        copy=copy,\n        inplace=inplace,\n        level=level,\n        errors=errors,\n    )",
                "@doc(NDFrame.fillna, **_shared_doc_kwargs)\ndef fillna(\n    self,\n    value=None,\n    method=None,\n    axis=None,\n    inplace=False,\n    limit=None,\n    downcast=None,\n) -> Optional[\"DataFrame\"]:\n    return super().fillna(\n        value=value,\n        method=method,\n        axis=axis,\n        inplace=inplace,\n        limit=limit,\n        downcast=downcast,\n    )",
                "@Appender(_shared_docs[\"replace\"] % _shared_doc_kwargs)\ndef replace(\n    self,\n    to_replace=None,\n    value=None,\n    inplace=False,\n    limit=None,\n    regex=False,\n    method=\"pad\",\n):\n    return super().replace(\n        to_replace=to_replace,\n        value=value,\n        inplace=inplace,\n        limit=limit,\n        regex=regex,\n        method=method,\n    )",
                "@Appender(_shared_docs[\"shift\"] % _shared_doc_kwargs)\ndef shift(self, periods=1, freq=None, axis=0, fill_value=None) -> \"DataFrame\":\n    return super().shift(\n        periods=periods, freq=freq, axis=axis, fill_value=fill_value\n    )",
                "def set_index(\n    self, keys, drop=True, append=False, inplace=False, verify_integrity=False\n):\n    \"\"\"\n    Set the DataFrame index using existing columns.\n\n    Set the DataFrame index (row labels) using one or more existing\n    columns or arrays (of the correct length). The index can replace the\n    existing index or expand on it.\n\n    Parameters\n    ----------\n    keys : label or array-like or list of labels/arrays\n        This parameter can be either a single column key, a single array of\n        the same length as the calling DataFrame, or a list containing an\n        arbitrary combination of column keys and arrays. Here, \"array\"\n        encompasses :class:`Series`, :class:`Index`, ``np.ndarray``, and\n        instances of :class:`~collections.abc.Iterator`.\n    drop : bool, default True\n        Delete columns to be used as the new index.\n    append : bool, default False\n        Whether to append columns to existing index.\n    inplace : bool, default False\n        Modify the DataFrame in place (do not create a new object).\n    verify_integrity : bool, default False\n        Check the new index for duplicates. Otherwise defer the check until\n        necessary. Setting to False will improve the performance of this\n        method.\n\n    Returns\n    -------\n    DataFrame\n        Changed row labels.\n\n    See Also\n    --------\n    DataFrame.reset_index : Opposite of set_index.\n    DataFrame.reindex : Change to new indices or expand indices.\n    DataFrame.reindex_like : Change to same indices as other DataFrame.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame({'month': [1, 4, 7, 10],\n    ...                    'year': [2012, 2014, 2013, 2014],\n    ...                    'sale': [55, 40, 84, 31]})\n    >>> df\n       month  year  sale\n    0      1  2012    55\n    1      4  2014    40\n    2      7  2013    84\n    3     10  2014    31\n\n    Set the index to become the 'month' column:\n\n    >>> df.set_index('month')\n           year  sale\n    month\n    1      2012    55\n    4      2014    40\n    7      2013    84\n    10     2014    31\n\n    Create a MultiIndex using columns 'year' and 'month':\n\n    >>> df.set_index(['year', 'month'])\n                sale\n    year  month\n    2012  1     55\n    2014  4     40\n    2013  7     84\n    2014  10    31\n\n    Create a MultiIndex using an Index and a column:\n\n    >>> df.set_index([pd.Index([1, 2, 3, 4]), 'year'])\n             month  sale\n       year\n    1  2012  1      55\n    2  2014  4      40\n    3  2013  7      84\n    4  2014  10     31\n\n    Create a MultiIndex using two Series:\n\n    >>> s = pd.Series([1, 2, 3, 4])\n    >>> df.set_index([s, s**2])\n          month  year  sale\n    1 1       1  2012    55\n    2 4       4  2014    40\n    3 9       7  2013    84\n    4 16     10  2014    31\n    \"\"\"\n    inplace = validate_bool_kwarg(inplace, \"inplace\")\n    if not isinstance(keys, list):\n        keys = [keys]\n\n    err_msg = (\n        'The parameter \"keys\" may be a column key, one-dimensional '\n        \"array, or a list containing only valid column keys and \"\n        \"one-dimensional arrays.\"\n    )\n\n    missing: List[Label] = []\n    for col in keys:\n        if isinstance(\n            col, (ABCIndexClass, ABCSeries, np.ndarray, list, abc.Iterator)\n        ):\n            # arrays are fine as long as they are one-dimensional\n            # iterators get converted to list below\n            if getattr(col, \"ndim\", 1) != 1:\n                raise ValueError(err_msg)\n        else:\n            # everything else gets tried as a key; see GH 24969\n            try:\n                found = col in self.columns\n            except TypeError as err:\n                raise TypeError(\n                    f\"{err_msg}. Received column of type {type(col)}\"\n                ) from err\n            else:\n                if not found:\n                    missing.append(col)\n\n    if missing:\n        raise KeyError(f\"None of {missing} are in the columns\")\n\n    if inplace:\n        frame = self\n    else:\n        frame = self.copy()\n\n    arrays = []\n    names = []\n    if append:\n        names = list(self.index.names)\n        if isinstance(self.index, ABCMultiIndex):\n            for i in range(self.index.nlevels):\n                arrays.append(self.index._get_level_values(i))\n        else:\n            arrays.append(self.index)\n\n    to_remove: List[Label] = []\n    for col in keys:\n        if isinstance(col, ABCMultiIndex):\n            for n in range(col.nlevels):\n                arrays.append(col._get_level_values(n))\n            names.extend(col.names)\n        elif isinstance(col, (ABCIndexClass, ABCSeries)):\n            # if Index then not MultiIndex (treated above)\n            arrays.append(col)\n            names.append(col.name)\n        elif isinstance(col, (list, np.ndarray)):\n            arrays.append(col)\n            names.append(None)\n        elif isinstance(col, abc.Iterator):\n            arrays.append(list(col))\n            names.append(None)\n        # from here, col can only be a column label\n        else:\n            arrays.append(frame[col]._values)\n            names.append(col)\n            if drop:\n                to_remove.append(col)\n\n        if len(arrays[-1]) != len(self):\n            # check newest element against length of calling frame, since\n            # ensure_index_from_sequences would not raise for append=False.\n            raise ValueError(\n                f\"Length mismatch: Expected {len(self)} rows, \"\n                f\"received array of length {len(arrays[-1])}\"\n            )\n\n    index = ensure_index_from_sequences(arrays, names)\n\n    if verify_integrity and not index.is_unique:\n        duplicates = index[index.duplicated()].unique()\n        raise ValueError(f\"Index has duplicate keys: {duplicates}\")\n\n    # use set to handle duplicate column names gracefully in case of drop\n    for c in set(to_remove):\n        del frame[c]\n\n    # clear up memory usage\n    index._cleanup()\n\n    frame.index = index\n\n    if not inplace:\n        return frame",
                "def reset_index(\n    self,\n    level: Optional[Union[Hashable, Sequence[Hashable]]] = None,\n    drop: bool = False,\n    inplace: bool = False,\n    col_level: Hashable = 0,\n    col_fill: Label = \"\",\n) -> Optional[\"DataFrame\"]:\n    \"\"\"\n    Reset the index, or a level of it.\n\n    Reset the index of the DataFrame, and use the default one instead.\n    If the DataFrame has a MultiIndex, this method can remove one or more\n    levels.\n\n    Parameters\n    ----------\n    level : int, str, tuple, or list, default None\n        Only remove the given levels from the index. Removes all levels by\n        default.\n    drop : bool, default False\n        Do not try to insert index into dataframe columns. This resets\n        the index to the default integer index.\n    inplace : bool, default False\n        Modify the DataFrame in place (do not create a new object).\n    col_level : int or str, default 0\n        If the columns have multiple levels, determines which level the\n        labels are inserted into. By default it is inserted into the first\n        level.\n    col_fill : object, default ''\n        If the columns have multiple levels, determines how the other\n        levels are named. If None then the index name is repeated.\n\n    Returns\n    -------\n    DataFrame or None\n        DataFrame with the new index or None if ``inplace=True``.\n\n    See Also\n    --------\n    DataFrame.set_index : Opposite of reset_index.\n    DataFrame.reindex : Change to new indices or expand indices.\n    DataFrame.reindex_like : Change to same indices as other DataFrame.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame([('bird', 389.0),\n    ...                    ('bird', 24.0),\n    ...                    ('mammal', 80.5),\n    ...                    ('mammal', np.nan)],\n    ...                   index=['falcon', 'parrot', 'lion', 'monkey'],\n    ...                   columns=('class', 'max_speed'))\n    >>> df\n             class  max_speed\n    falcon    bird      389.0\n    parrot    bird       24.0\n    lion    mammal       80.5\n    monkey  mammal        NaN\n\n    When we reset the index, the old index is added as a column, and a\n    new sequential index is used:\n\n    >>> df.reset_index()\n        index   class  max_speed\n    0  falcon    bird      389.0\n    1  parrot    bird       24.0\n    2    lion  mammal       80.5\n    3  monkey  mammal        NaN\n\n    We can use the `drop` parameter to avoid the old index being added as\n    a column:\n\n    >>> df.reset_index(drop=True)\n        class  max_speed\n    0    bird      389.0\n    1    bird       24.0\n    2  mammal       80.5\n    3  mammal        NaN\n\n    You can also use `reset_index` with `MultiIndex`.\n\n    >>> index = pd.MultiIndex.from_tuples([('bird', 'falcon'),\n    ...                                    ('bird', 'parrot'),\n    ...                                    ('mammal', 'lion'),\n    ...                                    ('mammal', 'monkey')],\n    ...                                   names=['class', 'name'])\n    >>> columns = pd.MultiIndex.from_tuples([('speed', 'max'),\n    ...                                      ('species', 'type')])\n    >>> df = pd.DataFrame([(389.0, 'fly'),\n    ...                    ( 24.0, 'fly'),\n    ...                    ( 80.5, 'run'),\n    ...                    (np.nan, 'jump')],\n    ...                   index=index,\n    ...                   columns=columns)\n    >>> df\n                   speed species\n                     max    type\n    class  name\n    bird   falcon  389.0     fly\n           parrot   24.0     fly\n    mammal lion     80.5     run\n           monkey    NaN    jump\n\n    If the index has multiple levels, we can reset a subset of them:\n\n    >>> df.reset_index(level='class')\n             class  speed species\n                      max    type\n    name\n    falcon    bird  389.0     fly\n    parrot    bird   24.0     fly\n    lion    mammal   80.5     run\n    monkey  mammal    NaN    jump\n\n    If we are not dropping the index, by default, it is placed in the top\n    level. We can place it in another level:\n\n    >>> df.reset_index(level='class', col_level=1)\n                    speed species\n             class    max    type\n    name\n    falcon    bird  389.0     fly\n    parrot    bird   24.0     fly\n    lion    mammal   80.5     run\n    monkey  mammal    NaN    jump\n\n    When the index is inserted under another level, we can specify under\n    which one with the parameter `col_fill`:\n\n    >>> df.reset_index(level='class', col_level=1, col_fill='species')\n                  species  speed species\n                    class    max    type\n    name\n    falcon           bird  389.0     fly\n    parrot           bird   24.0     fly\n    lion           mammal   80.5     run\n    monkey         mammal    NaN    jump\n\n    If we specify a nonexistent level for `col_fill`, it is created:\n\n    >>> df.reset_index(level='class', col_level=1, col_fill='genus')\n                    genus  speed species\n                    class    max    type\n    name\n    falcon           bird  389.0     fly\n    parrot           bird   24.0     fly\n    lion           mammal   80.5     run\n    monkey         mammal    NaN    jump\n    \"\"\"\n    inplace = validate_bool_kwarg(inplace, \"inplace\")\n    if inplace:\n        new_obj = self\n    else:\n        new_obj = self.copy()\n\n    def _maybe_casted_values(index, labels=None):\n        values = index._values\n        if not isinstance(index, (PeriodIndex, DatetimeIndex)):\n            if values.dtype == np.object_:\n                values = lib.maybe_convert_objects(values)\n\n        # if we have the labels, extract the values with a mask\n        if labels is not None:\n            mask = labels == -1\n\n            # we can have situations where the whole mask is -1,\n            # meaning there is nothing found in labels, so make all nan's\n            if mask.all():\n                values = np.empty(len(mask))\n                values.fill(np.nan)\n            else:\n                values = values.take(labels)\n\n                # TODO(https://github.com/pandas-dev/pandas/issues/24206)\n                # Push this into maybe_upcast_putmask?\n                # We can't pass EAs there right now. Looks a bit\n                # complicated.\n                # So we unbox the ndarray_values, op, re-box.\n                values_type = type(values)\n                values_dtype = values.dtype\n\n                if issubclass(values_type, DatetimeLikeArray):\n                    values = values._data\n\n                if mask.any():\n                    values, _ = maybe_upcast_putmask(values, mask, np.nan)\n\n                if issubclass(values_type, DatetimeLikeArray):\n                    values = values_type(values, dtype=values_dtype)\n\n        return values\n\n    new_index = ibase.default_index(len(new_obj))\n    if level is not None:\n        if not isinstance(level, (tuple, list)):\n            level = [level]\n        level = [self.index._get_level_number(lev) for lev in level]\n        if len(level) < self.index.nlevels:\n            new_index = self.index.droplevel(level)\n\n    if not drop:\n        to_insert: Iterable[Tuple[Any, Optional[Any]]]\n        if isinstance(self.index, ABCMultiIndex):\n            names = [\n                (n if n is not None else f\"level_{i}\")\n                for i, n in enumerate(self.index.names)\n            ]\n            to_insert = zip(self.index.levels, self.index.codes)\n        else:\n            default = \"index\" if \"index\" not in self else \"level_0\"\n            names = [default] if self.index.name is None else [self.index.name]\n            to_insert = ((self.index, None),)\n\n        multi_col = isinstance(self.columns, ABCMultiIndex)\n        for i, (lev, lab) in reversed(list(enumerate(to_insert))):\n            if not (level is None or i in level):\n                continue\n            name = names[i]\n            if multi_col:\n                col_name = list(name) if isinstance(name, tuple) else [name]\n                if col_fill is None:\n                    if len(col_name) not in (1, self.columns.nlevels):\n                        raise ValueError(\n                            \"col_fill=None is incompatible \"\n                            f\"with incomplete column name {name}\"\n                        )\n                    col_fill = col_name[0]\n\n                lev_num = self.columns._get_level_number(col_level)\n                name_lst = [col_fill] * lev_num + col_name\n                missing = self.columns.nlevels - len(name_lst)\n                name_lst += [col_fill] * missing\n                name = tuple(name_lst)\n            # to ndarray and maybe infer different dtype\n            level_values = _maybe_casted_values(lev, lab)\n            new_obj.insert(0, name, level_values)\n\n    new_obj.index = new_index\n    if not inplace:\n        return new_obj\n\n    return None",
                "@Appender(_shared_docs[\"isna\"] % _shared_doc_kwargs)\ndef isna(self) -> \"DataFrame\":\n    return super().isna()",
                "@Appender(_shared_docs[\"isna\"] % _shared_doc_kwargs)\ndef isnull(self) -> \"DataFrame\":\n    return super().isnull()",
                "@Appender(_shared_docs[\"notna\"] % _shared_doc_kwargs)\ndef notna(self) -> \"DataFrame\":\n    return super().notna()",
                "@Appender(_shared_docs[\"notna\"] % _shared_doc_kwargs)\ndef notnull(self) -> \"DataFrame\":\n    return super().notnull()",
                "def dropna(self, axis=0, how=\"any\", thresh=None, subset=None, inplace=False):\n    \"\"\"\n    Remove missing values.\n\n    See the :ref:`User Guide <missing_data>` for more on which values are\n    considered missing, and how to work with missing data.\n\n    Parameters\n    ----------\n    axis : {0 or 'index', 1 or 'columns'}, default 0\n        Determine if rows or columns which contain missing values are\n        removed.\n\n        * 0, or 'index' : Drop rows which contain missing values.\n        * 1, or 'columns' : Drop columns which contain missing value.\n\n        .. versionchanged:: 1.0.0\n\n           Pass tuple or list to drop on multiple axes.\n           Only a single axis is allowed.\n\n    how : {'any', 'all'}, default 'any'\n        Determine if row or column is removed from DataFrame, when we have\n        at least one NA or all NA.\n\n        * 'any' : If any NA values are present, drop that row or column.\n        * 'all' : If all values are NA, drop that row or column.\n\n    thresh : int, optional\n        Require that many non-NA values.\n    subset : array-like, optional\n        Labels along other axis to consider, e.g. if you are dropping rows\n        these would be a list of columns to include.\n    inplace : bool, default False\n        If True, do operation inplace and return None.\n\n    Returns\n    -------\n    DataFrame\n        DataFrame with NA entries dropped from it.\n\n    See Also\n    --------\n    DataFrame.isna: Indicate missing values.\n    DataFrame.notna : Indicate existing (non-missing) values.\n    DataFrame.fillna : Replace missing values.\n    Series.dropna : Drop missing values.\n    Index.dropna : Drop missing indices.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame({\"name\": ['Alfred', 'Batman', 'Catwoman'],\n    ...                    \"toy\": [np.nan, 'Batmobile', 'Bullwhip'],\n    ...                    \"born\": [pd.NaT, pd.Timestamp(\"1940-04-25\"),\n    ...                             pd.NaT]})\n    >>> df\n           name        toy       born\n    0    Alfred        NaN        NaT\n    1    Batman  Batmobile 1940-04-25\n    2  Catwoman   Bullwhip        NaT\n\n    Drop the rows where at least one element is missing.\n\n    >>> df.dropna()\n         name        toy       born\n    1  Batman  Batmobile 1940-04-25\n\n    Drop the columns where at least one element is missing.\n\n    >>> df.dropna(axis='columns')\n           name\n    0    Alfred\n    1    Batman\n    2  Catwoman\n\n    Drop the rows where all elements are missing.\n\n    >>> df.dropna(how='all')\n           name        toy       born\n    0    Alfred        NaN        NaT\n    1    Batman  Batmobile 1940-04-25\n    2  Catwoman   Bullwhip        NaT\n\n    Keep only the rows with at least 2 non-NA values.\n\n    >>> df.dropna(thresh=2)\n           name        toy       born\n    1    Batman  Batmobile 1940-04-25\n    2  Catwoman   Bullwhip        NaT\n\n    Define in which columns to look for missing values.\n\n    >>> df.dropna(subset=['name', 'born'])\n           name        toy       born\n    1    Batman  Batmobile 1940-04-25\n\n    Keep the DataFrame with valid entries in the same variable.\n\n    >>> df.dropna(inplace=True)\n    >>> df\n         name        toy       born\n    1  Batman  Batmobile 1940-04-25\n    \"\"\"\n    inplace = validate_bool_kwarg(inplace, \"inplace\")\n    if isinstance(axis, (tuple, list)):\n        # GH20987\n        raise TypeError(\"supplying multiple axes to axis is no longer supported.\")\n\n    axis = self._get_axis_number(axis)\n    agg_axis = 1 - axis\n\n    agg_obj = self\n    if subset is not None:\n        ax = self._get_axis(agg_axis)\n        indices = ax.get_indexer_for(subset)\n        check = indices == -1\n        if check.any():\n            raise KeyError(list(np.compress(check, subset)))\n        agg_obj = self.take(indices, axis=agg_axis)\n\n    count = agg_obj.count(axis=agg_axis)\n\n    if thresh is not None:\n        mask = count >= thresh\n    elif how == \"any\":\n        mask = count == len(agg_obj._get_axis(agg_axis))\n    elif how == \"all\":\n        mask = count > 0\n    else:\n        if how is not None:\n            raise ValueError(f\"invalid how option: {how}\")\n        else:\n            raise TypeError(\"must specify how or thresh\")\n\n    result = self.loc(axis=axis)[mask]\n\n    if inplace:\n        self._update_inplace(result)\n    else:\n        return result",
                "def drop_duplicates(\n    self,\n    subset: Optional[Union[Hashable, Sequence[Hashable]]] = None,\n    keep: Union[str, bool] = \"first\",\n    inplace: bool = False,\n    ignore_index: bool = False,\n) -> Optional[\"DataFrame\"]:\n    \"\"\"\n    Return DataFrame with duplicate rows removed.\n\n    Considering certain columns is optional. Indexes, including time indexes\n    are ignored.\n\n    Parameters\n    ----------\n    subset : column label or sequence of labels, optional\n        Only consider certain columns for identifying duplicates, by\n        default use all of the columns.\n    keep : {'first', 'last', False}, default 'first'\n        Determines which duplicates (if any) to keep.\n        - ``first`` : Drop duplicates except for the first occurrence.\n        - ``last`` : Drop duplicates except for the last occurrence.\n        - False : Drop all duplicates.\n    inplace : bool, default False\n        Whether to drop duplicates in place or to return a copy.\n    ignore_index : bool, default False\n        If True, the resulting axis will be labeled 0, 1, \u2026, n - 1.\n\n        .. versionadded:: 1.0.0\n\n    Returns\n    -------\n    DataFrame\n        DataFrame with duplicates removed or None if ``inplace=True``.\n\n    See Also\n    --------\n    DataFrame.value_counts: Count unique combinations of columns.\n    \"\"\"\n    if self.empty:\n        return self.copy()\n\n    inplace = validate_bool_kwarg(inplace, \"inplace\")\n    duplicated = self.duplicated(subset, keep=keep)\n\n    if inplace:\n        (inds,) = np.asarray(-duplicated).nonzero()\n        new_data = self._data.take(inds)\n\n        if ignore_index:\n            new_data.axes[1] = ibase.default_index(len(inds))\n        self._update_inplace(new_data)\n    else:\n        result = self[-duplicated]\n\n        if ignore_index:\n            result.index = ibase.default_index(len(result))\n        return result\n\n    return None",
                "def duplicated(\n    self,\n    subset: Optional[Union[Hashable, Sequence[Hashable]]] = None,\n    keep: Union[str, bool] = \"first\",\n) -> \"Series\":\n    \"\"\"\n    Return boolean Series denoting duplicate rows.\n\n    Considering certain columns is optional.\n\n    Parameters\n    ----------\n    subset : column label or sequence of labels, optional\n        Only consider certain columns for identifying duplicates, by\n        default use all of the columns.\n    keep : {'first', 'last', False}, default 'first'\n        Determines which duplicates (if any) to mark.\n\n        - ``first`` : Mark duplicates as ``True`` except for the first occurrence.\n        - ``last`` : Mark duplicates as ``True`` except for the last occurrence.\n        - False : Mark all duplicates as ``True``.\n\n    Returns\n    -------\n    Series\n    \"\"\"\n    from pandas.core.sorting import get_group_index\n    from pandas._libs.hashtable import duplicated_int64, _SIZE_HINT_LIMIT\n\n    if self.empty:\n        return Series(dtype=bool)\n\n    def f(vals):\n        labels, shape = algorithms.factorize(\n            vals, size_hint=min(len(self), _SIZE_HINT_LIMIT)\n        )\n        return labels.astype(\"i8\", copy=False), len(shape)\n\n    if subset is None:\n        subset = self.columns\n    elif (\n        not np.iterable(subset)\n        or isinstance(subset, str)\n        or isinstance(subset, tuple)\n        and subset in self.columns\n    ):\n        subset = (subset,)\n\n    #  needed for mypy since can't narrow types using np.iterable\n    subset = cast(Iterable, subset)\n\n    # Verify all columns in subset exist in the queried dataframe\n    # Otherwise, raise a KeyError, same as if you try to __getitem__ with a\n    # key that doesn't exist.\n    diff = Index(subset).difference(self.columns)\n    if not diff.empty:\n        raise KeyError(diff)\n\n    vals = (col.values for name, col in self.items() if name in subset)\n    labels, shape = map(list, zip(*map(f, vals)))\n\n    ids = get_group_index(labels, shape, sort=False, xnull=False)\n    return Series(duplicated_int64(ids, keep), index=self.index)",
                "@Substitution(**_shared_doc_kwargs)\n@Appender(NDFrame.sort_values.__doc__)\ndef sort_values(\n    self,\n    by,\n    axis=0,\n    ascending=True,\n    inplace=False,\n    kind=\"quicksort\",\n    na_position=\"last\",\n    ignore_index=False,\n):\n    inplace = validate_bool_kwarg(inplace, \"inplace\")\n    axis = self._get_axis_number(axis)\n\n    if not isinstance(by, list):\n        by = [by]\n    if is_sequence(ascending) and len(by) != len(ascending):\n        raise ValueError(\n            f\"Length of ascending ({len(ascending)}) != length of by ({len(by)})\"\n        )\n    if len(by) > 1:\n        from pandas.core.sorting import lexsort_indexer\n\n        keys = [self._get_label_or_level_values(x, axis=axis) for x in by]\n        indexer = lexsort_indexer(keys, orders=ascending, na_position=na_position)\n        indexer = ensure_platform_int(indexer)\n    else:\n        from pandas.core.sorting import nargsort\n\n        by = by[0]\n        k = self._get_label_or_level_values(by, axis=axis)\n\n        if isinstance(ascending, (tuple, list)):\n            ascending = ascending[0]\n\n        indexer = nargsort(\n            k, kind=kind, ascending=ascending, na_position=na_position\n        )\n\n    new_data = self._data.take(\n        indexer, axis=self._get_block_manager_axis(axis), verify=False\n    )\n\n    if ignore_index:\n        new_data.axes[1] = ibase.default_index(len(indexer))\n\n    if inplace:\n        return self._update_inplace(new_data)\n    else:\n        return self._constructor(new_data).__finalize__(self)",
                "def sort_index(\n    self,\n    axis=0,\n    level=None,\n    ascending: bool = True,\n    inplace: bool = False,\n    kind: str = \"quicksort\",\n    na_position: str = \"last\",\n    sort_remaining: bool = True,\n    ignore_index: bool = False,\n):\n    \"\"\"\n    Sort object by labels (along an axis).\n\n    Parameters\n    ----------\n    axis : {0 or 'index', 1 or 'columns'}, default 0\n        The axis along which to sort.  The value 0 identifies the rows,\n        and 1 identifies the columns.\n    level : int or level name or list of ints or list of level names\n        If not None, sort on values in specified index level(s).\n    ascending : bool or list of bools, default True\n        Sort ascending vs. descending. When the index is a MultiIndex the\n        sort direction can be controlled for each level individually.\n    inplace : bool, default False\n        If True, perform operation in-place.\n    kind : {'quicksort', 'mergesort', 'heapsort'}, default 'quicksort'\n        Choice of sorting algorithm. See also ndarray.np.sort for more\n        information.  `mergesort` is the only stable algorithm. For\n        DataFrames, this option is only applied when sorting on a single\n        column or label.\n    na_position : {'first', 'last'}, default 'last'\n        Puts NaNs at the beginning if `first`; `last` puts NaNs at the end.\n        Not implemented for MultiIndex.\n    sort_remaining : bool, default True\n        If True and sorting by level and index is multilevel, sort by other\n        levels too (in order) after sorting by specified level.\n    ignore_index : bool, default False\n        If True, the resulting axis will be labeled 0, 1, \u2026, n - 1.\n\n        .. versionadded:: 1.0.0\n\n    Returns\n    -------\n    sorted_obj : DataFrame or None\n        DataFrame with sorted index if inplace=False, None otherwise.\n    \"\"\"\n    # TODO: this can be combined with Series.sort_index impl as\n    # almost identical\n\n    inplace = validate_bool_kwarg(inplace, \"inplace\")\n\n    axis = self._get_axis_number(axis)\n    labels = self._get_axis(axis)\n\n    # make sure that the axis is lexsorted to start\n    # if not we need to reconstruct to get the correct indexer\n    labels = labels._sort_levels_monotonic()\n    if level is not None:\n\n        new_axis, indexer = labels.sortlevel(\n            level, ascending=ascending, sort_remaining=sort_remaining\n        )\n\n    elif isinstance(labels, ABCMultiIndex):\n        from pandas.core.sorting import lexsort_indexer\n\n        indexer = lexsort_indexer(\n            labels._get_codes_for_sorting(),\n            orders=ascending,\n            na_position=na_position,\n        )\n    else:\n        from pandas.core.sorting import nargsort\n\n        # Check monotonic-ness before sort an index\n        # GH11080\n        if (ascending and labels.is_monotonic_increasing) or (\n            not ascending and labels.is_monotonic_decreasing\n        ):\n            if inplace:\n                return\n            else:\n                return self.copy()\n\n        indexer = nargsort(\n            labels, kind=kind, ascending=ascending, na_position=na_position\n        )\n\n    baxis = self._get_block_manager_axis(axis)\n    new_data = self._data.take(indexer, axis=baxis, verify=False)\n\n    # reconstruct axis if needed\n    new_data.axes[baxis] = new_data.axes[baxis]._sort_levels_monotonic()\n\n    if ignore_index:\n        new_data.axes[1] = ibase.default_index(len(indexer))\n\n    if inplace:\n        return self._update_inplace(new_data)\n    else:\n        return self._constructor(new_data).__finalize__(self)",
                "def value_counts(\n    self,\n    subset: Optional[Sequence[Label]] = None,\n    normalize: bool = False,\n    sort: bool = True,\n    ascending: bool = False,\n):\n    \"\"\"\n    Return a Series containing counts of unique rows in the DataFrame.\n\n    .. versionadded:: 1.1.0\n\n    Parameters\n    ----------\n    subset : list-like, optional\n        Columns to use when counting unique combinations.\n    normalize : bool, default False\n        Return proportions rather than frequencies.\n    sort : bool, default True\n        Sort by frequencies.\n    ascending : bool, default False\n        Sort in ascending order.\n\n    Returns\n    -------\n    Series\n\n    See Also\n    --------\n    Series.value_counts: Equivalent method on Series.\n\n    Notes\n    -----\n    The returned Series will have a MultiIndex with one level per input\n    column. By default, rows that contain any NA values are omitted from\n    the result. By default, the resulting Series will be in descending\n    order so that the first element is the most frequently-occurring row.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame({'num_legs': [2, 4, 4, 6],\n    ...                    'num_wings': [2, 0, 0, 0]},\n    ...                   index=['falcon', 'dog', 'cat', 'ant'])\n    >>> df\n            num_legs  num_wings\n    falcon         2          2\n    dog            4          0\n    cat            4          0\n    ant            6          0\n\n    >>> df.value_counts()\n    num_legs  num_wings\n    4         0            2\n    6         0            1\n    2         2            1\n    dtype: int64\n\n    >>> df.value_counts(sort=False)\n    num_legs  num_wings\n    2         2            1\n    4         0            2\n    6         0            1\n    dtype: int64\n\n    >>> df.value_counts(ascending=True)\n    num_legs  num_wings\n    2         2            1\n    6         0            1\n    4         0            2\n    dtype: int64\n\n    >>> df.value_counts(normalize=True)\n    num_legs  num_wings\n    4         0            0.50\n    6         0            0.25\n    2         2            0.25\n    dtype: float64\n    \"\"\"\n    if subset is None:\n        subset = self.columns.tolist()\n\n    counts = self.groupby(subset).size()\n\n    if sort:\n        counts = counts.sort_values(ascending=ascending)\n    if normalize:\n        counts /= counts.sum()\n\n    # Force MultiIndex for single column\n    if len(subset) == 1:\n        counts.index = MultiIndex.from_arrays(\n            [counts.index], names=[counts.index.name]\n        )\n\n    return counts",
                "def nlargest(self, n, columns, keep=\"first\") -> \"DataFrame\":\n    \"\"\"\n    Return the first `n` rows ordered by `columns` in descending order.\n\n    Return the first `n` rows with the largest values in `columns`, in\n    descending order. The columns that are not specified are returned as\n    well, but not used for ordering.\n\n    This method is equivalent to\n    ``df.sort_values(columns, ascending=False).head(n)``, but more\n    performant.\n\n    Parameters\n    ----------\n    n : int\n        Number of rows to return.\n    columns : label or list of labels\n        Column label(s) to order by.\n    keep : {'first', 'last', 'all'}, default 'first'\n        Where there are duplicate values:\n\n        - `first` : prioritize the first occurrence(s)\n        - `last` : prioritize the last occurrence(s)\n        - ``all`` : do not drop any duplicates, even it means\n                    selecting more than `n` items.\n\n        .. versionadded:: 0.24.0\n\n    Returns\n    -------\n    DataFrame\n        The first `n` rows ordered by the given columns in descending\n        order.\n\n    See Also\n    --------\n    DataFrame.nsmallest : Return the first `n` rows ordered by `columns` in\n        ascending order.\n    DataFrame.sort_values : Sort DataFrame by the values.\n    DataFrame.head : Return the first `n` rows without re-ordering.\n\n    Notes\n    -----\n    This function cannot be used with all column types. For example, when\n    specifying columns with `object` or `category` dtypes, ``TypeError`` is\n    raised.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame({'population': [59000000, 65000000, 434000,\n    ...                                   434000, 434000, 337000, 11300,\n    ...                                   11300, 11300],\n    ...                    'GDP': [1937894, 2583560 , 12011, 4520, 12128,\n    ...                            17036, 182, 38, 311],\n    ...                    'alpha-2': [\"IT\", \"FR\", \"MT\", \"MV\", \"BN\",\n    ...                                \"IS\", \"NR\", \"TV\", \"AI\"]},\n    ...                   index=[\"Italy\", \"France\", \"Malta\",\n    ...                          \"Maldives\", \"Brunei\", \"Iceland\",\n    ...                          \"Nauru\", \"Tuvalu\", \"Anguilla\"])\n    >>> df\n              population      GDP alpha-2\n    Italy       59000000  1937894      IT\n    France      65000000  2583560      FR\n    Malta         434000    12011      MT\n    Maldives      434000     4520      MV\n    Brunei        434000    12128      BN\n    Iceland       337000    17036      IS\n    Nauru          11300      182      NR\n    Tuvalu         11300       38      TV\n    Anguilla       11300      311      AI\n\n    In the following example, we will use ``nlargest`` to select the three\n    rows having the largest values in column \"population\".\n\n    >>> df.nlargest(3, 'population')\n            population      GDP alpha-2\n    France    65000000  2583560      FR\n    Italy     59000000  1937894      IT\n    Malta       434000    12011      MT\n\n    When using ``keep='last'``, ties are resolved in reverse order:\n\n    >>> df.nlargest(3, 'population', keep='last')\n            population      GDP alpha-2\n    France    65000000  2583560      FR\n    Italy     59000000  1937894      IT\n    Brunei      434000    12128      BN\n\n    When using ``keep='all'``, all duplicate items are maintained:\n\n    >>> df.nlargest(3, 'population', keep='all')\n              population      GDP alpha-2\n    France      65000000  2583560      FR\n    Italy       59000000  1937894      IT\n    Malta         434000    12011      MT\n    Maldives      434000     4520      MV\n    Brunei        434000    12128      BN\n\n    To order by the largest values in column \"population\" and then \"GDP\",\n    we can specify multiple columns like in the next example.\n\n    >>> df.nlargest(3, ['population', 'GDP'])\n            population      GDP alpha-2\n    France    65000000  2583560      FR\n    Italy     59000000  1937894      IT\n    Brunei      434000    12128      BN\n    \"\"\"\n    return algorithms.SelectNFrame(self, n=n, keep=keep, columns=columns).nlargest()",
                "def nsmallest(self, n, columns, keep=\"first\") -> \"DataFrame\":\n    \"\"\"\n    Return the first `n` rows ordered by `columns` in ascending order.\n\n    Return the first `n` rows with the smallest values in `columns`, in\n    ascending order. The columns that are not specified are returned as\n    well, but not used for ordering.\n\n    This method is equivalent to\n    ``df.sort_values(columns, ascending=True).head(n)``, but more\n    performant.\n\n    Parameters\n    ----------\n    n : int\n        Number of items to retrieve.\n    columns : list or str\n        Column name or names to order by.\n    keep : {'first', 'last', 'all'}, default 'first'\n        Where there are duplicate values:\n\n        - ``first`` : take the first occurrence.\n        - ``last`` : take the last occurrence.\n        - ``all`` : do not drop any duplicates, even it means\n          selecting more than `n` items.\n\n        .. versionadded:: 0.24.0\n\n    Returns\n    -------\n    DataFrame\n\n    See Also\n    --------\n    DataFrame.nlargest : Return the first `n` rows ordered by `columns` in\n        descending order.\n    DataFrame.sort_values : Sort DataFrame by the values.\n    DataFrame.head : Return the first `n` rows without re-ordering.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame({'population': [59000000, 65000000, 434000,\n    ...                                   434000, 434000, 337000, 337000,\n    ...                                   11300, 11300],\n    ...                    'GDP': [1937894, 2583560 , 12011, 4520, 12128,\n    ...                            17036, 182, 38, 311],\n    ...                    'alpha-2': [\"IT\", \"FR\", \"MT\", \"MV\", \"BN\",\n    ...                                \"IS\", \"NR\", \"TV\", \"AI\"]},\n    ...                   index=[\"Italy\", \"France\", \"Malta\",\n    ...                          \"Maldives\", \"Brunei\", \"Iceland\",\n    ...                          \"Nauru\", \"Tuvalu\", \"Anguilla\"])\n    >>> df\n              population      GDP alpha-2\n    Italy       59000000  1937894      IT\n    France      65000000  2583560      FR\n    Malta         434000    12011      MT\n    Maldives      434000     4520      MV\n    Brunei        434000    12128      BN\n    Iceland       337000    17036      IS\n    Nauru         337000      182      NR\n    Tuvalu         11300       38      TV\n    Anguilla       11300      311      AI\n\n    In the following example, we will use ``nsmallest`` to select the\n    three rows having the smallest values in column \"population\".\n\n    >>> df.nsmallest(3, 'population')\n              population    GDP alpha-2\n    Tuvalu         11300     38      TV\n    Anguilla       11300    311      AI\n    Iceland       337000  17036\t     IS\n\n    When using ``keep='last'``, ties are resolved in reverse order:\n\n    >>> df.nsmallest(3, 'population', keep='last')\n              population  GDP alpha-2\n    Anguilla       11300  311      AI\n    Tuvalu         11300   38      TV\n    Nauru         337000  182      NR\n\n    When using ``keep='all'``, all duplicate items are maintained:\n\n    >>> df.nsmallest(3, 'population', keep='all')\n              population    GDP alpha-2\n    Tuvalu         11300     38      TV\n    Anguilla       11300    311      AI\n    Iceland       337000  17036      IS\n    Nauru         337000    182      NR\n\n    To order by the smallest values in column \"population\" and then \"GDP\", we can\n    specify multiple columns like in the next example.\n\n    >>> df.nsmallest(3, ['population', 'GDP'])\n              population  GDP alpha-2\n    Tuvalu         11300   38      TV\n    Anguilla       11300  311      AI\n    Nauru         337000  182      NR\n    \"\"\"\n    return algorithms.SelectNFrame(\n        self, n=n, keep=keep, columns=columns\n    ).nsmallest()",
                "def swaplevel(self, i=-2, j=-1, axis=0) -> \"DataFrame\":\n    \"\"\"\n    Swap levels i and j in a MultiIndex on a particular axis.\n\n    Parameters\n    ----------\n    i, j : int or str\n        Levels of the indices to be swapped. Can pass level name as string.\n\n    Returns\n    -------\n    DataFrame\n    \"\"\"\n    result = self.copy()\n\n    axis = self._get_axis_number(axis)\n\n    if not isinstance(result._get_axis(axis), ABCMultiIndex):  # pragma: no cover\n        raise TypeError(\"Can only swap levels on a hierarchical axis.\")\n\n    if axis == 0:\n        assert isinstance(result.index, ABCMultiIndex)\n        result.index = result.index.swaplevel(i, j)\n    else:\n        assert isinstance(result.columns, ABCMultiIndex)\n        result.columns = result.columns.swaplevel(i, j)\n    return result",
                "def reorder_levels(self, order, axis=0) -> \"DataFrame\":\n    \"\"\"\n    Rearrange index levels using input order. May not drop or duplicate levels.\n\n    Parameters\n    ----------\n    order : list of int or list of str\n        List representing new level order. Reference level by number\n        (position) or by key (label).\n    axis : int\n        Where to reorder levels.\n\n    Returns\n    -------\n    DataFrame\n    \"\"\"\n    axis = self._get_axis_number(axis)\n    if not isinstance(self._get_axis(axis), ABCMultiIndex):  # pragma: no cover\n        raise TypeError(\"Can only reorder levels on a hierarchical axis.\")\n\n    result = self.copy()\n\n    if axis == 0:\n        assert isinstance(result.index, ABCMultiIndex)\n        result.index = result.index.reorder_levels(order)\n    else:\n        assert isinstance(result.columns, ABCMultiIndex)\n        result.columns = result.columns.reorder_levels(order)\n    return result",
                "def _combine_frame(self, other: \"DataFrame\", func, fill_value=None):\n    # at this point we have `self._indexed_same(other)`\n\n    if fill_value is None:\n        # since _arith_op may be called in a loop, avoid function call\n        #  overhead if possible by doing this check once\n        _arith_op = func\n\n    else:\n\n        def _arith_op(left, right):\n            # for the mixed_type case where we iterate over columns,\n            # _arith_op(left, right) is equivalent to\n            # left._binop(right, func, fill_value=fill_value)\n            left, right = ops.fill_binop(left, right, fill_value)\n            return func(left, right)\n\n    if ops.should_series_dispatch(self, other, func):\n        # iterate over columns\n        new_data = ops.dispatch_to_series(self, other, _arith_op)\n    else:\n        with np.errstate(all=\"ignore\"):\n            res_values = _arith_op(self.values, other.values)\n        new_data = dispatch_fill_zeros(func, self.values, other.values, res_values)\n\n    return new_data",
                "def _construct_result(self, result) -> \"DataFrame\":\n    \"\"\"\n    Wrap the result of an arithmetic, comparison, or logical operation.\n\n    Parameters\n    ----------\n    result : DataFrame\n\n    Returns\n    -------\n    DataFrame\n    \"\"\"\n    out = self._constructor(result, index=self.index, copy=False)\n    # Pin columns instead of passing to constructor for compat with\n    #  non-unique columns case\n    out.columns = self.columns\n    return out",
                "def combine(\n    self, other: \"DataFrame\", func, fill_value=None, overwrite=True\n) -> \"DataFrame\":\n    \"\"\"\n    Perform column-wise combine with another DataFrame.\n\n    Combines a DataFrame with `other` DataFrame using `func`\n    to element-wise combine columns. The row and column indexes of the\n    resulting DataFrame will be the union of the two.\n\n    Parameters\n    ----------\n    other : DataFrame\n        The DataFrame to merge column-wise.\n    func : function\n        Function that takes two series as inputs and return a Series or a\n        scalar. Used to merge the two dataframes column by columns.\n    fill_value : scalar value, default None\n        The value to fill NaNs with prior to passing any column to the\n        merge func.\n    overwrite : bool, default True\n        If True, columns in `self` that do not exist in `other` will be\n        overwritten with NaNs.\n\n    Returns\n    -------\n    DataFrame\n        Combination of the provided DataFrames.\n\n    See Also\n    --------\n    DataFrame.combine_first : Combine two DataFrame objects and default to\n        non-null values in frame calling the method.\n\n    Examples\n    --------\n    Combine using a simple function that chooses the smaller column.\n\n    >>> df1 = pd.DataFrame({'A': [0, 0], 'B': [4, 4]})\n    >>> df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})\n    >>> take_smaller = lambda s1, s2: s1 if s1.sum() < s2.sum() else s2\n    >>> df1.combine(df2, take_smaller)\n       A  B\n    0  0  3\n    1  0  3\n\n    Example using a true element-wise combine function.\n\n    >>> df1 = pd.DataFrame({'A': [5, 0], 'B': [2, 4]})\n    >>> df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})\n    >>> df1.combine(df2, np.minimum)\n       A  B\n    0  1  2\n    1  0  3\n\n    Using `fill_value` fills Nones prior to passing the column to the\n    merge function.\n\n    >>> df1 = pd.DataFrame({'A': [0, 0], 'B': [None, 4]})\n    >>> df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})\n    >>> df1.combine(df2, take_smaller, fill_value=-5)\n       A    B\n    0  0 -5.0\n    1  0  4.0\n\n    However, if the same element in both dataframes is None, that None\n    is preserved\n\n    >>> df1 = pd.DataFrame({'A': [0, 0], 'B': [None, 4]})\n    >>> df2 = pd.DataFrame({'A': [1, 1], 'B': [None, 3]})\n    >>> df1.combine(df2, take_smaller, fill_value=-5)\n        A    B\n    0  0 -5.0\n    1  0  3.0\n\n    Example that demonstrates the use of `overwrite` and behavior when\n    the axis differ between the dataframes.\n\n    >>> df1 = pd.DataFrame({'A': [0, 0], 'B': [4, 4]})\n    >>> df2 = pd.DataFrame({'B': [3, 3], 'C': [-10, 1], }, index=[1, 2])\n    >>> df1.combine(df2, take_smaller)\n         A    B     C\n    0  NaN  NaN   NaN\n    1  NaN  3.0 -10.0\n    2  NaN  3.0   1.0\n\n    >>> df1.combine(df2, take_smaller, overwrite=False)\n         A    B     C\n    0  0.0  NaN   NaN\n    1  0.0  3.0 -10.0\n    2  NaN  3.0   1.0\n\n    Demonstrating the preference of the passed in dataframe.\n\n    >>> df2 = pd.DataFrame({'B': [3, 3], 'C': [1, 1], }, index=[1, 2])\n    >>> df2.combine(df1, take_smaller)\n       A    B   C\n    0  0.0  NaN NaN\n    1  0.0  3.0 NaN\n    2  NaN  3.0 NaN\n\n    >>> df2.combine(df1, take_smaller, overwrite=False)\n         A    B   C\n    0  0.0  NaN NaN\n    1  0.0  3.0 1.0\n    2  NaN  3.0 1.0\n    \"\"\"\n    other_idxlen = len(other.index)  # save for compare\n\n    this, other = self.align(other, copy=False)\n    new_index = this.index\n\n    if other.empty and len(new_index) == len(self.index):\n        return self.copy()\n\n    if self.empty and len(other) == other_idxlen:\n        return other.copy()\n\n    # sorts if possible\n    new_columns = this.columns.union(other.columns)\n    do_fill = fill_value is not None\n    result = {}\n    for col in new_columns:\n        series = this[col]\n        otherSeries = other[col]\n\n        this_dtype = series.dtype\n        other_dtype = otherSeries.dtype\n\n        this_mask = isna(series)\n        other_mask = isna(otherSeries)\n\n        # don't overwrite columns unnecessarily\n        # DO propagate if this column is not in the intersection\n        if not overwrite and other_mask.all():\n            result[col] = this[col].copy()\n            continue\n\n        if do_fill:\n            series = series.copy()\n            otherSeries = otherSeries.copy()\n            series[this_mask] = fill_value\n            otherSeries[other_mask] = fill_value\n\n        if col not in self.columns:\n            # If self DataFrame does not have col in other DataFrame,\n            # try to promote series, which is all NaN, as other_dtype.\n            new_dtype = other_dtype\n            try:\n                series = series.astype(new_dtype, copy=False)\n            except ValueError:\n                # e.g. new_dtype is integer types\n                pass\n        else:\n            # if we have different dtypes, possibly promote\n            new_dtype = find_common_type([this_dtype, other_dtype])\n            if not is_dtype_equal(this_dtype, new_dtype):\n                series = series.astype(new_dtype)\n            if not is_dtype_equal(other_dtype, new_dtype):\n                otherSeries = otherSeries.astype(new_dtype)\n\n        arr = func(series, otherSeries)\n        arr = maybe_downcast_to_dtype(arr, this_dtype)\n\n        result[col] = arr\n\n    # convert_objects just in case\n    return self._constructor(result, index=new_index, columns=new_columns)",
                "def combine_first(self, other: \"DataFrame\") -> \"DataFrame\":\n    \"\"\"\n    Update null elements with value in the same location in `other`.\n\n    Combine two DataFrame objects by filling null values in one DataFrame\n    with non-null values from other DataFrame. The row and column indexes\n    of the resulting DataFrame will be the union of the two.\n\n    Parameters\n    ----------\n    other : DataFrame\n        Provided DataFrame to use to fill null values.\n\n    Returns\n    -------\n    DataFrame\n\n    See Also\n    --------\n    DataFrame.combine : Perform series-wise operation on two DataFrames\n        using a given function.\n\n    Examples\n    --------\n    >>> df1 = pd.DataFrame({'A': [None, 0], 'B': [None, 4]})\n    >>> df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})\n    >>> df1.combine_first(df2)\n         A    B\n    0  1.0  3.0\n    1  0.0  4.0\n\n    Null values still persist if the location of that null value\n    does not exist in `other`\n\n    >>> df1 = pd.DataFrame({'A': [None, 0], 'B': [4, None]})\n    >>> df2 = pd.DataFrame({'B': [3, 3], 'C': [1, 1]}, index=[1, 2])\n    >>> df1.combine_first(df2)\n         A    B    C\n    0  NaN  4.0  NaN\n    1  0.0  3.0  1.0\n    2  NaN  3.0  1.0\n    \"\"\"\n    import pandas.core.computation.expressions as expressions\n\n    def extract_values(arr):\n        # Does two things:\n        # 1. maybe gets the values from the Series / Index\n        # 2. convert datelike to i8\n        if isinstance(arr, (ABCIndexClass, ABCSeries)):\n            arr = arr._values\n\n        if needs_i8_conversion(arr):\n            if is_extension_array_dtype(arr.dtype):\n                arr = arr.asi8\n            else:\n                arr = arr.view(\"i8\")\n        return arr\n\n    def combiner(x, y):\n        mask = isna(x)\n        if isinstance(mask, (ABCIndexClass, ABCSeries)):\n            mask = mask._values\n\n        x_values = extract_values(x)\n        y_values = extract_values(y)\n\n        # If the column y in other DataFrame is not in first DataFrame,\n        # just return y_values.\n        if y.name not in self.columns:\n            return y_values\n\n        return expressions.where(mask, y_values, x_values)\n\n    return self.combine(other, combiner, overwrite=False)",
                "def update(\n    self, other, join=\"left\", overwrite=True, filter_func=None, errors=\"ignore\"\n) -> None:\n    \"\"\"\n    Modify in place using non-NA values from another DataFrame.\n\n    Aligns on indices. There is no return value.\n\n    Parameters\n    ----------\n    other : DataFrame, or object coercible into a DataFrame\n        Should have at least one matching index/column label\n        with the original DataFrame. If a Series is passed,\n        its name attribute must be set, and that will be\n        used as the column name to align with the original DataFrame.\n    join : {'left'}, default 'left'\n        Only left join is implemented, keeping the index and columns of the\n        original object.\n    overwrite : bool, default True\n        How to handle non-NA values for overlapping keys:\n\n        * True: overwrite original DataFrame's values\n          with values from `other`.\n        * False: only update values that are NA in\n          the original DataFrame.\n\n    filter_func : callable(1d-array) -> bool 1d-array, optional\n        Can choose to replace values other than NA. Return True for values\n        that should be updated.\n    errors : {'raise', 'ignore'}, default 'ignore'\n        If 'raise', will raise a ValueError if the DataFrame and `other`\n        both contain non-NA data in the same place.\n\n        .. versionchanged:: 0.24.0\n           Changed from `raise_conflict=False|True`\n           to `errors='ignore'|'raise'`.\n\n    Returns\n    -------\n    None : method directly changes calling object\n\n    Raises\n    ------\n    ValueError\n        * When `errors='raise'` and there's overlapping non-NA data.\n        * When `errors` is not either `'ignore'` or `'raise'`\n    NotImplementedError\n        * If `join != 'left'`\n\n    See Also\n    --------\n    dict.update : Similar method for dictionaries.\n    DataFrame.merge : For column(s)-on-columns(s) operations.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame({'A': [1, 2, 3],\n    ...                    'B': [400, 500, 600]})\n    >>> new_df = pd.DataFrame({'B': [4, 5, 6],\n    ...                        'C': [7, 8, 9]})\n    >>> df.update(new_df)\n    >>> df\n       A  B\n    0  1  4\n    1  2  5\n    2  3  6\n\n    The DataFrame's length does not increase as a result of the update,\n    only values at matching index/column labels are updated.\n\n    >>> df = pd.DataFrame({'A': ['a', 'b', 'c'],\n    ...                    'B': ['x', 'y', 'z']})\n    >>> new_df = pd.DataFrame({'B': ['d', 'e', 'f', 'g', 'h', 'i']})\n    >>> df.update(new_df)\n    >>> df\n       A  B\n    0  a  d\n    1  b  e\n    2  c  f\n\n    For Series, it's name attribute must be set.\n\n    >>> df = pd.DataFrame({'A': ['a', 'b', 'c'],\n    ...                    'B': ['x', 'y', 'z']})\n    >>> new_column = pd.Series(['d', 'e'], name='B', index=[0, 2])\n    >>> df.update(new_column)\n    >>> df\n       A  B\n    0  a  d\n    1  b  y\n    2  c  e\n    >>> df = pd.DataFrame({'A': ['a', 'b', 'c'],\n    ...                    'B': ['x', 'y', 'z']})\n    >>> new_df = pd.DataFrame({'B': ['d', 'e']}, index=[1, 2])\n    >>> df.update(new_df)\n    >>> df\n       A  B\n    0  a  x\n    1  b  d\n    2  c  e\n\n    If `other` contains NaNs the corresponding values are not updated\n    in the original dataframe.\n\n    >>> df = pd.DataFrame({'A': [1, 2, 3],\n    ...                    'B': [400, 500, 600]})\n    >>> new_df = pd.DataFrame({'B': [4, np.nan, 6]})\n    >>> df.update(new_df)\n    >>> df\n       A      B\n    0  1    4.0\n    1  2  500.0\n    2  3    6.0\n    \"\"\"\n    import pandas.core.computation.expressions as expressions\n\n    # TODO: Support other joins\n    if join != \"left\":  # pragma: no cover\n        raise NotImplementedError(\"Only left join is supported\")\n    if errors not in [\"ignore\", \"raise\"]:\n        raise ValueError(\"The parameter errors must be either 'ignore' or 'raise'\")\n\n    if not isinstance(other, DataFrame):\n        other = DataFrame(other)\n\n    other = other.reindex_like(self)\n\n    for col in self.columns:\n        this = self[col]._values\n        that = other[col]._values\n        if filter_func is not None:\n            with np.errstate(all=\"ignore\"):\n                mask = ~filter_func(this) | isna(that)\n        else:\n            if errors == \"raise\":\n                mask_this = notna(that)\n                mask_that = notna(this)\n                if any(mask_this & mask_that):\n                    raise ValueError(\"Data overlaps.\")\n\n            if overwrite:\n                mask = isna(that)\n            else:\n                mask = notna(this)\n\n        # don't overwrite columns unnecessarily\n        if mask.all():\n            continue\n\n        self[col] = expressions.where(mask, this, that)",
                "    @Appender(\n        \"\"\"\nExamples\n--------\n>>> df = pd.DataFrame({'Animal': ['Falcon', 'Falcon',\n...                               'Parrot', 'Parrot'],\n...                    'Max Speed': [380., 370., 24., 26.]})\n>>> df\n   Animal  Max Speed\n0  Falcon      380.0\n1  Falcon      370.0\n2  Parrot       24.0\n3  Parrot       26.0\n>>> df.groupby(['Animal']).mean()\n        Max Speed\nAnimal\nFalcon      375.0\nParrot       25.0\n\n**Hierarchical Indexes**\n\nWe can groupby different levels of a hierarchical index\nusing the `level` parameter:\n\n>>> arrays = [['Falcon', 'Falcon', 'Parrot', 'Parrot'],\n...           ['Captive', 'Wild', 'Captive', 'Wild']]\n>>> index = pd.MultiIndex.from_arrays(arrays, names=('Animal', 'Type'))\n>>> df = pd.DataFrame({'Max Speed': [390., 350., 30., 20.]},\n...                   index=index)\n>>> df\n                Max Speed\nAnimal Type\nFalcon Captive      390.0\n       Wild         350.0\nParrot Captive       30.0\n       Wild          20.0\n>>> df.groupby(level=0).mean()\n        Max Speed\nAnimal\nFalcon      370.0\nParrot       25.0\n>>> df.groupby(level=\"Type\").mean()\n         Max Speed\nType\nCaptive      210.0\nWild         185.0\n\"\"\"\n    )\n    @Appender(_shared_docs[\"groupby\"] % _shared_doc_kwargs)\n    def groupby(\n        self,\n        by=None,\n        axis=0,\n        level=None,\n        as_index: bool = True,\n        sort: bool = True,\n        group_keys: bool = True,\n        squeeze: bool = False,\n        observed: bool = False,\n    ) -> \"DataFrameGroupBy\":\n        from pandas.core.groupby.generic import DataFrameGroupBy\n\n        if level is None and by is None:\n            raise TypeError(\"You have to supply one of 'by' and 'level'\")\n        axis = self._get_axis_number(axis)\n\n        return DataFrameGroupBy(\n            obj=self,\n            keys=by,\n            axis=axis,\n            level=level,\n            as_index=as_index,\n            sort=sort,\n            group_keys=group_keys,\n            squeeze=squeeze,\n            observed=observed,\n        )",
                "@Substitution(\"\")\n@Appender(_shared_docs[\"pivot\"])\ndef pivot(self, index=None, columns=None, values=None) -> \"DataFrame\":\n    from pandas.core.reshape.pivot import pivot\n\n    return pivot(self, index=index, columns=columns, values=values)",
                "@Substitution(\"\")\n@Appender(_shared_docs[\"pivot_table\"])\ndef pivot_table(\n    self,\n    values=None,\n    index=None,\n    columns=None,\n    aggfunc=\"mean\",\n    fill_value=None,\n    margins=False,\n    dropna=True,\n    margins_name=\"All\",\n    observed=False,\n) -> \"DataFrame\":\n    from pandas.core.reshape.pivot import pivot_table\n\n    return pivot_table(\n        self,\n        values=values,\n        index=index,\n        columns=columns,\n        aggfunc=aggfunc,\n        fill_value=fill_value,\n        margins=margins,\n        dropna=dropna,\n        margins_name=margins_name,\n        observed=observed,\n    )",
                "def stack(self, level=-1, dropna=True):\n    \"\"\"\n    Stack the prescribed level(s) from columns to index.\n\n    Return a reshaped DataFrame or Series having a multi-level\n    index with one or more new inner-most levels compared to the current\n    DataFrame. The new inner-most levels are created by pivoting the\n    columns of the current dataframe:\n\n      - if the columns have a single level, the output is a Series;\n      - if the columns have multiple levels, the new index\n        level(s) is (are) taken from the prescribed level(s) and\n        the output is a DataFrame.\n\n    The new index levels are sorted.\n\n    Parameters\n    ----------\n    level : int, str, list, default -1\n        Level(s) to stack from the column axis onto the index\n        axis, defined as one index or label, or a list of indices\n        or labels.\n    dropna : bool, default True\n        Whether to drop rows in the resulting Frame/Series with\n        missing values. Stacking a column level onto the index\n        axis can create combinations of index and column values\n        that are missing from the original dataframe. See Examples\n        section.\n\n    Returns\n    -------\n    DataFrame or Series\n        Stacked dataframe or series.\n\n    See Also\n    --------\n    DataFrame.unstack : Unstack prescribed level(s) from index axis\n         onto column axis.\n    DataFrame.pivot : Reshape dataframe from long format to wide\n         format.\n    DataFrame.pivot_table : Create a spreadsheet-style pivot table\n         as a DataFrame.\n\n    Notes\n    -----\n    The function is named by analogy with a collection of books\n    being reorganized from being side by side on a horizontal\n    position (the columns of the dataframe) to being stacked\n    vertically on top of each other (in the index of the\n    dataframe).\n\n    Examples\n    --------\n    **Single level columns**\n\n    >>> df_single_level_cols = pd.DataFrame([[0, 1], [2, 3]],\n    ...                                     index=['cat', 'dog'],\n    ...                                     columns=['weight', 'height'])\n\n    Stacking a dataframe with a single level column axis returns a Series:\n\n    >>> df_single_level_cols\n         weight height\n    cat       0      1\n    dog       2      3\n    >>> df_single_level_cols.stack()\n    cat  weight    0\n         height    1\n    dog  weight    2\n         height    3\n    dtype: int64\n\n    **Multi level columns: simple case**\n\n    >>> multicol1 = pd.MultiIndex.from_tuples([('weight', 'kg'),\n    ...                                        ('weight', 'pounds')])\n    >>> df_multi_level_cols1 = pd.DataFrame([[1, 2], [2, 4]],\n    ...                                     index=['cat', 'dog'],\n    ...                                     columns=multicol1)\n\n    Stacking a dataframe with a multi-level column axis:\n\n    >>> df_multi_level_cols1\n         weight\n             kg    pounds\n    cat       1        2\n    dog       2        4\n    >>> df_multi_level_cols1.stack()\n                weight\n    cat kg           1\n        pounds       2\n    dog kg           2\n        pounds       4\n\n    **Missing values**\n\n    >>> multicol2 = pd.MultiIndex.from_tuples([('weight', 'kg'),\n    ...                                        ('height', 'm')])\n    >>> df_multi_level_cols2 = pd.DataFrame([[1.0, 2.0], [3.0, 4.0]],\n    ...                                     index=['cat', 'dog'],\n    ...                                     columns=multicol2)\n\n    It is common to have missing values when stacking a dataframe\n    with multi-level columns, as the stacked dataframe typically\n    has more values than the original dataframe. Missing values\n    are filled with NaNs:\n\n    >>> df_multi_level_cols2\n        weight height\n            kg      m\n    cat    1.0    2.0\n    dog    3.0    4.0\n    >>> df_multi_level_cols2.stack()\n            height  weight\n    cat kg     NaN     1.0\n        m      2.0     NaN\n    dog kg     NaN     3.0\n        m      4.0     NaN\n\n    **Prescribing the level(s) to be stacked**\n\n    The first parameter controls which level or levels are stacked:\n\n    >>> df_multi_level_cols2.stack(0)\n                 kg    m\n    cat height  NaN  2.0\n        weight  1.0  NaN\n    dog height  NaN  4.0\n        weight  3.0  NaN\n    >>> df_multi_level_cols2.stack([0, 1])\n    cat  height  m     2.0\n         weight  kg    1.0\n    dog  height  m     4.0\n         weight  kg    3.0\n    dtype: float64\n\n    **Dropping missing values**\n\n    >>> df_multi_level_cols3 = pd.DataFrame([[None, 1.0], [2.0, 3.0]],\n    ...                                     index=['cat', 'dog'],\n    ...                                     columns=multicol2)\n\n    Note that rows where all values are missing are dropped by\n    default but this behaviour can be controlled via the dropna\n    keyword parameter:\n\n    >>> df_multi_level_cols3\n        weight height\n            kg      m\n    cat    NaN    1.0\n    dog    2.0    3.0\n    >>> df_multi_level_cols3.stack(dropna=False)\n            height  weight\n    cat kg     NaN     NaN\n        m      1.0     NaN\n    dog kg     NaN     2.0\n        m      3.0     NaN\n    >>> df_multi_level_cols3.stack(dropna=True)\n            height  weight\n    cat m      1.0     NaN\n    dog kg     NaN     2.0\n        m      3.0     NaN\n    \"\"\"\n    from pandas.core.reshape.reshape import stack, stack_multiple\n\n    if isinstance(level, (tuple, list)):\n        return stack_multiple(self, level, dropna=dropna)\n    else:\n        return stack(self, level, dropna=dropna)",
                "def explode(self, column: Union[str, Tuple]) -> \"DataFrame\":\n    \"\"\"\n    Transform each element of a list-like to a row, replicating index values.\n\n    .. versionadded:: 0.25.0\n\n    Parameters\n    ----------\n    column : str or tuple\n        Column to explode.\n\n    Returns\n    -------\n    DataFrame\n        Exploded lists to rows of the subset columns;\n        index will be duplicated for these rows.\n\n    Raises\n    ------\n    ValueError :\n        if columns of the frame are not unique.\n\n    See Also\n    --------\n    DataFrame.unstack : Pivot a level of the (necessarily hierarchical)\n        index labels.\n    DataFrame.melt : Unpivot a DataFrame from wide format to long format.\n    Series.explode : Explode a DataFrame from list-like columns to long format.\n\n    Notes\n    -----\n    This routine will explode list-likes including lists, tuples,\n    Series, and np.ndarray. The result dtype of the subset rows will\n    be object. Scalars will be returned unchanged. Empty list-likes will\n    result in a np.nan for that row.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame({'A': [[1, 2, 3], 'foo', [], [3, 4]], 'B': 1})\n    >>> df\n               A  B\n    0  [1, 2, 3]  1\n    1        foo  1\n    2         []  1\n    3     [3, 4]  1\n\n    >>> df.explode('A')\n         A  B\n    0    1  1\n    0    2  1\n    0    3  1\n    1  foo  1\n    2  NaN  1\n    3    3  1\n    3    4  1\n    \"\"\"\n    if not (is_scalar(column) or isinstance(column, tuple)):\n        raise ValueError(\"column must be a scalar\")\n    if not self.columns.is_unique:\n        raise ValueError(\"columns must be unique\")\n\n    df = self.reset_index(drop=True)\n    # TODO: use overload to refine return type of reset_index\n    assert df is not None  # needed for mypy\n    result = df[column].explode()\n    result = df.drop([column], axis=1).join(result)\n    result.index = self.index.take(result.index)\n    result = result.reindex(columns=self.columns, copy=False)\n\n    return result",
                "def unstack(self, level=-1, fill_value=None):\n    \"\"\"\n    Pivot a level of the (necessarily hierarchical) index labels.\n\n    Returns a DataFrame having a new level of column labels whose inner-most level\n    consists of the pivoted index labels.\n\n    If the index is not a MultiIndex, the output will be a Series\n    (the analogue of stack when the columns are not a MultiIndex).\n\n    The level involved will automatically get sorted.\n\n    Parameters\n    ----------\n    level : int, str, or list of these, default -1 (last level)\n        Level(s) of index to unstack, can pass level name.\n    fill_value : int, str or dict\n        Replace NaN with this value if the unstack produces missing values.\n\n    Returns\n    -------\n    Series or DataFrame\n\n    See Also\n    --------\n    DataFrame.pivot : Pivot a table based on column values.\n    DataFrame.stack : Pivot a level of the column labels (inverse operation\n        from `unstack`).\n\n    Examples\n    --------\n    >>> index = pd.MultiIndex.from_tuples([('one', 'a'), ('one', 'b'),\n    ...                                    ('two', 'a'), ('two', 'b')])\n    >>> s = pd.Series(np.arange(1.0, 5.0), index=index)\n    >>> s\n    one  a   1.0\n         b   2.0\n    two  a   3.0\n         b   4.0\n    dtype: float64\n\n    >>> s.unstack(level=-1)\n         a   b\n    one  1.0  2.0\n    two  3.0  4.0\n\n    >>> s.unstack(level=0)\n       one  two\n    a  1.0   3.0\n    b  2.0   4.0\n\n    >>> df = s.unstack(level=0)\n    >>> df.unstack()\n    one  a  1.0\n         b  2.0\n    two  a  3.0\n         b  4.0\n    dtype: float64\n    \"\"\"\n    from pandas.core.reshape.reshape import unstack\n\n    return unstack(self, level, fill_value)",
                "@Appender(\n    _shared_docs[\"melt\"]\n    % dict(\n        caller=\"df.melt(\",\n        versionadded=\"\\n    .. versionadded:: 0.20.0\\n\",\n        other=\"melt\",\n    )\n)\ndef melt(\n    self,\n    id_vars=None,\n    value_vars=None,\n    var_name=None,\n    value_name=\"value\",\n    col_level=None,\n) -> \"DataFrame\":\n    from pandas.core.reshape.melt import melt\n\n    return melt(\n        self,\n        id_vars=id_vars,\n        value_vars=value_vars,\n        var_name=var_name,\n        value_name=value_name,\n        col_level=col_level,\n    )",
                "def diff(self, periods=1, axis=0) -> \"DataFrame\":\n    \"\"\"\n    First discrete difference of element.\n\n    Calculates the difference of a DataFrame element compared with another\n    element in the DataFrame (default is the element in the same column\n    of the previous row).\n\n    Parameters\n    ----------\n    periods : int, default 1\n        Periods to shift for calculating difference, accepts negative\n        values.\n    axis : {0 or 'index', 1 or 'columns'}, default 0\n        Take difference over rows (0) or columns (1).\n\n    Returns\n    -------\n    DataFrame\n\n    See Also\n    --------\n    Series.diff: First discrete difference for a Series.\n    DataFrame.pct_change: Percent change over given number of periods.\n    DataFrame.shift: Shift index by desired number of periods with an\n        optional time freq.\n\n    Notes\n    -----\n    For boolean dtypes, this uses :meth:`operator.xor` rather than\n    :meth:`operator.sub`.\n\n    Examples\n    --------\n    Difference with previous row\n\n    >>> df = pd.DataFrame({'a': [1, 2, 3, 4, 5, 6],\n    ...                    'b': [1, 1, 2, 3, 5, 8],\n    ...                    'c': [1, 4, 9, 16, 25, 36]})\n    >>> df\n       a  b   c\n    0  1  1   1\n    1  2  1   4\n    2  3  2   9\n    3  4  3  16\n    4  5  5  25\n    5  6  8  36\n\n    >>> df.diff()\n         a    b     c\n    0  NaN  NaN   NaN\n    1  1.0  0.0   3.0\n    2  1.0  1.0   5.0\n    3  1.0  1.0   7.0\n    4  1.0  2.0   9.0\n    5  1.0  3.0  11.0\n\n    Difference with previous column\n\n    >>> df.diff(axis=1)\n        a    b     c\n    0 NaN  0.0   0.0\n    1 NaN -1.0   3.0\n    2 NaN -1.0   7.0\n    3 NaN -1.0  13.0\n    4 NaN  0.0  20.0\n    5 NaN  2.0  28.0\n\n    Difference with 3rd previous row\n\n    >>> df.diff(periods=3)\n         a    b     c\n    0  NaN  NaN   NaN\n    1  NaN  NaN   NaN\n    2  NaN  NaN   NaN\n    3  3.0  2.0  15.0\n    4  3.0  4.0  21.0\n    5  3.0  6.0  27.0\n\n    Difference with following row\n\n    >>> df.diff(periods=-1)\n         a    b     c\n    0 -1.0  0.0  -3.0\n    1 -1.0 -1.0  -5.0\n    2 -1.0 -1.0  -7.0\n    3 -1.0 -2.0  -9.0\n    4 -1.0 -3.0 -11.0\n    5  NaN  NaN   NaN\n    \"\"\"\n    bm_axis = self._get_block_manager_axis(axis)\n    new_data = self._data.diff(n=periods, axis=bm_axis)\n    return self._constructor(new_data)",
                "def _gotitem(\n    self,\n    key: Union[str, List[str]],\n    ndim: int,\n    subset: Optional[Union[Series, ABCDataFrame]] = None,\n) -> Union[Series, ABCDataFrame]:\n    \"\"\"\n    Sub-classes to define. Return a sliced object.\n\n    Parameters\n    ----------\n    key : string / list of selections\n    ndim : 1,2\n        requested ndim of result\n    subset : object, default None\n        subset to act on\n    \"\"\"\n    if subset is None:\n        subset = self\n    elif subset.ndim == 1:  # is Series\n        return subset\n\n    # TODO: _shallow_copy(subset)?\n    return subset[key]",
                "@Substitution(\n    see_also=_agg_summary_and_see_also_doc,\n    examples=_agg_examples_doc,\n    versionadded=\"\\n.. versionadded:: 0.20.0\\n\",\n    **_shared_doc_kwargs,\n)\n@Appender(_shared_docs[\"aggregate\"])\ndef aggregate(self, func, axis=0, *args, **kwargs):\n    axis = self._get_axis_number(axis)\n\n    result = None\n    try:\n        result, how = self._aggregate(func, axis=axis, *args, **kwargs)\n    except TypeError:\n        pass\n    if result is None:\n        return self.apply(func, axis=axis, args=args, **kwargs)\n    return result",
                "def _aggregate(self, arg, axis=0, *args, **kwargs):\n    if axis == 1:\n        # NDFrame.aggregate returns a tuple, and we need to transpose\n        # only result\n        result, how = self.T._aggregate(arg, *args, **kwargs)\n        result = result.T if result is not None else result\n        return result, how\n    return super()._aggregate(arg, *args, **kwargs)",
                "@Appender(_shared_docs[\"transform\"] % _shared_doc_kwargs)\ndef transform(self, func, axis=0, *args, **kwargs) -> \"DataFrame\":\n    axis = self._get_axis_number(axis)\n    if axis == 1:\n        return self.T.transform(func, *args, **kwargs).T\n    return super().transform(func, *args, **kwargs)",
                "def apply(self, func, axis=0, raw=False, result_type=None, args=(), **kwds):\n    \"\"\"\n    Apply a function along an axis of the DataFrame.\n\n    Objects passed to the function are Series objects whose index is\n    either the DataFrame's index (``axis=0``) or the DataFrame's columns\n    (``axis=1``). By default (``result_type=None``), the final return type\n    is inferred from the return type of the applied function. Otherwise,\n    it depends on the `result_type` argument.\n\n    Parameters\n    ----------\n    func : function\n        Function to apply to each column or row.\n    axis : {0 or 'index', 1 or 'columns'}, default 0\n        Axis along which the function is applied:\n\n        * 0 or 'index': apply function to each column.\n        * 1 or 'columns': apply function to each row.\n\n    raw : bool, default False\n        Determines if row or column is passed as a Series or ndarray object:\n\n        * ``False`` : passes each row or column as a Series to the\n          function.\n        * ``True`` : the passed function will receive ndarray objects\n          instead.\n          If you are just applying a NumPy reduction function this will\n          achieve much better performance.\n\n    result_type : {'expand', 'reduce', 'broadcast', None}, default None\n        These only act when ``axis=1`` (columns):\n\n        * 'expand' : list-like results will be turned into columns.\n        * 'reduce' : returns a Series if possible rather than expanding\n          list-like results. This is the opposite of 'expand'.\n        * 'broadcast' : results will be broadcast to the original shape\n          of the DataFrame, the original index and columns will be\n          retained.\n\n        The default behaviour (None) depends on the return value of the\n        applied function: list-like results will be returned as a Series\n        of those. However if the apply function returns a Series these\n        are expanded to columns.\n\n        .. versionadded:: 0.23.0\n\n    args : tuple\n        Positional arguments to pass to `func` in addition to the\n        array/series.\n    **kwds\n        Additional keyword arguments to pass as keywords arguments to\n        `func`.\n\n    Returns\n    -------\n    Series or DataFrame\n        Result of applying ``func`` along the given axis of the\n        DataFrame.\n\n    See Also\n    --------\n    DataFrame.applymap: For elementwise operations.\n    DataFrame.aggregate: Only perform aggregating type operations.\n    DataFrame.transform: Only perform transforming type operations.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame([[4, 9]] * 3, columns=['A', 'B'])\n    >>> df\n       A  B\n    0  4  9\n    1  4  9\n    2  4  9\n\n    Using a numpy universal function (in this case the same as\n    ``np.sqrt(df)``):\n\n    >>> df.apply(np.sqrt)\n         A    B\n    0  2.0  3.0\n    1  2.0  3.0\n    2  2.0  3.0\n\n    Using a reducing function on either axis\n\n    >>> df.apply(np.sum, axis=0)\n    A    12\n    B    27\n    dtype: int64\n\n    >>> df.apply(np.sum, axis=1)\n    0    13\n    1    13\n    2    13\n    dtype: int64\n\n    Returning a list-like will result in a Series\n\n    >>> df.apply(lambda x: [1, 2], axis=1)\n    0    [1, 2]\n    1    [1, 2]\n    2    [1, 2]\n    dtype: object\n\n    Passing result_type='expand' will expand list-like results\n    to columns of a Dataframe\n\n    >>> df.apply(lambda x: [1, 2], axis=1, result_type='expand')\n       0  1\n    0  1  2\n    1  1  2\n    2  1  2\n\n    Returning a Series inside the function is similar to passing\n    ``result_type='expand'``. The resulting column names\n    will be the Series index.\n\n    >>> df.apply(lambda x: pd.Series([1, 2], index=['foo', 'bar']), axis=1)\n       foo  bar\n    0    1    2\n    1    1    2\n    2    1    2\n\n    Passing ``result_type='broadcast'`` will ensure the same shape\n    result, whether list-like or scalar is returned by the function,\n    and broadcast it along the axis. The resulting column names will\n    be the originals.\n\n    >>> df.apply(lambda x: [1, 2], axis=1, result_type='broadcast')\n       A  B\n    0  1  2\n    1  1  2\n    2  1  2\n    \"\"\"\n    from pandas.core.apply import frame_apply\n\n    op = frame_apply(\n        self,\n        func=func,\n        axis=axis,\n        raw=raw,\n        result_type=result_type,\n        args=args,\n        kwds=kwds,\n    )\n    return op.get_result()",
                "def applymap(self, func) -> \"DataFrame\":\n    \"\"\"\n    Apply a function to a Dataframe elementwise.\n\n    This method applies a function that accepts and returns a scalar\n    to every element of a DataFrame.\n\n    Parameters\n    ----------\n    func : callable\n        Python function, returns a single value from a single value.\n\n    Returns\n    -------\n    DataFrame\n        Transformed DataFrame.\n\n    See Also\n    --------\n    DataFrame.apply : Apply a function along input axis of DataFrame.\n\n    Notes\n    -----\n    In the current implementation applymap calls `func` twice on the\n    first column/row to decide whether it can take a fast or slow\n    code path. This can lead to unexpected behavior if `func` has\n    side-effects, as they will take effect twice for the first\n    column/row.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame([[1, 2.12], [3.356, 4.567]])\n    >>> df\n           0      1\n    0  1.000  2.120\n    1  3.356  4.567\n\n    >>> df.applymap(lambda x: len(str(x)))\n       0  1\n    0  3  4\n    1  5  5\n\n    Note that a vectorized version of `func` often exists, which will\n    be much faster. You could square each number elementwise.\n\n    >>> df.applymap(lambda x: x**2)\n               0          1\n    0   1.000000   4.494400\n    1  11.262736  20.857489\n\n    But it's better to avoid applymap in that case.\n\n    >>> df ** 2\n               0          1\n    0   1.000000   4.494400\n    1  11.262736  20.857489\n    \"\"\"\n    # if we have a dtype == 'M8[ns]', provide boxed values\n    def infer(x):\n        if x.empty:\n            return lib.map_infer(x, func)\n        return lib.map_infer(x.astype(object).values, func)\n\n    return self.apply(infer)",
                "def append(\n    self, other, ignore_index=False, verify_integrity=False, sort=False\n) -> \"DataFrame\":\n    \"\"\"\n    Append rows of `other` to the end of caller, returning a new object.\n\n    Columns in `other` that are not in the caller are added as new columns.\n\n    Parameters\n    ----------\n    other : DataFrame or Series/dict-like object, or list of these\n        The data to append.\n    ignore_index : bool, default False\n        If True, do not use the index labels.\n    verify_integrity : bool, default False\n        If True, raise ValueError on creating index with duplicates.\n    sort : bool, default False\n        Sort columns if the columns of `self` and `other` are not aligned.\n\n        .. versionadded:: 0.23.0\n        .. versionchanged:: 1.0.0\n\n            Changed to not sort by default.\n\n    Returns\n    -------\n    DataFrame\n\n    See Also\n    --------\n    concat : General function to concatenate DataFrame or Series objects.\n\n    Notes\n    -----\n    If a list of dict/series is passed and the keys are all contained in\n    the DataFrame's index, the order of the columns in the resulting\n    DataFrame will be unchanged.\n\n    Iteratively appending rows to a DataFrame can be more computationally\n    intensive than a single concatenate. A better solution is to append\n    those rows to a list and then concatenate the list with the original\n    DataFrame all at once.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame([[1, 2], [3, 4]], columns=list('AB'))\n    >>> df\n       A  B\n    0  1  2\n    1  3  4\n    >>> df2 = pd.DataFrame([[5, 6], [7, 8]], columns=list('AB'))\n    >>> df.append(df2)\n       A  B\n    0  1  2\n    1  3  4\n    0  5  6\n    1  7  8\n\n    With `ignore_index` set to True:\n\n    >>> df.append(df2, ignore_index=True)\n       A  B\n    0  1  2\n    1  3  4\n    2  5  6\n    3  7  8\n\n    The following, while not recommended methods for generating DataFrames,\n    show two ways to generate a DataFrame from multiple data sources.\n\n    Less efficient:\n\n    >>> df = pd.DataFrame(columns=['A'])\n    >>> for i in range(5):\n    ...     df = df.append({'A': i}, ignore_index=True)\n    >>> df\n       A\n    0  0\n    1  1\n    2  2\n    3  3\n    4  4\n\n    More efficient:\n\n    >>> pd.concat([pd.DataFrame([i], columns=['A']) for i in range(5)],\n    ...           ignore_index=True)\n       A\n    0  0\n    1  1\n    2  2\n    3  3\n    4  4\n    \"\"\"\n    if isinstance(other, (Series, dict)):\n        if isinstance(other, dict):\n            if not ignore_index:\n                raise TypeError(\"Can only append a dict if ignore_index=True\")\n            other = Series(other)\n        if other.name is None and not ignore_index:\n            raise TypeError(\n                \"Can only append a Series if ignore_index=True \"\n                \"or if the Series has a name\"\n            )\n\n        index = Index([other.name], name=self.index.name)\n        idx_diff = other.index.difference(self.columns)\n        try:\n            combined_columns = self.columns.append(idx_diff)\n        except TypeError:\n            combined_columns = self.columns.astype(object).append(idx_diff)\n        other = (\n            other.reindex(combined_columns, copy=False)\n            .to_frame()\n            .T.infer_objects()\n            .rename_axis(index.names, copy=False)\n        )\n        if not self.columns.equals(combined_columns):\n            self = self.reindex(columns=combined_columns)\n    elif isinstance(other, list):\n        if not other:\n            pass\n        elif not isinstance(other[0], DataFrame):\n            other = DataFrame(other)\n            if (self.columns.get_indexer(other.columns) >= 0).all():\n                other = other.reindex(columns=self.columns)\n\n    from pandas.core.reshape.concat import concat\n\n    if isinstance(other, (list, tuple)):\n        to_concat = [self, *other]\n    else:\n        to_concat = [self, other]\n    return concat(\n        to_concat,\n        ignore_index=ignore_index,\n        verify_integrity=verify_integrity,\n        sort=sort,\n    )",
                "def join(\n    self, other, on=None, how=\"left\", lsuffix=\"\", rsuffix=\"\", sort=False\n) -> \"DataFrame\":\n    \"\"\"\n    Join columns of another DataFrame.\n\n    Join columns with `other` DataFrame either on index or on a key\n    column. Efficiently join multiple DataFrame objects by index at once by\n    passing a list.\n\n    Parameters\n    ----------\n    other : DataFrame, Series, or list of DataFrame\n        Index should be similar to one of the columns in this one. If a\n        Series is passed, its name attribute must be set, and that will be\n        used as the column name in the resulting joined DataFrame.\n    on : str, list of str, or array-like, optional\n        Column or index level name(s) in the caller to join on the index\n        in `other`, otherwise joins index-on-index. If multiple\n        values given, the `other` DataFrame must have a MultiIndex. Can\n        pass an array as the join key if it is not already contained in\n        the calling DataFrame. Like an Excel VLOOKUP operation.\n    how : {'left', 'right', 'outer', 'inner'}, default 'left'\n        How to handle the operation of the two objects.\n\n        * left: use calling frame's index (or column if on is specified)\n        * right: use `other`'s index.\n        * outer: form union of calling frame's index (or column if on is\n          specified) with `other`'s index, and sort it.\n          lexicographically.\n        * inner: form intersection of calling frame's index (or column if\n          on is specified) with `other`'s index, preserving the order\n          of the calling's one.\n    lsuffix : str, default ''\n        Suffix to use from left frame's overlapping columns.\n    rsuffix : str, default ''\n        Suffix to use from right frame's overlapping columns.\n    sort : bool, default False\n        Order result DataFrame lexicographically by the join key. If False,\n        the order of the join key depends on the join type (how keyword).\n\n    Returns\n    -------\n    DataFrame\n        A dataframe containing columns from both the caller and `other`.\n\n    See Also\n    --------\n    DataFrame.merge : For column(s)-on-columns(s) operations.\n\n    Notes\n    -----\n    Parameters `on`, `lsuffix`, and `rsuffix` are not supported when\n    passing a list of `DataFrame` objects.\n\n    Support for specifying index levels as the `on` parameter was added\n    in version 0.23.0.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3', 'K4', 'K5'],\n    ...                    'A': ['A0', 'A1', 'A2', 'A3', 'A4', 'A5']})\n\n    >>> df\n      key   A\n    0  K0  A0\n    1  K1  A1\n    2  K2  A2\n    3  K3  A3\n    4  K4  A4\n    5  K5  A5\n\n    >>> other = pd.DataFrame({'key': ['K0', 'K1', 'K2'],\n    ...                       'B': ['B0', 'B1', 'B2']})\n\n    >>> other\n      key   B\n    0  K0  B0\n    1  K1  B1\n    2  K2  B2\n\n    Join DataFrames using their indexes.\n\n    >>> df.join(other, lsuffix='_caller', rsuffix='_other')\n      key_caller   A key_other    B\n    0         K0  A0        K0   B0\n    1         K1  A1        K1   B1\n    2         K2  A2        K2   B2\n    3         K3  A3       NaN  NaN\n    4         K4  A4       NaN  NaN\n    5         K5  A5       NaN  NaN\n\n    If we want to join using the key columns, we need to set key to be\n    the index in both `df` and `other`. The joined DataFrame will have\n    key as its index.\n\n    >>> df.set_index('key').join(other.set_index('key'))\n          A    B\n    key\n    K0   A0   B0\n    K1   A1   B1\n    K2   A2   B2\n    K3   A3  NaN\n    K4   A4  NaN\n    K5   A5  NaN\n\n    Another option to join using the key columns is to use the `on`\n    parameter. DataFrame.join always uses `other`'s index but we can use\n    any column in `df`. This method preserves the original DataFrame's\n    index in the result.\n\n    >>> df.join(other.set_index('key'), on='key')\n      key   A    B\n    0  K0  A0   B0\n    1  K1  A1   B1\n    2  K2  A2   B2\n    3  K3  A3  NaN\n    4  K4  A4  NaN\n    5  K5  A5  NaN\n    \"\"\"\n    return self._join_compat(\n        other, on=on, how=how, lsuffix=lsuffix, rsuffix=rsuffix, sort=sort\n    )",
                "def _join_compat(\n    self, other, on=None, how=\"left\", lsuffix=\"\", rsuffix=\"\", sort=False\n):\n    from pandas.core.reshape.merge import merge\n    from pandas.core.reshape.concat import concat\n\n    if isinstance(other, Series):\n        if other.name is None:\n            raise ValueError(\"Other Series must have a name\")\n        other = DataFrame({other.name: other})\n\n    if isinstance(other, DataFrame):\n        return merge(\n            self,\n            other,\n            left_on=on,\n            how=how,\n            left_index=on is None,\n            right_index=True,\n            suffixes=(lsuffix, rsuffix),\n            sort=sort,\n        )\n    else:\n        if on is not None:\n            raise ValueError(\n                \"Joining multiple DataFrames only supported for joining on index\"\n            )\n\n        frames = [self] + list(other)\n\n        can_concat = all(df.index.is_unique for df in frames)\n\n        # join indexes only using concat\n        if can_concat:\n            if how == \"left\":\n                res = concat(\n                    frames, axis=1, join=\"outer\", verify_integrity=True, sort=sort\n                )\n                return res.reindex(self.index, copy=False)\n            else:\n                return concat(\n                    frames, axis=1, join=how, verify_integrity=True, sort=sort\n                )\n\n        joined = frames[0]\n\n        for frame in frames[1:]:\n            joined = merge(\n                joined, frame, how=how, left_index=True, right_index=True\n            )\n\n        return joined",
                "@Substitution(\"\")\n@Appender(_merge_doc, indents=2)\ndef merge(\n    self,\n    right,\n    how=\"inner\",\n    on=None,\n    left_on=None,\n    right_on=None,\n    left_index=False,\n    right_index=False,\n    sort=False,\n    suffixes=(\"_x\", \"_y\"),\n    copy=True,\n    indicator=False,\n    validate=None,\n) -> \"DataFrame\":\n    from pandas.core.reshape.merge import merge\n\n    return merge(\n        self,\n        right,\n        how=how,\n        on=on,\n        left_on=left_on,\n        right_on=right_on,\n        left_index=left_index,\n        right_index=right_index,\n        sort=sort,\n        suffixes=suffixes,\n        copy=copy,\n        indicator=indicator,\n        validate=validate,\n    )",
                "def round(self, decimals=0, *args, **kwargs) -> \"DataFrame\":\n    \"\"\"\n    Round a DataFrame to a variable number of decimal places.\n\n    Parameters\n    ----------\n    decimals : int, dict, Series\n        Number of decimal places to round each column to. If an int is\n        given, round each column to the same number of places.\n        Otherwise dict and Series round to variable numbers of places.\n        Column names should be in the keys if `decimals` is a\n        dict-like, or in the index if `decimals` is a Series. Any\n        columns not included in `decimals` will be left as is. Elements\n        of `decimals` which are not columns of the input will be\n        ignored.\n    *args\n        Additional keywords have no effect but might be accepted for\n        compatibility with numpy.\n    **kwargs\n        Additional keywords have no effect but might be accepted for\n        compatibility with numpy.\n\n    Returns\n    -------\n    DataFrame\n        A DataFrame with the affected columns rounded to the specified\n        number of decimal places.\n\n    See Also\n    --------\n    numpy.around : Round a numpy array to the given number of decimals.\n    Series.round : Round a Series to the given number of decimals.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame([(.21, .32), (.01, .67), (.66, .03), (.21, .18)],\n    ...                   columns=['dogs', 'cats'])\n    >>> df\n        dogs  cats\n    0  0.21  0.32\n    1  0.01  0.67\n    2  0.66  0.03\n    3  0.21  0.18\n\n    By providing an integer each column is rounded to the same number\n    of decimal places\n\n    >>> df.round(1)\n        dogs  cats\n    0   0.2   0.3\n    1   0.0   0.7\n    2   0.7   0.0\n    3   0.2   0.2\n\n    With a dict, the number of places for specific columns can be\n    specified with the column names as key and the number of decimal\n    places as value\n\n    >>> df.round({'dogs': 1, 'cats': 0})\n        dogs  cats\n    0   0.2   0.0\n    1   0.0   1.0\n    2   0.7   0.0\n    3   0.2   0.0\n\n    Using a Series, the number of places for specific columns can be\n    specified with the column names as index and the number of\n    decimal places as value\n\n    >>> decimals = pd.Series([0, 1], index=['cats', 'dogs'])\n    >>> df.round(decimals)\n        dogs  cats\n    0   0.2   0.0\n    1   0.0   1.0\n    2   0.7   0.0\n    3   0.2   0.0\n    \"\"\"\n    from pandas.core.reshape.concat import concat\n\n    def _dict_round(df, decimals):\n        for col, vals in df.items():\n            try:\n                yield _series_round(vals, decimals[col])\n            except KeyError:\n                yield vals\n\n    def _series_round(s, decimals):\n        if is_integer_dtype(s) or is_float_dtype(s):\n            return s.round(decimals)\n        return s\n\n    nv.validate_round(args, kwargs)\n\n    if isinstance(decimals, (dict, Series)):\n        if isinstance(decimals, Series):\n            if not decimals.index.is_unique:\n                raise ValueError(\"Index of decimals must be unique\")\n        new_cols = list(_dict_round(self, decimals))\n    elif is_integer(decimals):\n        # Dispatch to Series.round\n        new_cols = [_series_round(v, decimals) for _, v in self.items()]\n    else:\n        raise TypeError(\"decimals must be an integer, a dict-like or a Series\")\n\n    if len(new_cols) > 0:\n        return self._constructor(\n            concat(new_cols, axis=1), index=self.index, columns=self.columns\n        )\n    else:\n        return self",
                "def corr(self, method=\"pearson\", min_periods=1) -> \"DataFrame\":\n    \"\"\"\n    Compute pairwise correlation of columns, excluding NA/null values.\n\n    Parameters\n    ----------\n    method : {'pearson', 'kendall', 'spearman'} or callable\n        Method of correlation:\n\n        * pearson : standard correlation coefficient\n        * kendall : Kendall Tau correlation coefficient\n        * spearman : Spearman rank correlation\n        * callable: callable with input two 1d ndarrays\n            and returning a float. Note that the returned matrix from corr\n            will have 1 along the diagonals and will be symmetric\n            regardless of the callable's behavior.\n\n            .. versionadded:: 0.24.0\n\n    min_periods : int, optional\n        Minimum number of observations required per pair of columns\n        to have a valid result. Currently only available for Pearson\n        and Spearman correlation.\n\n    Returns\n    -------\n    DataFrame\n        Correlation matrix.\n\n    See Also\n    --------\n    DataFrame.corrwith : Compute pairwise correlation with another\n        DataFrame or Series.\n    Series.corr : Compute the correlation between two Series.\n\n    Examples\n    --------\n    >>> def histogram_intersection(a, b):\n    ...     v = np.minimum(a, b).sum().round(decimals=1)\n    ...     return v\n    >>> df = pd.DataFrame([(.2, .3), (.0, .6), (.6, .0), (.2, .1)],\n    ...                   columns=['dogs', 'cats'])\n    >>> df.corr(method=histogram_intersection)\n          dogs  cats\n    dogs   1.0   0.3\n    cats   0.3   1.0\n    \"\"\"\n    numeric_df = self._get_numeric_data()\n    cols = numeric_df.columns\n    idx = cols.copy()\n    mat = numeric_df.values\n\n    if method == \"pearson\":\n        correl = libalgos.nancorr(ensure_float64(mat), minp=min_periods)\n    elif method == \"spearman\":\n        correl = libalgos.nancorr_spearman(ensure_float64(mat), minp=min_periods)\n    elif method == \"kendall\" or callable(method):\n        if min_periods is None:\n            min_periods = 1\n        mat = ensure_float64(mat).T\n        corrf = nanops.get_corr_func(method)\n        K = len(cols)\n        correl = np.empty((K, K), dtype=float)\n        mask = np.isfinite(mat)\n        for i, ac in enumerate(mat):\n            for j, bc in enumerate(mat):\n                if i > j:\n                    continue\n\n                valid = mask[i] & mask[j]\n                if valid.sum() < min_periods:\n                    c = np.nan\n                elif i == j:\n                    c = 1.0\n                elif not valid.all():\n                    c = corrf(ac[valid], bc[valid])\n                else:\n                    c = corrf(ac, bc)\n                correl[i, j] = c\n                correl[j, i] = c\n    else:\n        raise ValueError(\n            \"method must be either 'pearson', \"\n            \"'spearman', 'kendall', or a callable, \"\n            f\"'{method}' was supplied\"\n        )\n\n    return self._constructor(correl, index=idx, columns=cols)",
                "def cov(self, min_periods=None) -> \"DataFrame\":\n    \"\"\"\n    Compute pairwise covariance of columns, excluding NA/null values.\n\n    Compute the pairwise covariance among the series of a DataFrame.\n    The returned data frame is the `covariance matrix\n    <https://en.wikipedia.org/wiki/Covariance_matrix>`__ of the columns\n    of the DataFrame.\n\n    Both NA and null values are automatically excluded from the\n    calculation. (See the note below about bias from missing values.)\n    A threshold can be set for the minimum number of\n    observations for each value created. Comparisons with observations\n    below this threshold will be returned as ``NaN``.\n\n    This method is generally used for the analysis of time series data to\n    understand the relationship between different measures\n    across time.\n\n    Parameters\n    ----------\n    min_periods : int, optional\n        Minimum number of observations required per pair of columns\n        to have a valid result.\n\n    Returns\n    -------\n    DataFrame\n        The covariance matrix of the series of the DataFrame.\n\n    See Also\n    --------\n    Series.cov : Compute covariance with another Series.\n    core.window.EWM.cov: Exponential weighted sample covariance.\n    core.window.Expanding.cov : Expanding sample covariance.\n    core.window.Rolling.cov : Rolling sample covariance.\n\n    Notes\n    -----\n    Returns the covariance matrix of the DataFrame's time series.\n    The covariance is normalized by N-1.\n\n    For DataFrames that have Series that are missing data (assuming that\n    data is `missing at random\n    <https://en.wikipedia.org/wiki/Missing_data#Missing_at_random>`__)\n    the returned covariance matrix will be an unbiased estimate\n    of the variance and covariance between the member Series.\n\n    However, for many applications this estimate may not be acceptable\n    because the estimate covariance matrix is not guaranteed to be positive\n    semi-definite. This could lead to estimate correlations having\n    absolute values which are greater than one, and/or a non-invertible\n    covariance matrix. See `Estimation of covariance matrices\n    <https://en.wikipedia.org/w/index.php?title=Estimation_of_covariance_\n    matrices>`__ for more details.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame([(1, 2), (0, 3), (2, 0), (1, 1)],\n    ...                   columns=['dogs', 'cats'])\n    >>> df.cov()\n              dogs      cats\n    dogs  0.666667 -1.000000\n    cats -1.000000  1.666667\n\n    >>> np.random.seed(42)\n    >>> df = pd.DataFrame(np.random.randn(1000, 5),\n    ...                   columns=['a', 'b', 'c', 'd', 'e'])\n    >>> df.cov()\n              a         b         c         d         e\n    a  0.998438 -0.020161  0.059277 -0.008943  0.014144\n    b -0.020161  1.059352 -0.008543 -0.024738  0.009826\n    c  0.059277 -0.008543  1.010670 -0.001486 -0.000271\n    d -0.008943 -0.024738 -0.001486  0.921297 -0.013692\n    e  0.014144  0.009826 -0.000271 -0.013692  0.977795\n\n    **Minimum number of periods**\n\n    This method also supports an optional ``min_periods`` keyword\n    that specifies the required minimum number of non-NA observations for\n    each column pair in order to have a valid result:\n\n    >>> np.random.seed(42)\n    >>> df = pd.DataFrame(np.random.randn(20, 3),\n    ...                   columns=['a', 'b', 'c'])\n    >>> df.loc[df.index[:5], 'a'] = np.nan\n    >>> df.loc[df.index[5:10], 'b'] = np.nan\n    >>> df.cov(min_periods=12)\n              a         b         c\n    a  0.316741       NaN -0.150812\n    b       NaN  1.248003  0.191417\n    c -0.150812  0.191417  0.895202\n    \"\"\"\n    numeric_df = self._get_numeric_data()\n    cols = numeric_df.columns\n    idx = cols.copy()\n    mat = numeric_df.values\n\n    if notna(mat).all():\n        if min_periods is not None and min_periods > len(mat):\n            baseCov = np.empty((mat.shape[1], mat.shape[1]))\n            baseCov.fill(np.nan)\n        else:\n            baseCov = np.cov(mat.T)\n        baseCov = baseCov.reshape((len(cols), len(cols)))\n    else:\n        baseCov = libalgos.nancorr(ensure_float64(mat), cov=True, minp=min_periods)\n\n    return self._constructor(baseCov, index=idx, columns=cols)",
                "def corrwith(self, other, axis=0, drop=False, method=\"pearson\") -> Series:\n    \"\"\"\n    Compute pairwise correlation.\n\n    Pairwise correlation is computed between rows or columns of\n    DataFrame with rows or columns of Series or DataFrame. DataFrames\n    are first aligned along both axes before computing the\n    correlations.\n\n    Parameters\n    ----------\n    other : DataFrame, Series\n        Object with which to compute correlations.\n    axis : {0 or 'index', 1 or 'columns'}, default 0\n        The axis to use. 0 or 'index' to compute column-wise, 1 or 'columns' for\n        row-wise.\n    drop : bool, default False\n        Drop missing indices from result.\n    method : {'pearson', 'kendall', 'spearman'} or callable\n        Method of correlation:\n\n        * pearson : standard correlation coefficient\n        * kendall : Kendall Tau correlation coefficient\n        * spearman : Spearman rank correlation\n        * callable: callable with input two 1d ndarrays\n            and returning a float.\n\n        .. versionadded:: 0.24.0\n\n    Returns\n    -------\n    Series\n        Pairwise correlations.\n\n    See Also\n    --------\n    DataFrame.corr : Compute pairwise correlation of columns.\n    \"\"\"\n    axis = self._get_axis_number(axis)\n    this = self._get_numeric_data()\n\n    if isinstance(other, Series):\n        return this.apply(lambda x: other.corr(x, method=method), axis=axis)\n\n    other = other._get_numeric_data()\n    left, right = this.align(other, join=\"inner\", copy=False)\n\n    if axis == 1:\n        left = left.T\n        right = right.T\n\n    if method == \"pearson\":\n        # mask missing values\n        left = left + right * 0\n        right = right + left * 0\n\n        # demeaned data\n        ldem = left - left.mean()\n        rdem = right - right.mean()\n\n        num = (ldem * rdem).sum()\n        dom = (left.count() - 1) * left.std() * right.std()\n\n        correl = num / dom\n\n    elif method in [\"kendall\", \"spearman\"] or callable(method):\n\n        def c(x):\n            return nanops.nancorr(x[0], x[1], method=method)\n\n        correl = Series(\n            map(c, zip(left.values.T, right.values.T)), index=left.columns\n        )\n\n    else:\n        raise ValueError(\n            f\"Invalid method {method} was passed, \"\n            \"valid methods are: 'pearson', 'kendall', \"\n            \"'spearman', or callable\"\n        )\n\n    if not drop:\n        # Find non-matching labels along the given axis\n        # and append missing correlations (GH 22375)\n        raxis = 1 if axis == 0 else 0\n        result_index = this._get_axis(raxis).union(other._get_axis(raxis))\n        idx_diff = result_index.difference(correl.index)\n\n        if len(idx_diff) > 0:\n            correl = correl.append(Series([np.nan] * len(idx_diff), index=idx_diff))\n\n    return correl",
                "def count(self, axis=0, level=None, numeric_only=False):\n    \"\"\"\n    Count non-NA cells for each column or row.\n\n    The values `None`, `NaN`, `NaT`, and optionally `numpy.inf` (depending\n    on `pandas.options.mode.use_inf_as_na`) are considered NA.\n\n    Parameters\n    ----------\n    axis : {0 or 'index', 1 or 'columns'}, default 0\n        If 0 or 'index' counts are generated for each column.\n        If 1 or 'columns' counts are generated for each **row**.\n    level : int or str, optional\n        If the axis is a `MultiIndex` (hierarchical), count along a\n        particular `level`, collapsing into a `DataFrame`.\n        A `str` specifies the level name.\n    numeric_only : bool, default False\n        Include only `float`, `int` or `boolean` data.\n\n    Returns\n    -------\n    Series or DataFrame\n        For each column/row the number of non-NA/null entries.\n        If `level` is specified returns a `DataFrame`.\n\n    See Also\n    --------\n    Series.count: Number of non-NA elements in a Series.\n    DataFrame.shape: Number of DataFrame rows and columns (including NA\n        elements).\n    DataFrame.isna: Boolean same-sized DataFrame showing places of NA\n        elements.\n\n    Examples\n    --------\n    Constructing DataFrame from a dictionary:\n\n    >>> df = pd.DataFrame({\"Person\":\n    ...                    [\"John\", \"Myla\", \"Lewis\", \"John\", \"Myla\"],\n    ...                    \"Age\": [24., np.nan, 21., 33, 26],\n    ...                    \"Single\": [False, True, True, True, False]})\n    >>> df\n       Person   Age  Single\n    0    John  24.0   False\n    1    Myla   NaN    True\n    2   Lewis  21.0    True\n    3    John  33.0    True\n    4    Myla  26.0   False\n\n    Notice the uncounted NA values:\n\n    >>> df.count()\n    Person    5\n    Age       4\n    Single    5\n    dtype: int64\n\n    Counts for each **row**:\n\n    >>> df.count(axis='columns')\n    0    3\n    1    2\n    2    3\n    3    3\n    4    3\n    dtype: int64\n\n    Counts for one level of a `MultiIndex`:\n\n    >>> df.set_index([\"Person\", \"Single\"]).count(level=\"Person\")\n            Age\n    Person\n    John      2\n    Lewis     1\n    Myla      1\n    \"\"\"\n    axis = self._get_axis_number(axis)\n    if level is not None:\n        return self._count_level(level, axis=axis, numeric_only=numeric_only)\n\n    if numeric_only:\n        frame = self._get_numeric_data()\n    else:\n        frame = self\n\n    # GH #423\n    if len(frame._get_axis(axis)) == 0:\n        result = Series(0, index=frame._get_agg_axis(axis))\n    else:\n        if frame._is_mixed_type or frame._data.any_extension_types:\n            # the or any_extension_types is really only hit for single-\n            # column frames with an extension array\n            result = notna(frame).sum(axis=axis)\n        else:\n            # GH13407\n            series_counts = notna(frame).sum(axis=axis)\n            counts = series_counts.values\n            result = Series(counts, index=frame._get_agg_axis(axis))\n\n    return result.astype(\"int64\")",
                "def _count_level(self, level, axis=0, numeric_only=False):\n    if numeric_only:\n        frame = self._get_numeric_data()\n    else:\n        frame = self\n\n    count_axis = frame._get_axis(axis)\n    agg_axis = frame._get_agg_axis(axis)\n\n    if not isinstance(count_axis, ABCMultiIndex):\n        raise TypeError(\n            f\"Can only count levels on hierarchical {self._get_axis_name(axis)}.\"\n        )\n\n    if frame._is_mixed_type:\n        # Since we have mixed types, calling notna(frame.values) might\n        # upcast everything to object\n        mask = notna(frame).values\n    else:\n        # But use the speedup when we have homogeneous dtypes\n        mask = notna(frame.values)\n\n    if axis == 1:\n        # We're transposing the mask rather than frame to avoid potential\n        # upcasts to object, which induces a ~20x slowdown\n        mask = mask.T\n\n    if isinstance(level, str):\n        level = count_axis._get_level_number(level)\n\n    level_name = count_axis._names[level]\n    level_index = count_axis.levels[level]._shallow_copy(name=level_name)\n    level_codes = ensure_int64(count_axis.codes[level])\n    counts = lib.count_level_2d(mask, level_codes, len(level_index), axis=0)\n\n    result = DataFrame(counts, index=level_index, columns=agg_axis)\n\n    if axis == 1:\n        # Undo our earlier transpose\n        return result.T\n    else:\n        return result",
                "def _reduce(\n    self, op, name, axis=0, skipna=True, numeric_only=None, filter_type=None, **kwds\n):\n\n    assert filter_type is None or filter_type == \"bool\", filter_type\n\n    dtype_is_dt = self.dtypes.apply(\n        lambda x: is_datetime64_any_dtype(x) or is_period_dtype(x)\n    )\n    if numeric_only is None and name in [\"mean\", \"median\"] and dtype_is_dt.any():\n        warnings.warn(\n            \"DataFrame.mean and DataFrame.median with numeric_only=None \"\n            \"will include datetime64, datetime64tz, and PeriodDtype columns in a \"\n            \"future version.\",\n            FutureWarning,\n            stacklevel=3,\n        )\n        cols = self.columns[~dtype_is_dt]\n        self = self[cols]\n\n    if axis is None and filter_type == \"bool\":\n        labels = None\n        constructor = None\n    else:\n        # TODO: Make other agg func handle axis=None properly\n        axis = self._get_axis_number(axis)\n        labels = self._get_agg_axis(axis)\n        constructor = self._constructor\n\n    def f(x):\n        return op(x, axis=axis, skipna=skipna, **kwds)\n\n    def _get_data(axis_matters):\n        if filter_type is None:\n            data = self._get_numeric_data()\n        elif filter_type == \"bool\":\n            if axis_matters:\n                # GH#25101, GH#24434\n                data = self._get_bool_data() if axis == 0 else self\n            else:\n                data = self._get_bool_data()\n        else:  # pragma: no cover\n            msg = (\n                f\"Generating numeric_only data with filter_type {filter_type} \"\n                \"not supported.\"\n            )\n            raise NotImplementedError(msg)\n        return data\n\n    if numeric_only is not None and axis in [0, 1]:\n        df = self\n        if numeric_only is True:\n            df = _get_data(axis_matters=True)\n        if axis == 1:\n            df = df.T\n            axis = 0\n\n        out_dtype = \"bool\" if filter_type == \"bool\" else None\n\n        def blk_func(values):\n            if values.ndim == 1 and not isinstance(values, np.ndarray):\n                # we can't pass axis=1\n                return op(values, axis=0, skipna=skipna, **kwds)\n            return op(values, axis=1, skipna=skipna, **kwds)\n\n        # After possibly _get_data and transposing, we are now in the\n        #  simple case where we can use BlockManager._reduce\n        res = df._data.reduce(blk_func)\n        assert isinstance(res, dict)\n        if len(res):\n            assert len(res) == max(list(res.keys())) + 1, res.keys()\n        out = df._constructor_sliced(res, index=range(len(res)), dtype=out_dtype)\n        out.index = df.columns\n        if axis == 0 and df.dtypes.apply(needs_i8_conversion).any():\n            # FIXME: needs_i8_conversion check is kludge, not sure\n            #  why it is necessary in this case and this case alone\n            out[:] = coerce_to_dtypes(out.values, df.dtypes)\n        return out\n\n    if numeric_only is None:\n        data = self\n        values = data.values\n        try:\n            result = f(values)\n\n        except TypeError:\n            # e.g. in nanops trying to convert strs to float\n\n            # try by-column first\n            if filter_type is None and axis == 0:\n                # this can end up with a non-reduction\n                # but not always. if the types are mixed\n                # with datelike then need to make sure a series\n\n                # we only end up here if we have not specified\n                # numeric_only and yet we have tried a\n                # column-by-column reduction, where we have mixed type.\n                # So let's just do what we can\n                from pandas.core.apply import frame_apply\n\n                opa = frame_apply(\n                    self, func=f, result_type=\"expand\", ignore_failures=True\n                )\n                result = opa.get_result()\n                if result.ndim == self.ndim:\n                    result = result.iloc[0]\n                return result\n\n            # TODO: why doesnt axis matter here?\n            data = _get_data(axis_matters=False)\n            labels = data._get_agg_axis(axis)\n\n            values = data.values\n            with np.errstate(all=\"ignore\"):\n                result = f(values)\n    else:\n        if numeric_only:\n            data = _get_data(axis_matters=True)\n            labels = data._get_agg_axis(axis)\n\n            values = data.values\n        else:\n            data = self\n            values = data.values\n        result = f(values)\n\n    if filter_type == \"bool\" and is_object_dtype(values) and axis is None:\n        # work around https://github.com/numpy/numpy/issues/10489\n        # TODO: can we de-duplicate parts of this with the next blocK?\n        result = np.bool_(result)\n    elif hasattr(result, \"dtype\") and is_object_dtype(result.dtype):\n        try:\n            if filter_type is None:\n                result = result.astype(np.float64)\n            elif filter_type == \"bool\" and notna(result).all():\n                result = result.astype(np.bool_)\n        except (ValueError, TypeError):\n            # try to coerce to the original dtypes item by item if we can\n            if axis == 0:\n                result = coerce_to_dtypes(result, data.dtypes)\n\n    if constructor is not None:\n        result = self._constructor_sliced(result, index=labels)\n    return result",
                "def nunique(self, axis=0, dropna=True) -> Series:\n    \"\"\"\n    Count distinct observations over requested axis.\n\n    Return Series with number of distinct observations. Can ignore NaN\n    values.\n\n    Parameters\n    ----------\n    axis : {0 or 'index', 1 or 'columns'}, default 0\n        The axis to use. 0 or 'index' for row-wise, 1 or 'columns' for\n        column-wise.\n    dropna : bool, default True\n        Don't include NaN in the counts.\n\n    Returns\n    -------\n    Series\n\n    See Also\n    --------\n    Series.nunique: Method nunique for Series.\n    DataFrame.count: Count non-NA cells for each column or row.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame({'A': [1, 2, 3], 'B': [1, 1, 1]})\n    >>> df.nunique()\n    A    3\n    B    1\n    dtype: int64\n\n    >>> df.nunique(axis=1)\n    0    1\n    1    2\n    2    2\n    dtype: int64\n    \"\"\"\n    return self.apply(Series.nunique, axis=axis, dropna=dropna)",
                "def idxmin(self, axis=0, skipna=True) -> Series:\n    \"\"\"\n    Return index of first occurrence of minimum over requested axis.\n\n    NA/null values are excluded.\n\n    Parameters\n    ----------\n    axis : {0 or 'index', 1 or 'columns'}, default 0\n        The axis to use. 0 or 'index' for row-wise, 1 or 'columns' for column-wise.\n    skipna : bool, default True\n        Exclude NA/null values. If an entire row/column is NA, the result\n        will be NA.\n\n    Returns\n    -------\n    Series\n        Indexes of minima along the specified axis.\n\n    Raises\n    ------\n    ValueError\n        * If the row/column is empty\n\n    See Also\n    --------\n    Series.idxmin : Return index of the minimum element.\n\n    Notes\n    -----\n    This method is the DataFrame version of ``ndarray.argmin``.\n\n    Examples\n    --------\n    Consider a dataset containing food consumption in Argentina.\n\n    >>> df = pd.DataFrame({'consumption': [10.51, 103.11, 55.48],\n    ...                    'co2_emissions': [37.2, 19.66, 1712]},\n    ...                    index=['Pork', 'Wheat Products', 'Beef'])\n\n    >>> df\n                    consumption  co2_emissions\n    Pork                  10.51         37.20\n    Wheat Products       103.11         19.66\n    Beef                  55.48       1712.00\n\n    By default, it returns the index for the minimum value in each column.\n\n    >>> df.idxmin()\n    consumption                Pork\n    co2_emissions    Wheat Products\n    dtype: object\n\n    To return the index for the minimum value in each row, use ``axis=\"columns\"``.\n\n    >>> df.idxmin(axis=\"columns\")\n    Pork                consumption\n    Wheat Products    co2_emissions\n    Beef                consumption\n    dtype: object\n    \"\"\"\n    axis = self._get_axis_number(axis)\n    indices = nanops.nanargmin(self.values, axis=axis, skipna=skipna)\n    index = self._get_axis(axis)\n    result = [index[i] if i >= 0 else np.nan for i in indices]\n    return Series(result, index=self._get_agg_axis(axis))",
                "def idxmax(self, axis=0, skipna=True) -> Series:\n    \"\"\"\n    Return index of first occurrence of maximum over requested axis.\n\n    NA/null values are excluded.\n\n    Parameters\n    ----------\n    axis : {0 or 'index', 1 or 'columns'}, default 0\n        The axis to use. 0 or 'index' for row-wise, 1 or 'columns' for column-wise.\n    skipna : bool, default True\n        Exclude NA/null values. If an entire row/column is NA, the result\n        will be NA.\n\n    Returns\n    -------\n    Series\n        Indexes of maxima along the specified axis.\n\n    Raises\n    ------\n    ValueError\n        * If the row/column is empty\n\n    See Also\n    --------\n    Series.idxmax : Return index of the maximum element.\n\n    Notes\n    -----\n    This method is the DataFrame version of ``ndarray.argmax``.\n\n    Examples\n    --------\n    Consider a dataset containing food consumption in Argentina.\n\n    >>> df = pd.DataFrame({'consumption': [10.51, 103.11, 55.48],\n    ...                    'co2_emissions': [37.2, 19.66, 1712]},\n    ...                    index=['Pork', 'Wheat Products', 'Beef'])\n\n    >>> df\n                    consumption  co2_emissions\n    Pork                  10.51         37.20\n    Wheat Products       103.11         19.66\n    Beef                  55.48       1712.00\n\n    By default, it returns the index for the maximum value in each column.\n\n    >>> df.idxmax()\n    consumption     Wheat Products\n    co2_emissions             Beef\n    dtype: object\n\n    To return the index for the maximum value in each row, use ``axis=\"columns\"``.\n\n    >>> df.idxmax(axis=\"columns\")\n    Pork              co2_emissions\n    Wheat Products     consumption\n    Beef              co2_emissions\n    dtype: object\n    \"\"\"\n    axis = self._get_axis_number(axis)\n    indices = nanops.nanargmax(self.values, axis=axis, skipna=skipna)\n    index = self._get_axis(axis)\n    result = [index[i] if i >= 0 else np.nan for i in indices]\n    return Series(result, index=self._get_agg_axis(axis))",
                "def _get_agg_axis(self, axis_num):\n    \"\"\"\n    Let's be explicit about this.\n    \"\"\"\n    if axis_num == 0:\n        return self.columns\n    elif axis_num == 1:\n        return self.index\n    else:\n        raise ValueError(f\"Axis must be 0 or 1 (got {repr(axis_num)})\")",
                "def mode(self, axis=0, numeric_only=False, dropna=True) -> \"DataFrame\":\n    \"\"\"\n    Get the mode(s) of each element along the selected axis.\n\n    The mode of a set of values is the value that appears most often.\n    It can be multiple values.\n\n    Parameters\n    ----------\n    axis : {0 or 'index', 1 or 'columns'}, default 0\n        The axis to iterate over while searching for the mode:\n\n        * 0 or 'index' : get mode of each column\n        * 1 or 'columns' : get mode of each row.\n\n    numeric_only : bool, default False\n        If True, only apply to numeric columns.\n    dropna : bool, default True\n        Don't consider counts of NaN/NaT.\n\n        .. versionadded:: 0.24.0\n\n    Returns\n    -------\n    DataFrame\n        The modes of each column or row.\n\n    See Also\n    --------\n    Series.mode : Return the highest frequency value in a Series.\n    Series.value_counts : Return the counts of values in a Series.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame([('bird', 2, 2),\n    ...                    ('mammal', 4, np.nan),\n    ...                    ('arthropod', 8, 0),\n    ...                    ('bird', 2, np.nan)],\n    ...                   index=('falcon', 'horse', 'spider', 'ostrich'),\n    ...                   columns=('species', 'legs', 'wings'))\n    >>> df\n               species  legs  wings\n    falcon        bird     2    2.0\n    horse       mammal     4    NaN\n    spider   arthropod     8    0.0\n    ostrich       bird     2    NaN\n\n    By default, missing values are not considered, and the mode of wings\n    are both 0 and 2. The second row of species and legs contains ``NaN``,\n    because they have only one mode, but the DataFrame has two rows.\n\n    >>> df.mode()\n      species  legs  wings\n    0    bird   2.0    0.0\n    1     NaN   NaN    2.0\n\n    Setting ``dropna=False`` ``NaN`` values are considered and they can be\n    the mode (like for wings).\n\n    >>> df.mode(dropna=False)\n      species  legs  wings\n    0    bird     2    NaN\n\n    Setting ``numeric_only=True``, only the mode of numeric columns is\n    computed, and columns of other types are ignored.\n\n    >>> df.mode(numeric_only=True)\n       legs  wings\n    0   2.0    0.0\n    1   NaN    2.0\n\n    To compute the mode over columns and not rows, use the axis parameter:\n\n    >>> df.mode(axis='columns', numeric_only=True)\n               0    1\n    falcon   2.0  NaN\n    horse    4.0  NaN\n    spider   0.0  8.0\n    ostrich  2.0  NaN\n    \"\"\"\n    data = self if not numeric_only else self._get_numeric_data()\n\n    def f(s):\n        return s.mode(dropna=dropna)\n\n    return data.apply(f, axis=axis)",
                "def quantile(self, q=0.5, axis=0, numeric_only=True, interpolation=\"linear\"):\n    \"\"\"\n    Return values at the given quantile over requested axis.\n\n    Parameters\n    ----------\n    q : float or array-like, default 0.5 (50% quantile)\n        Value between 0 <= q <= 1, the quantile(s) to compute.\n    axis : {0, 1, 'index', 'columns'} (default 0)\n        Equals 0 or 'index' for row-wise, 1 or 'columns' for column-wise.\n    numeric_only : bool, default True\n        If False, the quantile of datetime and timedelta data will be\n        computed as well.\n    interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}\n        This optional parameter specifies the interpolation method to use,\n        when the desired quantile lies between two data points `i` and `j`:\n\n        * linear: `i + (j - i) * fraction`, where `fraction` is the\n          fractional part of the index surrounded by `i` and `j`.\n        * lower: `i`.\n        * higher: `j`.\n        * nearest: `i` or `j` whichever is nearest.\n        * midpoint: (`i` + `j`) / 2.\n\n    Returns\n    -------\n    Series or DataFrame\n\n        If ``q`` is an array, a DataFrame will be returned where the\n          index is ``q``, the columns are the columns of self, and the\n          values are the quantiles.\n        If ``q`` is a float, a Series will be returned where the\n          index is the columns of self and the values are the quantiles.\n\n    See Also\n    --------\n    core.window.Rolling.quantile: Rolling quantile.\n    numpy.percentile: Numpy function to compute the percentile.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame(np.array([[1, 1], [2, 10], [3, 100], [4, 100]]),\n    ...                   columns=['a', 'b'])\n    >>> df.quantile(.1)\n    a    1.3\n    b    3.7\n    Name: 0.1, dtype: float64\n    >>> df.quantile([.1, .5])\n           a     b\n    0.1  1.3   3.7\n    0.5  2.5  55.0\n\n    Specifying `numeric_only=False` will also compute the quantile of\n    datetime and timedelta data.\n\n    >>> df = pd.DataFrame({'A': [1, 2],\n    ...                    'B': [pd.Timestamp('2010'),\n    ...                          pd.Timestamp('2011')],\n    ...                    'C': [pd.Timedelta('1 days'),\n    ...                          pd.Timedelta('2 days')]})\n    >>> df.quantile(0.5, numeric_only=False)\n    A                    1.5\n    B    2010-07-02 12:00:00\n    C        1 days 12:00:00\n    Name: 0.5, dtype: object\n    \"\"\"\n    validate_percentile(q)\n\n    data = self._get_numeric_data() if numeric_only else self\n    axis = self._get_axis_number(axis)\n    is_transposed = axis == 1\n\n    if is_transposed:\n        data = data.T\n\n    if len(data.columns) == 0:\n        # GH#23925 _get_numeric_data may have dropped all columns\n        cols = Index([], name=self.columns.name)\n        if is_list_like(q):\n            return self._constructor([], index=q, columns=cols)\n        return self._constructor_sliced([], index=cols, name=q, dtype=np.float64)\n\n    result = data._data.quantile(\n        qs=q, axis=1, interpolation=interpolation, transposed=is_transposed\n    )\n\n    if result.ndim == 2:\n        result = self._constructor(result)\n    else:\n        result = self._constructor_sliced(result, name=q)\n\n    if is_transposed:\n        result = result.T\n\n    return result",
                "def to_timestamp(\n    self, freq=None, how: str = \"start\", axis: Axis = 0, copy: bool = True\n) -> \"DataFrame\":\n    \"\"\"\n    Cast to DatetimeIndex of timestamps, at *beginning* of period.\n\n    Parameters\n    ----------\n    freq : str, default frequency of PeriodIndex\n        Desired frequency.\n    how : {'s', 'e', 'start', 'end'}\n        Convention for converting period to timestamp; start of period\n        vs. end.\n    axis : {0 or 'index', 1 or 'columns'}, default 0\n        The axis to convert (the index by default).\n    copy : bool, default True\n        If False then underlying input data is not copied.\n\n    Returns\n    -------\n    DataFrame with DatetimeIndex\n    \"\"\"\n    new_obj = self.copy(deep=copy)\n\n    axis_name = self._get_axis_name(axis)\n    old_ax = getattr(self, axis_name)\n    new_ax = old_ax.to_timestamp(freq=freq, how=how)\n\n    setattr(new_obj, axis_name, new_ax)\n    return new_obj",
                "def to_period(self, freq=None, axis: Axis = 0, copy: bool = True) -> \"DataFrame\":\n    \"\"\"\n    Convert DataFrame from DatetimeIndex to PeriodIndex.\n\n    Convert DataFrame from DatetimeIndex to PeriodIndex with desired\n    frequency (inferred from index if not passed).\n\n    Parameters\n    ----------\n    freq : str, default\n        Frequency of the PeriodIndex.\n    axis : {0 or 'index', 1 or 'columns'}, default 0\n        The axis to convert (the index by default).\n    copy : bool, default True\n        If False then underlying input data is not copied.\n\n    Returns\n    -------\n    DataFrame with PeriodIndex\n    \"\"\"\n    new_obj = self.copy(deep=copy)\n\n    axis_name = self._get_axis_name(axis)\n    old_ax = getattr(self, axis_name)\n    new_ax = old_ax.to_period(freq=freq)\n\n    setattr(new_obj, axis_name, new_ax)\n    return new_obj",
                "def isin(self, values) -> \"DataFrame\":\n    \"\"\"\n    Whether each element in the DataFrame is contained in values.\n\n    Parameters\n    ----------\n    values : iterable, Series, DataFrame or dict\n        The result will only be true at a location if all the\n        labels match. If `values` is a Series, that's the index. If\n        `values` is a dict, the keys must be the column names,\n        which must match. If `values` is a DataFrame,\n        then both the index and column labels must match.\n\n    Returns\n    -------\n    DataFrame\n        DataFrame of booleans showing whether each element in the DataFrame\n        is contained in values.\n\n    See Also\n    --------\n    DataFrame.eq: Equality test for DataFrame.\n    Series.isin: Equivalent method on Series.\n    Series.str.contains: Test if pattern or regex is contained within a\n        string of a Series or Index.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame({'num_legs': [2, 4], 'num_wings': [2, 0]},\n    ...                   index=['falcon', 'dog'])\n    >>> df\n            num_legs  num_wings\n    falcon         2          2\n    dog            4          0\n\n    When ``values`` is a list check whether every value in the DataFrame\n    is present in the list (which animals have 0 or 2 legs or wings)\n\n    >>> df.isin([0, 2])\n            num_legs  num_wings\n    falcon      True       True\n    dog        False       True\n\n    When ``values`` is a dict, we can pass values to check for each\n    column separately:\n\n    >>> df.isin({'num_wings': [0, 3]})\n            num_legs  num_wings\n    falcon     False      False\n    dog        False       True\n\n    When ``values`` is a Series or DataFrame the index and column must\n    match. Note that 'falcon' does not match based on the number of legs\n    in df2.\n\n    >>> other = pd.DataFrame({'num_legs': [8, 2], 'num_wings': [0, 2]},\n    ...                      index=['spider', 'falcon'])\n    >>> df.isin(other)\n            num_legs  num_wings\n    falcon      True       True\n    dog        False      False\n    \"\"\"\n    if isinstance(values, dict):\n        from pandas.core.reshape.concat import concat\n\n        values = collections.defaultdict(list, values)\n        return concat(\n            (\n                self.iloc[:, [i]].isin(values[col])\n                for i, col in enumerate(self.columns)\n            ),\n            axis=1,\n        )\n    elif isinstance(values, Series):\n        if not values.index.is_unique:\n            raise ValueError(\"cannot compute isin with a duplicate axis.\")\n        return self.eq(values.reindex_like(self), axis=\"index\")\n    elif isinstance(values, DataFrame):\n        if not (values.columns.is_unique and values.index.is_unique):\n            raise ValueError(\"cannot compute isin with a duplicate axis.\")\n        return self.eq(values.reindex_like(self))\n    else:\n        if not is_list_like(values):\n            raise TypeError(\n                \"only list-like or dict-like objects are allowed \"\n                \"to be passed to DataFrame.isin(), \"\n                f\"you passed a '{type(values).__name__}'\"\n            )\n        return DataFrame(\n            algorithms.isin(self.values.ravel(), values).reshape(self.shape),\n            self.index,\n            self.columns,\n        )",
                "def extract_unique_dtypes_from_dtypes_set(\n    dtypes_set: FrozenSet[Dtype], unique_dtypes: np.ndarray\n) -> List[Dtype]:\n    extracted_dtypes = [\n        unique_dtype\n        for unique_dtype in unique_dtypes\n        if issubclass(unique_dtype.type, tuple(dtypes_set))  # type: ignore\n    ]\n    return extracted_dtypes",
                "def reindexer(value):\n    # reindex if necessary\n\n    if value.index.equals(self.index) or not len(self.index):\n        value = value._values.copy()\n    else:\n\n        # GH 4107\n        try:\n            value = value.reindex(self.index)._values\n        except ValueError as err:\n            # raised in MultiIndex.from_tuples, see test_insert_error_msmgs\n            if not value.index.is_unique:\n                # duplicate axis\n                raise err\n\n            # other\n            raise TypeError(\n                \"incompatible index of inserted column with frame index\"\n            ) from err\n    return value",
                "def _maybe_casted_values(index, labels=None):\n    values = index._values\n    if not isinstance(index, (PeriodIndex, DatetimeIndex)):\n        if values.dtype == np.object_:\n            values = lib.maybe_convert_objects(values)\n\n    # if we have the labels, extract the values with a mask\n    if labels is not None:\n        mask = labels == -1\n\n        # we can have situations where the whole mask is -1,\n        # meaning there is nothing found in labels, so make all nan's\n        if mask.all():\n            values = np.empty(len(mask))\n            values.fill(np.nan)\n        else:\n            values = values.take(labels)\n\n            # TODO(https://github.com/pandas-dev/pandas/issues/24206)\n            # Push this into maybe_upcast_putmask?\n            # We can't pass EAs there right now. Looks a bit\n            # complicated.\n            # So we unbox the ndarray_values, op, re-box.\n            values_type = type(values)\n            values_dtype = values.dtype\n\n            if issubclass(values_type, DatetimeLikeArray):\n                values = values._data\n\n            if mask.any():\n                values, _ = maybe_upcast_putmask(values, mask, np.nan)\n\n            if issubclass(values_type, DatetimeLikeArray):\n                values = values_type(values, dtype=values_dtype)\n\n    return values",
                "def f(vals):\n    labels, shape = algorithms.factorize(\n        vals, size_hint=min(len(self), _SIZE_HINT_LIMIT)\n    )\n    return labels.astype(\"i8\", copy=False), len(shape)",
                "def extract_values(arr):\n    # Does two things:\n    # 1. maybe gets the values from the Series / Index\n    # 2. convert datelike to i8\n    if isinstance(arr, (ABCIndexClass, ABCSeries)):\n        arr = arr._values\n\n    if needs_i8_conversion(arr):\n        if is_extension_array_dtype(arr.dtype):\n            arr = arr.asi8\n        else:\n            arr = arr.view(\"i8\")\n    return arr",
                "def combiner(x, y):\n    mask = isna(x)\n    if isinstance(mask, (ABCIndexClass, ABCSeries)):\n        mask = mask._values\n\n    x_values = extract_values(x)\n    y_values = extract_values(y)\n\n    # If the column y in other DataFrame is not in first DataFrame,\n    # just return y_values.\n    if y.name not in self.columns:\n        return y_values\n\n    return expressions.where(mask, y_values, x_values)",
                "def infer(x):\n    if x.empty:\n        return lib.map_infer(x, func)\n    return lib.map_infer(x.astype(object).values, func)",
                "def _dict_round(df, decimals):\n    for col, vals in df.items():\n        try:\n            yield _series_round(vals, decimals[col])\n        except KeyError:\n            yield vals",
                "def _series_round(s, decimals):\n    if is_integer_dtype(s) or is_float_dtype(s):\n        return s.round(decimals)\n    return s",
                "def f(x):\n    return op(x, axis=axis, skipna=skipna, **kwds)",
                "def _get_data(axis_matters):\n    if filter_type is None:\n        data = self._get_numeric_data()\n    elif filter_type == \"bool\":\n        if axis_matters:\n            # GH#25101, GH#24434\n            data = self._get_bool_data() if axis == 0 else self\n        else:\n            data = self._get_bool_data()\n    else:  # pragma: no cover\n        msg = (\n            f\"Generating numeric_only data with filter_type {filter_type} \"\n            \"not supported.\"\n        )\n        raise NotImplementedError(msg)\n    return data",
                "def f(s):\n    return s.mode(dropna=dropna)",
                "def _arith_op(left, right):\n    # for the mixed_type case where we iterate over columns,\n    # _arith_op(left, right) is equivalent to\n    # left._binop(right, func, fill_value=fill_value)\n    left, right = ops.fill_binop(left, right, fill_value)\n    return func(left, right)",
                "def blk_func(values):\n    if values.ndim == 1 and not isinstance(values, np.ndarray):\n        # we can't pass axis=1\n        return op(values, axis=0, skipna=skipna, **kwds)\n    return op(values, axis=1, skipna=skipna, **kwds)",
                "def c(x):\n    return nanops.nancorr(x[0], x[1], method=method)"
            ],
            "inscope_function_signatures": [
                "_from_nested_dict(data)",
                "_constructor(self) -> Type['DataFrame']",
                "_constructor_expanddim(self)",
                "__init__(self, data=None, index: Optional[Axes]=None, columns: Optional[Axes]=None, dtype: Optional[Dtype]=None, copy: bool=False)",
                "axes(self) -> List[Index]",
                "shape(self) -> Tuple[int, int]",
                "_is_homogeneous_type(self) -> bool",
                "_repr_fits_vertical_(self) -> bool",
                "_repr_fits_horizontal_(self, ignore_width: bool=False) -> bool",
                "_info_repr(self) -> bool",
                "__repr__(self) -> str",
                "_repr_html_(self) -> Optional[str]",
                "to_string(self, buf: Optional[FilePathOrBuffer[str]]=None, columns: Optional[Sequence[str]]=None, col_space: Optional[int]=None, header: Union[bool, Sequence[str]]=True, index: bool=True, na_rep: str='NaN', formatters: Optional[fmt.FormattersType]=None, float_format: Optional[fmt.FloatFormatType]=None, sparsify: Optional[bool]=None, index_names: bool=True, justify: Optional[str]=None, max_rows: Optional[int]=None, min_rows: Optional[int]=None, max_cols: Optional[int]=None, show_dimensions: bool=False, decimal: str='.', line_width: Optional[int]=None, max_colwidth: Optional[int]=None, encoding: Optional[str]=None) -> Optional[str]",
                "style(self) -> 'Styler'",
                "items(self) -> Iterable[Tuple[Label, Series]]",
                "iteritems(self) -> Iterable[Tuple[Label, Series]]",
                "iterrows(self) -> Iterable[Tuple[Label, Series]]",
                "itertuples(self, index=True, name='Pandas')",
                "__len__(self) -> int",
                "dot(self, other)",
                "__matmul__(self, other)",
                "__rmatmul__(self, other)",
                "from_dict(cls, data, orient='columns', dtype=None, columns=None) -> 'DataFrame'",
                "to_numpy(self, dtype=None, copy=False) -> np.ndarray",
                "to_dict(self, orient='dict', into=dict)",
                "to_gbq(self, destination_table, project_id=None, chunksize=None, reauth=False, if_exists='fail', auth_local_webserver=False, table_schema=None, location=None, progress_bar=True, credentials=None) -> None",
                "from_records(cls, data, index=None, exclude=None, columns=None, coerce_float=False, nrows=None) -> 'DataFrame'",
                "to_records(self, index=True, column_dtypes=None, index_dtypes=None) -> np.recarray",
                "_from_arrays(cls, arrays, columns, index, dtype=None) -> 'DataFrame'",
                "to_stata(self, path: FilePathOrBuffer, convert_dates: Optional[Dict[Label, str]]=None, write_index: bool=True, byteorder: Optional[str]=None, time_stamp: Optional[datetime.datetime]=None, data_label: Optional[str]=None, variable_labels: Optional[Dict[Label, str]]=None, version: Optional[int]=114, convert_strl: Optional[Sequence[Label]]=None) -> None",
                "to_feather(self, path) -> None",
                "to_markdown(self, buf: Optional[IO[str]]=None, mode: Optional[str]=None, **kwargs) -> Optional[str]",
                "to_parquet(self, path, engine='auto', compression='snappy', index=None, partition_cols=None, **kwargs) -> None",
                "to_html(self, buf=None, columns=None, col_space=None, header=True, index=True, na_rep='NaN', formatters=None, float_format=None, sparsify=None, index_names=True, justify=None, max_rows=None, max_cols=None, show_dimensions=False, decimal='.', bold_rows=True, classes=None, escape=True, notebook=False, border=None, table_id=None, render_links=False, encoding=None)",
                "info(self, verbose=None, buf=None, max_cols=None, memory_usage=None, null_counts=None) -> None",
                "memory_usage(self, index=True, deep=False) -> Series",
                "transpose(self, *args) -> 'DataFrame'",
                "T(self) -> 'DataFrame'",
                "_ixs(self, i: int, axis: int=0)",
                "__getitem__(self, key)",
                "_getitem_bool_array(self, key)",
                "_getitem_multilevel(self, key)",
                "_get_value(self, index, col, takeable: bool=False)",
                "__setitem__(self, key, value)",
                "_setitem_slice(self, key: slice, value)",
                "_setitem_array(self, key, value)",
                "_setitem_frame(self, key, value)",
                "_iset_item(self, loc: int, value)",
                "_set_item(self, key, value)",
                "_set_value(self, index, col, value, takeable: bool=False)",
                "_ensure_valid_index(self, value)",
                "_box_item_values(self, key, values)",
                "_box_col_values(self, values, items)",
                "query(self, expr, inplace=False, **kwargs)",
                "eval(self, expr, inplace=False, **kwargs)",
                "select_dtypes(self, include=None, exclude=None) -> 'DataFrame'",
                "insert(self, loc, column, value, allow_duplicates=False) -> None",
                "assign(self, **kwargs) -> 'DataFrame'",
                "_sanitize_column(self, key, value, broadcast=True)",
                "_series(self)",
                "lookup(self, row_labels, col_labels) -> np.ndarray",
                "_reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy)",
                "_reindex_index(self, new_index, method, copy, level, fill_value=np.nan, limit=None, tolerance=None)",
                "_reindex_columns(self, new_columns, method, copy, level, fill_value=None, limit=None, tolerance=None)",
                "_reindex_multi(self, axes, copy, fill_value) -> 'DataFrame'",
                "align(self, other, join='outer', axis=None, level=None, copy=True, fill_value=None, method=None, limit=None, fill_axis=0, broadcast_axis=None) -> 'DataFrame'",
                "set_axis(self, labels, axis: Axis=0, inplace: bool=False)",
                "reindex(self, *args, **kwargs) -> 'DataFrame'",
                "drop(self, labels=None, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise')",
                "rename(self, mapper: Optional[Renamer]=None) -> Optional['DataFrame']",
                "fillna(self, value=None, method=None, axis=None, inplace=False, limit=None, downcast=None) -> Optional['DataFrame']",
                "replace(self, to_replace=None, value=None, inplace=False, limit=None, regex=False, method='pad')",
                "shift(self, periods=1, freq=None, axis=0, fill_value=None) -> 'DataFrame'",
                "set_index(self, keys, drop=True, append=False, inplace=False, verify_integrity=False)",
                "reset_index(self, level: Optional[Union[Hashable, Sequence[Hashable]]]=None, drop: bool=False, inplace: bool=False, col_level: Hashable=0, col_fill: Label='') -> Optional['DataFrame']",
                "isna(self) -> 'DataFrame'",
                "isnull(self) -> 'DataFrame'",
                "notna(self) -> 'DataFrame'",
                "notnull(self) -> 'DataFrame'",
                "dropna(self, axis=0, how='any', thresh=None, subset=None, inplace=False)",
                "drop_duplicates(self, subset: Optional[Union[Hashable, Sequence[Hashable]]]=None, keep: Union[str, bool]='first', inplace: bool=False, ignore_index: bool=False) -> Optional['DataFrame']",
                "duplicated(self, subset: Optional[Union[Hashable, Sequence[Hashable]]]=None, keep: Union[str, bool]='first') -> 'Series'",
                "sort_values(self, by, axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last', ignore_index=False)",
                "sort_index(self, axis=0, level=None, ascending: bool=True, inplace: bool=False, kind: str='quicksort', na_position: str='last', sort_remaining: bool=True, ignore_index: bool=False)",
                "value_counts(self, subset: Optional[Sequence[Label]]=None, normalize: bool=False, sort: bool=True, ascending: bool=False)",
                "nlargest(self, n, columns, keep='first') -> 'DataFrame'",
                "nsmallest(self, n, columns, keep='first') -> 'DataFrame'",
                "swaplevel(self, i=-2, j=-1, axis=0) -> 'DataFrame'",
                "reorder_levels(self, order, axis=0) -> 'DataFrame'",
                "_combine_frame(self, other: 'DataFrame', func, fill_value=None)",
                "_construct_result(self, result) -> 'DataFrame'",
                "combine(self, other: 'DataFrame', func, fill_value=None, overwrite=True) -> 'DataFrame'",
                "combine_first(self, other: 'DataFrame') -> 'DataFrame'",
                "update(self, other, join='left', overwrite=True, filter_func=None, errors='ignore') -> None",
                "groupby(self, by=None, axis=0, level=None, as_index: bool=True, sort: bool=True, group_keys: bool=True, squeeze: bool=False, observed: bool=False) -> 'DataFrameGroupBy'",
                "pivot(self, index=None, columns=None, values=None) -> 'DataFrame'",
                "pivot_table(self, values=None, index=None, columns=None, aggfunc='mean', fill_value=None, margins=False, dropna=True, margins_name='All', observed=False) -> 'DataFrame'",
                "stack(self, level=-1, dropna=True)",
                "explode(self, column: Union[str, Tuple]) -> 'DataFrame'",
                "unstack(self, level=-1, fill_value=None)",
                "melt(self, id_vars=None, value_vars=None, var_name=None, value_name='value', col_level=None) -> 'DataFrame'",
                "diff(self, periods=1, axis=0) -> 'DataFrame'",
                "_gotitem(self, key: Union[str, List[str]], ndim: int, subset: Optional[Union[Series, ABCDataFrame]]=None) -> Union[Series, ABCDataFrame]",
                "aggregate(self, func, axis=0, *args, **kwargs)",
                "_aggregate(self, arg, axis=0, *args, **kwargs)",
                "transform(self, func, axis=0, *args, **kwargs) -> 'DataFrame'",
                "apply(self, func, axis=0, raw=False, result_type=None, args=(), **kwds)",
                "applymap(self, func) -> 'DataFrame'",
                "append(self, other, ignore_index=False, verify_integrity=False, sort=False) -> 'DataFrame'",
                "join(self, other, on=None, how='left', lsuffix='', rsuffix='', sort=False) -> 'DataFrame'",
                "_join_compat(self, other, on=None, how='left', lsuffix='', rsuffix='', sort=False)",
                "merge(self, right, how='inner', on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=False, suffixes=('_x', '_y'), copy=True, indicator=False, validate=None) -> 'DataFrame'",
                "round(self, decimals=0, *args, **kwargs) -> 'DataFrame'",
                "corr(self, method='pearson', min_periods=1) -> 'DataFrame'",
                "cov(self, min_periods=None) -> 'DataFrame'",
                "corrwith(self, other, axis=0, drop=False, method='pearson') -> Series",
                "count(self, axis=0, level=None, numeric_only=False)",
                "_count_level(self, level, axis=0, numeric_only=False)",
                "_reduce(self, op, name, axis=0, skipna=True, numeric_only=None, filter_type=None, **kwds)",
                "nunique(self, axis=0, dropna=True) -> Series",
                "idxmin(self, axis=0, skipna=True) -> Series",
                "idxmax(self, axis=0, skipna=True) -> Series",
                "_get_agg_axis(self, axis_num)",
                "mode(self, axis=0, numeric_only=False, dropna=True) -> 'DataFrame'",
                "quantile(self, q=0.5, axis=0, numeric_only=True, interpolation='linear')",
                "to_timestamp(self, freq=None, how: str='start', axis: Axis=0, copy: bool=True) -> 'DataFrame'",
                "to_period(self, freq=None, axis: Axis=0, copy: bool=True) -> 'DataFrame'",
                "isin(self, values) -> 'DataFrame'",
                "extract_unique_dtypes_from_dtypes_set(dtypes_set: FrozenSet[Dtype], unique_dtypes: np.ndarray) -> List[Dtype]",
                "reindexer(value)",
                "_maybe_casted_values(index, labels=None)",
                "f(vals)",
                "extract_values(arr)",
                "combiner(x, y)",
                "infer(x)",
                "_dict_round(df, decimals)",
                "_series_round(s, decimals)",
                "f(x)",
                "_get_data(axis_matters)",
                "f(s)",
                "_arith_op(left, right)",
                "blk_func(values)",
                "c(x)"
            ],
            "variables_in_file": {
                "TYPE_CHECKING": [
                    136
                ],
                "_shared_doc_kwargs": [
                    3552,
                    3937,
                    5696,
                    3621,
                    4683,
                    3918,
                    143,
                    4398,
                    4402,
                    3956,
                    4406,
                    6679,
                    4410,
                    3612,
                    6653
                ],
                "dict": [
                    2435,
                    7875,
                    6439,
                    143,
                    1618,
                    1427,
                    6996,
                    6997,
                    438,
                    2423,
                    440,
                    7347,
                    8442,
                    1307,
                    8508,
                    1438,
                    1240
                ],
                "_numeric_only_doc": [
                    170
                ],
                "_merge_doc": [
                    7220,
                    175
                ],
                "NDFrame": [
                    3617,
                    324,
                    517,
                    3622,
                    4684,
                    3918,
                    402,
                    2739,
                    410,
                    2719
                ],
                "_internal_names_set": [
                    402
                ],
                "NDFrame._internal_names_set": [
                    402
                ],
                "_typ": [
                    403
                ],
                "DataFrame": [
                    7175,
                    7177,
                    8457,
                    8468,
                    407,
                    3362,
                    433,
                    8499,
                    8500,
                    8502,
                    8503,
                    2512,
                    3416,
                    1632,
                    2657,
                    1123,
                    7024,
                    5617,
                    5618,
                    7025,
                    1141,
                    7799,
                    2684
                ],
                "property": [
                    521,
                    829,
                    560,
                    2448,
                    405,
                    538,
                    3421,
                    413
                ],
                "Type": [
                    409,
                    406
                ],
                "_constructor_sliced": [
                    409
                ],
                "Series": [
                    1152,
                    7172,
                    8453,
                    904,
                    907,
                    2316,
                    7567,
                    2576,
                    2321,
                    7952,
                    409,
                    3359,
                    4646,
                    3367,
                    6568,
                    2601,
                    6569,
                    7347,
                    7348,
                    7990,
                    2232,
                    7608,
                    7992,
                    8124,
                    4678,
                    7750,
                    460,
                    7760,
                    6996,
                    7637,
                    1240,
                    7000,
                    8057,
                    3424,
                    1123,
                    2659,
                    485,
                    2788,
                    7656,
                    1145,
                    1146,
                    8059,
                    2556,
                    895
                ],
                "_deprecations": [
                    410
                ],
                "FrozenSet": [
                    3200,
                    410
                ],
                "str": [
                    1792,
                    8321,
                    770,
                    773,
                    774,
                    4741,
                    4742,
                    765,
                    4619,
                    2959,
                    410,
                    411,
                    668,
                    6566,
                    1964,
                    1838,
                    4658,
                    698,
                    6207,
                    1856,
                    1858,
                    1860,
                    1861,
                    4558,
                    3798,
                    473,
                    2017,
                    2018,
                    7791,
                    755,
                    756,
                    1653,
                    758,
                    760,
                    1789
                ],
                "NDFrame._deprecations": [
                    410
                ],
                "frozenset": [
                    410,
                    3187,
                    3180,
                    3186
                ],
                "_accessors": [
                    411
                ],
                "Set": [
                    411
                ],
                "NotImplementedError": [
                    5613,
                    7853,
                    2789,
                    415
                ],
                "Optional": [
                    768,
                    4353,
                    771,
                    772,
                    773,
                    774,
                    4618,
                    423,
                    424,
                    425,
                    6568,
                    698,
                    4154,
                    4159,
                    1856,
                    1858,
                    1859,
                    1860,
                    1861,
                    1862,
                    1863,
                    4557,
                    3790,
                    3792,
                    3793,
                    3794,
                    4561,
                    3797,
                    3799,
                    3927,
                    2017,
                    2018,
                    4840,
                    755,
                    756,
                    757,
                    761,
                    762,
                    763,
                    765,
                    766,
                    767
                ],
                "Axes": [
                    424,
                    423
                ],
                "Dtype": [
                    3200,
                    425,
                    3201
                ],
                "bool": [
                    769,
                    8321,
                    4739,
                    4740,
                    4743,
                    4744,
                    4619,
                    659,
                    2326,
                    8351,
                    3618,
                    4646,
                    426,
                    561,
                    2611,
                    4155,
                    2747,
                    4156,
                    1857,
                    5702,
                    5703,
                    5704,
                    5705,
                    5706,
                    4558,
                    4559,
                    4560,
                    3795,
                    3796,
                    599,
                    606,
                    2535,
                    4841,
                    4842,
                    4843,
                    758,
                    759,
                    763,
                    764
                ],
                "data": [
                    8217,
                    8222,
                    1593,
                    1598,
                    1609,
                    1611,
                    1614,
                    1616,
                    1618,
                    1620,
                    1621,
                    1625,
                    1632,
                    1633,
                    8292,
                    1638,
                    8297,
                    8299,
                    8306,
                    7841,
                    7845,
                    7847,
                    7854,
                    7887,
                    7888,
                    1238,
                    1240,
                    1241,
                    1243,
                    1250,
                    7916,
                    7917,
                    3311,
                    7919,
                    3314,
                    3315,
                    7924,
                    7925,
                    7927,
                    7929,
                    7930,
                    7946,
                    8509,
                    428,
                    429,
                    433,
                    434,
                    436,
                    438,
                    440,
                    441,
                    442,
                    446,
                    447,
                    451,
                    453,
                    454,
                    455,
                    457,
                    458,
                    460,
                    461,
                    462,
                    463,
                    466,
                    467,
                    468,
                    470,
                    473,
                    474,
                    475,
                    476,
                    477,
                    478,
                    479,
                    480,
                    485,
                    486,
                    487,
                    488,
                    490,
                    2538,
                    494,
                    2545,
                    2546,
                    499,
                    2548,
                    509
                ],
                "dtype": [
                    2433,
                    1304,
                    430,
                    431,
                    438,
                    441,
                    1849,
                    2429,
                    447,
                    1602,
                    1604,
                    458,
                    1613,
                    1614,
                    466,
                    468,
                    470,
                    480,
                    1250,
                    492,
                    494,
                    496,
                    499,
                    509,
                    2430
                ],
                "self._validate_dtype": [
                    431
                ],
                "self": [
                    4096,
                    4097,
                    4098,
                    4099,
                    4101,
                    8217,
                    4126,
                    4130,
                    6203,
                    6205,
                    2114,
                    8292,
                    8293,
                    8301,
                    8303,
                    8304,
                    8311,
                    6265,
                    8313,
                    6268,
                    6273,
                    6274,
                    2196,
                    8342,
                    8344,
                    8345,
                    8371,
                    8373,
                    2230,
                    8374,
                    6339,
                    4303,
                    4305,
                    4348,
                    4349,
                    4350,
                    8448,
                    8449,
                    4354,
                    4357,
                    4359,
                    8456,
                    4361,
                    4362,
                    4363,
                    8460,
                    2317,
                    2318,
                    4365,
                    2321,
                    4373,
                    8469,
                    8470,
                    8471,
                    4380,
                    4382,
                    6456,
                    2426,
                    2427,
                    2431,
                    2434,
                    2435,
                    2439,
                    2442,
                    2443,
                    2446,
                    2450,
                    6557,
                    6558,
                    6559,
                    2468,
                    2472,
                    2474,
                    2475,
                    4522,
                    4525,
                    2478,
                    431,
                    4527,
                    2483,
                    4532,
                    437,
                    2485,
                    2486,
                    6582,
                    2489,
                    2495,
                    2499,
                    2500,
                    2501,
                    2502,
                    4548,
                    4551,
                    2505,
                    2509,
                    2513,
                    2517,
                    2524,
                    2525,
                    2526,
                    2532,
                    2538,
                    2545,
                    4594,
                    4595,
                    4598,
                    4602,
                    2556,
                    4606,
                    4608,
                    6657,
                    2562,
                    2564,
                    517,
                    6661,
                    2569,
                    6665,
                    2571,
                    2575,
                    6672,
                    2577,
                    2579,
                    2580,
                    2583,
                    536,
                    2584,
                    2585,
                    2587,
                    6681,
                    6683,
                    4645,
                    2602,
                    2603,
                    4650,
                    558,
                    2606,
                    4655,
                    2609,
                    4660,
                    4670,
                    2626,
                    4674,
                    2629,
                    2630,
                    4678,
                    2637,
                    591,
                    592,
                    594,
                    2643,
                    2644,
                    2645,
                    2648,
                    4696,
                    2651,
                    604,
                    2655,
                    2658,
                    4707,
                    2660,
                    2663,
                    4714,
                    619,
                    2669,
                    2670,
                    2675,
                    4723,
                    2677,
                    4724,
                    2679,
                    2681,
                    2682,
                    4731,
                    4733,
                    2688,
                    2690,
                    645,
                    2693,
                    2694,
                    2700,
                    2702,
                    2709,
                    2710,
                    2711,
                    665,
                    2714,
                    2718,
                    2719,
                    673,
                    674,
                    2724,
                    2725,
                    6824,
                    686,
                    2737,
                    2738,
                    2739,
                    4787,
                    4788,
                    2744,
                    2745,
                    704,
                    706,
                    2760,
                    2764,
                    2765,
                    719,
                    4818,
                    2775,
                    4824,
                    2777,
                    2778,
                    4825,
                    2786,
                    4834,
                    4836,
                    2795,
                    2800,
                    6897,
                    2802,
                    2804,
                    2810,
                    2811,
                    807,
                    4917,
                    4919,
                    842,
                    7007,
                    7008,
                    7010,
                    7012,
                    7019,
                    7020,
                    7026,
                    7027,
                    7032,
                    7034,
                    896,
                    897,
                    898,
                    900,
                    901,
                    905,
                    2964,
                    2967,
                    2971,
                    2974,
                    5041,
                    952,
                    953,
                    954,
                    7162,
                    1023,
                    1025,
                    1029,
                    1032,
                    7179,
                    3087,
                    3088,
                    3091,
                    1044,
                    5142,
                    7194,
                    7204,
                    5158,
                    5160,
                    5189,
                    5190,
                    7239,
                    5193,
                    1124,
                    1125,
                    5223,
                    1128,
                    5225,
                    5228,
                    1133,
                    1134,
                    5229,
                    1142,
                    3197,
                    1150,
                    5245,
                    5248,
                    1160,
                    3209,
                    1166,
                    3215,
                    3221,
                    3223,
                    3241,
                    3242,
                    3243,
                    7351,
                    7354,
                    7359,
                    7360,
                    7363,
                    3311,
                    5360,
                    5363,
                    5364,
                    5366,
                    7415,
                    3340,
                    3346,
                    5395,
                    1304,
                    7455,
                    3365,
                    3366,
                    3368,
                    5418,
                    3378,
                    3383,
                    3405,
                    3413,
                    3414,
                    3415,
                    3424,
                    3425,
                    5488,
                    1396,
                    5493,
                    3452,
                    1405,
                    3453,
                    1407,
                    3454,
                    3455,
                    7550,
                    1411,
                    3460,
                    1412,
                    3465,
                    1417,
                    7565,
                    1423,
                    1425,
                    1428,
                    3476,
                    1435,
                    1438,
                    1439,
                    3502,
                    3505,
                    7605,
                    7606,
                    3522,
                    3525,
                    3536,
                    3537,
                    3542,
                    3544,
                    3546,
                    5620,
                    5622,
                    5623,
                    1539,
                    5644,
                    3635,
                    7739,
                    7741,
                    7744,
                    7746,
                    5712,
                    5715,
                    7766,
                    7768,
                    7775,
                    7813,
                    7824,
                    7825,
                    7832,
                    7833,
                    7834,
                    7841,
                    7845,
                    7847,
                    7857,
                    7887,
                    7908,
                    7911,
                    1770,
                    1772,
                    1774,
                    1776,
                    1779,
                    5876,
                    1781,
                    7929,
                    1789,
                    1791,
                    1792,
                    7949,
                    1816,
                    7990,
                    8053,
                    8054,
                    8055,
                    8057,
                    6025,
                    1975,
                    8120,
                    8121,
                    8122,
                    8124,
                    8131,
                    8133,
                    1998,
                    2022,
                    4076,
                    4089,
                    4091
                ],
                "isinstance": [
                    4097,
                    7172,
                    4105,
                    7177,
                    4109,
                    2576,
                    4113,
                    4116,
                    2597,
                    2601,
                    5162,
                    5166,
                    5169,
                    4658,
                    4659,
                    6202,
                    5190,
                    5196,
                    5199,
                    1618,
                    4698,
                    7773,
                    1632,
                    2657,
                    1123,
                    2659,
                    4716,
                    7791,
                    1141,
                    1653,
                    6263,
                    1145,
                    1147,
                    2684,
                    2699,
                    7347,
                    7348,
                    7867,
                    4799,
                    7875,
                    4309,
                    1240,
                    1770,
                    1781,
                    4346,
                    8442,
                    4354,
                    8453,
                    8457,
                    4365,
                    4371,
                    3359,
                    3362,
                    3365,
                    3367,
                    1838,
                    3374,
                    3380,
                    3384,
                    3385,
                    3391,
                    6996,
                    6997,
                    3414,
                    3416,
                    5468,
                    5480,
                    7021,
                    7024,
                    7031,
                    2959,
                    4518,
                    2471,
                    433,
                    436,
                    440,
                    7608,
                    442,
                    446,
                    460,
                    2512,
                    4055,
                    473,
                    474,
                    2521,
                    4066,
                    485,
                    487,
                    2545,
                    5617,
                    2556
                ],
                "data._data": [
                    434,
                    8306
                ],
                "BlockManager": [
                    436
                ],
                "mgr": [
                    517,
                    458,
                    511,
                    492,
                    494,
                    1678,
                    496,
                    1680,
                    466,
                    468,
                    437,
                    470,
                    1849,
                    441,
                    1850,
                    447
                ],
                "self._init_mgr": [
                    437
                ],
                "index": [
                    512,
                    1024,
                    1032,
                    4134,
                    4136,
                    4137,
                    4145,
                    4147,
                    1600,
                    2627,
                    2118,
                    2633,
                    2644,
                    2645,
                    1652,
                    1653,
                    1654,
                    1655,
                    1657,
                    1659,
                    1662,
                    1665,
                    1667,
                    1668,
                    2206,
                    3777,
                    2761,
                    2766,
                    1235,
                    4308,
                    4309,
                    2775,
                    2777,
                    1243,
                    1250,
                    1769,
                    5876,
                    1799,
                    2320,
                    1810,
                    1812,
                    1814,
                    1816,
                    1826,
                    1827,
                    8484,
                    817,
                    1849,
                    8509,
                    8511,
                    3909,
                    7007,
                    7017,
                    8055,
                    8056,
                    6027,
                    3484,
                    3485,
                    3487,
                    438,
                    441,
                    8122,
                    8123,
                    447,
                    458,
                    466,
                    468,
                    470,
                    484,
                    486,
                    488,
                    490,
                    492,
                    494,
                    496,
                    507,
                    509
                ],
                "columns": [
                    512,
                    1676,
                    6028,
                    1678,
                    1425,
                    1427,
                    2197,
                    3478,
                    3479,
                    5142,
                    3481,
                    8487,
                    808,
                    5041,
                    438,
                    1590,
                    952,
                    441,
                    1591,
                    955,
                    1849,
                    447,
                    1600,
                    3778,
                    3910,
                    458,
                    464,
                    465,
                    466,
                    1619,
                    468,
                    1620,
                    470,
                    1621,
                    1626,
                    1245,
                    478,
                    479,
                    480,
                    481,
                    1250,
                    1630,
                    1633,
                    1634,
                    1635,
                    1636,
                    1638,
                    1641,
                    1642,
                    492,
                    1644,
                    494,
                    496,
                    5876,
                    1654,
                    507,
                    509
                ],
                "copy": [
                    2440,
                    5386,
                    8342,
                    1304,
                    3481,
                    3487,
                    2471,
                    2478,
                    3507,
                    8371,
                    438,
                    447,
                    3527,
                    3912,
                    458,
                    7249,
                    470,
                    3548,
                    494,
                    499,
                    3571
                ],
                "init_dict": [
                    496,
                    441,
                    466,
                    468
                ],
                "ma.MaskedArray": [
                    442
                ],
                "ma": [
                    442,
                    451
                ],
                "mrecords.MaskedRecords": [
                    446
                ],
                "mrecords": [
                    446
                ],
                "masked_rec_array_to_mgr": [
                    447
                ],
                "mask": [
                    5636,
                    5638,
                    7431,
                    5641,
                    5644,
                    7437,
                    4537,
                    4539,
                    4541,
                    451,
                    452,
                    4548,
                    455,
                    4315,
                    4319,
                    4320,
                    7781,
                    5479,
                    5480,
                    5481,
                    7784,
                    7789,
                    4336,
                    4337,
                    5491,
                    7797,
                    5627
                ],
                "ma.getmaskarray": [
                    451
                ],
                "mask.any": [
                    4336,
                    452
                ],
                "fill_value": [
                    5209,
                    6339,
                    5220,
                    453,
                    455,
                    3528,
                    6030,
                    5392,
                    5393,
                    3508,
                    3572,
                    3542,
                    3959,
                    3481,
                    5371,
                    3549,
                    3487
                ],
                "maybe_upcast": [
                    453
                ],
                "data.soften_mask": [
                    454
                ],
                "data.copy": [
                    457
                ],
                "init_ndarray": [
                    458,
                    511,
                    470,
                    494
                ],
                "np.ndarray": [
                    1632,
                    3200,
                    2659,
                    1252,
                    3428,
                    4067,
                    2471,
                    3367,
                    2699,
                    460,
                    2576,
                    4113,
                    3384,
                    1147,
                    7867
                ],
                "np": [
                    3200,
                    7936,
                    7940,
                    7557,
                    7430,
                    3463,
                    7431,
                    7558,
                    7560,
                    2699,
                    7942,
                    1166,
                    7439,
                    2576,
                    4113,
                    5626,
                    1684,
                    1304,
                    2471,
                    3367,
                    3498,
                    3629,
                    1838,
                    4657,
                    4531,
                    1845,
                    3384,
                    7867,
                    8123,
                    460,
                    1614,
                    4310,
                    3417,
                    3419,
                    1632,
                    4320,
                    4321,
                    2659,
                    1252,
                    3428,
                    4067,
                    2536,
                    7656,
                    5227,
                    1772,
                    2796,
                    1135,
                    7920,
                    4337,
                    8304,
                    499,
                    1143,
                    8056,
                    4601,
                    1146,
                    1147,
                    1148,
                    3197
                ],
                "Index": [
                    2659,
                    3367,
                    1659,
                    522,
                    460,
                    8301,
                    2576,
                    3380,
                    7007,
                    3384,
                    1657,
                    1147,
                    4670,
                    3391
                ],
                "data.dtype.names": [
                    461,
                    462
                ],
                "data.dtype": [
                    461,
                    462
                ],
                "data_columns": [
                    465,
                    462,
                    463
                ],
                "list": [
                    4096,
                    1416,
                    4366,
                    4113,
                    4371,
                    4117,
                    7194,
                    4518,
                    2426,
                    4531,
                    7351,
                    3385,
                    6202,
                    4675,
                    7877,
                    462,
                    4055,
                    1240,
                    4698,
                    475,
                    1243,
                    2531,
                    2659,
                    4067,
                    1772,
                    4716,
                    7021,
                    1779,
                    7031,
                    4346,
                    8445,
                    1023
                ],
                "k": [
                    897,
                    898,
                    900,
                    901,
                    1029,
                    1423,
                    1431,
                    954,
                    955,
                    956,
                    463,
                    1621,
                    1625,
                    1626,
                    1627,
                    4714,
                    4720,
                    3313,
                    3314,
                    1405,
                    1407
                ],
                "getattr": [
                    2657,
                    4071,
                    2535,
                    467,
                    8374,
                    8345,
                    477
                ],
                "data.name": [
                    468
                ],
                "abc.Iterable": [
                    473
                ],
                "abc": [
                    473,
                    474,
                    4067,
                    4116
                ],
                "bytes": [
                    473
                ],
                "abc.Sequence": [
                    474
                ],
                "ExtensionArray": [
                    474,
                    3374
                ],
                "len": [
                    4605,
                    2562,
                    1795,
                    2564,
                    1029,
                    3460,
                    4611,
                    1032,
                    649,
                    7429,
                    7556,
                    3340,
                    7561,
                    655,
                    1044,
                    4373,
                    4126,
                    4382,
                    8480,
                    4130,
                    2595,
                    2724,
                    4131,
                    3369,
                    4650,
                    4652,
                    558,
                    2744,
                    3385,
                    4539,
                    7358,
                    4927,
                    3448,
                    2685,
                    7749,
                    7876,
                    7877,
                    7878,
                    3405,
                    592,
                    1238,
                    3417,
                    476,
                    604,
                    4700,
                    4702,
                    4320,
                    4344,
                    2786,
                    4704,
                    4831,
                    1125,
                    7655,
                    488,
                    7656,
                    490,
                    619,
                    4728,
                    8299,
                    5358,
                    2675,
                    5363,
                    2677,
                    5366,
                    3447,
                    1656,
                    4349,
                    7797,
                    509
                ],
                "is_list_like": [
                    2786,
                    3175,
                    3177,
                    8302,
                    8462,
                    2521,
                    477
                ],
                "is_named_tuple": [
                    478
                ],
                "_fields": [
                    479
                ],
                "arrays": [
                    1025,
                    4099,
                    1029,
                    1798,
                    4101,
                    1673,
                    1035,
                    4107,
                    1038,
                    1678,
                    4111,
                    4114,
                    4117,
                    1022,
                    4121,
                    4126,
                    4131,
                    4134,
                    1845,
                    1849,
                    1621,
                    1623,
                    1628,
                    1630,
                    480,
                    1633,
                    1638,
                    492,
                    1776,
                    1656,
                    1657,
                    4093,
                    1662,
                    1791
                ],
                "to_arrays": [
                    480,
                    1633,
                    1638
                ],
                "ensure_index": [
                    481,
                    1635,
                    1640,
                    1642,
                    1620,
                    1591
                ],
                "get_names_from_index": [
                    486
                ],
                "Categorical": [
                    487
                ],
                "ibase.default_index": [
                    4611,
                    488,
                    490,
                    4728,
                    4344,
                    4605,
                    4831
                ],
                "ibase": [
                    4611,
                    488,
                    490,
                    4728,
                    4344,
                    4605,
                    4831
                ],
                "arrays_to_mgr": [
                    1849,
                    492,
                    1678
                ],
                "arr": [
                    5472,
                    5473,
                    5475,
                    5412,
                    5413,
                    5476,
                    5415,
                    499,
                    507,
                    5468,
                    5469,
                    5471
                ],
                "np.array": [
                    1304,
                    499,
                    1772,
                    1614
                ],
                "ValueError": [
                    5633,
                    515,
                    2563,
                    7174,
                    7943,
                    8455,
                    8459,
                    2701,
                    2193,
                    2961,
                    3347,
                    4374,
                    7190,
                    2968,
                    5401,
                    7449,
                    1436,
                    1952,
                    4129,
                    1442,
                    1955,
                    4138,
                    1843,
                    7350,
                    4544,
                    8135,
                    3449,
                    7642,
                    4701,
                    1246,
                    1248,
                    2789,
                    1126,
                    2790,
                    4072,
                    3183,
                    5615,
                    1137,
                    500,
                    2676,
                    6264,
                    3193,
                    6266,
                    2686
                ],
                "TypeError": [
                    1154,
                    6662,
                    7943,
                    8463,
                    2705,
                    3354,
                    4520,
                    5163,
                    7356,
                    4546,
                    5191,
                    5711,
                    2772,
                    7892,
                    6999,
                    7002,
                    7774,
                    7011,
                    2789,
                    4077,
                    4078,
                    500,
                    501,
                    1663
                ],
                "exc": [
                    505,
                    501
                ],
                "err": [
                    503,
                    2793,
                    4080,
                    3351,
                    505,
                    3356
                ],
                "arr.ndim": [
                    507
                ],
                "values": [
                    512,
                    2433,
                    8448,
                    3461,
                    8453,
                    8454,
                    8456,
                    8457,
                    6026,
                    8458,
                    8460,
                    8462,
                    8466,
                    8469,
                    2485,
                    2486,
                    7867,
                    7869,
                    7870,
                    1606,
                    1609,
                    1611,
                    7927,
                    1614,
                    1616,
                    7888,
                    7890,
                    4308,
                    4310,
                    4311,
                    7931,
                    4320,
                    4321,
                    4323,
                    7781,
                    7933,
                    4330,
                    4331,
                    8442,
                    4334,
                    6895,
                    7919,
                    2801,
                    2802,
                    4337,
                    2804,
                    4340,
                    4342,
                    5876,
                    7921,
                    8445,
                    7930,
                    2811,
                    508,
                    3453,
                    2431
                ],
                "cast_scalar_to_array": [
                    508,
                    3405
                ],
                "values.dtype": [
                    512,
                    4331,
                    4310
                ],
                "NDFrame.__init__": [
                    517
                ],
                "self.index": [
                    4096,
                    1025,
                    2562,
                    1411,
                    2435,
                    2564,
                    4097,
                    4098,
                    4099,
                    2569,
                    4101,
                    2443,
                    3340,
                    4357,
                    4359,
                    4362,
                    4363,
                    2321,
                    3346,
                    4354,
                    1044,
                    5245,
                    8470,
                    536,
                    2585,
                    1435,
                    7204,
                    2475,
                    2603,
                    558,
                    3502,
                    3378,
                    3383,
                    954,
                    7360,
                    8133,
                    2630,
                    4678,
                    6273,
                    2637,
                    2765,
                    3405,
                    3536,
                    2644,
                    7007,
                    3424,
                    2786,
                    4350,
                    1770,
                    1772,
                    1774,
                    2802,
                    1779,
                    2675,
                    1781,
                    2677,
                    2679,
                    4348,
                    5363,
                    2811,
                    2556,
                    4349,
                    3454
                ],
                "self.columns": [
                    896,
                    897,
                    1792,
                    2435,
                    900,
                    1029,
                    1412,
                    3460,
                    1032,
                    5248,
                    6274,
                    2443,
                    4365,
                    2318,
                    2575,
                    7824,
                    1425,
                    2577,
                    5395,
                    8449,
                    4373,
                    8471,
                    536,
                    1816,
                    1023,
                    4380,
                    1438,
                    4382,
                    3365,
                    3366,
                    3368,
                    2474,
                    558,
                    4655,
                    2483,
                    4660,
                    4917,
                    952,
                    4670,
                    7360,
                    3522,
                    2499,
                    2500,
                    8131,
                    3537,
                    2643,
                    3413,
                    3414,
                    2524,
                    2526,
                    7008,
                    3425,
                    7010,
                    1124,
                    1125,
                    7012,
                    3455,
                    619,
                    4076,
                    7019,
                    8301,
                    1776,
                    2545,
                    2800,
                    5488,
                    1396,
                    7026,
                    5622,
                    7027,
                    6265,
                    1789,
                    1791
                ],
                "List": [
                    4064,
                    3201,
                    6566,
                    4103,
                    522
                ],
                "Tuple": [
                    4353,
                    904,
                    907,
                    539,
                    6207,
                    895
                ],
                "int": [
                    768,
                    771,
                    772,
                    1862,
                    6567,
                    1040,
                    757,
                    2455,
                    2713,
                    539,
                    766,
                    767
                ],
                "self._data.any_extension_types": [
                    591
                ],
                "self._data": [
                    3424,
                    2468,
                    2795,
                    3243,
                    591,
                    592,
                    594,
                    4723,
                    2485,
                    4825,
                    4602,
                    6558
                ],
                "block.dtype": [
                    592
                ],
                "block": [
                    592
                ],
                "self._data.blocks": [
                    592
                ],
                "self._data.is_mixed_type": [
                    594
                ],
                "max_rows": [
                    2209,
                    732,
                    677,
                    647,
                    649,
                    713,
                    688,
                    819,
                    634,
                    603,
                    636,
                    604
                ],
                "get_option": [
                    677,
                    678,
                    679,
                    680,
                    681,
                    618,
                    682,
                    712,
                    713,
                    714,
                    715,
                    716,
                    663,
                    632,
                    603,
                    636
                ],
                "width": [
                    617,
                    683,
                    685,
                    623,
                    657,
                    691
                ],
                "height": [
                    617
                ],
                "console.get_console_size": [
                    617,
                    683
                ],
                "console": [
                    632,
                    617,
                    683,
                    629
                ],
                "max_columns": [
                    618,
                    622
                ],
                "nb_columns": [
                    619,
                    622,
                    623
                ],
                "ignore_width": [
                    629,
                    623
                ],
                "console.in_interactive_session": [
                    629
                ],
                "console.in_ipython_frontend": [
                    632
                ],
                "buf": [
                    672,
                    641,
                    674,
                    675,
                    705,
                    706,
                    708,
                    2023,
                    2025,
                    2026,
                    2027,
                    2218,
                    653,
                    654,
                    687,
                    2230,
                    696,
                    825
                ],
                "StringIO": [
                    672,
                    641,
                    705
                ],
                "d": [
                    649,
                    645,
                    653
                ],
                "d.iloc": [
                    649
                ],
                "min": [
                    649,
                    4650
                ],
                "d.to_string": [
                    653
                ],
                "value": [
                    2688,
                    2694,
                    3340,
                    3341,
                    654,
                    655,
                    3346,
                    2709,
                    3349,
                    2711,
                    2714,
                    3357,
                    2718,
                    2719,
                    3359,
                    3360,
                    3362,
                    3241,
                    3242,
                    3243,
                    3369,
                    3370,
                    3372,
                    3374,
                    2737,
                    2738,
                    2739,
                    3377,
                    3378,
                    3380,
                    3383,
                    3384,
                    3385,
                    3386,
                    3388,
                    3389,
                    3390,
                    3391,
                    3392,
                    3394,
                    3397,
                    3398,
                    2761,
                    3402,
                    3405,
                    3406,
                    2767,
                    2769,
                    3409,
                    3410,
                    3413,
                    2775,
                    2777,
                    3417,
                    3419,
                    3929,
                    2655,
                    2658,
                    2786,
                    2660,
                    2788,
                    2663,
                    2796,
                    3949,
                    2670,
                    2682,
                    2684,
                    2685,
                    2687
                ],
                "buf.getvalue": [
                    696,
                    675,
                    708,
                    654
                ],
                "repr_width": [
                    657,
                    655
                ],
                "max": [
                    7877,
                    655
                ],
                "l": [
                    655
                ],
                "value.split": [
                    655
                ],
                "info_repr_option": [
                    664,
                    663
                ],
                "self._repr_fits_horizontal_": [
                    665
                ],
                "self._repr_fits_vertical_": [
                    665
                ],
                "self._info_repr": [
                    704,
                    673
                ],
                "self.info": [
                    706,
                    674
                ],
                "min_rows": [
                    678,
                    714,
                    689,
                    818,
                    733
                ],
                "max_cols": [
                    2210,
                    679,
                    715,
                    690,
                    820,
                    2230,
                    734
                ],
                "max_colwidth": [
                    680,
                    692,
                    805
                ],
                "show_dimensions": [
                    2211,
                    681,
                    716,
                    821,
                    693,
                    735
                ],
                "_": [
                    2025,
                    3402,
                    683,
                    4337,
                    7354
                ],
                "self.to_string": [
                    686
                ],
                "val": [
                    708,
                    709,
                    710
                ],
                "replace": [
                    3947,
                    708
                ],
                "val.replace": [
                    709
                ],
                "formatter": [
                    740,
                    806,
                    2217,
                    718,
                    2195,
                    825
                ],
                "fmt.DataFrameFormatter": [
                    806,
                    2195,
                    718
                ],
                "fmt": [
                    806,
                    718,
                    752,
                    2192,
                    2195,
                    2132,
                    761,
                    762
                ],
                "formatter.to_html": [
                    2217,
                    740
                ],
                "FilePathOrBuffer": [
                    755,
                    1855
                ],
                "Sequence": [
                    1863,
                    4840,
                    4618,
                    4557,
                    756,
                    758,
                    4154
                ],
                "Union": [
                    6566,
                    6568,
                    6569,
                    4618,
                    4619,
                    4557,
                    4558,
                    758,
                    4154,
                    6207
                ],
                "fmt.FormattersType": [
                    761
                ],
                "fmt.FloatFormatType": [
                    762
                ],
                "option_context": [
                    805
                ],
                "col_space": [
                    809,
                    2198
                ],
                "na_rep": [
                    810,
                    2199
                ],
                "formatters": [
                    2200,
                    811
                ],
                "float_format": [
                    2201,
                    812
                ],
                "sparsify": [
                    2202,
                    813
                ],
                "justify": [
                    2192,
                    2203,
                    814
                ],
                "index_names": [
                    1793,
                    1795,
                    815,
                    1779,
                    1812,
                    1782,
                    1784,
                    1786,
                    1787,
                    2204,
                    1789
                ],
                "header": [
                    816,
                    2205
                ],
                "decimal": [
                    2212,
                    822
                ],
                "line_width": [
                    823
                ],
                "formatter.to_string": [
                    825
                ],
                "encoding": [
                    825,
                    2222
                ],
                "Substitution": [
                    3621,
                    744,
                    2123,
                    4683,
                    5871,
                    752,
                    7219,
                    2132,
                    6008,
                    6649,
                    3611,
                    2014
                ],
                "fmt.common_docstring": [
                    752,
                    2132
                ],
                "fmt.return_docstring": [
                    752,
                    2132
                ],
                "Styler": [
                    842
                ],
                "_shared_docs": [
                    903,
                    6679,
                    6438,
                    4398,
                    4402,
                    4406,
                    4410,
                    5696,
                    6341,
                    844,
                    5726,
                    2015,
                    3552,
                    3937,
                    5872,
                    3956,
                    5878,
                    6009,
                    894,
                    6655
                ],
                "self.columns.is_unique": [
                    896,
                    2499,
                    1396,
                    3414,
                    6265
                ],
                "hasattr": [
                    896,
                    7937,
                    1603,
                    1653
                ],
                "self._get_item_cache": [
                    898,
                    2629,
                    2502,
                    2764,
                    2609
                ],
                "i": [
                    8448,
                    8449,
                    4098,
                    4099,
                    900,
                    901,
                    1798,
                    1799,
                    3464,
                    1673,
                    3465,
                    4356,
                    4357,
                    7432,
                    4366,
                    4367,
                    7434,
                    4369,
                    7437,
                    7440,
                    7446,
                    7447,
                    2468,
                    2475,
                    5167,
                    1841,
                    5170,
                    2483,
                    2485,
                    8123,
                    8056,
                    1654,
                    1782,
                    1784,
                    1657
                ],
                "enumerate": [
                    3425,
                    8449,
                    900,
                    4357,
                    1798,
                    3464,
                    1673,
                    7432,
                    7433,
                    4366,
                    1782
                ],
                "self._ixs": [
                    2760,
                    2626,
                    901
                ],
                "Appender": [
                    903,
                    5648,
                    6679,
                    3617,
                    6437,
                    3622,
                    4398,
                    2226,
                    4402,
                    7220,
                    4406,
                    4410,
                    5696,
                    4684,
                    2000,
                    2015,
                    3552,
                    3937,
                    5872,
                    3956,
                    6009,
                    3579,
                    894,
                    6655
                ],
                "Iterable": [
                    4353,
                    904,
                    907,
                    4665,
                    895
                ],
                "Label": [
                    1856,
                    4064,
                    1861,
                    1863,
                    904,
                    4103,
                    4840,
                    907,
                    4158,
                    895
                ],
                "self.items": [
                    4674,
                    905,
                    2317,
                    1423,
                    7354,
                    1405,
                    1407
                ],
                "klass": [
                    953,
                    2810,
                    955,
                    2811
                ],
                "self._constructor_sliced": [
                    8313,
                    2472,
                    2602,
                    7949,
                    8304,
                    953,
                    2810
                ],
                "v": [
                    8511,
                    1798,
                    7354,
                    1673,
                    1837,
                    1423,
                    3313,
                    3314,
                    1431,
                    1625,
                    954,
                    955,
                    1628,
                    1405,
                    8510,
                    1407
                ],
                "zip": [
                    2435,
                    4675,
                    4359,
                    3464,
                    1035,
                    1772,
                    1038,
                    1427,
                    7638,
                    954,
                    1438,
                    2687
                ],
                "self.values": [
                    2439,
                    5228,
                    5229,
                    1134,
                    8469,
                    3542,
                    2583,
                    1304,
                    8054,
                    954,
                    8121,
                    3453,
                    2431
                ],
                "s": [
                    7341,
                    7342,
                    7343,
                    8220,
                    955,
                    956,
                    8509,
                    8510
                ],
                "fields": [
                    1026,
                    1034,
                    1023
                ],
                "arrays.append": [
                    1025,
                    4099,
                    4101,
                    4107,
                    4111,
                    4114,
                    4117,
                    4121,
                    1628
                ],
                "fields.insert": [
                    1026
                ],
                "arrays.extend": [
                    1029
                ],
                "self.iloc": [
                    8448,
                    1029,
                    2694,
                    2670,
                    2775,
                    3223,
                    2682
                ],
                "range": [
                    4098,
                    4106,
                    1029,
                    7878
                ],
                "can_return_named_tuples": [
                    1032,
                    1033
                ],
                "PY37": [
                    1032
                ],
                "name": [
                    1824,
                    1825,
                    4376,
                    4384,
                    4387,
                    4674,
                    7816,
                    1033,
                    1034,
                    4369,
                    1842,
                    4371,
                    1812,
                    1816,
                    1789
                ],
                "itertuple": [
                    1034,
                    1035
                ],
                "collections.namedtuple": [
                    1034
                ],
                "collections": [
                    1034,
                    8508,
                    8445
                ],
                "map": [
                    4675,
                    1416,
                    1035,
                    1772,
                    7638
                ],
                "itertuple._make": [
                    1035
                ],
                "other": [
                    1154,
                    7022,
                    7172,
                    7173,
                    7175,
                    1160,
                    5624,
                    7177,
                    7024,
                    7180,
                    1166,
                    7025,
                    7026,
                    7194,
                    7027,
                    7031,
                    7032,
                    7608,
                    7609,
                    7611,
                    7612,
                    7034,
                    7163,
                    6996,
                    6997,
                    7000,
                    7001,
                    7007,
                    7008,
                    1123,
                    1124,
                    1125,
                    7013,
                    5223,
                    7014,
                    1129,
                    5225,
                    7652,
                    5228,
                    5229,
                    5358,
                    1135,
                    3567,
                    5360,
                    5617,
                    5363,
                    5618,
                    1141,
                    5366,
                    1143,
                    5493,
                    1145,
                    5370,
                    5367,
                    5620,
                    7021,
                    5375
                ],
                "common": [
                    1128,
                    1129,
                    1124,
                    1125
                ],
                "self.columns.union": [
                    1124
                ],
                "other.index": [
                    7008,
                    1124,
                    1125,
                    5358
                ],
                "left": [
                    1152,
                    5220,
                    5221,
                    7620,
                    7621,
                    1128,
                    7624,
                    1130,
                    7628,
                    1133,
                    7638,
                    1143,
                    1146,
                    7612,
                    1150,
                    7615
                ],
                "self.reindex": [
                    1128,
                    2580,
                    7020
                ],
                "right": [
                    7616,
                    5220,
                    5221,
                    7620,
                    7621,
                    7240,
                    1129,
                    7625,
                    1131,
                    7628,
                    7638,
                    7612
                ],
                "other.reindex": [
                    1129,
                    7027,
                    7014
                ],
                "lvals": [
                    1130,
                    1134,
                    1136,
                    1138,
                    1143,
                    1146,
                    1148
                ],
                "left.values": [
                    1130,
                    7638
                ],
                "rvals": [
                    1131,
                    1135,
                    1136,
                    1138,
                    1143,
                    1146,
                    1147,
                    1148
                ],
                "right.values": [
                    1131,
                    7638
                ],
                "np.asarray": [
                    4601,
                    3419,
                    1135
                ],
                "lvals.shape": [
                    1136,
                    1138
                ],
                "rvals.shape": [
                    1136,
                    1138
                ],
                "self._constructor": [
                    2434,
                    4733,
                    2442,
                    7565,
                    2702,
                    2584,
                    7834,
                    7455,
                    6559,
                    5418,
                    7359,
                    3544,
                    4836,
                    8303,
                    2802,
                    1142,
                    8311,
                    5245,
                    1150
                ],
                "np.dot": [
                    1146,
                    1148,
                    1143
                ],
                "left.index": [
                    1152,
                    1146,
                    1150,
                    1143
                ],
                "other.columns": [
                    5370,
                    7026,
                    1143
                ],
                "result": [
                    4608,
                    4611,
                    4612,
                    6659,
                    6661,
                    6664,
                    6666,
                    6672,
                    6673,
                    6674,
                    2580,
                    2581,
                    2584,
                    2587,
                    2595,
                    2596,
                    5158,
                    2600,
                    2601,
                    2602,
                    2603,
                    5162,
                    2606,
                    2607,
                    5166,
                    5167,
                    5169,
                    5170,
                    5171,
                    7750,
                    5193,
                    7755,
                    5196,
                    5197,
                    5199,
                    5200,
                    5201,
                    7760,
                    7762,
                    8306,
                    8310,
                    7799,
                    8311,
                    8313,
                    7803,
                    1148,
                    5245,
                    1149,
                    1150,
                    1152,
                    6272,
                    6273,
                    6274,
                    6276,
                    6271,
                    7805,
                    8318,
                    7890,
                    7910,
                    7911,
                    7912,
                    7913,
                    7921,
                    7931,
                    5372,
                    7936,
                    7937,
                    7940,
                    7941,
                    7942,
                    5386,
                    7946,
                    2316,
                    7949,
                    7950,
                    2321,
                    2322,
                    2324,
                    1304,
                    1305,
                    5415,
                    5418,
                    8316,
                    8056,
                    8057,
                    2434,
                    3461,
                    3463,
                    3465,
                    2442,
                    3467,
                    3468,
                    2446,
                    3470,
                    2472,
                    2478,
                    2479,
                    2486,
                    2489,
                    2491,
                    8123,
                    8124,
                    4548,
                    4551,
                    4553,
                    2022,
                    2024,
                    2027
                ],
                "result.ndim": [
                    1149,
                    8310,
                    7911
                ],
                "type": [
                    1154,
                    4330,
                    1838,
                    4079,
                    2960,
                    8466
                ],
                "self.dot": [
                    1160
                ],
                "T": [
                    7427,
                    7014,
                    3372,
                    1166,
                    6683,
                    3390
                ],
                "self.T.dot": [
                    1166
                ],
                "self.T": [
                    6672,
                    6683,
                    1166
                ],
                "np.transpose": [
                    1166
                ],
                "orient": [
                    1408,
                    1442,
                    1422,
                    1424,
                    1244,
                    1236,
                    1237,
                    1434,
                    1404,
                    1406
                ],
                "orient.lower": [
                    1408,
                    1422,
                    1424,
                    1236,
                    1434,
                    1404,
                    1406
                ],
                "data.values": [
                    7919,
                    7888,
                    7927,
                    1240,
                    7930,
                    1243
                ],
                "_from_nested_dict": [
                    1241
                ],
                "data.keys": [
                    1243
                ],
                "cls": [
                    1600,
                    1250,
                    1680,
                    1850,
                    1595
                ],
                "classmethod": [
                    1552,
                    1171,
                    1847
                ],
                "warnings.warn": [
                    2557,
                    7817,
                    1397
                ],
                "warnings": [
                    2557,
                    7817,
                    1397
                ],
                "UserWarning": [
                    2559,
                    1399
                ],
                "into_c": [
                    1409,
                    1423,
                    1431,
                    1403,
                    1405,
                    1437,
                    1407
                ],
                "com.standardize_mapping": [
                    1403
                ],
                "com": [
                    1416,
                    1423,
                    2674,
                    3314,
                    2516,
                    1431,
                    2648,
                    1403,
                    3388,
                    2495
                ],
                "into": [
                    1403,
                    1405
                ],
                "startswith": [
                    1408,
                    1422,
                    1424,
                    1434,
                    1404,
                    1406
                ],
                "v.to_dict": [
                    1405
                ],
                "v.tolist": [
                    1407
                ],
                "self.index.tolist": [
                    1411
                ],
                "self.columns.tolist": [
                    1425,
                    1412,
                    4917
                ],
                "com.maybe_box_datetimelike": [
                    1416,
                    1431,
                    1423
                ],
                "t": [
                    1416,
                    1417,
                    1438,
                    1439
                ],
                "self.itertuples": [
                    1417,
                    1428,
                    1439
                ],
                "rows": [
                    1432,
                    1426
                ],
                "row": [
                    2433,
                    1427,
                    1428,
                    1431,
                    1432
                ],
                "row.items": [
                    1431
                ],
                "self.index.is_unique": [
                    1435
                ],
                "gbq.to_gbq": [
                    1538
                ],
                "gbq": [
                    1538
                ],
                "destination_table": [
                    1540
                ],
                "project_id": [
                    1541
                ],
                "chunksize": [
                    1542
                ],
                "reauth": [
                    1543
                ],
                "if_exists": [
                    1544
                ],
                "auth_local_webserver": [
                    1545
                ],
                "table_schema": [
                    1546
                ],
                "location": [
                    1547
                ],
                "progress_bar": [
                    1548
                ],
                "credentials": [
                    1549
                ],
                "is_iterator": [
                    1593,
                    2530
                ],
                "nrows": [
                    1608,
                    1594,
                    1611
                ],
                "first_row": [
                    1606,
                    1603,
                    1604,
                    1598
                ],
                "next": [
                    1598
                ],
                "StopIteration": [
                    1599
                ],
                "first_row.dtype.names": [
                    1603
                ],
                "first_row.dtype": [
                    1603,
                    1604
                ],
                "values.extend": [
                    1611
                ],
                "itertools.islice": [
                    1611
                ],
                "itertools": [
                    1611,
                    1789
                ],
                "arr_columns": [
                    1636,
                    1638,
                    1671,
                    1640,
                    1672,
                    1662,
                    1675,
                    1644,
                    1678,
                    1620,
                    1624,
                    1627,
                    1630
                ],
                "sorted": [
                    1620
                ],
                "data.items": [
                    1625,
                    8509
                ],
                "arr_columns.append": [
                    1627
                ],
                "reorder_arrays": [
                    1630
                ],
                "coerce_float": [
                    1638
                ],
                "exclude": [
                    1668,
                    1670,
                    1671,
                    3177,
                    3178,
                    1676,
                    3180,
                    1646,
                    1647,
                    1649,
                    3217,
                    3187,
                    3188,
                    3219,
                    1655,
                    3192,
                    3193
                ],
                "set": [
                    1649,
                    4141,
                    1647
                ],
                "result_index": [
                    1665,
                    1667,
                    7652,
                    7653,
                    1678,
                    1651,
                    1657,
                    1659
                ],
                "columns.get_loc": [
                    1654
                ],
                "exclude.add": [
                    1655
                ],
                "index_data": [
                    1667,
                    1662
                ],
                "arr_columns.get_loc": [
                    1672,
                    1662
                ],
                "field": [
                    1662
                ],
                "KeyError": [
                    4672,
                    3457,
                    3459,
                    7337,
                    2635,
                    4531,
                    2772,
                    4086,
                    1663
                ],
                "ensure_index_from_sequences": [
                    1667,
                    4134
                ],
                "exclude.update": [
                    1668
                ],
                "any": [
                    3456,
                    5632,
                    3458,
                    1670,
                    7880,
                    3182
                ],
                "arr_exclude": [
                    1672,
                    1675,
                    1671
                ],
                "x": [
                    4707,
                    7814,
                    5479,
                    1671,
                    5483,
                    6893,
                    6894,
                    6895,
                    3186,
                    3187,
                    7635,
                    7609,
                    7837
                ],
                "to_remove": [
                    4103,
                    1672,
                    1673,
                    4141,
                    4124
                ],
                "col": [
                    8448,
                    8449,
                    1672,
                    4104,
                    4105,
                    4106,
                    4107,
                    2317,
                    4108,
                    4109,
                    4111,
                    4112,
                    4113,
                    4114,
                    4116,
                    4117,
                    5395,
                    4121,
                    4122,
                    4124,
                    7334,
                    5415,
                    7336,
                    8510,
                    8511,
                    2626,
                    4674,
                    2629,
                    2760,
                    2764,
                    2643,
                    2645,
                    2775,
                    2777,
                    2778,
                    5386,
                    4065,
                    4067,
                    4071,
                    4076,
                    5644,
                    4079,
                    4083,
                    5622,
                    5623,
                    5624,
                    5373,
                    5374,
                    5375
                ],
                "arr_columns.drop": [
                    1675
                ],
                "columns.drop": [
                    1676
                ],
                "ABCMultiIndex": [
                    4097,
                    4354,
                    3365,
                    5190,
                    4105,
                    1770,
                    5162,
                    5196,
                    4365,
                    5166,
                    5199,
                    2545,
                    5169,
                    1781,
                    3414,
                    7773,
                    4799
                ],
                "ix_vals": [
                    1776,
                    1772,
                    1774
                ],
                "self.index.values": [
                    1772,
                    1774
                ],
                "_internal_get_values": [
                    1776,
                    1791
                ],
                "c": [
                    1792,
                    3464,
                    3465,
                    2317,
                    4141,
                    4142,
                    1776,
                    7439,
                    7441,
                    7443,
                    7445,
                    7446,
                    7447,
                    7638,
                    1791
                ],
                "count": [
                    4537,
                    1778,
                    4534,
                    1784,
                    1785,
                    4539,
                    4541
                ],
                "self.index.names": [
                    4096,
                    1779,
                    4357
                ],
                "n": [
                    4356,
                    4357,
                    3463,
                    4106,
                    1783,
                    4107,
                    5041,
                    1782,
                    3447,
                    3448,
                    5142,
                    3452
                ],
                "names": [
                    1792,
                    4096,
                    4355,
                    4134,
                    4362,
                    4108,
                    4112,
                    4369,
                    4115,
                    1845,
                    4118,
                    4122,
                    1789,
                    4094
                ],
                "itertools.chain": [
                    1789
                ],
                "index_len": [
                    1841,
                    1810,
                    1795,
                    1814
                ],
                "formats": [
                    1845,
                    1796,
                    1837,
                    1839
                ],
                "dtype_mapping": [
                    1824,
                    1825,
                    1826,
                    1827,
                    1829,
                    1836,
                    1838,
                    1839,
                    1842,
                    1811,
                    1815,
                    1823
                ],
                "index_dtypes": [
                    1811
                ],
                "column_dtypes": [
                    1815
                ],
                "is_dict_like": [
                    1823
                ],
                "formats.append": [
                    1837,
                    1839
                ],
                "v.dtype": [
                    1837
                ],
                "np.dtype": [
                    1838
                ],
                "element": [
                    1841,
                    1842
                ],
                "msg": [
                    7849,
                    7853,
                    2960,
                    2961,
                    1842,
                    1843
                ],
                "np.rec.fromarrays": [
                    1845
                ],
                "np.rec": [
                    1845
                ],
                "np.recarray": [
                    1684
                ],
                "Dict": [
                    1856,
                    1964,
                    1861
                ],
                "datetime.datetime": [
                    1859
                ],
                "datetime": [
                    1859
                ],
                "version": [
                    1953,
                    1957,
                    1965,
                    1968,
                    1970,
                    1951
                ],
                "convert_strl": [
                    1954,
                    1967
                ],
                "kwargs": [
                    6661,
                    6665,
                    3084,
                    3085,
                    6672,
                    2962,
                    2963,
                    2964,
                    3090,
                    3091,
                    3092,
                    3094,
                    6675,
                    6683,
                    6684,
                    1964,
                    1967,
                    7345,
                    1970,
                    3635,
                    3636,
                    3638,
                    3639,
                    3640,
                    1982,
                    2120,
                    2019,
                    2020,
                    2022,
                    3313
                ],
                "Any": [
                    4353,
                    1964
                ],
                "writer": [
                    1984,
                    1973
                ],
                "statawriter": [
                    1973
                ],
                "path": [
                    2115,
                    1998,
                    1974
                ],
                "convert_dates": [
                    1976
                ],
                "byteorder": [
                    1977
                ],
                "time_stamp": [
                    1978
                ],
                "data_label": [
                    1979
                ],
                "write_index": [
                    1980
                ],
                "variable_labels": [
                    1981
                ],
                "writer.write_file": [
                    1984
                ],
                "deprecate_kwarg": [
                    1986,
                    1852,
                    2030
                ],
                "to_feather": [
                    1998
                ],
                "IO": [
                    2017
                ],
                "kwargs.setdefault": [
                    2019,
                    2020
                ],
                "tabulate": [
                    2021,
                    2022
                ],
                "import_optional_dependency": [
                    2021
                ],
                "tabulate.tabulate": [
                    2022
                ],
                "get_filepath_or_buffer": [
                    2025
                ],
                "mode": [
                    2025
                ],
                "buf.writelines": [
                    2027
                ],
                "to_parquet": [
                    2113
                ],
                "engine": [
                    2116,
                    2630,
                    2633,
                    2765,
                    2766
                ],
                "compression": [
                    2117
                ],
                "partition_cols": [
                    2119
                ],
                "fmt._VALID_JUSTIFY_PARAMETERS": [
                    2192
                ],
                "bold_rows": [
                    2207
                ],
                "escape": [
                    2208
                ],
                "table_id": [
                    2213
                ],
                "render_links": [
                    2214
                ],
                "classes": [
                    2219
                ],
                "notebook": [
                    2220
                ],
                "border": [
                    2221
                ],
                "info": [
                    2226,
                    2230
                ],
                "verbose": [
                    2230
                ],
                "memory_usage": [
                    2230
                ],
                "null_counts": [
                    2230
                ],
                "info.__doc__": [
                    2226
                ],
                "c.memory_usage": [
                    2317
                ],
                "deep": [
                    2321,
                    2317
                ],
                "append": [
                    2321,
                    7012,
                    4095
                ],
                "self.index.memory_usage": [
                    2321
                ],
                "nv.validate_transpose": [
                    2423
                ],
                "nv": [
                    7345,
                    2423
                ],
                "args": [
                    6661,
                    6665,
                    6829,
                    6672,
                    7345,
                    3635,
                    6675,
                    2423,
                    6683,
                    6684
                ],
                "dtypes": [
                    3188,
                    3189,
                    2426,
                    2427,
                    2429
                ],
                "self.dtypes": [
                    7813,
                    3209,
                    3215,
                    3221,
                    2426
                ],
                "self._is_homogeneous_type": [
                    2427
                ],
                "is_extension_array_dtype": [
                    5472,
                    3409,
                    2427
                ],
                "arr_type": [
                    2433,
                    2430
                ],
                "dtype.construct_array_type": [
                    2430
                ],
                "new_values": [
                    2433,
                    2435,
                    2468,
                    2439,
                    2471,
                    2441,
                    2473,
                    2443,
                    2476,
                    3541,
                    2583,
                    3544,
                    2585
                ],
                "arr_type._from_sequence": [
                    2433
                ],
                "self.values.T": [
                    2439
                ],
                "new_values.copy": [
                    2441
                ],
                "result.__finalize__": [
                    2587,
                    2446
                ],
                "self.transpose": [
                    2450
                ],
                "axis": [
                    6657,
                    6661,
                    6665,
                    6669,
                    6681,
                    6682,
                    8222,
                    3619,
                    5160,
                    5162,
                    5165,
                    7739,
                    7741,
                    5189,
                    5190,
                    7749,
                    7750,
                    5195,
                    7755,
                    7758,
                    5712,
                    7760,
                    5717,
                    4696,
                    7770,
                    7771,
                    7775,
                    4707,
                    8293,
                    8294,
                    4714,
                    7786,
                    4724,
                    7801,
                    7827,
                    7832,
                    7833,
                    8344,
                    7837,
                    7845,
                    6826,
                    7856,
                    4787,
                    4788,
                    7860,
                    7862,
                    8373,
                    3776,
                    7880,
                    4824,
                    7896,
                    7917,
                    7925,
                    7933,
                    7945,
                    7990,
                    3911,
                    3931,
                    8053,
                    8054,
                    8055,
                    3959,
                    8057,
                    6557,
                    2467,
                    4518,
                    4522,
                    4523,
                    7605,
                    8120,
                    7609,
                    8121,
                    8122,
                    8124,
                    7614,
                    4548,
                    7651,
                    3569
                ],
                "self._data.fast_xs": [
                    2468
                ],
                "new_values.base": [
                    2471
                ],
                "new_values.dtype": [
                    2476
                ],
                "result._set_is_copy": [
                    2606,
                    2478
                ],
                "label": [
                    2489,
                    2483,
                    2486
                ],
                "self._data.iget": [
                    3424,
                    2485
                ],
                "self._box_col_values": [
                    2804,
                    2486
                ],
                "result._set_as_cached": [
                    2489
                ],
                "key": [
                    2562,
                    2691,
                    2564,
                    2569,
                    2570,
                    2699,
                    2700,
                    2702,
                    2575,
                    2704,
                    2578,
                    2711,
                    3365,
                    3366,
                    3368,
                    2603,
                    2609,
                    2738,
                    2739,
                    6587,
                    2494,
                    2495,
                    2497,
                    2499,
                    2501,
                    2502,
                    2505,
                    2512,
                    2513,
                    2516,
                    2517,
                    3413,
                    3415,
                    2648,
                    2521,
                    2651,
                    2525,
                    2526,
                    2657,
                    2530,
                    2531,
                    2532,
                    2658,
                    2659,
                    2660,
                    2663,
                    2670,
                    2800,
                    2546,
                    2674,
                    2675,
                    2677,
                    2679,
                    2680,
                    2556,
                    2685,
                    2687
                ],
                "lib.item_from_zerodim": [
                    2494
                ],
                "lib": [
                    3468,
                    6894,
                    6895,
                    7797,
                    4311,
                    2494
                ],
                "com.apply_if_callable": [
                    2648,
                    3314,
                    2495
                ],
                "is_hashable": [
                    2497
                ],
                "self.columns.nlevels": [
                    2524,
                    2500,
                    4373,
                    4382
                ],
                "self._getitem_multilevel": [
                    2525,
                    2501
                ],
                "indexer": [
                    2690,
                    2694,
                    2570,
                    2571,
                    3502,
                    3506,
                    4795,
                    3522,
                    4802,
                    3526,
                    2505,
                    2506,
                    2509,
                    3540,
                    4820,
                    3542,
                    4825,
                    2651,
                    2652,
                    2526,
                    2655,
                    2528,
                    2527,
                    4831,
                    2532,
                    4708,
                    4709,
                    2535,
                    2536,
                    2538,
                    4728,
                    4719,
                    4724,
                    2680,
                    2682
                ],
                "convert_to_index_sliceable": [
                    2505,
                    2651
                ],
                "self._slice": [
                    2509
                ],
                "self.where": [
                    2513
                ],
                "com.is_bool_indexer": [
                    2674,
                    2516
                ],
                "self._getitem_bool_array": [
                    2517
                ],
                "is_single_key": [
                    2521,
                    2523,
                    2540
                ],
                "tuple": [
                    4384,
                    6202,
                    2597,
                    3205,
                    4518,
                    4716,
                    7031,
                    4371,
                    3092,
                    4659,
                    6263,
                    2521,
                    4346
                ],
                "self.columns.get_loc": [
                    3366,
                    2575,
                    2800,
                    2643,
                    2526
                ],
                "is_integer": [
                    7352,
                    2527
                ],
                "self.loc._get_listlike_indexer": [
                    2690,
                    2532
                ],
                "self.loc": [
                    2690,
                    4548,
                    2532,
                    2967,
                    2777
                ],
                "np.where": [
                    2536
                ],
                "self._take_with_is_copy": [
                    2538,
                    2571
                ],
                "data.shape": [
                    2545
                ],
                "key.index.equals": [
                    2556
                ],
                "key.index": [
                    2556
                ],
                "check_bool_indexer": [
                    2569,
                    2679
                ],
                "key.nonzero": [
                    2680,
                    2570
                ],
                "loc": [
                    3366,
                    3367,
                    3368,
                    2633,
                    2634,
                    3243,
                    2766,
                    2575,
                    2576,
                    2577,
                    2769,
                    2583,
                    2718,
                    2719
                ],
                "slice": [
                    2576,
                    2665,
                    2694,
                    3367
                ],
                "new_columns": [
                    3522,
                    3523,
                    3526,
                    5418,
                    2577,
                    2578,
                    3537,
                    2580,
                    3544,
                    5370,
                    3547,
                    5373
                ],
                "result_columns": [
                    2585,
                    2578,
                    2581
                ],
                "maybe_droplevels": [
                    3368,
                    2578
                ],
                "self._is_mixed_type": [
                    2579,
                    3452
                ],
                "result.columns": [
                    2595,
                    2596,
                    5199,
                    5200,
                    5169,
                    5170,
                    2581
                ],
                "top": [
                    2596,
                    2597,
                    2598,
                    2599
                ],
                "takeable": [
                    2625,
                    2774,
                    2759
                ],
                "series": [
                    5408,
                    5377,
                    2626,
                    2627,
                    5380,
                    2629,
                    5412,
                    2760,
                    2761,
                    2634,
                    2764,
                    5390,
                    2767,
                    5392,
                    2769,
                    5400,
                    5374
                ],
                "series._values": [
                    2769,
                    2634,
                    2627
                ],
                "self.index._engine": [
                    2765,
                    2630
                ],
                "engine.get_loc": [
                    2633,
                    2766
                ],
                "self.index.nlevels": [
                    4349,
                    4098,
                    2637
                ],
                "self.index.get_loc": [
                    2644
                ],
                "self._get_value": [
                    3465,
                    2645
                ],
                "self._setitem_slice": [
                    2655
                ],
                "self._setitem_frame": [
                    2658
                ],
                "self._setitem_array": [
                    2660
                ],
                "self._set_item": [
                    2663
                ],
                "self._check_setitem_copy": [
                    2693,
                    2725,
                    2669,
                    2745,
                    2710,
                    2681
                ],
                "self.iloc._setitem_with_indexer": [
                    2682,
                    2694,
                    2670
                ],
                "value.columns": [
                    3369,
                    2685,
                    2687
                ],
                "k1": [
                    2688,
                    2687
                ],
                "k2": [
                    2688,
                    2687
                ],
                "key.shape": [
                    2700
                ],
                "self.shape": [
                    8469,
                    2700,
                    3197
                ],
                "self._construct_axes_dict": [
                    2702
                ],
                "key.values.size": [
                    2704
                ],
                "key.values": [
                    2704
                ],
                "is_bool_dtype": [
                    2704
                ],
                "self._check_inplace_setting": [
                    2709
                ],
                "self._where": [
                    2711
                ],
                "self._ensure_valid_index": [
                    2737,
                    2714,
                    3241
                ],
                "self._sanitize_column": [
                    3242,
                    2738,
                    2718
                ],
                "NDFrame._iset_item": [
                    2719
                ],
                "NDFrame._set_item": [
                    2739
                ],
                "series._set_value": [
                    2761
                ],
                "validate_numeric_casting": [
                    2767
                ],
                "series.dtype": [
                    5377,
                    2767
                ],
                "self._item_cache.pop": [
                    2778
                ],
                "self._item_cache": [
                    2778
                ],
                "self._data.reindex_axis": [
                    2795
                ],
                "value.index.copy": [
                    2796
                ],
                "value.index": [
                    3349,
                    2796,
                    3340
                ],
                "np.nan": [
                    4321,
                    7558,
                    7656,
                    3498,
                    2796,
                    3629,
                    7439,
                    4337,
                    8056,
                    8123
                ],
                "items": [
                    2800,
                    2802,
                    2811,
                    2804
                ],
                "values.ndim": [
                    2801,
                    7867
                ],
                "values.T": [
                    2802
                ],
                "inplace": [
                    3083,
                    2958,
                    3094,
                    2973,
                    3619,
                    4517,
                    4390,
                    4785,
                    4149,
                    3780,
                    4550,
                    3913,
                    4301,
                    4302,
                    4815,
                    4054,
                    4695,
                    4088,
                    3932,
                    4833,
                    3950,
                    4597,
                    4600,
                    4730
                ],
                "validate_bool_kwarg": [
                    4517,
                    3083,
                    4301,
                    2958,
                    4785,
                    4597,
                    4054,
                    4695
                ],
                "expr": [
                    2960,
                    2964,
                    3094,
                    2959
                ],
                "kwargs.pop": [
                    3084,
                    3085,
                    2962,
                    3638,
                    3639
                ],
                "res": [
                    7201,
                    7874,
                    7875,
                    7204,
                    7876,
                    7877,
                    7878,
                    2964,
                    2967,
                    2971
                ],
                "self.eval": [
                    2964
                ],
                "new_data": [
                    4605,
                    2967,
                    2971,
                    2974,
                    6558,
                    2976,
                    6559,
                    8508,
                    8511,
                    8512,
                    4825,
                    4828,
                    4831,
                    4834,
                    4836,
                    5225,
                    5229,
                    5231,
                    4723,
                    4728,
                    4602,
                    4731,
                    4733,
                    4606
                ],
                "self._update_inplace": [
                    4834,
                    4551,
                    2974,
                    4731,
                    4606
                ],
                "resolvers": [
                    3089,
                    3084,
                    3092,
                    3086
                ],
                "index_resolvers": [
                    3089,
                    3087
                ],
                "self._get_index_resolvers": [
                    3087
                ],
                "column_resolvers": [
                    3088,
                    3089
                ],
                "self._get_cleaned_column_resolvers": [
                    3088
                ],
                "kwargs.get": [
                    3092
                ],
                "_eval": [
                    3094
                ],
                "include": [
                    3175,
                    3176,
                    3211,
                    3180,
                    3213,
                    3186,
                    3188,
                    3192,
                    3193
                ],
                "selection": [
                    3180,
                    3182
                ],
                "infer_dtype_from_object": [
                    3186,
                    3187
                ],
                "invalidate_string_dtypes": [
                    3189
                ],
                "include.isdisjoint": [
                    3192
                ],
                "keep_these": [
                    3223,
                    3197,
                    3221,
                    3215
                ],
                "np.full": [
                    3197
                ],
                "extracted_dtypes": [
                    3202,
                    3207
                ],
                "unique_dtype": [
                    3203,
                    3204,
                    3205
                ],
                "unique_dtypes": [
                    3209,
                    3219,
                    3204,
                    3213
                ],
                "issubclass": [
                    4333,
                    4339,
                    3205
                ],
                "unique_dtype.type": [
                    3205
                ],
                "dtypes_set": [
                    3205
                ],
                "self.dtypes.unique": [
                    3209
                ],
                "included_dtypes": [
                    3212,
                    3215
                ],
                "extract_unique_dtypes_from_dtypes_set": [
                    3218,
                    3212
                ],
                "self.dtypes.isin": [
                    3221,
                    3215
                ],
                "excluded_dtypes": [
                    3218,
                    3221
                ],
                "keep_these.values": [
                    3223
                ],
                "column": [
                    6272,
                    3242,
                    3243,
                    6263,
                    6271
                ],
                "self._data.insert": [
                    3243
                ],
                "allow_duplicates": [
                    3243
                ],
                "self.copy": [
                    5158,
                    5193,
                    3311,
                    4305,
                    4818,
                    4595,
                    5364,
                    8371,
                    8342,
                    4091
                ],
                "kwargs.items": [
                    3313
                ],
                "value.index.equals": [
                    3340
                ],
                "value._values.copy": [
                    3341
                ],
                "value._values": [
                    3341
                ],
                "_values": [
                    5624,
                    4121,
                    3346,
                    5623
                ],
                "value.reindex": [
                    3346,
                    3370
                ],
                "value.index.is_unique": [
                    3349
                ],
                "reindexer": [
                    3360,
                    3372
                ],
                "cols": [
                    7552,
                    7429,
                    7551,
                    3368,
                    3369,
                    3370,
                    7561,
                    7565,
                    8301,
                    8303,
                    7824,
                    7825,
                    8304,
                    7416,
                    7417,
                    7455
                ],
                "cols.equals": [
                    3369
                ],
                "value.copy": [
                    3392,
                    3377,
                    3394,
                    3390
                ],
                "sanitize_index": [
                    3378,
                    3383
                ],
                "is_sequence": [
                    3380,
                    4700
                ],
                "maybe_convert_platform": [
                    3386
                ],
                "com.asarray_tuplesafe": [
                    3388
                ],
                "value.ndim": [
                    3413,
                    3389
                ],
                "is_object_dtype": [
                    7933,
                    3467,
                    3397,
                    7937
                ],
                "value.dtype": [
                    3397
                ],
                "maybe_infer_to_datetimelike": [
                    3398
                ],
                "infer_dtype": [
                    3402,
                    3406
                ],
                "infer_dtype_from_scalar": [
                    3402
                ],
                "maybe_cast_to_datetime": [
                    3406
                ],
                "broadcast": [
                    3413
                ],
                "existing_piece": [
                    3416,
                    3417,
                    3415
                ],
                "np.tile": [
                    3417
                ],
                "existing_piece.columns": [
                    3417
                ],
                "np.atleast_2d": [
                    3419
                ],
                "item": [
                    3424,
                    3425
                ],
                "idx": [
                    3424,
                    3425,
                    7552,
                    7565,
                    7417,
                    7455
                ],
                "row_labels": [
                    3464,
                    3454,
                    3447
                ],
                "col_labels": [
                    3448,
                    3464,
                    3455
                ],
                "thresh": [
                    4536,
                    4537,
                    3451,
                    3452
                ],
                "ridx": [
                    3456,
                    3460,
                    3454
                ],
                "self.index.get_indexer": [
                    3454
                ],
                "cidx": [
                    3458,
                    3460,
                    3455
                ],
                "self.columns.get_indexer": [
                    7026,
                    3455
                ],
                "flat_index": [
                    3460,
                    3461
                ],
                "values.flat": [
                    3461
                ],
                "np.empty": [
                    4320,
                    7557,
                    7430,
                    3463
                ],
                "r": [
                    3464,
                    3465
                ],
                "lib.maybe_convert_objects": [
                    3468,
                    4311
                ],
                "frame": [
                    3476,
                    3480,
                    4121,
                    3486,
                    3490,
                    7212,
                    4142,
                    7214,
                    4147,
                    4150,
                    7744,
                    7746,
                    7749,
                    7750,
                    7752,
                    7755,
                    7758,
                    7760,
                    7766,
                    7768,
                    7770,
                    7771,
                    7778,
                    7781,
                    7784,
                    4089,
                    4091
                ],
                "axes": [
                    3536,
                    3537,
                    3635,
                    3636,
                    3478,
                    3484
                ],
                "frame._reindex_columns": [
                    3480
                ],
                "method": [
                    7424,
                    7618,
                    3523,
                    7428,
                    7609,
                    3503,
                    7632,
                    3953,
                    7635,
                    3573,
                    7452,
                    3481,
                    3930,
                    7643,
                    7420,
                    7422,
                    3487
                ],
                "level": [
                    4367,
                    3481,
                    3487,
                    3503,
                    4793,
                    6202,
                    6203,
                    4796,
                    6205,
                    7740,
                    7741,
                    3523,
                    3779,
                    6339,
                    3914,
                    5710,
                    5718,
                    7791,
                    7792,
                    3570,
                    7794,
                    7795,
                    7796,
                    4345,
                    4346,
                    4347,
                    4348,
                    4349,
                    4350
                ],
                "limit": [
                    3523,
                    3503,
                    3951,
                    3574,
                    3481,
                    3933,
                    3487
                ],
                "tolerance": [
                    3481,
                    3523,
                    3503,
                    3487
                ],
                "frame._reindex_index": [
                    3486
                ],
                "new_index": [
                    4344,
                    4389,
                    5418,
                    3502,
                    3503,
                    3536,
                    5361,
                    3506,
                    5363,
                    3544,
                    3547,
                    4350
                ],
                "self.index.reindex": [
                    3536,
                    3502
                ],
                "self._reindex_with_indexers": [
                    3505,
                    3546,
                    3525
                ],
                "self.columns.reindex": [
                    3537,
                    3522
                ],
                "row_indexer": [
                    3536,
                    3539,
                    3540,
                    3547
                ],
                "col_indexer": [
                    3537,
                    3539,
                    3540,
                    3547
                ],
                "algorithms.take_2d_multi": [
                    3541
                ],
                "algorithms": [
                    4649,
                    5041,
                    8469,
                    5141,
                    3541
                ],
                "align": [
                    3566
                ],
                "super": [
                    4408,
                    3907,
                    3619,
                    3947,
                    3566,
                    4400,
                    3928,
                    4404,
                    6675,
                    3958,
                    3640,
                    4412,
                    6684,
                    3774
                ],
                "join": [
                    3568,
                    5612,
                    6272
                ],
                "fill_axis": [
                    3575
                ],
                "broadcast_axis": [
                    3576
                ],
                "Axis": [
                    3794,
                    3618,
                    8321,
                    8351
                ],
                "set_axis": [
                    3619
                ],
                "labels": [
                    7949,
                    7828,
                    7833,
                    3619,
                    4649,
                    4652,
                    4788,
                    4792,
                    4795,
                    4799,
                    3775,
                    4675,
                    4803,
                    4677,
                    4812,
                    4813,
                    4821,
                    4314,
                    4315,
                    4323,
                    7917,
                    7925
                ],
                "NDFrame.set_axis.__doc__": [
                    3617
                ],
                "NDFrame.set_axis": [
                    3617
                ],
                "validate_axis_style_args": [
                    3635
                ],
                "kwargs.update": [
                    3636
                ],
                "reindex": [
                    3640
                ],
                "NDFrame.reindex.__doc__": [
                    3622
                ],
                "NDFrame.reindex": [
                    3622
                ],
                "rewrite_axis_style_signature": [
                    3784,
                    3623
                ],
                "drop": [
                    4352,
                    7648,
                    4123,
                    3774
                ],
                "errors": [
                    5629,
                    3915,
                    3781,
                    5614
                ],
                "Renamer": [
                    3792,
                    3793,
                    3790
                ],
                "Level": [
                    3797
                ],
                "rename": [
                    3907
                ],
                "mapper": [
                    3908
                ],
                "fillna": [
                    3928
                ],
                "downcast": [
                    3934
                ],
                "doc": [
                    3918
                ],
                "NDFrame.fillna": [
                    3918
                ],
                "to_replace": [
                    3948
                ],
                "regex": [
                    3952
                ],
                "shift": [
                    3958
                ],
                "periods": [
                    6558,
                    3959
                ],
                "freq": [
                    8375,
                    8346,
                    3959
                ],
                "keys": [
                    4065,
                    4707,
                    4708,
                    4104,
                    4055,
                    4056
                ],
                "err_msg": [
                    4072,
                    4058,
                    4079
                ],
                "missing": [
                    4064,
                    4083,
                    4085,
                    4086,
                    4382,
                    4383
                ],
                "ABCIndexClass": [
                    5480,
                    4067,
                    5468,
                    4109
                ],
                "ABCSeries": [
                    5480,
                    4067,
                    5468,
                    4109
                ],
                "abc.Iterator": [
                    4067,
                    4116
                ],
                "found": [
                    4082,
                    4076
                ],
                "missing.append": [
                    4083
                ],
                "self.index._get_level_values": [
                    4099
                ],
                "col.nlevels": [
                    4106
                ],
                "col._get_level_values": [
                    4107
                ],
                "names.extend": [
                    4108
                ],
                "col.names": [
                    4108
                ],
                "names.append": [
                    4112,
                    4122,
                    4115,
                    4118
                ],
                "col.name": [
                    4112
                ],
                "to_remove.append": [
                    4124
                ],
                "verify_integrity": [
                    4136,
                    7038
                ],
                "index.is_unique": [
                    4136
                ],
                "duplicates": [
                    4137,
                    4138
                ],
                "unique": [
                    4137
                ],
                "index.duplicated": [
                    4137
                ],
                "index._cleanup": [
                    4145
                ],
                "frame.index": [
                    4147
                ],
                "Hashable": [
                    4557,
                    4154,
                    4618,
                    4157
                ],
                "new_obj": [
                    4387,
                    4389,
                    4391,
                    4303,
                    4305,
                    8371,
                    8342,
                    4344,
                    8377,
                    8378,
                    8348,
                    8349
                ],
                "index._values": [
                    4308
                ],
                "PeriodIndex": [
                    4309
                ],
                "DatetimeIndex": [
                    4309
                ],
                "np.object_": [
                    4310
                ],
                "mask.all": [
                    5641,
                    4319
                ],
                "values.fill": [
                    4321
                ],
                "values.take": [
                    4323
                ],
                "values_type": [
                    4330,
                    4339,
                    4340,
                    4333
                ],
                "values_dtype": [
                    4331,
                    4340
                ],
                "DatetimeLikeArray": [
                    4339,
                    4333
                ],
                "values._data": [
                    4334
                ],
                "maybe_upcast_putmask": [
                    4337
                ],
                "self.index._get_level_number": [
                    4348
                ],
                "lev": [
                    4386,
                    4348,
                    4366
                ],
                "self.index.droplevel": [
                    4350
                ],
                "to_insert": [
                    4353,
                    4363,
                    4366,
                    4359
                ],
                "self.index.levels": [
                    4359
                ],
                "self.index.codes": [
                    4359
                ],
                "default": [
                    4361,
                    4362
                ],
                "self.index.name": [
                    4362,
                    7007
                ],
                "multi_col": [
                    4370,
                    4365
                ],
                "lab": [
                    4386,
                    4366
                ],
                "reversed": [
                    4366
                ],
                "col_name": [
                    4378,
                    4371,
                    4373,
                    4381
                ],
                "col_fill": [
                    4378,
                    4372,
                    4381,
                    4383
                ],
                "lev_num": [
                    4380,
                    4381
                ],
                "self.columns._get_level_number": [
                    4380
                ],
                "col_level": [
                    4380,
                    6461
                ],
                "name_lst": [
                    4384,
                    4381,
                    4382,
                    4383
                ],
                "level_values": [
                    4386,
                    4387
                ],
                "_maybe_casted_values": [
                    4386
                ],
                "new_obj.insert": [
                    4387
                ],
                "new_obj.index": [
                    4389
                ],
                "isna": [
                    5380,
                    5381,
                    5636,
                    5479,
                    4400,
                    5627
                ],
                "isnull": [
                    4404
                ],
                "notna": [
                    7555,
                    7781,
                    5638,
                    7941,
                    7784,
                    7755,
                    7758,
                    4408,
                    5630,
                    5631
                ],
                "notnull": [
                    4412
                ],
                "self._get_axis_number": [
                    6657,
                    5189,
                    8293,
                    5160,
                    4522,
                    7832,
                    5712,
                    4787,
                    7605,
                    8053,
                    8120,
                    4696,
                    6681,
                    7739
                ],
                "agg_axis": [
                    4523,
                    4527,
                    4532,
                    4534,
                    7799,
                    7771,
                    4539
                ],
                "agg_obj": [
                    4539,
                    4532,
                    4525,
                    4534
                ],
                "subset": [
                    4654,
                    4526,
                    4528,
                    4655,
                    4657,
                    4531,
                    4658,
                    4659,
                    4660,
                    4919,
                    4662,
                    4665,
                    4916,
                    4917,
                    6581,
                    6582,
                    4670,
                    4927,
                    6583,
                    6584,
                    4674,
                    6587,
                    4598
                ],
                "ax": [
                    4528,
                    4527
                ],
                "self._get_axis": [
                    5190,
                    4527,
                    4788,
                    8055,
                    8122
                ],
                "indices": [
                    4528,
                    4529,
                    4532,
                    8054,
                    8056,
                    8121,
                    8123
                ],
                "ax.get_indexer_for": [
                    4528
                ],
                "check": [
                    4529,
                    4530,
                    4531
                ],
                "check.any": [
                    4530
                ],
                "np.compress": [
                    4531
                ],
                "self.take": [
                    4532
                ],
                "agg_obj.count": [
                    4534
                ],
                "how": [
                    4544,
                    7200,
                    6661,
                    7207,
                    8346,
                    7241,
                    7182,
                    7214,
                    6672,
                    6674,
                    4538,
                    7163,
                    4540,
                    4543
                ],
                "agg_obj._get_axis": [
                    4539
                ],
                "self.empty": [
                    4594,
                    4645,
                    5366
                ],
                "duplicated": [
                    4608,
                    4601,
                    4598
                ],
                "self.duplicated": [
                    4598
                ],
                "keep": [
                    4678,
                    5041,
                    4598,
                    5142
                ],
                "inds": [
                    4601,
                    4602,
                    4605
                ],
                "nonzero": [
                    4601
                ],
                "self._data.take": [
                    4825,
                    4602,
                    4723
                ],
                "ignore_index": [
                    4610,
                    6998,
                    4727,
                    7001,
                    4604,
                    7037,
                    4830
                ],
                "new_data.axes": [
                    4728,
                    4828,
                    4605,
                    4831
                ],
                "result.index": [
                    6273,
                    4611,
                    5196,
                    5197,
                    5166,
                    5167
                ],
                "shape": [
                    4649,
                    4675,
                    4652,
                    4677
                ],
                "algorithms.factorize": [
                    4649
                ],
                "vals": [
                    4674,
                    4675,
                    7334,
                    7336,
                    4650,
                    7338
                ],
                "_SIZE_HINT_LIMIT": [
                    4650
                ],
                "labels.astype": [
                    4652
                ],
                "np.iterable": [
                    4657
                ],
                "cast": [
                    4665
                ],
                "diff": [
                    4672,
                    4670,
                    4671
                ],
                "difference": [
                    4670
                ],
                "diff.empty": [
                    4671
                ],
                "col.values": [
                    4674
                ],
                "f": [
                    4675,
                    7908,
                    7921,
                    7890,
                    7931,
                    8222
                ],
                "ids": [
                    4677,
                    4678
                ],
                "get_group_index": [
                    4677
                ],
                "duplicated_int64": [
                    4678
                ],
                "by": [
                    4704,
                    4707,
                    4713,
                    4714,
                    5710,
                    5716,
                    4698,
                    4699,
                    4700,
                    4702
                ],
                "ascending": [
                    4796,
                    4708,
                    4804,
                    4716,
                    4717,
                    4812,
                    4813,
                    4720,
                    4821,
                    4922,
                    4700,
                    4702
                ],
                "self._get_label_or_level_values": [
                    4714,
                    4707
                ],
                "lexsort_indexer": [
                    4802,
                    4708
                ],
                "na_position": [
                    4720,
                    4821,
                    4708,
                    4805
                ],
                "ensure_platform_int": [
                    4709
                ],
                "nargsort": [
                    4820,
                    4719
                ],
                "kind": [
                    4720,
                    4821
                ],
                "self._get_block_manager_axis": [
                    4824,
                    4724,
                    6557
                ],
                "__finalize__": [
                    4836,
                    4733
                ],
                "NDFrame.sort_values.__doc__": [
                    4684
                ],
                "NDFrame.sort_values": [
                    4684
                ],
                "labels._sort_levels_monotonic": [
                    4792
                ],
                "new_axis": [
                    4795
                ],
                "labels.sortlevel": [
                    4795
                ],
                "sort_remaining": [
                    4796
                ],
                "labels._get_codes_for_sorting": [
                    4803
                ],
                "labels.is_monotonic_increasing": [
                    4812
                ],
                "labels.is_monotonic_decreasing": [
                    4813
                ],
                "baxis": [
                    4824,
                    4825,
                    4828
                ],
                "_sort_levels_monotonic": [
                    4828
                ],
                "counts": [
                    4928,
                    4929,
                    4932,
                    7799,
                    7759,
                    7760,
                    7797,
                    4919,
                    4922,
                    4924
                ],
                "size": [
                    4919
                ],
                "self.groupby": [
                    4919
                ],
                "sort": [
                    7202,
                    7207,
                    7247,
                    7186,
                    5720,
                    4921,
                    7163,
                    7039
                ],
                "counts.sort_values": [
                    4922
                ],
                "normalize": [
                    4923
                ],
                "counts.sum": [
                    4924
                ],
                "counts.index": [
                    4928,
                    4929
                ],
                "MultiIndex.from_arrays": [
                    4928
                ],
                "MultiIndex": [
                    4928
                ],
                "counts.index.name": [
                    4929
                ],
                "nlargest": [
                    5041
                ],
                "algorithms.SelectNFrame": [
                    5041,
                    5141
                ],
                "nsmallest": [
                    5141
                ],
                "result._get_axis": [
                    5162
                ],
                "result.index.swaplevel": [
                    5167
                ],
                "j": [
                    7433,
                    7434,
                    7437,
                    5167,
                    7440,
                    5170,
                    7446,
                    7447
                ],
                "result.columns.swaplevel": [
                    5170
                ],
                "result.index.reorder_levels": [
                    5197
                ],
                "order": [
                    5200,
                    5197
                ],
                "result.columns.reorder_levels": [
                    5200
                ],
                "_arith_op": [
                    5228,
                    5225,
                    5212
                ],
                "func": [
                    5412,
                    5221,
                    6661,
                    5223,
                    6665,
                    6825,
                    5229,
                    6894,
                    6895,
                    6683,
                    5212,
                    6684
                ],
                "ops.fill_binop": [
                    5220
                ],
                "ops": [
                    5220,
                    5223,
                    5225,
                    8502,
                    8503
                ],
                "ops.should_series_dispatch": [
                    5223
                ],
                "ops.dispatch_to_series": [
                    5225
                ],
                "np.errstate": [
                    7920,
                    5626,
                    5227
                ],
                "res_values": [
                    5228,
                    5229
                ],
                "other.values": [
                    5228,
                    5229
                ],
                "dispatch_fill_zeros": [
                    5229
                ],
                "out": [
                    5248,
                    5249,
                    7878,
                    7879,
                    7883,
                    7884,
                    5245
                ],
                "out.columns": [
                    5248
                ],
                "other_idxlen": [
                    5366,
                    5358
                ],
                "this": [
                    7652,
                    5638,
                    5386,
                    5644,
                    5360,
                    5361,
                    7606,
                    5623,
                    7609,
                    5370,
                    5627,
                    7612,
                    5374,
                    5631
                ],
                "self.align": [
                    5360
                ],
                "this.index": [
                    5361
                ],
                "other.empty": [
                    5363
                ],
                "other.copy": [
                    5367
                ],
                "this.columns.union": [
                    5370
                ],
                "this.columns": [
                    5370
                ],
                "do_fill": [
                    5371,
                    5389
                ],
                "otherSeries": [
                    5378,
                    5410,
                    5412,
                    5381,
                    5391,
                    5393,
                    5375
                ],
                "this_dtype": [
                    5377,
                    5413,
                    5406,
                    5407
                ],
                "other_dtype": [
                    5409,
                    5378,
                    5398,
                    5406
                ],
                "otherSeries.dtype": [
                    5378
                ],
                "this_mask": [
                    5392,
                    5380
                ],
                "other_mask": [
                    5385,
                    5381,
                    5393
                ],
                "overwrite": [
                    5385,
                    5635
                ],
                "other_mask.all": [
                    5385
                ],
                "series.copy": [
                    5390
                ],
                "otherSeries.copy": [
                    5391
                ],
                "new_dtype": [
                    5408,
                    5409,
                    5410,
                    5398,
                    5400,
                    5406,
                    5407
                ],
                "series.astype": [
                    5400,
                    5408
                ],
                "find_common_type": [
                    5406
                ],
                "is_dtype_equal": [
                    5409,
                    5407
                ],
                "otherSeries.astype": [
                    5410
                ],
                "maybe_downcast_to_dtype": [
                    5413
                ],
                "arr._values": [
                    5469
                ],
                "needs_i8_conversion": [
                    7880,
                    5471
                ],
                "arr.dtype": [
                    5472
                ],
                "arr.asi8": [
                    5473
                ],
                "arr.view": [
                    5475
                ],
                "mask._values": [
                    5481
                ],
                "x_values": [
                    5483,
                    5491
                ],
                "extract_values": [
                    5483,
                    5484
                ],
                "y_values": [
                    5489,
                    5491,
                    5484
                ],
                "y": [
                    5488,
                    5484
                ],
                "y.name": [
                    5488
                ],
                "expressions.where": [
                    5491,
                    5644
                ],
                "expressions": [
                    5491,
                    5644
                ],
                "self.combine": [
                    5493
                ],
                "combiner": [
                    5493
                ],
                "other.reindex_like": [
                    5620
                ],
                "that": [
                    5636,
                    5644,
                    5624,
                    5627,
                    5630
                ],
                "filter_func": [
                    5625,
                    5627
                ],
                "mask_this": [
                    5632,
                    5630
                ],
                "mask_that": [
                    5632,
                    5631
                ],
                "DataFrameGroupBy": [
                    5714
                ],
                "as_index": [
                    5719
                ],
                "group_keys": [
                    5721
                ],
                "squeeze": [
                    5722
                ],
                "observed": [
                    6034,
                    5723
                ],
                "pivot": [
                    5876
                ],
                "pivot_table": [
                    6024
                ],
                "aggfunc": [
                    6029
                ],
                "margins": [
                    6031
                ],
                "dropna": [
                    6032,
                    7990,
                    6203,
                    8220,
                    6205
                ],
                "margins_name": [
                    6033
                ],
                "stack_multiple": [
                    6203
                ],
                "stack": [
                    6205
                ],
                "is_scalar": [
                    6263
                ],
                "df": [
                    6272,
                    7874,
                    7334,
                    7878,
                    7879,
                    7880,
                    7883,
                    7196,
                    7857,
                    7859,
                    7861,
                    6268,
                    6270,
                    6271
                ],
                "self.reset_index": [
                    6268
                ],
                "explode": [
                    6271
                ],
                "df.drop": [
                    6272
                ],
                "self.index.take": [
                    6273
                ],
                "result.reindex": [
                    6274
                ],
                "unstack": [
                    6339
                ],
                "melt": [
                    6455
                ],
                "id_vars": [
                    6457
                ],
                "value_vars": [
                    6458
                ],
                "var_name": [
                    6459
                ],
                "value_name": [
                    6460
                ],
                "bm_axis": [
                    6557,
                    6558
                ],
                "self._data.diff": [
                    6558
                ],
                "ABCDataFrame": [
                    6568,
                    6569
                ],
                "subset.ndim": [
                    6583
                ],
                "_agg_summary_and_see_also_doc": [
                    6650,
                    6589
                ],
                "dedent": [
                    6613,
                    6589
                ],
                "_agg_examples_doc": [
                    6651,
                    6613
                ],
                "self._aggregate": [
                    6661
                ],
                "self.apply": [
                    6665,
                    6897,
                    7990
                ],
                "self.T._aggregate": [
                    6672
                ],
                "arg": [
                    6672,
                    6675
                ],
                "result.T": [
                    6673,
                    7803,
                    8316
                ],
                "_aggregate": [
                    6675
                ],
                "agg": [
                    6677
                ],
                "aggregate": [
                    6677
                ],
                "self.T.transform": [
                    6683
                ],
                "transform": [
                    6684
                ],
                "op": [
                    7837,
                    6823,
                    6832,
                    7869,
                    7870
                ],
                "frame_apply": [
                    7907,
                    6823
                ],
                "raw": [
                    6827
                ],
                "result_type": [
                    6828
                ],
                "kwds": [
                    7870,
                    7837,
                    6830,
                    7869
                ],
                "op.get_result": [
                    6832
                ],
                "x.empty": [
                    6893
                ],
                "lib.map_infer": [
                    6894,
                    6895
                ],
                "x.astype": [
                    6895
                ],
                "object": [
                    7012,
                    6895
                ],
                "infer": [
                    6897
                ],
                "other.name": [
                    7001,
                    7175,
                    7173,
                    7007
                ],
                "idx_diff": [
                    7008,
                    7010,
                    7012,
                    7653,
                    7655,
                    7656
                ],
                "other.index.difference": [
                    7008
                ],
                "combined_columns": [
                    7010,
                    7012,
                    7014,
                    7019,
                    7020
                ],
                "self.columns.append": [
                    7010
                ],
                "self.columns.astype": [
                    7012
                ],
                "rename_axis": [
                    7014
                ],
                "T.infer_objects": [
                    7014
                ],
                "to_frame": [
                    7014
                ],
                "index.names": [
                    7017
                ],
                "self.columns.equals": [
                    7019
                ],
                "all": [
                    7026,
                    7555,
                    7196,
                    7941
                ],
                "to_concat": [
                    7032,
                    7034,
                    7036
                ],
                "concat": [
                    7360,
                    7201,
                    7206,
                    7035,
                    8446
                ],
                "self._join_compat": [
                    7162
                ],
                "on": [
                    7242,
                    7181,
                    7183,
                    7189,
                    7163
                ],
                "lsuffix": [
                    7185,
                    7163
                ],
                "rsuffix": [
                    7185,
                    7163
                ],
                "merge": [
                    7178,
                    7213,
                    7238
                ],
                "frames": [
                    7202,
                    7207,
                    7210,
                    7212,
                    7194,
                    7196
                ],
                "can_concat": [
                    7196,
                    7199
                ],
                "df.index.is_unique": [
                    7196
                ],
                "df.index": [
                    7196
                ],
                "res.reindex": [
                    7204
                ],
                "joined": [
                    7217,
                    7210,
                    7213,
                    7214
                ],
                "left_on": [
                    7243
                ],
                "right_on": [
                    7244
                ],
                "left_index": [
                    7245
                ],
                "right_index": [
                    7246
                ],
                "suffixes": [
                    7248
                ],
                "indicator": [
                    7250
                ],
                "validate": [
                    7251
                ],
                "df.items": [
                    7334
                ],
                "_series_round": [
                    7336,
                    7354
                ],
                "decimals": [
                    7336,
                    7342,
                    7347,
                    7348,
                    7349,
                    7351,
                    7352,
                    7354
                ],
                "is_integer_dtype": [
                    7341
                ],
                "is_float_dtype": [
                    7341
                ],
                "s.round": [
                    7342
                ],
                "nv.validate_round": [
                    7345
                ],
                "decimals.index.is_unique": [
                    7349
                ],
                "decimals.index": [
                    7349
                ],
                "new_cols": [
                    7360,
                    7354,
                    7358,
                    7351
                ],
                "_dict_round": [
                    7351
                ],
                "numeric_df": [
                    7553,
                    7415,
                    7416,
                    7418,
                    7550,
                    7551
                ],
                "self._get_numeric_data": [
                    7744,
                    7841,
                    8292,
                    7766,
                    7606,
                    8217,
                    7415,
                    7550
                ],
                "numeric_df.columns": [
                    7416,
                    7551
                ],
                "cols.copy": [
                    7552,
                    7417
                ],
                "mat": [
                    7553,
                    7427,
                    7555,
                    7556,
                    7557,
                    7431,
                    7432,
                    7433,
                    7560,
                    7563,
                    7418,
                    7421,
                    7423
                ],
                "numeric_df.values": [
                    7553,
                    7418
                ],
                "correl": [
                    7455,
                    7653,
                    7430,
                    7656,
                    7658,
                    7630,
                    7637,
                    7446,
                    7447,
                    7421,
                    7423
                ],
                "libalgos.nancorr": [
                    7563,
                    7421
                ],
                "libalgos": [
                    7563,
                    7421,
                    7423
                ],
                "ensure_float64": [
                    7427,
                    7563,
                    7421,
                    7423
                ],
                "min_periods": [
                    7425,
                    7426,
                    7556,
                    7563,
                    7438,
                    7421,
                    7423
                ],
                "libalgos.nancorr_spearman": [
                    7423
                ],
                "callable": [
                    7424,
                    7632
                ],
                "corrf": [
                    7443,
                    7428,
                    7445
                ],
                "nanops.get_corr_func": [
                    7428
                ],
                "nanops": [
                    8121,
                    7635,
                    7428,
                    8054
                ],
                "K": [
                    7429,
                    7430
                ],
                "float": [
                    7430
                ],
                "np.isfinite": [
                    7431
                ],
                "ac": [
                    7432,
                    7443,
                    7445
                ],
                "bc": [
                    7433,
                    7443,
                    7445
                ],
                "valid": [
                    7442,
                    7443,
                    7437,
                    7438
                ],
                "valid.sum": [
                    7438
                ],
                "valid.all": [
                    7442
                ],
                "baseCov": [
                    7557,
                    7558,
                    7560,
                    7561,
                    7563,
                    7565
                ],
                "mat.shape": [
                    7557
                ],
                "baseCov.fill": [
                    7558
                ],
                "np.cov": [
                    7560
                ],
                "mat.T": [
                    7560
                ],
                "baseCov.reshape": [
                    7561
                ],
                "this.apply": [
                    7609
                ],
                "other.corr": [
                    7609
                ],
                "other._get_numeric_data": [
                    7611
                ],
                "this.align": [
                    7612
                ],
                "left.T": [
                    7615
                ],
                "right.T": [
                    7616
                ],
                "ldem": [
                    7624,
                    7627
                ],
                "left.mean": [
                    7624
                ],
                "rdem": [
                    7625,
                    7627
                ],
                "right.mean": [
                    7625
                ],
                "num": [
                    7627,
                    7630
                ],
                "sum": [
                    7755,
                    7627,
                    7758
                ],
                "dom": [
                    7628,
                    7630
                ],
                "left.count": [
                    7628
                ],
                "left.std": [
                    7628
                ],
                "right.std": [
                    7628
                ],
                "nanops.nancorr": [
                    7635
                ],
                "left.values.T": [
                    7638
                ],
                "right.values.T": [
                    7638
                ],
                "left.columns": [
                    7638
                ],
                "raxis": [
                    7651,
                    7652
                ],
                "union": [
                    7652
                ],
                "this._get_axis": [
                    7652
                ],
                "other._get_axis": [
                    7652
                ],
                "result_index.difference": [
                    7653
                ],
                "correl.index": [
                    7653
                ],
                "correl.append": [
                    7656
                ],
                "self._count_level": [
                    7741
                ],
                "numeric_only": [
                    8292,
                    7816,
                    7886,
                    7856,
                    7858,
                    7923,
                    7765,
                    8217,
                    7741,
                    7743
                ],
                "frame._get_axis": [
                    7770,
                    7749
                ],
                "frame._get_agg_axis": [
                    7760,
                    7771,
                    7750
                ],
                "frame._is_mixed_type": [
                    7752,
                    7778
                ],
                "frame._data.any_extension_types": [
                    7752
                ],
                "frame._data": [
                    7752
                ],
                "series_counts": [
                    7758,
                    7759
                ],
                "series_counts.values": [
                    7759
                ],
                "result.astype": [
                    7762,
                    7940,
                    7942
                ],
                "count_axis": [
                    7792,
                    7794,
                    7795,
                    7796,
                    7770,
                    7773
                ],
                "self._get_axis_name": [
                    8344,
                    8373,
                    7775
                ],
                "frame.values": [
                    7784
                ],
                "mask.T": [
                    7789
                ],
                "count_axis._get_level_number": [
                    7792
                ],
                "level_name": [
                    7794,
                    7795
                ],
                "count_axis._names": [
                    7794
                ],
                "level_index": [
                    7795,
                    7797,
                    7799
                ],
                "_shallow_copy": [
                    7795
                ],
                "count_axis.levels": [
                    7795
                ],
                "level_codes": [
                    7796,
                    7797
                ],
                "ensure_int64": [
                    7796
                ],
                "count_axis.codes": [
                    7796
                ],
                "lib.count_level_2d": [
                    7797
                ],
                "filter_type": [
                    7840,
                    7842,
                    7811,
                    7939,
                    7941,
                    7850,
                    7896,
                    7827,
                    7864,
                    7933
                ],
                "dtype_is_dt": [
                    7816,
                    7824,
                    7813
                ],
                "self.dtypes.apply": [
                    7813
                ],
                "is_datetime64_any_dtype": [
                    7814
                ],
                "is_period_dtype": [
                    7814
                ],
                "dtype_is_dt.any": [
                    7816
                ],
                "FutureWarning": [
                    7821
                ],
                "constructor": [
                    7834,
                    7948,
                    7829
                ],
                "self._get_agg_axis": [
                    7833,
                    8124,
                    8057
                ],
                "skipna": [
                    7869,
                    8054,
                    8121,
                    7837,
                    7870
                ],
                "axis_matters": [
                    7843
                ],
                "self._get_bool_data": [
                    7845,
                    7847
                ],
                "_get_data": [
                    7859,
                    7916,
                    7924
                ],
                "df.T": [
                    7861
                ],
                "out_dtype": [
                    7864,
                    7878
                ],
                "df._data.reduce": [
                    7874
                ],
                "df._data": [
                    7874
                ],
                "blk_func": [
                    7874
                ],
                "res.keys": [
                    7877
                ],
                "df._constructor_sliced": [
                    7878
                ],
                "out.index": [
                    7879
                ],
                "df.columns": [
                    7879
                ],
                "df.dtypes.apply": [
                    7880
                ],
                "df.dtypes": [
                    7880,
                    7883
                ],
                "coerce_to_dtypes": [
                    7946,
                    7883
                ],
                "out.values": [
                    7883
                ],
                "opa": [
                    7907,
                    7910
                ],
                "opa.get_result": [
                    7910
                ],
                "self.ndim": [
                    7911
                ],
                "result.iloc": [
                    7912
                ],
                "data._get_agg_axis": [
                    7925,
                    7917
                ],
                "np.bool_": [
                    7936,
                    7942
                ],
                "result.dtype": [
                    7937
                ],
                "np.float64": [
                    8304,
                    7940
                ],
                "data.dtypes": [
                    7946
                ],
                "Series.nunique": [
                    7990
                ],
                "nanops.nanargmin": [
                    8054
                ],
                "nanops.nanargmax": [
                    8121
                ],
                "axis_num": [
                    8130,
                    8132,
                    8135
                ],
                "repr": [
                    8135
                ],
                "s.mode": [
                    8220
                ],
                "data.apply": [
                    8222
                ],
                "validate_percentile": [
                    8290
                ],
                "q": [
                    8290,
                    8302,
                    8303,
                    8304,
                    8307,
                    8313
                ],
                "is_transposed": [
                    8296,
                    8315,
                    8307,
                    8294
                ],
                "data.T": [
                    8297
                ],
                "data.columns": [
                    8299
                ],
                "self.columns.name": [
                    8301
                ],
                "data._data.quantile": [
                    8306
                ],
                "interpolation": [
                    8307
                ],
                "axis_name": [
                    8377,
                    8373,
                    8374,
                    8344,
                    8345,
                    8348
                ],
                "old_ax": [
                    8345,
                    8346,
                    8374,
                    8375
                ],
                "new_ax": [
                    8377,
                    8346,
                    8348,
                    8375
                ],
                "old_ax.to_timestamp": [
                    8346
                ],
                "setattr": [
                    8377,
                    8348
                ],
                "old_ax.to_period": [
                    8375
                ],
                "collections.defaultdict": [
                    8508,
                    8445
                ],
                "isin": [
                    8448
                ],
                "values.index.is_unique": [
                    8458,
                    8454
                ],
                "values.index": [
                    8458,
                    8454
                ],
                "self.eq": [
                    8456,
                    8460
                ],
                "values.reindex_like": [
                    8456,
                    8460
                ],
                "values.columns.is_unique": [
                    8458
                ],
                "values.columns": [
                    8458
                ],
                "__name__": [
                    8466
                ],
                "reshape": [
                    8469
                ],
                "algorithms.isin": [
                    8469
                ],
                "self.values.ravel": [
                    8469
                ],
                "_AXIS_ORDERS": [
                    8480,
                    8476
                ],
                "_AXIS_NUMBERS": [
                    8477
                ],
                "_AXIS_NAMES": [
                    8478
                ],
                "_AXIS_REVERSED": [
                    8479
                ],
                "_AXIS_LEN": [
                    8480
                ],
                "_info_axis_number": [
                    8481
                ],
                "_info_axis_name": [
                    8482
                ],
                "properties.AxisProperty": [
                    8484,
                    8487
                ],
                "properties": [
                    8484,
                    8487
                ],
                "plot": [
                    8493
                ],
                "CachedAccessor": [
                    8496,
                    8493
                ],
                "pandas.plotting.PlotAccessor": [
                    8493
                ],
                "pandas.plotting": [
                    8493,
                    8494,
                    8495
                ],
                "pandas": [
                    8493,
                    8494,
                    8495
                ],
                "hist": [
                    8494
                ],
                "pandas.plotting.hist_frame": [
                    8494
                ],
                "boxplot": [
                    8495
                ],
                "pandas.plotting.boxplot_frame": [
                    8495
                ],
                "sparse": [
                    8496
                ],
                "SparseFrameAccessor": [
                    8496
                ],
                "DataFrame._add_numeric_operations": [
                    8499
                ],
                "DataFrame._add_series_or_dataframe_operations": [
                    8500
                ],
                "ops.add_flex_arithmetic_methods": [
                    8502
                ],
                "ops.add_special_arithmetic_methods": [
                    8503
                ],
                "s.items": [
                    8510
                ]
            },
            "filtered_variables_in_file": {
                "TYPE_CHECKING": [
                    136
                ],
                "_shared_doc_kwargs": [
                    3552,
                    3937,
                    5696,
                    3621,
                    4683,
                    3918,
                    143,
                    4398,
                    4402,
                    3956,
                    4406,
                    6679,
                    4410,
                    3612,
                    6653
                ],
                "_numeric_only_doc": [
                    170
                ],
                "_merge_doc": [
                    7220,
                    175
                ],
                "NDFrame": [
                    3617,
                    324,
                    517,
                    3622,
                    4684,
                    3918,
                    402,
                    2739,
                    410,
                    2719
                ],
                "_internal_names_set": [
                    402
                ],
                "NDFrame._internal_names_set": [
                    402
                ],
                "_typ": [
                    403
                ],
                "DataFrame": [
                    7175,
                    7177,
                    8457,
                    8468,
                    407,
                    3362,
                    433,
                    8499,
                    8500,
                    8502,
                    8503,
                    2512,
                    3416,
                    1632,
                    2657,
                    1123,
                    7024,
                    5617,
                    5618,
                    7025,
                    1141,
                    7799,
                    2684
                ],
                "Type": [
                    409,
                    406
                ],
                "_constructor_sliced": [
                    409
                ],
                "Series": [
                    1152,
                    7172,
                    8453,
                    904,
                    907,
                    2316,
                    7567,
                    2576,
                    2321,
                    7952,
                    409,
                    3359,
                    4646,
                    3367,
                    6568,
                    2601,
                    6569,
                    7347,
                    7348,
                    7990,
                    2232,
                    7608,
                    7992,
                    8124,
                    4678,
                    7750,
                    460,
                    7760,
                    6996,
                    7637,
                    1240,
                    7000,
                    8057,
                    3424,
                    1123,
                    2659,
                    485,
                    2788,
                    7656,
                    1145,
                    1146,
                    8059,
                    2556,
                    895
                ],
                "_deprecations": [
                    410
                ],
                "FrozenSet": [
                    3200,
                    410
                ],
                "NDFrame._deprecations": [
                    410
                ],
                "_accessors": [
                    411
                ],
                "Set": [
                    411
                ],
                "Optional": [
                    768,
                    4353,
                    771,
                    772,
                    773,
                    774,
                    4618,
                    423,
                    424,
                    425,
                    6568,
                    698,
                    4154,
                    4159,
                    1856,
                    1858,
                    1859,
                    1860,
                    1861,
                    1862,
                    1863,
                    4557,
                    3790,
                    3792,
                    3793,
                    3794,
                    4561,
                    3797,
                    3799,
                    3927,
                    2017,
                    2018,
                    4840,
                    755,
                    756,
                    757,
                    761,
                    762,
                    763,
                    765,
                    766,
                    767
                ],
                "Axes": [
                    424,
                    423
                ],
                "Dtype": [
                    3200,
                    425,
                    3201
                ],
                "data": [
                    8217,
                    8222,
                    1593,
                    1598,
                    1609,
                    1611,
                    1614,
                    1616,
                    1618,
                    1620,
                    1621,
                    1625,
                    1632,
                    1633,
                    8292,
                    1638,
                    8297,
                    8299,
                    8306,
                    7841,
                    7845,
                    7847,
                    7854,
                    7887,
                    7888,
                    1238,
                    1240,
                    1241,
                    1243,
                    1250,
                    7916,
                    7917,
                    3311,
                    7919,
                    3314,
                    3315,
                    7924,
                    7925,
                    7927,
                    7929,
                    7930,
                    7946,
                    8509,
                    428,
                    429,
                    433,
                    434,
                    436,
                    438,
                    440,
                    441,
                    442,
                    446,
                    447,
                    451,
                    453,
                    454,
                    455,
                    457,
                    458,
                    460,
                    461,
                    462,
                    463,
                    466,
                    467,
                    468,
                    470,
                    473,
                    474,
                    475,
                    476,
                    477,
                    478,
                    479,
                    480,
                    485,
                    486,
                    487,
                    488,
                    490,
                    2538,
                    494,
                    2545,
                    2546,
                    499,
                    2548,
                    509
                ],
                "dtype": [
                    2433,
                    1304,
                    430,
                    431,
                    438,
                    441,
                    1849,
                    2429,
                    447,
                    1602,
                    1604,
                    458,
                    1613,
                    1614,
                    466,
                    468,
                    470,
                    480,
                    1250,
                    492,
                    494,
                    496,
                    499,
                    509,
                    2430
                ],
                "self._validate_dtype": [
                    431
                ],
                "self": [
                    4096,
                    4097,
                    4098,
                    4099,
                    4101,
                    8217,
                    4126,
                    4130,
                    6203,
                    6205,
                    2114,
                    8292,
                    8293,
                    8301,
                    8303,
                    8304,
                    8311,
                    6265,
                    8313,
                    6268,
                    6273,
                    6274,
                    2196,
                    8342,
                    8344,
                    8345,
                    8371,
                    8373,
                    2230,
                    8374,
                    6339,
                    4303,
                    4305,
                    4348,
                    4349,
                    4350,
                    8448,
                    8449,
                    4354,
                    4357,
                    4359,
                    8456,
                    4361,
                    4362,
                    4363,
                    8460,
                    2317,
                    2318,
                    4365,
                    2321,
                    4373,
                    8469,
                    8470,
                    8471,
                    4380,
                    4382,
                    6456,
                    2426,
                    2427,
                    2431,
                    2434,
                    2435,
                    2439,
                    2442,
                    2443,
                    2446,
                    2450,
                    6557,
                    6558,
                    6559,
                    2468,
                    2472,
                    2474,
                    2475,
                    4522,
                    4525,
                    2478,
                    431,
                    4527,
                    2483,
                    4532,
                    437,
                    2485,
                    2486,
                    6582,
                    2489,
                    2495,
                    2499,
                    2500,
                    2501,
                    2502,
                    4548,
                    4551,
                    2505,
                    2509,
                    2513,
                    2517,
                    2524,
                    2525,
                    2526,
                    2532,
                    2538,
                    2545,
                    4594,
                    4595,
                    4598,
                    4602,
                    2556,
                    4606,
                    4608,
                    6657,
                    2562,
                    2564,
                    517,
                    6661,
                    2569,
                    6665,
                    2571,
                    2575,
                    6672,
                    2577,
                    2579,
                    2580,
                    2583,
                    536,
                    2584,
                    2585,
                    2587,
                    6681,
                    6683,
                    4645,
                    2602,
                    2603,
                    4650,
                    558,
                    2606,
                    4655,
                    2609,
                    4660,
                    4670,
                    2626,
                    4674,
                    2629,
                    2630,
                    4678,
                    2637,
                    591,
                    592,
                    594,
                    2643,
                    2644,
                    2645,
                    2648,
                    4696,
                    2651,
                    604,
                    2655,
                    2658,
                    4707,
                    2660,
                    2663,
                    4714,
                    619,
                    2669,
                    2670,
                    2675,
                    4723,
                    2677,
                    4724,
                    2679,
                    2681,
                    2682,
                    4731,
                    4733,
                    2688,
                    2690,
                    645,
                    2693,
                    2694,
                    2700,
                    2702,
                    2709,
                    2710,
                    2711,
                    665,
                    2714,
                    2718,
                    2719,
                    673,
                    674,
                    2724,
                    2725,
                    6824,
                    686,
                    2737,
                    2738,
                    2739,
                    4787,
                    4788,
                    2744,
                    2745,
                    704,
                    706,
                    2760,
                    2764,
                    2765,
                    719,
                    4818,
                    2775,
                    4824,
                    2777,
                    2778,
                    4825,
                    2786,
                    4834,
                    4836,
                    2795,
                    2800,
                    6897,
                    2802,
                    2804,
                    2810,
                    2811,
                    807,
                    4917,
                    4919,
                    842,
                    7007,
                    7008,
                    7010,
                    7012,
                    7019,
                    7020,
                    7026,
                    7027,
                    7032,
                    7034,
                    896,
                    897,
                    898,
                    900,
                    901,
                    905,
                    2964,
                    2967,
                    2971,
                    2974,
                    5041,
                    952,
                    953,
                    954,
                    7162,
                    1023,
                    1025,
                    1029,
                    1032,
                    7179,
                    3087,
                    3088,
                    3091,
                    1044,
                    5142,
                    7194,
                    7204,
                    5158,
                    5160,
                    5189,
                    5190,
                    7239,
                    5193,
                    1124,
                    1125,
                    5223,
                    1128,
                    5225,
                    5228,
                    1133,
                    1134,
                    5229,
                    1142,
                    3197,
                    1150,
                    5245,
                    5248,
                    1160,
                    3209,
                    1166,
                    3215,
                    3221,
                    3223,
                    3241,
                    3242,
                    3243,
                    7351,
                    7354,
                    7359,
                    7360,
                    7363,
                    3311,
                    5360,
                    5363,
                    5364,
                    5366,
                    7415,
                    3340,
                    3346,
                    5395,
                    1304,
                    7455,
                    3365,
                    3366,
                    3368,
                    5418,
                    3378,
                    3383,
                    3405,
                    3413,
                    3414,
                    3415,
                    3424,
                    3425,
                    5488,
                    1396,
                    5493,
                    3452,
                    1405,
                    3453,
                    1407,
                    3454,
                    3455,
                    7550,
                    1411,
                    3460,
                    1412,
                    3465,
                    1417,
                    7565,
                    1423,
                    1425,
                    1428,
                    3476,
                    1435,
                    1438,
                    1439,
                    3502,
                    3505,
                    7605,
                    7606,
                    3522,
                    3525,
                    3536,
                    3537,
                    3542,
                    3544,
                    3546,
                    5620,
                    5622,
                    5623,
                    1539,
                    5644,
                    3635,
                    7739,
                    7741,
                    7744,
                    7746,
                    5712,
                    5715,
                    7766,
                    7768,
                    7775,
                    7813,
                    7824,
                    7825,
                    7832,
                    7833,
                    7834,
                    7841,
                    7845,
                    7847,
                    7857,
                    7887,
                    7908,
                    7911,
                    1770,
                    1772,
                    1774,
                    1776,
                    1779,
                    5876,
                    1781,
                    7929,
                    1789,
                    1791,
                    1792,
                    7949,
                    1816,
                    7990,
                    8053,
                    8054,
                    8055,
                    8057,
                    6025,
                    1975,
                    8120,
                    8121,
                    8122,
                    8124,
                    8131,
                    8133,
                    1998,
                    2022,
                    4076,
                    4089,
                    4091
                ],
                "data._data": [
                    434,
                    8306
                ],
                "BlockManager": [
                    436
                ],
                "mgr": [
                    517,
                    458,
                    511,
                    492,
                    494,
                    1678,
                    496,
                    1680,
                    466,
                    468,
                    437,
                    470,
                    1849,
                    441,
                    1850,
                    447
                ],
                "self._init_mgr": [
                    437
                ],
                "index": [
                    512,
                    1024,
                    1032,
                    4134,
                    4136,
                    4137,
                    4145,
                    4147,
                    1600,
                    2627,
                    2118,
                    2633,
                    2644,
                    2645,
                    1652,
                    1653,
                    1654,
                    1655,
                    1657,
                    1659,
                    1662,
                    1665,
                    1667,
                    1668,
                    2206,
                    3777,
                    2761,
                    2766,
                    1235,
                    4308,
                    4309,
                    2775,
                    2777,
                    1243,
                    1250,
                    1769,
                    5876,
                    1799,
                    2320,
                    1810,
                    1812,
                    1814,
                    1816,
                    1826,
                    1827,
                    8484,
                    817,
                    1849,
                    8509,
                    8511,
                    3909,
                    7007,
                    7017,
                    8055,
                    8056,
                    6027,
                    3484,
                    3485,
                    3487,
                    438,
                    441,
                    8122,
                    8123,
                    447,
                    458,
                    466,
                    468,
                    470,
                    484,
                    486,
                    488,
                    490,
                    492,
                    494,
                    496,
                    507,
                    509
                ],
                "columns": [
                    512,
                    1676,
                    6028,
                    1678,
                    1425,
                    1427,
                    2197,
                    3478,
                    3479,
                    5142,
                    3481,
                    8487,
                    808,
                    5041,
                    438,
                    1590,
                    952,
                    441,
                    1591,
                    955,
                    1849,
                    447,
                    1600,
                    3778,
                    3910,
                    458,
                    464,
                    465,
                    466,
                    1619,
                    468,
                    1620,
                    470,
                    1621,
                    1626,
                    1245,
                    478,
                    479,
                    480,
                    481,
                    1250,
                    1630,
                    1633,
                    1634,
                    1635,
                    1636,
                    1638,
                    1641,
                    1642,
                    492,
                    1644,
                    494,
                    496,
                    5876,
                    1654,
                    507,
                    509
                ],
                "copy": [
                    2440,
                    5386,
                    8342,
                    1304,
                    3481,
                    3487,
                    2471,
                    2478,
                    3507,
                    8371,
                    438,
                    447,
                    3527,
                    3912,
                    458,
                    7249,
                    470,
                    3548,
                    494,
                    499,
                    3571
                ],
                "init_dict": [
                    496,
                    441,
                    466,
                    468
                ],
                "ma.MaskedArray": [
                    442
                ],
                "ma": [
                    442,
                    451
                ],
                "mrecords.MaskedRecords": [
                    446
                ],
                "mrecords": [
                    446
                ],
                "masked_rec_array_to_mgr": [
                    447
                ],
                "mask": [
                    5636,
                    5638,
                    7431,
                    5641,
                    5644,
                    7437,
                    4537,
                    4539,
                    4541,
                    451,
                    452,
                    4548,
                    455,
                    4315,
                    4319,
                    4320,
                    7781,
                    5479,
                    5480,
                    5481,
                    7784,
                    7789,
                    4336,
                    4337,
                    5491,
                    7797,
                    5627
                ],
                "ma.getmaskarray": [
                    451
                ],
                "mask.any": [
                    4336,
                    452
                ],
                "fill_value": [
                    5209,
                    6339,
                    5220,
                    453,
                    455,
                    3528,
                    6030,
                    5392,
                    5393,
                    3508,
                    3572,
                    3542,
                    3959,
                    3481,
                    5371,
                    3549,
                    3487
                ],
                "maybe_upcast": [
                    453
                ],
                "data.soften_mask": [
                    454
                ],
                "data.copy": [
                    457
                ],
                "init_ndarray": [
                    458,
                    511,
                    470,
                    494
                ],
                "np.ndarray": [
                    1632,
                    3200,
                    2659,
                    1252,
                    3428,
                    4067,
                    2471,
                    3367,
                    2699,
                    460,
                    2576,
                    4113,
                    3384,
                    1147,
                    7867
                ],
                "np": [
                    3200,
                    7936,
                    7940,
                    7557,
                    7430,
                    3463,
                    7431,
                    7558,
                    7560,
                    2699,
                    7942,
                    1166,
                    7439,
                    2576,
                    4113,
                    5626,
                    1684,
                    1304,
                    2471,
                    3367,
                    3498,
                    3629,
                    1838,
                    4657,
                    4531,
                    1845,
                    3384,
                    7867,
                    8123,
                    460,
                    1614,
                    4310,
                    3417,
                    3419,
                    1632,
                    4320,
                    4321,
                    2659,
                    1252,
                    3428,
                    4067,
                    2536,
                    7656,
                    5227,
                    1772,
                    2796,
                    1135,
                    7920,
                    4337,
                    8304,
                    499,
                    1143,
                    8056,
                    4601,
                    1146,
                    1147,
                    1148,
                    3197
                ],
                "Index": [
                    2659,
                    3367,
                    1659,
                    522,
                    460,
                    8301,
                    2576,
                    3380,
                    7007,
                    3384,
                    1657,
                    1147,
                    4670,
                    3391
                ],
                "data.dtype.names": [
                    461,
                    462
                ],
                "data.dtype": [
                    461,
                    462
                ],
                "data_columns": [
                    465,
                    462,
                    463
                ],
                "k": [
                    897,
                    898,
                    900,
                    901,
                    1029,
                    1423,
                    1431,
                    954,
                    955,
                    956,
                    463,
                    1621,
                    1625,
                    1626,
                    1627,
                    4714,
                    4720,
                    3313,
                    3314,
                    1405,
                    1407
                ],
                "data.name": [
                    468
                ],
                "abc.Iterable": [
                    473
                ],
                "abc": [
                    473,
                    474,
                    4067,
                    4116
                ],
                "abc.Sequence": [
                    474
                ],
                "ExtensionArray": [
                    474,
                    3374
                ],
                "is_list_like": [
                    2786,
                    3175,
                    3177,
                    8302,
                    8462,
                    2521,
                    477
                ],
                "is_named_tuple": [
                    478
                ],
                "_fields": [
                    479
                ],
                "arrays": [
                    1025,
                    4099,
                    1029,
                    1798,
                    4101,
                    1673,
                    1035,
                    4107,
                    1038,
                    1678,
                    4111,
                    4114,
                    4117,
                    1022,
                    4121,
                    4126,
                    4131,
                    4134,
                    1845,
                    1849,
                    1621,
                    1623,
                    1628,
                    1630,
                    480,
                    1633,
                    1638,
                    492,
                    1776,
                    1656,
                    1657,
                    4093,
                    1662,
                    1791
                ],
                "to_arrays": [
                    480,
                    1633,
                    1638
                ],
                "ensure_index": [
                    481,
                    1635,
                    1640,
                    1642,
                    1620,
                    1591
                ],
                "get_names_from_index": [
                    486
                ],
                "Categorical": [
                    487
                ],
                "ibase.default_index": [
                    4611,
                    488,
                    490,
                    4728,
                    4344,
                    4605,
                    4831
                ],
                "ibase": [
                    4611,
                    488,
                    490,
                    4728,
                    4344,
                    4605,
                    4831
                ],
                "arrays_to_mgr": [
                    1849,
                    492,
                    1678
                ],
                "arr": [
                    5472,
                    5473,
                    5475,
                    5412,
                    5413,
                    5476,
                    5415,
                    499,
                    507,
                    5468,
                    5469,
                    5471
                ],
                "np.array": [
                    1304,
                    499,
                    1772,
                    1614
                ],
                "exc": [
                    505,
                    501
                ],
                "err": [
                    503,
                    2793,
                    4080,
                    3351,
                    505,
                    3356
                ],
                "arr.ndim": [
                    507
                ],
                "values": [
                    512,
                    2433,
                    8448,
                    3461,
                    8453,
                    8454,
                    8456,
                    8457,
                    6026,
                    8458,
                    8460,
                    8462,
                    8466,
                    8469,
                    2485,
                    2486,
                    7867,
                    7869,
                    7870,
                    1606,
                    1609,
                    1611,
                    7927,
                    1614,
                    1616,
                    7888,
                    7890,
                    4308,
                    4310,
                    4311,
                    7931,
                    4320,
                    4321,
                    4323,
                    7781,
                    7933,
                    4330,
                    4331,
                    8442,
                    4334,
                    6895,
                    7919,
                    2801,
                    2802,
                    4337,
                    2804,
                    4340,
                    4342,
                    5876,
                    7921,
                    8445,
                    7930,
                    2811,
                    508,
                    3453,
                    2431
                ],
                "cast_scalar_to_array": [
                    508,
                    3405
                ],
                "values.dtype": [
                    512,
                    4331,
                    4310
                ],
                "NDFrame.__init__": [
                    517
                ],
                "self.index": [
                    4096,
                    1025,
                    2562,
                    1411,
                    2435,
                    2564,
                    4097,
                    4098,
                    4099,
                    2569,
                    4101,
                    2443,
                    3340,
                    4357,
                    4359,
                    4362,
                    4363,
                    2321,
                    3346,
                    4354,
                    1044,
                    5245,
                    8470,
                    536,
                    2585,
                    1435,
                    7204,
                    2475,
                    2603,
                    558,
                    3502,
                    3378,
                    3383,
                    954,
                    7360,
                    8133,
                    2630,
                    4678,
                    6273,
                    2637,
                    2765,
                    3405,
                    3536,
                    2644,
                    7007,
                    3424,
                    2786,
                    4350,
                    1770,
                    1772,
                    1774,
                    2802,
                    1779,
                    2675,
                    1781,
                    2677,
                    2679,
                    4348,
                    5363,
                    2811,
                    2556,
                    4349,
                    3454
                ],
                "self.columns": [
                    896,
                    897,
                    1792,
                    2435,
                    900,
                    1029,
                    1412,
                    3460,
                    1032,
                    5248,
                    6274,
                    2443,
                    4365,
                    2318,
                    2575,
                    7824,
                    1425,
                    2577,
                    5395,
                    8449,
                    4373,
                    8471,
                    536,
                    1816,
                    1023,
                    4380,
                    1438,
                    4382,
                    3365,
                    3366,
                    3368,
                    2474,
                    558,
                    4655,
                    2483,
                    4660,
                    4917,
                    952,
                    4670,
                    7360,
                    3522,
                    2499,
                    2500,
                    8131,
                    3537,
                    2643,
                    3413,
                    3414,
                    2524,
                    2526,
                    7008,
                    3425,
                    7010,
                    1124,
                    1125,
                    7012,
                    3455,
                    619,
                    4076,
                    7019,
                    8301,
                    1776,
                    2545,
                    2800,
                    5488,
                    1396,
                    7026,
                    5622,
                    7027,
                    6265,
                    1789,
                    1791
                ],
                "List": [
                    4064,
                    3201,
                    6566,
                    4103,
                    522
                ],
                "Tuple": [
                    4353,
                    904,
                    907,
                    539,
                    6207,
                    895
                ],
                "self._data.any_extension_types": [
                    591
                ],
                "self._data": [
                    3424,
                    2468,
                    2795,
                    3243,
                    591,
                    592,
                    594,
                    4723,
                    2485,
                    4825,
                    4602,
                    6558
                ],
                "block.dtype": [
                    592
                ],
                "block": [
                    592
                ],
                "self._data.blocks": [
                    592
                ],
                "self._data.is_mixed_type": [
                    594
                ],
                "max_rows": [
                    2209,
                    732,
                    677,
                    647,
                    649,
                    713,
                    688,
                    819,
                    634,
                    603,
                    636,
                    604
                ],
                "get_option": [
                    677,
                    678,
                    679,
                    680,
                    681,
                    618,
                    682,
                    712,
                    713,
                    714,
                    715,
                    716,
                    663,
                    632,
                    603,
                    636
                ],
                "width": [
                    617,
                    683,
                    685,
                    623,
                    657,
                    691
                ],
                "height": [
                    617
                ],
                "console.get_console_size": [
                    617,
                    683
                ],
                "console": [
                    632,
                    617,
                    683,
                    629
                ],
                "max_columns": [
                    618,
                    622
                ],
                "nb_columns": [
                    619,
                    622,
                    623
                ],
                "ignore_width": [
                    629,
                    623
                ],
                "console.in_interactive_session": [
                    629
                ],
                "console.in_ipython_frontend": [
                    632
                ],
                "buf": [
                    672,
                    641,
                    674,
                    675,
                    705,
                    706,
                    708,
                    2023,
                    2025,
                    2026,
                    2027,
                    2218,
                    653,
                    654,
                    687,
                    2230,
                    696,
                    825
                ],
                "StringIO": [
                    672,
                    641,
                    705
                ],
                "d": [
                    649,
                    645,
                    653
                ],
                "d.iloc": [
                    649
                ],
                "d.to_string": [
                    653
                ],
                "value": [
                    2688,
                    2694,
                    3340,
                    3341,
                    654,
                    655,
                    3346,
                    2709,
                    3349,
                    2711,
                    2714,
                    3357,
                    2718,
                    2719,
                    3359,
                    3360,
                    3362,
                    3241,
                    3242,
                    3243,
                    3369,
                    3370,
                    3372,
                    3374,
                    2737,
                    2738,
                    2739,
                    3377,
                    3378,
                    3380,
                    3383,
                    3384,
                    3385,
                    3386,
                    3388,
                    3389,
                    3390,
                    3391,
                    3392,
                    3394,
                    3397,
                    3398,
                    2761,
                    3402,
                    3405,
                    3406,
                    2767,
                    2769,
                    3409,
                    3410,
                    3413,
                    2775,
                    2777,
                    3417,
                    3419,
                    3929,
                    2655,
                    2658,
                    2786,
                    2660,
                    2788,
                    2663,
                    2796,
                    3949,
                    2670,
                    2682,
                    2684,
                    2685,
                    2687
                ],
                "buf.getvalue": [
                    696,
                    675,
                    708,
                    654
                ],
                "repr_width": [
                    657,
                    655
                ],
                "l": [
                    655
                ],
                "value.split": [
                    655
                ],
                "info_repr_option": [
                    664,
                    663
                ],
                "self._repr_fits_horizontal_": [
                    665
                ],
                "self._repr_fits_vertical_": [
                    665
                ],
                "self._info_repr": [
                    704,
                    673
                ],
                "self.info": [
                    706,
                    674
                ],
                "min_rows": [
                    678,
                    714,
                    689,
                    818,
                    733
                ],
                "max_cols": [
                    2210,
                    679,
                    715,
                    690,
                    820,
                    2230,
                    734
                ],
                "max_colwidth": [
                    680,
                    692,
                    805
                ],
                "show_dimensions": [
                    2211,
                    681,
                    716,
                    821,
                    693,
                    735
                ],
                "_": [
                    2025,
                    3402,
                    683,
                    4337,
                    7354
                ],
                "self.to_string": [
                    686
                ],
                "val": [
                    708,
                    709,
                    710
                ],
                "replace": [
                    3947,
                    708
                ],
                "val.replace": [
                    709
                ],
                "formatter": [
                    740,
                    806,
                    2217,
                    718,
                    2195,
                    825
                ],
                "fmt.DataFrameFormatter": [
                    806,
                    2195,
                    718
                ],
                "fmt": [
                    806,
                    718,
                    752,
                    2192,
                    2195,
                    2132,
                    761,
                    762
                ],
                "formatter.to_html": [
                    2217,
                    740
                ],
                "FilePathOrBuffer": [
                    755,
                    1855
                ],
                "Sequence": [
                    1863,
                    4840,
                    4618,
                    4557,
                    756,
                    758,
                    4154
                ],
                "Union": [
                    6566,
                    6568,
                    6569,
                    4618,
                    4619,
                    4557,
                    4558,
                    758,
                    4154,
                    6207
                ],
                "fmt.FormattersType": [
                    761
                ],
                "fmt.FloatFormatType": [
                    762
                ],
                "option_context": [
                    805
                ],
                "col_space": [
                    809,
                    2198
                ],
                "na_rep": [
                    810,
                    2199
                ],
                "formatters": [
                    2200,
                    811
                ],
                "float_format": [
                    2201,
                    812
                ],
                "sparsify": [
                    2202,
                    813
                ],
                "justify": [
                    2192,
                    2203,
                    814
                ],
                "index_names": [
                    1793,
                    1795,
                    815,
                    1779,
                    1812,
                    1782,
                    1784,
                    1786,
                    1787,
                    2204,
                    1789
                ],
                "header": [
                    816,
                    2205
                ],
                "decimal": [
                    2212,
                    822
                ],
                "line_width": [
                    823
                ],
                "formatter.to_string": [
                    825
                ],
                "encoding": [
                    825,
                    2222
                ],
                "Substitution": [
                    3621,
                    744,
                    2123,
                    4683,
                    5871,
                    752,
                    7219,
                    2132,
                    6008,
                    6649,
                    3611,
                    2014
                ],
                "fmt.common_docstring": [
                    752,
                    2132
                ],
                "fmt.return_docstring": [
                    752,
                    2132
                ],
                "Styler": [
                    842
                ],
                "_shared_docs": [
                    903,
                    6679,
                    6438,
                    4398,
                    4402,
                    4406,
                    4410,
                    5696,
                    6341,
                    844,
                    5726,
                    2015,
                    3552,
                    3937,
                    5872,
                    3956,
                    5878,
                    6009,
                    894,
                    6655
                ],
                "self.columns.is_unique": [
                    896,
                    2499,
                    1396,
                    3414,
                    6265
                ],
                "self._get_item_cache": [
                    898,
                    2629,
                    2502,
                    2764,
                    2609
                ],
                "i": [
                    8448,
                    8449,
                    4098,
                    4099,
                    900,
                    901,
                    1798,
                    1799,
                    3464,
                    1673,
                    3465,
                    4356,
                    4357,
                    7432,
                    4366,
                    4367,
                    7434,
                    4369,
                    7437,
                    7440,
                    7446,
                    7447,
                    2468,
                    2475,
                    5167,
                    1841,
                    5170,
                    2483,
                    2485,
                    8123,
                    8056,
                    1654,
                    1782,
                    1784,
                    1657
                ],
                "self._ixs": [
                    2760,
                    2626,
                    901
                ],
                "Appender": [
                    903,
                    5648,
                    6679,
                    3617,
                    6437,
                    3622,
                    4398,
                    2226,
                    4402,
                    7220,
                    4406,
                    4410,
                    5696,
                    4684,
                    2000,
                    2015,
                    3552,
                    3937,
                    5872,
                    3956,
                    6009,
                    3579,
                    894,
                    6655
                ],
                "Iterable": [
                    4353,
                    904,
                    907,
                    4665,
                    895
                ],
                "Label": [
                    1856,
                    4064,
                    1861,
                    1863,
                    904,
                    4103,
                    4840,
                    907,
                    4158,
                    895
                ],
                "self.items": [
                    4674,
                    905,
                    2317,
                    1423,
                    7354,
                    1405,
                    1407
                ],
                "klass": [
                    953,
                    2810,
                    955,
                    2811
                ],
                "self._constructor_sliced": [
                    8313,
                    2472,
                    2602,
                    7949,
                    8304,
                    953,
                    2810
                ],
                "v": [
                    8511,
                    1798,
                    7354,
                    1673,
                    1837,
                    1423,
                    3313,
                    3314,
                    1431,
                    1625,
                    954,
                    955,
                    1628,
                    1405,
                    8510,
                    1407
                ],
                "self.values": [
                    2439,
                    5228,
                    5229,
                    1134,
                    8469,
                    3542,
                    2583,
                    1304,
                    8054,
                    954,
                    8121,
                    3453,
                    2431
                ],
                "s": [
                    7341,
                    7342,
                    7343,
                    8220,
                    955,
                    956,
                    8509,
                    8510
                ],
                "fields": [
                    1026,
                    1034,
                    1023
                ],
                "arrays.append": [
                    1025,
                    4099,
                    4101,
                    4107,
                    4111,
                    4114,
                    4117,
                    4121,
                    1628
                ],
                "fields.insert": [
                    1026
                ],
                "arrays.extend": [
                    1029
                ],
                "self.iloc": [
                    8448,
                    1029,
                    2694,
                    2670,
                    2775,
                    3223,
                    2682
                ],
                "can_return_named_tuples": [
                    1032,
                    1033
                ],
                "PY37": [
                    1032
                ],
                "name": [
                    1824,
                    1825,
                    4376,
                    4384,
                    4387,
                    4674,
                    7816,
                    1033,
                    1034,
                    4369,
                    1842,
                    4371,
                    1812,
                    1816,
                    1789
                ],
                "itertuple": [
                    1034,
                    1035
                ],
                "collections.namedtuple": [
                    1034
                ],
                "collections": [
                    1034,
                    8508,
                    8445
                ],
                "itertuple._make": [
                    1035
                ],
                "other": [
                    1154,
                    7022,
                    7172,
                    7173,
                    7175,
                    1160,
                    5624,
                    7177,
                    7024,
                    7180,
                    1166,
                    7025,
                    7026,
                    7194,
                    7027,
                    7031,
                    7032,
                    7608,
                    7609,
                    7611,
                    7612,
                    7034,
                    7163,
                    6996,
                    6997,
                    7000,
                    7001,
                    7007,
                    7008,
                    1123,
                    1124,
                    1125,
                    7013,
                    5223,
                    7014,
                    1129,
                    5225,
                    7652,
                    5228,
                    5229,
                    5358,
                    1135,
                    3567,
                    5360,
                    5617,
                    5363,
                    5618,
                    1141,
                    5366,
                    1143,
                    5493,
                    1145,
                    5370,
                    5367,
                    5620,
                    7021,
                    5375
                ],
                "common": [
                    1128,
                    1129,
                    1124,
                    1125
                ],
                "self.columns.union": [
                    1124
                ],
                "other.index": [
                    7008,
                    1124,
                    1125,
                    5358
                ],
                "left": [
                    1152,
                    5220,
                    5221,
                    7620,
                    7621,
                    1128,
                    7624,
                    1130,
                    7628,
                    1133,
                    7638,
                    1143,
                    1146,
                    7612,
                    1150,
                    7615
                ],
                "self.reindex": [
                    1128,
                    2580,
                    7020
                ],
                "right": [
                    7616,
                    5220,
                    5221,
                    7620,
                    7621,
                    7240,
                    1129,
                    7625,
                    1131,
                    7628,
                    7638,
                    7612
                ],
                "other.reindex": [
                    1129,
                    7027,
                    7014
                ],
                "lvals": [
                    1130,
                    1134,
                    1136,
                    1138,
                    1143,
                    1146,
                    1148
                ],
                "left.values": [
                    1130,
                    7638
                ],
                "rvals": [
                    1131,
                    1135,
                    1136,
                    1138,
                    1143,
                    1146,
                    1147,
                    1148
                ],
                "right.values": [
                    1131,
                    7638
                ],
                "np.asarray": [
                    4601,
                    3419,
                    1135
                ],
                "lvals.shape": [
                    1136,
                    1138
                ],
                "rvals.shape": [
                    1136,
                    1138
                ],
                "self._constructor": [
                    2434,
                    4733,
                    2442,
                    7565,
                    2702,
                    2584,
                    7834,
                    7455,
                    6559,
                    5418,
                    7359,
                    3544,
                    4836,
                    8303,
                    2802,
                    1142,
                    8311,
                    5245,
                    1150
                ],
                "np.dot": [
                    1146,
                    1148,
                    1143
                ],
                "left.index": [
                    1152,
                    1146,
                    1150,
                    1143
                ],
                "other.columns": [
                    5370,
                    7026,
                    1143
                ],
                "result": [
                    4608,
                    4611,
                    4612,
                    6659,
                    6661,
                    6664,
                    6666,
                    6672,
                    6673,
                    6674,
                    2580,
                    2581,
                    2584,
                    2587,
                    2595,
                    2596,
                    5158,
                    2600,
                    2601,
                    2602,
                    2603,
                    5162,
                    2606,
                    2607,
                    5166,
                    5167,
                    5169,
                    5170,
                    5171,
                    7750,
                    5193,
                    7755,
                    5196,
                    5197,
                    5199,
                    5200,
                    5201,
                    7760,
                    7762,
                    8306,
                    8310,
                    7799,
                    8311,
                    8313,
                    7803,
                    1148,
                    5245,
                    1149,
                    1150,
                    1152,
                    6272,
                    6273,
                    6274,
                    6276,
                    6271,
                    7805,
                    8318,
                    7890,
                    7910,
                    7911,
                    7912,
                    7913,
                    7921,
                    7931,
                    5372,
                    7936,
                    7937,
                    7940,
                    7941,
                    7942,
                    5386,
                    7946,
                    2316,
                    7949,
                    7950,
                    2321,
                    2322,
                    2324,
                    1304,
                    1305,
                    5415,
                    5418,
                    8316,
                    8056,
                    8057,
                    2434,
                    3461,
                    3463,
                    3465,
                    2442,
                    3467,
                    3468,
                    2446,
                    3470,
                    2472,
                    2478,
                    2479,
                    2486,
                    2489,
                    2491,
                    8123,
                    8124,
                    4548,
                    4551,
                    4553,
                    2022,
                    2024,
                    2027
                ],
                "result.ndim": [
                    1149,
                    8310,
                    7911
                ],
                "self.dot": [
                    1160
                ],
                "T": [
                    7427,
                    7014,
                    3372,
                    1166,
                    6683,
                    3390
                ],
                "self.T.dot": [
                    1166
                ],
                "self.T": [
                    6672,
                    6683,
                    1166
                ],
                "np.transpose": [
                    1166
                ],
                "orient": [
                    1408,
                    1442,
                    1422,
                    1424,
                    1244,
                    1236,
                    1237,
                    1434,
                    1404,
                    1406
                ],
                "orient.lower": [
                    1408,
                    1422,
                    1424,
                    1236,
                    1434,
                    1404,
                    1406
                ],
                "data.values": [
                    7919,
                    7888,
                    7927,
                    1240,
                    7930,
                    1243
                ],
                "_from_nested_dict": [
                    1241
                ],
                "data.keys": [
                    1243
                ],
                "cls": [
                    1600,
                    1250,
                    1680,
                    1850,
                    1595
                ],
                "warnings.warn": [
                    2557,
                    7817,
                    1397
                ],
                "warnings": [
                    2557,
                    7817,
                    1397
                ],
                "into_c": [
                    1409,
                    1423,
                    1431,
                    1403,
                    1405,
                    1437,
                    1407
                ],
                "com.standardize_mapping": [
                    1403
                ],
                "com": [
                    1416,
                    1423,
                    2674,
                    3314,
                    2516,
                    1431,
                    2648,
                    1403,
                    3388,
                    2495
                ],
                "into": [
                    1403,
                    1405
                ],
                "startswith": [
                    1408,
                    1422,
                    1424,
                    1434,
                    1404,
                    1406
                ],
                "v.to_dict": [
                    1405
                ],
                "v.tolist": [
                    1407
                ],
                "self.index.tolist": [
                    1411
                ],
                "self.columns.tolist": [
                    1425,
                    1412,
                    4917
                ],
                "com.maybe_box_datetimelike": [
                    1416,
                    1431,
                    1423
                ],
                "t": [
                    1416,
                    1417,
                    1438,
                    1439
                ],
                "self.itertuples": [
                    1417,
                    1428,
                    1439
                ],
                "rows": [
                    1432,
                    1426
                ],
                "row": [
                    2433,
                    1427,
                    1428,
                    1431,
                    1432
                ],
                "row.items": [
                    1431
                ],
                "self.index.is_unique": [
                    1435
                ],
                "gbq.to_gbq": [
                    1538
                ],
                "gbq": [
                    1538
                ],
                "destination_table": [
                    1540
                ],
                "project_id": [
                    1541
                ],
                "chunksize": [
                    1542
                ],
                "reauth": [
                    1543
                ],
                "if_exists": [
                    1544
                ],
                "auth_local_webserver": [
                    1545
                ],
                "table_schema": [
                    1546
                ],
                "location": [
                    1547
                ],
                "progress_bar": [
                    1548
                ],
                "credentials": [
                    1549
                ],
                "is_iterator": [
                    1593,
                    2530
                ],
                "nrows": [
                    1608,
                    1594,
                    1611
                ],
                "first_row": [
                    1606,
                    1603,
                    1604,
                    1598
                ],
                "first_row.dtype.names": [
                    1603
                ],
                "first_row.dtype": [
                    1603,
                    1604
                ],
                "values.extend": [
                    1611
                ],
                "itertools.islice": [
                    1611
                ],
                "itertools": [
                    1611,
                    1789
                ],
                "arr_columns": [
                    1636,
                    1638,
                    1671,
                    1640,
                    1672,
                    1662,
                    1675,
                    1644,
                    1678,
                    1620,
                    1624,
                    1627,
                    1630
                ],
                "data.items": [
                    1625,
                    8509
                ],
                "arr_columns.append": [
                    1627
                ],
                "reorder_arrays": [
                    1630
                ],
                "coerce_float": [
                    1638
                ],
                "exclude": [
                    1668,
                    1670,
                    1671,
                    3177,
                    3178,
                    1676,
                    3180,
                    1646,
                    1647,
                    1649,
                    3217,
                    3187,
                    3188,
                    3219,
                    1655,
                    3192,
                    3193
                ],
                "result_index": [
                    1665,
                    1667,
                    7652,
                    7653,
                    1678,
                    1651,
                    1657,
                    1659
                ],
                "columns.get_loc": [
                    1654
                ],
                "exclude.add": [
                    1655
                ],
                "index_data": [
                    1667,
                    1662
                ],
                "arr_columns.get_loc": [
                    1672,
                    1662
                ],
                "field": [
                    1662
                ],
                "ensure_index_from_sequences": [
                    1667,
                    4134
                ],
                "exclude.update": [
                    1668
                ],
                "arr_exclude": [
                    1672,
                    1675,
                    1671
                ],
                "x": [
                    4707,
                    7814,
                    5479,
                    1671,
                    5483,
                    6893,
                    6894,
                    6895,
                    3186,
                    3187,
                    7635,
                    7609,
                    7837
                ],
                "to_remove": [
                    4103,
                    1672,
                    1673,
                    4141,
                    4124
                ],
                "col": [
                    8448,
                    8449,
                    1672,
                    4104,
                    4105,
                    4106,
                    4107,
                    2317,
                    4108,
                    4109,
                    4111,
                    4112,
                    4113,
                    4114,
                    4116,
                    4117,
                    5395,
                    4121,
                    4122,
                    4124,
                    7334,
                    5415,
                    7336,
                    8510,
                    8511,
                    2626,
                    4674,
                    2629,
                    2760,
                    2764,
                    2643,
                    2645,
                    2775,
                    2777,
                    2778,
                    5386,
                    4065,
                    4067,
                    4071,
                    4076,
                    5644,
                    4079,
                    4083,
                    5622,
                    5623,
                    5624,
                    5373,
                    5374,
                    5375
                ],
                "arr_columns.drop": [
                    1675
                ],
                "columns.drop": [
                    1676
                ],
                "ABCMultiIndex": [
                    4097,
                    4354,
                    3365,
                    5190,
                    4105,
                    1770,
                    5162,
                    5196,
                    4365,
                    5166,
                    5199,
                    2545,
                    5169,
                    1781,
                    3414,
                    7773,
                    4799
                ],
                "ix_vals": [
                    1776,
                    1772,
                    1774
                ],
                "self.index.values": [
                    1772,
                    1774
                ],
                "_internal_get_values": [
                    1776,
                    1791
                ],
                "c": [
                    1792,
                    3464,
                    3465,
                    2317,
                    4141,
                    4142,
                    1776,
                    7439,
                    7441,
                    7443,
                    7445,
                    7446,
                    7447,
                    7638,
                    1791
                ],
                "count": [
                    4537,
                    1778,
                    4534,
                    1784,
                    1785,
                    4539,
                    4541
                ],
                "self.index.names": [
                    4096,
                    1779,
                    4357
                ],
                "n": [
                    4356,
                    4357,
                    3463,
                    4106,
                    1783,
                    4107,
                    5041,
                    1782,
                    3447,
                    3448,
                    5142,
                    3452
                ],
                "names": [
                    1792,
                    4096,
                    4355,
                    4134,
                    4362,
                    4108,
                    4112,
                    4369,
                    4115,
                    1845,
                    4118,
                    4122,
                    1789,
                    4094
                ],
                "itertools.chain": [
                    1789
                ],
                "index_len": [
                    1841,
                    1810,
                    1795,
                    1814
                ],
                "formats": [
                    1845,
                    1796,
                    1837,
                    1839
                ],
                "dtype_mapping": [
                    1824,
                    1825,
                    1826,
                    1827,
                    1829,
                    1836,
                    1838,
                    1839,
                    1842,
                    1811,
                    1815,
                    1823
                ],
                "index_dtypes": [
                    1811
                ],
                "column_dtypes": [
                    1815
                ],
                "is_dict_like": [
                    1823
                ],
                "formats.append": [
                    1837,
                    1839
                ],
                "v.dtype": [
                    1837
                ],
                "np.dtype": [
                    1838
                ],
                "element": [
                    1841,
                    1842
                ],
                "msg": [
                    7849,
                    7853,
                    2960,
                    2961,
                    1842,
                    1843
                ],
                "np.rec.fromarrays": [
                    1845
                ],
                "np.rec": [
                    1845
                ],
                "np.recarray": [
                    1684
                ],
                "Dict": [
                    1856,
                    1964,
                    1861
                ],
                "datetime.datetime": [
                    1859
                ],
                "datetime": [
                    1859
                ],
                "version": [
                    1953,
                    1957,
                    1965,
                    1968,
                    1970,
                    1951
                ],
                "convert_strl": [
                    1954,
                    1967
                ],
                "kwargs": [
                    6661,
                    6665,
                    3084,
                    3085,
                    6672,
                    2962,
                    2963,
                    2964,
                    3090,
                    3091,
                    3092,
                    3094,
                    6675,
                    6683,
                    6684,
                    1964,
                    1967,
                    7345,
                    1970,
                    3635,
                    3636,
                    3638,
                    3639,
                    3640,
                    1982,
                    2120,
                    2019,
                    2020,
                    2022,
                    3313
                ],
                "Any": [
                    4353,
                    1964
                ],
                "writer": [
                    1984,
                    1973
                ],
                "statawriter": [
                    1973
                ],
                "path": [
                    2115,
                    1998,
                    1974
                ],
                "convert_dates": [
                    1976
                ],
                "byteorder": [
                    1977
                ],
                "time_stamp": [
                    1978
                ],
                "data_label": [
                    1979
                ],
                "write_index": [
                    1980
                ],
                "variable_labels": [
                    1981
                ],
                "writer.write_file": [
                    1984
                ],
                "deprecate_kwarg": [
                    1986,
                    1852,
                    2030
                ],
                "to_feather": [
                    1998
                ],
                "IO": [
                    2017
                ],
                "kwargs.setdefault": [
                    2019,
                    2020
                ],
                "tabulate": [
                    2021,
                    2022
                ],
                "import_optional_dependency": [
                    2021
                ],
                "tabulate.tabulate": [
                    2022
                ],
                "get_filepath_or_buffer": [
                    2025
                ],
                "mode": [
                    2025
                ],
                "buf.writelines": [
                    2027
                ],
                "to_parquet": [
                    2113
                ],
                "engine": [
                    2116,
                    2630,
                    2633,
                    2765,
                    2766
                ],
                "compression": [
                    2117
                ],
                "partition_cols": [
                    2119
                ],
                "fmt._VALID_JUSTIFY_PARAMETERS": [
                    2192
                ],
                "bold_rows": [
                    2207
                ],
                "escape": [
                    2208
                ],
                "table_id": [
                    2213
                ],
                "render_links": [
                    2214
                ],
                "classes": [
                    2219
                ],
                "notebook": [
                    2220
                ],
                "border": [
                    2221
                ],
                "info": [
                    2226,
                    2230
                ],
                "verbose": [
                    2230
                ],
                "memory_usage": [
                    2230
                ],
                "null_counts": [
                    2230
                ],
                "info.__doc__": [
                    2226
                ],
                "c.memory_usage": [
                    2317
                ],
                "deep": [
                    2321,
                    2317
                ],
                "append": [
                    2321,
                    7012,
                    4095
                ],
                "self.index.memory_usage": [
                    2321
                ],
                "nv.validate_transpose": [
                    2423
                ],
                "nv": [
                    7345,
                    2423
                ],
                "args": [
                    6661,
                    6665,
                    6829,
                    6672,
                    7345,
                    3635,
                    6675,
                    2423,
                    6683,
                    6684
                ],
                "dtypes": [
                    3188,
                    3189,
                    2426,
                    2427,
                    2429
                ],
                "self.dtypes": [
                    7813,
                    3209,
                    3215,
                    3221,
                    2426
                ],
                "self._is_homogeneous_type": [
                    2427
                ],
                "is_extension_array_dtype": [
                    5472,
                    3409,
                    2427
                ],
                "arr_type": [
                    2433,
                    2430
                ],
                "dtype.construct_array_type": [
                    2430
                ],
                "new_values": [
                    2433,
                    2435,
                    2468,
                    2439,
                    2471,
                    2441,
                    2473,
                    2443,
                    2476,
                    3541,
                    2583,
                    3544,
                    2585
                ],
                "arr_type._from_sequence": [
                    2433
                ],
                "self.values.T": [
                    2439
                ],
                "new_values.copy": [
                    2441
                ],
                "result.__finalize__": [
                    2587,
                    2446
                ],
                "self.transpose": [
                    2450
                ],
                "axis": [
                    6657,
                    6661,
                    6665,
                    6669,
                    6681,
                    6682,
                    8222,
                    3619,
                    5160,
                    5162,
                    5165,
                    7739,
                    7741,
                    5189,
                    5190,
                    7749,
                    7750,
                    5195,
                    7755,
                    7758,
                    5712,
                    7760,
                    5717,
                    4696,
                    7770,
                    7771,
                    7775,
                    4707,
                    8293,
                    8294,
                    4714,
                    7786,
                    4724,
                    7801,
                    7827,
                    7832,
                    7833,
                    8344,
                    7837,
                    7845,
                    6826,
                    7856,
                    4787,
                    4788,
                    7860,
                    7862,
                    8373,
                    3776,
                    7880,
                    4824,
                    7896,
                    7917,
                    7925,
                    7933,
                    7945,
                    7990,
                    3911,
                    3931,
                    8053,
                    8054,
                    8055,
                    3959,
                    8057,
                    6557,
                    2467,
                    4518,
                    4522,
                    4523,
                    7605,
                    8120,
                    7609,
                    8121,
                    8122,
                    8124,
                    7614,
                    4548,
                    7651,
                    3569
                ],
                "self._data.fast_xs": [
                    2468
                ],
                "new_values.base": [
                    2471
                ],
                "new_values.dtype": [
                    2476
                ],
                "result._set_is_copy": [
                    2606,
                    2478
                ],
                "label": [
                    2489,
                    2483,
                    2486
                ],
                "self._data.iget": [
                    3424,
                    2485
                ],
                "self._box_col_values": [
                    2804,
                    2486
                ],
                "result._set_as_cached": [
                    2489
                ],
                "key": [
                    2562,
                    2691,
                    2564,
                    2569,
                    2570,
                    2699,
                    2700,
                    2702,
                    2575,
                    2704,
                    2578,
                    2711,
                    3365,
                    3366,
                    3368,
                    2603,
                    2609,
                    2738,
                    2739,
                    6587,
                    2494,
                    2495,
                    2497,
                    2499,
                    2501,
                    2502,
                    2505,
                    2512,
                    2513,
                    2516,
                    2517,
                    3413,
                    3415,
                    2648,
                    2521,
                    2651,
                    2525,
                    2526,
                    2657,
                    2530,
                    2531,
                    2532,
                    2658,
                    2659,
                    2660,
                    2663,
                    2670,
                    2800,
                    2546,
                    2674,
                    2675,
                    2677,
                    2679,
                    2680,
                    2556,
                    2685,
                    2687
                ],
                "lib.item_from_zerodim": [
                    2494
                ],
                "lib": [
                    3468,
                    6894,
                    6895,
                    7797,
                    4311,
                    2494
                ],
                "com.apply_if_callable": [
                    2648,
                    3314,
                    2495
                ],
                "is_hashable": [
                    2497
                ],
                "self.columns.nlevels": [
                    2524,
                    2500,
                    4373,
                    4382
                ],
                "self._getitem_multilevel": [
                    2525,
                    2501
                ],
                "indexer": [
                    2690,
                    2694,
                    2570,
                    2571,
                    3502,
                    3506,
                    4795,
                    3522,
                    4802,
                    3526,
                    2505,
                    2506,
                    2509,
                    3540,
                    4820,
                    3542,
                    4825,
                    2651,
                    2652,
                    2526,
                    2655,
                    2528,
                    2527,
                    4831,
                    2532,
                    4708,
                    4709,
                    2535,
                    2536,
                    2538,
                    4728,
                    4719,
                    4724,
                    2680,
                    2682
                ],
                "convert_to_index_sliceable": [
                    2505,
                    2651
                ],
                "self._slice": [
                    2509
                ],
                "self.where": [
                    2513
                ],
                "com.is_bool_indexer": [
                    2674,
                    2516
                ],
                "self._getitem_bool_array": [
                    2517
                ],
                "is_single_key": [
                    2521,
                    2523,
                    2540
                ],
                "self.columns.get_loc": [
                    3366,
                    2575,
                    2800,
                    2643,
                    2526
                ],
                "is_integer": [
                    7352,
                    2527
                ],
                "self.loc._get_listlike_indexer": [
                    2690,
                    2532
                ],
                "self.loc": [
                    2690,
                    4548,
                    2532,
                    2967,
                    2777
                ],
                "np.where": [
                    2536
                ],
                "self._take_with_is_copy": [
                    2538,
                    2571
                ],
                "data.shape": [
                    2545
                ],
                "key.index.equals": [
                    2556
                ],
                "key.index": [
                    2556
                ],
                "check_bool_indexer": [
                    2569,
                    2679
                ],
                "key.nonzero": [
                    2680,
                    2570
                ],
                "loc": [
                    3366,
                    3367,
                    3368,
                    2633,
                    2634,
                    3243,
                    2766,
                    2575,
                    2576,
                    2577,
                    2769,
                    2583,
                    2718,
                    2719
                ],
                "new_columns": [
                    3522,
                    3523,
                    3526,
                    5418,
                    2577,
                    2578,
                    3537,
                    2580,
                    3544,
                    5370,
                    3547,
                    5373
                ],
                "result_columns": [
                    2585,
                    2578,
                    2581
                ],
                "maybe_droplevels": [
                    3368,
                    2578
                ],
                "self._is_mixed_type": [
                    2579,
                    3452
                ],
                "result.columns": [
                    2595,
                    2596,
                    5199,
                    5200,
                    5169,
                    5170,
                    2581
                ],
                "top": [
                    2596,
                    2597,
                    2598,
                    2599
                ],
                "takeable": [
                    2625,
                    2774,
                    2759
                ],
                "series": [
                    5408,
                    5377,
                    2626,
                    2627,
                    5380,
                    2629,
                    5412,
                    2760,
                    2761,
                    2634,
                    2764,
                    5390,
                    2767,
                    5392,
                    2769,
                    5400,
                    5374
                ],
                "series._values": [
                    2769,
                    2634,
                    2627
                ],
                "self.index._engine": [
                    2765,
                    2630
                ],
                "engine.get_loc": [
                    2633,
                    2766
                ],
                "self.index.nlevels": [
                    4349,
                    4098,
                    2637
                ],
                "self.index.get_loc": [
                    2644
                ],
                "self._get_value": [
                    3465,
                    2645
                ],
                "self._setitem_slice": [
                    2655
                ],
                "self._setitem_frame": [
                    2658
                ],
                "self._setitem_array": [
                    2660
                ],
                "self._set_item": [
                    2663
                ],
                "self._check_setitem_copy": [
                    2693,
                    2725,
                    2669,
                    2745,
                    2710,
                    2681
                ],
                "self.iloc._setitem_with_indexer": [
                    2682,
                    2694,
                    2670
                ],
                "value.columns": [
                    3369,
                    2685,
                    2687
                ],
                "k1": [
                    2688,
                    2687
                ],
                "k2": [
                    2688,
                    2687
                ],
                "key.shape": [
                    2700
                ],
                "self.shape": [
                    8469,
                    2700,
                    3197
                ],
                "self._construct_axes_dict": [
                    2702
                ],
                "key.values.size": [
                    2704
                ],
                "key.values": [
                    2704
                ],
                "is_bool_dtype": [
                    2704
                ],
                "self._check_inplace_setting": [
                    2709
                ],
                "self._where": [
                    2711
                ],
                "self._ensure_valid_index": [
                    2737,
                    2714,
                    3241
                ],
                "self._sanitize_column": [
                    3242,
                    2738,
                    2718
                ],
                "NDFrame._iset_item": [
                    2719
                ],
                "NDFrame._set_item": [
                    2739
                ],
                "series._set_value": [
                    2761
                ],
                "validate_numeric_casting": [
                    2767
                ],
                "series.dtype": [
                    5377,
                    2767
                ],
                "self._item_cache.pop": [
                    2778
                ],
                "self._item_cache": [
                    2778
                ],
                "self._data.reindex_axis": [
                    2795
                ],
                "value.index.copy": [
                    2796
                ],
                "value.index": [
                    3349,
                    2796,
                    3340
                ],
                "np.nan": [
                    4321,
                    7558,
                    7656,
                    3498,
                    2796,
                    3629,
                    7439,
                    4337,
                    8056,
                    8123
                ],
                "items": [
                    2800,
                    2802,
                    2811,
                    2804
                ],
                "values.ndim": [
                    2801,
                    7867
                ],
                "values.T": [
                    2802
                ],
                "inplace": [
                    3083,
                    2958,
                    3094,
                    2973,
                    3619,
                    4517,
                    4390,
                    4785,
                    4149,
                    3780,
                    4550,
                    3913,
                    4301,
                    4302,
                    4815,
                    4054,
                    4695,
                    4088,
                    3932,
                    4833,
                    3950,
                    4597,
                    4600,
                    4730
                ],
                "validate_bool_kwarg": [
                    4517,
                    3083,
                    4301,
                    2958,
                    4785,
                    4597,
                    4054,
                    4695
                ],
                "expr": [
                    2960,
                    2964,
                    3094,
                    2959
                ],
                "kwargs.pop": [
                    3084,
                    3085,
                    2962,
                    3638,
                    3639
                ],
                "res": [
                    7201,
                    7874,
                    7875,
                    7204,
                    7876,
                    7877,
                    7878,
                    2964,
                    2967,
                    2971
                ],
                "self.eval": [
                    2964
                ],
                "new_data": [
                    4605,
                    2967,
                    2971,
                    2974,
                    6558,
                    2976,
                    6559,
                    8508,
                    8511,
                    8512,
                    4825,
                    4828,
                    4831,
                    4834,
                    4836,
                    5225,
                    5229,
                    5231,
                    4723,
                    4728,
                    4602,
                    4731,
                    4733,
                    4606
                ],
                "self._update_inplace": [
                    4834,
                    4551,
                    2974,
                    4731,
                    4606
                ],
                "resolvers": [
                    3089,
                    3084,
                    3092,
                    3086
                ],
                "index_resolvers": [
                    3089,
                    3087
                ],
                "self._get_index_resolvers": [
                    3087
                ],
                "column_resolvers": [
                    3088,
                    3089
                ],
                "self._get_cleaned_column_resolvers": [
                    3088
                ],
                "kwargs.get": [
                    3092
                ],
                "_eval": [
                    3094
                ],
                "include": [
                    3175,
                    3176,
                    3211,
                    3180,
                    3213,
                    3186,
                    3188,
                    3192,
                    3193
                ],
                "selection": [
                    3180,
                    3182
                ],
                "infer_dtype_from_object": [
                    3186,
                    3187
                ],
                "invalidate_string_dtypes": [
                    3189
                ],
                "include.isdisjoint": [
                    3192
                ],
                "keep_these": [
                    3223,
                    3197,
                    3221,
                    3215
                ],
                "np.full": [
                    3197
                ],
                "extracted_dtypes": [
                    3202,
                    3207
                ],
                "unique_dtype": [
                    3203,
                    3204,
                    3205
                ],
                "unique_dtypes": [
                    3209,
                    3219,
                    3204,
                    3213
                ],
                "unique_dtype.type": [
                    3205
                ],
                "dtypes_set": [
                    3205
                ],
                "self.dtypes.unique": [
                    3209
                ],
                "included_dtypes": [
                    3212,
                    3215
                ],
                "extract_unique_dtypes_from_dtypes_set": [
                    3218,
                    3212
                ],
                "self.dtypes.isin": [
                    3221,
                    3215
                ],
                "excluded_dtypes": [
                    3218,
                    3221
                ],
                "keep_these.values": [
                    3223
                ],
                "column": [
                    6272,
                    3242,
                    3243,
                    6263,
                    6271
                ],
                "self._data.insert": [
                    3243
                ],
                "allow_duplicates": [
                    3243
                ],
                "self.copy": [
                    5158,
                    5193,
                    3311,
                    4305,
                    4818,
                    4595,
                    5364,
                    8371,
                    8342,
                    4091
                ],
                "kwargs.items": [
                    3313
                ],
                "value.index.equals": [
                    3340
                ],
                "value._values.copy": [
                    3341
                ],
                "value._values": [
                    3341
                ],
                "_values": [
                    5624,
                    4121,
                    3346,
                    5623
                ],
                "value.reindex": [
                    3346,
                    3370
                ],
                "value.index.is_unique": [
                    3349
                ],
                "reindexer": [
                    3360,
                    3372
                ],
                "cols": [
                    7552,
                    7429,
                    7551,
                    3368,
                    3369,
                    3370,
                    7561,
                    7565,
                    8301,
                    8303,
                    7824,
                    7825,
                    8304,
                    7416,
                    7417,
                    7455
                ],
                "cols.equals": [
                    3369
                ],
                "value.copy": [
                    3392,
                    3377,
                    3394,
                    3390
                ],
                "sanitize_index": [
                    3378,
                    3383
                ],
                "is_sequence": [
                    3380,
                    4700
                ],
                "maybe_convert_platform": [
                    3386
                ],
                "com.asarray_tuplesafe": [
                    3388
                ],
                "value.ndim": [
                    3413,
                    3389
                ],
                "is_object_dtype": [
                    7933,
                    3467,
                    3397,
                    7937
                ],
                "value.dtype": [
                    3397
                ],
                "maybe_infer_to_datetimelike": [
                    3398
                ],
                "infer_dtype": [
                    3402,
                    3406
                ],
                "infer_dtype_from_scalar": [
                    3402
                ],
                "maybe_cast_to_datetime": [
                    3406
                ],
                "broadcast": [
                    3413
                ],
                "existing_piece": [
                    3416,
                    3417,
                    3415
                ],
                "np.tile": [
                    3417
                ],
                "existing_piece.columns": [
                    3417
                ],
                "np.atleast_2d": [
                    3419
                ],
                "item": [
                    3424,
                    3425
                ],
                "idx": [
                    3424,
                    3425,
                    7552,
                    7565,
                    7417,
                    7455
                ],
                "row_labels": [
                    3464,
                    3454,
                    3447
                ],
                "col_labels": [
                    3448,
                    3464,
                    3455
                ],
                "thresh": [
                    4536,
                    4537,
                    3451,
                    3452
                ],
                "ridx": [
                    3456,
                    3460,
                    3454
                ],
                "self.index.get_indexer": [
                    3454
                ],
                "cidx": [
                    3458,
                    3460,
                    3455
                ],
                "self.columns.get_indexer": [
                    7026,
                    3455
                ],
                "flat_index": [
                    3460,
                    3461
                ],
                "values.flat": [
                    3461
                ],
                "np.empty": [
                    4320,
                    7557,
                    7430,
                    3463
                ],
                "r": [
                    3464,
                    3465
                ],
                "lib.maybe_convert_objects": [
                    3468,
                    4311
                ],
                "frame": [
                    3476,
                    3480,
                    4121,
                    3486,
                    3490,
                    7212,
                    4142,
                    7214,
                    4147,
                    4150,
                    7744,
                    7746,
                    7749,
                    7750,
                    7752,
                    7755,
                    7758,
                    7760,
                    7766,
                    7768,
                    7770,
                    7771,
                    7778,
                    7781,
                    7784,
                    4089,
                    4091
                ],
                "axes": [
                    3536,
                    3537,
                    3635,
                    3636,
                    3478,
                    3484
                ],
                "frame._reindex_columns": [
                    3480
                ],
                "method": [
                    7424,
                    7618,
                    3523,
                    7428,
                    7609,
                    3503,
                    7632,
                    3953,
                    7635,
                    3573,
                    7452,
                    3481,
                    3930,
                    7643,
                    7420,
                    7422,
                    3487
                ],
                "level": [
                    4367,
                    3481,
                    3487,
                    3503,
                    4793,
                    6202,
                    6203,
                    4796,
                    6205,
                    7740,
                    7741,
                    3523,
                    3779,
                    6339,
                    3914,
                    5710,
                    5718,
                    7791,
                    7792,
                    3570,
                    7794,
                    7795,
                    7796,
                    4345,
                    4346,
                    4347,
                    4348,
                    4349,
                    4350
                ],
                "limit": [
                    3523,
                    3503,
                    3951,
                    3574,
                    3481,
                    3933,
                    3487
                ],
                "tolerance": [
                    3481,
                    3523,
                    3503,
                    3487
                ],
                "frame._reindex_index": [
                    3486
                ],
                "new_index": [
                    4344,
                    4389,
                    5418,
                    3502,
                    3503,
                    3536,
                    5361,
                    3506,
                    5363,
                    3544,
                    3547,
                    4350
                ],
                "self.index.reindex": [
                    3536,
                    3502
                ],
                "self._reindex_with_indexers": [
                    3505,
                    3546,
                    3525
                ],
                "self.columns.reindex": [
                    3537,
                    3522
                ],
                "row_indexer": [
                    3536,
                    3539,
                    3540,
                    3547
                ],
                "col_indexer": [
                    3537,
                    3539,
                    3540,
                    3547
                ],
                "algorithms.take_2d_multi": [
                    3541
                ],
                "algorithms": [
                    4649,
                    5041,
                    8469,
                    5141,
                    3541
                ],
                "align": [
                    3566
                ],
                "join": [
                    3568,
                    5612,
                    6272
                ],
                "fill_axis": [
                    3575
                ],
                "broadcast_axis": [
                    3576
                ],
                "Axis": [
                    3794,
                    3618,
                    8321,
                    8351
                ],
                "set_axis": [
                    3619
                ],
                "labels": [
                    7949,
                    7828,
                    7833,
                    3619,
                    4649,
                    4652,
                    4788,
                    4792,
                    4795,
                    4799,
                    3775,
                    4675,
                    4803,
                    4677,
                    4812,
                    4813,
                    4821,
                    4314,
                    4315,
                    4323,
                    7917,
                    7925
                ],
                "NDFrame.set_axis.__doc__": [
                    3617
                ],
                "NDFrame.set_axis": [
                    3617
                ],
                "validate_axis_style_args": [
                    3635
                ],
                "kwargs.update": [
                    3636
                ],
                "reindex": [
                    3640
                ],
                "NDFrame.reindex.__doc__": [
                    3622
                ],
                "NDFrame.reindex": [
                    3622
                ],
                "rewrite_axis_style_signature": [
                    3784,
                    3623
                ],
                "drop": [
                    4352,
                    7648,
                    4123,
                    3774
                ],
                "errors": [
                    5629,
                    3915,
                    3781,
                    5614
                ],
                "Renamer": [
                    3792,
                    3793,
                    3790
                ],
                "Level": [
                    3797
                ],
                "rename": [
                    3907
                ],
                "mapper": [
                    3908
                ],
                "fillna": [
                    3928
                ],
                "downcast": [
                    3934
                ],
                "doc": [
                    3918
                ],
                "NDFrame.fillna": [
                    3918
                ],
                "to_replace": [
                    3948
                ],
                "regex": [
                    3952
                ],
                "shift": [
                    3958
                ],
                "periods": [
                    6558,
                    3959
                ],
                "freq": [
                    8375,
                    8346,
                    3959
                ],
                "keys": [
                    4065,
                    4707,
                    4708,
                    4104,
                    4055,
                    4056
                ],
                "err_msg": [
                    4072,
                    4058,
                    4079
                ],
                "missing": [
                    4064,
                    4083,
                    4085,
                    4086,
                    4382,
                    4383
                ],
                "ABCIndexClass": [
                    5480,
                    4067,
                    5468,
                    4109
                ],
                "ABCSeries": [
                    5480,
                    4067,
                    5468,
                    4109
                ],
                "abc.Iterator": [
                    4067,
                    4116
                ],
                "found": [
                    4082,
                    4076
                ],
                "missing.append": [
                    4083
                ],
                "self.index._get_level_values": [
                    4099
                ],
                "col.nlevels": [
                    4106
                ],
                "col._get_level_values": [
                    4107
                ],
                "names.extend": [
                    4108
                ],
                "col.names": [
                    4108
                ],
                "names.append": [
                    4112,
                    4122,
                    4115,
                    4118
                ],
                "col.name": [
                    4112
                ],
                "to_remove.append": [
                    4124
                ],
                "verify_integrity": [
                    4136,
                    7038
                ],
                "index.is_unique": [
                    4136
                ],
                "duplicates": [
                    4137,
                    4138
                ],
                "unique": [
                    4137
                ],
                "index.duplicated": [
                    4137
                ],
                "index._cleanup": [
                    4145
                ],
                "frame.index": [
                    4147
                ],
                "Hashable": [
                    4557,
                    4154,
                    4618,
                    4157
                ],
                "new_obj": [
                    4387,
                    4389,
                    4391,
                    4303,
                    4305,
                    8371,
                    8342,
                    4344,
                    8377,
                    8378,
                    8348,
                    8349
                ],
                "index._values": [
                    4308
                ],
                "PeriodIndex": [
                    4309
                ],
                "DatetimeIndex": [
                    4309
                ],
                "np.object_": [
                    4310
                ],
                "mask.all": [
                    5641,
                    4319
                ],
                "values.fill": [
                    4321
                ],
                "values.take": [
                    4323
                ],
                "values_type": [
                    4330,
                    4339,
                    4340,
                    4333
                ],
                "values_dtype": [
                    4331,
                    4340
                ],
                "DatetimeLikeArray": [
                    4339,
                    4333
                ],
                "values._data": [
                    4334
                ],
                "maybe_upcast_putmask": [
                    4337
                ],
                "self.index._get_level_number": [
                    4348
                ],
                "lev": [
                    4386,
                    4348,
                    4366
                ],
                "self.index.droplevel": [
                    4350
                ],
                "to_insert": [
                    4353,
                    4363,
                    4366,
                    4359
                ],
                "self.index.levels": [
                    4359
                ],
                "self.index.codes": [
                    4359
                ],
                "default": [
                    4361,
                    4362
                ],
                "self.index.name": [
                    4362,
                    7007
                ],
                "multi_col": [
                    4370,
                    4365
                ],
                "lab": [
                    4386,
                    4366
                ],
                "col_name": [
                    4378,
                    4371,
                    4373,
                    4381
                ],
                "col_fill": [
                    4378,
                    4372,
                    4381,
                    4383
                ],
                "lev_num": [
                    4380,
                    4381
                ],
                "self.columns._get_level_number": [
                    4380
                ],
                "col_level": [
                    4380,
                    6461
                ],
                "name_lst": [
                    4384,
                    4381,
                    4382,
                    4383
                ],
                "level_values": [
                    4386,
                    4387
                ],
                "_maybe_casted_values": [
                    4386
                ],
                "new_obj.insert": [
                    4387
                ],
                "new_obj.index": [
                    4389
                ],
                "isna": [
                    5380,
                    5381,
                    5636,
                    5479,
                    4400,
                    5627
                ],
                "isnull": [
                    4404
                ],
                "notna": [
                    7555,
                    7781,
                    5638,
                    7941,
                    7784,
                    7755,
                    7758,
                    4408,
                    5630,
                    5631
                ],
                "notnull": [
                    4412
                ],
                "self._get_axis_number": [
                    6657,
                    5189,
                    8293,
                    5160,
                    4522,
                    7832,
                    5712,
                    4787,
                    7605,
                    8053,
                    8120,
                    4696,
                    6681,
                    7739
                ],
                "agg_axis": [
                    4523,
                    4527,
                    4532,
                    4534,
                    7799,
                    7771,
                    4539
                ],
                "agg_obj": [
                    4539,
                    4532,
                    4525,
                    4534
                ],
                "subset": [
                    4654,
                    4526,
                    4528,
                    4655,
                    4657,
                    4531,
                    4658,
                    4659,
                    4660,
                    4919,
                    4662,
                    4665,
                    4916,
                    4917,
                    6581,
                    6582,
                    4670,
                    4927,
                    6583,
                    6584,
                    4674,
                    6587,
                    4598
                ],
                "ax": [
                    4528,
                    4527
                ],
                "self._get_axis": [
                    5190,
                    4527,
                    4788,
                    8055,
                    8122
                ],
                "indices": [
                    4528,
                    4529,
                    4532,
                    8054,
                    8056,
                    8121,
                    8123
                ],
                "ax.get_indexer_for": [
                    4528
                ],
                "check": [
                    4529,
                    4530,
                    4531
                ],
                "check.any": [
                    4530
                ],
                "np.compress": [
                    4531
                ],
                "self.take": [
                    4532
                ],
                "agg_obj.count": [
                    4534
                ],
                "how": [
                    4544,
                    7200,
                    6661,
                    7207,
                    8346,
                    7241,
                    7182,
                    7214,
                    6672,
                    6674,
                    4538,
                    7163,
                    4540,
                    4543
                ],
                "agg_obj._get_axis": [
                    4539
                ],
                "self.empty": [
                    4594,
                    4645,
                    5366
                ],
                "duplicated": [
                    4608,
                    4601,
                    4598
                ],
                "self.duplicated": [
                    4598
                ],
                "keep": [
                    4678,
                    5041,
                    4598,
                    5142
                ],
                "inds": [
                    4601,
                    4602,
                    4605
                ],
                "nonzero": [
                    4601
                ],
                "self._data.take": [
                    4825,
                    4602,
                    4723
                ],
                "ignore_index": [
                    4610,
                    6998,
                    4727,
                    7001,
                    4604,
                    7037,
                    4830
                ],
                "new_data.axes": [
                    4728,
                    4828,
                    4605,
                    4831
                ],
                "result.index": [
                    6273,
                    4611,
                    5196,
                    5197,
                    5166,
                    5167
                ],
                "shape": [
                    4649,
                    4675,
                    4652,
                    4677
                ],
                "algorithms.factorize": [
                    4649
                ],
                "vals": [
                    4674,
                    4675,
                    7334,
                    7336,
                    4650,
                    7338
                ],
                "_SIZE_HINT_LIMIT": [
                    4650
                ],
                "labels.astype": [
                    4652
                ],
                "np.iterable": [
                    4657
                ],
                "cast": [
                    4665
                ],
                "diff": [
                    4672,
                    4670,
                    4671
                ],
                "difference": [
                    4670
                ],
                "diff.empty": [
                    4671
                ],
                "col.values": [
                    4674
                ],
                "f": [
                    4675,
                    7908,
                    7921,
                    7890,
                    7931,
                    8222
                ],
                "ids": [
                    4677,
                    4678
                ],
                "get_group_index": [
                    4677
                ],
                "duplicated_int64": [
                    4678
                ],
                "by": [
                    4704,
                    4707,
                    4713,
                    4714,
                    5710,
                    5716,
                    4698,
                    4699,
                    4700,
                    4702
                ],
                "ascending": [
                    4796,
                    4708,
                    4804,
                    4716,
                    4717,
                    4812,
                    4813,
                    4720,
                    4821,
                    4922,
                    4700,
                    4702
                ],
                "self._get_label_or_level_values": [
                    4714,
                    4707
                ],
                "lexsort_indexer": [
                    4802,
                    4708
                ],
                "na_position": [
                    4720,
                    4821,
                    4708,
                    4805
                ],
                "ensure_platform_int": [
                    4709
                ],
                "nargsort": [
                    4820,
                    4719
                ],
                "kind": [
                    4720,
                    4821
                ],
                "self._get_block_manager_axis": [
                    4824,
                    4724,
                    6557
                ],
                "__finalize__": [
                    4836,
                    4733
                ],
                "NDFrame.sort_values.__doc__": [
                    4684
                ],
                "NDFrame.sort_values": [
                    4684
                ],
                "labels._sort_levels_monotonic": [
                    4792
                ],
                "new_axis": [
                    4795
                ],
                "labels.sortlevel": [
                    4795
                ],
                "sort_remaining": [
                    4796
                ],
                "labels._get_codes_for_sorting": [
                    4803
                ],
                "labels.is_monotonic_increasing": [
                    4812
                ],
                "labels.is_monotonic_decreasing": [
                    4813
                ],
                "baxis": [
                    4824,
                    4825,
                    4828
                ],
                "_sort_levels_monotonic": [
                    4828
                ],
                "counts": [
                    4928,
                    4929,
                    4932,
                    7799,
                    7759,
                    7760,
                    7797,
                    4919,
                    4922,
                    4924
                ],
                "size": [
                    4919
                ],
                "self.groupby": [
                    4919
                ],
                "sort": [
                    7202,
                    7207,
                    7247,
                    7186,
                    5720,
                    4921,
                    7163,
                    7039
                ],
                "counts.sort_values": [
                    4922
                ],
                "normalize": [
                    4923
                ],
                "counts.sum": [
                    4924
                ],
                "counts.index": [
                    4928,
                    4929
                ],
                "MultiIndex.from_arrays": [
                    4928
                ],
                "MultiIndex": [
                    4928
                ],
                "counts.index.name": [
                    4929
                ],
                "nlargest": [
                    5041
                ],
                "algorithms.SelectNFrame": [
                    5041,
                    5141
                ],
                "nsmallest": [
                    5141
                ],
                "result._get_axis": [
                    5162
                ],
                "result.index.swaplevel": [
                    5167
                ],
                "j": [
                    7433,
                    7434,
                    7437,
                    5167,
                    7440,
                    5170,
                    7446,
                    7447
                ],
                "result.columns.swaplevel": [
                    5170
                ],
                "result.index.reorder_levels": [
                    5197
                ],
                "order": [
                    5200,
                    5197
                ],
                "result.columns.reorder_levels": [
                    5200
                ],
                "_arith_op": [
                    5228,
                    5225,
                    5212
                ],
                "func": [
                    5412,
                    5221,
                    6661,
                    5223,
                    6665,
                    6825,
                    5229,
                    6894,
                    6895,
                    6683,
                    5212,
                    6684
                ],
                "ops.fill_binop": [
                    5220
                ],
                "ops": [
                    5220,
                    5223,
                    5225,
                    8502,
                    8503
                ],
                "ops.should_series_dispatch": [
                    5223
                ],
                "ops.dispatch_to_series": [
                    5225
                ],
                "np.errstate": [
                    7920,
                    5626,
                    5227
                ],
                "res_values": [
                    5228,
                    5229
                ],
                "other.values": [
                    5228,
                    5229
                ],
                "dispatch_fill_zeros": [
                    5229
                ],
                "out": [
                    5248,
                    5249,
                    7878,
                    7879,
                    7883,
                    7884,
                    5245
                ],
                "out.columns": [
                    5248
                ],
                "other_idxlen": [
                    5366,
                    5358
                ],
                "this": [
                    7652,
                    5638,
                    5386,
                    5644,
                    5360,
                    5361,
                    7606,
                    5623,
                    7609,
                    5370,
                    5627,
                    7612,
                    5374,
                    5631
                ],
                "self.align": [
                    5360
                ],
                "this.index": [
                    5361
                ],
                "other.empty": [
                    5363
                ],
                "other.copy": [
                    5367
                ],
                "this.columns.union": [
                    5370
                ],
                "this.columns": [
                    5370
                ],
                "do_fill": [
                    5371,
                    5389
                ],
                "otherSeries": [
                    5378,
                    5410,
                    5412,
                    5381,
                    5391,
                    5393,
                    5375
                ],
                "this_dtype": [
                    5377,
                    5413,
                    5406,
                    5407
                ],
                "other_dtype": [
                    5409,
                    5378,
                    5398,
                    5406
                ],
                "otherSeries.dtype": [
                    5378
                ],
                "this_mask": [
                    5392,
                    5380
                ],
                "other_mask": [
                    5385,
                    5381,
                    5393
                ],
                "overwrite": [
                    5385,
                    5635
                ],
                "other_mask.all": [
                    5385
                ],
                "series.copy": [
                    5390
                ],
                "otherSeries.copy": [
                    5391
                ],
                "new_dtype": [
                    5408,
                    5409,
                    5410,
                    5398,
                    5400,
                    5406,
                    5407
                ],
                "series.astype": [
                    5400,
                    5408
                ],
                "find_common_type": [
                    5406
                ],
                "is_dtype_equal": [
                    5409,
                    5407
                ],
                "otherSeries.astype": [
                    5410
                ],
                "maybe_downcast_to_dtype": [
                    5413
                ],
                "arr._values": [
                    5469
                ],
                "needs_i8_conversion": [
                    7880,
                    5471
                ],
                "arr.dtype": [
                    5472
                ],
                "arr.asi8": [
                    5473
                ],
                "arr.view": [
                    5475
                ],
                "mask._values": [
                    5481
                ],
                "x_values": [
                    5483,
                    5491
                ],
                "extract_values": [
                    5483,
                    5484
                ],
                "y_values": [
                    5489,
                    5491,
                    5484
                ],
                "y": [
                    5488,
                    5484
                ],
                "y.name": [
                    5488
                ],
                "expressions.where": [
                    5491,
                    5644
                ],
                "expressions": [
                    5491,
                    5644
                ],
                "self.combine": [
                    5493
                ],
                "combiner": [
                    5493
                ],
                "other.reindex_like": [
                    5620
                ],
                "that": [
                    5636,
                    5644,
                    5624,
                    5627,
                    5630
                ],
                "filter_func": [
                    5625,
                    5627
                ],
                "mask_this": [
                    5632,
                    5630
                ],
                "mask_that": [
                    5632,
                    5631
                ],
                "DataFrameGroupBy": [
                    5714
                ],
                "as_index": [
                    5719
                ],
                "group_keys": [
                    5721
                ],
                "squeeze": [
                    5722
                ],
                "observed": [
                    6034,
                    5723
                ],
                "pivot": [
                    5876
                ],
                "pivot_table": [
                    6024
                ],
                "aggfunc": [
                    6029
                ],
                "margins": [
                    6031
                ],
                "dropna": [
                    6032,
                    7990,
                    6203,
                    8220,
                    6205
                ],
                "margins_name": [
                    6033
                ],
                "stack_multiple": [
                    6203
                ],
                "stack": [
                    6205
                ],
                "is_scalar": [
                    6263
                ],
                "df": [
                    6272,
                    7874,
                    7334,
                    7878,
                    7879,
                    7880,
                    7883,
                    7196,
                    7857,
                    7859,
                    7861,
                    6268,
                    6270,
                    6271
                ],
                "self.reset_index": [
                    6268
                ],
                "explode": [
                    6271
                ],
                "df.drop": [
                    6272
                ],
                "self.index.take": [
                    6273
                ],
                "result.reindex": [
                    6274
                ],
                "unstack": [
                    6339
                ],
                "melt": [
                    6455
                ],
                "id_vars": [
                    6457
                ],
                "value_vars": [
                    6458
                ],
                "var_name": [
                    6459
                ],
                "value_name": [
                    6460
                ],
                "bm_axis": [
                    6557,
                    6558
                ],
                "self._data.diff": [
                    6558
                ],
                "ABCDataFrame": [
                    6568,
                    6569
                ],
                "subset.ndim": [
                    6583
                ],
                "_agg_summary_and_see_also_doc": [
                    6650,
                    6589
                ],
                "dedent": [
                    6613,
                    6589
                ],
                "_agg_examples_doc": [
                    6651,
                    6613
                ],
                "self._aggregate": [
                    6661
                ],
                "self.apply": [
                    6665,
                    6897,
                    7990
                ],
                "self.T._aggregate": [
                    6672
                ],
                "arg": [
                    6672,
                    6675
                ],
                "result.T": [
                    6673,
                    7803,
                    8316
                ],
                "_aggregate": [
                    6675
                ],
                "agg": [
                    6677
                ],
                "aggregate": [
                    6677
                ],
                "self.T.transform": [
                    6683
                ],
                "transform": [
                    6684
                ],
                "op": [
                    7837,
                    6823,
                    6832,
                    7869,
                    7870
                ],
                "frame_apply": [
                    7907,
                    6823
                ],
                "raw": [
                    6827
                ],
                "result_type": [
                    6828
                ],
                "kwds": [
                    7870,
                    7837,
                    6830,
                    7869
                ],
                "op.get_result": [
                    6832
                ],
                "x.empty": [
                    6893
                ],
                "lib.map_infer": [
                    6894,
                    6895
                ],
                "x.astype": [
                    6895
                ],
                "infer": [
                    6897
                ],
                "other.name": [
                    7001,
                    7175,
                    7173,
                    7007
                ],
                "idx_diff": [
                    7008,
                    7010,
                    7012,
                    7653,
                    7655,
                    7656
                ],
                "other.index.difference": [
                    7008
                ],
                "combined_columns": [
                    7010,
                    7012,
                    7014,
                    7019,
                    7020
                ],
                "self.columns.append": [
                    7010
                ],
                "self.columns.astype": [
                    7012
                ],
                "rename_axis": [
                    7014
                ],
                "T.infer_objects": [
                    7014
                ],
                "to_frame": [
                    7014
                ],
                "index.names": [
                    7017
                ],
                "self.columns.equals": [
                    7019
                ],
                "to_concat": [
                    7032,
                    7034,
                    7036
                ],
                "concat": [
                    7360,
                    7201,
                    7206,
                    7035,
                    8446
                ],
                "self._join_compat": [
                    7162
                ],
                "on": [
                    7242,
                    7181,
                    7183,
                    7189,
                    7163
                ],
                "lsuffix": [
                    7185,
                    7163
                ],
                "rsuffix": [
                    7185,
                    7163
                ],
                "merge": [
                    7178,
                    7213,
                    7238
                ],
                "frames": [
                    7202,
                    7207,
                    7210,
                    7212,
                    7194,
                    7196
                ],
                "can_concat": [
                    7196,
                    7199
                ],
                "df.index.is_unique": [
                    7196
                ],
                "df.index": [
                    7196
                ],
                "res.reindex": [
                    7204
                ],
                "joined": [
                    7217,
                    7210,
                    7213,
                    7214
                ],
                "left_on": [
                    7243
                ],
                "right_on": [
                    7244
                ],
                "left_index": [
                    7245
                ],
                "right_index": [
                    7246
                ],
                "suffixes": [
                    7248
                ],
                "indicator": [
                    7250
                ],
                "validate": [
                    7251
                ],
                "df.items": [
                    7334
                ],
                "_series_round": [
                    7336,
                    7354
                ],
                "decimals": [
                    7336,
                    7342,
                    7347,
                    7348,
                    7349,
                    7351,
                    7352,
                    7354
                ],
                "is_integer_dtype": [
                    7341
                ],
                "is_float_dtype": [
                    7341
                ],
                "s.round": [
                    7342
                ],
                "nv.validate_round": [
                    7345
                ],
                "decimals.index.is_unique": [
                    7349
                ],
                "decimals.index": [
                    7349
                ],
                "new_cols": [
                    7360,
                    7354,
                    7358,
                    7351
                ],
                "_dict_round": [
                    7351
                ],
                "numeric_df": [
                    7553,
                    7415,
                    7416,
                    7418,
                    7550,
                    7551
                ],
                "self._get_numeric_data": [
                    7744,
                    7841,
                    8292,
                    7766,
                    7606,
                    8217,
                    7415,
                    7550
                ],
                "numeric_df.columns": [
                    7416,
                    7551
                ],
                "cols.copy": [
                    7552,
                    7417
                ],
                "mat": [
                    7553,
                    7427,
                    7555,
                    7556,
                    7557,
                    7431,
                    7432,
                    7433,
                    7560,
                    7563,
                    7418,
                    7421,
                    7423
                ],
                "numeric_df.values": [
                    7553,
                    7418
                ],
                "correl": [
                    7455,
                    7653,
                    7430,
                    7656,
                    7658,
                    7630,
                    7637,
                    7446,
                    7447,
                    7421,
                    7423
                ],
                "libalgos.nancorr": [
                    7563,
                    7421
                ],
                "libalgos": [
                    7563,
                    7421,
                    7423
                ],
                "ensure_float64": [
                    7427,
                    7563,
                    7421,
                    7423
                ],
                "min_periods": [
                    7425,
                    7426,
                    7556,
                    7563,
                    7438,
                    7421,
                    7423
                ],
                "libalgos.nancorr_spearman": [
                    7423
                ],
                "corrf": [
                    7443,
                    7428,
                    7445
                ],
                "nanops.get_corr_func": [
                    7428
                ],
                "nanops": [
                    8121,
                    7635,
                    7428,
                    8054
                ],
                "K": [
                    7429,
                    7430
                ],
                "np.isfinite": [
                    7431
                ],
                "ac": [
                    7432,
                    7443,
                    7445
                ],
                "bc": [
                    7433,
                    7443,
                    7445
                ],
                "valid": [
                    7442,
                    7443,
                    7437,
                    7438
                ],
                "valid.sum": [
                    7438
                ],
                "valid.all": [
                    7442
                ],
                "baseCov": [
                    7557,
                    7558,
                    7560,
                    7561,
                    7563,
                    7565
                ],
                "mat.shape": [
                    7557
                ],
                "baseCov.fill": [
                    7558
                ],
                "np.cov": [
                    7560
                ],
                "mat.T": [
                    7560
                ],
                "baseCov.reshape": [
                    7561
                ],
                "this.apply": [
                    7609
                ],
                "other.corr": [
                    7609
                ],
                "other._get_numeric_data": [
                    7611
                ],
                "this.align": [
                    7612
                ],
                "left.T": [
                    7615
                ],
                "right.T": [
                    7616
                ],
                "ldem": [
                    7624,
                    7627
                ],
                "left.mean": [
                    7624
                ],
                "rdem": [
                    7625,
                    7627
                ],
                "right.mean": [
                    7625
                ],
                "num": [
                    7627,
                    7630
                ],
                "dom": [
                    7628,
                    7630
                ],
                "left.count": [
                    7628
                ],
                "left.std": [
                    7628
                ],
                "right.std": [
                    7628
                ],
                "nanops.nancorr": [
                    7635
                ],
                "left.values.T": [
                    7638
                ],
                "right.values.T": [
                    7638
                ],
                "left.columns": [
                    7638
                ],
                "raxis": [
                    7651,
                    7652
                ],
                "union": [
                    7652
                ],
                "this._get_axis": [
                    7652
                ],
                "other._get_axis": [
                    7652
                ],
                "result_index.difference": [
                    7653
                ],
                "correl.index": [
                    7653
                ],
                "correl.append": [
                    7656
                ],
                "self._count_level": [
                    7741
                ],
                "numeric_only": [
                    8292,
                    7816,
                    7886,
                    7856,
                    7858,
                    7923,
                    7765,
                    8217,
                    7741,
                    7743
                ],
                "frame._get_axis": [
                    7770,
                    7749
                ],
                "frame._get_agg_axis": [
                    7760,
                    7771,
                    7750
                ],
                "frame._is_mixed_type": [
                    7752,
                    7778
                ],
                "frame._data.any_extension_types": [
                    7752
                ],
                "frame._data": [
                    7752
                ],
                "series_counts": [
                    7758,
                    7759
                ],
                "series_counts.values": [
                    7759
                ],
                "result.astype": [
                    7762,
                    7940,
                    7942
                ],
                "count_axis": [
                    7792,
                    7794,
                    7795,
                    7796,
                    7770,
                    7773
                ],
                "self._get_axis_name": [
                    8344,
                    8373,
                    7775
                ],
                "frame.values": [
                    7784
                ],
                "mask.T": [
                    7789
                ],
                "count_axis._get_level_number": [
                    7792
                ],
                "level_name": [
                    7794,
                    7795
                ],
                "count_axis._names": [
                    7794
                ],
                "level_index": [
                    7795,
                    7797,
                    7799
                ],
                "_shallow_copy": [
                    7795
                ],
                "count_axis.levels": [
                    7795
                ],
                "level_codes": [
                    7796,
                    7797
                ],
                "ensure_int64": [
                    7796
                ],
                "count_axis.codes": [
                    7796
                ],
                "lib.count_level_2d": [
                    7797
                ],
                "filter_type": [
                    7840,
                    7842,
                    7811,
                    7939,
                    7941,
                    7850,
                    7896,
                    7827,
                    7864,
                    7933
                ],
                "dtype_is_dt": [
                    7816,
                    7824,
                    7813
                ],
                "self.dtypes.apply": [
                    7813
                ],
                "is_datetime64_any_dtype": [
                    7814
                ],
                "is_period_dtype": [
                    7814
                ],
                "dtype_is_dt.any": [
                    7816
                ],
                "constructor": [
                    7834,
                    7948,
                    7829
                ],
                "self._get_agg_axis": [
                    7833,
                    8124,
                    8057
                ],
                "skipna": [
                    7869,
                    8054,
                    8121,
                    7837,
                    7870
                ],
                "axis_matters": [
                    7843
                ],
                "self._get_bool_data": [
                    7845,
                    7847
                ],
                "_get_data": [
                    7859,
                    7916,
                    7924
                ],
                "df.T": [
                    7861
                ],
                "out_dtype": [
                    7864,
                    7878
                ],
                "df._data.reduce": [
                    7874
                ],
                "df._data": [
                    7874
                ],
                "blk_func": [
                    7874
                ],
                "res.keys": [
                    7877
                ],
                "df._constructor_sliced": [
                    7878
                ],
                "out.index": [
                    7879
                ],
                "df.columns": [
                    7879
                ],
                "df.dtypes.apply": [
                    7880
                ],
                "df.dtypes": [
                    7880,
                    7883
                ],
                "coerce_to_dtypes": [
                    7946,
                    7883
                ],
                "out.values": [
                    7883
                ],
                "opa": [
                    7907,
                    7910
                ],
                "opa.get_result": [
                    7910
                ],
                "self.ndim": [
                    7911
                ],
                "result.iloc": [
                    7912
                ],
                "data._get_agg_axis": [
                    7925,
                    7917
                ],
                "np.bool_": [
                    7936,
                    7942
                ],
                "result.dtype": [
                    7937
                ],
                "np.float64": [
                    8304,
                    7940
                ],
                "data.dtypes": [
                    7946
                ],
                "Series.nunique": [
                    7990
                ],
                "nanops.nanargmin": [
                    8054
                ],
                "nanops.nanargmax": [
                    8121
                ],
                "axis_num": [
                    8130,
                    8132,
                    8135
                ],
                "s.mode": [
                    8220
                ],
                "data.apply": [
                    8222
                ],
                "validate_percentile": [
                    8290
                ],
                "q": [
                    8290,
                    8302,
                    8303,
                    8304,
                    8307,
                    8313
                ],
                "is_transposed": [
                    8296,
                    8315,
                    8307,
                    8294
                ],
                "data.T": [
                    8297
                ],
                "data.columns": [
                    8299
                ],
                "self.columns.name": [
                    8301
                ],
                "data._data.quantile": [
                    8306
                ],
                "interpolation": [
                    8307
                ],
                "axis_name": [
                    8377,
                    8373,
                    8374,
                    8344,
                    8345,
                    8348
                ],
                "old_ax": [
                    8345,
                    8346,
                    8374,
                    8375
                ],
                "new_ax": [
                    8377,
                    8346,
                    8348,
                    8375
                ],
                "old_ax.to_timestamp": [
                    8346
                ],
                "old_ax.to_period": [
                    8375
                ],
                "collections.defaultdict": [
                    8508,
                    8445
                ],
                "isin": [
                    8448
                ],
                "values.index.is_unique": [
                    8458,
                    8454
                ],
                "values.index": [
                    8458,
                    8454
                ],
                "self.eq": [
                    8456,
                    8460
                ],
                "values.reindex_like": [
                    8456,
                    8460
                ],
                "values.columns.is_unique": [
                    8458
                ],
                "values.columns": [
                    8458
                ],
                "reshape": [
                    8469
                ],
                "algorithms.isin": [
                    8469
                ],
                "self.values.ravel": [
                    8469
                ],
                "_AXIS_ORDERS": [
                    8480,
                    8476
                ],
                "_AXIS_NUMBERS": [
                    8477
                ],
                "_AXIS_NAMES": [
                    8478
                ],
                "_AXIS_REVERSED": [
                    8479
                ],
                "_AXIS_LEN": [
                    8480
                ],
                "_info_axis_number": [
                    8481
                ],
                "_info_axis_name": [
                    8482
                ],
                "properties.AxisProperty": [
                    8484,
                    8487
                ],
                "properties": [
                    8484,
                    8487
                ],
                "plot": [
                    8493
                ],
                "CachedAccessor": [
                    8496,
                    8493
                ],
                "pandas.plotting.PlotAccessor": [
                    8493
                ],
                "pandas.plotting": [
                    8493,
                    8494,
                    8495
                ],
                "pandas": [
                    8493,
                    8494,
                    8495
                ],
                "hist": [
                    8494
                ],
                "pandas.plotting.hist_frame": [
                    8494
                ],
                "boxplot": [
                    8495
                ],
                "pandas.plotting.boxplot_frame": [
                    8495
                ],
                "sparse": [
                    8496
                ],
                "SparseFrameAccessor": [
                    8496
                ],
                "DataFrame._add_numeric_operations": [
                    8499
                ],
                "DataFrame._add_series_or_dataframe_operations": [
                    8500
                ],
                "ops.add_flex_arithmetic_methods": [
                    8502
                ],
                "ops.add_special_arithmetic_methods": [
                    8503
                ],
                "s.items": [
                    8510
                ]
            }
        },
        "/Volumes/JerrySSD/bgp_envs/repos/pandas_47/pandas/core/indexing.py": {
            "buggy_functions": [
                {
                    "function_name": "_get_setitem_indexer",
                    "function_code": "def _get_setitem_indexer(self, key):\n    \"\"\"\n    Convert a potentially-label-based key into a positional indexer.\n    \"\"\"\n    if self.axis is not None:\n        return self._convert_tuple(key, is_setter=True)\n\n    ax = self.obj._get_axis(0)\n\n    if isinstance(ax, ABCMultiIndex) and self.name != \"iloc\":\n        try:\n            return ax.get_loc(key)\n        except (TypeError, KeyError, InvalidIndexError):\n            # TypeError e.g. passed a bool\n            pass\n\n    if isinstance(key, tuple):\n        try:\n            return self._convert_tuple(key, is_setter=True)\n        except IndexingError:\n            pass\n\n    if isinstance(key, range):\n        return list(key)\n\n    try:\n        return self._convert_to_indexer(key, axis=0, is_setter=True)\n    except TypeError as e:\n\n        # invalid indexer type vs 'other' indexing errors\n        if \"cannot do\" in str(e):\n            raise\n        raise IndexingError(key) from e\n",
                    "decorators": [],
                    "docstring": "Convert a potentially-label-based key into a positional indexer.",
                    "start_line": 580,
                    "variables": {
                        "self.axis": [
                            584
                        ],
                        "self": [
                            584,
                            585,
                            587,
                            589,
                            598,
                            606
                        ],
                        "self._convert_tuple": [
                            585,
                            598
                        ],
                        "key": [
                            612,
                            585,
                            591,
                            596,
                            598,
                            602,
                            603,
                            606
                        ],
                        "ax": [
                            587,
                            589,
                            591
                        ],
                        "self.obj._get_axis": [
                            587
                        ],
                        "self.obj": [
                            587
                        ],
                        "isinstance": [
                            602,
                            596,
                            589
                        ],
                        "ABCMultiIndex": [
                            589
                        ],
                        "self.name": [
                            589
                        ],
                        "ax.get_loc": [
                            591
                        ],
                        "TypeError": [
                            592,
                            607
                        ],
                        "KeyError": [
                            592
                        ],
                        "InvalidIndexError": [
                            592
                        ],
                        "tuple": [
                            596
                        ],
                        "IndexingError": [
                            612,
                            599
                        ],
                        "range": [
                            602
                        ],
                        "list": [
                            603
                        ],
                        "self._convert_to_indexer": [
                            606
                        ],
                        "str": [
                            610
                        ],
                        "e": [
                            610,
                            612
                        ]
                    },
                    "filtered_variables": {
                        "self.axis": [
                            584
                        ],
                        "self": [
                            584,
                            585,
                            587,
                            589,
                            598,
                            606
                        ],
                        "self._convert_tuple": [
                            585,
                            598
                        ],
                        "key": [
                            612,
                            585,
                            591,
                            596,
                            598,
                            602,
                            603,
                            606
                        ],
                        "ax": [
                            587,
                            589,
                            591
                        ],
                        "self.obj._get_axis": [
                            587
                        ],
                        "self.obj": [
                            587
                        ],
                        "ABCMultiIndex": [
                            589
                        ],
                        "self.name": [
                            589
                        ],
                        "ax.get_loc": [
                            591
                        ],
                        "InvalidIndexError": [
                            592
                        ],
                        "IndexingError": [
                            612,
                            599
                        ],
                        "self._convert_to_indexer": [
                            606
                        ],
                        "e": [
                            610,
                            612
                        ]
                    },
                    "diff_line_number": 583,
                    "class_data": {
                        "signature": "class _LocationIndexer(_NDFrameIndexerBase)",
                        "docstring": null,
                        "constructor_docstring": null,
                        "functions": [
                            "def __call__(self, axis=None):\n    new_self = type(self)(self.name, self.obj)\n    if axis is not None:\n        axis = self.obj._get_axis_number(axis)\n    new_self.axis = axis\n    return new_self",
                            "def _get_setitem_indexer(self, key):\n    \"\"\"\n    Convert a potentially-label-based key into a positional indexer.\n    \"\"\"\n    if self.axis is not None:\n        return self._convert_tuple(key, is_setter=True)\n    ax = self.obj._get_axis(0)\n    if isinstance(ax, ABCMultiIndex) and self.name != 'iloc':\n        try:\n            return ax.get_loc(key)\n        except (TypeError, KeyError, InvalidIndexError):\n            pass\n    if isinstance(key, tuple):\n        try:\n            return self._convert_tuple(key, is_setter=True)\n        except IndexingError:\n            pass\n    if isinstance(key, range):\n        return list(key)\n    try:\n        return self._convert_to_indexer(key, axis=0, is_setter=True)\n    except TypeError as e:\n        if 'cannot do' in str(e):\n            raise\n        raise IndexingError(key) from e",
                            "def __setitem__(self, key, value):\n    if isinstance(key, tuple):\n        key = tuple((com.apply_if_callable(x, self.obj) for x in key))\n    else:\n        key = com.apply_if_callable(key, self.obj)\n    indexer = self._get_setitem_indexer(key)\n    self._has_valid_setitem_indexer(key)\n    iloc = self if self.name == 'iloc' else self.obj.iloc\n    iloc._setitem_with_indexer(indexer, value)",
                            "def _validate_key(self, key, axis: int):\n    \"\"\"\n    Ensure that key is valid for current indexer.\n\n    Parameters\n    ----------\n    key : scalar, slice or list-like\n        Key requested.\n    axis : int\n        Dimension on which the indexing is being made.\n\n    Raises\n    ------\n    TypeError\n        If the key (or some element of it) has wrong type.\n    IndexError\n        If the key (or some element of it) is out of bounds.\n    KeyError\n        If the key was not found.\n    \"\"\"\n    raise AbstractMethodError(self)",
                            "def _has_valid_tuple(self, key: Tuple):\n    \"\"\"\n    Check the key for valid keys across my indexer.\n    \"\"\"\n    for i, k in enumerate(key):\n        if i >= self.ndim:\n            raise IndexingError('Too many indexers')\n        try:\n            self._validate_key(k, i)\n        except ValueError as err:\n            raise ValueError(f'Location based indexing can only have [{self._valid_types}] types') from err",
                            "def _is_nested_tuple_indexer(self, tup: Tuple) -> bool:\n    \"\"\"\n    Returns\n    -------\n    bool\n    \"\"\"\n    if any((isinstance(ax, ABCMultiIndex) for ax in self.obj.axes)):\n        return any((is_nested_tuple(tup, ax) for ax in self.obj.axes))\n    return False",
                            "def _convert_tuple(self, key, is_setter: bool=False):\n    keyidx = []\n    if self.axis is not None:\n        axis = self.obj._get_axis_number(self.axis)\n        for i in range(self.ndim):\n            if i == axis:\n                keyidx.append(self._convert_to_indexer(key, axis=axis, is_setter=is_setter))\n            else:\n                keyidx.append(slice(None))\n    else:\n        for i, k in enumerate(key):\n            if i >= self.ndim:\n                raise IndexingError('Too many indexers')\n            idx = self._convert_to_indexer(k, axis=i, is_setter=is_setter)\n            keyidx.append(idx)\n    return tuple(keyidx)",
                            "def _getitem_tuple_same_dim(self, tup: Tuple):\n    \"\"\"\n    Index with indexers that should return an object of the same dimension\n    as self.obj.\n\n    This is only called after a failed call to _getitem_lowerdim.\n    \"\"\"\n    retval = self.obj\n    for i, key in enumerate(tup):\n        if com.is_null_slice(key):\n            continue\n        retval = getattr(retval, self.name)._getitem_axis(key, axis=i)\n        assert retval.ndim == self.ndim\n    return retval",
                            "def _getitem_lowerdim(self, tup: Tuple):\n    if self.axis is not None:\n        axis = self.obj._get_axis_number(self.axis)\n        return self._getitem_axis(tup, axis=axis)\n    if self._is_nested_tuple_indexer(tup):\n        return self._getitem_nested_tuple(tup)\n    ax0 = self.obj._get_axis(0)\n    if isinstance(ax0, ABCMultiIndex) and self.name != 'iloc':\n        result = self._handle_lowerdim_multi_index_axis0(tup)\n        if result is not None:\n            return result\n    if len(tup) > self.ndim:\n        raise IndexingError('Too many indexers. handle elsewhere')\n    for i, key in enumerate(tup):\n        if is_label_like(key):\n            section = self._getitem_axis(key, axis=i)\n            if section.ndim == self.ndim:\n                new_key = tup[:i] + (_NS,) + tup[i + 1:]\n            else:\n                new_key = tup[:i] + tup[i + 1:]\n                if len(new_key) == 1:\n                    new_key = new_key[0]\n            if com.is_null_slice(new_key):\n                return section\n            return getattr(section, self.name)[new_key]\n    raise IndexingError('not applicable')",
                            "def _getitem_nested_tuple(self, tup: Tuple):\n    if len(tup) > self.ndim:\n        if self.name != 'loc':\n            raise ValueError('Too many indices')\n        result = self._handle_lowerdim_multi_index_axis0(tup)\n        if result is not None:\n            return result\n        axis = self.axis or 0\n        return self._getitem_axis(tup, axis=axis)\n    obj = self.obj\n    axis = 0\n    for i, key in enumerate(tup):\n        if com.is_null_slice(key):\n            axis += 1\n            continue\n        current_ndim = obj.ndim\n        obj = getattr(obj, self.name)._getitem_axis(key, axis=axis)\n        axis += 1\n        if is_scalar(obj) or not hasattr(obj, 'ndim'):\n            break\n        if obj.ndim < current_ndim:\n            axis -= 1\n    return obj",
                            "def _convert_to_indexer(self, key, axis: int, is_setter: bool=False):\n    raise AbstractMethodError(self)",
                            "def __getitem__(self, key):\n    if type(key) is tuple:\n        key = tuple((com.apply_if_callable(x, self.obj) for x in key))\n        if self._is_scalar_access(key):\n            try:\n                return self.obj._get_value(*key, takeable=self._takeable)\n            except (KeyError, IndexError, AttributeError):\n                pass\n        return self._getitem_tuple(key)\n    else:\n        axis = self.axis or 0\n        maybe_callable = com.apply_if_callable(key, self.obj)\n        return self._getitem_axis(maybe_callable, axis=axis)",
                            "def _is_scalar_access(self, key: Tuple):\n    raise NotImplementedError()",
                            "def _getitem_tuple(self, tup: Tuple):\n    raise AbstractMethodError(self)",
                            "def _getitem_axis(self, key, axis: int):\n    raise NotImplementedError()",
                            "def _has_valid_setitem_indexer(self, indexer) -> bool:\n    raise AbstractMethodError(self)",
                            "def _getbool_axis(self, key, axis: int):\n    labels = self.obj._get_axis(axis)\n    key = check_bool_indexer(labels, key)\n    inds = key.nonzero()[0]\n    return self.obj._take_with_is_copy(inds, axis=axis)"
                        ],
                        "constructor_variables": [],
                        "class_level_variables": [
                            "_valid_types",
                            "axis"
                        ],
                        "class_decorators": [],
                        "function_signatures": [
                            "__call__(self, axis=None)",
                            "_get_setitem_indexer(self, key)",
                            "__setitem__(self, key, value)",
                            "_validate_key(self, key, axis: int)",
                            "_has_valid_tuple(self, key: Tuple)",
                            "_is_nested_tuple_indexer(self, tup: Tuple) -> bool",
                            "_convert_tuple(self, key, is_setter: bool=False)",
                            "_getitem_tuple_same_dim(self, tup: Tuple)",
                            "_getitem_lowerdim(self, tup: Tuple)",
                            "_getitem_nested_tuple(self, tup: Tuple)",
                            "_convert_to_indexer(self, key, axis: int, is_setter: bool=False)",
                            "__getitem__(self, key)",
                            "_is_scalar_access(self, key: Tuple)",
                            "_getitem_tuple(self, tup: Tuple)",
                            "_getitem_axis(self, key, axis: int)",
                            "_has_valid_setitem_indexer(self, indexer) -> bool",
                            "_getbool_axis(self, key, axis: int)"
                        ]
                    },
                    "variable_values": [
                        [
                            {
                                "self.axis": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self": {
                                    "variable_value": "<pandas.core.indexing._LocIndexer object at 0x1189f66d0>",
                                    "variable_type": "_LocIndexer",
                                    "variable_shape": null
                                },
                                "self._convert_tuple": {
                                    "variable_value": "<bound method _LocationIndexer._convert_tuple of <pandas.core.indexing._LocIndexer object at 0x1189f66d0>>",
                                    "variable_type": "method",
                                    "variable_shape": null
                                },
                                "key": {
                                    "variable_value": "(slice(None, None, None), ['A', 'C'])",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "ax": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.obj._get_axis": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self.obj": {
                                    "variable_value": "   A  B\n0  1  2\n1  3  4\n2  5  6",
                                    "variable_type": "DataFrame",
                                    "variable_shape": "3"
                                },
                                "ABCMultiIndex": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.name": {
                                    "variable_value": "'loc'",
                                    "variable_type": "str",
                                    "variable_shape": "3"
                                },
                                "ax.get_loc": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "InvalidIndexError": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "IndexingError": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self._convert_to_indexer": {
                                    "variable_value": "<bound method _LocIndexer._convert_to_indexer of <pandas.core.indexing._LocIndexer object at 0x1189f66d0>>",
                                    "variable_type": "method",
                                    "variable_shape": null
                                },
                                "e": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                }
                            },
                            {}
                        ]
                    ],
                    "angelic_variable_values": [
                        [
                            {
                                "self.name": {
                                    "variable_value": "'loc'",
                                    "variable_type": "str",
                                    "variable_shape": "3"
                                },
                                "self": {
                                    "variable_value": "<pandas.core.indexing._LocIndexer object at 0x11e18fc20>",
                                    "variable_type": "_LocIndexer",
                                    "variable_shape": null
                                },
                                "self._ensure_listlike_indexer": {
                                    "variable_value": "<bound method _LocationIndexer._ensure_listlike_indexer of <pandas.core.indexing._LocIndexer object at 0x11e18fc20>>",
                                    "variable_type": "method",
                                    "variable_shape": null
                                },
                                "key": {
                                    "variable_value": "(slice(None, None, None), ['A', 'C'])",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "self.axis": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self._convert_tuple": {
                                    "variable_value": "<bound method _LocationIndexer._convert_tuple of <pandas.core.indexing._LocIndexer object at 0x11e18fc20>>",
                                    "variable_type": "method",
                                    "variable_shape": null
                                },
                                "ax": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.obj._get_axis": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self.obj": {
                                    "variable_value": "   A  B\n0  1  2\n1  3  4\n2  5  6",
                                    "variable_type": "DataFrame",
                                    "variable_shape": "3"
                                },
                                "ABCMultiIndex": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "ax.get_loc": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "InvalidIndexError": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "IndexingError": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self._convert_to_indexer": {
                                    "variable_value": "<bound method _LocIndexer._convert_to_indexer of <pandas.core.indexing._LocIndexer object at 0x11e18fc20>>",
                                    "variable_type": "method",
                                    "variable_shape": null
                                },
                                "e": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                }
                            },
                            {}
                        ]
                    ]
                },
                {
                    "function_name": "__setitem__",
                    "function_code": "def __setitem__(self, key, value):\n    if isinstance(key, tuple):\n        key = tuple(com.apply_if_callable(x, self.obj) for x in key)\n    else:\n        key = com.apply_if_callable(key, self.obj)\n    indexer = self._get_setitem_indexer(key)\n    self._has_valid_setitem_indexer(key)\n\n    iloc = self if self.name == \"iloc\" else self.obj.iloc\n    iloc._setitem_with_indexer(indexer, value)\n",
                    "decorators": [],
                    "docstring": null,
                    "start_line": 614,
                    "variables": {
                        "isinstance": [
                            615
                        ],
                        "key": [
                            615,
                            616,
                            618,
                            619,
                            620
                        ],
                        "tuple": [
                            616,
                            615
                        ],
                        "com.apply_if_callable": [
                            616,
                            618
                        ],
                        "com": [
                            616,
                            618
                        ],
                        "x": [
                            616
                        ],
                        "self.obj": [
                            616,
                            618,
                            622
                        ],
                        "self": [
                            616,
                            618,
                            619,
                            620,
                            622
                        ],
                        "indexer": [
                            619,
                            623
                        ],
                        "self._get_setitem_indexer": [
                            619
                        ],
                        "self._has_valid_setitem_indexer": [
                            620
                        ],
                        "iloc": [
                            622,
                            623
                        ],
                        "self.name": [
                            622
                        ],
                        "self.obj.iloc": [
                            622
                        ],
                        "iloc._setitem_with_indexer": [
                            623
                        ],
                        "value": [
                            623
                        ]
                    },
                    "filtered_variables": {
                        "key": [
                            615,
                            616,
                            618,
                            619,
                            620
                        ],
                        "com.apply_if_callable": [
                            616,
                            618
                        ],
                        "com": [
                            616,
                            618
                        ],
                        "x": [
                            616
                        ],
                        "self.obj": [
                            616,
                            618,
                            622
                        ],
                        "self": [
                            616,
                            618,
                            619,
                            620,
                            622
                        ],
                        "indexer": [
                            619,
                            623
                        ],
                        "self._get_setitem_indexer": [
                            619
                        ],
                        "self._has_valid_setitem_indexer": [
                            620
                        ],
                        "iloc": [
                            622,
                            623
                        ],
                        "self.name": [
                            622
                        ],
                        "self.obj.iloc": [
                            622
                        ],
                        "iloc._setitem_with_indexer": [
                            623
                        ],
                        "value": [
                            623
                        ]
                    },
                    "diff_line_number": 614,
                    "class_data": {
                        "signature": "class _LocationIndexer(_NDFrameIndexerBase)",
                        "docstring": null,
                        "constructor_docstring": null,
                        "functions": [
                            "def __call__(self, axis=None):\n    new_self = type(self)(self.name, self.obj)\n    if axis is not None:\n        axis = self.obj._get_axis_number(axis)\n    new_self.axis = axis\n    return new_self",
                            "def _get_setitem_indexer(self, key):\n    \"\"\"\n    Convert a potentially-label-based key into a positional indexer.\n    \"\"\"\n    if self.axis is not None:\n        return self._convert_tuple(key, is_setter=True)\n    ax = self.obj._get_axis(0)\n    if isinstance(ax, ABCMultiIndex) and self.name != 'iloc':\n        try:\n            return ax.get_loc(key)\n        except (TypeError, KeyError, InvalidIndexError):\n            pass\n    if isinstance(key, tuple):\n        try:\n            return self._convert_tuple(key, is_setter=True)\n        except IndexingError:\n            pass\n    if isinstance(key, range):\n        return list(key)\n    try:\n        return self._convert_to_indexer(key, axis=0, is_setter=True)\n    except TypeError as e:\n        if 'cannot do' in str(e):\n            raise\n        raise IndexingError(key) from e",
                            "def __setitem__(self, key, value):\n    if isinstance(key, tuple):\n        key = tuple((com.apply_if_callable(x, self.obj) for x in key))\n    else:\n        key = com.apply_if_callable(key, self.obj)\n    indexer = self._get_setitem_indexer(key)\n    self._has_valid_setitem_indexer(key)\n    iloc = self if self.name == 'iloc' else self.obj.iloc\n    iloc._setitem_with_indexer(indexer, value)",
                            "def _validate_key(self, key, axis: int):\n    \"\"\"\n    Ensure that key is valid for current indexer.\n\n    Parameters\n    ----------\n    key : scalar, slice or list-like\n        Key requested.\n    axis : int\n        Dimension on which the indexing is being made.\n\n    Raises\n    ------\n    TypeError\n        If the key (or some element of it) has wrong type.\n    IndexError\n        If the key (or some element of it) is out of bounds.\n    KeyError\n        If the key was not found.\n    \"\"\"\n    raise AbstractMethodError(self)",
                            "def _has_valid_tuple(self, key: Tuple):\n    \"\"\"\n    Check the key for valid keys across my indexer.\n    \"\"\"\n    for i, k in enumerate(key):\n        if i >= self.ndim:\n            raise IndexingError('Too many indexers')\n        try:\n            self._validate_key(k, i)\n        except ValueError as err:\n            raise ValueError(f'Location based indexing can only have [{self._valid_types}] types') from err",
                            "def _is_nested_tuple_indexer(self, tup: Tuple) -> bool:\n    \"\"\"\n    Returns\n    -------\n    bool\n    \"\"\"\n    if any((isinstance(ax, ABCMultiIndex) for ax in self.obj.axes)):\n        return any((is_nested_tuple(tup, ax) for ax in self.obj.axes))\n    return False",
                            "def _convert_tuple(self, key, is_setter: bool=False):\n    keyidx = []\n    if self.axis is not None:\n        axis = self.obj._get_axis_number(self.axis)\n        for i in range(self.ndim):\n            if i == axis:\n                keyidx.append(self._convert_to_indexer(key, axis=axis, is_setter=is_setter))\n            else:\n                keyidx.append(slice(None))\n    else:\n        for i, k in enumerate(key):\n            if i >= self.ndim:\n                raise IndexingError('Too many indexers')\n            idx = self._convert_to_indexer(k, axis=i, is_setter=is_setter)\n            keyidx.append(idx)\n    return tuple(keyidx)",
                            "def _getitem_tuple_same_dim(self, tup: Tuple):\n    \"\"\"\n    Index with indexers that should return an object of the same dimension\n    as self.obj.\n\n    This is only called after a failed call to _getitem_lowerdim.\n    \"\"\"\n    retval = self.obj\n    for i, key in enumerate(tup):\n        if com.is_null_slice(key):\n            continue\n        retval = getattr(retval, self.name)._getitem_axis(key, axis=i)\n        assert retval.ndim == self.ndim\n    return retval",
                            "def _getitem_lowerdim(self, tup: Tuple):\n    if self.axis is not None:\n        axis = self.obj._get_axis_number(self.axis)\n        return self._getitem_axis(tup, axis=axis)\n    if self._is_nested_tuple_indexer(tup):\n        return self._getitem_nested_tuple(tup)\n    ax0 = self.obj._get_axis(0)\n    if isinstance(ax0, ABCMultiIndex) and self.name != 'iloc':\n        result = self._handle_lowerdim_multi_index_axis0(tup)\n        if result is not None:\n            return result\n    if len(tup) > self.ndim:\n        raise IndexingError('Too many indexers. handle elsewhere')\n    for i, key in enumerate(tup):\n        if is_label_like(key):\n            section = self._getitem_axis(key, axis=i)\n            if section.ndim == self.ndim:\n                new_key = tup[:i] + (_NS,) + tup[i + 1:]\n            else:\n                new_key = tup[:i] + tup[i + 1:]\n                if len(new_key) == 1:\n                    new_key = new_key[0]\n            if com.is_null_slice(new_key):\n                return section\n            return getattr(section, self.name)[new_key]\n    raise IndexingError('not applicable')",
                            "def _getitem_nested_tuple(self, tup: Tuple):\n    if len(tup) > self.ndim:\n        if self.name != 'loc':\n            raise ValueError('Too many indices')\n        result = self._handle_lowerdim_multi_index_axis0(tup)\n        if result is not None:\n            return result\n        axis = self.axis or 0\n        return self._getitem_axis(tup, axis=axis)\n    obj = self.obj\n    axis = 0\n    for i, key in enumerate(tup):\n        if com.is_null_slice(key):\n            axis += 1\n            continue\n        current_ndim = obj.ndim\n        obj = getattr(obj, self.name)._getitem_axis(key, axis=axis)\n        axis += 1\n        if is_scalar(obj) or not hasattr(obj, 'ndim'):\n            break\n        if obj.ndim < current_ndim:\n            axis -= 1\n    return obj",
                            "def _convert_to_indexer(self, key, axis: int, is_setter: bool=False):\n    raise AbstractMethodError(self)",
                            "def __getitem__(self, key):\n    if type(key) is tuple:\n        key = tuple((com.apply_if_callable(x, self.obj) for x in key))\n        if self._is_scalar_access(key):\n            try:\n                return self.obj._get_value(*key, takeable=self._takeable)\n            except (KeyError, IndexError, AttributeError):\n                pass\n        return self._getitem_tuple(key)\n    else:\n        axis = self.axis or 0\n        maybe_callable = com.apply_if_callable(key, self.obj)\n        return self._getitem_axis(maybe_callable, axis=axis)",
                            "def _is_scalar_access(self, key: Tuple):\n    raise NotImplementedError()",
                            "def _getitem_tuple(self, tup: Tuple):\n    raise AbstractMethodError(self)",
                            "def _getitem_axis(self, key, axis: int):\n    raise NotImplementedError()",
                            "def _has_valid_setitem_indexer(self, indexer) -> bool:\n    raise AbstractMethodError(self)",
                            "def _getbool_axis(self, key, axis: int):\n    labels = self.obj._get_axis(axis)\n    key = check_bool_indexer(labels, key)\n    inds = key.nonzero()[0]\n    return self.obj._take_with_is_copy(inds, axis=axis)"
                        ],
                        "constructor_variables": [],
                        "class_level_variables": [
                            "_valid_types",
                            "axis"
                        ],
                        "class_decorators": [],
                        "function_signatures": [
                            "__call__(self, axis=None)",
                            "_get_setitem_indexer(self, key)",
                            "__setitem__(self, key, value)",
                            "_validate_key(self, key, axis: int)",
                            "_has_valid_tuple(self, key: Tuple)",
                            "_is_nested_tuple_indexer(self, tup: Tuple) -> bool",
                            "_convert_tuple(self, key, is_setter: bool=False)",
                            "_getitem_tuple_same_dim(self, tup: Tuple)",
                            "_getitem_lowerdim(self, tup: Tuple)",
                            "_getitem_nested_tuple(self, tup: Tuple)",
                            "_convert_to_indexer(self, key, axis: int, is_setter: bool=False)",
                            "__getitem__(self, key)",
                            "_is_scalar_access(self, key: Tuple)",
                            "_getitem_tuple(self, tup: Tuple)",
                            "_getitem_axis(self, key, axis: int)",
                            "_has_valid_setitem_indexer(self, indexer) -> bool",
                            "_getbool_axis(self, key, axis: int)"
                        ]
                    },
                    "variable_values": [
                        [
                            {
                                "key": {
                                    "variable_value": "A    True\nB    True\ndtype: bool",
                                    "variable_type": "Series",
                                    "variable_shape": "2"
                                },
                                "com.apply_if_callable": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "com": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "x": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.obj": {
                                    "variable_value": "A    NaN\nB    NaN\ndtype: object",
                                    "variable_type": "Series",
                                    "variable_shape": "2"
                                },
                                "self": {
                                    "variable_value": "<pandas.core.indexing._LocIndexer object at 0x11f1c4680>",
                                    "variable_type": "_LocIndexer",
                                    "variable_shape": null
                                },
                                "indexer": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self._get_setitem_indexer": {
                                    "variable_value": "<bound method _LocationIndexer._get_setitem_indexer of <pandas.core.indexing._LocIndexer object at 0x11f1c4680>>",
                                    "variable_type": "method",
                                    "variable_shape": null
                                },
                                "self._has_valid_setitem_indexer": {
                                    "variable_value": "<bound method _LocIndexer._has_valid_setitem_indexer of <pandas.core.indexing._LocIndexer object at 0x11f1c4680>>",
                                    "variable_type": "method",
                                    "variable_shape": null
                                },
                                "iloc": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.name": {
                                    "variable_value": "'loc'",
                                    "variable_type": "str",
                                    "variable_shape": "3"
                                },
                                "self.obj.iloc": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "iloc._setitem_with_indexer": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "value": {
                                    "variable_value": "[array([], dtype=object), array([], dtype=object)]",
                                    "variable_type": "list",
                                    "variable_shape": "2"
                                }
                            },
                            {
                                "key": {
                                    "variable_value": "A    True\nB    True\ndtype: bool",
                                    "variable_type": "Series",
                                    "variable_shape": "2"
                                },
                                "com.apply_if_callable": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "com": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "x": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.obj": {
                                    "variable_value": "A    []\nB    []\ndtype: object",
                                    "variable_type": "Series",
                                    "variable_shape": "2"
                                },
                                "self": {
                                    "variable_value": "<pandas.core.indexing._LocIndexer object at 0x11f1c4680>",
                                    "variable_type": "_LocIndexer",
                                    "variable_shape": null
                                },
                                "indexer": {
                                    "variable_value": "array([0, 1])",
                                    "variable_type": "ndarray",
                                    "variable_shape": "2"
                                },
                                "self._get_setitem_indexer": {
                                    "variable_value": "<bound method _LocationIndexer._get_setitem_indexer of <pandas.core.indexing._LocIndexer object at 0x11f1c4680>>",
                                    "variable_type": "method",
                                    "variable_shape": null
                                },
                                "self._has_valid_setitem_indexer": {
                                    "variable_value": "<bound method _LocIndexer._has_valid_setitem_indexer of <pandas.core.indexing._LocIndexer object at 0x11f1c4680>>",
                                    "variable_type": "method",
                                    "variable_shape": null
                                },
                                "iloc": {
                                    "variable_value": "<pandas.core.indexing._iLocIndexer object at 0x11f1c4950>",
                                    "variable_type": "_iLocIndexer",
                                    "variable_shape": null
                                },
                                "self.name": {
                                    "variable_value": "'loc'",
                                    "variable_type": "str",
                                    "variable_shape": "3"
                                },
                                "self.obj.iloc": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "iloc._setitem_with_indexer": {
                                    "variable_value": "<bound method _iLocIndexer._setitem_with_indexer of <pandas.core.indexing._iLocIndexer object at 0x11f1c4950>>",
                                    "variable_type": "method",
                                    "variable_shape": null
                                },
                                "value": {
                                    "variable_value": "[array([], dtype=object), array([], dtype=object)]",
                                    "variable_type": "list",
                                    "variable_shape": "2"
                                }
                            }
                        ],
                        [
                            {
                                "key": {
                                    "variable_value": "A    True\nB    True\ndtype: bool",
                                    "variable_type": "Series",
                                    "variable_shape": "2"
                                },
                                "com.apply_if_callable": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "com": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "x": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.obj": {
                                    "variable_value": "A    NaN\nB    NaN\ndtype: object",
                                    "variable_type": "Series",
                                    "variable_shape": "2"
                                },
                                "self": {
                                    "variable_value": "<pandas.core.indexing._LocIndexer object at 0x11f1c44a0>",
                                    "variable_type": "_LocIndexer",
                                    "variable_shape": null
                                },
                                "indexer": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self._get_setitem_indexer": {
                                    "variable_value": "<bound method _LocationIndexer._get_setitem_indexer of <pandas.core.indexing._LocIndexer object at 0x11f1c44a0>>",
                                    "variable_type": "method",
                                    "variable_shape": null
                                },
                                "self._has_valid_setitem_indexer": {
                                    "variable_value": "<bound method _LocIndexer._has_valid_setitem_indexer of <pandas.core.indexing._LocIndexer object at 0x11f1c44a0>>",
                                    "variable_type": "method",
                                    "variable_shape": null
                                },
                                "iloc": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.name": {
                                    "variable_value": "'loc'",
                                    "variable_type": "str",
                                    "variable_shape": "3"
                                },
                                "self.obj.iloc": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "iloc._setitem_with_indexer": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "value": {
                                    "variable_value": "[array([nan, nan, nan], dtype=object), array([nan, nan, nan], dtype=object)]",
                                    "variable_type": "list",
                                    "variable_shape": "2"
                                }
                            },
                            {
                                "key": {
                                    "variable_value": "A    True\nB    True\ndtype: bool",
                                    "variable_type": "Series",
                                    "variable_shape": "2"
                                },
                                "com.apply_if_callable": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "com": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "x": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.obj": {
                                    "variable_value": "A    [nan, nan, nan]\nB    [nan, nan, nan]\ndtype: object",
                                    "variable_type": "Series",
                                    "variable_shape": "2"
                                },
                                "self": {
                                    "variable_value": "<pandas.core.indexing._LocIndexer object at 0x11f1c44a0>",
                                    "variable_type": "_LocIndexer",
                                    "variable_shape": null
                                },
                                "indexer": {
                                    "variable_value": "array([0, 1])",
                                    "variable_type": "ndarray",
                                    "variable_shape": "2"
                                },
                                "self._get_setitem_indexer": {
                                    "variable_value": "<bound method _LocationIndexer._get_setitem_indexer of <pandas.core.indexing._LocIndexer object at 0x11f1c44a0>>",
                                    "variable_type": "method",
                                    "variable_shape": null
                                },
                                "self._has_valid_setitem_indexer": {
                                    "variable_value": "<bound method _LocIndexer._has_valid_setitem_indexer of <pandas.core.indexing._LocIndexer object at 0x11f1c44a0>>",
                                    "variable_type": "method",
                                    "variable_shape": null
                                },
                                "iloc": {
                                    "variable_value": "<pandas.core.indexing._iLocIndexer object at 0x11f1c4d60>",
                                    "variable_type": "_iLocIndexer",
                                    "variable_shape": null
                                },
                                "self.name": {
                                    "variable_value": "'loc'",
                                    "variable_type": "str",
                                    "variable_shape": "3"
                                },
                                "self.obj.iloc": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "iloc._setitem_with_indexer": {
                                    "variable_value": "<bound method _iLocIndexer._setitem_with_indexer of <pandas.core.indexing._iLocIndexer object at 0x11f1c4d60>>",
                                    "variable_type": "method",
                                    "variable_shape": null
                                },
                                "value": {
                                    "variable_value": "[array([nan, nan, nan], dtype=object), array([nan, nan, nan], dtype=object)]",
                                    "variable_type": "list",
                                    "variable_shape": "2"
                                }
                            }
                        ]
                    ]
                }
            ],
            "snippets": [
                {
                    "snippet_code": "from pandas.core.dtypes.common import (\n    is_integer,\n    is_iterator,\n    is_list_like,\n    is_numeric_dtype,\n    is_object_dtype,\n    is_scalar,\n    is_sequence,\n)",
                    "start_line": 10,
                    "end_line": 18
                }
            ],
            "inscope_functions": [
                "def _tuplify(ndim: int, loc: Hashable) -> Tuple[Union[Hashable, slice], ...]:\n    \"\"\"\n    Given an indexer for the first dimension, create an equivalent tuple\n    for indexing over all dimensions.\n\n    Parameters\n    ----------\n    ndim : int\n    loc : object\n\n    Returns\n    -------\n    tuple\n    \"\"\"\n    _tup: List[Union[Hashable, slice]]\n    _tup = [slice(None, None) for _ in range(ndim)]\n    _tup[0] = loc\n    return tuple(_tup)",
                "def convert_to_index_sliceable(obj, key):\n    \"\"\"\n    If we are index sliceable, then return my slicer, otherwise return None.\n    \"\"\"\n    idx = obj.index\n    if isinstance(key, slice):\n        return idx._convert_slice_indexer(key, kind=\"getitem\")\n\n    elif isinstance(key, str):\n\n        # we are an actual column\n        if key in obj._data.items:\n            return None\n\n        # We might have a datetimelike string that we can translate to a\n        # slice here via partial string indexing\n        if idx._supports_partial_string_indexing:\n            try:\n                return idx._get_string_slice(key)\n            except (KeyError, ValueError, NotImplementedError):\n                return None\n\n    return None",
                "def check_bool_indexer(index: Index, key) -> np.ndarray:\n    \"\"\"\n    Check if key is a valid boolean indexer for an object with such index and\n    perform reindexing or conversion if needed.\n\n    This function assumes that is_bool_indexer(key) == True.\n\n    Parameters\n    ----------\n    index : Index\n        Index of the object on which the indexing is done.\n    key : list-like\n        Boolean indexer to check.\n\n    Returns\n    -------\n    np.array\n        Resulting key.\n\n    Raises\n    ------\n    IndexError\n        If the key does not have the same length as index.\n    IndexingError\n        If the index of the key is unalignable to index.\n    \"\"\"\n    result = key\n    if isinstance(key, ABCSeries) and not key.index.equals(index):\n        result = result.reindex(index)\n        mask = isna(result._values)\n        if mask.any():\n            raise IndexingError(\n                \"Unalignable boolean Series provided as \"\n                \"indexer (index of the boolean Series and of \"\n                \"the indexed object do not match).\"\n            )\n        result = result.astype(bool)._values\n    elif is_object_dtype(key):\n        # key might be object-dtype bool, check_array_indexer needs bool array\n        result = np.asarray(result, dtype=bool)\n        result = check_array_indexer(index, result)\n    else:\n        result = check_array_indexer(index, result)\n\n    return result",
                "def convert_missing_indexer(indexer):\n    \"\"\"\n    Reverse convert a missing indexer, which is a dict\n    return the scalar indexer and a boolean indicating if we converted\n    \"\"\"\n    if isinstance(indexer, dict):\n\n        # a missing key (but not a tuple indexer)\n        indexer = indexer[\"key\"]\n\n        if isinstance(indexer, bool):\n            raise KeyError(\"cannot use a single bool to index into setitem\")\n        return indexer, True\n\n    return indexer, False",
                "def convert_from_missing_indexer_tuple(indexer, axes):\n    \"\"\"\n    Create a filtered indexer that doesn't have any missing indexers.\n    \"\"\"\n\n    def get_indexer(_i, _idx):\n        return axes[_i].get_loc(_idx[\"key\"]) if isinstance(_idx, dict) else _idx\n\n    return tuple(get_indexer(_i, _idx) for _i, _idx in enumerate(indexer))",
                "def maybe_convert_ix(*args):\n    \"\"\"\n    We likely want to take the cross-product.\n    \"\"\"\n    ixify = True\n    for arg in args:\n        if not isinstance(arg, (np.ndarray, list, ABCSeries, Index)):\n            ixify = False\n\n    if ixify:\n        return np.ix_(*args)\n    else:\n        return args",
                "def is_nested_tuple(tup, labels) -> bool:\n    \"\"\"\n    Returns\n    -------\n    bool\n    \"\"\"\n    # check for a compatible nested tuple and multiindexes among the axes\n    if not isinstance(tup, tuple):\n        return False\n\n    for i, k in enumerate(tup):\n\n        if is_list_like(k) or isinstance(k, slice):\n            return isinstance(labels, ABCMultiIndex)\n\n    return False",
                "def is_label_like(key) -> bool:\n    \"\"\"\n    Returns\n    -------\n    bool\n    \"\"\"\n    # select a label or row\n    return not isinstance(key, slice) and not is_list_like_indexer(key)",
                "def need_slice(obj) -> bool:\n    \"\"\"\n    Returns\n    -------\n    bool\n    \"\"\"\n    return (\n        obj.start is not None\n        or obj.stop is not None\n        or (obj.step is not None and obj.step != 1)\n    )",
                "def _non_reducing_slice(slice_):\n    \"\"\"\n    Ensurse that a slice doesn't reduce to a Series or Scalar.\n\n    Any user-paseed `subset` should have this called on it\n    to make sure we're always working with DataFrames.\n    \"\"\"\n    # default to column slice, like DataFrame\n    # ['A', 'B'] -> IndexSlices[:, ['A', 'B']]\n    kinds = (ABCSeries, np.ndarray, Index, list, str)\n    if isinstance(slice_, kinds):\n        slice_ = IndexSlice[:, slice_]\n\n    def pred(part) -> bool:\n        \"\"\"\n        Returns\n        -------\n        bool\n            True if slice does *not* reduce,\n            False if `part` is a tuple.\n        \"\"\"\n        # true when slice does *not* reduce, False when part is a tuple,\n        # i.e. MultiIndex slice\n        return (isinstance(part, slice) or is_list_like(part)) and not isinstance(\n            part, tuple\n        )\n\n    if not is_list_like(slice_):\n        if not isinstance(slice_, slice):\n            # a 1-d slice, like df.loc[1]\n            slice_ = [[slice_]]\n        else:\n            # slice(a, b, c)\n            slice_ = [slice_]  # to tuplize later\n    else:\n        slice_ = [part if pred(part) else [part] for part in slice_]\n    return tuple(slice_)",
                "def _maybe_numeric_slice(df, slice_, include_bool=False):\n    \"\"\"\n    Want nice defaults for background_gradient that don't break\n    with non-numeric data. But if slice_ is passed go with that.\n    \"\"\"\n    if slice_ is None:\n        dtypes = [np.number]\n        if include_bool:\n            dtypes.append(bool)\n        slice_ = IndexSlice[:, df.select_dtypes(include=dtypes).columns]\n    return slice_",
                "def __getitem__(self, arg):\n    return arg",
                "@property\ndef iloc(self) -> \"_iLocIndexer\":\n    \"\"\"\n    Purely integer-location based indexing for selection by position.\n\n    ``.iloc[]`` is primarily integer position based (from ``0`` to\n    ``length-1`` of the axis), but may also be used with a boolean\n    array.\n\n    Allowed inputs are:\n\n    - An integer, e.g. ``5``.\n    - A list or array of integers, e.g. ``[4, 3, 0]``.\n    - A slice object with ints, e.g. ``1:7``.\n    - A boolean array.\n    - A ``callable`` function with one argument (the calling Series or\n      DataFrame) and that returns valid output for indexing (one of the above).\n      This is useful in method chains, when you don't have a reference to the\n      calling object, but would like to base your selection on some value.\n\n    ``.iloc`` will raise ``IndexError`` if a requested indexer is\n    out-of-bounds, except *slice* indexers which allow out-of-bounds\n    indexing (this conforms with python/numpy *slice* semantics).\n\n    See more at :ref:`Selection by Position <indexing.integer>`.\n\n    See Also\n    --------\n    DataFrame.iat : Fast integer location scalar accessor.\n    DataFrame.loc : Purely label-location based indexer for selection by label.\n    Series.iloc : Purely integer-location based indexing for\n                   selection by position.\n\n    Examples\n    --------\n    >>> mydict = [{'a': 1, 'b': 2, 'c': 3, 'd': 4},\n    ...           {'a': 100, 'b': 200, 'c': 300, 'd': 400},\n    ...           {'a': 1000, 'b': 2000, 'c': 3000, 'd': 4000 }]\n    >>> df = pd.DataFrame(mydict)\n    >>> df\n          a     b     c     d\n    0     1     2     3     4\n    1   100   200   300   400\n    2  1000  2000  3000  4000\n\n    **Indexing just the rows**\n\n    With a scalar integer.\n\n    >>> type(df.iloc[0])\n    <class 'pandas.core.series.Series'>\n    >>> df.iloc[0]\n    a    1\n    b    2\n    c    3\n    d    4\n    Name: 0, dtype: int64\n\n    With a list of integers.\n\n    >>> df.iloc[[0]]\n       a  b  c  d\n    0  1  2  3  4\n    >>> type(df.iloc[[0]])\n    <class 'pandas.core.frame.DataFrame'>\n\n    >>> df.iloc[[0, 1]]\n         a    b    c    d\n    0    1    2    3    4\n    1  100  200  300  400\n\n    With a `slice` object.\n\n    >>> df.iloc[:3]\n          a     b     c     d\n    0     1     2     3     4\n    1   100   200   300   400\n    2  1000  2000  3000  4000\n\n    With a boolean mask the same length as the index.\n\n    >>> df.iloc[[True, False, True]]\n          a     b     c     d\n    0     1     2     3     4\n    2  1000  2000  3000  4000\n\n    With a callable, useful in method chains. The `x` passed\n    to the ``lambda`` is the DataFrame being sliced. This selects\n    the rows whose index label even.\n\n    >>> df.iloc[lambda x: x.index % 2 == 0]\n          a     b     c     d\n    0     1     2     3     4\n    2  1000  2000  3000  4000\n\n    **Indexing both axes**\n\n    You can mix the indexer types for the index and columns. Use ``:`` to\n    select the entire axis.\n\n    With scalar integers.\n\n    >>> df.iloc[0, 1]\n    2\n\n    With lists of integers.\n\n    >>> df.iloc[[0, 2], [1, 3]]\n          b     d\n    0     2     4\n    2  2000  4000\n\n    With `slice` objects.\n\n    >>> df.iloc[1:3, 0:3]\n          a     b     c\n    1   100   200   300\n    2  1000  2000  3000\n\n    With a boolean array whose length matches the columns.\n\n    >>> df.iloc[:, [True, False, True, False]]\n          a     c\n    0     1     3\n    1   100   300\n    2  1000  3000\n\n    With a callable function that expects the Series or DataFrame.\n\n    >>> df.iloc[:, lambda df: [0, 2]]\n          a     c\n    0     1     3\n    1   100   300\n    2  1000  3000\n    \"\"\"\n    return _iLocIndexer(\"iloc\", self)",
                "@property\ndef loc(self) -> \"_LocIndexer\":\n    \"\"\"\n    Access a group of rows and columns by label(s) or a boolean array.\n\n    ``.loc[]`` is primarily label based, but may also be used with a\n    boolean array.\n\n    Allowed inputs are:\n\n    - A single label, e.g. ``5`` or ``'a'``, (note that ``5`` is\n      interpreted as a *label* of the index, and **never** as an\n      integer position along the index).\n    - A list or array of labels, e.g. ``['a', 'b', 'c']``.\n    - A slice object with labels, e.g. ``'a':'f'``.\n\n      .. warning:: Note that contrary to usual python slices, **both** the\n          start and the stop are included\n\n    - A boolean array of the same length as the axis being sliced,\n      e.g. ``[True, False, True]``.\n    - A ``callable`` function with one argument (the calling Series or\n      DataFrame) and that returns valid output for indexing (one of the above)\n\n    See more at :ref:`Selection by Label <indexing.label>`\n\n    Raises\n    ------\n    KeyError\n        If any items are not found.\n\n    See Also\n    --------\n    DataFrame.at : Access a single value for a row/column label pair.\n    DataFrame.iloc : Access group of rows and columns by integer position(s).\n    DataFrame.xs : Returns a cross-section (row(s) or column(s)) from the\n        Series/DataFrame.\n    Series.loc : Access group of values using labels.\n\n    Examples\n    --------\n    **Getting values**\n\n    >>> df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],\n    ...      index=['cobra', 'viper', 'sidewinder'],\n    ...      columns=['max_speed', 'shield'])\n    >>> df\n                max_speed  shield\n    cobra               1       2\n    viper               4       5\n    sidewinder          7       8\n\n    Single label. Note this returns the row as a Series.\n\n    >>> df.loc['viper']\n    max_speed    4\n    shield       5\n    Name: viper, dtype: int64\n\n    List of labels. Note using ``[[]]`` returns a DataFrame.\n\n    >>> df.loc[['viper', 'sidewinder']]\n                max_speed  shield\n    viper               4       5\n    sidewinder          7       8\n\n    Single label for row and column\n\n    >>> df.loc['cobra', 'shield']\n    2\n\n    Slice with labels for row and single label for column. As mentioned\n    above, note that both the start and stop of the slice are included.\n\n    >>> df.loc['cobra':'viper', 'max_speed']\n    cobra    1\n    viper    4\n    Name: max_speed, dtype: int64\n\n    Boolean list with the same length as the row axis\n\n    >>> df.loc[[False, False, True]]\n                max_speed  shield\n    sidewinder          7       8\n\n    Conditional that returns a boolean Series\n\n    >>> df.loc[df['shield'] > 6]\n                max_speed  shield\n    sidewinder          7       8\n\n    Conditional that returns a boolean Series with column labels specified\n\n    >>> df.loc[df['shield'] > 6, ['max_speed']]\n                max_speed\n    sidewinder          7\n\n    Callable that returns a boolean Series\n\n    >>> df.loc[lambda df: df['shield'] == 8]\n                max_speed  shield\n    sidewinder          7       8\n\n    **Setting values**\n\n    Set value for all items matching the list of labels\n\n    >>> df.loc[['viper', 'sidewinder'], ['shield']] = 50\n    >>> df\n                max_speed  shield\n    cobra               1       2\n    viper               4      50\n    sidewinder          7      50\n\n    Set value for an entire row\n\n    >>> df.loc['cobra'] = 10\n    >>> df\n                max_speed  shield\n    cobra              10      10\n    viper               4      50\n    sidewinder          7      50\n\n    Set value for an entire column\n\n    >>> df.loc[:, 'max_speed'] = 30\n    >>> df\n                max_speed  shield\n    cobra              30      10\n    viper              30      50\n    sidewinder         30      50\n\n    Set value for rows matching callable condition\n\n    >>> df.loc[df['shield'] > 35] = 0\n    >>> df\n                max_speed  shield\n    cobra              30      10\n    viper               0       0\n    sidewinder          0       0\n\n    **Getting values on a DataFrame with an index that has integer labels**\n\n    Another example using integers for the index\n\n    >>> df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],\n    ...      index=[7, 8, 9], columns=['max_speed', 'shield'])\n    >>> df\n       max_speed  shield\n    7          1       2\n    8          4       5\n    9          7       8\n\n    Slice with integer labels for rows. As mentioned above, note that both\n    the start and stop of the slice are included.\n\n    >>> df.loc[7:9]\n       max_speed  shield\n    7          1       2\n    8          4       5\n    9          7       8\n\n    **Getting values with a MultiIndex**\n\n    A number of examples using a DataFrame with a MultiIndex\n\n    >>> tuples = [\n    ...    ('cobra', 'mark i'), ('cobra', 'mark ii'),\n    ...    ('sidewinder', 'mark i'), ('sidewinder', 'mark ii'),\n    ...    ('viper', 'mark ii'), ('viper', 'mark iii')\n    ... ]\n    >>> index = pd.MultiIndex.from_tuples(tuples)\n    >>> values = [[12, 2], [0, 4], [10, 20],\n    ...         [1, 4], [7, 1], [16, 36]]\n    >>> df = pd.DataFrame(values, columns=['max_speed', 'shield'], index=index)\n    >>> df\n                         max_speed  shield\n    cobra      mark i           12       2\n               mark ii           0       4\n    sidewinder mark i           10      20\n               mark ii           1       4\n    viper      mark ii           7       1\n               mark iii         16      36\n\n    Single label. Note this returns a DataFrame with a single index.\n\n    >>> df.loc['cobra']\n             max_speed  shield\n    mark i          12       2\n    mark ii          0       4\n\n    Single index tuple. Note this returns a Series.\n\n    >>> df.loc[('cobra', 'mark ii')]\n    max_speed    0\n    shield       4\n    Name: (cobra, mark ii), dtype: int64\n\n    Single label for row and column. Similar to passing in a tuple, this\n    returns a Series.\n\n    >>> df.loc['cobra', 'mark i']\n    max_speed    12\n    shield        2\n    Name: (cobra, mark i), dtype: int64\n\n    Single tuple. Note using ``[[]]`` returns a DataFrame.\n\n    >>> df.loc[[('cobra', 'mark ii')]]\n                   max_speed  shield\n    cobra mark ii          0       4\n\n    Single tuple for the index with a single label for the column\n\n    >>> df.loc[('cobra', 'mark i'), 'shield']\n    2\n\n    Slice from index tuple to single label\n\n    >>> df.loc[('cobra', 'mark i'):'viper']\n                         max_speed  shield\n    cobra      mark i           12       2\n               mark ii           0       4\n    sidewinder mark i           10      20\n               mark ii           1       4\n    viper      mark ii           7       1\n               mark iii         16      36\n\n    Slice from index tuple to index tuple\n\n    >>> df.loc[('cobra', 'mark i'):('viper', 'mark ii')]\n                        max_speed  shield\n    cobra      mark i          12       2\n               mark ii          0       4\n    sidewinder mark i          10      20\n               mark ii          1       4\n    viper      mark ii          7       1\n    \"\"\"\n    return _LocIndexer(\"loc\", self)",
                "@property\ndef at(self) -> \"_AtIndexer\":\n    \"\"\"\n    Access a single value for a row/column label pair.\n\n    Similar to ``loc``, in that both provide label-based lookups. Use\n    ``at`` if you only need to get or set a single value in a DataFrame\n    or Series.\n\n    Raises\n    ------\n    KeyError\n        If 'label' does not exist in DataFrame.\n\n    See Also\n    --------\n    DataFrame.iat : Access a single value for a row/column pair by integer\n        position.\n    DataFrame.loc : Access a group of rows and columns by label(s).\n    Series.at : Access a single value using a label.\n\n    Examples\n    --------\n    >>> df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],\n    ...                   index=[4, 5, 6], columns=['A', 'B', 'C'])\n    >>> df\n        A   B   C\n    4   0   2   3\n    5   0   4   1\n    6  10  20  30\n\n    Get value at specified row/column pair\n\n    >>> df.at[4, 'B']\n    2\n\n    Set value at specified row/column pair\n\n    >>> df.at[4, 'B'] = 10\n    >>> df.at[4, 'B']\n    10\n\n    Get value within a Series\n\n    >>> df.loc[5].at['B']\n    4\n    \"\"\"\n    return _AtIndexer(\"at\", self)",
                "@property\ndef iat(self) -> \"_iAtIndexer\":\n    \"\"\"\n    Access a single value for a row/column pair by integer position.\n\n    Similar to ``iloc``, in that both provide integer-based lookups. Use\n    ``iat`` if you only need to get or set a single value in a DataFrame\n    or Series.\n\n    Raises\n    ------\n    IndexError\n        When integer position is out of bounds.\n\n    See Also\n    --------\n    DataFrame.at : Access a single value for a row/column label pair.\n    DataFrame.loc : Access a group of rows and columns by label(s).\n    DataFrame.iloc : Access a group of rows and columns by integer position(s).\n\n    Examples\n    --------\n    >>> df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],\n    ...                   columns=['A', 'B', 'C'])\n    >>> df\n        A   B   C\n    0   0   2   3\n    1   0   4   1\n    2  10  20  30\n\n    Get value at specified row/column pair\n\n    >>> df.iat[1, 2]\n    1\n\n    Set value at specified row/column pair\n\n    >>> df.iat[1, 2] = 10\n    >>> df.iat[1, 2]\n    10\n\n    Get value within a series\n\n    >>> df.loc[0].iat[1]\n    2\n    \"\"\"\n    return _iAtIndexer(\"iat\", self)",
                "def __call__(self, axis=None):\n    # we need to return a copy of ourselves\n    new_self = type(self)(self.name, self.obj)\n\n    if axis is not None:\n        axis = self.obj._get_axis_number(axis)\n    new_self.axis = axis\n    return new_self",
                "def _get_setitem_indexer(self, key):\n    \"\"\"\n    Convert a potentially-label-based key into a positional indexer.\n    \"\"\"\n    if self.axis is not None:\n        return self._convert_tuple(key, is_setter=True)\n\n    ax = self.obj._get_axis(0)\n\n    if isinstance(ax, ABCMultiIndex) and self.name != \"iloc\":\n        try:\n            return ax.get_loc(key)\n        except (TypeError, KeyError, InvalidIndexError):\n            # TypeError e.g. passed a bool\n            pass\n\n    if isinstance(key, tuple):\n        try:\n            return self._convert_tuple(key, is_setter=True)\n        except IndexingError:\n            pass\n\n    if isinstance(key, range):\n        return list(key)\n\n    try:\n        return self._convert_to_indexer(key, axis=0, is_setter=True)\n    except TypeError as e:\n\n        # invalid indexer type vs 'other' indexing errors\n        if \"cannot do\" in str(e):\n            raise\n        raise IndexingError(key) from e",
                "def __setitem__(self, key, value):\n    if isinstance(key, tuple):\n        key = tuple(com.apply_if_callable(x, self.obj) for x in key)\n    else:\n        key = com.apply_if_callable(key, self.obj)\n    indexer = self._get_setitem_indexer(key)\n    self._has_valid_setitem_indexer(key)\n\n    iloc = self if self.name == \"iloc\" else self.obj.iloc\n    iloc._setitem_with_indexer(indexer, value)",
                "def _validate_key(self, key, axis: int):\n    \"\"\"\n    Ensure that key is valid for current indexer.\n\n    Parameters\n    ----------\n    key : scalar, slice or list-like\n        Key requested.\n    axis : int\n        Dimension on which the indexing is being made.\n\n    Raises\n    ------\n    TypeError\n        If the key (or some element of it) has wrong type.\n    IndexError\n        If the key (or some element of it) is out of bounds.\n    KeyError\n        If the key was not found.\n    \"\"\"\n    raise AbstractMethodError(self)",
                "def _has_valid_tuple(self, key: Tuple):\n    \"\"\"\n    Check the key for valid keys across my indexer.\n    \"\"\"\n    for i, k in enumerate(key):\n        if i >= self.ndim:\n            raise IndexingError(\"Too many indexers\")\n        try:\n            self._validate_key(k, i)\n        except ValueError as err:\n            raise ValueError(\n                \"Location based indexing can only have \"\n                f\"[{self._valid_types}] types\"\n            ) from err",
                "def _is_nested_tuple_indexer(self, tup: Tuple) -> bool:\n    \"\"\"\n    Returns\n    -------\n    bool\n    \"\"\"\n    if any(isinstance(ax, ABCMultiIndex) for ax in self.obj.axes):\n        return any(is_nested_tuple(tup, ax) for ax in self.obj.axes)\n    return False",
                "def _convert_tuple(self, key, is_setter: bool = False):\n    keyidx = []\n    if self.axis is not None:\n        axis = self.obj._get_axis_number(self.axis)\n        for i in range(self.ndim):\n            if i == axis:\n                keyidx.append(\n                    self._convert_to_indexer(key, axis=axis, is_setter=is_setter)\n                )\n            else:\n                keyidx.append(slice(None))\n    else:\n        for i, k in enumerate(key):\n            if i >= self.ndim:\n                raise IndexingError(\"Too many indexers\")\n            idx = self._convert_to_indexer(k, axis=i, is_setter=is_setter)\n            keyidx.append(idx)\n    return tuple(keyidx)",
                "def _getitem_tuple_same_dim(self, tup: Tuple):\n    \"\"\"\n    Index with indexers that should return an object of the same dimension\n    as self.obj.\n\n    This is only called after a failed call to _getitem_lowerdim.\n    \"\"\"\n    retval = self.obj\n    for i, key in enumerate(tup):\n        if com.is_null_slice(key):\n            continue\n\n        retval = getattr(retval, self.name)._getitem_axis(key, axis=i)\n        # We should never have retval.ndim < self.ndim, as that should\n        #  be handled by the _getitem_lowerdim call above.\n        assert retval.ndim == self.ndim\n\n    return retval",
                "def _getitem_lowerdim(self, tup: Tuple):\n\n    # we can directly get the axis result since the axis is specified\n    if self.axis is not None:\n        axis = self.obj._get_axis_number(self.axis)\n        return self._getitem_axis(tup, axis=axis)\n\n    # we may have a nested tuples indexer here\n    if self._is_nested_tuple_indexer(tup):\n        return self._getitem_nested_tuple(tup)\n\n    # we maybe be using a tuple to represent multiple dimensions here\n    ax0 = self.obj._get_axis(0)\n    # ...but iloc should handle the tuple as simple integer-location\n    # instead of checking it as multiindex representation (GH 13797)\n    if isinstance(ax0, ABCMultiIndex) and self.name != \"iloc\":\n        result = self._handle_lowerdim_multi_index_axis0(tup)\n        if result is not None:\n            return result\n\n    if len(tup) > self.ndim:\n        raise IndexingError(\"Too many indexers. handle elsewhere\")\n\n    for i, key in enumerate(tup):\n        if is_label_like(key):\n            # We don't need to check for tuples here because those are\n            #  caught by the _is_nested_tuple_indexer check above.\n            section = self._getitem_axis(key, axis=i)\n\n            # We should never have a scalar section here, because\n            #  _getitem_lowerdim is only called after a check for\n            #  is_scalar_access, which that would be.\n            if section.ndim == self.ndim:\n                # we're in the middle of slicing through a MultiIndex\n                # revise the key wrt to `section` by inserting an _NS\n                new_key = tup[:i] + (_NS,) + tup[i + 1 :]\n\n            else:\n                # Note: the section.ndim == self.ndim check above\n                #  rules out having DataFrame here, so we dont need to worry\n                #  about transposing.\n                new_key = tup[:i] + tup[i + 1 :]\n\n                if len(new_key) == 1:\n                    new_key = new_key[0]\n\n            # Slices should return views, but calling iloc/loc with a null\n            # slice returns a new object.\n            if com.is_null_slice(new_key):\n                return section\n            # This is an elided recursive call to iloc/loc\n            return getattr(section, self.name)[new_key]\n\n    raise IndexingError(\"not applicable\")",
                "def _getitem_nested_tuple(self, tup: Tuple):\n    # we have a nested tuple so have at least 1 multi-index level\n    # we should be able to match up the dimensionality here\n\n    # we have too many indexers for our dim, but have at least 1\n    # multi-index dimension, try to see if we have something like\n    # a tuple passed to a series with a multi-index\n    if len(tup) > self.ndim:\n        if self.name != \"loc\":\n            # This should never be reached, but lets be explicit about it\n            raise ValueError(\"Too many indices\")\n        result = self._handle_lowerdim_multi_index_axis0(tup)\n        if result is not None:\n            return result\n\n        # this is a series with a multi-index specified a tuple of\n        # selectors\n        axis = self.axis or 0\n        return self._getitem_axis(tup, axis=axis)\n\n    # handle the multi-axis by taking sections and reducing\n    # this is iterative\n    obj = self.obj\n    axis = 0\n    for i, key in enumerate(tup):\n\n        if com.is_null_slice(key):\n            axis += 1\n            continue\n\n        current_ndim = obj.ndim\n        obj = getattr(obj, self.name)._getitem_axis(key, axis=axis)\n        axis += 1\n\n        # if we have a scalar, we are done\n        if is_scalar(obj) or not hasattr(obj, \"ndim\"):\n            break\n\n        # has the dim of the obj changed?\n        # GH 7199\n        if obj.ndim < current_ndim:\n            axis -= 1\n\n    return obj",
                "def _convert_to_indexer(self, key, axis: int, is_setter: bool = False):\n    raise AbstractMethodError(self)",
                "def __getitem__(self, key):\n    if type(key) is tuple:\n        key = tuple(com.apply_if_callable(x, self.obj) for x in key)\n        if self._is_scalar_access(key):\n            try:\n                return self.obj._get_value(*key, takeable=self._takeable)\n            except (KeyError, IndexError, AttributeError):\n                # AttributeError for IntervalTree get_value\n                pass\n        return self._getitem_tuple(key)\n    else:\n        # we by definition only have the 0th axis\n        axis = self.axis or 0\n\n        maybe_callable = com.apply_if_callable(key, self.obj)\n        return self._getitem_axis(maybe_callable, axis=axis)",
                "def _is_scalar_access(self, key: Tuple):\n    raise NotImplementedError()",
                "def _getitem_tuple(self, tup: Tuple):\n    raise AbstractMethodError(self)",
                "def _getitem_axis(self, key, axis: int):\n    raise NotImplementedError()",
                "def _has_valid_setitem_indexer(self, indexer) -> bool:\n    raise AbstractMethodError(self)",
                "def _getbool_axis(self, key, axis: int):\n    # caller is responsible for ensuring non-None axis\n    labels = self.obj._get_axis(axis)\n    key = check_bool_indexer(labels, key)\n    inds = key.nonzero()[0]\n    return self.obj._take_with_is_copy(inds, axis=axis)",
                "@Appender(_LocationIndexer._validate_key.__doc__)\ndef _validate_key(self, key, axis: int):\n\n    # valid for a collection of labels (we check their presence later)\n    # slice of labels (where start-end in labels)\n    # slice of integers (only if in the labels)\n    # boolean\n    pass",
                "def _has_valid_setitem_indexer(self, indexer) -> bool:\n    return True",
                "def _is_scalar_access(self, key: Tuple) -> bool:\n    \"\"\"\n    Returns\n    -------\n    bool\n    \"\"\"\n    # this is a shortcut accessor to both .loc and .iloc\n    # that provide the equivalent access of .at and .iat\n    # a) avoid getting things via sections and (to minimize dtype changes)\n    # b) provide a performant path\n    if len(key) != self.ndim:\n        return False\n\n    for i, k in enumerate(key):\n        if not is_scalar(k):\n            return False\n\n        ax = self.obj.axes[i]\n        if isinstance(ax, ABCMultiIndex):\n            return False\n\n        if isinstance(k, str) and ax._supports_partial_string_indexing:\n            # partial string indexing, df.loc['2000', 'A']\n            # should not be considered scalar\n            return False\n\n        if not ax.is_unique:\n            return False\n\n    return True",
                "def _multi_take_opportunity(self, tup: Tuple) -> bool:\n    \"\"\"\n    Check whether there is the possibility to use ``_multi_take``.\n\n    Currently the limit is that all axes being indexed, must be indexed with\n    list-likes.\n\n    Parameters\n    ----------\n    tup : tuple\n        Tuple of indexers, one per axis.\n\n    Returns\n    -------\n    bool\n        Whether the current indexing,\n        can be passed through `_multi_take`.\n    \"\"\"\n    if not all(is_list_like_indexer(x) for x in tup):\n        return False\n\n    # just too complicated\n    if any(com.is_bool_indexer(x) for x in tup):\n        return False\n\n    return True",
                "def _multi_take(self, tup: Tuple):\n    \"\"\"\n    Create the indexers for the passed tuple of keys, and\n    executes the take operation. This allows the take operation to be\n    executed all at once, rather than once for each dimension.\n    Improving efficiency.\n\n    Parameters\n    ----------\n    tup : tuple\n        Tuple of indexers, one per axis.\n\n    Returns\n    -------\n    values: same type as the object being indexed\n    \"\"\"\n    # GH 836\n    d = {\n        axis: self._get_listlike_indexer(key, axis)\n        for (key, axis) in zip(tup, self.obj._AXIS_ORDERS)\n    }\n    return self.obj._reindex_with_indexers(d, copy=True, allow_dups=True)",
                "def _getitem_iterable(self, key, axis: int):\n    \"\"\"\n    Index current object with an an iterable collection of keys.\n\n    Parameters\n    ----------\n    key : iterable\n        Targeted labels.\n    axis: int\n        Dimension on which the indexing is being made.\n\n    Raises\n    ------\n    KeyError\n        If no key was found. Will change in the future to raise if not all\n        keys were found.\n\n    Returns\n    -------\n    scalar, DataFrame, or Series: indexed value(s).\n    \"\"\"\n    # we assume that not com.is_bool_indexer(key), as that is\n    #  handled before we get here.\n    self._validate_key(key, axis)\n\n    # A collection of keys\n    keyarr, indexer = self._get_listlike_indexer(key, axis, raise_missing=False)\n    return self.obj._reindex_with_indexers(\n        {axis: [keyarr, indexer]}, copy=True, allow_dups=True\n    )",
                "def _getitem_tuple(self, tup: Tuple):\n    try:\n        return self._getitem_lowerdim(tup)\n    except IndexingError:\n        pass\n\n    # no multi-index, so validate all of the indexers\n    self._has_valid_tuple(tup)\n\n    # ugly hack for GH #836\n    if self._multi_take_opportunity(tup):\n        return self._multi_take(tup)\n\n    return self._getitem_tuple_same_dim(tup)",
                "def _get_label(self, label, axis: int):\n    # GH#5667 this will fail if the label is not present in the axis.\n    return self.obj._xs(label, axis=axis)",
                "def _handle_lowerdim_multi_index_axis0(self, tup: Tuple):\n    # we have an axis0 multi-index, handle or raise\n    axis = self.axis or 0\n    try:\n        # fast path for series or for tup devoid of slices\n        return self._get_label(tup, axis=axis)\n    except TypeError:\n        # slices are unhashable\n        pass\n    except KeyError as ek:\n        # raise KeyError if number of indexers match\n        # else IndexingError will be raised\n        if len(tup) <= self.obj.index.nlevels and len(tup) > self.ndim:\n            raise ek\n\n    return None",
                "def _getitem_axis(self, key, axis: int):\n    key = item_from_zerodim(key)\n    if is_iterator(key):\n        key = list(key)\n\n    labels = self.obj._get_axis(axis)\n    key = labels._get_partial_string_timestamp_match_key(key)\n\n    if isinstance(key, slice):\n        self._validate_key(key, axis)\n        return self._get_slice_axis(key, axis=axis)\n    elif com.is_bool_indexer(key):\n        return self._getbool_axis(key, axis=axis)\n    elif is_list_like_indexer(key):\n\n        # convert various list-like indexers\n        # to a list of keys\n        # we will use the *values* of the object\n        # and NOT the index if its a PandasObject\n        if isinstance(labels, ABCMultiIndex):\n\n            if isinstance(key, (ABCSeries, np.ndarray)) and key.ndim <= 1:\n                # Series, or 0,1 ndim ndarray\n                # GH 14730\n                key = list(key)\n            elif isinstance(key, ABCDataFrame):\n                # GH 15438\n                raise NotImplementedError(\n                    \"Indexing a MultiIndex with a \"\n                    \"DataFrame key is not \"\n                    \"implemented\"\n                )\n            elif hasattr(key, \"ndim\") and key.ndim > 1:\n                raise NotImplementedError(\n                    \"Indexing a MultiIndex with a \"\n                    \"multidimensional key is not \"\n                    \"implemented\"\n                )\n\n            if (\n                not isinstance(key, tuple)\n                and len(key)\n                and not isinstance(key[0], tuple)\n            ):\n                key = tuple([key])\n\n        # an iterable multi-selection\n        if not (isinstance(key, tuple) and isinstance(labels, ABCMultiIndex)):\n\n            if hasattr(key, \"ndim\") and key.ndim > 1:\n                raise ValueError(\"Cannot index with multidimensional key\")\n\n            return self._getitem_iterable(key, axis=axis)\n\n        # nested tuple slicing\n        if is_nested_tuple(key, labels):\n            locs = labels.get_locs(key)\n            indexer = [slice(None)] * self.ndim\n            indexer[axis] = locs\n            return self.obj.iloc[tuple(indexer)]\n\n    # fall thru to straight lookup\n    self._validate_key(key, axis)\n    return self._get_label(key, axis=axis)",
                "def _get_slice_axis(self, slice_obj: slice, axis: int):\n    \"\"\"\n    This is pretty simple as we just have to deal with labels.\n    \"\"\"\n    # caller is responsible for ensuring non-None axis\n    obj = self.obj\n    if not need_slice(slice_obj):\n        return obj.copy(deep=False)\n\n    labels = obj._get_axis(axis)\n    indexer = labels.slice_indexer(\n        slice_obj.start, slice_obj.stop, slice_obj.step, kind=\"loc\"\n    )\n\n    if isinstance(indexer, slice):\n        return self.obj._slice(indexer, axis=axis)\n    else:\n        # DatetimeIndex overrides Index.slice_indexer and may\n        #  return a DatetimeIndex instead of a slice object.\n        return self.obj.take(indexer, axis=axis)",
                "def _convert_to_indexer(self, key, axis: int, is_setter: bool = False):\n    \"\"\"\n    Convert indexing key into something we can use to do actual fancy\n    indexing on a ndarray.\n\n    Examples\n    ix[:5] -> slice(0, 5)\n    ix[[1,2,3]] -> [1,2,3]\n    ix[['foo', 'bar', 'baz']] -> [i, j, k] (indices of foo, bar, baz)\n\n    Going by Zen of Python?\n    'In the face of ambiguity, refuse the temptation to guess.'\n    raise AmbiguousIndexError with integer labels?\n    - No, prefer label-based indexing\n    \"\"\"\n    labels = self.obj._get_axis(axis)\n\n    if isinstance(key, slice):\n        return labels._convert_slice_indexer(key, kind=\"loc\")\n\n    # see if we are positional in nature\n    is_int_index = labels.is_integer()\n    is_int_positional = is_integer(key) and not is_int_index\n\n    if is_scalar(key) or isinstance(labels, ABCMultiIndex):\n        # Otherwise get_loc will raise InvalidIndexError\n\n        # if we are a label return me\n        try:\n            return labels.get_loc(key)\n        except LookupError:\n            if isinstance(key, tuple) and isinstance(labels, ABCMultiIndex):\n                if len(key) == labels.nlevels:\n                    return {\"key\": key}\n                raise\n        except TypeError:\n            pass\n        except ValueError:\n            if not is_int_positional:\n                raise\n\n    # a positional\n    if is_int_positional:\n\n        # if we are setting and its not a valid location\n        # its an insert which fails by definition\n\n        # always valid\n        return {\"key\": key}\n\n    if is_nested_tuple(key, labels):\n        return labels.get_locs(key)\n\n    elif is_list_like_indexer(key):\n\n        if com.is_bool_indexer(key):\n            key = check_bool_indexer(labels, key)\n            (inds,) = key.nonzero()\n            return inds\n        else:\n            # When setting, missing keys are not allowed, even with .loc:\n            return self._get_listlike_indexer(key, axis, raise_missing=True)[1]\n    else:\n        try:\n            return labels.get_loc(key)\n        except LookupError:\n            # allow a not found key only if we are a setter\n            if not is_list_like_indexer(key):\n                return {\"key\": key}\n            raise",
                "def _get_listlike_indexer(self, key, axis: int, raise_missing: bool = False):\n    \"\"\"\n    Transform a list-like of keys into a new index and an indexer.\n\n    Parameters\n    ----------\n    key : list-like\n        Targeted labels.\n    axis: int\n        Dimension on which the indexing is being made.\n    raise_missing: bool, default False\n        Whether to raise a KeyError if some labels were not found.\n        Will be removed in the future, and then this method will always behave as\n        if ``raise_missing=True``.\n\n    Raises\n    ------\n    KeyError\n        If at least one key was requested but none was found, and\n        raise_missing=True.\n\n    Returns\n    -------\n    keyarr: Index\n        New index (coinciding with 'key' if the axis is unique).\n    values : array-like\n        Indexer for the return object, -1 denotes keys not found.\n    \"\"\"\n    ax = self.obj._get_axis(axis)\n\n    # Have the index compute an indexer or return None\n    # if it cannot handle:\n    indexer, keyarr = ax._convert_listlike_indexer(key)\n    # We only act on all found values:\n    if indexer is not None and (indexer != -1).all():\n        self._validate_read_indexer(key, indexer, axis, raise_missing=raise_missing)\n        return ax[indexer], indexer\n\n    if ax.is_unique and not getattr(ax, \"is_overlapping\", False):\n        indexer = ax.get_indexer_for(key)\n        keyarr = ax.reindex(keyarr)[0]\n    else:\n        keyarr, indexer, new_indexer = ax._reindex_non_unique(keyarr)\n\n    self._validate_read_indexer(keyarr, indexer, axis, raise_missing=raise_missing)\n    return keyarr, indexer",
                "def _validate_read_indexer(\n    self, key, indexer, axis: int, raise_missing: bool = False\n):\n    \"\"\"\n    Check that indexer can be used to return a result.\n\n    e.g. at least one element was found,\n    unless the list of keys was actually empty.\n\n    Parameters\n    ----------\n    key : list-like\n        Targeted labels (only used to show correct error message).\n    indexer: array-like of booleans\n        Indices corresponding to the key,\n        (with -1 indicating not found).\n    axis: int\n        Dimension on which the indexing is being made.\n    raise_missing: bool\n        Whether to raise a KeyError if some labels are not found. Will be\n        removed in the future, and then this method will always behave as\n        if raise_missing=True.\n\n    Raises\n    ------\n    KeyError\n        If at least one key was requested but none was found, and\n        raise_missing=True.\n    \"\"\"\n    ax = self.obj._get_axis(axis)\n\n    if len(key) == 0:\n        return\n\n    # Count missing values:\n    missing = (indexer < 0).sum()\n\n    if missing:\n        if missing == len(indexer):\n            axis_name = self.obj._get_axis_name(axis)\n            raise KeyError(f\"None of [{key}] are in the [{axis_name}]\")\n\n        # We (temporarily) allow for some missing keys with .loc, except in\n        # some cases (e.g. setting) in which \"raise_missing\" will be False\n        if raise_missing:\n            not_found = list(set(key) - set(ax))\n            raise KeyError(f\"{not_found} not in index\")\n\n        # we skip the warning on Categorical\n        # as this check is actually done (check for\n        # non-missing values), but a bit later in the\n        # code, so we want to avoid warning & then\n        # just raising\n        if not ax.is_categorical():\n            raise KeyError(\n                \"Passing list-likes to .loc or [] with any missing labels \"\n                \"is no longer supported, see \"\n                \"https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\"  # noqa:E501\n            )",
                "def _validate_key(self, key, axis: int):\n    if com.is_bool_indexer(key):\n        if hasattr(key, \"index\") and isinstance(key.index, Index):\n            if key.index.inferred_type == \"integer\":\n                raise NotImplementedError(\n                    \"iLocation based boolean \"\n                    \"indexing on an integer type \"\n                    \"is not available\"\n                )\n            raise ValueError(\n                \"iLocation based boolean indexing cannot use \"\n                \"an indexable as a mask\"\n            )\n        return\n\n    if isinstance(key, slice):\n        return\n    elif is_integer(key):\n        self._validate_integer(key, axis)\n    elif isinstance(key, tuple):\n        # a tuple should already have been caught by this point\n        # so don't treat a tuple as a valid indexer\n        raise IndexingError(\"Too many indexers\")\n    elif is_list_like_indexer(key):\n        arr = np.array(key)\n        len_axis = len(self.obj._get_axis(axis))\n\n        # check that the key has a numeric dtype\n        if not is_numeric_dtype(arr.dtype):\n            raise IndexError(f\".iloc requires numeric indexers, got {arr}\")\n\n        # check that the key does not exceed the maximum size of the index\n        if len(arr) and (arr.max() >= len_axis or arr.min() < -len_axis):\n            raise IndexError(\"positional indexers are out-of-bounds\")\n    else:\n        raise ValueError(f\"Can only index by location with a [{self._valid_types}]\")",
                "def _has_valid_setitem_indexer(self, indexer) -> bool:\n    \"\"\"\n    Validate that a positional indexer cannot enlarge its target\n    will raise if needed, does not modify the indexer externally.\n\n    Returns\n    -------\n    bool\n    \"\"\"\n    if isinstance(indexer, dict):\n        raise IndexError(\"iloc cannot enlarge its target object\")\n    else:\n        if not isinstance(indexer, tuple):\n            indexer = _tuplify(self.ndim, indexer)\n        for ax, i in zip(self.obj.axes, indexer):\n            if isinstance(i, slice):\n                # should check the stop slice?\n                pass\n            elif is_list_like_indexer(i):\n                # should check the elements?\n                pass\n            elif is_integer(i):\n                if i >= len(ax):\n                    raise IndexError(\"iloc cannot enlarge its target object\")\n            elif isinstance(i, dict):\n                raise IndexError(\"iloc cannot enlarge its target object\")\n\n    return True",
                "def _is_scalar_access(self, key: Tuple) -> bool:\n    \"\"\"\n    Returns\n    -------\n    bool\n    \"\"\"\n    # this is a shortcut accessor to both .loc and .iloc\n    # that provide the equivalent access of .at and .iat\n    # a) avoid getting things via sections and (to minimize dtype changes)\n    # b) provide a performant path\n    if len(key) != self.ndim:\n        return False\n\n    for i, k in enumerate(key):\n        if not is_integer(k):\n            return False\n\n    return True",
                "def _validate_integer(self, key: int, axis: int) -> None:\n    \"\"\"\n    Check that 'key' is a valid position in the desired axis.\n\n    Parameters\n    ----------\n    key : int\n        Requested position.\n    axis : int\n        Desired axis.\n\n    Raises\n    ------\n    IndexError\n        If 'key' is not a valid position in axis 'axis'.\n    \"\"\"\n    len_axis = len(self.obj._get_axis(axis))\n    if key >= len_axis or key < -len_axis:\n        raise IndexError(\"single positional indexer is out-of-bounds\")",
                "def _getitem_tuple(self, tup: Tuple):\n\n    self._has_valid_tuple(tup)\n    try:\n        return self._getitem_lowerdim(tup)\n    except IndexingError:\n        pass\n\n    return self._getitem_tuple_same_dim(tup)",
                "def _get_list_axis(self, key, axis: int):\n    \"\"\"\n    Return Series values by list or array of integers.\n\n    Parameters\n    ----------\n    key : list-like positional indexer\n    axis : int\n\n    Returns\n    -------\n    Series object\n\n    Notes\n    -----\n    `axis` can only be zero.\n    \"\"\"\n    try:\n        return self.obj._take_with_is_copy(key, axis=axis)\n    except IndexError as err:\n        # re-raise with different error message\n        raise IndexError(\"positional indexers are out-of-bounds\") from err",
                "def _getitem_axis(self, key, axis: int):\n    if isinstance(key, slice):\n        return self._get_slice_axis(key, axis=axis)\n\n    if isinstance(key, list):\n        key = np.asarray(key)\n\n    if com.is_bool_indexer(key):\n        self._validate_key(key, axis)\n        return self._getbool_axis(key, axis=axis)\n\n    # a list of integers\n    elif is_list_like_indexer(key):\n        return self._get_list_axis(key, axis=axis)\n\n    # a single integer\n    else:\n        key = item_from_zerodim(key)\n        if not is_integer(key):\n            raise TypeError(\"Cannot index by location index with a non-integer key\")\n\n        # validate the location\n        self._validate_integer(key, axis)\n\n        return self.obj._ixs(key, axis=axis)",
                "def _get_slice_axis(self, slice_obj: slice, axis: int):\n    # caller is responsible for ensuring non-None axis\n    obj = self.obj\n\n    if not need_slice(slice_obj):\n        return obj.copy(deep=False)\n\n    labels = obj._get_axis(axis)\n    labels._validate_positional_slice(slice_obj)\n    return self.obj._slice(slice_obj, axis=axis)",
                "def _convert_to_indexer(self, key, axis: int, is_setter: bool = False):\n    \"\"\"\n    Much simpler as we only have to deal with our valid types.\n    \"\"\"\n    return key",
                "def _get_setitem_indexer(self, key):\n    # GH#32257 Fall through to let numnpy do validation\n    return key",
                "def _setitem_with_indexer(self, indexer, value):\n    \"\"\"\n    _setitem_with_indexer is for setting values on a Series/DataFrame\n    using positional indexers.\n\n    If the relevant keys are not present, the Series/DataFrame may be\n    expanded.\n\n    This method is currently broken when dealing with non-unique Indexes,\n    since it goes from positional indexers back to labels when calling\n    BlockManager methods, see GH#12991, GH#22046, GH#15686.\n    \"\"\"\n\n    # also has the side effect of consolidating in-place\n    from pandas import Series\n\n    info_axis = self.obj._info_axis_number\n\n    # maybe partial set\n    take_split_path = self.obj._is_mixed_type\n\n    # if there is only one block/type, still have to take split path\n    # unless the block is one-dimensional or it can hold the value\n    if not take_split_path and self.obj._data.blocks:\n        (blk,) = self.obj._data.blocks\n        if 1 < blk.ndim:  # in case of dict, keys are indices\n            val = list(value.values()) if isinstance(value, dict) else value\n            take_split_path = not blk._can_hold_element(val)\n\n    # if we have any multi-indexes that have non-trivial slices\n    # (not null slices) then we must take the split path, xref\n    # GH 10360, GH 27841\n    if isinstance(indexer, tuple) and len(indexer) == len(self.obj.axes):\n        for i, ax in zip(indexer, self.obj.axes):\n            if isinstance(ax, ABCMultiIndex) and not (\n                is_integer(i) or com.is_null_slice(i)\n            ):\n                take_split_path = True\n                break\n\n    if isinstance(indexer, tuple):\n        nindexer = []\n        for i, idx in enumerate(indexer):\n            if isinstance(idx, dict):\n\n                # reindex the axis to the new value\n                # and set inplace\n                key, _ = convert_missing_indexer(idx)\n\n                # if this is the items axes, then take the main missing\n                # path first\n                # this correctly sets the dtype and avoids cache issues\n                # essentially this separates out the block that is needed\n                # to possibly be modified\n                if self.ndim > 1 and i == info_axis:\n\n                    # add the new item, and set the value\n                    # must have all defined axes if we have a scalar\n                    # or a list-like on the non-info axes if we have a\n                    # list-like\n                    len_non_info_axes = (\n                        len(_ax) for _i, _ax in enumerate(self.obj.axes) if _i != i\n                    )\n                    if any(not l for l in len_non_info_axes):\n                        if not is_list_like_indexer(value):\n                            raise ValueError(\n                                \"cannot set a frame with no \"\n                                \"defined index and a scalar\"\n                            )\n                        self.obj[key] = value\n                        return\n\n                    # add a new item with the dtype setup\n                    self.obj[key] = _infer_fill_value(value)\n\n                    new_indexer = convert_from_missing_indexer_tuple(\n                        indexer, self.obj.axes\n                    )\n                    self._setitem_with_indexer(new_indexer, value)\n\n                    return\n\n                # reindex the axis\n                # make sure to clear the cache because we are\n                # just replacing the block manager here\n                # so the object is the same\n                index = self.obj._get_axis(i)\n                labels = index.insert(len(index), key)\n                self.obj._data = self.obj.reindex(labels, axis=i)._data\n                self.obj._maybe_update_cacher(clear=True)\n                self.obj._is_copy = None\n\n                nindexer.append(labels.get_loc(key))\n\n            else:\n                nindexer.append(idx)\n\n        indexer = tuple(nindexer)\n    else:\n\n        indexer, missing = convert_missing_indexer(indexer)\n\n        if missing:\n            self._setitem_with_indexer_missing(indexer, value)\n            return\n\n    # set\n    item_labels = self.obj._get_axis(info_axis)\n\n    # align and set the values\n    if take_split_path:\n        # Above we only set take_split_path to True for 2D cases\n        assert self.ndim == 2\n        assert info_axis == 1\n\n        if not isinstance(indexer, tuple):\n            indexer = _tuplify(self.ndim, indexer)\n\n        if isinstance(value, ABCSeries):\n            value = self._align_series(indexer, value)\n\n        info_idx = indexer[info_axis]\n        if is_integer(info_idx):\n            info_idx = [info_idx]\n        labels = item_labels[info_idx]\n\n        # Ensure we have something we can iterate over\n        ilocs = info_idx\n        if isinstance(info_idx, slice):\n            ri = Index(range(len(self.obj.columns)))\n            ilocs = ri[info_idx]\n\n        plane_indexer = indexer[:1]\n        lplane_indexer = length_of_indexer(plane_indexer[0], self.obj.index)\n        # lplane_indexer gives the expected length of obj[indexer[0]]\n\n        if len(labels) == 1:\n            # We can operate on a single column\n\n            # require that we are setting the right number of values that\n            # we are indexing\n            if is_list_like_indexer(value) and 0 != lplane_indexer != len(value):\n                # Exclude zero-len for e.g. boolean masking that is all-false\n                raise ValueError(\n                    \"cannot set using a multi-index \"\n                    \"selection indexer with a different \"\n                    \"length than the value\"\n                )\n\n        pi = plane_indexer[0] if lplane_indexer == 1 else plane_indexer\n\n        def isetter(loc, v):\n            # positional setting on column loc\n            ser = self.obj._ixs(loc, axis=1)\n\n            # perform the equivalent of a setitem on the info axis\n            # as we have a null slice or a slice with full bounds\n            # which means essentially reassign to the columns of a\n            # multi-dim object\n            # GH6149 (null slice), GH10408 (full bounds)\n            if isinstance(pi, tuple) and all(\n                com.is_null_slice(idx) or com.is_full_slice(idx, len(self.obj))\n                for idx in pi\n            ):\n                ser = v\n            else:\n                # set the item, possibly having a dtype change\n                ser._consolidate_inplace()\n                ser = ser.copy()\n                ser._data = ser._data.setitem(indexer=pi, value=v)\n                ser._maybe_update_cacher(clear=True)\n\n            # reset the sliced object if unique\n            self.obj._iset_item(loc, ser)\n\n        # we need an iterable, with a ndim of at least 1\n        # eg. don't pass through np.array(0)\n        if is_list_like_indexer(value) and getattr(value, \"ndim\", 1) > 0:\n\n            # we have an equal len Frame\n            if isinstance(value, ABCDataFrame):\n                sub_indexer = list(indexer)\n                multiindex_indexer = isinstance(labels, ABCMultiIndex)\n                # TODO: we are implicitly assuming value.columns is unique\n\n                for loc in ilocs:\n                    item = item_labels[loc]\n                    if item in value:\n                        sub_indexer[info_axis] = item\n                        v = self._align_series(\n                            tuple(sub_indexer), value[item], multiindex_indexer\n                        )\n                    else:\n                        v = np.nan\n\n                    isetter(loc, v)\n\n            # we have an equal len ndarray/convertible to our labels\n            # hasattr first, to avoid coercing to ndarray without reason.\n            # But we may be relying on the ndarray coercion to check ndim.\n            # Why not just convert to an ndarray earlier on if needed?\n            elif np.ndim(value) == 2:\n\n                # note that this coerces the dtype if we are mixed\n                # GH 7551\n                value = np.array(value, dtype=object)\n                if len(ilocs) != value.shape[1]:\n                    raise ValueError(\n                        \"Must have equal len keys and value \"\n                        \"when setting with an ndarray\"\n                    )\n\n                for i, loc in enumerate(ilocs):\n                    # setting with a list, re-coerces\n                    isetter(loc, value[:, i].tolist())\n\n            elif (\n                len(labels) == 1\n                and lplane_indexer == len(value)\n                and not is_scalar(plane_indexer[0])\n            ):\n                # we have an equal len list/ndarray\n                # We only get here with len(labels) == len(ilocs) == 1\n                isetter(ilocs[0], value)\n\n            elif lplane_indexer == 0 and len(value) == len(self.obj.index):\n                # We get here in one case via .loc with a all-False mask\n                pass\n\n            else:\n                # per-label values\n                if len(ilocs) != len(value):\n                    raise ValueError(\n                        \"Must have equal len keys and value \"\n                        \"when setting with an iterable\"\n                    )\n\n                for loc, v in zip(ilocs, value):\n                    isetter(loc, v)\n        else:\n\n            # scalar value\n            for loc in ilocs:\n                isetter(loc, value)\n\n    else:\n        if isinstance(indexer, tuple):\n\n            # if we are setting on the info axis ONLY\n            # set using those methods to avoid block-splitting\n            # logic here\n            if (\n                len(indexer) > info_axis\n                and is_integer(indexer[info_axis])\n                and all(\n                    com.is_null_slice(idx)\n                    for i, idx in enumerate(indexer)\n                    if i != info_axis\n                )\n                and item_labels.is_unique\n            ):\n                self.obj[item_labels[indexer[info_axis]]] = value\n                return\n\n            indexer = maybe_convert_ix(*indexer)\n\n        if isinstance(value, (ABCSeries, dict)):\n            # TODO(EA): ExtensionBlock.setitem this causes issues with\n            # setting for extensionarrays that store dicts. Need to decide\n            # if it's worth supporting that.\n            value = self._align_series(indexer, Series(value))\n\n        elif isinstance(value, ABCDataFrame):\n            value = self._align_frame(indexer, value)\n\n        # check for chained assignment\n        self.obj._check_is_chained_assignment_possible()\n\n        # actually do the set\n        self.obj._consolidate_inplace()\n        self.obj._data = self.obj._data.setitem(indexer=indexer, value=value)\n        self.obj._maybe_update_cacher(clear=True)",
                "def _setitem_with_indexer_missing(self, indexer, value):\n    \"\"\"\n    Insert new row(s) or column(s) into the Series or DataFrame.\n    \"\"\"\n    from pandas import Series\n\n    # reindex the axis to the new value\n    # and set inplace\n    if self.ndim == 1:\n        index = self.obj.index\n        new_index = index.insert(len(index), indexer)\n\n        # we have a coerced indexer, e.g. a float\n        # that matches in an Int64Index, so\n        # we will not create a duplicate index, rather\n        # index to that element\n        # e.g. 0.0 -> 0\n        # GH#12246\n        if index.is_unique:\n            new_indexer = index.get_indexer([new_index[-1]])\n            if (new_indexer != -1).any():\n                return self._setitem_with_indexer(new_indexer, value)\n\n        # this preserves dtype of the value\n        new_values = Series([value])._values\n        if len(self.obj._values):\n            # GH#22717 handle casting compatibility that np.concatenate\n            #  does incorrectly\n            new_values = concat_compat([self.obj._values, new_values])\n        self.obj._data = self.obj._constructor(\n            new_values, index=new_index, name=self.obj.name\n        )._data\n        self.obj._maybe_update_cacher(clear=True)\n\n    elif self.ndim == 2:\n\n        if not len(self.obj.columns):\n            # no columns and scalar\n            raise ValueError(\"cannot set a frame with no defined columns\")\n\n        if isinstance(value, ABCSeries):\n            # append a Series\n            value = value.reindex(index=self.obj.columns, copy=True)\n            value.name = indexer\n\n        else:\n            # a list-list\n            if is_list_like_indexer(value):\n                # must have conforming columns\n                if len(value) != len(self.obj.columns):\n                    raise ValueError(\"cannot set a row with mismatched columns\")\n\n            value = Series(value, index=self.obj.columns, name=indexer)\n\n        self.obj._data = self.obj.append(value)._data\n        self.obj._maybe_update_cacher(clear=True)",
                "def _align_series(self, indexer, ser: ABCSeries, multiindex_indexer: bool = False):\n    \"\"\"\n    Parameters\n    ----------\n    indexer : tuple, slice, scalar\n        Indexer used to get the locations that will be set to `ser`.\n    ser : pd.Series\n        Values to assign to the locations specified by `indexer`.\n    multiindex_indexer : boolean, optional\n        Defaults to False. Should be set to True if `indexer` was from\n        a `pd.MultiIndex`, to avoid unnecessary broadcasting.\n\n    Returns\n    -------\n    `np.array` of `ser` broadcast to the appropriate shape for assignment\n    to the locations selected by `indexer`\n    \"\"\"\n    if isinstance(indexer, (slice, np.ndarray, list, Index)):\n        indexer = tuple([indexer])\n\n    if isinstance(indexer, tuple):\n\n        # flatten np.ndarray indexers\n        def ravel(i):\n            return i.ravel() if isinstance(i, np.ndarray) else i\n\n        indexer = tuple(map(ravel, indexer))\n\n        aligners = [not com.is_null_slice(idx) for idx in indexer]\n        sum_aligners = sum(aligners)\n        single_aligner = sum_aligners == 1\n        is_frame = self.ndim == 2\n        obj = self.obj\n\n        # are we a single alignable value on a non-primary\n        # dim (e.g. panel: 1,2, or frame: 0) ?\n        # hence need to align to a single axis dimension\n        # rather that find all valid dims\n\n        # frame\n        if is_frame:\n            single_aligner = single_aligner and aligners[0]\n\n        # we have a frame, with multiple indexers on both axes; and a\n        # series, so need to broadcast (see GH5206)\n        if sum_aligners == self.ndim and all(is_sequence(_) for _ in indexer):\n            ser = ser.reindex(obj.axes[0][indexer[0]], copy=True)._values\n\n            # single indexer\n            if len(indexer) > 1 and not multiindex_indexer:\n                len_indexer = len(indexer[1])\n                ser = np.tile(ser, len_indexer).reshape(len_indexer, -1).T\n\n            return ser\n\n        for i, idx in enumerate(indexer):\n            ax = obj.axes[i]\n\n            # multiple aligners (or null slices)\n            if is_sequence(idx) or isinstance(idx, slice):\n                if single_aligner and com.is_null_slice(idx):\n                    continue\n                new_ix = ax[idx]\n                if not is_list_like_indexer(new_ix):\n                    new_ix = Index([new_ix])\n                else:\n                    new_ix = Index(new_ix)\n                if ser.index.equals(new_ix) or not len(new_ix):\n                    return ser._values.copy()\n\n                return ser.reindex(new_ix)._values\n\n            # 2 dims\n            elif single_aligner:\n\n                # reindex along index\n                ax = self.obj.axes[1]\n                if ser.index.equals(ax) or not len(ax):\n                    return ser._values.copy()\n                return ser.reindex(ax)._values\n\n    elif is_scalar(indexer):\n        ax = self.obj._get_axis(1)\n\n        if ser.index.equals(ax):\n            return ser._values.copy()\n\n        return ser.reindex(ax)._values\n\n    raise ValueError(\"Incompatible indexer with Series\")",
                "def _align_frame(self, indexer, df: ABCDataFrame):\n    is_frame = self.ndim == 2\n\n    if isinstance(indexer, tuple):\n\n        idx, cols = None, None\n        sindexers = []\n        for i, ix in enumerate(indexer):\n            ax = self.obj.axes[i]\n            if is_sequence(ix) or isinstance(ix, slice):\n                if isinstance(ix, np.ndarray):\n                    ix = ix.ravel()\n                if idx is None:\n                    idx = ax[ix]\n                elif cols is None:\n                    cols = ax[ix]\n                else:\n                    break\n            else:\n                sindexers.append(i)\n\n        if idx is not None and cols is not None:\n\n            if df.index.equals(idx) and df.columns.equals(cols):\n                val = df.copy()._values\n            else:\n                val = df.reindex(idx, columns=cols)._values\n            return val\n\n    elif (isinstance(indexer, slice) or is_list_like_indexer(indexer)) and is_frame:\n        ax = self.obj.index[indexer]\n        if df.index.equals(ax):\n            val = df.copy()._values\n        else:\n\n            # we have a multi-index and are trying to align\n            # with a particular, level GH3738\n            if (\n                isinstance(ax, ABCMultiIndex)\n                and isinstance(df.index, ABCMultiIndex)\n                and ax.nlevels != df.index.nlevels\n            ):\n                raise TypeError(\n                    \"cannot align on a multi-index with out \"\n                    \"specifying the join levels\"\n                )\n\n            val = df.reindex(index=ax)._values\n        return val\n\n    raise ValueError(\"Incompatible indexer with DataFrame\")",
                "def _convert_key(self, key, is_setter: bool = False):\n    raise AbstractMethodError(self)",
                "def __getitem__(self, key):\n    if not isinstance(key, tuple):\n\n        # we could have a convertible item here (e.g. Timestamp)\n        if not is_list_like_indexer(key):\n            key = tuple([key])\n        else:\n            raise ValueError(\"Invalid call for scalar access (getting)!\")\n\n    key = self._convert_key(key)\n    return self.obj._get_value(*key, takeable=self._takeable)",
                "def __setitem__(self, key, value):\n    if isinstance(key, tuple):\n        key = tuple(com.apply_if_callable(x, self.obj) for x in key)\n    else:\n        # scalar callable may return tuple\n        key = com.apply_if_callable(key, self.obj)\n\n    if not isinstance(key, tuple):\n        key = _tuplify(self.ndim, key)\n    if len(key) != self.ndim:\n        raise ValueError(\"Not enough indexers for scalar access (setting)!\")\n    key = list(self._convert_key(key, is_setter=True))\n    self.obj._set_value(*key, value=value, takeable=self._takeable)",
                "def _convert_key(self, key, is_setter: bool = False):\n    \"\"\"\n    Require they keys to be the same type as the index. (so we don't\n    fallback)\n    \"\"\"\n    # allow arbitrary setting\n    if is_setter:\n        return list(key)\n\n    return key",
                "def __getitem__(self, key):\n    if self.ndim != 1 or not is_scalar(key):\n        # FIXME: is_scalar check is a kludge\n        return super().__getitem__(key)\n\n    # Like Index.get_value, but we do not allow positional fallback\n    obj = self.obj\n    loc = obj.index.get_loc(key)\n    return obj.index._get_values_for_loc(obj, loc, key)",
                "def _convert_key(self, key, is_setter: bool = False):\n    \"\"\"\n    Require integer args. (and convert to label arguments)\n    \"\"\"\n    for a, i in zip(self.obj.axes, key):\n        if not is_integer(i):\n            raise ValueError(\"iAt based indexing can only have integer indexers\")\n    return key",
                "def get_indexer(_i, _idx):\n    return axes[_i].get_loc(_idx[\"key\"]) if isinstance(_idx, dict) else _idx",
                "def pred(part) -> bool:\n    \"\"\"\n    Returns\n    -------\n    bool\n        True if slice does *not* reduce,\n        False if `part` is a tuple.\n    \"\"\"\n    # true when slice does *not* reduce, False when part is a tuple,\n    # i.e. MultiIndex slice\n    return (isinstance(part, slice) or is_list_like(part)) and not isinstance(\n        part, tuple\n    )",
                "def isetter(loc, v):\n    # positional setting on column loc\n    ser = self.obj._ixs(loc, axis=1)\n\n    # perform the equivalent of a setitem on the info axis\n    # as we have a null slice or a slice with full bounds\n    # which means essentially reassign to the columns of a\n    # multi-dim object\n    # GH6149 (null slice), GH10408 (full bounds)\n    if isinstance(pi, tuple) and all(\n        com.is_null_slice(idx) or com.is_full_slice(idx, len(self.obj))\n        for idx in pi\n    ):\n        ser = v\n    else:\n        # set the item, possibly having a dtype change\n        ser._consolidate_inplace()\n        ser = ser.copy()\n        ser._data = ser._data.setitem(indexer=pi, value=v)\n        ser._maybe_update_cacher(clear=True)\n\n    # reset the sliced object if unique\n    self.obj._iset_item(loc, ser)",
                "def ravel(i):\n    return i.ravel() if isinstance(i, np.ndarray) else i"
            ],
            "inscope_function_signatures": [
                "_tuplify(ndim: int, loc: Hashable) -> Tuple[Union[Hashable, slice], ...]",
                "convert_to_index_sliceable(obj, key)",
                "check_bool_indexer(index: Index, key) -> np.ndarray",
                "convert_missing_indexer(indexer)",
                "convert_from_missing_indexer_tuple(indexer, axes)",
                "maybe_convert_ix(*args)",
                "is_nested_tuple(tup, labels) -> bool",
                "is_label_like(key) -> bool",
                "need_slice(obj) -> bool",
                "_non_reducing_slice(slice_)",
                "_maybe_numeric_slice(df, slice_, include_bool=False)",
                "__getitem__(self, arg)",
                "iloc(self) -> '_iLocIndexer'",
                "loc(self) -> '_LocIndexer'",
                "at(self) -> '_AtIndexer'",
                "iat(self) -> '_iAtIndexer'",
                "__call__(self, axis=None)",
                "_get_setitem_indexer(self, key)",
                "__setitem__(self, key, value)",
                "_validate_key(self, key, axis: int)",
                "_has_valid_tuple(self, key: Tuple)",
                "_is_nested_tuple_indexer(self, tup: Tuple) -> bool",
                "_convert_tuple(self, key, is_setter: bool=False)",
                "_getitem_tuple_same_dim(self, tup: Tuple)",
                "_getitem_lowerdim(self, tup: Tuple)",
                "_getitem_nested_tuple(self, tup: Tuple)",
                "_convert_to_indexer(self, key, axis: int, is_setter: bool=False)",
                "__getitem__(self, key)",
                "_is_scalar_access(self, key: Tuple)",
                "_getitem_tuple(self, tup: Tuple)",
                "_getitem_axis(self, key, axis: int)",
                "_has_valid_setitem_indexer(self, indexer) -> bool",
                "_getbool_axis(self, key, axis: int)",
                "_validate_key(self, key, axis: int)",
                "_has_valid_setitem_indexer(self, indexer) -> bool",
                "_is_scalar_access(self, key: Tuple) -> bool",
                "_multi_take_opportunity(self, tup: Tuple) -> bool",
                "_multi_take(self, tup: Tuple)",
                "_getitem_iterable(self, key, axis: int)",
                "_getitem_tuple(self, tup: Tuple)",
                "_get_label(self, label, axis: int)",
                "_handle_lowerdim_multi_index_axis0(self, tup: Tuple)",
                "_getitem_axis(self, key, axis: int)",
                "_get_slice_axis(self, slice_obj: slice, axis: int)",
                "_convert_to_indexer(self, key, axis: int, is_setter: bool=False)",
                "_get_listlike_indexer(self, key, axis: int, raise_missing: bool=False)",
                "_validate_read_indexer(self, key, indexer, axis: int, raise_missing: bool=False)",
                "_validate_key(self, key, axis: int)",
                "_has_valid_setitem_indexer(self, indexer) -> bool",
                "_is_scalar_access(self, key: Tuple) -> bool",
                "_validate_integer(self, key: int, axis: int) -> None",
                "_getitem_tuple(self, tup: Tuple)",
                "_get_list_axis(self, key, axis: int)",
                "_getitem_axis(self, key, axis: int)",
                "_get_slice_axis(self, slice_obj: slice, axis: int)",
                "_convert_to_indexer(self, key, axis: int, is_setter: bool=False)",
                "_get_setitem_indexer(self, key)",
                "_setitem_with_indexer(self, indexer, value)",
                "_setitem_with_indexer_missing(self, indexer, value)",
                "_align_series(self, indexer, ser: ABCSeries, multiindex_indexer: bool=False)",
                "_align_frame(self, indexer, df: ABCDataFrame)",
                "_convert_key(self, key, is_setter: bool=False)",
                "__getitem__(self, key)",
                "__setitem__(self, key, value)",
                "_convert_key(self, key, is_setter: bool=False)",
                "__getitem__(self, key)",
                "_convert_key(self, key, is_setter: bool=False)",
                "get_indexer(_i, _idx)",
                "pred(part) -> bool",
                "isetter(loc, v)",
                "ravel(i)"
            ],
            "variables_in_file": {
                "_NS": [
                    32,
                    745
                ],
                "slice": [
                    2051,
                    1035,
                    1932,
                    2065,
                    2066,
                    2198,
                    2076,
                    32,
                    1952,
                    2211,
                    1444,
                    1318,
                    682,
                    1849,
                    1084,
                    1469,
                    1092,
                    2250,
                    1355,
                    2255,
                    1106,
                    1620,
                    1891,
                    1130
                ],
                "arg": [
                    2176,
                    2177,
                    77
                ],
                "IndexSlice": [
                    80,
                    2275,
                    2238
                ],
                "_IndexSlice": [
                    80
                ],
                "Exception": [
                    83
                ],
                "_iLocIndexer": [
                    227
                ],
                "self": [
                    516,
                    1032,
                    1546,
                    1036,
                    1037,
                    1039,
                    1553,
                    1561,
                    1565,
                    1568,
                    1570,
                    1578,
                    1580,
                    1581,
                    1582,
                    564,
                    1079,
                    1595,
                    1084,
                    573,
                    1086,
                    1599,
                    576,
                    1089,
                    1090,
                    1604,
                    584,
                    585,
                    1097,
                    587,
                    1608,
                    589,
                    1611,
                    1107,
                    1621,
                    598,
                    1111,
                    1625,
                    606,
                    616,
                    1128,
                    618,
                    619,
                    620,
                    1645,
                    622,
                    1653,
                    1665,
                    645,
                    652,
                    655,
                    1681,
                    659,
                    1174,
                    668,
                    669,
                    674,
                    675,
                    676,
                    679,
                    685,
                    687,
                    1717,
                    698,
                    1212,
                    703,
                    706,
                    1219,
                    713,
                    714,
                    715,
                    1228,
                    718,
                    719,
                    722,
                    725,
                    726,
                    1753,
                    730,
                    737,
                    1762,
                    227,
                    1765,
                    742,
                    1768,
                    1771,
                    1260,
                    1772,
                    1773,
                    1270,
                    1783,
                    1784,
                    761,
                    772,
                    773,
                    1796,
                    776,
                    1800,
                    1803,
                    1804,
                    1805,
                    782,
                    783,
                    1807,
                    1809,
                    787,
                    1811,
                    1817,
                    796,
                    1824,
                    1827,
                    1829,
                    1830,
                    1321,
                    811,
                    815,
                    816,
                    1328,
                    818,
                    822,
                    825,
                    1338,
                    827,
                    828,
                    834,
                    1863,
                    840,
                    1353,
                    1354,
                    1864,
                    844,
                    847,
                    1877,
                    1379,
                    884,
                    1908,
                    1914,
                    891,
                    1404,
                    1412,
                    1924,
                    1414,
                    1418,
                    1931,
                    1438,
                    1953,
                    1445,
                    1451,
                    1452,
                    1456,
                    953,
                    954,
                    1465,
                    956,
                    1467,
                    1982,
                    1471,
                    1478,
                    1993,
                    1994,
                    1998,
                    2001,
                    467,
                    2004,
                    2005,
                    983,
                    2007,
                    2008,
                    986,
                    987,
                    993,
                    1508,
                    998,
                    1511,
                    1001,
                    1002,
                    1515,
                    1004,
                    1516,
                    2027,
                    1008,
                    2032,
                    1012,
                    1524,
                    1525,
                    1015,
                    2045,
                    1022
                ],
                "property": [
                    469,
                    92,
                    229,
                    518
                ],
                "_LocIndexer": [
                    467
                ],
                "_AtIndexer": [
                    516
                ],
                "_iAtIndexer": [
                    564
                ],
                "_NDFrameIndexerBase": [
                    1976,
                    567
                ],
                "_valid_types": [
                    568,
                    853,
                    1294
                ],
                "str": [
                    610,
                    895,
                    568,
                    2236,
                    2079
                ],
                "axis": [
                    1032,
                    1036,
                    1037,
                    782,
                    783,
                    1039,
                    788,
                    1174,
                    792,
                    796,
                    797,
                    1438,
                    675,
                    677,
                    806,
                    679,
                    1445,
                    1321,
                    1451,
                    1452,
                    1328,
                    1456,
                    1079,
                    825,
                    569,
                    953,
                    828,
                    954,
                    1085,
                    575,
                    576,
                    577,
                    1089,
                    1090,
                    1212,
                    1219,
                    1476,
                    1478,
                    714,
                    715,
                    844,
                    1101,
                    1228,
                    847,
                    1465,
                    1107,
                    1467,
                    983,
                    1111,
                    986,
                    988,
                    1128,
                    1260,
                    1008,
                    1012,
                    1270,
                    1015,
                    1404
                ],
                "new_self": [
                    577,
                    578,
                    573
                ],
                "type": [
                    573,
                    814
                ],
                "self.name": [
                    773,
                    589,
                    622,
                    725,
                    761,
                    796,
                    573,
                    703
                ],
                "self.obj": [
                    1032,
                    1553,
                    1561,
                    1565,
                    1568,
                    1578,
                    1580,
                    1581,
                    1582,
                    573,
                    1086,
                    1599,
                    576,
                    1097,
                    587,
                    1107,
                    1621,
                    1111,
                    1625,
                    616,
                    1128,
                    618,
                    1645,
                    622,
                    1653,
                    1665,
                    668,
                    669,
                    675,
                    1717,
                    698,
                    1212,
                    714,
                    722,
                    1753,
                    1768,
                    1771,
                    1260,
                    1773,
                    1772,
                    1270,
                    1784,
                    1800,
                    1803,
                    1804,
                    1805,
                    1807,
                    787,
                    1811,
                    1817,
                    1824,
                    1827,
                    1829,
                    1830,
                    815,
                    1328,
                    818,
                    827,
                    1864,
                    1354,
                    844,
                    847,
                    1908,
                    1914,
                    891,
                    1404,
                    1931,
                    1438,
                    1953,
                    954,
                    1467,
                    956,
                    1471,
                    1478,
                    1994,
                    1998,
                    2001,
                    2008,
                    987,
                    1508,
                    1511,
                    1515,
                    1516,
                    1008,
                    2032,
                    1524,
                    1525,
                    2045,
                    1022
                ],
                "self.obj._get_axis_number": [
                    576,
                    714,
                    675
                ],
                "new_self.axis": [
                    577
                ],
                "self.axis": [
                    674,
                    675,
                    584,
                    713,
                    714,
                    782,
                    1012,
                    825
                ],
                "self._convert_tuple": [
                    585,
                    598
                ],
                "key": [
                    2048,
                    1539,
                    1028,
                    1029,
                    1030,
                    1033,
                    1035,
                    1036,
                    1037,
                    1038,
                    1039,
                    1040,
                    1048,
                    1561,
                    1051,
                    1052,
                    1565,
                    2076,
                    2077,
                    2079,
                    2082,
                    1059,
                    2089,
                    1067,
                    1068,
                    1069,
                    1579,
                    1071,
                    1584,
                    1074,
                    1076,
                    1079,
                    1082,
                    1083,
                    1089,
                    1090,
                    585,
                    2122,
                    2123,
                    591,
                    596,
                    2133,
                    598,
                    602,
                    603,
                    606,
                    612,
                    615,
                    616,
                    618,
                    619,
                    620,
                    1130,
                    1131,
                    1135,
                    1137,
                    1142,
                    1144,
                    1145,
                    1146,
                    1161,
                    651,
                    1163,
                    1164,
                    1166,
                    1168,
                    1169,
                    1170,
                    1174,
                    1177,
                    1180,
                    1181,
                    2211,
                    679,
                    684,
                    699,
                    700,
                    703,
                    1216,
                    1219,
                    1223,
                    733,
                    734,
                    737,
                    1262,
                    1271,
                    1276,
                    789,
                    791,
                    1304,
                    1305,
                    1306,
                    796,
                    1318,
                    1320,
                    1321,
                    1322,
                    814,
                    815,
                    816,
                    1326,
                    818,
                    1327,
                    822,
                    827,
                    845,
                    846,
                    1379,
                    1382,
                    884,
                    887,
                    1405,
                    1438,
                    1444,
                    1445,
                    1447,
                    1448,
                    1450,
                    1451,
                    1452,
                    1455,
                    1456,
                    1460,
                    1461,
                    953,
                    954,
                    1465,
                    1467,
                    1985,
                    1988,
                    1989,
                    1993,
                    1994,
                    1484,
                    1997,
                    1998,
                    1488,
                    2001,
                    2003,
                    2004,
                    2005,
                    983,
                    2007,
                    2008,
                    986,
                    2022,
                    2024,
                    2027,
                    2029,
                    2033,
                    2034,
                    2045
                ],
                "ax": [
                    900,
                    1284,
                    1931,
                    1911,
                    1936,
                    1938,
                    1276,
                    668,
                    669,
                    1953,
                    1954,
                    1916,
                    1961,
                    1963,
                    1970,
                    1919,
                    1212,
                    1216,
                    1220,
                    1222,
                    1223,
                    1224,
                    1226,
                    587,
                    1354,
                    589,
                    591,
                    1362,
                    1888,
                    1894,
                    1260,
                    1908,
                    1525,
                    1526,
                    1909,
                    1914,
                    891,
                    892,
                    895
                ],
                "self.obj._get_axis": [
                    1032,
                    1128,
                    1578,
                    587,
                    844,
                    1260,
                    1328,
                    722,
                    1404,
                    1914,
                    1212,
                    1599
                ],
                "isinstance": [
                    2177,
                    1926,
                    1672,
                    1674,
                    1035,
                    1932,
                    1933,
                    2193,
                    1046,
                    1815,
                    1048,
                    1305,
                    2198,
                    2199,
                    1052,
                    668,
                    1532,
                    2076,
                    1952,
                    2079,
                    2211,
                    1444,
                    1318,
                    1447,
                    1961,
                    1322,
                    1067,
                    1535,
                    1069,
                    1962,
                    1074,
                    1849,
                    1852,
                    2237,
                    1856,
                    1985,
                    1349,
                    1607,
                    1352,
                    1610,
                    1355,
                    1738,
                    589,
                    1997,
                    2123,
                    2250,
                    2255,
                    1106,
                    2003,
                    596,
                    725,
                    1364,
                    1620,
                    602,
                    1758,
                    1891,
                    1764,
                    2148,
                    615,
                    2153,
                    1130,
                    1518,
                    1137,
                    1524,
                    1652,
                    1526,
                    2166,
                    1144,
                    892,
                    895
                ],
                "ABCMultiIndex": [
                    668,
                    1961,
                    1674,
                    1962,
                    589,
                    1137,
                    1074,
                    725,
                    1046,
                    1526,
                    1144,
                    2199,
                    892
                ],
                "ax.get_loc": [
                    591
                ],
                "TypeError": [
                    1965,
                    592,
                    1462,
                    1016,
                    1148,
                    607
                ],
                "KeyError": [
                    1285,
                    2090,
                    2154,
                    592,
                    819,
                    1271,
                    1019,
                    1277
                ],
                "InvalidIndexError": [
                    592
                ],
                "tuple": [
                    1926,
                    2193,
                    1682,
                    2068,
                    2168,
                    1322,
                    1067,
                    1069,
                    814,
                    815,
                    1071,
                    689,
                    1074,
                    1589,
                    1850,
                    1852,
                    1086,
                    1985,
                    1858,
                    1989,
                    1607,
                    1352,
                    1738,
                    2251,
                    1997,
                    1998,
                    2003,
                    596,
                    2263,
                    615,
                    616,
                    1524,
                    1652,
                    1144,
                    1532
                ],
                "IndexingError": [
                    994,
                    612,
                    1415,
                    653,
                    686,
                    1325,
                    2127,
                    599,
                    731,
                    763
                ],
                "range": [
                    602,
                    2066,
                    676,
                    1621
                ],
                "list": [
                    2177,
                    1030,
                    1447,
                    2022,
                    1673,
                    1518,
                    2236,
                    2007,
                    1849,
                    603,
                    1051,
                    1276
                ],
                "self._convert_to_indexer": [
                    687,
                    606,
                    679
                ],
                "e": [
                    610,
                    612
                ],
                "com.apply_if_callable": [
                    616,
                    618,
                    1998,
                    815,
                    2001,
                    827
                ],
                "com": [
                    1038,
                    1168,
                    791,
                    1304,
                    930,
                    1450,
                    815,
                    827,
                    700,
                    1860,
                    1998,
                    2001,
                    1747,
                    1892,
                    616,
                    618,
                    1653,
                    758,
                    1527
                ],
                "x": [
                    930,
                    616,
                    1998,
                    815,
                    926
                ],
                "indexer": [
                    1926,
                    1673,
                    1930,
                    1860,
                    1913,
                    1818,
                    1568,
                    1952,
                    1953,
                    1827,
                    1738,
                    1589,
                    1592,
                    1849,
                    1850,
                    1595,
                    1084,
                    1085,
                    1086,
                    1852,
                    1216,
                    1218,
                    1219,
                    1220,
                    1349,
                    1858,
                    1223,
                    1352,
                    1353,
                    1226,
                    1354,
                    1228,
                    1229,
                    1102,
                    1607,
                    1608,
                    1611,
                    1106,
                    1107,
                    1613,
                    1744,
                    1745,
                    1111,
                    1624,
                    1748,
                    986,
                    1753,
                    988,
                    1756,
                    1877,
                    1878,
                    1881,
                    1882,
                    1762,
                    1887,
                    2148,
                    1765,
                    2151,
                    2153,
                    619,
                    1772,
                    2155,
                    2157,
                    623,
                    1266,
                    1524,
                    1269,
                    1525,
                    2168,
                    1785,
                    1532,
                    1534
                ],
                "self._get_setitem_indexer": [
                    619
                ],
                "self._has_valid_setitem_indexer": [
                    620
                ],
                "iloc": [
                    622,
                    623
                ],
                "self.obj.iloc": [
                    1086,
                    622
                ],
                "iloc._setitem_with_indexer": [
                    623
                ],
                "value": [
                    1796,
                    1669,
                    1799,
                    1672,
                    1679,
                    1682,
                    1556,
                    1815,
                    1561,
                    1817,
                    1818,
                    1693,
                    1565,
                    1822,
                    1824,
                    1697,
                    1570,
                    1698,
                    1827,
                    1829,
                    1706,
                    1710,
                    1715,
                    1717,
                    1595,
                    1723,
                    1729,
                    1735,
                    1610,
                    1611,
                    2008,
                    1753,
                    1758,
                    1633,
                    1762,
                    1764,
                    1765,
                    1772,
                    1518,
                    623
                ],
                "int": [
                    1027,
                    2051,
                    1420,
                    1303,
                    1184,
                    1443,
                    810,
                    1469,
                    960,
                    836,
                    1092,
                    1480,
                    842,
                    1232,
                    1113,
                    863,
                    1388,
                    1006,
                    625
                ],
                "AbstractMethodError": [
                    834,
                    645,
                    840,
                    811,
                    1982
                ],
                "Tuple": [
                    833,
                    1410,
                    2051,
                    710,
                    647,
                    935,
                    874,
                    908,
                    1010,
                    691,
                    662,
                    1369,
                    765,
                    830,
                    991
                ],
                "i": [
                    1527,
                    1546,
                    651,
                    652,
                    1930,
                    1931,
                    655,
                    1553,
                    2196,
                    789,
                    1942,
                    676,
                    677,
                    1704,
                    1578,
                    1706,
                    684,
                    685,
                    1580,
                    687,
                    2046,
                    699,
                    703,
                    1856,
                    1354,
                    1355,
                    1358,
                    1361,
                    1362,
                    1364,
                    1748,
                    1749,
                    733,
                    1887,
                    1888,
                    737,
                    1382,
                    745,
                    751,
                    1525,
                    887,
                    891,
                    2045,
                    1534
                ],
                "k": [
                    1382,
                    1383,
                    651,
                    684,
                    687,
                    655,
                    2196,
                    2198,
                    887,
                    888,
                    895
                ],
                "enumerate": [
                    1382,
                    1704,
                    1930,
                    651,
                    684,
                    1553,
                    1748,
                    789,
                    2196,
                    887,
                    2168,
                    699,
                    733,
                    1534,
                    1887
                ],
                "self.ndim": [
                    772,
                    1924,
                    1546,
                    652,
                    1809,
                    676,
                    685,
                    1084,
                    706,
                    1604,
                    1863,
                    1608,
                    1353,
                    2004,
                    1877,
                    2005,
                    730,
                    1379,
                    742,
                    2027,
                    884,
                    1783,
                    1022
                ],
                "self._validate_key": [
                    1089,
                    1451,
                    1036,
                    655,
                    983
                ],
                "ValueError": [
                    1921,
                    775,
                    656,
                    657,
                    1557,
                    1813,
                    1312,
                    1825,
                    1699,
                    2090,
                    1077,
                    1973,
                    1338,
                    1724,
                    1991,
                    2006,
                    1635,
                    1150,
                    2047
                ],
                "self._valid_types": [
                    1338,
                    659
                ],
                "err": [
                    1441,
                    660
                ],
                "any": [
                    930,
                    1795,
                    1555,
                    668,
                    669
                ],
                "self.obj.axes": [
                    1568,
                    1354,
                    1931,
                    1553,
                    2045,
                    1524,
                    1525,
                    1908,
                    891,
                    668,
                    669
                ],
                "is_nested_tuple": [
                    1082,
                    1163,
                    669
                ],
                "tup": [
                    772,
                    1412,
                    1414,
                    776,
                    1418,
                    783,
                    2193,
                    2196,
                    789,
                    669,
                    926,
                    930,
                    954,
                    699,
                    715,
                    718,
                    719,
                    726,
                    730,
                    733,
                    993,
                    998,
                    745,
                    1001,
                    1002,
                    1004,
                    751,
                    1015,
                    1022
                ],
                "bool": [
                    2186,
                    908,
                    662,
                    2204,
                    672,
                    1184,
                    2214,
                    1832,
                    810,
                    1340,
                    1981,
                    2240,
                    839,
                    1480,
                    1232,
                    852,
                    2132,
                    2135,
                    1369,
                    1113,
                    2015,
                    2274,
                    871,
                    2153,
                    874,
                    2041
                ],
                "keyidx": [
                    673,
                    678,
                    682,
                    688,
                    689
                ],
                "keyidx.append": [
                    688,
                    682,
                    678
                ],
                "is_setter": [
                    687,
                    2021,
                    679
                ],
                "idx": [
                    1539,
                    1928,
                    1935,
                    1936,
                    1944,
                    1946,
                    2075,
                    1949,
                    2077,
                    2087,
                    2089,
                    687,
                    688,
                    1587,
                    1860,
                    1747,
                    1748,
                    1887,
                    1891,
                    1892,
                    1894,
                    1653,
                    1654,
                    1534,
                    1535
                ],
                "retval": [
                    706,
                    698,
                    708,
                    703
                ],
                "com.is_null_slice": [
                    1860,
                    1892,
                    791,
                    1747,
                    1653,
                    758,
                    1527,
                    700
                ],
                "_getitem_axis": [
                    796,
                    703
                ],
                "getattr": [
                    1669,
                    1222,
                    761,
                    796,
                    703
                ],
                "retval.ndim": [
                    706
                ],
                "self._getitem_axis": [
                    737,
                    715,
                    828,
                    783
                ],
                "self._is_nested_tuple_indexer": [
                    718
                ],
                "self._getitem_nested_tuple": [
                    719
                ],
                "ax0": [
                    722,
                    725
                ],
                "result": [
                    776,
                    777,
                    778,
                    2122,
                    2124,
                    2125,
                    2132,
                    726,
                    727,
                    728,
                    2135,
                    2138,
                    2136,
                    2140
                ],
                "self._handle_lowerdim_multi_index_axis0": [
                    776,
                    726
                ],
                "len": [
                    772,
                    1800,
                    1553,
                    1811,
                    1785,
                    1824,
                    1698,
                    1579,
                    1068,
                    1709,
                    1710,
                    1328,
                    1717,
                    1335,
                    1723,
                    1744,
                    1362,
                    1621,
                    2005,
                    1881,
                    730,
                    1882,
                    1628,
                    1633,
                    1379,
                    1899,
                    1262,
                    753,
                    884,
                    1269,
                    1524,
                    1653,
                    1909,
                    1145,
                    1404,
                    1022
                ],
                "is_label_like": [
                    734
                ],
                "section": [
                    737,
                    761,
                    742,
                    759
                ],
                "section.ndim": [
                    742
                ],
                "new_key": [
                    745,
                    751,
                    753,
                    754,
                    758,
                    761
                ],
                "obj": [
                    787,
                    2075,
                    795,
                    796,
                    800,
                    2082,
                    805,
                    808,
                    2221,
                    2222,
                    2223,
                    1471,
                    1474,
                    1476,
                    1864,
                    1097,
                    1099,
                    1101,
                    1878,
                    1888,
                    2032,
                    2033,
                    2034
                ],
                "current_ndim": [
                    795,
                    805
                ],
                "obj.ndim": [
                    795,
                    805
                ],
                "is_scalar": [
                    800,
                    2027,
                    1711,
                    1137,
                    888,
                    1913
                ],
                "hasattr": [
                    800,
                    1305,
                    1059,
                    1076
                ],
                "self._is_scalar_access": [
                    816
                ],
                "self.obj._get_value": [
                    1994,
                    818
                ],
                "self._takeable": [
                    2008,
                    1994,
                    818
                ],
                "IndexError": [
                    1441,
                    1350,
                    1363,
                    819,
                    1332,
                    1365,
                    1336,
                    1406,
                    1439
                ],
                "AttributeError": [
                    819
                ],
                "self._getitem_tuple": [
                    822
                ],
                "maybe_callable": [
                    827,
                    828
                ],
                "NotImplementedError": [
                    1060,
                    837,
                    2090,
                    1307,
                    1054,
                    831
                ],
                "labels": [
                    1032,
                    1033,
                    1674,
                    1163,
                    1164,
                    1169,
                    1046,
                    2199,
                    1177,
                    1579,
                    1580,
                    1709,
                    1584,
                    1074,
                    1082,
                    1083,
                    1476,
                    1477,
                    844,
                    845,
                    1101,
                    1102,
                    1616,
                    1628,
                    1128,
                    1131,
                    1134,
                    1137,
                    1142,
                    1144,
                    1145
                ],
                "check_bool_indexer": [
                    1169,
                    845
                ],
                "inds": [
                    1170,
                    1171,
                    846,
                    847
                ],
                "key.nonzero": [
                    1170,
                    846
                ],
                "self.obj._take_with_is_copy": [
                    1438,
                    847
                ],
                "_LocationIndexer": [
                    851,
                    1293,
                    862
                ],
                "_takeable": [
                    1298,
                    852,
                    2013,
                    2039
                ],
                "Appender": [
                    1292,
                    850,
                    2037,
                    2011,
                    862
                ],
                "_LocationIndexer._validate_key.__doc__": [
                    862
                ],
                "_LocationIndexer._validate_key": [
                    862
                ],
                "ax._supports_partial_string_indexing": [
                    895
                ],
                "ax.is_unique": [
                    900,
                    1222
                ],
                "all": [
                    1218,
                    1746,
                    1652,
                    1877,
                    926
                ],
                "is_list_like_indexer": [
                    1952,
                    1633,
                    2211,
                    1988,
                    1669,
                    1895,
                    1326,
                    1166,
                    1040,
                    1358,
                    1455,
                    1822,
                    1556,
                    1180,
                    926
                ],
                "com.is_bool_indexer": [
                    930,
                    1450,
                    1038,
                    1168,
                    1304
                ],
                "d": [
                    952,
                    956
                ],
                "self._get_listlike_indexer": [
                    953,
                    986,
                    1174
                ],
                "zip": [
                    1729,
                    1354,
                    1525,
                    954,
                    2045
                ],
                "self.obj._AXIS_ORDERS": [
                    954
                ],
                "self.obj._reindex_with_indexers": [
                    987,
                    956
                ],
                "keyarr": [
                    1216,
                    1224,
                    1226,
                    1228,
                    1229,
                    986,
                    988
                ],
                "self._getitem_lowerdim": [
                    993,
                    1414
                ],
                "self._has_valid_tuple": [
                    1412,
                    998
                ],
                "self._multi_take_opportunity": [
                    1001
                ],
                "self._multi_take": [
                    1002
                ],
                "self._getitem_tuple_same_dim": [
                    1418,
                    1004
                ],
                "self.obj._xs": [
                    1008
                ],
                "label": [
                    1008
                ],
                "self._get_label": [
                    1090,
                    1015
                ],
                "self.obj.index.nlevels": [
                    1022
                ],
                "self.obj.index": [
                    1953,
                    1717,
                    1784,
                    1625,
                    1022
                ],
                "ek": [
                    1023
                ],
                "item_from_zerodim": [
                    1460,
                    1028
                ],
                "is_iterator": [
                    1029
                ],
                "labels._get_partial_string_timestamp_match_key": [
                    1033
                ],
                "self._get_slice_axis": [
                    1037,
                    1445
                ],
                "self._getbool_axis": [
                    1452,
                    1039
                ],
                "ABCSeries": [
                    2177,
                    1832,
                    1610,
                    2123,
                    1815,
                    1048,
                    2236,
                    1758
                ],
                "np.ndarray": [
                    1856,
                    2177,
                    1933,
                    2096,
                    1048,
                    1849,
                    2236
                ],
                "np": [
                    1856,
                    1697,
                    2177,
                    2272,
                    2181,
                    1448,
                    1933,
                    1327,
                    2096,
                    1685,
                    2135,
                    1048,
                    1849,
                    1883,
                    2236,
                    1693
                ],
                "key.ndim": [
                    1048,
                    1059,
                    1076
                ],
                "ABCDataFrame": [
                    1672,
                    1923,
                    1052,
                    1764
                ],
                "self._getitem_iterable": [
                    1079
                ],
                "locs": [
                    1083,
                    1085
                ],
                "labels.get_locs": [
                    1083,
                    1164
                ],
                "need_slice": [
                    1473,
                    1098
                ],
                "slice_obj": [
                    1473,
                    1477,
                    1478,
                    1098,
                    1103
                ],
                "obj.copy": [
                    1474,
                    1099
                ],
                "obj._get_axis": [
                    1476,
                    1101
                ],
                "labels.slice_indexer": [
                    1102
                ],
                "slice_obj.start": [
                    1103
                ],
                "slice_obj.stop": [
                    1103
                ],
                "slice_obj.step": [
                    1103
                ],
                "self.obj._slice": [
                    1107,
                    1478
                ],
                "self.obj.take": [
                    1111
                ],
                "labels._convert_slice_indexer": [
                    1131
                ],
                "is_int_index": [
                    1134,
                    1135
                ],
                "labels.is_integer": [
                    1134
                ],
                "is_int_positional": [
                    1155,
                    1151,
                    1135
                ],
                "is_integer": [
                    1383,
                    1320,
                    1614,
                    1135,
                    1361,
                    1745,
                    1461,
                    1527,
                    2046
                ],
                "labels.get_loc": [
                    1584,
                    1177,
                    1142
                ],
                "LookupError": [
                    1178,
                    1143
                ],
                "labels.nlevels": [
                    1145
                ],
                "ax._convert_listlike_indexer": [
                    1216
                ],
                "self._validate_read_indexer": [
                    1219,
                    1228
                ],
                "raise_missing": [
                    1219,
                    1228,
                    1275
                ],
                "ax.get_indexer_for": [
                    1223
                ],
                "ax.reindex": [
                    1224
                ],
                "new_indexer": [
                    1794,
                    1795,
                    1570,
                    1796,
                    1226,
                    1567
                ],
                "ax._reindex_non_unique": [
                    1226
                ],
                "missing": [
                    1266,
                    1268,
                    1269,
                    1592,
                    1594
                ],
                "sum": [
                    1266,
                    1861
                ],
                "axis_name": [
                    1270,
                    1271
                ],
                "self.obj._get_axis_name": [
                    1270
                ],
                "not_found": [
                    1276,
                    1277
                ],
                "set": [
                    1276
                ],
                "ax.is_categorical": [
                    1284
                ],
                "IndexingMixin.loc.__doc__": [
                    850
                ],
                "IndexingMixin.loc": [
                    850
                ],
                "IndexingMixin": [
                    850,
                    2011,
                    1292,
                    2037
                ],
                "key.index": [
                    1305,
                    1306,
                    2123
                ],
                "Index": [
                    2177,
                    1896,
                    1898,
                    2096,
                    1621,
                    1849,
                    1305,
                    2236
                ],
                "key.index.inferred_type": [
                    1306
                ],
                "self._validate_integer": [
                    1321,
                    1465
                ],
                "arr": [
                    1331,
                    1332,
                    1335,
                    1327
                ],
                "np.array": [
                    1697,
                    1327
                ],
                "len_axis": [
                    1328,
                    1404,
                    1405,
                    1335
                ],
                "is_numeric_dtype": [
                    1331
                ],
                "arr.dtype": [
                    1331
                ],
                "arr.max": [
                    1335
                ],
                "arr.min": [
                    1335
                ],
                "dict": [
                    2148,
                    1349,
                    1518,
                    1364,
                    2166,
                    1758,
                    1535
                ],
                "_tuplify": [
                    1608,
                    1353,
                    2004
                ],
                "np.asarray": [
                    1448,
                    2135
                ],
                "self._get_list_axis": [
                    1456
                ],
                "self.obj._ixs": [
                    1467,
                    1645
                ],
                "labels._validate_positional_slice": [
                    1477
                ],
                "info_axis": [
                    1508,
                    1605,
                    1546,
                    1613,
                    1680,
                    1744,
                    1745,
                    1749,
                    1753,
                    1599
                ],
                "self.obj._info_axis_number": [
                    1508
                ],
                "take_split_path": [
                    1602,
                    1511,
                    1515,
                    1519,
                    1529
                ],
                "self.obj._is_mixed_type": [
                    1511
                ],
                "self.obj._data.blocks": [
                    1515,
                    1516
                ],
                "self.obj._data": [
                    1829,
                    1515,
                    1516,
                    1804,
                    1580,
                    1772
                ],
                "blk": [
                    1516,
                    1517,
                    1519
                ],
                "blk.ndim": [
                    1517
                ],
                "val": [
                    1955,
                    1518,
                    1519,
                    1970,
                    1971,
                    1947,
                    1949,
                    1950
                ],
                "value.values": [
                    1518
                ],
                "blk._can_hold_element": [
                    1519
                ],
                "nindexer": [
                    1584,
                    1589,
                    1587,
                    1533
                ],
                "_": [
                    2066,
                    1539,
                    1877
                ],
                "convert_missing_indexer": [
                    1592,
                    1539
                ],
                "len_non_info_axes": [
                    1552,
                    1555
                ],
                "_ax": [
                    1553
                ],
                "_i": [
                    2168,
                    1553,
                    2166
                ],
                "l": [
                    1555
                ],
                "_infer_fill_value": [
                    1565
                ],
                "convert_from_missing_indexer_tuple": [
                    1567
                ],
                "self._setitem_with_indexer": [
                    1570,
                    1796
                ],
                "index": [
                    1793,
                    1794,
                    1578,
                    1579,
                    2123,
                    2124,
                    1784,
                    1785,
                    2138,
                    2136
                ],
                "index.insert": [
                    1785,
                    1579
                ],
                "_data": [
                    1829,
                    1580,
                    1804
                ],
                "self.obj.reindex": [
                    1580
                ],
                "self.obj._maybe_update_cacher": [
                    1773,
                    1581,
                    1830,
                    1807
                ],
                "self.obj._is_copy": [
                    1582
                ],
                "nindexer.append": [
                    1584,
                    1587
                ],
                "self._setitem_with_indexer_missing": [
                    1595
                ],
                "item_labels": [
                    1678,
                    1616,
                    1751,
                    1753,
                    1599
                ],
                "self._align_series": [
                    1681,
                    1762,
                    1611
                ],
                "info_idx": [
                    1613,
                    1614,
                    1615,
                    1616,
                    1619,
                    1620,
                    1622
                ],
                "ilocs": [
                    1729,
                    1698,
                    1734,
                    1704,
                    1677,
                    1619,
                    1715,
                    1622,
                    1723
                ],
                "ri": [
                    1621,
                    1622
                ],
                "self.obj.columns": [
                    1824,
                    1827,
                    1811,
                    1621,
                    1817
                ],
                "plane_indexer": [
                    1624,
                    1625,
                    1711,
                    1641
                ],
                "lplane_indexer": [
                    1633,
                    1641,
                    1710,
                    1717,
                    1625
                ],
                "length_of_indexer": [
                    1625
                ],
                "pi": [
                    1641,
                    1652,
                    1661,
                    1654
                ],
                "ser": [
                    1665,
                    1660,
                    1661,
                    1878,
                    1883,
                    1885,
                    1899,
                    1900,
                    1645,
                    1902,
                    1909,
                    1910,
                    1911,
                    1656,
                    1659,
                    1916,
                    1917,
                    1662,
                    1919
                ],
                "loc": [
                    1665,
                    1729,
                    1730,
                    1734,
                    1735,
                    1704,
                    1706,
                    1645,
                    1678,
                    1677,
                    2033,
                    2034,
                    2067,
                    1687
                ],
                "com.is_full_slice": [
                    1653
                ],
                "v": [
                    1729,
                    1730,
                    1681,
                    1685,
                    1687,
                    1656,
                    1661
                ],
                "ser._consolidate_inplace": [
                    1659
                ],
                "ser.copy": [
                    1660
                ],
                "ser._data": [
                    1661
                ],
                "ser._data.setitem": [
                    1661
                ],
                "ser._maybe_update_cacher": [
                    1662
                ],
                "self.obj._iset_item": [
                    1665
                ],
                "sub_indexer": [
                    1680,
                    1673,
                    1682
                ],
                "multiindex_indexer": [
                    1881,
                    1674,
                    1682
                ],
                "item": [
                    1680,
                    1682,
                    1678,
                    1679
                ],
                "np.nan": [
                    1685
                ],
                "isetter": [
                    1730,
                    1735,
                    1706,
                    1715,
                    1687
                ],
                "np.ndim": [
                    1693
                ],
                "object": [
                    1697
                ],
                "value.shape": [
                    1698
                ],
                "tolist": [
                    1706
                ],
                "item_labels.is_unique": [
                    1751
                ],
                "maybe_convert_ix": [
                    1756
                ],
                "Series": [
                    1762,
                    1827,
                    1799
                ],
                "self._align_frame": [
                    1765
                ],
                "self.obj._check_is_chained_assignment_possible": [
                    1768
                ],
                "self.obj._consolidate_inplace": [
                    1771
                ],
                "self.obj._data.setitem": [
                    1772
                ],
                "new_index": [
                    1785,
                    1794,
                    1805
                ],
                "index.is_unique": [
                    1793
                ],
                "index.get_indexer": [
                    1794
                ],
                "new_values": [
                    1803,
                    1805,
                    1799
                ],
                "_values": [
                    1955,
                    1799,
                    1902,
                    1970,
                    2132,
                    1878,
                    1911,
                    1947,
                    1949,
                    1919
                ],
                "self.obj._values": [
                    1800,
                    1803
                ],
                "concat_compat": [
                    1803
                ],
                "self.obj._constructor": [
                    1804
                ],
                "self.obj.name": [
                    1805
                ],
                "value.reindex": [
                    1817
                ],
                "value.name": [
                    1818
                ],
                "self.obj.append": [
                    1829
                ],
                "i.ravel": [
                    1856
                ],
                "map": [
                    1858
                ],
                "ravel": [
                    1858
                ],
                "aligners": [
                    1873,
                    1860,
                    1861
                ],
                "sum_aligners": [
                    1877,
                    1861,
                    1862
                ],
                "single_aligner": [
                    1873,
                    1892,
                    1862,
                    1905
                ],
                "is_frame": [
                    1872,
                    1924,
                    1952,
                    1863
                ],
                "is_sequence": [
                    1891,
                    1932,
                    1877
                ],
                "ser.reindex": [
                    1902,
                    1919,
                    1878,
                    1911
                ],
                "obj.axes": [
                    1888,
                    1878
                ],
                "len_indexer": [
                    1882,
                    1883
                ],
                "T": [
                    1883
                ],
                "reshape": [
                    1883
                ],
                "np.tile": [
                    1883
                ],
                "new_ix": [
                    1894,
                    1895,
                    1896,
                    1898,
                    1899,
                    1902
                ],
                "ser.index.equals": [
                    1899,
                    1916,
                    1909
                ],
                "ser.index": [
                    1899,
                    1916,
                    1909
                ],
                "ser._values.copy": [
                    1900,
                    1917,
                    1910
                ],
                "ser._values": [
                    1900,
                    1917,
                    1910
                ],
                "cols": [
                    1928,
                    1937,
                    1938,
                    1944,
                    1946,
                    1949
                ],
                "sindexers": [
                    1929,
                    1942
                ],
                "ix": [
                    1930,
                    1932,
                    1933,
                    1934,
                    1936,
                    1938
                ],
                "ix.ravel": [
                    1934
                ],
                "sindexers.append": [
                    1942
                ],
                "df.index.equals": [
                    1954,
                    1946
                ],
                "df.index": [
                    1954,
                    1946,
                    1962,
                    1963
                ],
                "df": [
                    1954,
                    1955,
                    2275,
                    1962,
                    1963,
                    1970,
                    1946,
                    1947,
                    1949
                ],
                "df.columns.equals": [
                    1946
                ],
                "df.columns": [
                    1946
                ],
                "df.copy": [
                    1947,
                    1955
                ],
                "df.reindex": [
                    1970,
                    1949
                ],
                "ax.nlevels": [
                    1963
                ],
                "df.index.nlevels": [
                    1963
                ],
                "IndexingMixin.iloc.__doc__": [
                    1292
                ],
                "IndexingMixin.iloc": [
                    1292
                ],
                "self._convert_key": [
                    1993,
                    2007
                ],
                "self.obj._set_value": [
                    2008
                ],
                "_ScalarAccessIndexer": [
                    2012,
                    2038
                ],
                "__getitem__": [
                    2029
                ],
                "super": [
                    2029
                ],
                "obj.index.get_loc": [
                    2033
                ],
                "obj.index": [
                    2033,
                    2034,
                    2075
                ],
                "obj.index._get_values_for_loc": [
                    2034
                ],
                "IndexingMixin.at.__doc__": [
                    2011
                ],
                "IndexingMixin.at": [
                    2011
                ],
                "a": [
                    2045
                ],
                "IndexingMixin.iat.__doc__": [
                    2037
                ],
                "IndexingMixin.iat": [
                    2037
                ],
                "Hashable": [
                    2065,
                    2051
                ],
                "_tup": [
                    2065,
                    2066,
                    2067,
                    2068
                ],
                "List": [
                    2065
                ],
                "Union": [
                    2065,
                    2051
                ],
                "ndim": [
                    2066
                ],
                "idx._convert_slice_indexer": [
                    2077
                ],
                "obj._data.items": [
                    2082
                ],
                "obj._data": [
                    2082
                ],
                "idx._supports_partial_string_indexing": [
                    2087
                ],
                "idx._get_string_slice": [
                    2089
                ],
                "key.index.equals": [
                    2123
                ],
                "result.reindex": [
                    2124
                ],
                "mask": [
                    2125,
                    2126
                ],
                "isna": [
                    2125
                ],
                "result._values": [
                    2125
                ],
                "mask.any": [
                    2126
                ],
                "result.astype": [
                    2132
                ],
                "is_object_dtype": [
                    2133
                ],
                "check_array_indexer": [
                    2136,
                    2138
                ],
                "_idx": [
                    2168,
                    2166
                ],
                "get_loc": [
                    2166
                ],
                "axes": [
                    2166
                ],
                "get_indexer": [
                    2168
                ],
                "ixify": [
                    2178,
                    2180,
                    2175
                ],
                "args": [
                    2176,
                    2181,
                    2183
                ],
                "np.ix_": [
                    2181
                ],
                "is_list_like": [
                    2250,
                    2254,
                    2198
                ],
                "obj.start": [
                    2221
                ],
                "obj.stop": [
                    2222
                ],
                "obj.step": [
                    2223
                ],
                "kinds": [
                    2236,
                    2237
                ],
                "slice_": [
                    2275,
                    2276,
                    2254,
                    2255,
                    2257,
                    2260,
                    2262,
                    2263,
                    2237,
                    2238,
                    2271
                ],
                "part": [
                    2250,
                    2251,
                    2262
                ],
                "pred": [
                    2262
                ],
                "dtypes": [
                    2272,
                    2274,
                    2275
                ],
                "np.number": [
                    2272
                ],
                "include_bool": [
                    2273
                ],
                "dtypes.append": [
                    2274
                ],
                "columns": [
                    2275
                ],
                "df.select_dtypes": [
                    2275
                ]
            },
            "filtered_variables_in_file": {
                "_NS": [
                    32,
                    745
                ],
                "arg": [
                    2176,
                    2177,
                    77
                ],
                "IndexSlice": [
                    80,
                    2275,
                    2238
                ],
                "_IndexSlice": [
                    80
                ],
                "_iLocIndexer": [
                    227
                ],
                "self": [
                    516,
                    1032,
                    1546,
                    1036,
                    1037,
                    1039,
                    1553,
                    1561,
                    1565,
                    1568,
                    1570,
                    1578,
                    1580,
                    1581,
                    1582,
                    564,
                    1079,
                    1595,
                    1084,
                    573,
                    1086,
                    1599,
                    576,
                    1089,
                    1090,
                    1604,
                    584,
                    585,
                    1097,
                    587,
                    1608,
                    589,
                    1611,
                    1107,
                    1621,
                    598,
                    1111,
                    1625,
                    606,
                    616,
                    1128,
                    618,
                    619,
                    620,
                    1645,
                    622,
                    1653,
                    1665,
                    645,
                    652,
                    655,
                    1681,
                    659,
                    1174,
                    668,
                    669,
                    674,
                    675,
                    676,
                    679,
                    685,
                    687,
                    1717,
                    698,
                    1212,
                    703,
                    706,
                    1219,
                    713,
                    714,
                    715,
                    1228,
                    718,
                    719,
                    722,
                    725,
                    726,
                    1753,
                    730,
                    737,
                    1762,
                    227,
                    1765,
                    742,
                    1768,
                    1771,
                    1260,
                    1772,
                    1773,
                    1270,
                    1783,
                    1784,
                    761,
                    772,
                    773,
                    1796,
                    776,
                    1800,
                    1803,
                    1804,
                    1805,
                    782,
                    783,
                    1807,
                    1809,
                    787,
                    1811,
                    1817,
                    796,
                    1824,
                    1827,
                    1829,
                    1830,
                    1321,
                    811,
                    815,
                    816,
                    1328,
                    818,
                    822,
                    825,
                    1338,
                    827,
                    828,
                    834,
                    1863,
                    840,
                    1353,
                    1354,
                    1864,
                    844,
                    847,
                    1877,
                    1379,
                    884,
                    1908,
                    1914,
                    891,
                    1404,
                    1412,
                    1924,
                    1414,
                    1418,
                    1931,
                    1438,
                    1953,
                    1445,
                    1451,
                    1452,
                    1456,
                    953,
                    954,
                    1465,
                    956,
                    1467,
                    1982,
                    1471,
                    1478,
                    1993,
                    1994,
                    1998,
                    2001,
                    467,
                    2004,
                    2005,
                    983,
                    2007,
                    2008,
                    986,
                    987,
                    993,
                    1508,
                    998,
                    1511,
                    1001,
                    1002,
                    1515,
                    1004,
                    1516,
                    2027,
                    1008,
                    2032,
                    1012,
                    1524,
                    1525,
                    1015,
                    2045,
                    1022
                ],
                "_LocIndexer": [
                    467
                ],
                "_AtIndexer": [
                    516
                ],
                "_iAtIndexer": [
                    564
                ],
                "_NDFrameIndexerBase": [
                    1976,
                    567
                ],
                "_valid_types": [
                    568,
                    853,
                    1294
                ],
                "axis": [
                    1032,
                    1036,
                    1037,
                    782,
                    783,
                    1039,
                    788,
                    1174,
                    792,
                    796,
                    797,
                    1438,
                    675,
                    677,
                    806,
                    679,
                    1445,
                    1321,
                    1451,
                    1452,
                    1328,
                    1456,
                    1079,
                    825,
                    569,
                    953,
                    828,
                    954,
                    1085,
                    575,
                    576,
                    577,
                    1089,
                    1090,
                    1212,
                    1219,
                    1476,
                    1478,
                    714,
                    715,
                    844,
                    1101,
                    1228,
                    847,
                    1465,
                    1107,
                    1467,
                    983,
                    1111,
                    986,
                    988,
                    1128,
                    1260,
                    1008,
                    1012,
                    1270,
                    1015,
                    1404
                ],
                "new_self": [
                    577,
                    578,
                    573
                ],
                "self.name": [
                    773,
                    589,
                    622,
                    725,
                    761,
                    796,
                    573,
                    703
                ],
                "self.obj": [
                    1032,
                    1553,
                    1561,
                    1565,
                    1568,
                    1578,
                    1580,
                    1581,
                    1582,
                    573,
                    1086,
                    1599,
                    576,
                    1097,
                    587,
                    1107,
                    1621,
                    1111,
                    1625,
                    616,
                    1128,
                    618,
                    1645,
                    622,
                    1653,
                    1665,
                    668,
                    669,
                    675,
                    1717,
                    698,
                    1212,
                    714,
                    722,
                    1753,
                    1768,
                    1771,
                    1260,
                    1773,
                    1772,
                    1270,
                    1784,
                    1800,
                    1803,
                    1804,
                    1805,
                    1807,
                    787,
                    1811,
                    1817,
                    1824,
                    1827,
                    1829,
                    1830,
                    815,
                    1328,
                    818,
                    827,
                    1864,
                    1354,
                    844,
                    847,
                    1908,
                    1914,
                    891,
                    1404,
                    1931,
                    1438,
                    1953,
                    954,
                    1467,
                    956,
                    1471,
                    1478,
                    1994,
                    1998,
                    2001,
                    2008,
                    987,
                    1508,
                    1511,
                    1515,
                    1516,
                    1008,
                    2032,
                    1524,
                    1525,
                    2045,
                    1022
                ],
                "self.obj._get_axis_number": [
                    576,
                    714,
                    675
                ],
                "new_self.axis": [
                    577
                ],
                "self.axis": [
                    674,
                    675,
                    584,
                    713,
                    714,
                    782,
                    1012,
                    825
                ],
                "self._convert_tuple": [
                    585,
                    598
                ],
                "key": [
                    2048,
                    1539,
                    1028,
                    1029,
                    1030,
                    1033,
                    1035,
                    1036,
                    1037,
                    1038,
                    1039,
                    1040,
                    1048,
                    1561,
                    1051,
                    1052,
                    1565,
                    2076,
                    2077,
                    2079,
                    2082,
                    1059,
                    2089,
                    1067,
                    1068,
                    1069,
                    1579,
                    1071,
                    1584,
                    1074,
                    1076,
                    1079,
                    1082,
                    1083,
                    1089,
                    1090,
                    585,
                    2122,
                    2123,
                    591,
                    596,
                    2133,
                    598,
                    602,
                    603,
                    606,
                    612,
                    615,
                    616,
                    618,
                    619,
                    620,
                    1130,
                    1131,
                    1135,
                    1137,
                    1142,
                    1144,
                    1145,
                    1146,
                    1161,
                    651,
                    1163,
                    1164,
                    1166,
                    1168,
                    1169,
                    1170,
                    1174,
                    1177,
                    1180,
                    1181,
                    2211,
                    679,
                    684,
                    699,
                    700,
                    703,
                    1216,
                    1219,
                    1223,
                    733,
                    734,
                    737,
                    1262,
                    1271,
                    1276,
                    789,
                    791,
                    1304,
                    1305,
                    1306,
                    796,
                    1318,
                    1320,
                    1321,
                    1322,
                    814,
                    815,
                    816,
                    1326,
                    818,
                    1327,
                    822,
                    827,
                    845,
                    846,
                    1379,
                    1382,
                    884,
                    887,
                    1405,
                    1438,
                    1444,
                    1445,
                    1447,
                    1448,
                    1450,
                    1451,
                    1452,
                    1455,
                    1456,
                    1460,
                    1461,
                    953,
                    954,
                    1465,
                    1467,
                    1985,
                    1988,
                    1989,
                    1993,
                    1994,
                    1484,
                    1997,
                    1998,
                    1488,
                    2001,
                    2003,
                    2004,
                    2005,
                    983,
                    2007,
                    2008,
                    986,
                    2022,
                    2024,
                    2027,
                    2029,
                    2033,
                    2034,
                    2045
                ],
                "ax": [
                    900,
                    1284,
                    1931,
                    1911,
                    1936,
                    1938,
                    1276,
                    668,
                    669,
                    1953,
                    1954,
                    1916,
                    1961,
                    1963,
                    1970,
                    1919,
                    1212,
                    1216,
                    1220,
                    1222,
                    1223,
                    1224,
                    1226,
                    587,
                    1354,
                    589,
                    591,
                    1362,
                    1888,
                    1894,
                    1260,
                    1908,
                    1525,
                    1526,
                    1909,
                    1914,
                    891,
                    892,
                    895
                ],
                "self.obj._get_axis": [
                    1032,
                    1128,
                    1578,
                    587,
                    844,
                    1260,
                    1328,
                    722,
                    1404,
                    1914,
                    1212,
                    1599
                ],
                "ABCMultiIndex": [
                    668,
                    1961,
                    1674,
                    1962,
                    589,
                    1137,
                    1074,
                    725,
                    1046,
                    1526,
                    1144,
                    2199,
                    892
                ],
                "ax.get_loc": [
                    591
                ],
                "InvalidIndexError": [
                    592
                ],
                "IndexingError": [
                    994,
                    612,
                    1415,
                    653,
                    686,
                    1325,
                    2127,
                    599,
                    731,
                    763
                ],
                "self._convert_to_indexer": [
                    687,
                    606,
                    679
                ],
                "e": [
                    610,
                    612
                ],
                "com.apply_if_callable": [
                    616,
                    618,
                    1998,
                    815,
                    2001,
                    827
                ],
                "com": [
                    1038,
                    1168,
                    791,
                    1304,
                    930,
                    1450,
                    815,
                    827,
                    700,
                    1860,
                    1998,
                    2001,
                    1747,
                    1892,
                    616,
                    618,
                    1653,
                    758,
                    1527
                ],
                "x": [
                    930,
                    616,
                    1998,
                    815,
                    926
                ],
                "indexer": [
                    1926,
                    1673,
                    1930,
                    1860,
                    1913,
                    1818,
                    1568,
                    1952,
                    1953,
                    1827,
                    1738,
                    1589,
                    1592,
                    1849,
                    1850,
                    1595,
                    1084,
                    1085,
                    1086,
                    1852,
                    1216,
                    1218,
                    1219,
                    1220,
                    1349,
                    1858,
                    1223,
                    1352,
                    1353,
                    1226,
                    1354,
                    1228,
                    1229,
                    1102,
                    1607,
                    1608,
                    1611,
                    1106,
                    1107,
                    1613,
                    1744,
                    1745,
                    1111,
                    1624,
                    1748,
                    986,
                    1753,
                    988,
                    1756,
                    1877,
                    1878,
                    1881,
                    1882,
                    1762,
                    1887,
                    2148,
                    1765,
                    2151,
                    2153,
                    619,
                    1772,
                    2155,
                    2157,
                    623,
                    1266,
                    1524,
                    1269,
                    1525,
                    2168,
                    1785,
                    1532,
                    1534
                ],
                "self._get_setitem_indexer": [
                    619
                ],
                "self._has_valid_setitem_indexer": [
                    620
                ],
                "iloc": [
                    622,
                    623
                ],
                "self.obj.iloc": [
                    1086,
                    622
                ],
                "iloc._setitem_with_indexer": [
                    623
                ],
                "value": [
                    1796,
                    1669,
                    1799,
                    1672,
                    1679,
                    1682,
                    1556,
                    1815,
                    1561,
                    1817,
                    1818,
                    1693,
                    1565,
                    1822,
                    1824,
                    1697,
                    1570,
                    1698,
                    1827,
                    1829,
                    1706,
                    1710,
                    1715,
                    1717,
                    1595,
                    1723,
                    1729,
                    1735,
                    1610,
                    1611,
                    2008,
                    1753,
                    1758,
                    1633,
                    1762,
                    1764,
                    1765,
                    1772,
                    1518,
                    623
                ],
                "AbstractMethodError": [
                    834,
                    645,
                    840,
                    811,
                    1982
                ],
                "Tuple": [
                    833,
                    1410,
                    2051,
                    710,
                    647,
                    935,
                    874,
                    908,
                    1010,
                    691,
                    662,
                    1369,
                    765,
                    830,
                    991
                ],
                "i": [
                    1527,
                    1546,
                    651,
                    652,
                    1930,
                    1931,
                    655,
                    1553,
                    2196,
                    789,
                    1942,
                    676,
                    677,
                    1704,
                    1578,
                    1706,
                    684,
                    685,
                    1580,
                    687,
                    2046,
                    699,
                    703,
                    1856,
                    1354,
                    1355,
                    1358,
                    1361,
                    1362,
                    1364,
                    1748,
                    1749,
                    733,
                    1887,
                    1888,
                    737,
                    1382,
                    745,
                    751,
                    1525,
                    887,
                    891,
                    2045,
                    1534
                ],
                "k": [
                    1382,
                    1383,
                    651,
                    684,
                    687,
                    655,
                    2196,
                    2198,
                    887,
                    888,
                    895
                ],
                "self.ndim": [
                    772,
                    1924,
                    1546,
                    652,
                    1809,
                    676,
                    685,
                    1084,
                    706,
                    1604,
                    1863,
                    1608,
                    1353,
                    2004,
                    1877,
                    2005,
                    730,
                    1379,
                    742,
                    2027,
                    884,
                    1783,
                    1022
                ],
                "self._validate_key": [
                    1089,
                    1451,
                    1036,
                    655,
                    983
                ],
                "self._valid_types": [
                    1338,
                    659
                ],
                "err": [
                    1441,
                    660
                ],
                "self.obj.axes": [
                    1568,
                    1354,
                    1931,
                    1553,
                    2045,
                    1524,
                    1525,
                    1908,
                    891,
                    668,
                    669
                ],
                "is_nested_tuple": [
                    1082,
                    1163,
                    669
                ],
                "tup": [
                    772,
                    1412,
                    1414,
                    776,
                    1418,
                    783,
                    2193,
                    2196,
                    789,
                    669,
                    926,
                    930,
                    954,
                    699,
                    715,
                    718,
                    719,
                    726,
                    730,
                    733,
                    993,
                    998,
                    745,
                    1001,
                    1002,
                    1004,
                    751,
                    1015,
                    1022
                ],
                "keyidx": [
                    673,
                    678,
                    682,
                    688,
                    689
                ],
                "keyidx.append": [
                    688,
                    682,
                    678
                ],
                "is_setter": [
                    687,
                    2021,
                    679
                ],
                "idx": [
                    1539,
                    1928,
                    1935,
                    1936,
                    1944,
                    1946,
                    2075,
                    1949,
                    2077,
                    2087,
                    2089,
                    687,
                    688,
                    1587,
                    1860,
                    1747,
                    1748,
                    1887,
                    1891,
                    1892,
                    1894,
                    1653,
                    1654,
                    1534,
                    1535
                ],
                "retval": [
                    706,
                    698,
                    708,
                    703
                ],
                "com.is_null_slice": [
                    1860,
                    1892,
                    791,
                    1747,
                    1653,
                    758,
                    1527,
                    700
                ],
                "_getitem_axis": [
                    796,
                    703
                ],
                "retval.ndim": [
                    706
                ],
                "self._getitem_axis": [
                    737,
                    715,
                    828,
                    783
                ],
                "self._is_nested_tuple_indexer": [
                    718
                ],
                "self._getitem_nested_tuple": [
                    719
                ],
                "ax0": [
                    722,
                    725
                ],
                "result": [
                    776,
                    777,
                    778,
                    2122,
                    2124,
                    2125,
                    2132,
                    726,
                    727,
                    728,
                    2135,
                    2138,
                    2136,
                    2140
                ],
                "self._handle_lowerdim_multi_index_axis0": [
                    776,
                    726
                ],
                "is_label_like": [
                    734
                ],
                "section": [
                    737,
                    761,
                    742,
                    759
                ],
                "section.ndim": [
                    742
                ],
                "new_key": [
                    745,
                    751,
                    753,
                    754,
                    758,
                    761
                ],
                "obj": [
                    787,
                    2075,
                    795,
                    796,
                    800,
                    2082,
                    805,
                    808,
                    2221,
                    2222,
                    2223,
                    1471,
                    1474,
                    1476,
                    1864,
                    1097,
                    1099,
                    1101,
                    1878,
                    1888,
                    2032,
                    2033,
                    2034
                ],
                "current_ndim": [
                    795,
                    805
                ],
                "obj.ndim": [
                    795,
                    805
                ],
                "is_scalar": [
                    800,
                    2027,
                    1711,
                    1137,
                    888,
                    1913
                ],
                "self._is_scalar_access": [
                    816
                ],
                "self.obj._get_value": [
                    1994,
                    818
                ],
                "self._takeable": [
                    2008,
                    1994,
                    818
                ],
                "self._getitem_tuple": [
                    822
                ],
                "maybe_callable": [
                    827,
                    828
                ],
                "labels": [
                    1032,
                    1033,
                    1674,
                    1163,
                    1164,
                    1169,
                    1046,
                    2199,
                    1177,
                    1579,
                    1580,
                    1709,
                    1584,
                    1074,
                    1082,
                    1083,
                    1476,
                    1477,
                    844,
                    845,
                    1101,
                    1102,
                    1616,
                    1628,
                    1128,
                    1131,
                    1134,
                    1137,
                    1142,
                    1144,
                    1145
                ],
                "check_bool_indexer": [
                    1169,
                    845
                ],
                "inds": [
                    1170,
                    1171,
                    846,
                    847
                ],
                "key.nonzero": [
                    1170,
                    846
                ],
                "self.obj._take_with_is_copy": [
                    1438,
                    847
                ],
                "_LocationIndexer": [
                    851,
                    1293,
                    862
                ],
                "_takeable": [
                    1298,
                    852,
                    2013,
                    2039
                ],
                "Appender": [
                    1292,
                    850,
                    2037,
                    2011,
                    862
                ],
                "_LocationIndexer._validate_key.__doc__": [
                    862
                ],
                "_LocationIndexer._validate_key": [
                    862
                ],
                "ax._supports_partial_string_indexing": [
                    895
                ],
                "ax.is_unique": [
                    900,
                    1222
                ],
                "is_list_like_indexer": [
                    1952,
                    1633,
                    2211,
                    1988,
                    1669,
                    1895,
                    1326,
                    1166,
                    1040,
                    1358,
                    1455,
                    1822,
                    1556,
                    1180,
                    926
                ],
                "com.is_bool_indexer": [
                    930,
                    1450,
                    1038,
                    1168,
                    1304
                ],
                "d": [
                    952,
                    956
                ],
                "self._get_listlike_indexer": [
                    953,
                    986,
                    1174
                ],
                "self.obj._AXIS_ORDERS": [
                    954
                ],
                "self.obj._reindex_with_indexers": [
                    987,
                    956
                ],
                "keyarr": [
                    1216,
                    1224,
                    1226,
                    1228,
                    1229,
                    986,
                    988
                ],
                "self._getitem_lowerdim": [
                    993,
                    1414
                ],
                "self._has_valid_tuple": [
                    1412,
                    998
                ],
                "self._multi_take_opportunity": [
                    1001
                ],
                "self._multi_take": [
                    1002
                ],
                "self._getitem_tuple_same_dim": [
                    1418,
                    1004
                ],
                "self.obj._xs": [
                    1008
                ],
                "label": [
                    1008
                ],
                "self._get_label": [
                    1090,
                    1015
                ],
                "self.obj.index.nlevels": [
                    1022
                ],
                "self.obj.index": [
                    1953,
                    1717,
                    1784,
                    1625,
                    1022
                ],
                "ek": [
                    1023
                ],
                "item_from_zerodim": [
                    1460,
                    1028
                ],
                "is_iterator": [
                    1029
                ],
                "labels._get_partial_string_timestamp_match_key": [
                    1033
                ],
                "self._get_slice_axis": [
                    1037,
                    1445
                ],
                "self._getbool_axis": [
                    1452,
                    1039
                ],
                "ABCSeries": [
                    2177,
                    1832,
                    1610,
                    2123,
                    1815,
                    1048,
                    2236,
                    1758
                ],
                "np.ndarray": [
                    1856,
                    2177,
                    1933,
                    2096,
                    1048,
                    1849,
                    2236
                ],
                "np": [
                    1856,
                    1697,
                    2177,
                    2272,
                    2181,
                    1448,
                    1933,
                    1327,
                    2096,
                    1685,
                    2135,
                    1048,
                    1849,
                    1883,
                    2236,
                    1693
                ],
                "key.ndim": [
                    1048,
                    1059,
                    1076
                ],
                "ABCDataFrame": [
                    1672,
                    1923,
                    1052,
                    1764
                ],
                "self._getitem_iterable": [
                    1079
                ],
                "locs": [
                    1083,
                    1085
                ],
                "labels.get_locs": [
                    1083,
                    1164
                ],
                "need_slice": [
                    1473,
                    1098
                ],
                "slice_obj": [
                    1473,
                    1477,
                    1478,
                    1098,
                    1103
                ],
                "obj.copy": [
                    1474,
                    1099
                ],
                "obj._get_axis": [
                    1476,
                    1101
                ],
                "labels.slice_indexer": [
                    1102
                ],
                "slice_obj.start": [
                    1103
                ],
                "slice_obj.stop": [
                    1103
                ],
                "slice_obj.step": [
                    1103
                ],
                "self.obj._slice": [
                    1107,
                    1478
                ],
                "self.obj.take": [
                    1111
                ],
                "labels._convert_slice_indexer": [
                    1131
                ],
                "is_int_index": [
                    1134,
                    1135
                ],
                "labels.is_integer": [
                    1134
                ],
                "is_int_positional": [
                    1155,
                    1151,
                    1135
                ],
                "is_integer": [
                    1383,
                    1320,
                    1614,
                    1135,
                    1361,
                    1745,
                    1461,
                    1527,
                    2046
                ],
                "labels.get_loc": [
                    1584,
                    1177,
                    1142
                ],
                "labels.nlevels": [
                    1145
                ],
                "ax._convert_listlike_indexer": [
                    1216
                ],
                "self._validate_read_indexer": [
                    1219,
                    1228
                ],
                "raise_missing": [
                    1219,
                    1228,
                    1275
                ],
                "ax.get_indexer_for": [
                    1223
                ],
                "ax.reindex": [
                    1224
                ],
                "new_indexer": [
                    1794,
                    1795,
                    1570,
                    1796,
                    1226,
                    1567
                ],
                "ax._reindex_non_unique": [
                    1226
                ],
                "missing": [
                    1266,
                    1268,
                    1269,
                    1592,
                    1594
                ],
                "axis_name": [
                    1270,
                    1271
                ],
                "self.obj._get_axis_name": [
                    1270
                ],
                "not_found": [
                    1276,
                    1277
                ],
                "ax.is_categorical": [
                    1284
                ],
                "IndexingMixin.loc.__doc__": [
                    850
                ],
                "IndexingMixin.loc": [
                    850
                ],
                "IndexingMixin": [
                    850,
                    2011,
                    1292,
                    2037
                ],
                "key.index": [
                    1305,
                    1306,
                    2123
                ],
                "Index": [
                    2177,
                    1896,
                    1898,
                    2096,
                    1621,
                    1849,
                    1305,
                    2236
                ],
                "key.index.inferred_type": [
                    1306
                ],
                "self._validate_integer": [
                    1321,
                    1465
                ],
                "arr": [
                    1331,
                    1332,
                    1335,
                    1327
                ],
                "np.array": [
                    1697,
                    1327
                ],
                "len_axis": [
                    1328,
                    1404,
                    1405,
                    1335
                ],
                "is_numeric_dtype": [
                    1331
                ],
                "arr.dtype": [
                    1331
                ],
                "arr.max": [
                    1335
                ],
                "arr.min": [
                    1335
                ],
                "_tuplify": [
                    1608,
                    1353,
                    2004
                ],
                "np.asarray": [
                    1448,
                    2135
                ],
                "self._get_list_axis": [
                    1456
                ],
                "self.obj._ixs": [
                    1467,
                    1645
                ],
                "labels._validate_positional_slice": [
                    1477
                ],
                "info_axis": [
                    1508,
                    1605,
                    1546,
                    1613,
                    1680,
                    1744,
                    1745,
                    1749,
                    1753,
                    1599
                ],
                "self.obj._info_axis_number": [
                    1508
                ],
                "take_split_path": [
                    1602,
                    1511,
                    1515,
                    1519,
                    1529
                ],
                "self.obj._is_mixed_type": [
                    1511
                ],
                "self.obj._data.blocks": [
                    1515,
                    1516
                ],
                "self.obj._data": [
                    1829,
                    1515,
                    1516,
                    1804,
                    1580,
                    1772
                ],
                "blk": [
                    1516,
                    1517,
                    1519
                ],
                "blk.ndim": [
                    1517
                ],
                "val": [
                    1955,
                    1518,
                    1519,
                    1970,
                    1971,
                    1947,
                    1949,
                    1950
                ],
                "value.values": [
                    1518
                ],
                "blk._can_hold_element": [
                    1519
                ],
                "nindexer": [
                    1584,
                    1589,
                    1587,
                    1533
                ],
                "_": [
                    2066,
                    1539,
                    1877
                ],
                "convert_missing_indexer": [
                    1592,
                    1539
                ],
                "len_non_info_axes": [
                    1552,
                    1555
                ],
                "_ax": [
                    1553
                ],
                "_i": [
                    2168,
                    1553,
                    2166
                ],
                "l": [
                    1555
                ],
                "_infer_fill_value": [
                    1565
                ],
                "convert_from_missing_indexer_tuple": [
                    1567
                ],
                "self._setitem_with_indexer": [
                    1570,
                    1796
                ],
                "index": [
                    1793,
                    1794,
                    1578,
                    1579,
                    2123,
                    2124,
                    1784,
                    1785,
                    2138,
                    2136
                ],
                "index.insert": [
                    1785,
                    1579
                ],
                "_data": [
                    1829,
                    1580,
                    1804
                ],
                "self.obj.reindex": [
                    1580
                ],
                "self.obj._maybe_update_cacher": [
                    1773,
                    1581,
                    1830,
                    1807
                ],
                "self.obj._is_copy": [
                    1582
                ],
                "nindexer.append": [
                    1584,
                    1587
                ],
                "self._setitem_with_indexer_missing": [
                    1595
                ],
                "item_labels": [
                    1678,
                    1616,
                    1751,
                    1753,
                    1599
                ],
                "self._align_series": [
                    1681,
                    1762,
                    1611
                ],
                "info_idx": [
                    1613,
                    1614,
                    1615,
                    1616,
                    1619,
                    1620,
                    1622
                ],
                "ilocs": [
                    1729,
                    1698,
                    1734,
                    1704,
                    1677,
                    1619,
                    1715,
                    1622,
                    1723
                ],
                "ri": [
                    1621,
                    1622
                ],
                "self.obj.columns": [
                    1824,
                    1827,
                    1811,
                    1621,
                    1817
                ],
                "plane_indexer": [
                    1624,
                    1625,
                    1711,
                    1641
                ],
                "lplane_indexer": [
                    1633,
                    1641,
                    1710,
                    1717,
                    1625
                ],
                "length_of_indexer": [
                    1625
                ],
                "pi": [
                    1641,
                    1652,
                    1661,
                    1654
                ],
                "ser": [
                    1665,
                    1660,
                    1661,
                    1878,
                    1883,
                    1885,
                    1899,
                    1900,
                    1645,
                    1902,
                    1909,
                    1910,
                    1911,
                    1656,
                    1659,
                    1916,
                    1917,
                    1662,
                    1919
                ],
                "loc": [
                    1665,
                    1729,
                    1730,
                    1734,
                    1735,
                    1704,
                    1706,
                    1645,
                    1678,
                    1677,
                    2033,
                    2034,
                    2067,
                    1687
                ],
                "com.is_full_slice": [
                    1653
                ],
                "v": [
                    1729,
                    1730,
                    1681,
                    1685,
                    1687,
                    1656,
                    1661
                ],
                "ser._consolidate_inplace": [
                    1659
                ],
                "ser.copy": [
                    1660
                ],
                "ser._data": [
                    1661
                ],
                "ser._data.setitem": [
                    1661
                ],
                "ser._maybe_update_cacher": [
                    1662
                ],
                "self.obj._iset_item": [
                    1665
                ],
                "sub_indexer": [
                    1680,
                    1673,
                    1682
                ],
                "multiindex_indexer": [
                    1881,
                    1674,
                    1682
                ],
                "item": [
                    1680,
                    1682,
                    1678,
                    1679
                ],
                "np.nan": [
                    1685
                ],
                "isetter": [
                    1730,
                    1735,
                    1706,
                    1715,
                    1687
                ],
                "np.ndim": [
                    1693
                ],
                "value.shape": [
                    1698
                ],
                "tolist": [
                    1706
                ],
                "item_labels.is_unique": [
                    1751
                ],
                "maybe_convert_ix": [
                    1756
                ],
                "Series": [
                    1762,
                    1827,
                    1799
                ],
                "self._align_frame": [
                    1765
                ],
                "self.obj._check_is_chained_assignment_possible": [
                    1768
                ],
                "self.obj._consolidate_inplace": [
                    1771
                ],
                "self.obj._data.setitem": [
                    1772
                ],
                "new_index": [
                    1785,
                    1794,
                    1805
                ],
                "index.is_unique": [
                    1793
                ],
                "index.get_indexer": [
                    1794
                ],
                "new_values": [
                    1803,
                    1805,
                    1799
                ],
                "_values": [
                    1955,
                    1799,
                    1902,
                    1970,
                    2132,
                    1878,
                    1911,
                    1947,
                    1949,
                    1919
                ],
                "self.obj._values": [
                    1800,
                    1803
                ],
                "concat_compat": [
                    1803
                ],
                "self.obj._constructor": [
                    1804
                ],
                "self.obj.name": [
                    1805
                ],
                "value.reindex": [
                    1817
                ],
                "value.name": [
                    1818
                ],
                "self.obj.append": [
                    1829
                ],
                "i.ravel": [
                    1856
                ],
                "ravel": [
                    1858
                ],
                "aligners": [
                    1873,
                    1860,
                    1861
                ],
                "sum_aligners": [
                    1877,
                    1861,
                    1862
                ],
                "single_aligner": [
                    1873,
                    1892,
                    1862,
                    1905
                ],
                "is_frame": [
                    1872,
                    1924,
                    1952,
                    1863
                ],
                "is_sequence": [
                    1891,
                    1932,
                    1877
                ],
                "ser.reindex": [
                    1902,
                    1919,
                    1878,
                    1911
                ],
                "obj.axes": [
                    1888,
                    1878
                ],
                "len_indexer": [
                    1882,
                    1883
                ],
                "T": [
                    1883
                ],
                "reshape": [
                    1883
                ],
                "np.tile": [
                    1883
                ],
                "new_ix": [
                    1894,
                    1895,
                    1896,
                    1898,
                    1899,
                    1902
                ],
                "ser.index.equals": [
                    1899,
                    1916,
                    1909
                ],
                "ser.index": [
                    1899,
                    1916,
                    1909
                ],
                "ser._values.copy": [
                    1900,
                    1917,
                    1910
                ],
                "ser._values": [
                    1900,
                    1917,
                    1910
                ],
                "cols": [
                    1928,
                    1937,
                    1938,
                    1944,
                    1946,
                    1949
                ],
                "sindexers": [
                    1929,
                    1942
                ],
                "ix": [
                    1930,
                    1932,
                    1933,
                    1934,
                    1936,
                    1938
                ],
                "ix.ravel": [
                    1934
                ],
                "sindexers.append": [
                    1942
                ],
                "df.index.equals": [
                    1954,
                    1946
                ],
                "df.index": [
                    1954,
                    1946,
                    1962,
                    1963
                ],
                "df": [
                    1954,
                    1955,
                    2275,
                    1962,
                    1963,
                    1970,
                    1946,
                    1947,
                    1949
                ],
                "df.columns.equals": [
                    1946
                ],
                "df.columns": [
                    1946
                ],
                "df.copy": [
                    1947,
                    1955
                ],
                "df.reindex": [
                    1970,
                    1949
                ],
                "ax.nlevels": [
                    1963
                ],
                "df.index.nlevels": [
                    1963
                ],
                "IndexingMixin.iloc.__doc__": [
                    1292
                ],
                "IndexingMixin.iloc": [
                    1292
                ],
                "self._convert_key": [
                    1993,
                    2007
                ],
                "self.obj._set_value": [
                    2008
                ],
                "_ScalarAccessIndexer": [
                    2012,
                    2038
                ],
                "__getitem__": [
                    2029
                ],
                "obj.index.get_loc": [
                    2033
                ],
                "obj.index": [
                    2033,
                    2034,
                    2075
                ],
                "obj.index._get_values_for_loc": [
                    2034
                ],
                "IndexingMixin.at.__doc__": [
                    2011
                ],
                "IndexingMixin.at": [
                    2011
                ],
                "a": [
                    2045
                ],
                "IndexingMixin.iat.__doc__": [
                    2037
                ],
                "IndexingMixin.iat": [
                    2037
                ],
                "Hashable": [
                    2065,
                    2051
                ],
                "_tup": [
                    2065,
                    2066,
                    2067,
                    2068
                ],
                "List": [
                    2065
                ],
                "Union": [
                    2065,
                    2051
                ],
                "ndim": [
                    2066
                ],
                "idx._convert_slice_indexer": [
                    2077
                ],
                "obj._data.items": [
                    2082
                ],
                "obj._data": [
                    2082
                ],
                "idx._supports_partial_string_indexing": [
                    2087
                ],
                "idx._get_string_slice": [
                    2089
                ],
                "key.index.equals": [
                    2123
                ],
                "result.reindex": [
                    2124
                ],
                "mask": [
                    2125,
                    2126
                ],
                "isna": [
                    2125
                ],
                "result._values": [
                    2125
                ],
                "mask.any": [
                    2126
                ],
                "result.astype": [
                    2132
                ],
                "is_object_dtype": [
                    2133
                ],
                "check_array_indexer": [
                    2136,
                    2138
                ],
                "_idx": [
                    2168,
                    2166
                ],
                "get_loc": [
                    2166
                ],
                "axes": [
                    2166
                ],
                "get_indexer": [
                    2168
                ],
                "ixify": [
                    2178,
                    2180,
                    2175
                ],
                "args": [
                    2176,
                    2181,
                    2183
                ],
                "np.ix_": [
                    2181
                ],
                "is_list_like": [
                    2250,
                    2254,
                    2198
                ],
                "obj.start": [
                    2221
                ],
                "obj.stop": [
                    2222
                ],
                "obj.step": [
                    2223
                ],
                "kinds": [
                    2236,
                    2237
                ],
                "slice_": [
                    2275,
                    2276,
                    2254,
                    2255,
                    2257,
                    2260,
                    2262,
                    2263,
                    2237,
                    2238,
                    2271
                ],
                "part": [
                    2250,
                    2251,
                    2262
                ],
                "pred": [
                    2262
                ],
                "dtypes": [
                    2272,
                    2274,
                    2275
                ],
                "np.number": [
                    2272
                ],
                "include_bool": [
                    2273
                ],
                "dtypes.append": [
                    2274
                ],
                "columns": [
                    2275
                ],
                "df.select_dtypes": [
                    2275
                ]
            }
        },
        "test_data": [
            {
                "test_path": "/Volumes/JerrySSD/bgp_envs/repos/pandas_47/pandas/tests/frame/indexing/test_indexing.py",
                "test_function": "test_setitem_list_missing_columns",
                "test_function_code": "    @pytest.mark.parametrize(\n        \"columns,box,expected\",\n        [\n            (\n                [\"A\", \"B\", \"C\", \"D\"],\n                7,\n                pd.DataFrame(\n                    [[7, 7, 7, 7], [7, 7, 7, 7], [7, 7, 7, 7]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                [\"C\", \"D\"],\n                [7, 8],\n                pd.DataFrame(\n                    [[1, 2, 7, 8], [3, 4, 7, 8], [5, 6, 7, 8]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                [\"A\", \"B\", \"C\"],\n                np.array([7, 8, 9], dtype=np.int64),\n                pd.DataFrame(\n                    [[7, 8, 9], [7, 8, 9], [7, 8, 9]], columns=[\"A\", \"B\", \"C\"]\n                ),\n            ),\n            (\n                [\"B\", \"C\", \"D\"],\n                [[7, 8, 9], [10, 11, 12], [13, 14, 15]],\n                pd.DataFrame(\n                    [[1, 7, 8, 9], [3, 10, 11, 12], [5, 13, 14, 15]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                [\"C\", \"A\", \"D\"],\n                np.array([[7, 8, 9], [10, 11, 12], [13, 14, 15]], dtype=np.int64),\n                pd.DataFrame(\n                    [[8, 2, 7, 9], [11, 4, 10, 12], [14, 6, 13, 15]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                [\"A\", \"C\"],\n                pd.DataFrame([[7, 8], [9, 10], [11, 12]], columns=[\"A\", \"C\"]),\n                pd.DataFrame(\n                    [[7, 2, 8], [9, 4, 10], [11, 6, 12]], columns=[\"A\", \"B\", \"C\"]\n                ),\n            ),\n        ],\n    )\n    def test_setitem_list_missing_columns(self, columns, box, expected):\n        # GH 29334\n        df = pd.DataFrame([[1, 2], [3, 4], [5, 6]], columns=[\"A\", \"B\"])\n        df[columns] = box\n        tm.assert_frame_equal(df, expected)",
                "test_error": "KeyError: 'Passing list-likes to .loc or [] with any missing labels is no longer supported, see https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike'",
                "full_test_error": "self = <test_indexing.TestDataFrameIndexing object at 0x120f6e5e0>\ncolumns = ['A', 'B', 'C', 'D'], box = 7\nexpected =    A  B  C  D\n0  7  7  7  7\n1  7  7  7  7\n2  7  7  7  7\n\n    @pytest.mark.parametrize(\n        \"columns,box,expected\",\n        [\n            (\n                [\"A\", \"B\", \"C\", \"D\"],\n                7,\n                pd.DataFrame(\n                    [[7, 7, 7, 7], [7, 7, 7, 7], [7, 7, 7, 7]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                [\"C\", \"D\"],\n                [7, 8],\n                pd.DataFrame(\n                    [[1, 2, 7, 8], [3, 4, 7, 8], [5, 6, 7, 8]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                [\"A\", \"B\", \"C\"],\n                np.array([7, 8, 9], dtype=np.int64),\n                pd.DataFrame(\n                    [[7, 8, 9], [7, 8, 9], [7, 8, 9]], columns=[\"A\", \"B\", \"C\"]\n                ),\n            ),\n            (\n                [\"B\", \"C\", \"D\"],\n                [[7, 8, 9], [10, 11, 12], [13, 14, 15]],\n                pd.DataFrame(\n                    [[1, 7, 8, 9], [3, 10, 11, 12], [5, 13, 14, 15]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                [\"C\", \"A\", \"D\"],\n                np.array([[7, 8, 9], [10, 11, 12], [13, 14, 15]], dtype=np.int64),\n                pd.DataFrame(\n                    [[8, 2, 7, 9], [11, 4, 10, 12], [14, 6, 13, 15]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                [\"A\", \"C\"],\n                pd.DataFrame([[7, 8], [9, 10], [11, 12]], columns=[\"A\", \"C\"]),\n                pd.DataFrame(\n                    [[7, 2, 8], [9, 4, 10], [11, 6, 12]], columns=[\"A\", \"B\", \"C\"]\n                ),\n            ),\n        ],\n    )\n    def test_setitem_list_missing_columns(self, columns, box, expected):\n        # GH 29334\n        df = pd.DataFrame([[1, 2], [3, 4], [5, 6]], columns=[\"A\", \"B\"])\n>       df[columns] = box\n\npandas/tests/frame/indexing/test_indexing.py:272: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \npandas/core/frame.py:2660: in __setitem__\n    self._setitem_array(key, value)\npandas/core/frame.py:2690: in _setitem_array\n    indexer = self.loc._get_listlike_indexer(\npandas/core/indexing.py:1228: in _get_listlike_indexer\n    self._validate_read_indexer(keyarr, indexer, axis, raise_missing=raise_missing)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <pandas.core.indexing._LocIndexer object at 0x118f8a5e0>\nkey = Index(['A', 'B', 'C', 'D'], dtype='object')\nindexer = array([ 0,  1, -1, -1]), axis = 1, raise_missing = False\n\n    def _validate_read_indexer(\n        self, key, indexer, axis: int, raise_missing: bool = False\n    ):\n        \"\"\"\n        Check that indexer can be used to return a result.\n    \n        e.g. at least one element was found,\n        unless the list of keys was actually empty.\n    \n        Parameters\n        ----------\n        key : list-like\n            Targeted labels (only used to show correct error message).\n        indexer: array-like of booleans\n            Indices corresponding to the key,\n            (with -1 indicating not found).\n        axis: int\n            Dimension on which the indexing is being made.\n        raise_missing: bool\n            Whether to raise a KeyError if some labels are not found. Will be\n            removed in the future, and then this method will always behave as\n            if raise_missing=True.\n    \n        Raises\n        ------\n        KeyError\n            If at least one key was requested but none was found, and\n            raise_missing=True.\n        \"\"\"\n        ax = self.obj._get_axis(axis)\n    \n        if len(key) == 0:\n            return\n    \n        # Count missing values:\n        missing = (indexer < 0).sum()\n    \n        if missing:\n            if missing == len(indexer):\n                axis_name = self.obj._get_axis_name(axis)\n                raise KeyError(f\"None of [{key}] are in the [{axis_name}]\")\n    \n            # We (temporarily) allow for some missing keys with .loc, except in\n            # some cases (e.g. setting) in which \"raise_missing\" will be False\n            if raise_missing:\n                not_found = list(set(key) - set(ax))\n                raise KeyError(f\"{not_found} not in index\")\n    \n            # we skip the warning on Categorical\n            # as this check is actually done (check for\n            # non-missing values), but a bit later in the\n            # code, so we want to avoid warning & then\n            # just raising\n            if not ax.is_categorical():\n>               raise KeyError(\n                    \"Passing list-likes to .loc or [] with any missing labels \"\n                    \"is no longer supported, see \"\n                    \"https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\"  # noqa:E501\n                )\nE               KeyError: 'Passing list-likes to .loc or [] with any missing labels is no longer supported, see https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike'\n\npandas/core/indexing.py:1285: KeyError",
                "traceback": "pandas/core/frame.py:2660: in __setitem__\n    self._setitem_array(key, value)\npandas/core/frame.py:2690: in _setitem_array\n    indexer = self.loc._get_listlike_indexer(\npandas/core/indexing.py:1228: in _get_listlike_indexer\n    self._validate_read_indexer(keyarr, indexer, axis, raise_missing=raise_missing)",
                "test_error_location": "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <pandas.core.indexing._LocIndexer object at 0x118f8a5e0>\nkey = Index(['A', 'B', 'C', 'D'], dtype='object')\nindexer = array([ 0,  1, -1, -1]), axis = 1, raise_missing = False\n\n    def _validate_read_indexer(\n        self, key, indexer, axis: int, raise_missing: bool = False\n    ):\n        \"\"\"\n        Check that indexer can be used to return a result.\n    \n        e.g. at least one element was found,\n        unless the list of keys was actually empty.\n    \n        Parameters\n        ----------\n        key : list-like\n            Targeted labels (only used to show correct error message).\n        indexer: array-like of booleans\n            Indices corresponding to the key,\n            (with -1 indicating not found).\n        axis: int\n            Dimension on which the indexing is being made.\n        raise_missing: bool\n            Whether to raise a KeyError if some labels are not found. Will be\n            removed in the future, and then this method will always behave as\n            if raise_missing=True.\n    \n        Raises\n        ------\n        KeyError\n            If at least one key was requested but none was found, and\n            raise_missing=True.\n        \"\"\"\n        ax = self.obj._get_axis(axis)\n    \n        if len(key) == 0:\n            return\n    \n        # Count missing values:\n        missing = (indexer < 0).sum()\n    \n        if missing:\n            if missing == len(indexer):\n                axis_name = self.obj._get_axis_name(axis)\n                raise KeyError(f\"None of [{key}] are in the [{axis_name}]\")\n    \n            # We (temporarily) allow for some missing keys with .loc, except in\n            # some cases (e.g. setting) in which \"raise_missing\" will be False\n            if raise_missing:\n                not_found = list(set(key) - set(ax))\n                raise KeyError(f\"{not_found} not in index\")\n    \n            # we skip the warning on Categorical\n            # as this check is actually done (check for\n            # non-missing values), but a bit later in the\n            # code, so we want to avoid warning & then\n            # just raising\n            if not ax.is_categorical():\n>               raise KeyError(\n                    \"Passing list-likes to .loc or [] with any missing labels \"\n                    \"is no longer supported, see \"\n                    \"https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\"  # noqa:E501\n                )\nE               KeyError: 'Passing list-likes to .loc or [] with any missing labels is no longer supported, see https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike'\n\npandas/core/indexing.py:1285: KeyError",
                "test_function_decorators": [
                    "pytest.mark.parametrize('columns,box,expected', [(['A', 'B', 'C', 'D'], 7, pd.DataFrame([[7, 7, 7, 7], [7, 7, 7, 7], [7, 7, 7, 7]], columns=['A', 'B', 'C', 'D'])), (['C', 'D'], [7, 8], pd.DataFrame([[1, 2, 7, 8], [3, 4, 7, 8], [5, 6, 7, 8]], columns=['A', 'B', 'C', 'D'])), (['A', 'B', 'C'], np.array([7, 8, 9], dtype=np.int64), pd.DataFrame([[7, 8, 9], [7, 8, 9], [7, 8, 9]], columns=['A', 'B', 'C'])), (['B', 'C', 'D'], [[7, 8, 9], [10, 11, 12], [13, 14, 15]], pd.DataFrame([[1, 7, 8, 9], [3, 10, 11, 12], [5, 13, 14, 15]], columns=['A', 'B', 'C', 'D'])), (['C', 'A', 'D'], np.array([[7, 8, 9], [10, 11, 12], [13, 14, 15]], dtype=np.int64), pd.DataFrame([[8, 2, 7, 9], [11, 4, 10, 12], [14, 6, 13, 15]], columns=['A', 'B', 'C', 'D'])), (['A', 'C'], pd.DataFrame([[7, 8], [9, 10], [11, 12]], columns=['A', 'C']), pd.DataFrame([[7, 2, 8], [9, 4, 10], [11, 6, 12]], columns=['A', 'B', 'C']))])"
                ]
            },
            {
                "test_path": "/Volumes/JerrySSD/bgp_envs/repos/pandas_47/pandas/tests/frame/indexing/test_indexing.py",
                "test_function": "test_setitem_list_missing_columns",
                "test_function_code": "    @pytest.mark.parametrize(\n        \"columns,box,expected\",\n        [\n            (\n                [\"A\", \"B\", \"C\", \"D\"],\n                7,\n                pd.DataFrame(\n                    [[7, 7, 7, 7], [7, 7, 7, 7], [7, 7, 7, 7]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                [\"C\", \"D\"],\n                [7, 8],\n                pd.DataFrame(\n                    [[1, 2, 7, 8], [3, 4, 7, 8], [5, 6, 7, 8]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                [\"A\", \"B\", \"C\"],\n                np.array([7, 8, 9], dtype=np.int64),\n                pd.DataFrame(\n                    [[7, 8, 9], [7, 8, 9], [7, 8, 9]], columns=[\"A\", \"B\", \"C\"]\n                ),\n            ),\n            (\n                [\"B\", \"C\", \"D\"],\n                [[7, 8, 9], [10, 11, 12], [13, 14, 15]],\n                pd.DataFrame(\n                    [[1, 7, 8, 9], [3, 10, 11, 12], [5, 13, 14, 15]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                [\"C\", \"A\", \"D\"],\n                np.array([[7, 8, 9], [10, 11, 12], [13, 14, 15]], dtype=np.int64),\n                pd.DataFrame(\n                    [[8, 2, 7, 9], [11, 4, 10, 12], [14, 6, 13, 15]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                [\"A\", \"C\"],\n                pd.DataFrame([[7, 8], [9, 10], [11, 12]], columns=[\"A\", \"C\"]),\n                pd.DataFrame(\n                    [[7, 2, 8], [9, 4, 10], [11, 6, 12]], columns=[\"A\", \"B\", \"C\"]\n                ),\n            ),\n        ],\n    )\n    def test_setitem_list_missing_columns(self, columns, box, expected):\n        # GH 29334\n        df = pd.DataFrame([[1, 2], [3, 4], [5, 6]], columns=[\"A\", \"B\"])\n        df[columns] = box\n        tm.assert_frame_equal(df, expected)",
                "test_error": "KeyError: \"None of [Index(['C', 'D'], dtype='object')] are in the [columns]\"",
                "full_test_error": "self = <test_indexing.TestDataFrameIndexing object at 0x120df16a0>\ncolumns = ['C', 'D'], box = [7, 8]\nexpected =    A  B  C  D\n0  1  2  7  8\n1  3  4  7  8\n2  5  6  7  8\n\n    @pytest.mark.parametrize(\n        \"columns,box,expected\",\n        [\n            (\n                [\"A\", \"B\", \"C\", \"D\"],\n                7,\n                pd.DataFrame(\n                    [[7, 7, 7, 7], [7, 7, 7, 7], [7, 7, 7, 7]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                [\"C\", \"D\"],\n                [7, 8],\n                pd.DataFrame(\n                    [[1, 2, 7, 8], [3, 4, 7, 8], [5, 6, 7, 8]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                [\"A\", \"B\", \"C\"],\n                np.array([7, 8, 9], dtype=np.int64),\n                pd.DataFrame(\n                    [[7, 8, 9], [7, 8, 9], [7, 8, 9]], columns=[\"A\", \"B\", \"C\"]\n                ),\n            ),\n            (\n                [\"B\", \"C\", \"D\"],\n                [[7, 8, 9], [10, 11, 12], [13, 14, 15]],\n                pd.DataFrame(\n                    [[1, 7, 8, 9], [3, 10, 11, 12], [5, 13, 14, 15]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                [\"C\", \"A\", \"D\"],\n                np.array([[7, 8, 9], [10, 11, 12], [13, 14, 15]], dtype=np.int64),\n                pd.DataFrame(\n                    [[8, 2, 7, 9], [11, 4, 10, 12], [14, 6, 13, 15]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                [\"A\", \"C\"],\n                pd.DataFrame([[7, 8], [9, 10], [11, 12]], columns=[\"A\", \"C\"]),\n                pd.DataFrame(\n                    [[7, 2, 8], [9, 4, 10], [11, 6, 12]], columns=[\"A\", \"B\", \"C\"]\n                ),\n            ),\n        ],\n    )\n    def test_setitem_list_missing_columns(self, columns, box, expected):\n        # GH 29334\n        df = pd.DataFrame([[1, 2], [3, 4], [5, 6]], columns=[\"A\", \"B\"])\n>       df[columns] = box\n\npandas/tests/frame/indexing/test_indexing.py:272: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \npandas/core/frame.py:2660: in __setitem__\n    self._setitem_array(key, value)\npandas/core/frame.py:2690: in _setitem_array\n    indexer = self.loc._get_listlike_indexer(\npandas/core/indexing.py:1228: in _get_listlike_indexer\n    self._validate_read_indexer(keyarr, indexer, axis, raise_missing=raise_missing)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <pandas.core.indexing._LocIndexer object at 0x118f48ae0>\nkey = Index(['C', 'D'], dtype='object'), indexer = array([-1, -1]), axis = 1\nraise_missing = False\n\n    def _validate_read_indexer(\n        self, key, indexer, axis: int, raise_missing: bool = False\n    ):\n        \"\"\"\n        Check that indexer can be used to return a result.\n    \n        e.g. at least one element was found,\n        unless the list of keys was actually empty.\n    \n        Parameters\n        ----------\n        key : list-like\n            Targeted labels (only used to show correct error message).\n        indexer: array-like of booleans\n            Indices corresponding to the key,\n            (with -1 indicating not found).\n        axis: int\n            Dimension on which the indexing is being made.\n        raise_missing: bool\n            Whether to raise a KeyError if some labels are not found. Will be\n            removed in the future, and then this method will always behave as\n            if raise_missing=True.\n    \n        Raises\n        ------\n        KeyError\n            If at least one key was requested but none was found, and\n            raise_missing=True.\n        \"\"\"\n        ax = self.obj._get_axis(axis)\n    \n        if len(key) == 0:\n            return\n    \n        # Count missing values:\n        missing = (indexer < 0).sum()\n    \n        if missing:\n            if missing == len(indexer):\n                axis_name = self.obj._get_axis_name(axis)\n>               raise KeyError(f\"None of [{key}] are in the [{axis_name}]\")\nE               KeyError: \"None of [Index(['C', 'D'], dtype='object')] are in the [columns]\"\n\npandas/core/indexing.py:1271: KeyError",
                "traceback": "pandas/core/frame.py:2660: in __setitem__\n    self._setitem_array(key, value)\npandas/core/frame.py:2690: in _setitem_array\n    indexer = self.loc._get_listlike_indexer(\npandas/core/indexing.py:1228: in _get_listlike_indexer\n    self._validate_read_indexer(keyarr, indexer, axis, raise_missing=raise_missing)",
                "test_error_location": "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <pandas.core.indexing._LocIndexer object at 0x118f48ae0>\nkey = Index(['C', 'D'], dtype='object'), indexer = array([-1, -1]), axis = 1\nraise_missing = False\n\n    def _validate_read_indexer(\n        self, key, indexer, axis: int, raise_missing: bool = False\n    ):\n        \"\"\"\n        Check that indexer can be used to return a result.\n    \n        e.g. at least one element was found,\n        unless the list of keys was actually empty.\n    \n        Parameters\n        ----------\n        key : list-like\n            Targeted labels (only used to show correct error message).\n        indexer: array-like of booleans\n            Indices corresponding to the key,\n            (with -1 indicating not found).\n        axis: int\n            Dimension on which the indexing is being made.\n        raise_missing: bool\n            Whether to raise a KeyError if some labels are not found. Will be\n            removed in the future, and then this method will always behave as\n            if raise_missing=True.\n    \n        Raises\n        ------\n        KeyError\n            If at least one key was requested but none was found, and\n            raise_missing=True.\n        \"\"\"\n        ax = self.obj._get_axis(axis)\n    \n        if len(key) == 0:\n            return\n    \n        # Count missing values:\n        missing = (indexer < 0).sum()\n    \n        if missing:\n            if missing == len(indexer):\n                axis_name = self.obj._get_axis_name(axis)\n>               raise KeyError(f\"None of [{key}] are in the [{axis_name}]\")\nE               KeyError: \"None of [Index(['C', 'D'], dtype='object')] are in the [columns]\"\n\npandas/core/indexing.py:1271: KeyError",
                "test_function_decorators": [
                    "pytest.mark.parametrize('columns,box,expected', [(['A', 'B', 'C', 'D'], 7, pd.DataFrame([[7, 7, 7, 7], [7, 7, 7, 7], [7, 7, 7, 7]], columns=['A', 'B', 'C', 'D'])), (['C', 'D'], [7, 8], pd.DataFrame([[1, 2, 7, 8], [3, 4, 7, 8], [5, 6, 7, 8]], columns=['A', 'B', 'C', 'D'])), (['A', 'B', 'C'], np.array([7, 8, 9], dtype=np.int64), pd.DataFrame([[7, 8, 9], [7, 8, 9], [7, 8, 9]], columns=['A', 'B', 'C'])), (['B', 'C', 'D'], [[7, 8, 9], [10, 11, 12], [13, 14, 15]], pd.DataFrame([[1, 7, 8, 9], [3, 10, 11, 12], [5, 13, 14, 15]], columns=['A', 'B', 'C', 'D'])), (['C', 'A', 'D'], np.array([[7, 8, 9], [10, 11, 12], [13, 14, 15]], dtype=np.int64), pd.DataFrame([[8, 2, 7, 9], [11, 4, 10, 12], [14, 6, 13, 15]], columns=['A', 'B', 'C', 'D'])), (['A', 'C'], pd.DataFrame([[7, 8], [9, 10], [11, 12]], columns=['A', 'C']), pd.DataFrame([[7, 2, 8], [9, 4, 10], [11, 6, 12]], columns=['A', 'B', 'C']))])"
                ]
            },
            {
                "test_path": "/Volumes/JerrySSD/bgp_envs/repos/pandas_47/pandas/tests/frame/indexing/test_indexing.py",
                "test_function": "test_setitem_list_missing_columns",
                "test_function_code": "    @pytest.mark.parametrize(\n        \"columns,box,expected\",\n        [\n            (\n                [\"A\", \"B\", \"C\", \"D\"],\n                7,\n                pd.DataFrame(\n                    [[7, 7, 7, 7], [7, 7, 7, 7], [7, 7, 7, 7]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                [\"C\", \"D\"],\n                [7, 8],\n                pd.DataFrame(\n                    [[1, 2, 7, 8], [3, 4, 7, 8], [5, 6, 7, 8]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                [\"A\", \"B\", \"C\"],\n                np.array([7, 8, 9], dtype=np.int64),\n                pd.DataFrame(\n                    [[7, 8, 9], [7, 8, 9], [7, 8, 9]], columns=[\"A\", \"B\", \"C\"]\n                ),\n            ),\n            (\n                [\"B\", \"C\", \"D\"],\n                [[7, 8, 9], [10, 11, 12], [13, 14, 15]],\n                pd.DataFrame(\n                    [[1, 7, 8, 9], [3, 10, 11, 12], [5, 13, 14, 15]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                [\"C\", \"A\", \"D\"],\n                np.array([[7, 8, 9], [10, 11, 12], [13, 14, 15]], dtype=np.int64),\n                pd.DataFrame(\n                    [[8, 2, 7, 9], [11, 4, 10, 12], [14, 6, 13, 15]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                [\"A\", \"C\"],\n                pd.DataFrame([[7, 8], [9, 10], [11, 12]], columns=[\"A\", \"C\"]),\n                pd.DataFrame(\n                    [[7, 2, 8], [9, 4, 10], [11, 6, 12]], columns=[\"A\", \"B\", \"C\"]\n                ),\n            ),\n        ],\n    )\n    def test_setitem_list_missing_columns(self, columns, box, expected):\n        # GH 29334\n        df = pd.DataFrame([[1, 2], [3, 4], [5, 6]], columns=[\"A\", \"B\"])\n        df[columns] = box\n        tm.assert_frame_equal(df, expected)",
                "test_error": "KeyError: 'Passing list-likes to .loc or [] with any missing labels is no longer supported, see https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike'",
                "full_test_error": "self = <test_indexing.TestDataFrameIndexing object at 0x12119d820>\ncolumns = ['A', 'B', 'C'], box = array([7, 8, 9])\nexpected =    A  B  C\n0  7  8  9\n1  7  8  9\n2  7  8  9\n\n    @pytest.mark.parametrize(\n        \"columns,box,expected\",\n        [\n            (\n                [\"A\", \"B\", \"C\", \"D\"],\n                7,\n                pd.DataFrame(\n                    [[7, 7, 7, 7], [7, 7, 7, 7], [7, 7, 7, 7]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                [\"C\", \"D\"],\n                [7, 8],\n                pd.DataFrame(\n                    [[1, 2, 7, 8], [3, 4, 7, 8], [5, 6, 7, 8]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                [\"A\", \"B\", \"C\"],\n                np.array([7, 8, 9], dtype=np.int64),\n                pd.DataFrame(\n                    [[7, 8, 9], [7, 8, 9], [7, 8, 9]], columns=[\"A\", \"B\", \"C\"]\n                ),\n            ),\n            (\n                [\"B\", \"C\", \"D\"],\n                [[7, 8, 9], [10, 11, 12], [13, 14, 15]],\n                pd.DataFrame(\n                    [[1, 7, 8, 9], [3, 10, 11, 12], [5, 13, 14, 15]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                [\"C\", \"A\", \"D\"],\n                np.array([[7, 8, 9], [10, 11, 12], [13, 14, 15]], dtype=np.int64),\n                pd.DataFrame(\n                    [[8, 2, 7, 9], [11, 4, 10, 12], [14, 6, 13, 15]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                [\"A\", \"C\"],\n                pd.DataFrame([[7, 8], [9, 10], [11, 12]], columns=[\"A\", \"C\"]),\n                pd.DataFrame(\n                    [[7, 2, 8], [9, 4, 10], [11, 6, 12]], columns=[\"A\", \"B\", \"C\"]\n                ),\n            ),\n        ],\n    )\n    def test_setitem_list_missing_columns(self, columns, box, expected):\n        # GH 29334\n        df = pd.DataFrame([[1, 2], [3, 4], [5, 6]], columns=[\"A\", \"B\"])\n>       df[columns] = box\n\npandas/tests/frame/indexing/test_indexing.py:272: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \npandas/core/frame.py:2660: in __setitem__\n    self._setitem_array(key, value)\npandas/core/frame.py:2690: in _setitem_array\n    indexer = self.loc._get_listlike_indexer(\npandas/core/indexing.py:1228: in _get_listlike_indexer\n    self._validate_read_indexer(keyarr, indexer, axis, raise_missing=raise_missing)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <pandas.core.indexing._LocIndexer object at 0x120f6d180>\nkey = Index(['A', 'B', 'C'], dtype='object'), indexer = array([ 0,  1, -1])\naxis = 1, raise_missing = False\n\n    def _validate_read_indexer(\n        self, key, indexer, axis: int, raise_missing: bool = False\n    ):\n        \"\"\"\n        Check that indexer can be used to return a result.\n    \n        e.g. at least one element was found,\n        unless the list of keys was actually empty.\n    \n        Parameters\n        ----------\n        key : list-like\n            Targeted labels (only used to show correct error message).\n        indexer: array-like of booleans\n            Indices corresponding to the key,\n            (with -1 indicating not found).\n        axis: int\n            Dimension on which the indexing is being made.\n        raise_missing: bool\n            Whether to raise a KeyError if some labels are not found. Will be\n            removed in the future, and then this method will always behave as\n            if raise_missing=True.\n    \n        Raises\n        ------\n        KeyError\n            If at least one key was requested but none was found, and\n            raise_missing=True.\n        \"\"\"\n        ax = self.obj._get_axis(axis)\n    \n        if len(key) == 0:\n            return\n    \n        # Count missing values:\n        missing = (indexer < 0).sum()\n    \n        if missing:\n            if missing == len(indexer):\n                axis_name = self.obj._get_axis_name(axis)\n                raise KeyError(f\"None of [{key}] are in the [{axis_name}]\")\n    \n            # We (temporarily) allow for some missing keys with .loc, except in\n            # some cases (e.g. setting) in which \"raise_missing\" will be False\n            if raise_missing:\n                not_found = list(set(key) - set(ax))\n                raise KeyError(f\"{not_found} not in index\")\n    \n            # we skip the warning on Categorical\n            # as this check is actually done (check for\n            # non-missing values), but a bit later in the\n            # code, so we want to avoid warning & then\n            # just raising\n            if not ax.is_categorical():\n>               raise KeyError(\n                    \"Passing list-likes to .loc or [] with any missing labels \"\n                    \"is no longer supported, see \"\n                    \"https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\"  # noqa:E501\n                )\nE               KeyError: 'Passing list-likes to .loc or [] with any missing labels is no longer supported, see https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike'\n\npandas/core/indexing.py:1285: KeyError",
                "traceback": "pandas/core/frame.py:2660: in __setitem__\n    self._setitem_array(key, value)\npandas/core/frame.py:2690: in _setitem_array\n    indexer = self.loc._get_listlike_indexer(\npandas/core/indexing.py:1228: in _get_listlike_indexer\n    self._validate_read_indexer(keyarr, indexer, axis, raise_missing=raise_missing)",
                "test_error_location": "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <pandas.core.indexing._LocIndexer object at 0x120f6d180>\nkey = Index(['A', 'B', 'C'], dtype='object'), indexer = array([ 0,  1, -1])\naxis = 1, raise_missing = False\n\n    def _validate_read_indexer(\n        self, key, indexer, axis: int, raise_missing: bool = False\n    ):\n        \"\"\"\n        Check that indexer can be used to return a result.\n    \n        e.g. at least one element was found,\n        unless the list of keys was actually empty.\n    \n        Parameters\n        ----------\n        key : list-like\n            Targeted labels (only used to show correct error message).\n        indexer: array-like of booleans\n            Indices corresponding to the key,\n            (with -1 indicating not found).\n        axis: int\n            Dimension on which the indexing is being made.\n        raise_missing: bool\n            Whether to raise a KeyError if some labels are not found. Will be\n            removed in the future, and then this method will always behave as\n            if raise_missing=True.\n    \n        Raises\n        ------\n        KeyError\n            If at least one key was requested but none was found, and\n            raise_missing=True.\n        \"\"\"\n        ax = self.obj._get_axis(axis)\n    \n        if len(key) == 0:\n            return\n    \n        # Count missing values:\n        missing = (indexer < 0).sum()\n    \n        if missing:\n            if missing == len(indexer):\n                axis_name = self.obj._get_axis_name(axis)\n                raise KeyError(f\"None of [{key}] are in the [{axis_name}]\")\n    \n            # We (temporarily) allow for some missing keys with .loc, except in\n            # some cases (e.g. setting) in which \"raise_missing\" will be False\n            if raise_missing:\n                not_found = list(set(key) - set(ax))\n                raise KeyError(f\"{not_found} not in index\")\n    \n            # we skip the warning on Categorical\n            # as this check is actually done (check for\n            # non-missing values), but a bit later in the\n            # code, so we want to avoid warning & then\n            # just raising\n            if not ax.is_categorical():\n>               raise KeyError(\n                    \"Passing list-likes to .loc or [] with any missing labels \"\n                    \"is no longer supported, see \"\n                    \"https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\"  # noqa:E501\n                )\nE               KeyError: 'Passing list-likes to .loc or [] with any missing labels is no longer supported, see https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike'\n\npandas/core/indexing.py:1285: KeyError",
                "test_function_decorators": [
                    "pytest.mark.parametrize('columns,box,expected', [(['A', 'B', 'C', 'D'], 7, pd.DataFrame([[7, 7, 7, 7], [7, 7, 7, 7], [7, 7, 7, 7]], columns=['A', 'B', 'C', 'D'])), (['C', 'D'], [7, 8], pd.DataFrame([[1, 2, 7, 8], [3, 4, 7, 8], [5, 6, 7, 8]], columns=['A', 'B', 'C', 'D'])), (['A', 'B', 'C'], np.array([7, 8, 9], dtype=np.int64), pd.DataFrame([[7, 8, 9], [7, 8, 9], [7, 8, 9]], columns=['A', 'B', 'C'])), (['B', 'C', 'D'], [[7, 8, 9], [10, 11, 12], [13, 14, 15]], pd.DataFrame([[1, 7, 8, 9], [3, 10, 11, 12], [5, 13, 14, 15]], columns=['A', 'B', 'C', 'D'])), (['C', 'A', 'D'], np.array([[7, 8, 9], [10, 11, 12], [13, 14, 15]], dtype=np.int64), pd.DataFrame([[8, 2, 7, 9], [11, 4, 10, 12], [14, 6, 13, 15]], columns=['A', 'B', 'C', 'D'])), (['A', 'C'], pd.DataFrame([[7, 8], [9, 10], [11, 12]], columns=['A', 'C']), pd.DataFrame([[7, 2, 8], [9, 4, 10], [11, 6, 12]], columns=['A', 'B', 'C']))])"
                ]
            },
            {
                "test_path": "/Volumes/JerrySSD/bgp_envs/repos/pandas_47/pandas/tests/frame/indexing/test_indexing.py",
                "test_function": "test_setitem_list_missing_columns",
                "test_function_code": "    @pytest.mark.parametrize(\n        \"columns,box,expected\",\n        [\n            (\n                [\"A\", \"B\", \"C\", \"D\"],\n                7,\n                pd.DataFrame(\n                    [[7, 7, 7, 7], [7, 7, 7, 7], [7, 7, 7, 7]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                [\"C\", \"D\"],\n                [7, 8],\n                pd.DataFrame(\n                    [[1, 2, 7, 8], [3, 4, 7, 8], [5, 6, 7, 8]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                [\"A\", \"B\", \"C\"],\n                np.array([7, 8, 9], dtype=np.int64),\n                pd.DataFrame(\n                    [[7, 8, 9], [7, 8, 9], [7, 8, 9]], columns=[\"A\", \"B\", \"C\"]\n                ),\n            ),\n            (\n                [\"B\", \"C\", \"D\"],\n                [[7, 8, 9], [10, 11, 12], [13, 14, 15]],\n                pd.DataFrame(\n                    [[1, 7, 8, 9], [3, 10, 11, 12], [5, 13, 14, 15]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                [\"C\", \"A\", \"D\"],\n                np.array([[7, 8, 9], [10, 11, 12], [13, 14, 15]], dtype=np.int64),\n                pd.DataFrame(\n                    [[8, 2, 7, 9], [11, 4, 10, 12], [14, 6, 13, 15]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                [\"A\", \"C\"],\n                pd.DataFrame([[7, 8], [9, 10], [11, 12]], columns=[\"A\", \"C\"]),\n                pd.DataFrame(\n                    [[7, 2, 8], [9, 4, 10], [11, 6, 12]], columns=[\"A\", \"B\", \"C\"]\n                ),\n            ),\n        ],\n    )\n    def test_setitem_list_missing_columns(self, columns, box, expected):\n        # GH 29334\n        df = pd.DataFrame([[1, 2], [3, 4], [5, 6]], columns=[\"A\", \"B\"])\n        df[columns] = box\n        tm.assert_frame_equal(df, expected)",
                "test_error": "KeyError: 'Passing list-likes to .loc or [] with any missing labels is no longer supported, see https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike'",
                "full_test_error": "self = <test_indexing.TestDataFrameIndexing object at 0x1210e5910>\ncolumns = ['B', 'C', 'D'], box = [[7, 8, 9], [10, 11, 12], [13, 14, 15]]\nexpected =    A   B   C   D\n0  1   7   8   9\n1  3  10  11  12\n2  5  13  14  15\n\n    @pytest.mark.parametrize(\n        \"columns,box,expected\",\n        [\n            (\n                [\"A\", \"B\", \"C\", \"D\"],\n                7,\n                pd.DataFrame(\n                    [[7, 7, 7, 7], [7, 7, 7, 7], [7, 7, 7, 7]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                [\"C\", \"D\"],\n                [7, 8],\n                pd.DataFrame(\n                    [[1, 2, 7, 8], [3, 4, 7, 8], [5, 6, 7, 8]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                [\"A\", \"B\", \"C\"],\n                np.array([7, 8, 9], dtype=np.int64),\n                pd.DataFrame(\n                    [[7, 8, 9], [7, 8, 9], [7, 8, 9]], columns=[\"A\", \"B\", \"C\"]\n                ),\n            ),\n            (\n                [\"B\", \"C\", \"D\"],\n                [[7, 8, 9], [10, 11, 12], [13, 14, 15]],\n                pd.DataFrame(\n                    [[1, 7, 8, 9], [3, 10, 11, 12], [5, 13, 14, 15]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                [\"C\", \"A\", \"D\"],\n                np.array([[7, 8, 9], [10, 11, 12], [13, 14, 15]], dtype=np.int64),\n                pd.DataFrame(\n                    [[8, 2, 7, 9], [11, 4, 10, 12], [14, 6, 13, 15]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                [\"A\", \"C\"],\n                pd.DataFrame([[7, 8], [9, 10], [11, 12]], columns=[\"A\", \"C\"]),\n                pd.DataFrame(\n                    [[7, 2, 8], [9, 4, 10], [11, 6, 12]], columns=[\"A\", \"B\", \"C\"]\n                ),\n            ),\n        ],\n    )\n    def test_setitem_list_missing_columns(self, columns, box, expected):\n        # GH 29334\n        df = pd.DataFrame([[1, 2], [3, 4], [5, 6]], columns=[\"A\", \"B\"])\n>       df[columns] = box\n\npandas/tests/frame/indexing/test_indexing.py:272: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \npandas/core/frame.py:2660: in __setitem__\n    self._setitem_array(key, value)\npandas/core/frame.py:2690: in _setitem_array\n    indexer = self.loc._get_listlike_indexer(\npandas/core/indexing.py:1228: in _get_listlike_indexer\n    self._validate_read_indexer(keyarr, indexer, axis, raise_missing=raise_missing)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <pandas.core.indexing._LocIndexer object at 0x120d8edb0>\nkey = Index(['B', 'C', 'D'], dtype='object'), indexer = array([ 1, -1, -1])\naxis = 1, raise_missing = False\n\n    def _validate_read_indexer(\n        self, key, indexer, axis: int, raise_missing: bool = False\n    ):\n        \"\"\"\n        Check that indexer can be used to return a result.\n    \n        e.g. at least one element was found,\n        unless the list of keys was actually empty.\n    \n        Parameters\n        ----------\n        key : list-like\n            Targeted labels (only used to show correct error message).\n        indexer: array-like of booleans\n            Indices corresponding to the key,\n            (with -1 indicating not found).\n        axis: int\n            Dimension on which the indexing is being made.\n        raise_missing: bool\n            Whether to raise a KeyError if some labels are not found. Will be\n            removed in the future, and then this method will always behave as\n            if raise_missing=True.\n    \n        Raises\n        ------\n        KeyError\n            If at least one key was requested but none was found, and\n            raise_missing=True.\n        \"\"\"\n        ax = self.obj._get_axis(axis)\n    \n        if len(key) == 0:\n            return\n    \n        # Count missing values:\n        missing = (indexer < 0).sum()\n    \n        if missing:\n            if missing == len(indexer):\n                axis_name = self.obj._get_axis_name(axis)\n                raise KeyError(f\"None of [{key}] are in the [{axis_name}]\")\n    \n            # We (temporarily) allow for some missing keys with .loc, except in\n            # some cases (e.g. setting) in which \"raise_missing\" will be False\n            if raise_missing:\n                not_found = list(set(key) - set(ax))\n                raise KeyError(f\"{not_found} not in index\")\n    \n            # we skip the warning on Categorical\n            # as this check is actually done (check for\n            # non-missing values), but a bit later in the\n            # code, so we want to avoid warning & then\n            # just raising\n            if not ax.is_categorical():\n>               raise KeyError(\n                    \"Passing list-likes to .loc or [] with any missing labels \"\n                    \"is no longer supported, see \"\n                    \"https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\"  # noqa:E501\n                )\nE               KeyError: 'Passing list-likes to .loc or [] with any missing labels is no longer supported, see https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike'\n\npandas/core/indexing.py:1285: KeyError",
                "traceback": "pandas/core/frame.py:2660: in __setitem__\n    self._setitem_array(key, value)\npandas/core/frame.py:2690: in _setitem_array\n    indexer = self.loc._get_listlike_indexer(\npandas/core/indexing.py:1228: in _get_listlike_indexer\n    self._validate_read_indexer(keyarr, indexer, axis, raise_missing=raise_missing)",
                "test_error_location": "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <pandas.core.indexing._LocIndexer object at 0x120d8edb0>\nkey = Index(['B', 'C', 'D'], dtype='object'), indexer = array([ 1, -1, -1])\naxis = 1, raise_missing = False\n\n    def _validate_read_indexer(\n        self, key, indexer, axis: int, raise_missing: bool = False\n    ):\n        \"\"\"\n        Check that indexer can be used to return a result.\n    \n        e.g. at least one element was found,\n        unless the list of keys was actually empty.\n    \n        Parameters\n        ----------\n        key : list-like\n            Targeted labels (only used to show correct error message).\n        indexer: array-like of booleans\n            Indices corresponding to the key,\n            (with -1 indicating not found).\n        axis: int\n            Dimension on which the indexing is being made.\n        raise_missing: bool\n            Whether to raise a KeyError if some labels are not found. Will be\n            removed in the future, and then this method will always behave as\n            if raise_missing=True.\n    \n        Raises\n        ------\n        KeyError\n            If at least one key was requested but none was found, and\n            raise_missing=True.\n        \"\"\"\n        ax = self.obj._get_axis(axis)\n    \n        if len(key) == 0:\n            return\n    \n        # Count missing values:\n        missing = (indexer < 0).sum()\n    \n        if missing:\n            if missing == len(indexer):\n                axis_name = self.obj._get_axis_name(axis)\n                raise KeyError(f\"None of [{key}] are in the [{axis_name}]\")\n    \n            # We (temporarily) allow for some missing keys with .loc, except in\n            # some cases (e.g. setting) in which \"raise_missing\" will be False\n            if raise_missing:\n                not_found = list(set(key) - set(ax))\n                raise KeyError(f\"{not_found} not in index\")\n    \n            # we skip the warning on Categorical\n            # as this check is actually done (check for\n            # non-missing values), but a bit later in the\n            # code, so we want to avoid warning & then\n            # just raising\n            if not ax.is_categorical():\n>               raise KeyError(\n                    \"Passing list-likes to .loc or [] with any missing labels \"\n                    \"is no longer supported, see \"\n                    \"https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\"  # noqa:E501\n                )\nE               KeyError: 'Passing list-likes to .loc or [] with any missing labels is no longer supported, see https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike'\n\npandas/core/indexing.py:1285: KeyError",
                "test_function_decorators": [
                    "pytest.mark.parametrize('columns,box,expected', [(['A', 'B', 'C', 'D'], 7, pd.DataFrame([[7, 7, 7, 7], [7, 7, 7, 7], [7, 7, 7, 7]], columns=['A', 'B', 'C', 'D'])), (['C', 'D'], [7, 8], pd.DataFrame([[1, 2, 7, 8], [3, 4, 7, 8], [5, 6, 7, 8]], columns=['A', 'B', 'C', 'D'])), (['A', 'B', 'C'], np.array([7, 8, 9], dtype=np.int64), pd.DataFrame([[7, 8, 9], [7, 8, 9], [7, 8, 9]], columns=['A', 'B', 'C'])), (['B', 'C', 'D'], [[7, 8, 9], [10, 11, 12], [13, 14, 15]], pd.DataFrame([[1, 7, 8, 9], [3, 10, 11, 12], [5, 13, 14, 15]], columns=['A', 'B', 'C', 'D'])), (['C', 'A', 'D'], np.array([[7, 8, 9], [10, 11, 12], [13, 14, 15]], dtype=np.int64), pd.DataFrame([[8, 2, 7, 9], [11, 4, 10, 12], [14, 6, 13, 15]], columns=['A', 'B', 'C', 'D'])), (['A', 'C'], pd.DataFrame([[7, 8], [9, 10], [11, 12]], columns=['A', 'C']), pd.DataFrame([[7, 2, 8], [9, 4, 10], [11, 6, 12]], columns=['A', 'B', 'C']))])"
                ]
            },
            {
                "test_path": "/Volumes/JerrySSD/bgp_envs/repos/pandas_47/pandas/tests/frame/indexing/test_indexing.py",
                "test_function": "test_setitem_list_missing_columns",
                "test_function_code": "    @pytest.mark.parametrize(\n        \"columns,box,expected\",\n        [\n            (\n                [\"A\", \"B\", \"C\", \"D\"],\n                7,\n                pd.DataFrame(\n                    [[7, 7, 7, 7], [7, 7, 7, 7], [7, 7, 7, 7]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                [\"C\", \"D\"],\n                [7, 8],\n                pd.DataFrame(\n                    [[1, 2, 7, 8], [3, 4, 7, 8], [5, 6, 7, 8]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                [\"A\", \"B\", \"C\"],\n                np.array([7, 8, 9], dtype=np.int64),\n                pd.DataFrame(\n                    [[7, 8, 9], [7, 8, 9], [7, 8, 9]], columns=[\"A\", \"B\", \"C\"]\n                ),\n            ),\n            (\n                [\"B\", \"C\", \"D\"],\n                [[7, 8, 9], [10, 11, 12], [13, 14, 15]],\n                pd.DataFrame(\n                    [[1, 7, 8, 9], [3, 10, 11, 12], [5, 13, 14, 15]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                [\"C\", \"A\", \"D\"],\n                np.array([[7, 8, 9], [10, 11, 12], [13, 14, 15]], dtype=np.int64),\n                pd.DataFrame(\n                    [[8, 2, 7, 9], [11, 4, 10, 12], [14, 6, 13, 15]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                [\"A\", \"C\"],\n                pd.DataFrame([[7, 8], [9, 10], [11, 12]], columns=[\"A\", \"C\"]),\n                pd.DataFrame(\n                    [[7, 2, 8], [9, 4, 10], [11, 6, 12]], columns=[\"A\", \"B\", \"C\"]\n                ),\n            ),\n        ],\n    )\n    def test_setitem_list_missing_columns(self, columns, box, expected):\n        # GH 29334\n        df = pd.DataFrame([[1, 2], [3, 4], [5, 6]], columns=[\"A\", \"B\"])\n        df[columns] = box\n        tm.assert_frame_equal(df, expected)",
                "test_error": "KeyError: 'Passing list-likes to .loc or [] with any missing labels is no longer supported, see https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike'",
                "full_test_error": "self = <test_indexing.TestDataFrameIndexing object at 0x1210668b0>\ncolumns = ['C', 'A', 'D']\nbox = array([[ 7,  8,  9],\n       [10, 11, 12],\n       [13, 14, 15]])\nexpected =     A  B   C   D\n0   8  2   7   9\n1  11  4  10  12\n2  14  6  13  15\n\n    @pytest.mark.parametrize(\n        \"columns,box,expected\",\n        [\n            (\n                [\"A\", \"B\", \"C\", \"D\"],\n                7,\n                pd.DataFrame(\n                    [[7, 7, 7, 7], [7, 7, 7, 7], [7, 7, 7, 7]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                [\"C\", \"D\"],\n                [7, 8],\n                pd.DataFrame(\n                    [[1, 2, 7, 8], [3, 4, 7, 8], [5, 6, 7, 8]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                [\"A\", \"B\", \"C\"],\n                np.array([7, 8, 9], dtype=np.int64),\n                pd.DataFrame(\n                    [[7, 8, 9], [7, 8, 9], [7, 8, 9]], columns=[\"A\", \"B\", \"C\"]\n                ),\n            ),\n            (\n                [\"B\", \"C\", \"D\"],\n                [[7, 8, 9], [10, 11, 12], [13, 14, 15]],\n                pd.DataFrame(\n                    [[1, 7, 8, 9], [3, 10, 11, 12], [5, 13, 14, 15]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                [\"C\", \"A\", \"D\"],\n                np.array([[7, 8, 9], [10, 11, 12], [13, 14, 15]], dtype=np.int64),\n                pd.DataFrame(\n                    [[8, 2, 7, 9], [11, 4, 10, 12], [14, 6, 13, 15]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                [\"A\", \"C\"],\n                pd.DataFrame([[7, 8], [9, 10], [11, 12]], columns=[\"A\", \"C\"]),\n                pd.DataFrame(\n                    [[7, 2, 8], [9, 4, 10], [11, 6, 12]], columns=[\"A\", \"B\", \"C\"]\n                ),\n            ),\n        ],\n    )\n    def test_setitem_list_missing_columns(self, columns, box, expected):\n        # GH 29334\n        df = pd.DataFrame([[1, 2], [3, 4], [5, 6]], columns=[\"A\", \"B\"])\n>       df[columns] = box\n\npandas/tests/frame/indexing/test_indexing.py:272: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \npandas/core/frame.py:2660: in __setitem__\n    self._setitem_array(key, value)\npandas/core/frame.py:2690: in _setitem_array\n    indexer = self.loc._get_listlike_indexer(\npandas/core/indexing.py:1228: in _get_listlike_indexer\n    self._validate_read_indexer(keyarr, indexer, axis, raise_missing=raise_missing)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <pandas.core.indexing._LocIndexer object at 0x118b45f90>\nkey = Index(['C', 'A', 'D'], dtype='object'), indexer = array([-1,  0, -1])\naxis = 1, raise_missing = False\n\n    def _validate_read_indexer(\n        self, key, indexer, axis: int, raise_missing: bool = False\n    ):\n        \"\"\"\n        Check that indexer can be used to return a result.\n    \n        e.g. at least one element was found,\n        unless the list of keys was actually empty.\n    \n        Parameters\n        ----------\n        key : list-like\n            Targeted labels (only used to show correct error message).\n        indexer: array-like of booleans\n            Indices corresponding to the key,\n            (with -1 indicating not found).\n        axis: int\n            Dimension on which the indexing is being made.\n        raise_missing: bool\n            Whether to raise a KeyError if some labels are not found. Will be\n            removed in the future, and then this method will always behave as\n            if raise_missing=True.\n    \n        Raises\n        ------\n        KeyError\n            If at least one key was requested but none was found, and\n            raise_missing=True.\n        \"\"\"\n        ax = self.obj._get_axis(axis)\n    \n        if len(key) == 0:\n            return\n    \n        # Count missing values:\n        missing = (indexer < 0).sum()\n    \n        if missing:\n            if missing == len(indexer):\n                axis_name = self.obj._get_axis_name(axis)\n                raise KeyError(f\"None of [{key}] are in the [{axis_name}]\")\n    \n            # We (temporarily) allow for some missing keys with .loc, except in\n            # some cases (e.g. setting) in which \"raise_missing\" will be False\n            if raise_missing:\n                not_found = list(set(key) - set(ax))\n                raise KeyError(f\"{not_found} not in index\")\n    \n            # we skip the warning on Categorical\n            # as this check is actually done (check for\n            # non-missing values), but a bit later in the\n            # code, so we want to avoid warning & then\n            # just raising\n            if not ax.is_categorical():\n>               raise KeyError(\n                    \"Passing list-likes to .loc or [] with any missing labels \"\n                    \"is no longer supported, see \"\n                    \"https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\"  # noqa:E501\n                )\nE               KeyError: 'Passing list-likes to .loc or [] with any missing labels is no longer supported, see https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike'\n\npandas/core/indexing.py:1285: KeyError",
                "traceback": "pandas/core/frame.py:2660: in __setitem__\n    self._setitem_array(key, value)\npandas/core/frame.py:2690: in _setitem_array\n    indexer = self.loc._get_listlike_indexer(\npandas/core/indexing.py:1228: in _get_listlike_indexer\n    self._validate_read_indexer(keyarr, indexer, axis, raise_missing=raise_missing)",
                "test_error_location": "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <pandas.core.indexing._LocIndexer object at 0x118b45f90>\nkey = Index(['C', 'A', 'D'], dtype='object'), indexer = array([-1,  0, -1])\naxis = 1, raise_missing = False\n\n    def _validate_read_indexer(\n        self, key, indexer, axis: int, raise_missing: bool = False\n    ):\n        \"\"\"\n        Check that indexer can be used to return a result.\n    \n        e.g. at least one element was found,\n        unless the list of keys was actually empty.\n    \n        Parameters\n        ----------\n        key : list-like\n            Targeted labels (only used to show correct error message).\n        indexer: array-like of booleans\n            Indices corresponding to the key,\n            (with -1 indicating not found).\n        axis: int\n            Dimension on which the indexing is being made.\n        raise_missing: bool\n            Whether to raise a KeyError if some labels are not found. Will be\n            removed in the future, and then this method will always behave as\n            if raise_missing=True.\n    \n        Raises\n        ------\n        KeyError\n            If at least one key was requested but none was found, and\n            raise_missing=True.\n        \"\"\"\n        ax = self.obj._get_axis(axis)\n    \n        if len(key) == 0:\n            return\n    \n        # Count missing values:\n        missing = (indexer < 0).sum()\n    \n        if missing:\n            if missing == len(indexer):\n                axis_name = self.obj._get_axis_name(axis)\n                raise KeyError(f\"None of [{key}] are in the [{axis_name}]\")\n    \n            # We (temporarily) allow for some missing keys with .loc, except in\n            # some cases (e.g. setting) in which \"raise_missing\" will be False\n            if raise_missing:\n                not_found = list(set(key) - set(ax))\n                raise KeyError(f\"{not_found} not in index\")\n    \n            # we skip the warning on Categorical\n            # as this check is actually done (check for\n            # non-missing values), but a bit later in the\n            # code, so we want to avoid warning & then\n            # just raising\n            if not ax.is_categorical():\n>               raise KeyError(\n                    \"Passing list-likes to .loc or [] with any missing labels \"\n                    \"is no longer supported, see \"\n                    \"https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\"  # noqa:E501\n                )\nE               KeyError: 'Passing list-likes to .loc or [] with any missing labels is no longer supported, see https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike'\n\npandas/core/indexing.py:1285: KeyError",
                "test_function_decorators": [
                    "pytest.mark.parametrize('columns,box,expected', [(['A', 'B', 'C', 'D'], 7, pd.DataFrame([[7, 7, 7, 7], [7, 7, 7, 7], [7, 7, 7, 7]], columns=['A', 'B', 'C', 'D'])), (['C', 'D'], [7, 8], pd.DataFrame([[1, 2, 7, 8], [3, 4, 7, 8], [5, 6, 7, 8]], columns=['A', 'B', 'C', 'D'])), (['A', 'B', 'C'], np.array([7, 8, 9], dtype=np.int64), pd.DataFrame([[7, 8, 9], [7, 8, 9], [7, 8, 9]], columns=['A', 'B', 'C'])), (['B', 'C', 'D'], [[7, 8, 9], [10, 11, 12], [13, 14, 15]], pd.DataFrame([[1, 7, 8, 9], [3, 10, 11, 12], [5, 13, 14, 15]], columns=['A', 'B', 'C', 'D'])), (['C', 'A', 'D'], np.array([[7, 8, 9], [10, 11, 12], [13, 14, 15]], dtype=np.int64), pd.DataFrame([[8, 2, 7, 9], [11, 4, 10, 12], [14, 6, 13, 15]], columns=['A', 'B', 'C', 'D'])), (['A', 'C'], pd.DataFrame([[7, 8], [9, 10], [11, 12]], columns=['A', 'C']), pd.DataFrame([[7, 2, 8], [9, 4, 10], [11, 6, 12]], columns=['A', 'B', 'C']))])"
                ]
            },
            {
                "test_path": "/Volumes/JerrySSD/bgp_envs/repos/pandas_47/pandas/tests/indexing/test_loc.py",
                "test_function": "test_loc_setitem_missing_columns",
                "test_function_code": "    @pytest.mark.parametrize(\n        \"index,box,expected\",\n        [\n            (\n                ([0, 2], [\"A\", \"B\", \"C\", \"D\"]),\n                7,\n                pd.DataFrame(\n                    [[7, 7, 7, 7], [3, 4, np.nan, np.nan], [7, 7, 7, 7]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                (1, [\"C\", \"D\"]),\n                [7, 8],\n                pd.DataFrame(\n                    [[1, 2, np.nan, np.nan], [3, 4, 7, 8], [5, 6, np.nan, np.nan]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                (1, [\"A\", \"B\", \"C\"]),\n                np.array([7, 8, 9], dtype=np.int64),\n                pd.DataFrame(\n                    [[1, 2, np.nan], [7, 8, 9], [5, 6, np.nan]],\n                    columns=[\"A\", \"B\", \"C\"],\n                ),\n            ),\n            (\n                (slice(1, 3, None), [\"B\", \"C\", \"D\"]),\n                [[7, 8, 9], [10, 11, 12]],\n                pd.DataFrame(\n                    [[1, 2, np.nan, np.nan], [3, 7, 8, 9], [5, 10, 11, 12]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                (slice(1, 3, None), [\"C\", \"A\", \"D\"]),\n                np.array([[7, 8, 9], [10, 11, 12]], dtype=np.int64),\n                pd.DataFrame(\n                    [[1, 2, np.nan, np.nan], [8, 4, 7, 9], [11, 6, 10, 12]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                (slice(None, None, None), [\"A\", \"C\"]),\n                pd.DataFrame([[7, 8], [9, 10], [11, 12]], columns=[\"A\", \"C\"]),\n                pd.DataFrame(\n                    [[7, 2, 8], [9, 4, 10], [11, 6, 12]], columns=[\"A\", \"B\", \"C\"]\n                ),\n            ),\n        ],\n    )\n    def test_loc_setitem_missing_columns(self, index, box, expected):\n        # GH 29334\n        df = pd.DataFrame([[1, 2], [3, 4], [5, 6]], columns=[\"A\", \"B\"])\n        df.loc[index] = box\n        tm.assert_frame_equal(df, expected)",
                "test_error": "KeyError: \"['C', 'D'] not in index\"",
                "full_test_error": "self = <pandas.tests.indexing.test_loc.TestLoc2 object at 0x120f83a30>\nindex = ([0, 2], ['A', 'B', 'C', 'D']), box = 7\nexpected =    A  B    C    D\n0  7  7  7.0  7.0\n1  3  4  NaN  NaN\n2  7  7  7.0  7.0\n\n    @pytest.mark.parametrize(\n        \"index,box,expected\",\n        [\n            (\n                ([0, 2], [\"A\", \"B\", \"C\", \"D\"]),\n                7,\n                pd.DataFrame(\n                    [[7, 7, 7, 7], [3, 4, np.nan, np.nan], [7, 7, 7, 7]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                (1, [\"C\", \"D\"]),\n                [7, 8],\n                pd.DataFrame(\n                    [[1, 2, np.nan, np.nan], [3, 4, 7, 8], [5, 6, np.nan, np.nan]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                (1, [\"A\", \"B\", \"C\"]),\n                np.array([7, 8, 9], dtype=np.int64),\n                pd.DataFrame(\n                    [[1, 2, np.nan], [7, 8, 9], [5, 6, np.nan]],\n                    columns=[\"A\", \"B\", \"C\"],\n                ),\n            ),\n            (\n                (slice(1, 3, None), [\"B\", \"C\", \"D\"]),\n                [[7, 8, 9], [10, 11, 12]],\n                pd.DataFrame(\n                    [[1, 2, np.nan, np.nan], [3, 7, 8, 9], [5, 10, 11, 12]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                (slice(1, 3, None), [\"C\", \"A\", \"D\"]),\n                np.array([[7, 8, 9], [10, 11, 12]], dtype=np.int64),\n                pd.DataFrame(\n                    [[1, 2, np.nan, np.nan], [8, 4, 7, 9], [11, 6, 10, 12]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                (slice(None, None, None), [\"A\", \"C\"]),\n                pd.DataFrame([[7, 8], [9, 10], [11, 12]], columns=[\"A\", \"C\"]),\n                pd.DataFrame(\n                    [[7, 2, 8], [9, 4, 10], [11, 6, 12]], columns=[\"A\", \"B\", \"C\"]\n                ),\n            ),\n        ],\n    )\n    def test_loc_setitem_missing_columns(self, index, box, expected):\n        # GH 29334\n        df = pd.DataFrame([[1, 2], [3, 4], [5, 6]], columns=[\"A\", \"B\"])\n>       df.loc[index] = box\n\npandas/tests/indexing/test_loc.py:689: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \npandas/core/indexing.py:619: in __setitem__\n    indexer = self._get_setitem_indexer(key)\npandas/core/indexing.py:598: in _get_setitem_indexer\n    return self._convert_tuple(key, is_setter=True)\npandas/core/indexing.py:687: in _convert_tuple\n    idx = self._convert_to_indexer(k, axis=i, is_setter=is_setter)\npandas/core/indexing.py:1174: in _convert_to_indexer\n    return self._get_listlike_indexer(key, axis, raise_missing=True)[1]\npandas/core/indexing.py:1228: in _get_listlike_indexer\n    self._validate_read_indexer(keyarr, indexer, axis, raise_missing=raise_missing)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <pandas.core.indexing._LocIndexer object at 0x120d82d10>\nkey = Index(['A', 'B', 'C', 'D'], dtype='object')\nindexer = array([ 0,  1, -1, -1]), axis = 1, raise_missing = True\n\n    def _validate_read_indexer(\n        self, key, indexer, axis: int, raise_missing: bool = False\n    ):\n        \"\"\"\n        Check that indexer can be used to return a result.\n    \n        e.g. at least one element was found,\n        unless the list of keys was actually empty.\n    \n        Parameters\n        ----------\n        key : list-like\n            Targeted labels (only used to show correct error message).\n        indexer: array-like of booleans\n            Indices corresponding to the key,\n            (with -1 indicating not found).\n        axis: int\n            Dimension on which the indexing is being made.\n        raise_missing: bool\n            Whether to raise a KeyError if some labels are not found. Will be\n            removed in the future, and then this method will always behave as\n            if raise_missing=True.\n    \n        Raises\n        ------\n        KeyError\n            If at least one key was requested but none was found, and\n            raise_missing=True.\n        \"\"\"\n        ax = self.obj._get_axis(axis)\n    \n        if len(key) == 0:\n            return\n    \n        # Count missing values:\n        missing = (indexer < 0).sum()\n    \n        if missing:\n            if missing == len(indexer):\n                axis_name = self.obj._get_axis_name(axis)\n                raise KeyError(f\"None of [{key}] are in the [{axis_name}]\")\n    \n            # We (temporarily) allow for some missing keys with .loc, except in\n            # some cases (e.g. setting) in which \"raise_missing\" will be False\n            if raise_missing:\n                not_found = list(set(key) - set(ax))\n>               raise KeyError(f\"{not_found} not in index\")\nE               KeyError: \"['C', 'D'] not in index\"\n\npandas/core/indexing.py:1277: KeyError",
                "traceback": "pandas/core/indexing.py:619: in __setitem__\n    indexer = self._get_setitem_indexer(key)\npandas/core/indexing.py:598: in _get_setitem_indexer\n    return self._convert_tuple(key, is_setter=True)\npandas/core/indexing.py:687: in _convert_tuple\n    idx = self._convert_to_indexer(k, axis=i, is_setter=is_setter)\npandas/core/indexing.py:1174: in _convert_to_indexer\n    return self._get_listlike_indexer(key, axis, raise_missing=True)[1]\npandas/core/indexing.py:1228: in _get_listlike_indexer\n    self._validate_read_indexer(keyarr, indexer, axis, raise_missing=raise_missing)",
                "test_error_location": "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <pandas.core.indexing._LocIndexer object at 0x120d82d10>\nkey = Index(['A', 'B', 'C', 'D'], dtype='object')\nindexer = array([ 0,  1, -1, -1]), axis = 1, raise_missing = True\n\n    def _validate_read_indexer(\n        self, key, indexer, axis: int, raise_missing: bool = False\n    ):\n        \"\"\"\n        Check that indexer can be used to return a result.\n    \n        e.g. at least one element was found,\n        unless the list of keys was actually empty.\n    \n        Parameters\n        ----------\n        key : list-like\n            Targeted labels (only used to show correct error message).\n        indexer: array-like of booleans\n            Indices corresponding to the key,\n            (with -1 indicating not found).\n        axis: int\n            Dimension on which the indexing is being made.\n        raise_missing: bool\n            Whether to raise a KeyError if some labels are not found. Will be\n            removed in the future, and then this method will always behave as\n            if raise_missing=True.\n    \n        Raises\n        ------\n        KeyError\n            If at least one key was requested but none was found, and\n            raise_missing=True.\n        \"\"\"\n        ax = self.obj._get_axis(axis)\n    \n        if len(key) == 0:\n            return\n    \n        # Count missing values:\n        missing = (indexer < 0).sum()\n    \n        if missing:\n            if missing == len(indexer):\n                axis_name = self.obj._get_axis_name(axis)\n                raise KeyError(f\"None of [{key}] are in the [{axis_name}]\")\n    \n            # We (temporarily) allow for some missing keys with .loc, except in\n            # some cases (e.g. setting) in which \"raise_missing\" will be False\n            if raise_missing:\n                not_found = list(set(key) - set(ax))\n>               raise KeyError(f\"{not_found} not in index\")\nE               KeyError: \"['C', 'D'] not in index\"\n\npandas/core/indexing.py:1277: KeyError",
                "test_function_decorators": [
                    "pytest.mark.parametrize('index,box,expected', [(([0, 2], ['A', 'B', 'C', 'D']), 7, pd.DataFrame([[7, 7, 7, 7], [3, 4, np.nan, np.nan], [7, 7, 7, 7]], columns=['A', 'B', 'C', 'D'])), ((1, ['C', 'D']), [7, 8], pd.DataFrame([[1, 2, np.nan, np.nan], [3, 4, 7, 8], [5, 6, np.nan, np.nan]], columns=['A', 'B', 'C', 'D'])), ((1, ['A', 'B', 'C']), np.array([7, 8, 9], dtype=np.int64), pd.DataFrame([[1, 2, np.nan], [7, 8, 9], [5, 6, np.nan]], columns=['A', 'B', 'C'])), ((slice(1, 3, None), ['B', 'C', 'D']), [[7, 8, 9], [10, 11, 12]], pd.DataFrame([[1, 2, np.nan, np.nan], [3, 7, 8, 9], [5, 10, 11, 12]], columns=['A', 'B', 'C', 'D'])), ((slice(1, 3, None), ['C', 'A', 'D']), np.array([[7, 8, 9], [10, 11, 12]], dtype=np.int64), pd.DataFrame([[1, 2, np.nan, np.nan], [8, 4, 7, 9], [11, 6, 10, 12]], columns=['A', 'B', 'C', 'D'])), ((slice(None, None, None), ['A', 'C']), pd.DataFrame([[7, 8], [9, 10], [11, 12]], columns=['A', 'C']), pd.DataFrame([[7, 2, 8], [9, 4, 10], [11, 6, 12]], columns=['A', 'B', 'C']))])"
                ]
            },
            {
                "test_path": "/Volumes/JerrySSD/bgp_envs/repos/pandas_47/pandas/tests/indexing/test_loc.py",
                "test_function": "test_loc_setitem_missing_columns",
                "test_function_code": "    @pytest.mark.parametrize(\n        \"index,box,expected\",\n        [\n            (\n                ([0, 2], [\"A\", \"B\", \"C\", \"D\"]),\n                7,\n                pd.DataFrame(\n                    [[7, 7, 7, 7], [3, 4, np.nan, np.nan], [7, 7, 7, 7]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                (1, [\"C\", \"D\"]),\n                [7, 8],\n                pd.DataFrame(\n                    [[1, 2, np.nan, np.nan], [3, 4, 7, 8], [5, 6, np.nan, np.nan]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                (1, [\"A\", \"B\", \"C\"]),\n                np.array([7, 8, 9], dtype=np.int64),\n                pd.DataFrame(\n                    [[1, 2, np.nan], [7, 8, 9], [5, 6, np.nan]],\n                    columns=[\"A\", \"B\", \"C\"],\n                ),\n            ),\n            (\n                (slice(1, 3, None), [\"B\", \"C\", \"D\"]),\n                [[7, 8, 9], [10, 11, 12]],\n                pd.DataFrame(\n                    [[1, 2, np.nan, np.nan], [3, 7, 8, 9], [5, 10, 11, 12]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                (slice(1, 3, None), [\"C\", \"A\", \"D\"]),\n                np.array([[7, 8, 9], [10, 11, 12]], dtype=np.int64),\n                pd.DataFrame(\n                    [[1, 2, np.nan, np.nan], [8, 4, 7, 9], [11, 6, 10, 12]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                (slice(None, None, None), [\"A\", \"C\"]),\n                pd.DataFrame([[7, 8], [9, 10], [11, 12]], columns=[\"A\", \"C\"]),\n                pd.DataFrame(\n                    [[7, 2, 8], [9, 4, 10], [11, 6, 12]], columns=[\"A\", \"B\", \"C\"]\n                ),\n            ),\n        ],\n    )\n    def test_loc_setitem_missing_columns(self, index, box, expected):\n        # GH 29334\n        df = pd.DataFrame([[1, 2], [3, 4], [5, 6]], columns=[\"A\", \"B\"])\n        df.loc[index] = box\n        tm.assert_frame_equal(df, expected)",
                "test_error": "KeyError: \"None of [Index(['C', 'D'], dtype='object')] are in the [columns]\"",
                "full_test_error": "self = <pandas.tests.indexing.test_loc.TestLoc2 object at 0x118b49a00>\nindex = (1, ['C', 'D']), box = [7, 8]\nexpected =    A  B    C    D\n0  1  2  NaN  NaN\n1  3  4  7.0  8.0\n2  5  6  NaN  NaN\n\n    @pytest.mark.parametrize(\n        \"index,box,expected\",\n        [\n            (\n                ([0, 2], [\"A\", \"B\", \"C\", \"D\"]),\n                7,\n                pd.DataFrame(\n                    [[7, 7, 7, 7], [3, 4, np.nan, np.nan], [7, 7, 7, 7]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                (1, [\"C\", \"D\"]),\n                [7, 8],\n                pd.DataFrame(\n                    [[1, 2, np.nan, np.nan], [3, 4, 7, 8], [5, 6, np.nan, np.nan]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                (1, [\"A\", \"B\", \"C\"]),\n                np.array([7, 8, 9], dtype=np.int64),\n                pd.DataFrame(\n                    [[1, 2, np.nan], [7, 8, 9], [5, 6, np.nan]],\n                    columns=[\"A\", \"B\", \"C\"],\n                ),\n            ),\n            (\n                (slice(1, 3, None), [\"B\", \"C\", \"D\"]),\n                [[7, 8, 9], [10, 11, 12]],\n                pd.DataFrame(\n                    [[1, 2, np.nan, np.nan], [3, 7, 8, 9], [5, 10, 11, 12]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                (slice(1, 3, None), [\"C\", \"A\", \"D\"]),\n                np.array([[7, 8, 9], [10, 11, 12]], dtype=np.int64),\n                pd.DataFrame(\n                    [[1, 2, np.nan, np.nan], [8, 4, 7, 9], [11, 6, 10, 12]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                (slice(None, None, None), [\"A\", \"C\"]),\n                pd.DataFrame([[7, 8], [9, 10], [11, 12]], columns=[\"A\", \"C\"]),\n                pd.DataFrame(\n                    [[7, 2, 8], [9, 4, 10], [11, 6, 12]], columns=[\"A\", \"B\", \"C\"]\n                ),\n            ),\n        ],\n    )\n    def test_loc_setitem_missing_columns(self, index, box, expected):\n        # GH 29334\n        df = pd.DataFrame([[1, 2], [3, 4], [5, 6]], columns=[\"A\", \"B\"])\n>       df.loc[index] = box\n\npandas/tests/indexing/test_loc.py:689: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \npandas/core/indexing.py:619: in __setitem__\n    indexer = self._get_setitem_indexer(key)\npandas/core/indexing.py:598: in _get_setitem_indexer\n    return self._convert_tuple(key, is_setter=True)\npandas/core/indexing.py:687: in _convert_tuple\n    idx = self._convert_to_indexer(k, axis=i, is_setter=is_setter)\npandas/core/indexing.py:1174: in _convert_to_indexer\n    return self._get_listlike_indexer(key, axis, raise_missing=True)[1]\npandas/core/indexing.py:1228: in _get_listlike_indexer\n    self._validate_read_indexer(keyarr, indexer, axis, raise_missing=raise_missing)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <pandas.core.indexing._LocIndexer object at 0x120d8e0e0>\nkey = Index(['C', 'D'], dtype='object'), indexer = array([-1, -1]), axis = 1\nraise_missing = True\n\n    def _validate_read_indexer(\n        self, key, indexer, axis: int, raise_missing: bool = False\n    ):\n        \"\"\"\n        Check that indexer can be used to return a result.\n    \n        e.g. at least one element was found,\n        unless the list of keys was actually empty.\n    \n        Parameters\n        ----------\n        key : list-like\n            Targeted labels (only used to show correct error message).\n        indexer: array-like of booleans\n            Indices corresponding to the key,\n            (with -1 indicating not found).\n        axis: int\n            Dimension on which the indexing is being made.\n        raise_missing: bool\n            Whether to raise a KeyError if some labels are not found. Will be\n            removed in the future, and then this method will always behave as\n            if raise_missing=True.\n    \n        Raises\n        ------\n        KeyError\n            If at least one key was requested but none was found, and\n            raise_missing=True.\n        \"\"\"\n        ax = self.obj._get_axis(axis)\n    \n        if len(key) == 0:\n            return\n    \n        # Count missing values:\n        missing = (indexer < 0).sum()\n    \n        if missing:\n            if missing == len(indexer):\n                axis_name = self.obj._get_axis_name(axis)\n>               raise KeyError(f\"None of [{key}] are in the [{axis_name}]\")\nE               KeyError: \"None of [Index(['C', 'D'], dtype='object')] are in the [columns]\"\n\npandas/core/indexing.py:1271: KeyError",
                "traceback": "pandas/core/indexing.py:619: in __setitem__\n    indexer = self._get_setitem_indexer(key)\npandas/core/indexing.py:598: in _get_setitem_indexer\n    return self._convert_tuple(key, is_setter=True)\npandas/core/indexing.py:687: in _convert_tuple\n    idx = self._convert_to_indexer(k, axis=i, is_setter=is_setter)\npandas/core/indexing.py:1174: in _convert_to_indexer\n    return self._get_listlike_indexer(key, axis, raise_missing=True)[1]\npandas/core/indexing.py:1228: in _get_listlike_indexer\n    self._validate_read_indexer(keyarr, indexer, axis, raise_missing=raise_missing)",
                "test_error_location": "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <pandas.core.indexing._LocIndexer object at 0x120d8e0e0>\nkey = Index(['C', 'D'], dtype='object'), indexer = array([-1, -1]), axis = 1\nraise_missing = True\n\n    def _validate_read_indexer(\n        self, key, indexer, axis: int, raise_missing: bool = False\n    ):\n        \"\"\"\n        Check that indexer can be used to return a result.\n    \n        e.g. at least one element was found,\n        unless the list of keys was actually empty.\n    \n        Parameters\n        ----------\n        key : list-like\n            Targeted labels (only used to show correct error message).\n        indexer: array-like of booleans\n            Indices corresponding to the key,\n            (with -1 indicating not found).\n        axis: int\n            Dimension on which the indexing is being made.\n        raise_missing: bool\n            Whether to raise a KeyError if some labels are not found. Will be\n            removed in the future, and then this method will always behave as\n            if raise_missing=True.\n    \n        Raises\n        ------\n        KeyError\n            If at least one key was requested but none was found, and\n            raise_missing=True.\n        \"\"\"\n        ax = self.obj._get_axis(axis)\n    \n        if len(key) == 0:\n            return\n    \n        # Count missing values:\n        missing = (indexer < 0).sum()\n    \n        if missing:\n            if missing == len(indexer):\n                axis_name = self.obj._get_axis_name(axis)\n>               raise KeyError(f\"None of [{key}] are in the [{axis_name}]\")\nE               KeyError: \"None of [Index(['C', 'D'], dtype='object')] are in the [columns]\"\n\npandas/core/indexing.py:1271: KeyError",
                "test_function_decorators": [
                    "pytest.mark.parametrize('index,box,expected', [(([0, 2], ['A', 'B', 'C', 'D']), 7, pd.DataFrame([[7, 7, 7, 7], [3, 4, np.nan, np.nan], [7, 7, 7, 7]], columns=['A', 'B', 'C', 'D'])), ((1, ['C', 'D']), [7, 8], pd.DataFrame([[1, 2, np.nan, np.nan], [3, 4, 7, 8], [5, 6, np.nan, np.nan]], columns=['A', 'B', 'C', 'D'])), ((1, ['A', 'B', 'C']), np.array([7, 8, 9], dtype=np.int64), pd.DataFrame([[1, 2, np.nan], [7, 8, 9], [5, 6, np.nan]], columns=['A', 'B', 'C'])), ((slice(1, 3, None), ['B', 'C', 'D']), [[7, 8, 9], [10, 11, 12]], pd.DataFrame([[1, 2, np.nan, np.nan], [3, 7, 8, 9], [5, 10, 11, 12]], columns=['A', 'B', 'C', 'D'])), ((slice(1, 3, None), ['C', 'A', 'D']), np.array([[7, 8, 9], [10, 11, 12]], dtype=np.int64), pd.DataFrame([[1, 2, np.nan, np.nan], [8, 4, 7, 9], [11, 6, 10, 12]], columns=['A', 'B', 'C', 'D'])), ((slice(None, None, None), ['A', 'C']), pd.DataFrame([[7, 8], [9, 10], [11, 12]], columns=['A', 'C']), pd.DataFrame([[7, 2, 8], [9, 4, 10], [11, 6, 12]], columns=['A', 'B', 'C']))])"
                ]
            },
            {
                "test_path": "/Volumes/JerrySSD/bgp_envs/repos/pandas_47/pandas/tests/indexing/test_loc.py",
                "test_function": "test_loc_setitem_missing_columns",
                "test_function_code": "    @pytest.mark.parametrize(\n        \"index,box,expected\",\n        [\n            (\n                ([0, 2], [\"A\", \"B\", \"C\", \"D\"]),\n                7,\n                pd.DataFrame(\n                    [[7, 7, 7, 7], [3, 4, np.nan, np.nan], [7, 7, 7, 7]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                (1, [\"C\", \"D\"]),\n                [7, 8],\n                pd.DataFrame(\n                    [[1, 2, np.nan, np.nan], [3, 4, 7, 8], [5, 6, np.nan, np.nan]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                (1, [\"A\", \"B\", \"C\"]),\n                np.array([7, 8, 9], dtype=np.int64),\n                pd.DataFrame(\n                    [[1, 2, np.nan], [7, 8, 9], [5, 6, np.nan]],\n                    columns=[\"A\", \"B\", \"C\"],\n                ),\n            ),\n            (\n                (slice(1, 3, None), [\"B\", \"C\", \"D\"]),\n                [[7, 8, 9], [10, 11, 12]],\n                pd.DataFrame(\n                    [[1, 2, np.nan, np.nan], [3, 7, 8, 9], [5, 10, 11, 12]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                (slice(1, 3, None), [\"C\", \"A\", \"D\"]),\n                np.array([[7, 8, 9], [10, 11, 12]], dtype=np.int64),\n                pd.DataFrame(\n                    [[1, 2, np.nan, np.nan], [8, 4, 7, 9], [11, 6, 10, 12]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                (slice(None, None, None), [\"A\", \"C\"]),\n                pd.DataFrame([[7, 8], [9, 10], [11, 12]], columns=[\"A\", \"C\"]),\n                pd.DataFrame(\n                    [[7, 2, 8], [9, 4, 10], [11, 6, 12]], columns=[\"A\", \"B\", \"C\"]\n                ),\n            ),\n        ],\n    )\n    def test_loc_setitem_missing_columns(self, index, box, expected):\n        # GH 29334\n        df = pd.DataFrame([[1, 2], [3, 4], [5, 6]], columns=[\"A\", \"B\"])\n        df.loc[index] = box\n        tm.assert_frame_equal(df, expected)",
                "test_error": "KeyError: \"['C'] not in index\"",
                "full_test_error": "self = <pandas.tests.indexing.test_loc.TestLoc2 object at 0x120dfe0d0>\nindex = (1, ['A', 'B', 'C']), box = array([7, 8, 9])\nexpected =    A  B    C\n0  1  2  NaN\n1  7  8  9.0\n2  5  6  NaN\n\n    @pytest.mark.parametrize(\n        \"index,box,expected\",\n        [\n            (\n                ([0, 2], [\"A\", \"B\", \"C\", \"D\"]),\n                7,\n                pd.DataFrame(\n                    [[7, 7, 7, 7], [3, 4, np.nan, np.nan], [7, 7, 7, 7]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                (1, [\"C\", \"D\"]),\n                [7, 8],\n                pd.DataFrame(\n                    [[1, 2, np.nan, np.nan], [3, 4, 7, 8], [5, 6, np.nan, np.nan]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                (1, [\"A\", \"B\", \"C\"]),\n                np.array([7, 8, 9], dtype=np.int64),\n                pd.DataFrame(\n                    [[1, 2, np.nan], [7, 8, 9], [5, 6, np.nan]],\n                    columns=[\"A\", \"B\", \"C\"],\n                ),\n            ),\n            (\n                (slice(1, 3, None), [\"B\", \"C\", \"D\"]),\n                [[7, 8, 9], [10, 11, 12]],\n                pd.DataFrame(\n                    [[1, 2, np.nan, np.nan], [3, 7, 8, 9], [5, 10, 11, 12]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                (slice(1, 3, None), [\"C\", \"A\", \"D\"]),\n                np.array([[7, 8, 9], [10, 11, 12]], dtype=np.int64),\n                pd.DataFrame(\n                    [[1, 2, np.nan, np.nan], [8, 4, 7, 9], [11, 6, 10, 12]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                (slice(None, None, None), [\"A\", \"C\"]),\n                pd.DataFrame([[7, 8], [9, 10], [11, 12]], columns=[\"A\", \"C\"]),\n                pd.DataFrame(\n                    [[7, 2, 8], [9, 4, 10], [11, 6, 12]], columns=[\"A\", \"B\", \"C\"]\n                ),\n            ),\n        ],\n    )\n    def test_loc_setitem_missing_columns(self, index, box, expected):\n        # GH 29334\n        df = pd.DataFrame([[1, 2], [3, 4], [5, 6]], columns=[\"A\", \"B\"])\n>       df.loc[index] = box\n\npandas/tests/indexing/test_loc.py:689: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \npandas/core/indexing.py:619: in __setitem__\n    indexer = self._get_setitem_indexer(key)\npandas/core/indexing.py:598: in _get_setitem_indexer\n    return self._convert_tuple(key, is_setter=True)\npandas/core/indexing.py:687: in _convert_tuple\n    idx = self._convert_to_indexer(k, axis=i, is_setter=is_setter)\npandas/core/indexing.py:1174: in _convert_to_indexer\n    return self._get_listlike_indexer(key, axis, raise_missing=True)[1]\npandas/core/indexing.py:1228: in _get_listlike_indexer\n    self._validate_read_indexer(keyarr, indexer, axis, raise_missing=raise_missing)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <pandas.core.indexing._LocIndexer object at 0x118b3c900>\nkey = Index(['A', 'B', 'C'], dtype='object'), indexer = array([ 0,  1, -1])\naxis = 1, raise_missing = True\n\n    def _validate_read_indexer(\n        self, key, indexer, axis: int, raise_missing: bool = False\n    ):\n        \"\"\"\n        Check that indexer can be used to return a result.\n    \n        e.g. at least one element was found,\n        unless the list of keys was actually empty.\n    \n        Parameters\n        ----------\n        key : list-like\n            Targeted labels (only used to show correct error message).\n        indexer: array-like of booleans\n            Indices corresponding to the key,\n            (with -1 indicating not found).\n        axis: int\n            Dimension on which the indexing is being made.\n        raise_missing: bool\n            Whether to raise a KeyError if some labels are not found. Will be\n            removed in the future, and then this method will always behave as\n            if raise_missing=True.\n    \n        Raises\n        ------\n        KeyError\n            If at least one key was requested but none was found, and\n            raise_missing=True.\n        \"\"\"\n        ax = self.obj._get_axis(axis)\n    \n        if len(key) == 0:\n            return\n    \n        # Count missing values:\n        missing = (indexer < 0).sum()\n    \n        if missing:\n            if missing == len(indexer):\n                axis_name = self.obj._get_axis_name(axis)\n                raise KeyError(f\"None of [{key}] are in the [{axis_name}]\")\n    \n            # We (temporarily) allow for some missing keys with .loc, except in\n            # some cases (e.g. setting) in which \"raise_missing\" will be False\n            if raise_missing:\n                not_found = list(set(key) - set(ax))\n>               raise KeyError(f\"{not_found} not in index\")\nE               KeyError: \"['C'] not in index\"\n\npandas/core/indexing.py:1277: KeyError",
                "traceback": "pandas/core/indexing.py:619: in __setitem__\n    indexer = self._get_setitem_indexer(key)\npandas/core/indexing.py:598: in _get_setitem_indexer\n    return self._convert_tuple(key, is_setter=True)\npandas/core/indexing.py:687: in _convert_tuple\n    idx = self._convert_to_indexer(k, axis=i, is_setter=is_setter)\npandas/core/indexing.py:1174: in _convert_to_indexer\n    return self._get_listlike_indexer(key, axis, raise_missing=True)[1]\npandas/core/indexing.py:1228: in _get_listlike_indexer\n    self._validate_read_indexer(keyarr, indexer, axis, raise_missing=raise_missing)",
                "test_error_location": "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <pandas.core.indexing._LocIndexer object at 0x118b3c900>\nkey = Index(['A', 'B', 'C'], dtype='object'), indexer = array([ 0,  1, -1])\naxis = 1, raise_missing = True\n\n    def _validate_read_indexer(\n        self, key, indexer, axis: int, raise_missing: bool = False\n    ):\n        \"\"\"\n        Check that indexer can be used to return a result.\n    \n        e.g. at least one element was found,\n        unless the list of keys was actually empty.\n    \n        Parameters\n        ----------\n        key : list-like\n            Targeted labels (only used to show correct error message).\n        indexer: array-like of booleans\n            Indices corresponding to the key,\n            (with -1 indicating not found).\n        axis: int\n            Dimension on which the indexing is being made.\n        raise_missing: bool\n            Whether to raise a KeyError if some labels are not found. Will be\n            removed in the future, and then this method will always behave as\n            if raise_missing=True.\n    \n        Raises\n        ------\n        KeyError\n            If at least one key was requested but none was found, and\n            raise_missing=True.\n        \"\"\"\n        ax = self.obj._get_axis(axis)\n    \n        if len(key) == 0:\n            return\n    \n        # Count missing values:\n        missing = (indexer < 0).sum()\n    \n        if missing:\n            if missing == len(indexer):\n                axis_name = self.obj._get_axis_name(axis)\n                raise KeyError(f\"None of [{key}] are in the [{axis_name}]\")\n    \n            # We (temporarily) allow for some missing keys with .loc, except in\n            # some cases (e.g. setting) in which \"raise_missing\" will be False\n            if raise_missing:\n                not_found = list(set(key) - set(ax))\n>               raise KeyError(f\"{not_found} not in index\")\nE               KeyError: \"['C'] not in index\"\n\npandas/core/indexing.py:1277: KeyError",
                "test_function_decorators": [
                    "pytest.mark.parametrize('index,box,expected', [(([0, 2], ['A', 'B', 'C', 'D']), 7, pd.DataFrame([[7, 7, 7, 7], [3, 4, np.nan, np.nan], [7, 7, 7, 7]], columns=['A', 'B', 'C', 'D'])), ((1, ['C', 'D']), [7, 8], pd.DataFrame([[1, 2, np.nan, np.nan], [3, 4, 7, 8], [5, 6, np.nan, np.nan]], columns=['A', 'B', 'C', 'D'])), ((1, ['A', 'B', 'C']), np.array([7, 8, 9], dtype=np.int64), pd.DataFrame([[1, 2, np.nan], [7, 8, 9], [5, 6, np.nan]], columns=['A', 'B', 'C'])), ((slice(1, 3, None), ['B', 'C', 'D']), [[7, 8, 9], [10, 11, 12]], pd.DataFrame([[1, 2, np.nan, np.nan], [3, 7, 8, 9], [5, 10, 11, 12]], columns=['A', 'B', 'C', 'D'])), ((slice(1, 3, None), ['C', 'A', 'D']), np.array([[7, 8, 9], [10, 11, 12]], dtype=np.int64), pd.DataFrame([[1, 2, np.nan, np.nan], [8, 4, 7, 9], [11, 6, 10, 12]], columns=['A', 'B', 'C', 'D'])), ((slice(None, None, None), ['A', 'C']), pd.DataFrame([[7, 8], [9, 10], [11, 12]], columns=['A', 'C']), pd.DataFrame([[7, 2, 8], [9, 4, 10], [11, 6, 12]], columns=['A', 'B', 'C']))])"
                ]
            },
            {
                "test_path": "/Volumes/JerrySSD/bgp_envs/repos/pandas_47/pandas/tests/indexing/test_loc.py",
                "test_function": "test_loc_setitem_missing_columns",
                "test_function_code": "    @pytest.mark.parametrize(\n        \"index,box,expected\",\n        [\n            (\n                ([0, 2], [\"A\", \"B\", \"C\", \"D\"]),\n                7,\n                pd.DataFrame(\n                    [[7, 7, 7, 7], [3, 4, np.nan, np.nan], [7, 7, 7, 7]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                (1, [\"C\", \"D\"]),\n                [7, 8],\n                pd.DataFrame(\n                    [[1, 2, np.nan, np.nan], [3, 4, 7, 8], [5, 6, np.nan, np.nan]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                (1, [\"A\", \"B\", \"C\"]),\n                np.array([7, 8, 9], dtype=np.int64),\n                pd.DataFrame(\n                    [[1, 2, np.nan], [7, 8, 9], [5, 6, np.nan]],\n                    columns=[\"A\", \"B\", \"C\"],\n                ),\n            ),\n            (\n                (slice(1, 3, None), [\"B\", \"C\", \"D\"]),\n                [[7, 8, 9], [10, 11, 12]],\n                pd.DataFrame(\n                    [[1, 2, np.nan, np.nan], [3, 7, 8, 9], [5, 10, 11, 12]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                (slice(1, 3, None), [\"C\", \"A\", \"D\"]),\n                np.array([[7, 8, 9], [10, 11, 12]], dtype=np.int64),\n                pd.DataFrame(\n                    [[1, 2, np.nan, np.nan], [8, 4, 7, 9], [11, 6, 10, 12]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                (slice(None, None, None), [\"A\", \"C\"]),\n                pd.DataFrame([[7, 8], [9, 10], [11, 12]], columns=[\"A\", \"C\"]),\n                pd.DataFrame(\n                    [[7, 2, 8], [9, 4, 10], [11, 6, 12]], columns=[\"A\", \"B\", \"C\"]\n                ),\n            ),\n        ],\n    )\n    def test_loc_setitem_missing_columns(self, index, box, expected):\n        # GH 29334\n        df = pd.DataFrame([[1, 2], [3, 4], [5, 6]], columns=[\"A\", \"B\"])\n        df.loc[index] = box\n        tm.assert_frame_equal(df, expected)",
                "test_error": "KeyError: \"['C', 'D'] not in index\"",
                "full_test_error": "self = <pandas.tests.indexing.test_loc.TestLoc2 object at 0x120dba670>\nindex = (slice(1, 3, None), ['B', 'C', 'D']), box = [[7, 8, 9], [10, 11, 12]]\nexpected =    A   B     C     D\n0  1   2   NaN   NaN\n1  3   7   8.0   9.0\n2  5  10  11.0  12.0\n\n    @pytest.mark.parametrize(\n        \"index,box,expected\",\n        [\n            (\n                ([0, 2], [\"A\", \"B\", \"C\", \"D\"]),\n                7,\n                pd.DataFrame(\n                    [[7, 7, 7, 7], [3, 4, np.nan, np.nan], [7, 7, 7, 7]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                (1, [\"C\", \"D\"]),\n                [7, 8],\n                pd.DataFrame(\n                    [[1, 2, np.nan, np.nan], [3, 4, 7, 8], [5, 6, np.nan, np.nan]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                (1, [\"A\", \"B\", \"C\"]),\n                np.array([7, 8, 9], dtype=np.int64),\n                pd.DataFrame(\n                    [[1, 2, np.nan], [7, 8, 9], [5, 6, np.nan]],\n                    columns=[\"A\", \"B\", \"C\"],\n                ),\n            ),\n            (\n                (slice(1, 3, None), [\"B\", \"C\", \"D\"]),\n                [[7, 8, 9], [10, 11, 12]],\n                pd.DataFrame(\n                    [[1, 2, np.nan, np.nan], [3, 7, 8, 9], [5, 10, 11, 12]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                (slice(1, 3, None), [\"C\", \"A\", \"D\"]),\n                np.array([[7, 8, 9], [10, 11, 12]], dtype=np.int64),\n                pd.DataFrame(\n                    [[1, 2, np.nan, np.nan], [8, 4, 7, 9], [11, 6, 10, 12]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                (slice(None, None, None), [\"A\", \"C\"]),\n                pd.DataFrame([[7, 8], [9, 10], [11, 12]], columns=[\"A\", \"C\"]),\n                pd.DataFrame(\n                    [[7, 2, 8], [9, 4, 10], [11, 6, 12]], columns=[\"A\", \"B\", \"C\"]\n                ),\n            ),\n        ],\n    )\n    def test_loc_setitem_missing_columns(self, index, box, expected):\n        # GH 29334\n        df = pd.DataFrame([[1, 2], [3, 4], [5, 6]], columns=[\"A\", \"B\"])\n>       df.loc[index] = box\n\npandas/tests/indexing/test_loc.py:689: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \npandas/core/indexing.py:619: in __setitem__\n    indexer = self._get_setitem_indexer(key)\npandas/core/indexing.py:598: in _get_setitem_indexer\n    return self._convert_tuple(key, is_setter=True)\npandas/core/indexing.py:687: in _convert_tuple\n    idx = self._convert_to_indexer(k, axis=i, is_setter=is_setter)\npandas/core/indexing.py:1174: in _convert_to_indexer\n    return self._get_listlike_indexer(key, axis, raise_missing=True)[1]\npandas/core/indexing.py:1228: in _get_listlike_indexer\n    self._validate_read_indexer(keyarr, indexer, axis, raise_missing=raise_missing)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <pandas.core.indexing._LocIndexer object at 0x120dff4a0>\nkey = Index(['B', 'C', 'D'], dtype='object'), indexer = array([ 1, -1, -1])\naxis = 1, raise_missing = True\n\n    def _validate_read_indexer(\n        self, key, indexer, axis: int, raise_missing: bool = False\n    ):\n        \"\"\"\n        Check that indexer can be used to return a result.\n    \n        e.g. at least one element was found,\n        unless the list of keys was actually empty.\n    \n        Parameters\n        ----------\n        key : list-like\n            Targeted labels (only used to show correct error message).\n        indexer: array-like of booleans\n            Indices corresponding to the key,\n            (with -1 indicating not found).\n        axis: int\n            Dimension on which the indexing is being made.\n        raise_missing: bool\n            Whether to raise a KeyError if some labels are not found. Will be\n            removed in the future, and then this method will always behave as\n            if raise_missing=True.\n    \n        Raises\n        ------\n        KeyError\n            If at least one key was requested but none was found, and\n            raise_missing=True.\n        \"\"\"\n        ax = self.obj._get_axis(axis)\n    \n        if len(key) == 0:\n            return\n    \n        # Count missing values:\n        missing = (indexer < 0).sum()\n    \n        if missing:\n            if missing == len(indexer):\n                axis_name = self.obj._get_axis_name(axis)\n                raise KeyError(f\"None of [{key}] are in the [{axis_name}]\")\n    \n            # We (temporarily) allow for some missing keys with .loc, except in\n            # some cases (e.g. setting) in which \"raise_missing\" will be False\n            if raise_missing:\n                not_found = list(set(key) - set(ax))\n>               raise KeyError(f\"{not_found} not in index\")\nE               KeyError: \"['C', 'D'] not in index\"\n\npandas/core/indexing.py:1277: KeyError",
                "traceback": "pandas/core/indexing.py:619: in __setitem__\n    indexer = self._get_setitem_indexer(key)\npandas/core/indexing.py:598: in _get_setitem_indexer\n    return self._convert_tuple(key, is_setter=True)\npandas/core/indexing.py:687: in _convert_tuple\n    idx = self._convert_to_indexer(k, axis=i, is_setter=is_setter)\npandas/core/indexing.py:1174: in _convert_to_indexer\n    return self._get_listlike_indexer(key, axis, raise_missing=True)[1]\npandas/core/indexing.py:1228: in _get_listlike_indexer\n    self._validate_read_indexer(keyarr, indexer, axis, raise_missing=raise_missing)",
                "test_error_location": "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <pandas.core.indexing._LocIndexer object at 0x120dff4a0>\nkey = Index(['B', 'C', 'D'], dtype='object'), indexer = array([ 1, -1, -1])\naxis = 1, raise_missing = True\n\n    def _validate_read_indexer(\n        self, key, indexer, axis: int, raise_missing: bool = False\n    ):\n        \"\"\"\n        Check that indexer can be used to return a result.\n    \n        e.g. at least one element was found,\n        unless the list of keys was actually empty.\n    \n        Parameters\n        ----------\n        key : list-like\n            Targeted labels (only used to show correct error message).\n        indexer: array-like of booleans\n            Indices corresponding to the key,\n            (with -1 indicating not found).\n        axis: int\n            Dimension on which the indexing is being made.\n        raise_missing: bool\n            Whether to raise a KeyError if some labels are not found. Will be\n            removed in the future, and then this method will always behave as\n            if raise_missing=True.\n    \n        Raises\n        ------\n        KeyError\n            If at least one key was requested but none was found, and\n            raise_missing=True.\n        \"\"\"\n        ax = self.obj._get_axis(axis)\n    \n        if len(key) == 0:\n            return\n    \n        # Count missing values:\n        missing = (indexer < 0).sum()\n    \n        if missing:\n            if missing == len(indexer):\n                axis_name = self.obj._get_axis_name(axis)\n                raise KeyError(f\"None of [{key}] are in the [{axis_name}]\")\n    \n            # We (temporarily) allow for some missing keys with .loc, except in\n            # some cases (e.g. setting) in which \"raise_missing\" will be False\n            if raise_missing:\n                not_found = list(set(key) - set(ax))\n>               raise KeyError(f\"{not_found} not in index\")\nE               KeyError: \"['C', 'D'] not in index\"\n\npandas/core/indexing.py:1277: KeyError",
                "test_function_decorators": [
                    "pytest.mark.parametrize('index,box,expected', [(([0, 2], ['A', 'B', 'C', 'D']), 7, pd.DataFrame([[7, 7, 7, 7], [3, 4, np.nan, np.nan], [7, 7, 7, 7]], columns=['A', 'B', 'C', 'D'])), ((1, ['C', 'D']), [7, 8], pd.DataFrame([[1, 2, np.nan, np.nan], [3, 4, 7, 8], [5, 6, np.nan, np.nan]], columns=['A', 'B', 'C', 'D'])), ((1, ['A', 'B', 'C']), np.array([7, 8, 9], dtype=np.int64), pd.DataFrame([[1, 2, np.nan], [7, 8, 9], [5, 6, np.nan]], columns=['A', 'B', 'C'])), ((slice(1, 3, None), ['B', 'C', 'D']), [[7, 8, 9], [10, 11, 12]], pd.DataFrame([[1, 2, np.nan, np.nan], [3, 7, 8, 9], [5, 10, 11, 12]], columns=['A', 'B', 'C', 'D'])), ((slice(1, 3, None), ['C', 'A', 'D']), np.array([[7, 8, 9], [10, 11, 12]], dtype=np.int64), pd.DataFrame([[1, 2, np.nan, np.nan], [8, 4, 7, 9], [11, 6, 10, 12]], columns=['A', 'B', 'C', 'D'])), ((slice(None, None, None), ['A', 'C']), pd.DataFrame([[7, 8], [9, 10], [11, 12]], columns=['A', 'C']), pd.DataFrame([[7, 2, 8], [9, 4, 10], [11, 6, 12]], columns=['A', 'B', 'C']))])"
                ]
            },
            {
                "test_path": "/Volumes/JerrySSD/bgp_envs/repos/pandas_47/pandas/tests/indexing/test_loc.py",
                "test_function": "test_loc_setitem_missing_columns",
                "test_function_code": "    @pytest.mark.parametrize(\n        \"index,box,expected\",\n        [\n            (\n                ([0, 2], [\"A\", \"B\", \"C\", \"D\"]),\n                7,\n                pd.DataFrame(\n                    [[7, 7, 7, 7], [3, 4, np.nan, np.nan], [7, 7, 7, 7]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                (1, [\"C\", \"D\"]),\n                [7, 8],\n                pd.DataFrame(\n                    [[1, 2, np.nan, np.nan], [3, 4, 7, 8], [5, 6, np.nan, np.nan]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                (1, [\"A\", \"B\", \"C\"]),\n                np.array([7, 8, 9], dtype=np.int64),\n                pd.DataFrame(\n                    [[1, 2, np.nan], [7, 8, 9], [5, 6, np.nan]],\n                    columns=[\"A\", \"B\", \"C\"],\n                ),\n            ),\n            (\n                (slice(1, 3, None), [\"B\", \"C\", \"D\"]),\n                [[7, 8, 9], [10, 11, 12]],\n                pd.DataFrame(\n                    [[1, 2, np.nan, np.nan], [3, 7, 8, 9], [5, 10, 11, 12]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                (slice(1, 3, None), [\"C\", \"A\", \"D\"]),\n                np.array([[7, 8, 9], [10, 11, 12]], dtype=np.int64),\n                pd.DataFrame(\n                    [[1, 2, np.nan, np.nan], [8, 4, 7, 9], [11, 6, 10, 12]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                (slice(None, None, None), [\"A\", \"C\"]),\n                pd.DataFrame([[7, 8], [9, 10], [11, 12]], columns=[\"A\", \"C\"]),\n                pd.DataFrame(\n                    [[7, 2, 8], [9, 4, 10], [11, 6, 12]], columns=[\"A\", \"B\", \"C\"]\n                ),\n            ),\n        ],\n    )\n    def test_loc_setitem_missing_columns(self, index, box, expected):\n        # GH 29334\n        df = pd.DataFrame([[1, 2], [3, 4], [5, 6]], columns=[\"A\", \"B\"])\n        df.loc[index] = box\n        tm.assert_frame_equal(df, expected)",
                "test_error": "KeyError: \"['C', 'D'] not in index\"",
                "full_test_error": "self = <pandas.tests.indexing.test_loc.TestLoc2 object at 0x120f54550>\nindex = (slice(1, 3, None), ['C', 'A', 'D'])\nbox = array([[ 7,  8,  9],\n       [10, 11, 12]])\nexpected =     A  B     C     D\n0   1  2   NaN   NaN\n1   8  4   7.0   9.0\n2  11  6  10.0  12.0\n\n    @pytest.mark.parametrize(\n        \"index,box,expected\",\n        [\n            (\n                ([0, 2], [\"A\", \"B\", \"C\", \"D\"]),\n                7,\n                pd.DataFrame(\n                    [[7, 7, 7, 7], [3, 4, np.nan, np.nan], [7, 7, 7, 7]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                (1, [\"C\", \"D\"]),\n                [7, 8],\n                pd.DataFrame(\n                    [[1, 2, np.nan, np.nan], [3, 4, 7, 8], [5, 6, np.nan, np.nan]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                (1, [\"A\", \"B\", \"C\"]),\n                np.array([7, 8, 9], dtype=np.int64),\n                pd.DataFrame(\n                    [[1, 2, np.nan], [7, 8, 9], [5, 6, np.nan]],\n                    columns=[\"A\", \"B\", \"C\"],\n                ),\n            ),\n            (\n                (slice(1, 3, None), [\"B\", \"C\", \"D\"]),\n                [[7, 8, 9], [10, 11, 12]],\n                pd.DataFrame(\n                    [[1, 2, np.nan, np.nan], [3, 7, 8, 9], [5, 10, 11, 12]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                (slice(1, 3, None), [\"C\", \"A\", \"D\"]),\n                np.array([[7, 8, 9], [10, 11, 12]], dtype=np.int64),\n                pd.DataFrame(\n                    [[1, 2, np.nan, np.nan], [8, 4, 7, 9], [11, 6, 10, 12]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                (slice(None, None, None), [\"A\", \"C\"]),\n                pd.DataFrame([[7, 8], [9, 10], [11, 12]], columns=[\"A\", \"C\"]),\n                pd.DataFrame(\n                    [[7, 2, 8], [9, 4, 10], [11, 6, 12]], columns=[\"A\", \"B\", \"C\"]\n                ),\n            ),\n        ],\n    )\n    def test_loc_setitem_missing_columns(self, index, box, expected):\n        # GH 29334\n        df = pd.DataFrame([[1, 2], [3, 4], [5, 6]], columns=[\"A\", \"B\"])\n>       df.loc[index] = box\n\npandas/tests/indexing/test_loc.py:689: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \npandas/core/indexing.py:619: in __setitem__\n    indexer = self._get_setitem_indexer(key)\npandas/core/indexing.py:598: in _get_setitem_indexer\n    return self._convert_tuple(key, is_setter=True)\npandas/core/indexing.py:687: in _convert_tuple\n    idx = self._convert_to_indexer(k, axis=i, is_setter=is_setter)\npandas/core/indexing.py:1174: in _convert_to_indexer\n    return self._get_listlike_indexer(key, axis, raise_missing=True)[1]\npandas/core/indexing.py:1228: in _get_listlike_indexer\n    self._validate_read_indexer(keyarr, indexer, axis, raise_missing=raise_missing)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <pandas.core.indexing._LocIndexer object at 0x120f86810>\nkey = Index(['C', 'A', 'D'], dtype='object'), indexer = array([-1,  0, -1])\naxis = 1, raise_missing = True\n\n    def _validate_read_indexer(\n        self, key, indexer, axis: int, raise_missing: bool = False\n    ):\n        \"\"\"\n        Check that indexer can be used to return a result.\n    \n        e.g. at least one element was found,\n        unless the list of keys was actually empty.\n    \n        Parameters\n        ----------\n        key : list-like\n            Targeted labels (only used to show correct error message).\n        indexer: array-like of booleans\n            Indices corresponding to the key,\n            (with -1 indicating not found).\n        axis: int\n            Dimension on which the indexing is being made.\n        raise_missing: bool\n            Whether to raise a KeyError if some labels are not found. Will be\n            removed in the future, and then this method will always behave as\n            if raise_missing=True.\n    \n        Raises\n        ------\n        KeyError\n            If at least one key was requested but none was found, and\n            raise_missing=True.\n        \"\"\"\n        ax = self.obj._get_axis(axis)\n    \n        if len(key) == 0:\n            return\n    \n        # Count missing values:\n        missing = (indexer < 0).sum()\n    \n        if missing:\n            if missing == len(indexer):\n                axis_name = self.obj._get_axis_name(axis)\n                raise KeyError(f\"None of [{key}] are in the [{axis_name}]\")\n    \n            # We (temporarily) allow for some missing keys with .loc, except in\n            # some cases (e.g. setting) in which \"raise_missing\" will be False\n            if raise_missing:\n                not_found = list(set(key) - set(ax))\n>               raise KeyError(f\"{not_found} not in index\")\nE               KeyError: \"['C', 'D'] not in index\"\n\npandas/core/indexing.py:1277: KeyError",
                "traceback": "pandas/core/indexing.py:619: in __setitem__\n    indexer = self._get_setitem_indexer(key)\npandas/core/indexing.py:598: in _get_setitem_indexer\n    return self._convert_tuple(key, is_setter=True)\npandas/core/indexing.py:687: in _convert_tuple\n    idx = self._convert_to_indexer(k, axis=i, is_setter=is_setter)\npandas/core/indexing.py:1174: in _convert_to_indexer\n    return self._get_listlike_indexer(key, axis, raise_missing=True)[1]\npandas/core/indexing.py:1228: in _get_listlike_indexer\n    self._validate_read_indexer(keyarr, indexer, axis, raise_missing=raise_missing)",
                "test_error_location": "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <pandas.core.indexing._LocIndexer object at 0x120f86810>\nkey = Index(['C', 'A', 'D'], dtype='object'), indexer = array([-1,  0, -1])\naxis = 1, raise_missing = True\n\n    def _validate_read_indexer(\n        self, key, indexer, axis: int, raise_missing: bool = False\n    ):\n        \"\"\"\n        Check that indexer can be used to return a result.\n    \n        e.g. at least one element was found,\n        unless the list of keys was actually empty.\n    \n        Parameters\n        ----------\n        key : list-like\n            Targeted labels (only used to show correct error message).\n        indexer: array-like of booleans\n            Indices corresponding to the key,\n            (with -1 indicating not found).\n        axis: int\n            Dimension on which the indexing is being made.\n        raise_missing: bool\n            Whether to raise a KeyError if some labels are not found. Will be\n            removed in the future, and then this method will always behave as\n            if raise_missing=True.\n    \n        Raises\n        ------\n        KeyError\n            If at least one key was requested but none was found, and\n            raise_missing=True.\n        \"\"\"\n        ax = self.obj._get_axis(axis)\n    \n        if len(key) == 0:\n            return\n    \n        # Count missing values:\n        missing = (indexer < 0).sum()\n    \n        if missing:\n            if missing == len(indexer):\n                axis_name = self.obj._get_axis_name(axis)\n                raise KeyError(f\"None of [{key}] are in the [{axis_name}]\")\n    \n            # We (temporarily) allow for some missing keys with .loc, except in\n            # some cases (e.g. setting) in which \"raise_missing\" will be False\n            if raise_missing:\n                not_found = list(set(key) - set(ax))\n>               raise KeyError(f\"{not_found} not in index\")\nE               KeyError: \"['C', 'D'] not in index\"\n\npandas/core/indexing.py:1277: KeyError",
                "test_function_decorators": [
                    "pytest.mark.parametrize('index,box,expected', [(([0, 2], ['A', 'B', 'C', 'D']), 7, pd.DataFrame([[7, 7, 7, 7], [3, 4, np.nan, np.nan], [7, 7, 7, 7]], columns=['A', 'B', 'C', 'D'])), ((1, ['C', 'D']), [7, 8], pd.DataFrame([[1, 2, np.nan, np.nan], [3, 4, 7, 8], [5, 6, np.nan, np.nan]], columns=['A', 'B', 'C', 'D'])), ((1, ['A', 'B', 'C']), np.array([7, 8, 9], dtype=np.int64), pd.DataFrame([[1, 2, np.nan], [7, 8, 9], [5, 6, np.nan]], columns=['A', 'B', 'C'])), ((slice(1, 3, None), ['B', 'C', 'D']), [[7, 8, 9], [10, 11, 12]], pd.DataFrame([[1, 2, np.nan, np.nan], [3, 7, 8, 9], [5, 10, 11, 12]], columns=['A', 'B', 'C', 'D'])), ((slice(1, 3, None), ['C', 'A', 'D']), np.array([[7, 8, 9], [10, 11, 12]], dtype=np.int64), pd.DataFrame([[1, 2, np.nan, np.nan], [8, 4, 7, 9], [11, 6, 10, 12]], columns=['A', 'B', 'C', 'D'])), ((slice(None, None, None), ['A', 'C']), pd.DataFrame([[7, 8], [9, 10], [11, 12]], columns=['A', 'C']), pd.DataFrame([[7, 2, 8], [9, 4, 10], [11, 6, 12]], columns=['A', 'B', 'C']))])"
                ]
            },
            {
                "test_path": "/Volumes/JerrySSD/bgp_envs/repos/pandas_47/pandas/tests/indexing/test_loc.py",
                "test_function": "test_loc_setitem_missing_columns",
                "test_function_code": "    @pytest.mark.parametrize(\n        \"index,box,expected\",\n        [\n            (\n                ([0, 2], [\"A\", \"B\", \"C\", \"D\"]),\n                7,\n                pd.DataFrame(\n                    [[7, 7, 7, 7], [3, 4, np.nan, np.nan], [7, 7, 7, 7]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                (1, [\"C\", \"D\"]),\n                [7, 8],\n                pd.DataFrame(\n                    [[1, 2, np.nan, np.nan], [3, 4, 7, 8], [5, 6, np.nan, np.nan]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                (1, [\"A\", \"B\", \"C\"]),\n                np.array([7, 8, 9], dtype=np.int64),\n                pd.DataFrame(\n                    [[1, 2, np.nan], [7, 8, 9], [5, 6, np.nan]],\n                    columns=[\"A\", \"B\", \"C\"],\n                ),\n            ),\n            (\n                (slice(1, 3, None), [\"B\", \"C\", \"D\"]),\n                [[7, 8, 9], [10, 11, 12]],\n                pd.DataFrame(\n                    [[1, 2, np.nan, np.nan], [3, 7, 8, 9], [5, 10, 11, 12]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                (slice(1, 3, None), [\"C\", \"A\", \"D\"]),\n                np.array([[7, 8, 9], [10, 11, 12]], dtype=np.int64),\n                pd.DataFrame(\n                    [[1, 2, np.nan, np.nan], [8, 4, 7, 9], [11, 6, 10, 12]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                (slice(None, None, None), [\"A\", \"C\"]),\n                pd.DataFrame([[7, 8], [9, 10], [11, 12]], columns=[\"A\", \"C\"]),\n                pd.DataFrame(\n                    [[7, 2, 8], [9, 4, 10], [11, 6, 12]], columns=[\"A\", \"B\", \"C\"]\n                ),\n            ),\n        ],\n    )\n    def test_loc_setitem_missing_columns(self, index, box, expected):\n        # GH 29334\n        df = pd.DataFrame([[1, 2], [3, 4], [5, 6]], columns=[\"A\", \"B\"])\n        df.loc[index] = box\n        tm.assert_frame_equal(df, expected)",
                "test_error": "KeyError: \"['C'] not in index\"",
                "full_test_error": "self = <pandas.tests.indexing.test_loc.TestLoc2 object at 0x120d9ea00>\nindex = (slice(None, None, None), ['A', 'C'])\nbox =     A   C\n0   7   8\n1   9  10\n2  11  12\nexpected =     A  B   C\n0   7  2   8\n1   9  4  10\n2  11  6  12\n\n    @pytest.mark.parametrize(\n        \"index,box,expected\",\n        [\n            (\n                ([0, 2], [\"A\", \"B\", \"C\", \"D\"]),\n                7,\n                pd.DataFrame(\n                    [[7, 7, 7, 7], [3, 4, np.nan, np.nan], [7, 7, 7, 7]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                (1, [\"C\", \"D\"]),\n                [7, 8],\n                pd.DataFrame(\n                    [[1, 2, np.nan, np.nan], [3, 4, 7, 8], [5, 6, np.nan, np.nan]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                (1, [\"A\", \"B\", \"C\"]),\n                np.array([7, 8, 9], dtype=np.int64),\n                pd.DataFrame(\n                    [[1, 2, np.nan], [7, 8, 9], [5, 6, np.nan]],\n                    columns=[\"A\", \"B\", \"C\"],\n                ),\n            ),\n            (\n                (slice(1, 3, None), [\"B\", \"C\", \"D\"]),\n                [[7, 8, 9], [10, 11, 12]],\n                pd.DataFrame(\n                    [[1, 2, np.nan, np.nan], [3, 7, 8, 9], [5, 10, 11, 12]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                (slice(1, 3, None), [\"C\", \"A\", \"D\"]),\n                np.array([[7, 8, 9], [10, 11, 12]], dtype=np.int64),\n                pd.DataFrame(\n                    [[1, 2, np.nan, np.nan], [8, 4, 7, 9], [11, 6, 10, 12]],\n                    columns=[\"A\", \"B\", \"C\", \"D\"],\n                ),\n            ),\n            (\n                (slice(None, None, None), [\"A\", \"C\"]),\n                pd.DataFrame([[7, 8], [9, 10], [11, 12]], columns=[\"A\", \"C\"]),\n                pd.DataFrame(\n                    [[7, 2, 8], [9, 4, 10], [11, 6, 12]], columns=[\"A\", \"B\", \"C\"]\n                ),\n            ),\n        ],\n    )\n    def test_loc_setitem_missing_columns(self, index, box, expected):\n        # GH 29334\n        df = pd.DataFrame([[1, 2], [3, 4], [5, 6]], columns=[\"A\", \"B\"])\n>       df.loc[index] = box\n\npandas/tests/indexing/test_loc.py:689: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \npandas/core/indexing.py:619: in __setitem__\n    indexer = self._get_setitem_indexer(key)\npandas/core/indexing.py:598: in _get_setitem_indexer\n    return self._convert_tuple(key, is_setter=True)\npandas/core/indexing.py:687: in _convert_tuple\n    idx = self._convert_to_indexer(k, axis=i, is_setter=is_setter)\npandas/core/indexing.py:1174: in _convert_to_indexer\n    return self._get_listlike_indexer(key, axis, raise_missing=True)[1]\npandas/core/indexing.py:1228: in _get_listlike_indexer\n    self._validate_read_indexer(keyarr, indexer, axis, raise_missing=raise_missing)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <pandas.core.indexing._LocIndexer object at 0x12133de50>\nkey = Index(['A', 'C'], dtype='object'), indexer = array([ 0, -1]), axis = 1\nraise_missing = True\n\n    def _validate_read_indexer(\n        self, key, indexer, axis: int, raise_missing: bool = False\n    ):\n        \"\"\"\n        Check that indexer can be used to return a result.\n    \n        e.g. at least one element was found,\n        unless the list of keys was actually empty.\n    \n        Parameters\n        ----------\n        key : list-like\n            Targeted labels (only used to show correct error message).\n        indexer: array-like of booleans\n            Indices corresponding to the key,\n            (with -1 indicating not found).\n        axis: int\n            Dimension on which the indexing is being made.\n        raise_missing: bool\n            Whether to raise a KeyError if some labels are not found. Will be\n            removed in the future, and then this method will always behave as\n            if raise_missing=True.\n    \n        Raises\n        ------\n        KeyError\n            If at least one key was requested but none was found, and\n            raise_missing=True.\n        \"\"\"\n        ax = self.obj._get_axis(axis)\n    \n        if len(key) == 0:\n            return\n    \n        # Count missing values:\n        missing = (indexer < 0).sum()\n    \n        if missing:\n            if missing == len(indexer):\n                axis_name = self.obj._get_axis_name(axis)\n                raise KeyError(f\"None of [{key}] are in the [{axis_name}]\")\n    \n            # We (temporarily) allow for some missing keys with .loc, except in\n            # some cases (e.g. setting) in which \"raise_missing\" will be False\n            if raise_missing:\n                not_found = list(set(key) - set(ax))\n>               raise KeyError(f\"{not_found} not in index\")\nE               KeyError: \"['C'] not in index\"\n\npandas/core/indexing.py:1277: KeyError",
                "traceback": "pandas/core/indexing.py:619: in __setitem__\n    indexer = self._get_setitem_indexer(key)\npandas/core/indexing.py:598: in _get_setitem_indexer\n    return self._convert_tuple(key, is_setter=True)\npandas/core/indexing.py:687: in _convert_tuple\n    idx = self._convert_to_indexer(k, axis=i, is_setter=is_setter)\npandas/core/indexing.py:1174: in _convert_to_indexer\n    return self._get_listlike_indexer(key, axis, raise_missing=True)[1]\npandas/core/indexing.py:1228: in _get_listlike_indexer\n    self._validate_read_indexer(keyarr, indexer, axis, raise_missing=raise_missing)",
                "test_error_location": "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <pandas.core.indexing._LocIndexer object at 0x12133de50>\nkey = Index(['A', 'C'], dtype='object'), indexer = array([ 0, -1]), axis = 1\nraise_missing = True\n\n    def _validate_read_indexer(\n        self, key, indexer, axis: int, raise_missing: bool = False\n    ):\n        \"\"\"\n        Check that indexer can be used to return a result.\n    \n        e.g. at least one element was found,\n        unless the list of keys was actually empty.\n    \n        Parameters\n        ----------\n        key : list-like\n            Targeted labels (only used to show correct error message).\n        indexer: array-like of booleans\n            Indices corresponding to the key,\n            (with -1 indicating not found).\n        axis: int\n            Dimension on which the indexing is being made.\n        raise_missing: bool\n            Whether to raise a KeyError if some labels are not found. Will be\n            removed in the future, and then this method will always behave as\n            if raise_missing=True.\n    \n        Raises\n        ------\n        KeyError\n            If at least one key was requested but none was found, and\n            raise_missing=True.\n        \"\"\"\n        ax = self.obj._get_axis(axis)\n    \n        if len(key) == 0:\n            return\n    \n        # Count missing values:\n        missing = (indexer < 0).sum()\n    \n        if missing:\n            if missing == len(indexer):\n                axis_name = self.obj._get_axis_name(axis)\n                raise KeyError(f\"None of [{key}] are in the [{axis_name}]\")\n    \n            # We (temporarily) allow for some missing keys with .loc, except in\n            # some cases (e.g. setting) in which \"raise_missing\" will be False\n            if raise_missing:\n                not_found = list(set(key) - set(ax))\n>               raise KeyError(f\"{not_found} not in index\")\nE               KeyError: \"['C'] not in index\"\n\npandas/core/indexing.py:1277: KeyError",
                "test_function_decorators": [
                    "pytest.mark.parametrize('index,box,expected', [(([0, 2], ['A', 'B', 'C', 'D']), 7, pd.DataFrame([[7, 7, 7, 7], [3, 4, np.nan, np.nan], [7, 7, 7, 7]], columns=['A', 'B', 'C', 'D'])), ((1, ['C', 'D']), [7, 8], pd.DataFrame([[1, 2, np.nan, np.nan], [3, 4, 7, 8], [5, 6, np.nan, np.nan]], columns=['A', 'B', 'C', 'D'])), ((1, ['A', 'B', 'C']), np.array([7, 8, 9], dtype=np.int64), pd.DataFrame([[1, 2, np.nan], [7, 8, 9], [5, 6, np.nan]], columns=['A', 'B', 'C'])), ((slice(1, 3, None), ['B', 'C', 'D']), [[7, 8, 9], [10, 11, 12]], pd.DataFrame([[1, 2, np.nan, np.nan], [3, 7, 8, 9], [5, 10, 11, 12]], columns=['A', 'B', 'C', 'D'])), ((slice(1, 3, None), ['C', 'A', 'D']), np.array([[7, 8, 9], [10, 11, 12]], dtype=np.int64), pd.DataFrame([[1, 2, np.nan, np.nan], [8, 4, 7, 9], [11, 6, 10, 12]], columns=['A', 'B', 'C', 'D'])), ((slice(None, None, None), ['A', 'C']), pd.DataFrame([[7, 8], [9, 10], [11, 12]], columns=['A', 'C']), pd.DataFrame([[7, 2, 8], [9, 4, 10], [11, 6, 12]], columns=['A', 'B', 'C']))])"
                ]
            }
        ]
    }
}