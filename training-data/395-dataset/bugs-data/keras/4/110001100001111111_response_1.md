The error in the provided function is likely related to the custom optimizer `MyTfOptimizer` that is being used with Keras. It seems that the `MyTfOptimizer` does not fully support the compute_gradients and apply_gradients methods.

To fix the function, you can modify it to directly use the TensorFlow optimizer's compute_gradients and apply_gradients methods. This can be done by accessing the TensorFlow optimizer object from the Keras optimizer and calling its methods directly. 

Here's the corrected function:

```python
@interfaces.legacy_get_updates_support
def get_updates(self, loss, params):
    grads = self.optimizer.get_gradients(loss, params)
    self.updates = [K.update_add(self.iterations, 1)]
    opt_update = self.optimizer.apply_gradients(zip(grads, params), global_step=self.iterations)
    self.updates.append(opt_update)
    return self.updates
```

With this modification, the function will now use the native TensorFlow optimizer's methods to compute gradients and apply the gradients to the parameters, which should resolve the issue with the custom optimizer.