{
    "keras:20": {
        "/Volumes/SSD2T/bgp_envs_non_pandas/repos/keras_20/keras/backend/cntk_backend.py": {
            "buggy_functions": [
                {
                    "function_name": "conv2d_transpose",
                    "function_code": "def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),\n                     padding='valid', data_format=None):\n    data_format = normalize_data_format(data_format)\n\n    x = _preprocess_conv2d_input(x, data_format)\n    kernel = _preprocess_conv2d_kernel(kernel, data_format)\n    padding = _preprocess_border_mode(padding)\n    strides = (1,) + strides\n    # cntk output_shape does not include batch axis\n    output_shape = output_shape[1:]\n    # in keras2, need handle output shape in different format\n    if data_format == 'channels_last':\n        output_shape = transpose_shape(output_shape, 'channels_first',\n                                       spatial_axes=(0, 1))\n\n    x = C.convolution_transpose(\n        kernel,\n        x,\n        strides,\n        auto_padding=[\n            False,\n            padding,\n            padding],\n        output_shape=output_shape)\n    return _postprocess_conv2d_output(x, data_format)\n",
                    "decorators": [],
                    "docstring": null,
                    "start_line": 2188,
                    "end_line": 2212,
                    "variables": {
                        "data_format": [
                            2212,
                            2190,
                            2192,
                            2193,
                            2199
                        ],
                        "normalize_data_format": [
                            2190
                        ],
                        "x": [
                            2192,
                            2203,
                            2212,
                            2205
                        ],
                        "_preprocess_conv2d_input": [
                            2192
                        ],
                        "kernel": [
                            2193,
                            2204
                        ],
                        "_preprocess_conv2d_kernel": [
                            2193
                        ],
                        "padding": [
                            2210,
                            2209,
                            2194
                        ],
                        "_preprocess_border_mode": [
                            2194
                        ],
                        "strides": [
                            2195,
                            2206
                        ],
                        "output_shape": [
                            2200,
                            2211,
                            2197
                        ],
                        "transpose_shape": [
                            2200
                        ],
                        "C.convolution_transpose": [
                            2203
                        ],
                        "C": [
                            2203
                        ],
                        "_postprocess_conv2d_output": [
                            2212
                        ]
                    },
                    "filtered_variables": {
                        "data_format": [
                            2212,
                            2190,
                            2192,
                            2193,
                            2199
                        ],
                        "normalize_data_format": [
                            2190
                        ],
                        "x": [
                            2192,
                            2203,
                            2212,
                            2205
                        ],
                        "_preprocess_conv2d_input": [
                            2192
                        ],
                        "kernel": [
                            2193,
                            2204
                        ],
                        "_preprocess_conv2d_kernel": [
                            2193
                        ],
                        "padding": [
                            2210,
                            2209,
                            2194
                        ],
                        "_preprocess_border_mode": [
                            2194
                        ],
                        "strides": [
                            2195,
                            2206
                        ],
                        "output_shape": [
                            2200,
                            2211,
                            2197
                        ],
                        "transpose_shape": [
                            2200
                        ],
                        "C.convolution_transpose": [
                            2203
                        ],
                        "C": [
                            2203
                        ],
                        "_postprocess_conv2d_output": [
                            2212
                        ]
                    },
                    "diff_line_number": 2189,
                    "class_data": null,
                    "variable_values": [
                        [
                            {},
                            {}
                        ]
                    ],
                    "angelic_variable_values": [
                        [
                            {},
                            {}
                        ]
                    ]
                }
            ],
            "inscope_functions": [
                "@contextmanager\ndef name_scope(name):\n    global NAME_SCOPE_STACK\n    NAME_SCOPE_STACK.append(name)\n    yield\n    NAME_SCOPE_STACK.pop()",
                "def get_uid(prefix=''):\n    _UID_PREFIXES[prefix] += 1\n    return _UID_PREFIXES[prefix]",
                "def learning_phase():\n    # If _LEARNING_PHASE is not 0 or 1, return dynamic learning phase tensor\n    return _LEARNING_PHASE if _LEARNING_PHASE in {0, 1} else _LEARNING_PHASE_PLACEHOLDER",
                "def set_learning_phase(value):\n    global _LEARNING_PHASE\n    if value not in {0, 1}:\n        raise ValueError('CNTK Backend: Set learning phase '\n                         'with value %s is not supported, '\n                         'expected 0 or 1.' % value)\n    _LEARNING_PHASE = value",
                "def clear_session():\n    \"\"\"Reset learning phase flag for cntk backend.\n    \"\"\"\n    global _LEARNING_PHASE\n    global _LEARNING_PHASE_PLACEHOLDER\n    _LEARNING_PHASE = -1\n    _LEARNING_PHASE_PLACEHOLDER.value = np.asarray(1.0)",
                "def in_train_phase(x, alt, training=None):\n    global _LEARNING_PHASE\n    if training is None:\n        training = learning_phase()\n        uses_learning_phase = True\n    else:\n        uses_learning_phase = False\n\n    # CNTK currently don't support cond op, so here we use\n    # element_select approach as workaround. It may have\n    # perf issue, will resolve it later with cntk cond op.\n    if callable(x) and isinstance(x, C.cntk_py.Function) is False:\n        x = x()\n    if callable(alt) and isinstance(alt, C.cntk_py.Function) is False:\n        alt = alt()\n\n    if training is True:\n        x._uses_learning_phase = uses_learning_phase\n        return x\n    else:\n        # if _LEARNING_PHASE is static\n        if isinstance(training, int) or isinstance(training, bool):\n            result = x if training == 1 or training is True else alt\n        else:\n            result = C.element_select(training, x, alt)\n        result._uses_learning_phase = uses_learning_phase\n        return result",
                "def in_test_phase(x, alt, training=None):\n    return in_train_phase(alt, x, training=training)",
                "def _convert_string_dtype(dtype):\n    if dtype == 'float32':\n        return np.float32\n    elif dtype == 'float64':\n        return np.float64\n    elif dtype == 'float16':\n        return np.float16\n    else:\n        # cntk only running with float,\n        # try to cast to float to run the model\n        return np.float32",
                "def _convert_dtype_string(dtype):\n    if dtype == np.float32:\n        return 'float32'\n    elif dtype == np.float64:\n        return 'float64'\n    elif dtype == np.float16:\n        return 'float16'\n    else:\n        raise ValueError('CNTK Backend: Unsupported dtype: %s. '\n                         'CNTK only supports float32, float64, and '\n                         'float16.' % dtype)",
                "def variable(value, dtype=None, name=None, constraint=None):\n    \"\"\"Instantiates a variable and returns it.\n\n    # Arguments\n        value: Numpy array, initial value of the tensor.\n        dtype: Tensor type.\n        name: Optional name string for the tensor.\n        constraint: Optional projection function to be\n            applied to the variable after an optimizer update.\n\n    # Returns\n        A variable instance (with Keras metadata included).\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n\n    if name is None:\n        name = ''\n\n    if isinstance(\n            value,\n            C.variables.Constant) or isinstance(\n            value,\n            C.variables.Parameter):\n        value = value.value\n\n    # we don't support init parameter with symbolic op, so eval it first as\n    # workaround\n    if isinstance(value, C.cntk_py.Function):\n        value = eval(value)\n\n    shape = value.shape if hasattr(value, 'shape') else ()\n    if hasattr(value, 'dtype') and value.dtype != dtype and len(shape) > 0:\n        value = value.astype(dtype)\n\n    # TODO: remove the conversion when cntk supports int32, int64\n    # https://docs.microsoft.com/en-us/python/api/cntk.variables.parameter\n    dtype = 'float32' if 'int' in str(dtype) else dtype\n\n    v = C.parameter(shape=shape,\n                    init=value,\n                    dtype=dtype,\n                    name=_prepare_name(name, 'variable'))\n    v._keras_shape = v.shape\n    v._uses_learning_phase = False\n    v.constraint = constraint\n    return v",
                "def bias_add(x, bias, data_format=None):\n    data_format = normalize_data_format(data_format)\n\n    dims = len(x.shape)\n    if dims > 0 and x.shape[0] == C.InferredDimension:\n        dims -= 1\n\n    bias_dims = len(bias.shape)\n    if bias_dims != 1 and bias_dims != dims:\n        raise ValueError('Unexpected bias dimensions %d, '\n                         'expected 1 or %d dimensions' % (bias_dims, dims))\n\n    if dims == 4:\n        if data_format == 'channels_first':\n            if bias_dims == 1:\n                shape = (bias.shape[0], 1, 1, 1)\n            else:\n                shape = (bias.shape[3],) + bias.shape[:3]\n        elif data_format == 'channels_last':\n            if bias_dims == 1:\n                shape = (1, 1, 1, bias.shape[0])\n            else:\n                shape = bias.shape\n    elif dims == 3:\n        if data_format == 'channels_first':\n            if bias_dims == 1:\n                shape = (bias.shape[0], 1, 1)\n            else:\n                shape = (bias.shape[2],) + bias.shape[:2]\n        elif data_format == 'channels_last':\n            if bias_dims == 1:\n                shape = (1, 1, bias.shape[0])\n            else:\n                shape = bias.shape\n    elif dims == 2:\n        if data_format == 'channels_first':\n            if bias_dims == 1:\n                shape = (bias.shape[0], 1)\n            else:\n                shape = (bias.shape[1],) + bias.shape[:1]\n        elif data_format == 'channels_last':\n            if bias_dims == 1:\n                shape = (1, bias.shape[0])\n            else:\n                shape = bias.shape\n    else:\n        shape = bias.shape\n    return x + reshape(bias, shape)",
                "def eval(x):\n    if isinstance(x, C.cntk_py.Function):\n        return x.eval()\n    elif isinstance(x, C.variables.Constant) or isinstance(x, C.variables.Parameter):\n        return x.value\n    else:\n        raise ValueError('CNTK Backend: `eval` method on '\n                         '`%s` type is not supported. '\n                         'CNTK only supports `eval` with '\n                         '`Function`, `Constant` or '\n                         '`Parameter`.' % type(x))",
                "def placeholder(\n        shape=None,\n        ndim=None,\n        dtype=None,\n        sparse=False,\n        name=None,\n        dynamic_axis_num=1):\n    if dtype is None:\n        dtype = floatx()\n    if not shape:\n        if ndim:\n            shape = tuple([None for _ in range(ndim)])\n\n    dynamic_dimension = C.FreeDimension if _get_cntk_version() >= 2.2 else C.InferredDimension\n    cntk_shape = [dynamic_dimension if s is None else s for s in shape]\n    cntk_shape = tuple(cntk_shape)\n\n    if dynamic_axis_num > len(cntk_shape):\n        raise ValueError('CNTK backend: creating placeholder with '\n                         '%d dimension is not supported, at least '\n                         '%d dimensions are needed.'\n                         % (len(cntk_shape), dynamic_axis_num))\n\n    if name is None:\n        name = ''\n\n    cntk_shape = cntk_shape[dynamic_axis_num:]\n\n    x = C.input(\n        shape=cntk_shape,\n        dtype=_convert_string_dtype(dtype),\n        is_sparse=sparse,\n        name=name)\n    x._keras_shape = shape\n    x._uses_learning_phase = False\n    x._cntk_placeholder = True\n    return x",
                "def is_placeholder(x):\n    \"\"\"Returns whether `x` is a placeholder.\n\n    # Arguments\n        x: A candidate placeholder.\n\n    # Returns\n        Boolean.\n    \"\"\"\n    return hasattr(x, '_cntk_placeholder') and x._cntk_placeholder",
                "def is_keras_tensor(x):\n    if not is_tensor(x):\n        raise ValueError('Unexpectedly found an instance of type `' +\n                         str(type(x)) + '`. '\n                         'Expected a symbolic tensor instance.')\n    return hasattr(x, '_keras_history')",
                "def is_tensor(x):\n    return isinstance(x, (C.variables.Constant,\n                          C.variables.Variable,\n                          C.variables.Parameter,\n                          C.ops.functions.Function))",
                "def shape(x):\n    shape = list(int_shape(x))\n    num_dynamic = _get_dynamic_axis_num(x)\n    non_dyn_shape = []\n    for i in range(len(x.shape)):\n        if shape[i + num_dynamic] is None:\n            non_dyn_shape.append(x.shape[i])\n        else:\n            non_dyn_shape.append(shape[i + num_dynamic])\n    return shape[:num_dynamic] + non_dyn_shape",
                "def is_sparse(tensor):\n    return tensor.is_sparse",
                "def int_shape(x):\n    if hasattr(x, '_keras_shape'):\n        return x._keras_shape\n\n    shape = x.shape\n    if hasattr(x, 'dynamic_axes'):\n        dynamic_shape = [None for a in x.dynamic_axes]\n        shape = tuple(dynamic_shape) + shape\n    return shape",
                "def ndim(x):\n    shape = int_shape(x)\n    return len(shape)",
                "def _prepare_name(name, default):\n    prefix = '_'.join(NAME_SCOPE_STACK)\n    if name is None or name == '':\n        return prefix + '/' + default\n    return prefix + '/' + name",
                "def constant(value, dtype=None, shape=None, name=None):\n    if dtype is None:\n        dtype = floatx()\n    if shape is None:\n        shape = ()\n    np_value = value * np.ones(shape)\n    const = C.constant(np_value,\n                       dtype=dtype,\n                       name=_prepare_name(name, 'constant'))\n    const._keras_shape = const.shape\n    const._uses_learning_phase = False\n    return const",
                "def random_binomial(shape, p=0.0, dtype=None, seed=None):\n    if seed is None:\n        # ensure that randomness is conditioned by the Numpy RNG\n        seed = np.random.randint(10e7)\n    if dtype is None:\n        dtype = np.float32\n    else:\n        dtype = _convert_string_dtype(dtype)\n\n    for _ in shape:\n        if _ is None:\n            raise ValueError('CNTK Backend: randomness op with '\n                             'dynamic shape is not supported now. '\n                             'Please provide fixed dimension '\n                             'instead of `None`.')\n    return C.random.bernoulli(shape=shape, dtype=dtype, mean=p, seed=seed)",
                "def random_uniform(shape, minval=0.0, maxval=1.0, dtype=None, seed=None):\n    for _ in shape:\n        if _ is None:\n            raise ValueError('CNTK Backend: randomness op with '\n                             'dynamic shape is not supported now. '\n                             'Please provide fixed dimension '\n                             'instead of `None`.')\n\n    if seed is None:\n        # ensure that randomness is conditioned by the Numpy RNG\n        seed = np.random.randint(10e3)\n    return C.random.uniform(shape=shape, dtype=dtype, low=minval, high=maxval, seed=seed)",
                "def random_uniform_variable(shape, low, high,\n                            dtype=None, name=None, seed=None):\n    if dtype is None:\n        dtype = floatx()\n    if seed is None:\n        # ensure that randomness is conditioned by the Numpy RNG\n        seed = np.random.randint(10e3)\n\n    if dtype is None:\n        dtype = np.float32\n    else:\n        dtype = _convert_string_dtype(dtype)\n\n    if name is None:\n        name = ''\n\n    scale = (high - low) / 2\n    p = C.parameter(\n        shape,\n        init=C.initializer.uniform(\n            scale,\n            seed=seed),\n        dtype=dtype,\n        name=name)\n    return variable(value=p.value + low + scale)",
                "def random_normal_variable(\n        shape,\n        mean,\n        scale,\n        dtype=None,\n        name=None,\n        seed=None):\n    if dtype is None:\n        dtype = floatx()\n    if seed is None:\n        # ensure that randomness is conditioned by the Numpy RNG\n        seed = np.random.randint(10e7)\n    if dtype is None:\n        dtype = np.float32\n    else:\n        dtype = _convert_string_dtype(dtype)\n\n    if name is None:\n        name = ''\n\n    p = C.parameter(\n        shape=shape,\n        init=C.initializer.normal(\n            scale=scale,\n            seed=seed),\n        dtype=dtype,\n        name=name)\n    return variable(value=p.value + mean)",
                "def random_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n    if dtype is None:\n        dtype = floatx()\n    for _ in shape:\n        if _ is None:\n            raise ValueError('CNTK Backend: randomness op with '\n                             'dynamic shape is not supported now. '\n                             'Please provide fixed dimension '\n                             'instead of `None`.')\n    if seed is None:\n        # ensure that randomness is conditioned by the Numpy RNG\n        seed = np.random.randint(10e3)\n    return C.random.normal(shape=shape, mean=mean, scale=stddev, seed=seed, dtype=dtype)",
                "def truncated_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n    if seed is None:\n        seed = np.random.randint(1, 10e6)\n    if dtype is None:\n        dtype = np.float32\n    else:\n        dtype = _convert_string_dtype(dtype)\n\n    return C.parameter(\n        shape, init=C.initializer.truncated_normal(\n            stddev, seed=seed), dtype=dtype)",
                "def dtype(x):\n    return _convert_dtype_string(x.dtype)",
                "def zeros(shape, dtype=None, name=None):\n    if dtype is None:\n        dtype = floatx()\n    ctype = _convert_string_dtype(dtype)\n    return variable(value=np.zeros(shape, ctype), dtype=dtype, name=name)",
                "def ones(shape, dtype=None, name=None):\n    if dtype is None:\n        dtype = floatx()\n    ctype = _convert_string_dtype(dtype)\n    return variable(value=np.ones(shape, ctype), dtype=dtype, name=name)",
                "def eye(size, dtype=None, name=None):\n    if dtype is None:\n        dtype = floatx()\n    return variable(np.eye(size), dtype, name)",
                "def zeros_like(x, dtype=None, name=None):\n    return x * 0",
                "def ones_like(x, dtype=None, name=None):\n    return zeros_like(x) + 1",
                "def count_params(x):\n    for _ in x.shape:\n        if _ == C.InferredDimension or _ == C.FreeDimension:\n            raise ValueError('CNTK backend: `count_params` with dynamic '\n                             'shape is not supported. Please provide '\n                             'fixed dimension instead of `None`.')\n\n    return np.prod(int_shape(x))",
                "def cast(x, dtype):\n    # cntk calculate everything in float, so don't need case from bool / int\n    return x",
                "def dot(x, y):\n    if len(x.shape) > 2 or len(y.shape) > 2:\n        y_shape = int_shape(y)\n        if len(y_shape) > 2:\n            permutation = [len(y_shape) - 2]\n            permutation += list(range(len(y_shape) - 2))\n            permutation += [len(y_shape) - 1]\n            y = C.transpose(y, perm=permutation)\n        return C.times(x, y, len(y_shape) - 1)\n    else:\n        return C.times(x, y)",
                "def batch_dot(x, y, axes=None):\n    x_shape = int_shape(x)\n    y_shape = int_shape(y)\n\n    if isinstance(axes, int):\n        axes = (axes, axes)\n    if axes is None:\n        # behaves like tf.batch_matmul as default\n        axes = [len(x_shape) - 1, len(y_shape) - 2]\n    if b_any([isinstance(a, (list, tuple)) for a in axes]):\n        raise ValueError('Multiple target dimensions are not supported. ' +\n                         'Expected: None, int, (int, int), ' +\n                         'Provided: ' + str(axes))\n\n    if len(x_shape) == 2 and len(y_shape) == 2:\n        if axes[0] == axes[1]:\n            result = sum(x * y, axis=axes[0], keepdims=True)\n            return result if axes[0] == 1 else transpose(result)\n        else:\n            return sum(x * transpose(y), axis=axes[0], keepdims=True)\n    else:\n        if len(y_shape) == 2:\n            y = expand_dims(y)\n\n        normalized_axis = []\n        normalized_axis.append(_normalize_axis(axes[0], x)[0])\n        normalized_axis.append(_normalize_axis(axes[1], y)[0])\n        # transpose\n        i = normalized_axis[0]\n        while i < len(x.shape) - 1:\n            x = C.swapaxes(x, i, i + 1)\n            i += 1\n        i = normalized_axis[1]\n        while i > 0:\n            y = C.swapaxes(y, i, i - 1)\n            i -= 1\n        result = C.times(x, y, output_rank=(len(y.shape) - 1)\n                         if len(y.shape) > 1 else 1)\n        if len(y_shape) == 2:\n            result = squeeze(result, -1)\n        return result",
                "def transpose(x):\n    return C.swapaxes(x, 0, 1)",
                "def gather(reference, indices):\n    # There is a bug in cntk gather op which may cause crash.\n    # We have made a fix but not catched in CNTK 2.1 release.\n    # Will update with gather op in next release\n    if _get_cntk_version() >= 2.2:\n        return C.ops.gather(reference, indices)\n    else:\n        num_classes = reference.shape[0]\n        one_hot_matrix = C.ops.one_hot(indices, num_classes)\n        return C.times(one_hot_matrix, reference, output_rank=len(reference.shape) - 1)",
                "def _remove_dims(x, axis, keepdims=False):\n    if keepdims is False and isinstance(axis, list):\n        # sequence axis is removed by default, so don't need reshape on it\n        reduce_axes = []\n        for a in axis:\n            if isinstance(a, C.Axis) is False:\n                reduce_axes.append(a)\n        return _reshape_dummy_dim(x, reduce_axes)\n    else:\n        if isinstance(axis, list):\n            has_seq = False\n            for a in axis:\n                if isinstance(a, C.Axis):\n                    has_seq = True\n                    break\n            if has_seq:\n                nones = _get_dynamic_axis_num(x)\n                x = expand_dims(x, nones)\n        return x",
                "def max(x, axis=None, keepdims=False):\n    axis = _normalize_axis(axis, x)\n    output = _reduce_on_axis(x, axis, 'reduce_max')\n\n    return _remove_dims(output, axis, keepdims)",
                "def min(x, axis=None, keepdims=False):\n    axis = _normalize_axis(axis, x)\n    output = _reduce_on_axis(x, axis, 'reduce_min')\n\n    return _remove_dims(output, axis, keepdims)",
                "def sum(x, axis=None, keepdims=False):\n    axis = _normalize_axis(axis, x)\n    output = _reduce_on_axis(x, axis, 'reduce_sum')\n\n    return _remove_dims(output, axis, keepdims)",
                "def prod(x, axis=None, keepdims=False):\n    axis = _normalize_axis(axis, x)\n    output = _reduce_on_axis(x, axis, 'reduce_prod')\n\n    return _remove_dims(output, axis, keepdims)",
                "def logsumexp(x, axis=None, keepdims=False):\n    return log(sum(exp(x), axis=axis, keepdims=keepdims))",
                "def var(x, axis=None, keepdims=False):\n    m = mean(x, axis, keepdims=True)\n    devs_squared = C.square(x - m)\n    return mean(devs_squared, axis=axis, keepdims=keepdims)",
                "def std(x, axis=None, keepdims=False):\n    return C.sqrt(var(x, axis=axis, keepdims=keepdims))",
                "def expand_dims(x, axis=-1):\n    shape = list(int_shape(x))\n    nones = _get_dynamic_axis_num(x)\n    index = axis if axis >= 0 else len(shape) + 1\n    shape.insert(index, 1)\n    new_shape = shape[nones:]\n    new_shape = tuple(\n        [C.InferredDimension if _ is None else _ for _ in new_shape])\n    result = C.reshape(x, new_shape)\n    if index < nones:\n        result._keras_shape = shape\n    return result",
                "def squeeze(x, axis):\n    if isinstance(axis, tuple):\n        axis = list(axis)\n    if not isinstance(axis, list):\n        axis = [axis]\n\n    shape = list(int_shape(x))\n\n    _axis = []\n    for _ in axis:\n        if isinstance(_, int):\n            _axis.append(_ if _ >= 0 else _ + len(shape))\n\n    if len(_axis) == 0:\n        return x\n\n    nones = _get_dynamic_axis_num(x)\n    for _ in sorted(_axis, reverse=True):\n        del shape[_]\n\n    new_shape = shape[nones:]\n    new_shape = tuple([C.InferredDimension if _ == C.FreeDimension else _ for _ in new_shape])\n    return C.reshape(x, new_shape)",
                "def tile(x, n):\n    if isinstance(n, int):\n        n = (n,)\n    elif isinstance(n, list):\n        n = tuple(n)\n\n    shape = int_shape(x)\n    num_dynamic_axis = _get_dynamic_axis_num(x)\n    # Padding the axis\n    if len(n) < len(shape):\n        n = tuple([1 for _ in range(len(shape) - len(n))]) + n\n\n    if len(n) != len(shape):\n        raise NotImplementedError\n\n    i = num_dynamic_axis\n    for i, rep in enumerate(n):\n        if i >= num_dynamic_axis and shape[i] is not None:\n            tmp = [x] * rep\n            x = C.splice(*tmp, axis=i - num_dynamic_axis)\n        i += 1\n\n    return x",
                "def _normalize_axis(axis, x):\n    shape = int_shape(x)\n    ndim = len(shape)\n\n    nones = _get_dynamic_axis_num(x)\n\n    if nones > ndim:\n        raise ValueError('CNTK Backend: tensor with keras shape: `%s` has '\n                         '%d cntk dynamic axis, this is not expected, please '\n                         'double check the keras shape history.' % (str(shape), nones))\n\n    # Current cntk does not support shape like (1, batch). so using the workaround\n    # here to mapping the correct axis. Will remove this tricky after we add support\n    # in native cntk op\n    cntk_axis = []\n    dynamic_axis_index = 0\n    for i in range(ndim):\n        if shape[i] is None and dynamic_axis_index < nones:\n            cntk_axis.append(x.dynamic_axes[dynamic_axis_index])\n            dynamic_axis_index += 1\n        else:\n            cntk_axis.append(i - dynamic_axis_index)\n\n    if dynamic_axis_index < nones:\n        i = 0\n        while dynamic_axis_index < nones:\n            cntk_axis[i] = x.dynamic_axes[dynamic_axis_index]\n            i += 1\n            dynamic_axis_index += 1\n\n        while i < len(cntk_axis):\n            cntk_axis[i] -= nones\n            i += 1\n\n    if isinstance(axis, tuple):\n        _axis = list(axis)\n    elif isinstance(axis, int):\n        _axis = [axis]\n    elif isinstance(axis, list):\n        _axis = list(axis)\n    else:\n        _axis = axis\n\n    if isinstance(_axis, list):\n        for i, a in enumerate(_axis):\n            if a is not None and a < 0:\n                _axis[i] = (a % ndim)\n            if _axis[i] is not None:\n                _axis[i] = cntk_axis[_axis[i]]\n    else:\n        if _axis is None:\n            _axis = C.Axis.all_axes()\n\n    return _axis",
                "def _reshape_dummy_dim(x, axis):\n    shape = list(x.shape)\n\n    _axis = [_ + len(shape) if _ < 0 else _ for _ in axis]\n\n    if shape.count(C.InferredDimension) > 1 or shape.count(C.FreeDimension) > 1:\n        result = x\n        for index in sorted(_axis, reverse=True):\n            result = C.reshape(result,\n                               shape=(),\n                               begin_axis=index,\n                               end_axis=index + 1)\n        return result\n    else:\n        for index in sorted(_axis, reverse=True):\n            del shape[index]\n\n        shape = [C.InferredDimension if _ == C.FreeDimension else _ for _ in shape]\n        return C.reshape(x, shape)",
                "def mean(x, axis=None, keepdims=False):\n    axis = _normalize_axis(axis, x)\n    output = _reduce_on_axis(x, axis, 'reduce_mean')\n\n    return _remove_dims(output, axis, keepdims)",
                "def any(x, axis=None, keepdims=False):\n    reduce_result = sum(x, axis, keepdims=keepdims)\n    any_matrix = C.element_select(\n        reduce_result,\n        ones_like(reduce_result),\n        zeros_like(reduce_result))\n    if len(reduce_result.shape) == 0 and _get_dynamic_axis_num(x) == 0:\n        return C.reduce_sum(any_matrix)\n    else:\n        return any_matrix",
                "def all(x, axis=None, keepdims=False):\n    reduce_result = prod(x, axis, keepdims=keepdims)\n    all_matrix = C.element_select(\n        reduce_result,\n        ones_like(reduce_result),\n        zeros_like(reduce_result))\n    if len(reduce_result.shape) == 0 and _get_dynamic_axis_num(x) == 0:\n        return C.reduce_sum(all_matrix)\n    else:\n        return all_matrix",
                "def classification_error(target, output, axis=-1):\n    return C.ops.reduce_mean(\n        C.equal(\n            argmax(\n                output,\n                axis=-1),\n            argmax(\n                target,\n                axis=-1)),\n        axis=C.Axis.all_axes())",
                "def argmax(x, axis=-1):\n    axis = [axis]\n    axis = _normalize_axis(axis, x)\n    output = C.ops.argmax(x, axis=axis[0])\n    return _reshape_dummy_dim(output, axis)",
                "def argmin(x, axis=-1):\n    axis = [axis]\n    axis = _normalize_axis(axis, x)\n    output = C.ops.argmin(x, axis=axis[0])\n    return _reshape_dummy_dim(output, axis)",
                "def square(x):\n    return C.square(x)",
                "def abs(x):\n    return C.abs(x)",
                "def sqrt(x):\n    return C.sqrt(x)",
                "def exp(x):\n    return C.exp(x)",
                "def log(x):\n    return C.log(x)",
                "def round(x):\n    return C.round(x)",
                "def sigmoid(x):\n    return C.sigmoid(x)",
                "def sign(x):\n    return x / C.abs(x)",
                "def pow(x, a):\n    return C.pow(x, a)",
                "def clip(x, min_value, max_value):\n    if max_value is not None and max_value < min_value:\n        max_value = min_value\n    if max_value is None:\n        max_value = np.inf\n    if min_value is None:\n        min_value = -np.inf\n    return C.clip(x, min_value, max_value)",
                "def binary_crossentropy(target, output, from_logits=False):\n    if from_logits:\n        output = C.sigmoid(output)\n    output = C.clip(output, epsilon(), 1.0 - epsilon())\n    output = -target * C.log(output) - (1.0 - target) * C.log(1.0 - output)\n    return output",
                "def get_variable_shape(x):\n    return int_shape(x)",
                "def update(x, new_x):\n    return C.assign(x, new_x)",
                "def moving_average_update(variable, value, momentum):\n    return C.assign(variable, variable * momentum + value * (1. - momentum))",
                "def update_add(x, increment):\n    result = x + increment\n    return C.assign(x, result)",
                "def gradients(loss, variables):\n    # cntk does not support gradients as symbolic op,\n    # to hook up with keras model\n    # we will return a constant as place holder, the cntk learner will apply\n    # the gradient during training.\n    global grad_parameter_dict\n    if isinstance(variables, list) is False:\n        variables = [variables]\n    grads = []\n    for v in variables:\n        g = C.constant(0, shape=v.shape, name='keras_grad_placeholder')\n        grads.append(g)\n        grad_parameter_dict[g] = v\n    return grads",
                "def equal(x, y):\n    return C.equal(x, y)",
                "def not_equal(x, y):\n    return C.not_equal(x, y)",
                "def greater(x, y):\n    return C.greater(x, y)",
                "def greater_equal(x, y):\n    return C.greater_equal(x, y)",
                "def less(x, y):\n    return C.less(x, y)",
                "def less_equal(x, y):\n    return C.less_equal(x, y)",
                "def maximum(x, y):\n    return C.element_max(x, y)",
                "def minimum(x, y):\n    return C.element_min(x, y)",
                "def sin(x):\n    return C.sin(x)",
                "def cos(x):\n    return C.cos(x)",
                "def normalize_batch_in_training(x, gamma, beta,\n                                reduction_axes, epsilon=1e-3):\n    if gamma is None:\n        if beta is None:\n            gamma = ones_like(x)\n        else:\n            gamma = ones_like(beta)\n    if beta is None:\n        if gamma is None:\n            beta = zeros_like(x)\n        else:\n            beta = zeros_like(gamma)\n\n    mean, variant = _moments(x, _normalize_axis(reduction_axes, x))\n\n    if sorted(reduction_axes) == list(range(ndim(x)))[:-1]:\n        normalized = batch_normalization(\n            x, mean, variant, beta, gamma, epsilon)\n    else:\n        # need broadcasting\n        target_shape = []\n        x_shape = int_shape(x)\n        # skip the batch axis\n        for axis in range(1, ndim(x)):\n            if axis in reduction_axes:\n                target_shape.append(1)\n                if ndim(gamma) > axis:\n                    gamma = C.reduce_mean(gamma, axis - 1)\n                    beta = C.reduce_mean(beta, axis - 1)\n            else:\n                target_shape.append(x_shape[axis])\n\n        broadcast_mean = C.reshape(mean, target_shape)\n        broadcast_var = C.reshape(variant, target_shape)\n        broadcast_gamma = C.reshape(gamma, target_shape)\n        broadcast_beta = C.reshape(beta, target_shape)\n        normalized = batch_normalization(\n            x,\n            broadcast_mean,\n            broadcast_var,\n            broadcast_beta,\n            broadcast_gamma,\n            epsilon)\n\n    return normalized, mean, variant",
                "def _moments(x, axes=None, shift=None, keep_dims=False):\n    _axes = tuple(axes)\n    if shift is None:\n        shift = x\n        # Compute true mean while keeping the dims for proper broadcasting.\n        for axis in _axes:\n            shift = C.reduce_mean(shift, axis=axis)\n\n    shift = C.stop_gradient(shift)\n    shifted_mean = C.minus(x, shift)\n    for axis in _axes:\n        shifted_mean = C.reduce_mean(shifted_mean, axis=axis)\n\n    variance_mean = C.square(C.minus(x, shift))\n    for axis in _axes:\n        variance_mean = C.reduce_mean(variance_mean, axis=axis)\n\n    variance = C.minus(variance_mean, C.square(shifted_mean))\n    mean = C.plus(shifted_mean, shift)\n\n    if not keep_dims:\n        mean = squeeze(mean, _axes)\n        variance = squeeze(variance, _axes)\n\n    return mean, variance",
                "def batch_normalization(x, mean, var, beta, gamma, axis=-1, epsilon=1e-3):\n    # The mean / var / beta / gamma may be processed by broadcast\n    # so it may have an extra batch axis with 1, it is not needed\n    # in cntk, need to remove those dummy axis.\n    if ndim(mean) == ndim(x) and shape(mean)[0] == 1:\n        mean = _reshape_dummy_dim(mean, [0])\n    if ndim(var) == ndim(x) and shape(var)[0] == 1:\n        var = _reshape_dummy_dim(var, [0])\n\n    if gamma is None:\n        gamma = ones_like(var)\n    elif ndim(gamma) == ndim(x) and shape(gamma)[0] == 1:\n        gamma = _reshape_dummy_dim(gamma, [0])\n\n    if beta is None:\n        beta = zeros_like(mean)\n    elif ndim(beta) == ndim(x) and shape(beta)[0] == 1:\n        beta = _reshape_dummy_dim(beta, [0])\n\n    return (x - mean) / C.sqrt(var + epsilon) * gamma + beta",
                "def concatenate(tensors, axis=-1):\n    if len(tensors) == 0:\n        return None\n\n    axis = [axis]\n    axis = _normalize_axis(axis, tensors[0])\n    return C.splice(*tensors, axis=axis[0])",
                "def flatten(x):\n    return reshape(x, (-1,))",
                "def reshape(x, shape):\n    shape = tuple([C.InferredDimension if _ == C.FreeDimension else _ for _ in shape])\n    if isinstance(x, C.variables.Parameter):\n        return C.reshape(x, shape)\n    else:\n        num_dynamic_axis = _get_dynamic_axis_num(x)\n\n        if num_dynamic_axis == 1 and len(shape) > 0 and shape[0] == -1:\n            # collapse axis with batch axis\n            if b_any(_ == C.InferredDimension for _ in x.shape) or b_any(\n                    _ == C.FreeDimension for _ in x.shape):\n                warnings.warn(\n                    'Warning: CNTK backend does not support '\n                    'collapse of batch axis with inferred dimension. '\n                    'The reshape did not take place.')\n                return x\n            return _reshape_batch(x, shape)\n        else:\n            # no collapse, then first need to padding the shape\n            if num_dynamic_axis >= len(shape):\n                i = 0\n                while i < len(shape):\n                    if shape[i] is None or shape[i] == -1:\n                        i += 1\n                    else:\n                        break\n                shape = tuple([-1 for _ in range(num_dynamic_axis - i)]) + shape\n\n            new_shape = list(shape)\n            new_shape = new_shape[num_dynamic_axis:]\n            new_shape = [C.InferredDimension if _ is None else _ for _ in new_shape]\n            return C.reshape(x, new_shape)",
                "def permute_dimensions(x, pattern):\n    dims = len(int_shape(x))\n    num_dynamic_axis = _get_dynamic_axis_num(x)\n    if isinstance(pattern, list):\n        current_layout = [i for i in range(dims)]\n    else:\n        current_layout = tuple([i for i in range(dims)])\n\n    if num_dynamic_axis > 0 and pattern[:num_dynamic_axis] != current_layout[:num_dynamic_axis]:\n        raise ValueError('CNTK backend: the permute pattern %s '\n                         'requested permute on dynamic axis, '\n                         'which is not supported. Please do permute '\n                         'on static axis.' % pattern)\n\n    axis = list(pattern)\n    axis = axis[num_dynamic_axis:]\n    axis = _normalize_axis(axis, x)\n    return C.transpose(x, axis)",
                "def resize_images(x, height_factor, width_factor, data_format, interpolation='nearest'):\n    if interpolation == 'nearest':\n        if data_format == 'channels_first':\n            output = repeat_elements(x, height_factor, axis=2)\n            output = repeat_elements(output, width_factor, axis=3)\n            return output\n        elif data_format == 'channels_last':\n            output = repeat_elements(x, height_factor, axis=1)\n            output = repeat_elements(output, width_factor, axis=2)\n            return output\n        else:\n            raise ValueError('CNTK Backend: Invalid data_format: %s' % data_format)\n    else:\n        raise NotImplementedError('CNTK only supports `nearest` interpolation.')",
                "def resize_volumes(x, depth_factor, height_factor, width_factor, data_format):\n    if data_format == 'channels_first':\n        output = repeat_elements(x, depth_factor, axis=2)\n        output = repeat_elements(output, height_factor, axis=3)\n        output = repeat_elements(output, width_factor, axis=4)\n        return output\n    elif data_format == 'channels_last':\n        output = repeat_elements(x, depth_factor, axis=1)\n        output = repeat_elements(output, height_factor, axis=2)\n        output = repeat_elements(output, width_factor, axis=3)\n        return output\n    else:\n        raise ValueError('CNTK Backend: Invalid data_format: %s' % data_format)",
                "def repeat_elements(x, rep, axis):\n    axis = _normalize_axis(axis, x)\n    axis = axis[0]\n    slices = []\n    shape = x.shape\n    i = 0\n    while i < shape[axis]:\n        tmp = C.ops.slice(x, axis, i, i + 1)\n        for _ in range(rep):\n            slices.append(tmp)\n        i += 1\n    return C.splice(*slices, axis=axis)",
                "def repeat(x, n):\n    # this is a workaround for recurrent layer\n    # if n is inferred dimension,\n    # we can't figure out how to repeat it in cntk now\n    # return the same x to take cntk broadcast feature\n    # to make the recurrent layer work.\n    # need to be fixed in GA.\n    if n is C.InferredDimension or n is C.FreeDimension:\n        return x\n    index = 1 - _get_dynamic_axis_num(x)\n    if index < 0 or index > 1:\n        raise NotImplementedError\n\n    new_shape = list(x.shape)\n    new_shape.insert(index, 1)\n    new_shape = tuple(new_shape)\n    x = C.reshape(x, new_shape)\n    temp = [x] * n\n    return C.splice(*temp, axis=index)",
                "def tanh(x):\n    return C.tanh(x)",
                "def _static_rnn(step_function, inputs, initial_states,\n                go_backwards=False, mask=None, constants=None,\n                unroll=False, input_length=None):\n\n    shape = int_shape(inputs)\n    dims = len(shape)\n\n    uses_learning_phase = False\n\n    if dims < 3:\n        raise ValueError('Input should be at least 3D.')\n\n    # if the second axis is static axis, CNTK will do unroll by default\n    if shape[1] is None:\n        raise ValueError('CNTK Backend: the input of static rnn '\n                         'has shape `%s`, the second axis '\n                         'is not static. If you want to run '\n                         'rnn with non-static axis, please try '\n                         'dynamic rnn with sequence axis.' % shape)\n    if constants is None:\n        constants = []\n\n    if mask is not None:\n        mask_shape = int_shape(mask)\n        if len(mask_shape) == dims - 1:\n            mask = expand_dims(mask)\n\n    nones = _get_dynamic_axis_num(inputs)\n\n    states = tuple(initial_states)\n\n    outputs = []\n\n    time_axis = 1 - nones if nones > 0 else 1\n\n    if go_backwards:\n        i = shape[1] - 1\n        while i >= 0:\n            current = C.ops.slice(inputs, time_axis, i, i + 1)\n            # remove dummy dimension\n            current = squeeze(current, time_axis)\n\n            output, new_states = step_function(\n                current, tuple(states) + tuple(constants))\n            if getattr(output, '_uses_learning_phase', False):\n                uses_learning_phase = True\n\n            if mask is not None:\n                mask_slice = C.ops.slice(mask, time_axis, i, i + 1)\n                mask_slice = squeeze(mask_slice, time_axis)\n                if len(outputs) == 0:\n                    prev_output = zeros_like(output)\n                else:\n                    prev_output = outputs[-1]\n                output = C.ops.element_select(mask_slice, output, prev_output)\n\n                return_states = []\n                for s, n_s in zip(states, new_states):\n                    return_states.append(\n                        C.ops.element_select(\n                            mask_slice, n_s, s))\n                new_states = return_states\n            outputs.append(output)\n            states = new_states\n            i -= 1\n    else:\n        i = 0\n        while i < shape[1]:\n            current = C.ops.slice(inputs, time_axis, i, i + 1)\n            # remove dummy dimension\n            current = squeeze(current, 1)\n\n            output, new_states = step_function(\n                current, tuple(states) + tuple(constants))\n            if getattr(output, '_uses_learning_phase', False):\n                uses_learning_phase = True\n\n            if mask is not None:\n                mask_slice = C.ops.slice(mask, time_axis, i, i + 1)\n                mask_slice = squeeze(mask_slice, 1)\n                if len(outputs) == 0:\n                    prev_output = zeros_like(output)\n                else:\n                    prev_output = outputs[-1]\n                output = C.ops.element_select(mask_slice, output, prev_output)\n\n                return_states = []\n                for s, n_s in zip(states, new_states):\n                    return_states.append(\n                        C.ops.element_select(\n                            mask_slice, n_s, s))\n                new_states = return_states\n            outputs.append(output)\n            states = new_states[:len(states)]\n            i += 1\n\n    i = 1\n    # add the time_step axis back\n    final_output = expand_dims(outputs[0], 1)\n    last_output = outputs[0]\n    while i < len(outputs):\n        # add the time_step axis back\n        output_slice = expand_dims(outputs[i], 1)\n        final_output = C.splice(final_output, output_slice, axis=time_axis)\n        last_output = outputs[i]\n        i += 1\n\n    last_output._uses_learning_phase = uses_learning_phase\n    return last_output, final_output, states",
                "def rnn(step_function, inputs, initial_states,\n        go_backwards=False, mask=None, constants=None,\n        unroll=False, input_length=None):\n\n    shape = int_shape(inputs)\n    dims = len(shape)\n\n    global uses_learning_phase\n    uses_learning_phase = False\n\n    if dims < 3:\n        raise ValueError('CNTK Backend: the input of rnn has only rank %d '\n                         'Need at least rank 3 to run RNN.' % dims)\n\n    if _get_dynamic_axis_num(inputs) == 0 or unroll:\n        return _static_rnn(\n            step_function,\n            inputs,\n            initial_states,\n            go_backwards,\n            mask,\n            constants,\n            unroll,\n            input_length)\n\n    if constants is None:\n        constants = []\n\n    num_time_step = shape[1]\n    if num_time_step is None and not has_seq_axis(inputs):\n        num_time_step = inputs.shape[0]\n\n    initial = []\n    for s in initial_states:\n        if _get_dynamic_axis_num(s) == 0:\n            if hasattr(C, 'to_batch'):\n                initial.append(C.to_batch(s))\n            else:\n                initial.append(C.user_function(ConvertToBatch(s)))\n        else:\n            initial.append(s)\n\n    need_convert = not has_seq_axis(inputs)\n    if go_backwards and need_convert is False:\n        raise NotImplementedError('CNTK Backend: `go_backwards` is not supported with '\n                                  'variable-length sequences. Please specify a '\n                                  'static length for your sequences.')\n\n    rnn_inputs = inputs\n    if need_convert:\n        if go_backwards:\n            rnn_inputs = reverse(rnn_inputs, 1)\n\n        rnn_inputs = C.to_sequence(rnn_inputs)\n\n        rnn_constants = []\n        for constant in constants:\n            if isinstance(constant, list):\n                new_c = []\n                for c in constant:\n                    if _get_dynamic_axis_num(c) == 1:\n                        new_c.append(C.sequence.broadcast_as(c, rnn_inputs))\n                    else:\n                        new_c.append(c)\n                rnn_constants.append(new_c)\n            else:\n                if _get_dynamic_axis_num(constant) == 1:\n                    rnn_constants.append(C.sequence.broadcast_as(constant, rnn_inputs))\n                else:\n                    rnn_constants.append(constant)\n    else:\n        rnn_constants = constants\n\n    if mask is not None and not has_seq_axis(mask):\n        if go_backwards:\n            mask = reverse(mask, 1)\n        if len(int_shape(mask)) == 2:\n            mask = expand_dims(mask)\n        mask = C.to_sequence_like(mask, rnn_inputs)\n\n    states = tuple(initial)\n\n    with C.default_options(axis_offset=1):\n        def _recurrence(x, states, m):\n            # create place holder\n            place_holders = [C.placeholder(dynamic_axes=x.dynamic_axes) for _ in states]\n            past_values = []\n            for s, p in zip(states, place_holders):\n                past_values.append(C.sequence.past_value(p, s))\n            new_output, new_states = step_function(\n                x, tuple(past_values) + tuple(rnn_constants))\n\n            if getattr(new_output, '_uses_learning_phase', False):\n                global uses_learning_phase\n                uses_learning_phase = True\n\n            if m is not None:\n                new_states = [C.element_select(m, n, s) for n, s in zip(new_states, past_values)]\n            n_s = []\n            for o, p in zip(new_states, place_holders):\n                n_s.append(o.replace_placeholders({p: o.output}))\n            if len(n_s) > 0:\n                new_output = n_s[0]\n            return new_output, n_s\n\n        final_output, final_states = _recurrence(rnn_inputs, states, mask)\n        last_output = C.sequence.last(final_output)\n        last_states = [C.sequence.last(s) for s in final_states]\n\n    if need_convert:\n        final_output = C.sequence.unpack(final_output, 0, no_mask_output=True)\n        if num_time_step is not None and num_time_step is not C.FreeDimension:\n            final_output = _reshape_sequence(final_output, num_time_step)\n\n    f_stats = []\n    for l_s, i_s in zip(last_states, initial_states):\n        if _get_dynamic_axis_num(i_s) == 0 and _get_dynamic_axis_num(l_s) == 1:\n            if hasattr(C, 'unpack_batch'):\n                f_stats.append(C.unpack_batch(l_s))\n            else:\n                f_stats.append(C.user_function(ConvertToStatic(l_s, batch_size=i_s.shape[0])))\n        else:\n            f_stats.append(l_s)\n\n    last_output._uses_learning_phase = uses_learning_phase\n    return last_output, final_output, f_stats",
                "def has_seq_axis(x):\n    return hasattr(x, 'dynamic_axes') and len(x.dynamic_axes) > 1",
                "def l2_normalize(x, axis=None):\n    axis = [axis]\n    axis = _normalize_axis(axis, x)\n    norm = C.sqrt(C.reduce_sum(C.square(x), axis=axis[0]))\n    return x / norm",
                "def hard_sigmoid(x):\n    x = (0.2 * x) + 0.5\n    x = C.clip(x, 0.0, 1.0)\n    return x",
                "def conv1d(x, kernel, strides=1, padding='valid',\n           data_format=None, dilation_rate=1):\n    data_format = normalize_data_format(data_format)\n\n    if padding == 'causal':\n        # causal (dilated) convolution:\n        left_pad = dilation_rate * (kernel.shape[0] - 1)\n        x = temporal_padding(x, (left_pad, 0))\n        padding = 'valid'\n\n    if data_format == 'channels_last':\n        x = C.swapaxes(x, 0, 1)\n        kernel = C.swapaxes(kernel, 0, 2)\n\n    padding = _preprocess_border_mode(padding)\n\n    if dev.type() == 0 and dilation_rate != 1:\n        raise ValueError('Dilated convolution on CPU is not supported by CNTK backend. '\n                         'Please set `dilation_rate` to 1. You passed: %s' % (dilation_rate,))\n\n    x = C.convolution(\n        kernel,\n        x,\n        strides=strides,\n        auto_padding=[False, padding],\n        dilation=dilation_rate)\n\n    if data_format == 'channels_last':\n        x = C.swapaxes(x, 0, 1)\n    return x",
                "def conv2d(x, kernel, strides=(1, 1), padding='valid',\n           data_format=None, dilation_rate=(1, 1)):\n    data_format = normalize_data_format(data_format)\n\n    x = _preprocess_conv2d_input(x, data_format)\n    kernel = _preprocess_conv2d_kernel(kernel, data_format)\n    padding = _preprocess_border_mode(padding)\n\n    if dev.type() == 0 and dilation_rate != (1, 1):\n        raise ValueError('Dilated convolution on CPU is not supported by CNTK backend. '\n                         'Please set `dilation_rate` to (1, 1). '\n                         'You passed: %s' % (dilation_rate,))\n\n    x = C.convolution(kernel,\n                      x,\n                      strides,\n                      auto_padding=[False, padding, padding],\n                      dilation=dilation_rate)\n\n    return _postprocess_conv2d_output(x, data_format)",
                "def separable_conv1d(x, depthwise_kernel, pointwise_kernel, strides=1,\n                     padding='valid', data_format=None, dilation_rate=1):\n    data_format = normalize_data_format(data_format)\n    if isinstance(strides, int):\n        strides = (strides,)\n    if isinstance(dilation_rate, int):\n        dilation_rate = (dilation_rate,)\n\n    if data_format == 'channels_last':\n        spatial_start_dim = 2\n    else:\n        spatial_start_dim = 3\n    x = expand_dims(x, spatial_start_dim)\n    depthwise_kernel = expand_dims(depthwise_kernel, 1)\n    pointwise_kernel = expand_dims(pointwise_kernel, 1)\n    strides = (1,) + strides + (1,)\n    dilation_rate = (1,) + dilation_rate\n\n    x = _preprocess_conv2d_input(x, data_format)\n    depthwise_kernel = _preprocess_conv2d_kernel(depthwise_kernel, data_format)\n    depthwise_kernel = C.reshape(C.transpose(depthwise_kernel, (1, 0, 2, 3)),\n                                 (-1, 1) + depthwise_kernel.shape[2:])\n    pointwise_kernel = _preprocess_conv2d_kernel(pointwise_kernel, data_format)\n    padding = _preprocess_border_mode(padding)\n\n    if dilation_rate == (1, 1):\n        x = C.convolution(depthwise_kernel, x,\n                          strides=strides,\n                          auto_padding=[False, padding, padding],\n                          groups=x.shape[0])\n        x = C.convolution(pointwise_kernel, x,\n                          strides=(1, 1, 1),\n                          auto_padding=[False])\n    else:\n        if dilation_rate[0] != dilation_rate[1]:\n            raise ValueError('CNTK Backend: non-square dilation_rate is '\n                             'not supported.')\n        if strides != (1, 1):\n            raise ValueError('Invalid strides for dilated convolution')\n        x = C.convolution(depthwise_kernel, x,\n                          strides=strides,\n                          auto_padding=[False, padding, padding],\n                          groups=x.shape[0])\n        x = C.convolution(pointwise_kernel, x,\n                          strides=(1, 1, 1),\n                          auto_padding=[False])\n    x = _postprocess_conv2d_output(x, data_format)\n    return squeeze(x, spatial_start_dim)",
                "def separable_conv2d(x, depthwise_kernel, pointwise_kernel, strides=(1, 1),\n                     padding='valid', data_format=None, dilation_rate=(1, 1)):\n    data_format = normalize_data_format(data_format)\n\n    x = _preprocess_conv2d_input(x, data_format)\n    depthwise_kernel = _preprocess_conv2d_kernel(depthwise_kernel, data_format)\n    depthwise_kernel = C.reshape(C.transpose(depthwise_kernel, (1, 0, 2, 3)),\n                                 (-1, 1) + depthwise_kernel.shape[2:])\n    pointwise_kernel = _preprocess_conv2d_kernel(pointwise_kernel, data_format)\n    padding = _preprocess_border_mode(padding)\n\n    if dilation_rate == (1, 1):\n        strides = (1,) + strides\n        x = C.convolution(depthwise_kernel, x,\n                          strides=strides,\n                          auto_padding=[False, padding, padding],\n                          groups=x.shape[0])\n        x = C.convolution(pointwise_kernel, x,\n                          strides=(1, 1, 1),\n                          auto_padding=[False])\n    else:\n        if dilation_rate[0] != dilation_rate[1]:\n            raise ValueError('CNTK Backend: non-square dilation_rate is '\n                             'not supported.')\n        if strides != (1, 1):\n            raise ValueError('Invalid strides for dilated convolution')\n        x = C.convolution(depthwise_kernel, x,\n                          strides=dilation_rate[0],\n                          auto_padding=[False, padding, padding])\n        x = C.convolution(pointwise_kernel, x,\n                          strides=(1, 1, 1),\n                          auto_padding=[False])\n    return _postprocess_conv2d_output(x, data_format)",
                "def depthwise_conv2d(x, depthwise_kernel, strides=(1, 1), padding='valid',\n                     data_format=None, dilation_rate=(1, 1)):\n    data_format = normalize_data_format(data_format)\n\n    x = _preprocess_conv2d_input(x, data_format)\n    depthwise_kernel = _preprocess_conv2d_kernel(depthwise_kernel, data_format)\n    depthwise_kernel = C.reshape(C.transpose(depthwise_kernel, (1, 0, 2, 3)),\n                                 (-1, 1) + depthwise_kernel.shape[2:])\n    padding = _preprocess_border_mode(padding)\n    if dilation_rate == (1, 1):\n        strides = (1,) + strides\n        x = C.convolution(depthwise_kernel, x,\n                          strides=strides,\n                          auto_padding=[False, padding, padding],\n                          groups=x.shape[0])\n    else:\n        if dilation_rate[0] != dilation_rate[1]:\n            raise ValueError('CNTK Backend: non-square dilation_rate is '\n                             'not supported.')\n        if strides != (1, 1):\n            raise ValueError('Invalid strides for dilated convolution')\n        x = C.convolution(depthwise_kernel, x,\n                          strides=dilation_rate[0],\n                          auto_padding=[False, padding, padding],\n                          groups=x.shape[0])\n    return _postprocess_conv2d_output(x, data_format)",
                "def conv3d(x, kernel, strides=(1, 1, 1), padding='valid',\n           data_format=None, dilation_rate=(1, 1, 1)):\n    data_format = normalize_data_format(data_format)\n\n    x = _preprocess_conv3d_input(x, data_format)\n    kernel = _preprocess_conv3d_kernel(kernel, data_format)\n    padding = _preprocess_border_mode(padding)\n\n    if dev.type() == 0 and dilation_rate != (1, 1, 1):\n        raise ValueError('Dilated convolution on CPU is not supported by CNTK backend. '\n                         'Please set `dilation_rate` to (1, 1, 1). '\n                         'You passed: %s' % (dilation_rate,))\n\n    x = C.convolution(\n        kernel,\n        x,\n        strides,\n        auto_padding=[False, padding, padding, padding],\n        dilation=dilation_rate)\n\n    return _postprocess_conv3d_output(x, data_format)",
                "def conv3d_transpose(x, kernel, output_shape, strides=(1, 1, 1),\n                     padding='valid', data_format=None):\n    data_format = normalize_data_format(data_format)\n\n    x = _preprocess_conv3d_input(x, data_format)\n    kernel = _preprocess_conv3d_kernel(kernel, data_format)\n    padding = _preprocess_border_mode(padding)\n    strides = (1,) + strides\n    # cntk output_shape does not include batch axis\n    output_shape = output_shape[1:]\n    # in keras2, need handle output shape in different format\n    if data_format == 'channels_last':\n        output_shape = transpose_shape(output_shape, 'channels_first',\n                                       spatial_axes=(0, 1, 2))\n\n    x = C.convolution_transpose(\n        kernel,\n        x,\n        strides,\n        auto_padding=[\n            False,\n            padding,\n            padding,\n            padding],\n        output_shape=output_shape)\n    return _postprocess_conv3d_output(x, data_format)",
                "def pool2d(x, pool_size, strides=(1, 1),\n           padding='valid', data_format=None,\n           pool_mode='max'):\n    data_format = normalize_data_format(data_format)\n\n    padding = _preprocess_border_mode(padding)\n    strides = strides\n    pool_size = pool_size\n    x = _preprocess_conv2d_input(x, data_format)\n    if pool_mode == 'max':\n        x = C.pooling(\n            x,\n            C.MAX_POOLING,\n            pool_size,\n            strides,\n            auto_padding=[padding])\n    elif pool_mode == 'avg':\n        x = C.pooling(\n            x,\n            C.AVG_POOLING,\n            pool_size,\n            strides,\n            auto_padding=[padding])\n    else:\n        raise ValueError('Invalid pooling mode: ' + str(pool_mode))\n    return _postprocess_conv2d_output(x, data_format)",
                "def pool3d(x, pool_size, strides=(1, 1, 1), padding='valid',\n           data_format=None, pool_mode='max'):\n    data_format = normalize_data_format(data_format)\n\n    padding = _preprocess_border_mode(padding)\n\n    x = _preprocess_conv3d_input(x, data_format)\n\n    if pool_mode == 'max':\n        x = C.pooling(\n            x,\n            C.MAX_POOLING,\n            pool_size,\n            strides,\n            auto_padding=[padding])\n    elif pool_mode == 'avg':\n        x = C.pooling(\n            x,\n            C.AVG_POOLING,\n            pool_size,\n            strides,\n            auto_padding=[padding])\n    else:\n        raise ValueError('Invalid pooling mode: ' + str(pool_mode))\n\n    return _postprocess_conv3d_output(x, data_format)",
                "def relu(x, alpha=0., max_value=None):\n    if alpha != 0.:\n        negative_part = C.relu(-x)\n    x = C.relu(x)\n    if max_value is not None:\n        x = C.clip(x, 0.0, max_value)\n    if alpha != 0.:\n        x -= alpha * negative_part\n    return x",
                "def dropout(x, level, noise_shape=None, seed=None):\n    if level < 0. or level >= 1:\n        raise ValueError('CNTK Backend: Invalid dropout level %s, '\n                         'must be in interval [0, 1].' % level)\n    return C.dropout(x, level)",
                "def batch_flatten(x):\n    # cntk's batch axis is not in shape,\n    # so just flatten all the dim in x.shape\n    dim = np.prod(x.shape)\n    x = C.reshape(x, (-1,))\n    x._keras_shape = (None, dim)\n    return x",
                "def softmax(x, axis=-1):\n    return C.softmax(x, axis=axis)",
                "def softplus(x):\n    return C.softplus(x)",
                "def softsign(x):\n    return x / (1 + C.abs(x))",
                "def categorical_crossentropy(target, output, from_logits=False, axis=-1):\n    # Here, unlike other backends, the tensors lack a batch dimension:\n    axis_without_batch = -1 if axis == -1 else axis - 1\n    output_dimensions = list(range(len(output.shape)))\n    if axis_without_batch != -1 and axis_without_batch not in output_dimensions:\n        raise ValueError(\n            '{}{}{}'.format(\n                'Unexpected channels axis {}. '.format(axis_without_batch),\n                'Expected to be -1 or one of the axes of `output`, ',\n                'which has {} dimensions.'.format(len(output.shape))))\n    # If the channels are not in the last axis, move them to be there:\n    if axis_without_batch != -1 and axis_without_batch != output_dimensions[-1]:\n        permutation = output_dimensions[:axis_without_batch]\n        permutation += output_dimensions[axis_without_batch + 1:]\n        permutation += [axis_without_batch]\n        output = C.transpose(output, permutation)\n        target = C.transpose(target, permutation)\n    if from_logits:\n        result = C.cross_entropy_with_softmax(output, target)\n        # cntk's result shape is (batch, 1), while keras expect (batch, )\n        return C.reshape(result, ())\n    else:\n        # scale preds so that the class probas of each sample sum to 1\n        output /= C.reduce_sum(output, axis=-1)\n        # avoid numerical instability with epsilon clipping\n        output = C.clip(output, epsilon(), 1.0 - epsilon())\n        return -sum(target * C.log(output), axis=-1)",
                "def sparse_categorical_crossentropy(target, output, from_logits=False, axis=-1):\n    # Here, unlike other backends, the tensors lack a batch dimension:\n    axis_without_batch = -1 if axis == -1 else axis - 1\n    output_dimensions = list(range(len(output.shape)))\n    if axis_without_batch != -1 and axis_without_batch not in output_dimensions:\n        raise ValueError(\n            '{}{}{}'.format(\n                'Unexpected channels axis {}. '.format(axis_without_batch),\n                'Expected to be -1 or one of the axes of `output`, ',\n                'which has {} dimensions.'.format(len(output.shape))))\n    target = C.one_hot(target, output.shape[axis_without_batch],\n                       axis=axis_without_batch)\n    target = C.reshape(target, output.shape)\n    return categorical_crossentropy(target, output, from_logits, axis=axis)",
                "def function(inputs, outputs, updates=[], **kwargs):\n    return Function(inputs, outputs, updates=updates, **kwargs)",
                "def temporal_padding(x, padding=(1, 1)):\n    assert len(padding) == 2\n    num_dynamic_axis = _get_dynamic_axis_num(x)\n    assert len(x.shape) == 3 - (1 if num_dynamic_axis > 0 else 0)\n    return pad(x, [padding], 'channels_last', num_dynamic_axis)",
                "def _padding(x, pattern, axis):  # pragma: no cover\n    base_shape = x.shape\n    if b_any([dim < 0 for dim in base_shape]):\n        raise ValueError('CNTK Backend: padding input tensor with '\n                         'shape `%s` contains non-specified dimension, '\n                         'which is not supported. Please give fixed '\n                         'dimension to enable padding.' % base_shape)\n    if pattern[0] > 0:\n        prefix_shape = list(base_shape)\n        prefix_shape[axis] = pattern[0]\n        prefix_shape = tuple(prefix_shape)\n        x = C.splice(C.constant(value=0, shape=prefix_shape), x, axis=axis)\n        base_shape = x.shape\n    if pattern[1] > 0:\n        postfix_shape = list(base_shape)\n        postfix_shape[axis] = pattern[1]\n        postfix_shape = tuple(postfix_shape)\n        x = C.splice(x, C.constant(value=0, shape=postfix_shape), axis=axis)\n    return x",
                "def pad(x, pad_info, data_format, num_dynamic_axis):\n    if hasattr(C, 'pad'):\n        pattern = [list(p) for p in pad_info]\n        if data_format == 'channels_first':\n            pattern = [[0, 0]] + pattern\n        else:\n            pattern = pattern + [[0, 0]]\n        if num_dynamic_axis == 0:\n            pattern = [[0, 0]] + pattern\n        return C.pad(x, pattern=pattern)\n    else:  # pragma: no cover\n        for (a, p) in enumerate(pad_info):\n            x = _padding(x, p,\n                         a + (1 if num_dynamic_axis == 0 else 0) +\n                         (1 if data_format == 'channels_first' else 0))\n        return x",
                "def spatial_2d_padding(x, padding=((1, 1), (1, 1)), data_format=None):\n    assert len(padding) == 2\n    assert len(padding[0]) == 2\n    assert len(padding[1]) == 2\n    data_format = normalize_data_format(data_format)\n\n    num_dynamic_axis = _get_dynamic_axis_num(x)\n    assert len(x.shape) == 4 - (1 if num_dynamic_axis > 0 else 0)\n    return pad(x, padding, data_format, num_dynamic_axis)",
                "def spatial_3d_padding(x, padding=((1, 1), (1, 1), (1, 1)), data_format=None):\n    assert len(padding) == 3\n    assert len(padding[0]) == 2\n    assert len(padding[1]) == 2\n    assert len(padding[2]) == 2\n    data_format = normalize_data_format(data_format)\n\n    num_dynamic_axis = _get_dynamic_axis_num(x)\n    assert len(x.shape) == 5 - (1 if num_dynamic_axis > 0 else 0)\n    return pad(x, padding, data_format, num_dynamic_axis)",
                "def one_hot(indices, num_classes):\n    return C.one_hot(indices, num_classes)",
                "def get_value(x):\n    if isinstance(\n            x,\n            C.variables.Parameter) or isinstance(\n            x,\n            C.variables.Constant):\n        return x.value\n    else:\n        return eval(x)",
                "def batch_get_value(xs):\n    result = []\n    for x in xs:\n        if (isinstance(x, C.variables.Parameter) or\n           isinstance(x, C.variables.Constant)):\n            result.append(x.value)\n        else:\n            result.append(eval(x))\n    return result",
                "def set_value(x, value):\n    if (isinstance(x, C.variables.Parameter) or\n       isinstance(x, C.variables.Constant)):\n        if isinstance(value, (float, int)):\n            value = np.full(x.shape, value, dtype=floatx())\n        x.value = value\n    else:\n        raise NotImplementedError",
                "def print_tensor(x, message=''):\n    return C.user_function(\n        LambdaFunc(x,\n                   when=lambda x: True,\n                   execute=lambda x: print(message)))",
                "def batch_set_value(tuples):\n    for t in tuples:\n        x = t[0]\n        value = t[1]\n        if isinstance(value, np.ndarray) is False:\n            value = np.asarray(value)\n        if isinstance(x, C.variables.Parameter):\n            x.value = value\n        else:\n            raise NotImplementedError",
                "def stop_gradient(variables):\n    if isinstance(variables, (list, tuple)):\n        return map(C.stop_gradient, variables)\n    else:\n        return C.stop_gradient(variables)",
                "def switch(condition, then_expression, else_expression):\n    ndim_cond = ndim(condition)\n    ndim_expr = ndim(then_expression)\n    if ndim_cond > ndim_expr:\n        raise ValueError('Rank of condition should be less'\n                         ' than or equal to rank of then and'\n                         ' else expressions. ndim(condition)=' +\n                         str(ndim_cond) + ', ndim(then_expression)'\n                         '=' + str(ndim_expr))\n    elif ndim_cond < ndim_expr:\n        shape_expr = int_shape(then_expression)\n        ndim_diff = ndim_expr - ndim_cond\n        for i in range(ndim_diff):\n            condition = expand_dims(condition)\n            condition = tile(condition, shape_expr[ndim_cond + i])\n    return C.element_select(condition,\n                            then_expression,\n                            else_expression)",
                "def elu(x, alpha=1.):\n    res = C.elu(x)\n    if alpha == 1:\n        return res\n    else:\n        return C.element_select(C.greater(x, 0), res, alpha * res)",
                "def in_top_k(predictions, targets, k):\n    _targets = C.one_hot(targets, predictions.shape[-1])\n    result = C.classification_error(predictions, _targets, topN=k)\n    return 1 - C.reshape(result, shape=())",
                "def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),\n                     padding='valid', data_format=None):\n    data_format = normalize_data_format(data_format)\n\n    x = _preprocess_conv2d_input(x, data_format)\n    kernel = _preprocess_conv2d_kernel(kernel, data_format)\n    padding = _preprocess_border_mode(padding)\n    strides = (1,) + strides\n    # cntk output_shape does not include batch axis\n    output_shape = output_shape[1:]\n    # in keras2, need handle output shape in different format\n    if data_format == 'channels_last':\n        output_shape = transpose_shape(output_shape, 'channels_first',\n                                       spatial_axes=(0, 1))\n\n    x = C.convolution_transpose(\n        kernel,\n        x,\n        strides,\n        auto_padding=[\n            False,\n            padding,\n            padding],\n        output_shape=output_shape)\n    return _postprocess_conv2d_output(x, data_format)",
                "def identity(x, name=None):\n    if name is None:\n        name = '%s_alias' % x.name\n    return C.alias(x, name=name)",
                "def _preprocess_conv2d_input(x, data_format):\n    if data_format == 'channels_last':\n        # TF uses the last dimension as channel dimension,\n        # instead of the 2nd one.\n        # TH input shape: (samples, input_depth, rows, cols)\n        # TF input shape: (samples, rows, cols, input_depth)\n        x = C.transpose(x, (2, 0, 1))\n    return x",
                "def _preprocess_conv2d_kernel(kernel, data_format):\n    # As of Keras 2.0.0, all kernels are normalized\n    # on the format `(rows, cols, input_depth, depth)`,\n    # independently of `data_format`.\n    # CNTK expects `(depth, input_depth, rows, cols)`.\n    kernel = C.transpose(kernel, (3, 2, 0, 1))\n    return kernel",
                "def _preprocess_border_mode(padding):\n    if padding == 'same':\n        padding = True\n    elif padding == 'valid':\n        padding = False\n    else:\n        raise ValueError('Invalid border mode: ' + str(padding))\n    return padding",
                "def _postprocess_conv2d_output(x, data_format):\n    if data_format == 'channels_last':\n        x = C.transpose(x, (1, 2, 0))\n    return x",
                "def _preprocess_conv3d_input(x, data_format):\n    if data_format == 'channels_last':\n        # TF uses the last dimension as channel dimension,\n        # instead of the 2nd one.\n        # TH input shape: (samples, input_depth, conv_dim1, conv_dim2, conv_dim3)\n        # TF input shape: (samples, conv_dim1, conv_dim2, conv_dim3,\n        # input_depth)\n        x = C.transpose(x, (3, 0, 1, 2))\n    return x",
                "def _preprocess_conv3d_kernel(kernel, dim_ordering):\n    kernel = C.transpose(kernel, (4, 3, 0, 1, 2))\n    return kernel",
                "def _postprocess_conv3d_output(x, dim_ordering):\n    if dim_ordering == 'channels_last':\n        x = C.transpose(x, (1, 2, 3, 0))\n    return x",
                "def _get_dynamic_axis_num(x):\n    if hasattr(x, 'dynamic_axes'):\n        return len(x.dynamic_axes)\n    else:\n        return 0",
                "def _contain_seqence_axis(x):\n    if _get_dynamic_axis_num(x) > 1:\n        return x.dynamic_axes[1] == C.Axis.default_dynamic_axis()\n    else:\n        return False",
                "def get_num_dynamic_axis(x):\n    return _get_dynamic_axis_num(x)",
                "def _reduce_on_axis(x, axis, reduce_fun_name):\n    if isinstance(axis, list):\n        for a in axis:\n            if isinstance(a, C.Axis) \\\n                    and a != C.Axis.default_batch_axis() \\\n                    and hasattr(C.sequence, reduce_fun_name):\n                x = getattr(C.sequence, reduce_fun_name)(x, a)\n            else:\n                x = getattr(C, reduce_fun_name)(x, a)\n    else:\n        x = getattr(C, reduce_fun_name)(x, axis)\n    return x",
                "def _reshape_sequence(x, time_step):\n    tmp_shape = list(int_shape(x))\n    tmp_shape[1] = time_step\n    return reshape(x, tmp_shape)",
                "def local_conv1d(inputs, kernel, kernel_size, strides, data_format=None):\n    data_format = normalize_data_format(data_format)\n\n    stride = strides[0]\n    kernel_shape = int_shape(kernel)\n    output_length, feature_dim, filters = kernel_shape\n\n    xs = []\n    for i in range(output_length):\n        slice_length = py_slice(i * stride,\n                                i * stride + kernel_size[0])\n        xs.append(reshape(inputs[:, slice_length, :],\n                          (-1, 1, feature_dim)))\n    x_aggregate = concatenate(xs, axis=1)\n    # transpose kernel to output_filters first, to apply broadcast\n    weight = permute_dimensions(kernel, (2, 0, 1))\n    # Shape: (batch, filters, output_length, input_length * kernel_size)\n    output = x_aggregate * weight\n    # Shape: (batch, filters, output_length)\n    output = sum(output, axis=3)\n    # Shape: (batch, output_length, filters)\n    return permute_dimensions(output, (0, 2, 1))",
                "def local_conv2d(inputs,\n                 kernel,\n                 kernel_size,\n                 strides,\n                 output_shape,\n                 data_format=None):\n    data_format = normalize_data_format(data_format)\n\n    stride_row, stride_col = strides\n    output_row, output_col = output_shape\n    kernel_shape = int_shape(kernel)\n    _, feature_dim, filters = kernel_shape\n    xs = []\n\n    for i in range(output_row):\n        for j in range(output_col):\n            slice_row = py_slice(i * stride_row,\n                                 i * stride_row + kernel_size[0])\n            slice_col = py_slice(j * stride_col,\n                                 j * stride_col + kernel_size[1])\n            if data_format == 'channels_first':\n                xs.append(reshape(inputs[:, :, slice_row, slice_col],\n                                  (-1, 1, feature_dim)))\n            else:\n                xs.append(reshape(inputs[:, slice_row, slice_col, :],\n                                  (-1, 1, feature_dim)))\n    x_aggregate = concatenate(xs, axis=1)\n    # transpose kernel to put filters first\n    weight = permute_dimensions(kernel, (2, 0, 1))\n    # shape: batch, filters, output_length, input_length * kernel_size\n    output = x_aggregate * weight\n    # shape: batch, filters, output_length\n    output = sum(output, axis=3)\n    # shape: batch, filters, row, col\n    output = reshape(output,\n                     (-1, filters, output_row, output_col))\n\n    if data_format == 'channels_last':\n        # shape: batch, row, col, filters\n        output = permute_dimensions(output, (0, 2, 3, 1))\n\n    return output",
                "def reverse(x, axes):\n    if isinstance(axes, int):\n        axes = [axes]\n    cntk_axes = _normalize_axis(axes, x)\n    begin_index = [0 for _ in cntk_axes]\n    end_index = [0 for _ in cntk_axes]\n    strides = [-1 for _ in cntk_axes]\n    return C.slice(x, cntk_axes, begin_index, end_index, strides)",
                "def slice(x, start, size):\n    raise NotImplementedError",
                "def _reshape_batch(x, shape):\n    # there is a bug in cntk 2.1's unpack_batch implementation\n    if hasattr(C, 'unpack_batch') and _get_cntk_version() >= 2.2:\n        const_a = C.unpack_batch(x)\n        const_a = C.reshape(const_a, shape)\n        return C.to_batch(const_a)\n    else:\n        return C.user_function(ReshapeBatch(x, shape[1:]))",
                "def _get_cntk_version():\n    version = C.__version__\n    if version.endswith('+'):\n        version = version[:-1]\n    # for hot fix, ignore all the . except the first one.\n    if len(version) > 2 and version[1] == '.':\n        version = version[:2] + version[2:].replace('.', '')\n    try:\n        return float(version)\n    except:\n        warnings.warn(\n            'CNTK backend warning: CNTK version not detected. '\n            'Will using CNTK 2.0 GA as default.')\n        return float(2.0)",
                "def __init__(self, inputs, outputs, updates=[], **kwargs):\n    self.placeholders = inputs\n    self.trainer = None\n    self.unrelated_updates = None\n    self.updates = updates\n    if len(updates) > 0:\n        assert len(outputs) > 0\n        self.loss = outputs[0]\n        # need group update by gradient place holder\n        u_ops = []\n        unrelated_updates = []\n        for update in updates:\n            if isinstance(update, tuple):\n                if len(update) != 2:\n                    raise NotImplementedError\n                else:\n                    u = C.assign(update[0], update[1])\n            else:\n                u = update\n\n            if len(u.arguments) == 0:\n                u_ops.append(u)\n            else:\n                unrelated_updates.append(u)\n\n        update_func = C.combine([u.output for u in u_ops])\n\n        grads = update_func.find_all_with_name('keras_grad_placeholder')\n\n        u_list = []\n        p_list = []\n        for g in grads:\n            if g in grad_parameter_dict:\n                p_list.append(grad_parameter_dict[g])\n                u_list.append(g)\n            else:\n                raise ValueError(\n                    'CNTK backend: when constructing trainer, '\n                    'found gradient node `%s` which is not '\n                    'related to any parameters in the model. '\n                    'Please double check how the gradient node '\n                    'is constructed.' % g)\n\n        if len(u_list) > 0:\n            learner = C.cntk_py.universal_learner(p_list, u_list, update_func)\n\n            criterion = (\n                outputs[0],\n                outputs[1]) if len(outputs) > 1 else (\n                outputs[0],\n            )\n            self.trainer = C.trainer.Trainer(\n                outputs[0], criterion, [learner])\n            self.trainer_output = tuple([f.output for f in criterion])\n        elif len(u_ops) > 0:\n            unrelated_updates.extend(u_ops)\n\n        if len(unrelated_updates) > 0:\n            self.unrelated_updates = C.combine([_.output for _ in unrelated_updates])\n\n    if self.trainer is None:\n        self.metrics_outputs = [f.output for f in outputs]\n        self.metrics_func = C.combine(self.metrics_outputs)\n    # cntk only could handle loss and 1 metric in trainer, for metrics more\n    # than 2, need manual eval\n    elif len(outputs) > 2:\n        self.metrics_outputs = [f.output for f in outputs[2:]]\n        self.metrics_func = C.combine(self.metrics_outputs)\n    else:\n        self.metrics_func = None",
                "@staticmethod\ndef _is_input_shape_compatible(input, placeholder):\n    if hasattr(input, 'shape') and hasattr(placeholder, 'shape'):\n        num_dynamic = get_num_dynamic_axis(placeholder)\n        input_shape = input.shape[num_dynamic:]\n        placeholder_shape = placeholder.shape\n        for i, p in zip(input_shape, placeholder_shape):\n            if i != p and p != C.InferredDimension and p != C.FreeDimension:\n                return False\n    return True",
                "def __call__(self, inputs):\n    global _LEARNING_PHASE_PLACEHOLDER\n    global _LEARNING_PHASE\n    assert isinstance(inputs, (list, tuple))\n    feed_dict = {}\n    for tensor, value in zip(self.placeholders, inputs):\n        # cntk only support calculate on float, do auto cast here\n        if (hasattr(value, 'dtype') and\n           value.dtype != np.float32 and\n           value.dtype != np.float64):\n            value = value.astype(np.float32)\n\n        if tensor == _LEARNING_PHASE_PLACEHOLDER:\n            _LEARNING_PHASE_PLACEHOLDER.value = np.asarray(value)\n        else:\n            # in current version cntk can't support input with variable\n            # length. Will support it in next release.\n            if not self._is_input_shape_compatible(value, tensor):\n                raise ValueError('CNTK backend: The placeholder has been resolved '\n                                 'to shape `%s`, but input shape is `%s`. Currently '\n                                 'CNTK can not take variable length inputs. Please '\n                                 'pass inputs that have a static shape.'\n                                 % (str(tensor.shape), str(value.shape)))\n        feed_dict[tensor] = value\n\n    updated = []\n    if self.trainer is not None:\n        input_dict = {}\n        for argument in self.loss.arguments:\n            if argument in feed_dict:\n                input_dict[argument] = feed_dict[argument]\n            else:\n                raise ValueError(\n                    'CNTK backend: argument %s is not found in inputs. '\n                    'Please double check the model and inputs in '\n                    '`train_function`.' % argument.name)\n\n        result = self.trainer.train_minibatch(\n            input_dict, self.trainer_output)\n\n        assert(len(result) == 2)\n        outputs = result[1]\n        for o in self.trainer_output:\n            updated.append(outputs[o])\n\n    if self.metrics_func is not None:\n        input_dict = {}\n        for argument in self.metrics_func.arguments:\n            if argument in feed_dict:\n                input_dict[argument] = feed_dict[argument]\n            else:\n                raise ValueError('CNTK backend: metrics argument %s '\n                                 'is not found in inputs. Please double '\n                                 'check the model and inputs.' % argument.name)\n        # Some ops (like dropout) won't be applied during \"eval\" in cntk.\n        # They only evaluated in training phase. To make it work, call\n        # \"forward\" method to let cntk know we want to evaluate them.from\n        # But the assign ops won't be executed under this mode, that's why\n        # we need this check.\n        if (self.unrelated_updates is None and\n                (_LEARNING_PHASE_PLACEHOLDER.value == 1.0 or _LEARNING_PHASE == 1)):\n            _, output_values = self.metrics_func.forward(\n                input_dict,\n                self.metrics_func.outputs,\n                (self.metrics_func.outputs[0],),\n                as_numpy=False)\n        else:\n            output_values = self.metrics_func.eval(input_dict, as_numpy=False)\n        if isinstance(output_values, dict):\n            for o in self.metrics_outputs:\n                value = output_values[o]\n                v = value.asarray()\n                updated.append(v)\n        else:\n            v = output_values.asarray()\n            for o in self.metrics_outputs:\n                updated.append(v)\n\n    if self.unrelated_updates is not None:\n        input_dict = {}\n        for argument in self.unrelated_updates.arguments:\n            if argument in feed_dict:\n                input_dict[argument] = feed_dict[argument]\n            else:\n                raise ValueError(\n                    'CNTK backend: assign ops argument %s '\n                    'is not found in inputs. Please double '\n                    'check the model and inputs.' % argument.name)\n        self.unrelated_updates.eval(input_dict, as_numpy=False)\n    return updated",
                "def __init__(self, input, shape, name='reshape_with_batch'):\n    super(ReshapeBatch, self).__init__([input], as_numpy=False, name=name)\n    self.from_shape = input.shape\n    self.target_shape = shape",
                "def infer_outputs(self):\n    batch_axis = C.Axis.default_batch_axis()\n    return [\n        C.output_variable(\n            self.target_shape,\n            self.inputs[0].dtype,\n            [batch_axis])]",
                "def forward(self, arguments, device=None, outputs_to_retain=None):\n    num_element = arguments.shape()[0] * np.prod(np.asarray(self.from_shape))\n    num_static_element = np.prod(np.asarray(self.target_shape))\n    num_batch = int(num_element / num_static_element)\n    result = arguments.data().as_shape((num_batch,) + self.target_shape)\n    return None, C.cntk_py.Value(result)",
                "def backward(self, state, root_gradients):\n    grad_array_view = root_gradients.data()\n    num_element = root_gradients.shape()[0] * np.prod(np.asarray(self.target_shape))\n    num_static_element = np.prod(np.asarray(self.from_shape))\n    num_old_batch = int(num_element / num_static_element)\n    return C.cntk_py.Value(\n        grad_array_view.as_shape(\n            (num_old_batch,) + self.from_shape))",
                "def __init__(self, input, name='convert_to_batch'):\n    super(ConvertToBatch, self).__init__([input], as_numpy=False, name=name)",
                "def infer_outputs(self):\n    batch_axis = C.Axis.default_batch_axis()\n    return [\n        C.output_variable(\n            self.inputs[0].shape[1:],\n            self.inputs[0].dtype,\n            [batch_axis])]",
                "def forward(self, arguments, device=None, outputs_to_retain=None):\n    return None, C.cntk_py.Value(arguments.data())",
                "def backward(self, state, root_gradients):\n    return C.cntk_py.Value(root_gradients.data())",
                "def __init__(self, input, batch_size, name='convert_to_static'):\n    super(ConvertToStatic, self).__init__([input], as_numpy=False, name=name)\n    self.target_shape = (batch_size,) + input.shape",
                "def infer_outputs(self):\n    return [\n        C.output_variable(\n            self.target_shape,\n            self.inputs[0].dtype,\n            [])]",
                "def forward(self, arguments, device=None, outputs_to_retain=None):\n    return None, C.cntk_py.Value(arguments.data())",
                "def backward(self, state, root_gradients):\n    return C.cntk_py.Value(root_gradients.data())",
                "def __init__(self,\n             arg,\n             when=lambda arg: True,\n             execute=lambda arg: print(arg),\n             name=''):\n    self.when = when\n    self.execute = execute\n\n    super(LambdaFunc, self).__init__([arg], name=name)",
                "def infer_outputs(self):\n    return [\n        C.output_variable(\n            self.inputs[0].shape,\n            self.inputs[0].dtype,\n            self.inputs[0].dynamic_axes)]",
                "def forward(self, argument, device=None, outputs_to_retain=None):\n    if self.when(argument):\n        self.execute(argument)\n\n    return None, argument",
                "def backward(self, state, root_gradients):\n    return root_gradients",
                "def _recurrence(x, states, m):\n    # create place holder\n    place_holders = [C.placeholder(dynamic_axes=x.dynamic_axes) for _ in states]\n    past_values = []\n    for s, p in zip(states, place_holders):\n        past_values.append(C.sequence.past_value(p, s))\n    new_output, new_states = step_function(\n        x, tuple(past_values) + tuple(rnn_constants))\n\n    if getattr(new_output, '_uses_learning_phase', False):\n        global uses_learning_phase\n        uses_learning_phase = True\n\n    if m is not None:\n        new_states = [C.element_select(m, n, s) for n, s in zip(new_states, past_values)]\n    n_s = []\n    for o, p in zip(new_states, place_holders):\n        n_s.append(o.replace_placeholders({p: o.output}))\n    if len(n_s) > 0:\n        new_output = n_s[0]\n    return new_output, n_s"
            ],
            "inscope_function_signatures": [
                "name_scope(name)",
                "get_uid(prefix='')",
                "learning_phase()",
                "set_learning_phase(value)",
                "clear_session()",
                "in_train_phase(x, alt, training=None)",
                "in_test_phase(x, alt, training=None)",
                "_convert_string_dtype(dtype)",
                "_convert_dtype_string(dtype)",
                "variable(value, dtype=None, name=None, constraint=None)",
                "bias_add(x, bias, data_format=None)",
                "eval(x)",
                "placeholder(shape=None, ndim=None, dtype=None, sparse=False, name=None, dynamic_axis_num=1)",
                "is_placeholder(x)",
                "is_keras_tensor(x)",
                "is_tensor(x)",
                "shape(x)",
                "is_sparse(tensor)",
                "int_shape(x)",
                "ndim(x)",
                "_prepare_name(name, default)",
                "constant(value, dtype=None, shape=None, name=None)",
                "random_binomial(shape, p=0.0, dtype=None, seed=None)",
                "random_uniform(shape, minval=0.0, maxval=1.0, dtype=None, seed=None)",
                "random_uniform_variable(shape, low, high, dtype=None, name=None, seed=None)",
                "random_normal_variable(shape, mean, scale, dtype=None, name=None, seed=None)",
                "random_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None)",
                "truncated_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None)",
                "dtype(x)",
                "zeros(shape, dtype=None, name=None)",
                "ones(shape, dtype=None, name=None)",
                "eye(size, dtype=None, name=None)",
                "zeros_like(x, dtype=None, name=None)",
                "ones_like(x, dtype=None, name=None)",
                "count_params(x)",
                "cast(x, dtype)",
                "dot(x, y)",
                "batch_dot(x, y, axes=None)",
                "transpose(x)",
                "gather(reference, indices)",
                "_remove_dims(x, axis, keepdims=False)",
                "max(x, axis=None, keepdims=False)",
                "min(x, axis=None, keepdims=False)",
                "sum(x, axis=None, keepdims=False)",
                "prod(x, axis=None, keepdims=False)",
                "logsumexp(x, axis=None, keepdims=False)",
                "var(x, axis=None, keepdims=False)",
                "std(x, axis=None, keepdims=False)",
                "expand_dims(x, axis=-1)",
                "squeeze(x, axis)",
                "tile(x, n)",
                "_normalize_axis(axis, x)",
                "_reshape_dummy_dim(x, axis)",
                "mean(x, axis=None, keepdims=False)",
                "any(x, axis=None, keepdims=False)",
                "all(x, axis=None, keepdims=False)",
                "classification_error(target, output, axis=-1)",
                "argmax(x, axis=-1)",
                "argmin(x, axis=-1)",
                "square(x)",
                "abs(x)",
                "sqrt(x)",
                "exp(x)",
                "log(x)",
                "round(x)",
                "sigmoid(x)",
                "sign(x)",
                "pow(x, a)",
                "clip(x, min_value, max_value)",
                "binary_crossentropy(target, output, from_logits=False)",
                "get_variable_shape(x)",
                "update(x, new_x)",
                "moving_average_update(variable, value, momentum)",
                "update_add(x, increment)",
                "gradients(loss, variables)",
                "equal(x, y)",
                "not_equal(x, y)",
                "greater(x, y)",
                "greater_equal(x, y)",
                "less(x, y)",
                "less_equal(x, y)",
                "maximum(x, y)",
                "minimum(x, y)",
                "sin(x)",
                "cos(x)",
                "normalize_batch_in_training(x, gamma, beta, reduction_axes, epsilon=0.001)",
                "_moments(x, axes=None, shift=None, keep_dims=False)",
                "batch_normalization(x, mean, var, beta, gamma, axis=-1, epsilon=0.001)",
                "concatenate(tensors, axis=-1)",
                "flatten(x)",
                "reshape(x, shape)",
                "permute_dimensions(x, pattern)",
                "resize_images(x, height_factor, width_factor, data_format, interpolation='nearest')",
                "resize_volumes(x, depth_factor, height_factor, width_factor, data_format)",
                "repeat_elements(x, rep, axis)",
                "repeat(x, n)",
                "tanh(x)",
                "_static_rnn(step_function, inputs, initial_states, go_backwards=False, mask=None, constants=None, unroll=False, input_length=None)",
                "rnn(step_function, inputs, initial_states, go_backwards=False, mask=None, constants=None, unroll=False, input_length=None)",
                "has_seq_axis(x)",
                "l2_normalize(x, axis=None)",
                "hard_sigmoid(x)",
                "conv1d(x, kernel, strides=1, padding='valid', data_format=None, dilation_rate=1)",
                "conv2d(x, kernel, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1))",
                "separable_conv1d(x, depthwise_kernel, pointwise_kernel, strides=1, padding='valid', data_format=None, dilation_rate=1)",
                "separable_conv2d(x, depthwise_kernel, pointwise_kernel, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1))",
                "depthwise_conv2d(x, depthwise_kernel, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1))",
                "conv3d(x, kernel, strides=(1, 1, 1), padding='valid', data_format=None, dilation_rate=(1, 1, 1))",
                "conv3d_transpose(x, kernel, output_shape, strides=(1, 1, 1), padding='valid', data_format=None)",
                "pool2d(x, pool_size, strides=(1, 1), padding='valid', data_format=None, pool_mode='max')",
                "pool3d(x, pool_size, strides=(1, 1, 1), padding='valid', data_format=None, pool_mode='max')",
                "relu(x, alpha=0.0, max_value=None)",
                "dropout(x, level, noise_shape=None, seed=None)",
                "batch_flatten(x)",
                "softmax(x, axis=-1)",
                "softplus(x)",
                "softsign(x)",
                "categorical_crossentropy(target, output, from_logits=False, axis=-1)",
                "sparse_categorical_crossentropy(target, output, from_logits=False, axis=-1)",
                "function(inputs, outputs, updates=[], **kwargs)",
                "temporal_padding(x, padding=(1, 1))",
                "_padding(x, pattern, axis)",
                "pad(x, pad_info, data_format, num_dynamic_axis)",
                "spatial_2d_padding(x, padding=((1, 1), (1, 1)), data_format=None)",
                "spatial_3d_padding(x, padding=((1, 1), (1, 1), (1, 1)), data_format=None)",
                "one_hot(indices, num_classes)",
                "get_value(x)",
                "batch_get_value(xs)",
                "set_value(x, value)",
                "print_tensor(x, message='')",
                "batch_set_value(tuples)",
                "stop_gradient(variables)",
                "switch(condition, then_expression, else_expression)",
                "elu(x, alpha=1.0)",
                "in_top_k(predictions, targets, k)",
                "conv2d_transpose(x, kernel, output_shape, strides=(1, 1), padding='valid', data_format=None)",
                "identity(x, name=None)",
                "_preprocess_conv2d_input(x, data_format)",
                "_preprocess_conv2d_kernel(kernel, data_format)",
                "_preprocess_border_mode(padding)",
                "_postprocess_conv2d_output(x, data_format)",
                "_preprocess_conv3d_input(x, data_format)",
                "_preprocess_conv3d_kernel(kernel, dim_ordering)",
                "_postprocess_conv3d_output(x, dim_ordering)",
                "_get_dynamic_axis_num(x)",
                "_contain_seqence_axis(x)",
                "get_num_dynamic_axis(x)",
                "_reduce_on_axis(x, axis, reduce_fun_name)",
                "_reshape_sequence(x, time_step)",
                "local_conv1d(inputs, kernel, kernel_size, strides, data_format=None)",
                "local_conv2d(inputs, kernel, kernel_size, strides, output_shape, data_format=None)",
                "reverse(x, axes)",
                "slice(x, start, size)",
                "_reshape_batch(x, shape)",
                "_get_cntk_version()",
                "__init__(self, inputs, outputs, updates=[], **kwargs)",
                "_is_input_shape_compatible(input, placeholder)",
                "__call__(self, inputs)",
                "__init__(self, input, shape, name='reshape_with_batch')",
                "infer_outputs(self)",
                "forward(self, arguments, device=None, outputs_to_retain=None)",
                "backward(self, state, root_gradients)",
                "__init__(self, input, name='convert_to_batch')",
                "infer_outputs(self)",
                "forward(self, arguments, device=None, outputs_to_retain=None)",
                "backward(self, state, root_gradients)",
                "__init__(self, input, batch_size, name='convert_to_static')",
                "infer_outputs(self)",
                "forward(self, arguments, device=None, outputs_to_retain=None)",
                "backward(self, state, root_gradients)",
                "__init__(self, arg, when=lambda arg: True, execute=lambda arg: print(arg), name='')",
                "infer_outputs(self)",
                "forward(self, argument, device=None, outputs_to_retain=None)",
                "backward(self, state, root_gradients)",
                "_recurrence(x, states, m)"
            ],
            "variables_in_file": {
                "C.set_global_option": [
                    17
                ],
                "C": [
                    1024,
                    1028,
                    1029,
                    1030,
                    1031,
                    2052,
                    523,
                    2060,
                    17,
                    23,
                    1559,
                    1049,
                    1051,
                    1052,
                    1565,
                    1054,
                    543,
                    544,
                    33,
                    546,
                    1056,
                    1058,
                    1060,
                    1061,
                    1569,
                    1578,
                    2093,
                    1582,
                    2099,
                    2101,
                    1595,
                    2047,
                    2110,
                    2111,
                    1089,
                    1602,
                    579,
                    1606,
                    583,
                    2119,
                    585,
                    1098,
                    2120,
                    1615,
                    593,
                    1106,
                    1107,
                    1108,
                    1618,
                    2129,
                    601,
                    1114,
                    1115,
                    604,
                    93,
                    605,
                    95,
                    1630,
                    2141,
                    1635,
                    613,
                    2149,
                    2151,
                    106,
                    620,
                    1645,
                    1135,
                    1136,
                    2169,
                    2175,
                    1665,
                    2179,
                    1156,
                    2183,
                    2184,
                    2185,
                    663,
                    1690,
                    2203,
                    668,
                    162,
                    164,
                    678,
                    679,
                    169,
                    2218,
                    1197,
                    1201,
                    1713,
                    1715,
                    180,
                    2227,
                    1720,
                    1722,
                    1211,
                    2236,
                    194,
                    706,
                    707,
                    1220,
                    1222,
                    1226,
                    1740,
                    2252,
                    1742,
                    1747,
                    1749,
                    2263,
                    729,
                    2268,
                    1761,
                    1762,
                    2274,
                    1764,
                    1774,
                    2287,
                    241,
                    243,
                    1267,
                    1781,
                    1787,
                    2299,
                    1277,
                    2300,
                    1791,
                    2301,
                    2302,
                    2304,
                    1283,
                    1795,
                    2306,
                    1288,
                    266,
                    1297,
                    786,
                    1813,
                    1814,
                    1816,
                    281,
                    1818,
                    1307,
                    796,
                    1821,
                    799,
                    1823,
                    1313,
                    1824,
                    1318,
                    808,
                    809,
                    1837,
                    1839,
                    1332,
                    821,
                    313,
                    314,
                    315,
                    316,
                    826,
                    833,
                    1861,
                    838,
                    844,
                    845,
                    1870,
                    852,
                    2391,
                    858,
                    1375,
                    1376,
                    865,
                    1378,
                    1889,
                    2400,
                    2401,
                    870,
                    2402,
                    1896,
                    2403,
                    874,
                    2405,
                    364,
                    2409,
                    878,
                    1903,
                    1393,
                    882,
                    1907,
                    886,
                    1912,
                    1401,
                    890,
                    2424,
                    894,
                    1407,
                    2431,
                    2433,
                    898,
                    387,
                    1923,
                    902,
                    1418,
                    2443,
                    1422,
                    912,
                    401,
                    1425,
                    2450,
                    1428,
                    917,
                    918,
                    919,
                    2455,
                    1437,
                    928,
                    932,
                    421,
                    1446,
                    423,
                    1447,
                    937,
                    1450,
                    1451,
                    2470,
                    2472,
                    2478,
                    1457,
                    1458,
                    2481,
                    1460,
                    2484,
                    950,
                    957,
                    961,
                    451,
                    1475,
                    453,
                    965,
                    2502,
                    969,
                    1481,
                    2508,
                    973,
                    2511,
                    977,
                    2514,
                    981,
                    1496,
                    473,
                    985,
                    1497,
                    989,
                    2527,
                    993,
                    1505,
                    484,
                    485,
                    1513,
                    2041,
                    1530,
                    1023
                ],
                "b_any": [
                    2032,
                    1114,
                    19,
                    558
                ],
                "any": [
                    19
                ],
                "py_slice": [
                    2358,
                    20,
                    2325,
                    2356
                ],
                "slice": [
                    20
                ],
                "dev": [
                    1525,
                    23,
                    24,
                    1660,
                    1501
                ],
                "C.device.use_default_device": [
                    23
                ],
                "C.device": [
                    23
                ],
                "dev.type": [
                    24,
                    1525,
                    1660,
                    1501
                ],
                "warnings.warn": [
                    25,
                    2418,
                    1116
                ],
                "warnings": [
                    25,
                    2418,
                    1116
                ],
                "_LEARNING_PHASE_PLACEHOLDER": [
                    33,
                    1987,
                    79,
                    1939,
                    1940,
                    61
                ],
                "C.constant": [
                    33,
                    364,
                    950,
                    2041,
                    2047
                ],
                "np.float32": [
                    480,
                    33,
                    129,
                    1935,
                    1937,
                    117,
                    377,
                    444,
                    125,
                    413
                ],
                "np": [
                    129,
                    131,
                    133,
                    2439,
                    2440,
                    909,
                    911,
                    400,
                    528,
                    1935,
                    1936,
                    1937,
                    1940,
                    2447,
                    2448,
                    410,
                    413,
                    33,
                    442,
                    444,
                    2122,
                    79,
                    472,
                    2139,
                    2140,
                    478,
                    375,
                    480,
                    121,
                    363,
                    497,
                    1780,
                    117,
                    119,
                    504,
                    377,
                    125,
                    510
                ],
                "_LEARNING_PHASE": [
                    1987,
                    35,
                    70,
                    78,
                    61
                ],
                "_UID_PREFIXES": [
                    56,
                    36,
                    55
                ],
                "defaultdict": [
                    36
                ],
                "int": [
                    771,
                    36,
                    1542,
                    711,
                    103,
                    553,
                    1544,
                    2121,
                    2441,
                    2385,
                    2449,
                    695
                ],
                "grad_parameter_dict": [
                    952,
                    41,
                    1877,
                    1878
                ],
                "NAME_SCOPE_STACK": [
                    352,
                    49,
                    43,
                    51
                ],
                "NAME_SCOPE_STACK.append": [
                    49
                ],
                "name": [
                    276,
                    277,
                    285,
                    157,
                    158,
                    417,
                    418,
                    2467,
                    2216,
                    2217,
                    2218,
                    427,
                    49,
                    183,
                    448,
                    449,
                    2497,
                    457,
                    2523,
                    353,
                    355,
                    366,
                    497,
                    504,
                    2426,
                    510
                ],
                "NAME_SCOPE_STACK.pop": [
                    51
                ],
                "contextmanager": [
                    46
                ],
                "prefix": [
                    352,
                    354,
                    355,
                    55,
                    56
                ],
                "value": [
                    1932,
                    1934,
                    1935,
                    1936,
                    1937,
                    1940,
                    1944,
                    1949,
                    1950,
                    161,
                    163,
                    932,
                    165,
                    169,
                    170,
                    172,
                    173,
                    174,
                    181,
                    66,
                    69,
                    70,
                    2121,
                    2122,
                    2123,
                    1997,
                    1998,
                    2138,
                    2139,
                    2140,
                    2142,
                    363
                ],
                "ValueError": [
                    136,
                    393,
                    1803,
                    524,
                    271,
                    1170,
                    1945,
                    1187,
                    1574,
                    1959,
                    1832,
                    1577,
                    559,
                    306,
                    1978,
                    1727,
                    67,
                    2246,
                    199,
                    1351,
                    1611,
                    1614,
                    466,
                    1239,
                    1881,
                    1754,
                    1243,
                    2011,
                    1502,
                    742,
                    1641,
                    1644,
                    1772,
                    2158,
                    2033,
                    246,
                    1526,
                    1148,
                    1661,
                    383
                ],
                "_LEARNING_PHASE_PLACEHOLDER.value": [
                    1987,
                    1940,
                    79
                ],
                "np.asarray": [
                    2439,
                    2440,
                    79,
                    2447,
                    2448,
                    1940,
                    2140
                ],
                "training": [
                    98,
                    103,
                    104,
                    106,
                    112,
                    84,
                    85
                ],
                "learning_phase": [
                    85
                ],
                "uses_learning_phase": [
                    1304,
                    1336,
                    99,
                    1348,
                    1464,
                    107,
                    1434,
                    1236,
                    86,
                    88,
                    1274
                ],
                "callable": [
                    93,
                    95
                ],
                "x": [
                    1536,
                    2048,
                    514,
                    518,
                    1033,
                    522,
                    2060,
                    1551,
                    528,
                    2063,
                    2066,
                    533,
                    1046,
                    1531,
                    1557,
                    537,
                    2075,
                    1052,
                    1565,
                    2041,
                    2076,
                    544,
                    1056,
                    546,
                    1568,
                    1569,
                    2042,
                    550,
                    2087,
                    2088,
                    2089,
                    1578,
                    1581,
                    1582,
                    1585,
                    1074,
                    1586,
                    1076,
                    565,
                    2098,
                    2100,
                    568,
                    1081,
                    1593,
                    2102,
                    2104,
                    2109,
                    574,
                    1086,
                    2110,
                    1089,
                    578,
                    579,
                    1602,
                    1605,
                    1606,
                    2111,
                    2112,
                    585,
                    2114,
                    2119,
                    2120,
                    2122,
                    1102,
                    1615,
                    2123,
                    593,
                    1618,
                    1107,
                    1108,
                    1621,
                    1110,
                    2130,
                    2137,
                    1114,
                    1115,
                    1628,
                    93,
                    94,
                    2141,
                    1120,
                    1121,
                    2142,
                    99,
                    100,
                    1635,
                    1638,
                    615,
                    104,
                    106,
                    1645,
                    112,
                    624,
                    625,
                    626,
                    1136,
                    1140,
                    630,
                    631,
                    1141,
                    1648,
                    1649,
                    1656,
                    637,
                    638,
                    2175,
                    1665,
                    1155,
                    644,
                    645,
                    1156,
                    1667,
                    1672,
                    2179,
                    1162,
                    651,
                    652,
                    1166,
                    1679,
                    2192,
                    658,
                    662,
                    663,
                    1177,
                    1690,
                    2203,
                    668,
                    1692,
                    1182,
                    2205,
                    672,
                    673,
                    1700,
                    2212,
                    679,
                    1191,
                    2217,
                    1194,
                    2218,
                    1197,
                    1711,
                    1713,
                    1714,
                    691,
                    2227,
                    2228,
                    1720,
                    1721,
                    699,
                    1212,
                    701,
                    1213,
                    1728,
                    193,
                    194,
                    707,
                    1217,
                    1220,
                    1221,
                    1737,
                    1226,
                    716,
                    717,
                    1740,
                    1741,
                    2252,
                    2253,
                    2077,
                    1747,
                    1748,
                    2263,
                    728,
                    729,
                    2264,
                    732,
                    1756,
                    736,
                    1761,
                    1762,
                    739,
                    1764,
                    2274,
                    1766,
                    1767,
                    2275,
                    2279,
                    2280,
                    237,
                    1774,
                    2286,
                    2287,
                    241,
                    242,
                    243,
                    244,
                    753,
                    1780,
                    1781,
                    1782,
                    761,
                    250,
                    1783,
                    1787,
                    2293,
                    2302,
                    1791,
                    2304,
                    2306,
                    1795,
                    2307,
                    2311,
                    2313,
                    792,
                    281,
                    797,
                    286,
                    287,
                    288,
                    289,
                    809,
                    301,
                    813,
                    814,
                    305,
                    307,
                    820,
                    309,
                    313,
                    825,
                    320,
                    321,
                    832,
                    323,
                    325,
                    837,
                    336,
                    337,
                    339,
                    340,
                    341,
                    2387,
                    2391,
                    857,
                    858,
                    347,
                    864,
                    865,
                    2401,
                    2405,
                    870,
                    874,
                    878,
                    882,
                    886,
                    890,
                    894,
                    898,
                    902,
                    912,
                    1425,
                    1430,
                    924,
                    928,
                    936,
                    937,
                    957,
                    1469,
                    961,
                    1474,
                    1475,
                    1476,
                    965,
                    1480,
                    969,
                    1481,
                    1482,
                    973,
                    977,
                    1492,
                    981,
                    1496,
                    985,
                    989,
                    993,
                    1505,
                    1507,
                    1000,
                    1513,
                    490,
                    1514,
                    2025,
                    1005,
                    2026,
                    2027,
                    2031,
                    1009,
                    1521,
                    1011,
                    1013,
                    1017,
                    1530,
                    1019,
                    2047
                ],
                "isinstance": [
                    769,
                    771,
                    773,
                    1542,
                    1544,
                    778,
                    1930,
                    160,
                    162,
                    169,
                    553,
                    558,
                    686,
                    688,
                    2097,
                    946,
                    2099,
                    695,
                    313,
                    2110,
                    2111,
                    1857,
                    711,
                    2119,
                    713,
                    2120,
                    1995,
                    2121,
                    2385,
                    1107,
                    2139,
                    93,
                    2141,
                    95,
                    609,
                    2148,
                    613,
                    103,
                    617,
                    620,
                    241,
                    243,
                    1397,
                    1142,
                    2297,
                    2299
                ],
                "C.cntk_py.Function": [
                    169,
                    241,
                    93,
                    95
                ],
                "C.cntk_py": [
                    1889,
                    169,
                    2443,
                    2508,
                    2478,
                    2511,
                    241,
                    2450,
                    2481,
                    93,
                    95
                ],
                "alt": [
                    96,
                    104,
                    106,
                    112,
                    95
                ],
                "x._uses_learning_phase": [
                    99,
                    287
                ],
                "bool": [
                    103
                ],
                "result": [
                    2184,
                    2185,
                    2442,
                    2443,
                    1816,
                    1818,
                    797,
                    799,
                    803,
                    679,
                    936,
                    681,
                    682,
                    937,
                    1964,
                    1967,
                    1968,
                    565,
                    566,
                    2108,
                    2112,
                    2114,
                    2115,
                    585,
                    588,
                    589,
                    104,
                    106,
                    107,
                    108
                ],
                "C.element_select": [
                    833,
                    2179,
                    106,
                    821,
                    2169,
                    1437
                ],
                "result._uses_learning_phase": [
                    107
                ],
                "in_train_phase": [
                    112
                ],
                "dtype": [
                    129,
                    131,
                    260,
                    133,
                    261,
                    387,
                    2435,
                    138,
                    401,
                    406,
                    407,
                    154,
                    283,
                    155,
                    412,
                    413,
                    415,
                    426,
                    2474,
                    173,
                    174,
                    178,
                    182,
                    438,
                    439,
                    443,
                    444,
                    446,
                    456,
                    2504,
                    462,
                    463,
                    473,
                    479,
                    480,
                    2529,
                    482,
                    503,
                    376,
                    486,
                    359,
                    360,
                    504,
                    365,
                    494,
                    495,
                    496,
                    497,
                    116,
                    501,
                    118,
                    502,
                    120,
                    377,
                    379,
                    508,
                    509,
                    510
                ],
                "np.float64": [
                    1936,
                    131,
                    119
                ],
                "np.float16": [
                    121,
                    133
                ],
                "floatx": [
                    407,
                    261,
                    360,
                    2122,
                    463,
                    495,
                    502,
                    439,
                    155,
                    509
                ],
                "C.variables.Constant": [
                    162,
                    2120,
                    243,
                    2101,
                    313,
                    2111
                ],
                "C.variables": [
                    162,
                    164,
                    2119,
                    2120,
                    243,
                    1107,
                    2099,
                    2101,
                    313,
                    314,
                    315,
                    2141,
                    2110,
                    2111
                ],
                "C.variables.Parameter": [
                    164,
                    2119,
                    2099,
                    1107,
                    243,
                    315,
                    2141,
                    2110
                ],
                "value.value": [
                    165
                ],
                "eval": [
                    2104,
                    170,
                    2114
                ],
                "shape": [
                    1074,
                    1076,
                    1081,
                    1086,
                    1106,
                    1108,
                    1112,
                    1121,
                    1124,
                    1126,
                    1127,
                    1131,
                    1133,
                    672,
                    674,
                    675,
                    676,
                    681,
                    1194,
                    172,
                    173,
                    1196,
                    691,
                    180,
                    696,
                    703,
                    705,
                    716,
                    205,
                    207,
                    719,
                    720,
                    722,
                    210,
                    212,
                    1233,
                    1234,
                    727,
                    216,
                    218,
                    1242,
                    221,
                    223,
                    736,
                    737,
                    1247,
                    227,
                    229,
                    232,
                    744,
                    234,
                    236,
                    237,
                    752,
                    1265,
                    262,
                    264,
                    267,
                    1296,
                    792,
                    794,
                    796,
                    286,
                    806,
                    808,
                    809,
                    320,
                    1344,
                    1345,
                    324,
                    327,
                    328,
                    339,
                    342,
                    343,
                    1368,
                    347,
                    348,
                    2402,
                    2405,
                    361,
                    362,
                    363,
                    2428,
                    381,
                    387,
                    391,
                    401,
                    422,
                    2473,
                    452,
                    464,
                    473,
                    2528,
                    485,
                    497,
                    504
                ],
                "hasattr": [
                    2400,
                    2052,
                    2279,
                    172,
                    301,
                    173,
                    1934,
                    336,
                    1457,
                    340,
                    309,
                    2301,
                    1469,
                    1918,
                    1375
                ],
                "value.shape": [
                    172,
                    1949
                ],
                "value.dtype": [
                    1936,
                    173,
                    1935
                ],
                "len": [
                    1416,
                    1801,
                    270,
                    1807,
                    274,
                    2070,
                    2071,
                    2072,
                    537,
                    794,
                    539,
                    540,
                    541,
                    542,
                    1309,
                    544,
                    1441,
                    674,
                    2076,
                    2081,
                    2082,
                    1830,
                    2083,
                    2084,
                    2088,
                    1322,
                    1836,
                    173,
                    557,
                    1967,
                    1329,
                    563,
                    696,
                    825,
                    570,
                    698,
                    1850,
                    1469,
                    1851,
                    193,
                    578,
                    323,
                    1345,
                    197,
                    837,
                    1093,
                    1858,
                    585,
                    586,
                    587,
                    1865,
                    719,
                    720,
                    722,
                    1234,
                    1112,
                    348,
                    605,
                    1888,
                    737,
                    1124,
                    1253,
                    1126,
                    1893,
                    2024,
                    2280,
                    2026,
                    1899,
                    2413,
                    1902,
                    1140,
                    1910,
                    765,
                    1279
                ],
                "value.astype": [
                    1937,
                    174
                ],
                "str": [
                    2246,
                    744,
                    561,
                    178,
                    307,
                    2161,
                    2162,
                    1754,
                    1949,
                    1727
                ],
                "v": [
                    1998,
                    1999,
                    2001,
                    2003,
                    180,
                    949,
                    950,
                    952,
                    184,
                    185,
                    186,
                    187
                ],
                "C.parameter": [
                    484,
                    451,
                    180,
                    421
                ],
                "_prepare_name": [
                    366,
                    183
                ],
                "v._keras_shape": [
                    184
                ],
                "v.shape": [
                    184,
                    950
                ],
                "v._uses_learning_phase": [
                    185
                ],
                "v.constraint": [
                    186
                ],
                "constraint": [
                    186
                ],
                "data_format": [
                    1536,
                    1541,
                    2054,
                    1672,
                    1161,
                    2317,
                    1547,
                    1165,
                    1677,
                    1679,
                    1680,
                    2065,
                    1170,
                    2190,
                    2192,
                    1557,
                    1558,
                    1686,
                    1176,
                    1561,
                    2073,
                    2193,
                    2199,
                    1181,
                    2077,
                    1187,
                    1700,
                    2085,
                    2212,
                    2089,
                    1706,
                    2346,
                    2222,
                    1711,
                    1585,
                    1591,
                    2360,
                    1593,
                    1594,
                    1597,
                    191,
                    1728,
                    1733,
                    1737,
                    2377,
                    203,
                    2251,
                    1487,
                    208,
                    2257,
                    1621,
                    214,
                    1495,
                    1626,
                    219,
                    1628,
                    1629,
                    1756,
                    225,
                    230,
                    1512,
                    1519,
                    1521,
                    1522,
                    1649,
                    1654,
                    1656,
                    1657
                ],
                "normalize_data_format": [
                    1541,
                    1733,
                    2085,
                    1706,
                    2346,
                    1677,
                    2190,
                    1487,
                    1519,
                    2317,
                    1654,
                    1591,
                    2073,
                    1626,
                    191
                ],
                "dims": [
                    224,
                    193,
                    194,
                    195,
                    1345,
                    1253,
                    198,
                    1350,
                    200,
                    1352,
                    202,
                    1234,
                    1140,
                    213,
                    1238,
                    1143,
                    1145
                ],
                "x.shape": [
                    522,
                    792,
                    537,
                    2076,
                    1568,
                    2088,
                    1194,
                    1581,
                    193,
                    194,
                    323,
                    578,
                    325,
                    1217,
                    1605,
                    2122,
                    339,
                    1114,
                    1115,
                    1638,
                    2026,
                    2031,
                    1648,
                    1780,
                    2042
                ],
                "C.InferredDimension": [
                    706,
                    194,
                    1923,
                    678,
                    808,
                    266,
                    523,
                    1135,
                    1106,
                    1114,
                    1211,
                    796
                ],
                "bias_dims": [
                    226,
                    197,
                    198,
                    231,
                    200,
                    204,
                    209,
                    215,
                    220
                ],
                "bias.shape": [
                    227,
                    197,
                    229,
                    232,
                    234,
                    236,
                    205,
                    207,
                    210,
                    212,
                    216,
                    218,
                    221,
                    223
                ],
                "bias": [
                    227,
                    197,
                    229,
                    232,
                    234,
                    236,
                    205,
                    237,
                    207,
                    210,
                    212,
                    216,
                    218,
                    221,
                    223
                ],
                "reshape": [
                    2374,
                    2313,
                    237,
                    1102,
                    2327,
                    2361,
                    2364
                ],
                "x.eval": [
                    242
                ],
                "x.value": [
                    2112,
                    2123,
                    244,
                    2102,
                    2142
                ],
                "type": [
                    250,
                    307
                ],
                "ndim": [
                    737,
                    741,
                    263,
                    264,
                    2155,
                    2156,
                    781,
                    751,
                    1074,
                    1011,
                    1076,
                    1086,
                    1081,
                    1019,
                    1022
                ],
                "tuple": [
                    769,
                    264,
                    1930,
                    268,
                    1420,
                    1044,
                    1302,
                    1430,
                    2040,
                    677,
                    558,
                    686,
                    1857,
                    706,
                    1219,
                    714,
                    720,
                    1106,
                    342,
                    2148,
                    1258,
                    1131,
                    1898,
                    1272,
                    1145,
                    2046
                ],
                "_": [
                    391,
                    264,
                    392,
                    522,
                    523,
                    1425,
                    794,
                    678,
                    808,
                    1198,
                    2351,
                    694,
                    695,
                    696,
                    702,
                    703,
                    706,
                    1988,
                    464,
                    465,
                    720,
                    1106,
                    2388,
                    2389,
                    2390,
                    1114,
                    1115,
                    1131,
                    1135,
                    1903,
                    381,
                    382
                ],
                "range": [
                    323,
                    1830,
                    264,
                    1801,
                    1131,
                    1198,
                    751,
                    720,
                    2354,
                    1011,
                    2324,
                    2355,
                    2166,
                    1143,
                    1145,
                    1019,
                    541
                ],
                "dynamic_dimension": [
                    266,
                    267
                ],
                "_get_cntk_version": [
                    600,
                    266,
                    2400
                ],
                "C.FreeDimension": [
                    706,
                    1923,
                    808,
                    266,
                    523,
                    1451,
                    1211,
                    1106,
                    1115,
                    796
                ],
                "cntk_shape": [
                    267,
                    268,
                    270,
                    274,
                    279,
                    282
                ],
                "s": [
                    1376,
                    1378,
                    1316,
                    1380,
                    1286,
                    1319,
                    1447,
                    1289,
                    267,
                    1427,
                    1428,
                    1437,
                    1373,
                    1374
                ],
                "dynamic_axis_num": [
                    274,
                    270,
                    279
                ],
                "C.input": [
                    281
                ],
                "_convert_string_dtype": [
                    482,
                    283,
                    496,
                    503,
                    379,
                    446,
                    415
                ],
                "sparse": [
                    284
                ],
                "x._keras_shape": [
                    1782,
                    337,
                    286
                ],
                "x._cntk_placeholder": [
                    288,
                    301
                ],
                "is_tensor": [
                    305
                ],
                "C.variables.Variable": [
                    314
                ],
                "C.ops.functions.Function": [
                    316
                ],
                "C.ops.functions": [
                    2514,
                    2484,
                    2455,
                    2424,
                    316
                ],
                "C.ops": [
                    1283,
                    1288,
                    1297,
                    2455,
                    1307,
                    1313,
                    1318,
                    1197,
                    2484,
                    316,
                    844,
                    2514,
                    601,
                    858,
                    604,
                    865,
                    1267,
                    2424,
                    1277
                ],
                "list": [
                    1153,
                    770,
                    773,
                    774,
                    2053,
                    2311,
                    1801,
                    778,
                    1930,
                    792,
                    541,
                    672,
                    1830,
                    558,
                    687,
                    688,
                    946,
                    691,
                    320,
                    1217,
                    713,
                    609,
                    2148,
                    617,
                    1133,
                    1011,
                    1397,
                    1142,
                    2038,
                    2297,
                    2044
                ],
                "int_shape": [
                    2311,
                    1416,
                    528,
                    2320,
                    538,
                    924,
                    672,
                    550,
                    551,
                    2350,
                    691,
                    320,
                    1344,
                    716,
                    1233,
                    347,
                    736,
                    1252,
                    1140,
                    2164,
                    1017
                ],
                "num_dynamic": [
                    1920,
                    321,
                    324,
                    327,
                    328,
                    1919
                ],
                "_get_dynamic_axis_num": [
                    2075,
                    673,
                    2087,
                    1456,
                    825,
                    1213,
                    701,
                    321,
                    837,
                    1354,
                    717,
                    1110,
                    1374,
                    739,
                    1256,
                    2025,
                    2286,
                    624,
                    1141,
                    2293,
                    1400,
                    1406
                ],
                "non_dyn_shape": [
                    328,
                    322,
                    325,
                    327
                ],
                "i": [
                    1145,
                    1922,
                    1923,
                    779,
                    781,
                    782,
                    783,
                    1293,
                    1295,
                    1296,
                    1297,
                    2324,
                    2325,
                    2326,
                    1277,
                    1307,
                    1195,
                    1196,
                    1197,
                    1323,
                    1325,
                    1200,
                    1329,
                    2354,
                    1331,
                    2356,
                    1333,
                    1334,
                    2357,
                    577,
                    578,
                    323,
                    324,
                    325,
                    579,
                    327,
                    580,
                    581,
                    582,
                    583,
                    584,
                    725,
                    726,
                    727,
                    1143,
                    729,
                    730,
                    1125,
                    1126,
                    1127,
                    1128,
                    1131,
                    751,
                    752,
                    1265,
                    1266,
                    1267,
                    756,
                    2166,
                    759,
                    2168,
                    761,
                    762,
                    765,
                    766,
                    767
                ],
                "non_dyn_shape.append": [
                    325,
                    327
                ],
                "tensor.is_sparse": [
                    332
                ],
                "tensor": [
                    1932,
                    332,
                    1939,
                    1944,
                    1949,
                    1950
                ],
                "dynamic_shape": [
                    341,
                    342
                ],
                "a": [
                    2304,
                    612,
                    613,
                    614,
                    902,
                    619,
                    620,
                    779,
                    558,
                    780,
                    781,
                    2062,
                    2064,
                    341,
                    2298,
                    2299,
                    2300,
                    2302
                ],
                "x.dynamic_axes": [
                    2280,
                    2287,
                    753,
                    1425,
                    341,
                    761,
                    1469
                ],
                "join": [
                    352
                ],
                "default": [
                    354
                ],
                "np_value": [
                    363,
                    364
                ],
                "np.ones": [
                    504,
                    363
                ],
                "const": [
                    368,
                    369,
                    364,
                    367
                ],
                "const._keras_shape": [
                    367
                ],
                "const.shape": [
                    367
                ],
                "const._uses_learning_phase": [
                    368
                ],
                "seed": [
                    387,
                    440,
                    455,
                    472,
                    425,
                    486,
                    398,
                    400,
                    401,
                    442,
                    373,
                    470,
                    375,
                    408,
                    473,
                    410,
                    477,
                    478
                ],
                "np.random.randint": [
                    410,
                    400,
                    375,
                    472,
                    442,
                    478
                ],
                "np.random": [
                    410,
                    400,
                    375,
                    472,
                    442,
                    478
                ],
                "C.random.bernoulli": [
                    387
                ],
                "C.random": [
                    401,
                    387,
                    473
                ],
                "p": [
                    1440,
                    1922,
                    387,
                    451,
                    421,
                    1923,
                    2053,
                    458,
                    428,
                    2062,
                    2063,
                    1427,
                    1428,
                    1439
                ],
                "C.random.uniform": [
                    401
                ],
                "minval": [
                    401
                ],
                "maxval": [
                    401
                ],
                "scale": [
                    424,
                    428,
                    420,
                    454
                ],
                "high": [
                    420
                ],
                "low": [
                    428,
                    420
                ],
                "C.initializer.uniform": [
                    423
                ],
                "C.initializer": [
                    485,
                    453,
                    423
                ],
                "variable": [
                    932,
                    458,
                    428,
                    497,
                    504,
                    510
                ],
                "p.value": [
                    458,
                    428
                ],
                "C.initializer.normal": [
                    453
                ],
                "mean": [
                    1089,
                    1028,
                    1061,
                    1064,
                    458,
                    1067,
                    1040,
                    1009,
                    1074,
                    1075,
                    1013,
                    662,
                    664,
                    473,
                    1085
                ],
                "C.random.normal": [
                    473
                ],
                "stddev": [
                    473,
                    486
                ],
                "C.initializer.truncated_normal": [
                    485
                ],
                "_convert_dtype_string": [
                    490
                ],
                "x.dtype": [
                    490
                ],
                "ctype": [
                    496,
                    497,
                    504,
                    503
                ],
                "np.zeros": [
                    497
                ],
                "np.eye": [
                    510
                ],
                "size": [
                    510
                ],
                "zeros_like": [
                    1280,
                    836,
                    518,
                    1005,
                    1007,
                    824,
                    1085,
                    1310
                ],
                "np.prod": [
                    2439,
                    2440,
                    2447,
                    528,
                    2448,
                    1780
                ],
                "y.shape": [
                    585,
                    537,
                    586
                ],
                "y": [
                    537,
                    538,
                    543,
                    544,
                    546,
                    551,
                    565,
                    568,
                    571,
                    957,
                    575,
                    961,
                    965,
                    583,
                    585,
                    586,
                    969,
                    973,
                    977,
                    981,
                    985
                ],
                "y_shape": [
                    544,
                    551,
                    587,
                    557,
                    563,
                    570,
                    538,
                    539,
                    540,
                    541,
                    542
                ],
                "permutation": [
                    1810,
                    1811,
                    1812,
                    1813,
                    1814,
                    540,
                    541,
                    542,
                    543
                ],
                "C.transpose": [
                    2274,
                    1156,
                    2252,
                    2227,
                    2268,
                    1813,
                    1814,
                    1559,
                    2263,
                    1595,
                    2236,
                    1630,
                    543
                ],
                "C.times": [
                    544,
                    585,
                    546,
                    605
                ],
                "x_shape": [
                    1026,
                    550,
                    557,
                    563,
                    1017
                ],
                "axes": [
                    553,
                    554,
                    555,
                    557,
                    558,
                    561,
                    2385,
                    2386,
                    564,
                    565,
                    566,
                    1044,
                    568,
                    2387,
                    574,
                    575
                ],
                "sum": [
                    1824,
                    2372,
                    658,
                    820,
                    565,
                    568,
                    2335
                ],
                "transpose": [
                    568,
                    566
                ],
                "expand_dims": [
                    1254,
                    1417,
                    1327,
                    1551,
                    625,
                    1552,
                    1331,
                    1553,
                    2167,
                    571
                ],
                "normalized_axis": [
                    577,
                    581,
                    573,
                    574,
                    575
                ],
                "normalized_axis.append": [
                    574,
                    575
                ],
                "_normalize_axis": [
                    864,
                    1474,
                    1155,
                    644,
                    1191,
                    1097,
                    651,
                    813,
                    1009,
                    2387,
                    630,
                    857,
                    637,
                    574,
                    575
                ],
                "C.swapaxes": [
                    579,
                    583,
                    1513,
                    593,
                    1496,
                    1497
                ],
                "squeeze": [
                    1064,
                    1065,
                    588,
                    1586,
                    1299,
                    1269,
                    1308,
                    1278
                ],
                "C.ops.gather": [
                    601
                ],
                "reference": [
                    601,
                    603,
                    605
                ],
                "indices": [
                    601,
                    604,
                    2093
                ],
                "num_classes": [
                    603,
                    604,
                    2093
                ],
                "reference.shape": [
                    603,
                    605
                ],
                "one_hot_matrix": [
                    604,
                    605
                ],
                "C.ops.one_hot": [
                    604
                ],
                "keepdims": [
                    640,
                    609,
                    832,
                    647,
                    654,
                    816,
                    658,
                    820,
                    664,
                    633,
                    668
                ],
                "axis": [
                    1024,
                    1026,
                    1048,
                    1049,
                    1053,
                    1054,
                    1057,
                    1058,
                    2047,
                    1096,
                    1097,
                    1098,
                    609,
                    612,
                    617,
                    619,
                    630,
                    631,
                    633,
                    637,
                    638,
                    640,
                    1153,
                    1154,
                    1155,
                    644,
                    645,
                    1156,
                    647,
                    651,
                    652,
                    654,
                    658,
                    662,
                    664,
                    668,
                    674,
                    1191,
                    1192,
                    1196,
                    1197,
                    686,
                    687,
                    688,
                    689,
                    1201,
                    694,
                    2297,
                    2298,
                    1787,
                    769,
                    770,
                    771,
                    772,
                    773,
                    774,
                    2306,
                    776,
                    1800,
                    794,
                    1829,
                    813,
                    814,
                    816,
                    1840,
                    820,
                    832,
                    856,
                    857,
                    858,
                    859,
                    863,
                    864,
                    865,
                    866,
                    1473,
                    1474,
                    1475,
                    2039,
                    2041,
                    1019,
                    1020,
                    2045,
                    1022,
                    1023
                ],
                "reduce_axes": [
                    611,
                    614,
                    615
                ],
                "C.Axis": [
                    613,
                    2470,
                    620,
                    2287,
                    786,
                    852,
                    2299,
                    2300,
                    2431
                ],
                "reduce_axes.append": [
                    614
                ],
                "_reshape_dummy_dim": [
                    866,
                    615,
                    1075,
                    1077,
                    1082,
                    859,
                    1087
                ],
                "has_seq": [
                    618,
                    621,
                    623
                ],
                "nones": [
                    673,
                    705,
                    739,
                    676,
                    741,
                    680,
                    744,
                    1256,
                    1262,
                    624,
                    625,
                    752,
                    758,
                    760,
                    701,
                    766
                ],
                "output": [
                    640,
                    1280,
                    1283,
                    645,
                    1273,
                    647,
                    1801,
                    1162,
                    1163,
                    652,
                    1164,
                    654,
                    1166,
                    1167,
                    1168,
                    1291,
                    1807,
                    917,
                    918,
                    919,
                    920,
                    1177,
                    1178,
                    1179,
                    1180,
                    1301,
                    1182,
                    1183,
                    1184,
                    1185,
                    1303,
                    1310,
                    1313,
                    1813,
                    1821,
                    1823,
                    1824,
                    1321,
                    1830,
                    1836,
                    1837,
                    814,
                    1839,
                    816,
                    1816,
                    1840,
                    2370,
                    2372,
                    2374,
                    2379,
                    2381,
                    847,
                    858,
                    859,
                    2333,
                    865,
                    866,
                    2335,
                    2337,
                    631,
                    633,
                    1271,
                    638
                ],
                "_reduce_on_axis": [
                    645,
                    652,
                    814,
                    631,
                    638
                ],
                "_remove_dims": [
                    640,
                    647,
                    654,
                    816,
                    633
                ],
                "log": [
                    658
                ],
                "exp": [
                    658
                ],
                "m": [
                    1436,
                    1437,
                    662,
                    663
                ],
                "devs_squared": [
                    664,
                    663
                ],
                "C.square": [
                    1056,
                    1475,
                    1060,
                    870,
                    663
                ],
                "C.sqrt": [
                    1089,
                    1475,
                    668,
                    878
                ],
                "var": [
                    1089,
                    1076,
                    1077,
                    1080,
                    668
                ],
                "index": [
                    801,
                    674,
                    675,
                    802,
                    805,
                    806,
                    1218,
                    680,
                    1222,
                    1214,
                    1213,
                    798
                ],
                "shape.insert": [
                    675
                ],
                "new_shape": [
                    705,
                    706,
                    707,
                    676,
                    677,
                    678,
                    679,
                    1217,
                    1218,
                    1219,
                    1220,
                    1133,
                    1134,
                    1135,
                    1136
                ],
                "C.reshape": [
                    1028,
                    1029,
                    1030,
                    1031,
                    2185,
                    1559,
                    1818,
                    799,
                    679,
                    809,
                    1839,
                    1595,
                    707,
                    1220,
                    1108,
                    1630,
                    2402,
                    1136,
                    1781
                ],
                "result._keras_shape": [
                    681
                ],
                "_axis": [
                    770,
                    772,
                    774,
                    776,
                    778,
                    779,
                    781,
                    782,
                    783,
                    785,
                    786,
                    788,
                    794,
                    798,
                    805,
                    693,
                    696,
                    698,
                    702
                ],
                "_axis.append": [
                    696
                ],
                "sorted": [
                    1011,
                    805,
                    702,
                    798
                ],
                "n": [
                    1221,
                    711,
                    712,
                    713,
                    714,
                    719,
                    720,
                    722,
                    726,
                    1211,
                    1437
                ],
                "num_dynamic_axis": [
                    1154,
                    2058,
                    2064,
                    2075,
                    2076,
                    2077,
                    2087,
                    2088,
                    2089,
                    717,
                    725,
                    1110,
                    727,
                    1112,
                    729,
                    1124,
                    2025,
                    2026,
                    1131,
                    2027,
                    1134,
                    1141,
                    1147
                ],
                "NotImplementedError": [
                    2144,
                    1859,
                    1384,
                    2125,
                    723,
                    1172,
                    2395,
                    1215
                ],
                "rep": [
                    728,
                    1198,
                    726
                ],
                "enumerate": [
                    779,
                    726,
                    2062
                ],
                "tmp": [
                    728,
                    729,
                    1197,
                    1199
                ],
                "C.splice": [
                    1222,
                    1098,
                    1201,
                    1332,
                    729,
                    2041,
                    2047
                ],
                "cntk_axis": [
                    749,
                    783,
                    753,
                    756,
                    761,
                    765,
                    766
                ],
                "dynamic_axis_index": [
                    750,
                    752,
                    753,
                    754,
                    756,
                    758,
                    760,
                    761,
                    763
                ],
                "cntk_axis.append": [
                    753,
                    756
                ],
                "C.Axis.all_axes": [
                    786,
                    852
                ],
                "shape.count": [
                    796
                ],
                "reduce_result": [
                    832,
                    834,
                    835,
                    836,
                    837,
                    820,
                    822,
                    823,
                    824,
                    825
                ],
                "any_matrix": [
                    826,
                    828,
                    821
                ],
                "ones_like": [
                    835,
                    1000,
                    1002,
                    823,
                    1080
                ],
                "reduce_result.shape": [
                    825,
                    837
                ],
                "C.reduce_sum": [
                    826,
                    1475,
                    1821,
                    838
                ],
                "prod": [
                    832
                ],
                "all_matrix": [
                    840,
                    833,
                    838
                ],
                "C.ops.reduce_mean": [
                    844
                ],
                "C.equal": [
                    845,
                    957
                ],
                "argmax": [
                    849,
                    846
                ],
                "target": [
                    1824,
                    1837,
                    1839,
                    1840,
                    850,
                    1814,
                    919,
                    1816
                ],
                "C.ops.argmax": [
                    858
                ],
                "C.ops.argmin": [
                    865
                ],
                "C.abs": [
                    874,
                    1795,
                    898
                ],
                "C.exp": [
                    882
                ],
                "C.log": [
                    1824,
                    886,
                    919
                ],
                "C.round": [
                    890
                ],
                "C.sigmoid": [
                    917,
                    894
                ],
                "C.pow": [
                    902
                ],
                "max_value": [
                    1763,
                    1764,
                    906,
                    907,
                    908,
                    909,
                    912
                ],
                "min_value": [
                    906,
                    907,
                    910,
                    911,
                    912
                ],
                "np.inf": [
                    909,
                    911
                ],
                "C.clip": [
                    1764,
                    1481,
                    912,
                    918,
                    1823
                ],
                "from_logits": [
                    1840,
                    916,
                    1815
                ],
                "epsilon": [
                    1089,
                    1038,
                    1013,
                    918,
                    1823
                ],
                "C.assign": [
                    928,
                    937,
                    932,
                    1861
                ],
                "new_x": [
                    928
                ],
                "momentum": [
                    932
                ],
                "increment": [
                    936
                ],
                "variables": [
                    2148,
                    2149,
                    2151,
                    946,
                    947,
                    949
                ],
                "grads": [
                    1872,
                    948,
                    1876,
                    951,
                    953
                ],
                "g": [
                    1879,
                    1876,
                    1877,
                    950,
                    951,
                    952,
                    1878,
                    1886
                ],
                "grads.append": [
                    951
                ],
                "C.not_equal": [
                    961
                ],
                "C.greater": [
                    2179,
                    965
                ],
                "C.greater_equal": [
                    969
                ],
                "C.less": [
                    973
                ],
                "C.less_equal": [
                    977
                ],
                "C.element_max": [
                    981
                ],
                "C.element_min": [
                    985
                ],
                "C.sin": [
                    989
                ],
                "C.cos": [
                    993
                ],
                "gamma": [
                    1089,
                    998,
                    1030,
                    1000,
                    1002,
                    1004,
                    1007,
                    1013,
                    1079,
                    1080,
                    1081,
                    1082,
                    1022,
                    1023
                ],
                "beta": [
                    1024,
                    1089,
                    999,
                    1031,
                    1002,
                    1003,
                    1005,
                    1007,
                    1013,
                    1084,
                    1085,
                    1086,
                    1087
                ],
                "variant": [
                    1040,
                    1009,
                    1029,
                    1013
                ],
                "_moments": [
                    1009
                ],
                "reduction_axes": [
                    1009,
                    1011,
                    1020
                ],
                "normalized": [
                    1032,
                    1040,
                    1012
                ],
                "batch_normalization": [
                    1032,
                    1012
                ],
                "target_shape": [
                    1026,
                    1028,
                    1029,
                    1030,
                    1031,
                    1016,
                    1021
                ],
                "target_shape.append": [
                    1026,
                    1021
                ],
                "C.reduce_mean": [
                    1024,
                    1058,
                    1049,
                    1054,
                    1023
                ],
                "broadcast_mean": [
                    1034,
                    1028
                ],
                "broadcast_var": [
                    1035,
                    1029
                ],
                "broadcast_gamma": [
                    1037,
                    1030
                ],
                "broadcast_beta": [
                    1036,
                    1031
                ],
                "_axes": [
                    1057,
                    1064,
                    1065,
                    1044,
                    1048,
                    1053
                ],
                "shift": [
                    1056,
                    1061,
                    1045,
                    1046,
                    1049,
                    1051,
                    1052
                ],
                "C.stop_gradient": [
                    1051,
                    2149,
                    2151
                ],
                "shifted_mean": [
                    1060,
                    1052,
                    1061,
                    1054
                ],
                "C.minus": [
                    1056,
                    1052,
                    1060
                ],
                "variance_mean": [
                    1056,
                    1058,
                    1060
                ],
                "variance": [
                    1065,
                    1067,
                    1060
                ],
                "C.plus": [
                    1061
                ],
                "keep_dims": [
                    1063
                ],
                "tensors": [
                    1097,
                    1098,
                    1093
                ],
                "_reshape_batch": [
                    1121
                ],
                "pattern": [
                    1153,
                    2053,
                    2043,
                    2055,
                    2057,
                    2059,
                    2060,
                    2037,
                    1142,
                    2039,
                    1147,
                    2045,
                    1151
                ],
                "current_layout": [
                    1145,
                    1147,
                    1143
                ],
                "interpolation": [
                    1160
                ],
                "repeat_elements": [
                    1184,
                    1162,
                    1163,
                    1166,
                    1167,
                    1177,
                    1178,
                    1179,
                    1182,
                    1183
                ],
                "height_factor": [
                    1183,
                    1162,
                    1166,
                    1178
                ],
                "width_factor": [
                    1184,
                    1163,
                    1179,
                    1167
                ],
                "depth_factor": [
                    1177,
                    1182
                ],
                "slices": [
                    1193,
                    1201,
                    1199
                ],
                "C.ops.slice": [
                    1197,
                    1297,
                    1267,
                    1307,
                    1277
                ],
                "slices.append": [
                    1199
                ],
                "new_shape.insert": [
                    1218
                ],
                "temp": [
                    1221,
                    1222
                ],
                "C.tanh": [
                    1226
                ],
                "inputs": [
                    1344,
                    2020,
                    1382,
                    2361,
                    1256,
                    1354,
                    1930,
                    1388,
                    1357,
                    1932,
                    1233,
                    1297,
                    1267,
                    1846,
                    2327,
                    1369,
                    1370,
                    2364
                ],
                "constants": [
                    1248,
                    1249,
                    1411,
                    1361,
                    1396,
                    1365,
                    1302,
                    1366,
                    1272
                ],
                "mask": [
                    1251,
                    1252,
                    1413,
                    1254,
                    1415,
                    1416,
                    1417,
                    1418,
                    1445,
                    1360,
                    1306,
                    1307,
                    1276,
                    1277
                ],
                "mask_shape": [
                    1252,
                    1253
                ],
                "states": [
                    1316,
                    1445,
                    1286,
                    1258,
                    1322,
                    1292,
                    1420,
                    1425,
                    1427,
                    1302,
                    1272,
                    1337
                ],
                "initial_states": [
                    1258,
                    1373,
                    1358,
                    1455
                ],
                "outputs": [
                    1282,
                    1291,
                    1309,
                    1312,
                    1321,
                    1327,
                    1328,
                    1329,
                    1968,
                    1331,
                    1970,
                    1333,
                    1851,
                    1852,
                    1892,
                    1893,
                    1894,
                    2020,
                    1897,
                    1260,
                    1906,
                    1910,
                    1911,
                    1279
                ],
                "time_axis": [
                    1262,
                    1297,
                    1267,
                    1332,
                    1269,
                    1307,
                    1277,
                    1278
                ],
                "go_backwards": [
                    1414,
                    1383,
                    1390,
                    1359,
                    1264
                ],
                "current": [
                    1297,
                    1299,
                    1267,
                    1269,
                    1302,
                    1272
                ],
                "new_states": [
                    1316,
                    1286,
                    1320,
                    1290,
                    1322,
                    1292,
                    1301,
                    1429,
                    1271,
                    1437,
                    1439
                ],
                "step_function": [
                    1356,
                    1301,
                    1429,
                    1271
                ],
                "getattr": [
                    2304,
                    2306,
                    1303,
                    1432,
                    1273,
                    2302
                ],
                "mask_slice": [
                    1313,
                    1283,
                    1319,
                    1289,
                    1307,
                    1308,
                    1277,
                    1278
                ],
                "prev_output": [
                    1280,
                    1312,
                    1282,
                    1283,
                    1313,
                    1310
                ],
                "C.ops.element_select": [
                    1288,
                    1313,
                    1283,
                    1318
                ],
                "return_states": [
                    1315,
                    1317,
                    1285,
                    1287,
                    1320,
                    1290
                ],
                "n_s": [
                    1440,
                    1441,
                    1442,
                    1443,
                    1316,
                    1286,
                    1319,
                    1289,
                    1438
                ],
                "zip": [
                    1922,
                    1316,
                    1286,
                    1932,
                    1455,
                    1427,
                    1437,
                    1439
                ],
                "return_states.append": [
                    1317,
                    1287
                ],
                "outputs.append": [
                    1321,
                    1291
                ],
                "final_output": [
                    1445,
                    1446,
                    1450,
                    1465,
                    1452,
                    1327,
                    1332,
                    1337
                ],
                "last_output": [
                    1446,
                    1464,
                    1465,
                    1328,
                    1333,
                    1336,
                    1337
                ],
                "output_slice": [
                    1331,
                    1332
                ],
                "last_output._uses_learning_phase": [
                    1336,
                    1464
                ],
                "unroll": [
                    1354,
                    1362
                ],
                "_static_rnn": [
                    1355
                ],
                "input_length": [
                    1363
                ],
                "num_time_step": [
                    1451,
                    1452,
                    1368,
                    1369,
                    1370
                ],
                "has_seq_axis": [
                    1369,
                    1413,
                    1382
                ],
                "inputs.shape": [
                    1370
                ],
                "initial": [
                    1376,
                    1378,
                    1380,
                    1420,
                    1372
                ],
                "initial.append": [
                    1376,
                    1378,
                    1380
                ],
                "C.to_batch": [
                    1376,
                    2403
                ],
                "C.user_function": [
                    2129,
                    1378,
                    1460,
                    2405
                ],
                "ConvertToBatch": [
                    1378,
                    2467
                ],
                "need_convert": [
                    1449,
                    1389,
                    1382,
                    1383
                ],
                "rnn_inputs": [
                    1445,
                    1418,
                    1388,
                    1391,
                    1393,
                    1401,
                    1407
                ],
                "reverse": [
                    1415,
                    1391
                ],
                "C.to_sequence": [
                    1393
                ],
                "rnn_constants": [
                    1409,
                    1411,
                    1395,
                    1430,
                    1404,
                    1407
                ],
                "constant": [
                    1409,
                    1396,
                    1397,
                    1399,
                    1406,
                    1407
                ],
                "new_c": [
                    1401,
                    1403,
                    1404,
                    1398
                ],
                "c": [
                    1400,
                    1401,
                    1403,
                    1399
                ],
                "new_c.append": [
                    1401,
                    1403
                ],
                "C.sequence.broadcast_as": [
                    1401,
                    1407
                ],
                "C.sequence": [
                    1446,
                    1447,
                    1450,
                    1428,
                    1401,
                    2301,
                    2302,
                    1407
                ],
                "rnn_constants.append": [
                    1409,
                    1404,
                    1407
                ],
                "C.to_sequence_like": [
                    1418
                ],
                "C.default_options": [
                    1422
                ],
                "place_holders": [
                    1425,
                    1427,
                    1439
                ],
                "C.placeholder": [
                    1425
                ],
                "past_values": [
                    1426,
                    1428,
                    1437,
                    1430
                ],
                "past_values.append": [
                    1428
                ],
                "C.sequence.past_value": [
                    1428
                ],
                "new_output": [
                    1432,
                    1442,
                    1443,
                    1429
                ],
                "o": [
                    1440,
                    1996,
                    1997,
                    1969,
                    1970,
                    2002,
                    1439
                ],
                "n_s.append": [
                    1440
                ],
                "o.replace_placeholders": [
                    1440
                ],
                "o.output": [
                    1440
                ],
                "final_states": [
                    1445,
                    1447
                ],
                "_recurrence": [
                    1445
                ],
                "C.sequence.last": [
                    1446,
                    1447
                ],
                "last_states": [
                    1455,
                    1447
                ],
                "C.sequence.unpack": [
                    1450
                ],
                "_reshape_sequence": [
                    1452
                ],
                "f_stats": [
                    1454,
                    1458,
                    1460,
                    1462,
                    1465
                ],
                "l_s": [
                    1455,
                    1456,
                    1458,
                    1460,
                    1462
                ],
                "i_s": [
                    1456,
                    1460,
                    1455
                ],
                "f_stats.append": [
                    1458,
                    1460,
                    1462
                ],
                "C.unpack_batch": [
                    2401,
                    1458
                ],
                "ConvertToStatic": [
                    2497,
                    1460
                ],
                "i_s.shape": [
                    1460
                ],
                "norm": [
                    1475,
                    1476
                ],
                "padding": [
                    1669,
                    1681,
                    2194,
                    2070,
                    2071,
                    2072,
                    1562,
                    2077,
                    1567,
                    1696,
                    1697,
                    1698,
                    2081,
                    2082,
                    2083,
                    2084,
                    2209,
                    2210,
                    2089,
                    1580,
                    1708,
                    1718,
                    1725,
                    1598,
                    2241,
                    2242,
                    2243,
                    1604,
                    2244,
                    2246,
                    1735,
                    2247,
                    1489,
                    1617,
                    1745,
                    1493,
                    1752,
                    1499,
                    1632,
                    1509,
                    1637,
                    2024,
                    2027,
                    1647,
                    1523,
                    1658,
                    1533
                ],
                "left_pad": [
                    1491,
                    1492
                ],
                "dilation_rate": [
                    1670,
                    1544,
                    1545,
                    1555,
                    1564,
                    1573,
                    1600,
                    1610,
                    1616,
                    1491,
                    1501,
                    1503,
                    1633,
                    1510,
                    1640,
                    1646,
                    1525,
                    1528,
                    1660,
                    1534,
                    1663
                ],
                "kernel.shape": [
                    1491
                ],
                "kernel": [
                    1666,
                    1680,
                    2193,
                    2320,
                    2331,
                    1691,
                    2204,
                    2350,
                    2236,
                    2237,
                    2368,
                    1491,
                    1497,
                    2268,
                    2269,
                    1506,
                    1522,
                    1657,
                    1530
                ],
                "temporal_padding": [
                    1492
                ],
                "_preprocess_border_mode": [
                    1632,
                    1735,
                    1708,
                    1681,
                    2194,
                    1523,
                    1658,
                    1562,
                    1499,
                    1598
                ],
                "C.convolution": [
                    1505,
                    1569,
                    1602,
                    1635,
                    1665,
                    1606,
                    1578,
                    1645,
                    1582,
                    1615,
                    1618,
                    1530,
                    1565
                ],
                "strides": [
                    1668,
                    1542,
                    1543,
                    2319,
                    1554,
                    1682,
                    2195,
                    1693,
                    1566,
                    2206,
                    1576,
                    1579,
                    2348,
                    1709,
                    1717,
                    1724,
                    1601,
                    1603,
                    1613,
                    1744,
                    2390,
                    1751,
                    2391,
                    1634,
                    1508,
                    1636,
                    1643,
                    1532
                ],
                "_preprocess_conv2d_input": [
                    1711,
                    2192,
                    1521,
                    1557,
                    1593,
                    1628
                ],
                "_preprocess_conv2d_kernel": [
                    1629,
                    2193,
                    1522,
                    1558,
                    1561,
                    1594,
                    1597
                ],
                "_postprocess_conv2d_output": [
                    1536,
                    1728,
                    2212,
                    1585,
                    1649,
                    1621
                ],
                "spatial_start_dim": [
                    1586,
                    1548,
                    1550,
                    1551
                ],
                "depthwise_kernel": [
                    1602,
                    1635,
                    1629,
                    1578,
                    1645,
                    1615,
                    1552,
                    1558,
                    1559,
                    1560,
                    1594,
                    1595,
                    1596,
                    1565,
                    1630,
                    1631
                ],
                "pointwise_kernel": [
                    1569,
                    1606,
                    1582,
                    1553,
                    1618,
                    1561,
                    1597
                ],
                "depthwise_kernel.shape": [
                    1560,
                    1596,
                    1631
                ],
                "_preprocess_conv3d_input": [
                    1656,
                    1737,
                    1679
                ],
                "_preprocess_conv3d_kernel": [
                    1680,
                    1657
                ],
                "_postprocess_conv3d_output": [
                    1672,
                    1756,
                    1700
                ],
                "output_shape": [
                    1699,
                    2211,
                    2349,
                    1684,
                    2197,
                    1687,
                    2200
                ],
                "transpose_shape": [
                    2200,
                    1687
                ],
                "C.convolution_transpose": [
                    1690,
                    2203
                ],
                "pool_size": [
                    1710,
                    1743,
                    1716,
                    1750,
                    1723
                ],
                "pool_mode": [
                    1739,
                    1712,
                    1746,
                    1719,
                    1754,
                    1727
                ],
                "C.pooling": [
                    1720,
                    1713,
                    1747,
                    1740
                ],
                "C.MAX_POOLING": [
                    1715,
                    1742
                ],
                "C.AVG_POOLING": [
                    1722,
                    1749
                ],
                "alpha": [
                    1760,
                    2176,
                    2179,
                    1765,
                    1766
                ],
                "negative_part": [
                    1761,
                    1766
                ],
                "C.relu": [
                    1761,
                    1762
                ],
                "level": [
                    1771,
                    1773,
                    1774
                ],
                "C.dropout": [
                    1774
                ],
                "dim": [
                    2032,
                    1780,
                    1782
                ],
                "C.softmax": [
                    1787
                ],
                "C.softplus": [
                    1791
                ],
                "axis_without_batch": [
                    1829,
                    1831,
                    1800,
                    1802,
                    1834,
                    1805,
                    1837,
                    1838,
                    1809,
                    1810,
                    1811,
                    1812
                ],
                "output_dimensions": [
                    1830,
                    1831,
                    1801,
                    1802,
                    1809,
                    1810,
                    1811
                ],
                "output.shape": [
                    1830,
                    1801,
                    1836,
                    1837,
                    1807,
                    1839
                ],
                "format": [
                    1833,
                    1834,
                    1804,
                    1805,
                    1836,
                    1807
                ],
                "C.cross_entropy_with_softmax": [
                    1816
                ],
                "C.one_hot": [
                    2093,
                    1837,
                    2183
                ],
                "categorical_crossentropy": [
                    1840
                ],
                "object": [
                    1843
                ],
                "self.placeholders": [
                    1932,
                    1846
                ],
                "self": [
                    2434,
                    2435,
                    2439,
                    2440,
                    2442,
                    1932,
                    2447,
                    2448,
                    2452,
                    1944,
                    1953,
                    1955,
                    2467,
                    2473,
                    2474,
                    1964,
                    1965,
                    2426,
                    1969,
                    1972,
                    1846,
                    1847,
                    1848,
                    1849,
                    1974,
                    1852,
                    2497,
                    1986,
                    2498,
                    1988,
                    1990,
                    1991,
                    2503,
                    2504,
                    1994,
                    1996,
                    2002,
                    2005,
                    2007,
                    2520,
                    2521,
                    2523,
                    2015,
                    2528,
                    2529,
                    2530,
                    2533,
                    2534,
                    1896,
                    1898,
                    1903,
                    1905,
                    1906,
                    1907,
                    1911,
                    1912,
                    1914,
                    2427,
                    2428
                ],
                "self.trainer": [
                    1953,
                    1896,
                    1964,
                    1905,
                    1847
                ],
                "self.unrelated_updates": [
                    1986,
                    1903,
                    2005,
                    2007,
                    1848,
                    2015
                ],
                "self.updates": [
                    1849
                ],
                "updates": [
                    1856,
                    1849,
                    1850,
                    2020
                ],
                "self.loss": [
                    1955,
                    1852
                ],
                "u_ops": [
                    1866,
                    1899,
                    1900,
                    1870,
                    1854
                ],
                "unrelated_updates": [
                    1900,
                    1868,
                    1902,
                    1903,
                    1855
                ],
                "update": [
                    1856,
                    1857,
                    1858,
                    1861,
                    1863
                ],
                "u": [
                    1861,
                    1863,
                    1865,
                    1866,
                    1868,
                    1870
                ],
                "u.arguments": [
                    1865
                ],
                "u_ops.append": [
                    1866
                ],
                "unrelated_updates.append": [
                    1868
                ],
                "update_func": [
                    1872,
                    1889,
                    1870
                ],
                "C.combine": [
                    1912,
                    1907,
                    1870,
                    1903
                ],
                "u.output": [
                    1870
                ],
                "update_func.find_all_with_name": [
                    1872
                ],
                "u_list": [
                    1888,
                    1889,
                    1874,
                    1879
                ],
                "p_list": [
                    1889,
                    1875,
                    1878
                ],
                "p_list.append": [
                    1878
                ],
                "u_list.append": [
                    1879
                ],
                "learner": [
                    1889,
                    1897
                ],
                "C.cntk_py.universal_learner": [
                    1889
                ],
                "criterion": [
                    1897,
                    1898,
                    1891
                ],
                "C.trainer.Trainer": [
                    1896
                ],
                "C.trainer": [
                    1896
                ],
                "self.trainer_output": [
                    1969,
                    1898,
                    1965
                ],
                "f.output": [
                    1898,
                    1906,
                    1911
                ],
                "f": [
                    1898,
                    1906,
                    1911
                ],
                "unrelated_updates.extend": [
                    1900
                ],
                "_.output": [
                    1903
                ],
                "self.metrics_outputs": [
                    1996,
                    1906,
                    1907,
                    2002,
                    1911,
                    1912
                ],
                "self.metrics_func": [
                    1988,
                    1990,
                    1991,
                    1994,
                    1907,
                    1972,
                    1974,
                    1912,
                    1914
                ],
                "input": [
                    1920,
                    2497,
                    2498,
                    2467,
                    2426,
                    2427,
                    1918
                ],
                "placeholder": [
                    1921,
                    1918,
                    1919
                ],
                "get_num_dynamic_axis": [
                    1919
                ],
                "input_shape": [
                    1920,
                    1922
                ],
                "input.shape": [
                    1920,
                    2498,
                    2427
                ],
                "placeholder_shape": [
                    1921,
                    1922
                ],
                "placeholder.shape": [
                    1921
                ],
                "staticmethod": [
                    1916
                ],
                "feed_dict": [
                    1956,
                    1957,
                    1931,
                    2008,
                    1975,
                    1976,
                    2009,
                    1950
                ],
                "self._is_input_shape_compatible": [
                    1944
                ],
                "tensor.shape": [
                    1949
                ],
                "updated": [
                    1952,
                    2016,
                    1999,
                    1970,
                    2003
                ],
                "input_dict": [
                    1954,
                    1957,
                    1989,
                    1994,
                    1965,
                    1973,
                    2006,
                    1976,
                    2009,
                    2015
                ],
                "argument": [
                    1955,
                    1956,
                    1957,
                    2533,
                    2534,
                    2536,
                    1962,
                    2007,
                    2008,
                    1974,
                    1975,
                    1976,
                    2009,
                    1980,
                    2014
                ],
                "self.loss.arguments": [
                    1955
                ],
                "argument.name": [
                    1962,
                    1980,
                    2014
                ],
                "self.trainer.train_minibatch": [
                    1964
                ],
                "updated.append": [
                    1970,
                    2003,
                    1999
                ],
                "self.metrics_func.arguments": [
                    1974
                ],
                "output_values": [
                    1988,
                    1994,
                    1995,
                    1997,
                    2001
                ],
                "self.metrics_func.forward": [
                    1988
                ],
                "self.metrics_func.outputs": [
                    1990,
                    1991
                ],
                "self.metrics_func.eval": [
                    1994
                ],
                "dict": [
                    1995
                ],
                "value.asarray": [
                    1998
                ],
                "output_values.asarray": [
                    2001
                ],
                "self.unrelated_updates.arguments": [
                    2007
                ],
                "self.unrelated_updates.eval": [
                    2015
                ],
                "Function": [
                    2020
                ],
                "kwargs": [
                    2020
                ],
                "pad": [
                    2089,
                    2027,
                    2077
                ],
                "base_shape": [
                    2031,
                    2032,
                    2036,
                    2038,
                    2042,
                    2044
                ],
                "prefix_shape": [
                    2040,
                    2041,
                    2038,
                    2039
                ],
                "postfix_shape": [
                    2044,
                    2045,
                    2046,
                    2047
                ],
                "pad_info": [
                    2053,
                    2062
                ],
                "C.pad": [
                    2060
                ],
                "_padding": [
                    2063
                ],
                "xs": [
                    2361,
                    2352,
                    2323,
                    2327,
                    2329,
                    2364,
                    2109,
                    2366
                ],
                "result.append": [
                    2112,
                    2114
                ],
                "float": [
                    2416,
                    2121,
                    2421
                ],
                "np.full": [
                    2122
                ],
                "LambdaFunc": [
                    2130,
                    2523
                ],
                "print": [
                    2132,
                    2518
                ],
                "message": [
                    2132
                ],
                "t": [
                    2136,
                    2137,
                    2138
                ],
                "tuples": [
                    2136
                ],
                "np.ndarray": [
                    2139
                ],
                "map": [
                    2149
                ],
                "ndim_cond": [
                    2155,
                    2157,
                    2161,
                    2163,
                    2165,
                    2168
                ],
                "condition": [
                    2168,
                    2169,
                    2155,
                    2167
                ],
                "ndim_expr": [
                    2156,
                    2157,
                    2162,
                    2163,
                    2165
                ],
                "then_expression": [
                    2164,
                    2170,
                    2156
                ],
                "shape_expr": [
                    2168,
                    2164
                ],
                "ndim_diff": [
                    2165,
                    2166
                ],
                "tile": [
                    2168
                ],
                "else_expression": [
                    2171
                ],
                "res": [
                    2177,
                    2179,
                    2175
                ],
                "C.elu": [
                    2175
                ],
                "_targets": [
                    2184,
                    2183
                ],
                "targets": [
                    2183
                ],
                "predictions.shape": [
                    2183
                ],
                "predictions": [
                    2184,
                    2183
                ],
                "C.classification_error": [
                    2184
                ],
                "k": [
                    2184
                ],
                "x.name": [
                    2217
                ],
                "C.alias": [
                    2218
                ],
                "dim_ordering": [
                    2273
                ],
                "C.Axis.default_dynamic_axis": [
                    2287
                ],
                "C.Axis.default_batch_axis": [
                    2300,
                    2470,
                    2431
                ],
                "reduce_fun_name": [
                    2304,
                    2306,
                    2301,
                    2302
                ],
                "tmp_shape": [
                    2312,
                    2313,
                    2311
                ],
                "time_step": [
                    2312
                ],
                "stride": [
                    2325,
                    2326,
                    2319
                ],
                "kernel_shape": [
                    2320,
                    2321,
                    2350,
                    2351
                ],
                "output_length": [
                    2321,
                    2324
                ],
                "feature_dim": [
                    2351,
                    2321,
                    2328,
                    2362,
                    2365
                ],
                "filters": [
                    2321,
                    2375,
                    2351
                ],
                "slice_length": [
                    2325,
                    2327
                ],
                "kernel_size": [
                    2357,
                    2326,
                    2359
                ],
                "xs.append": [
                    2361,
                    2364,
                    2327
                ],
                "x_aggregate": [
                    2329,
                    2370,
                    2333,
                    2366
                ],
                "concatenate": [
                    2329,
                    2366
                ],
                "weight": [
                    2368,
                    2370,
                    2331,
                    2333
                ],
                "permute_dimensions": [
                    2368,
                    2337,
                    2379,
                    2331
                ],
                "stride_row": [
                    2348,
                    2357,
                    2356
                ],
                "stride_col": [
                    2348,
                    2358,
                    2359
                ],
                "output_row": [
                    2354,
                    2349,
                    2375
                ],
                "output_col": [
                    2355,
                    2349,
                    2375
                ],
                "j": [
                    2355,
                    2358,
                    2359
                ],
                "slice_row": [
                    2361,
                    2356,
                    2364
                ],
                "slice_col": [
                    2361,
                    2364,
                    2358
                ],
                "cntk_axes": [
                    2387,
                    2388,
                    2389,
                    2390,
                    2391
                ],
                "begin_index": [
                    2388,
                    2391
                ],
                "end_index": [
                    2389,
                    2391
                ],
                "C.slice": [
                    2391
                ],
                "const_a": [
                    2401,
                    2402,
                    2403
                ],
                "ReshapeBatch": [
                    2426,
                    2405
                ],
                "version": [
                    2409,
                    2410,
                    2411,
                    2413,
                    2414,
                    2416
                ],
                "C.__version__": [
                    2409
                ],
                "version.endswith": [
                    2410
                ],
                "replace": [
                    2414
                ],
                "C.ops.functions.UserFunction": [
                    2424,
                    2514,
                    2484,
                    2455
                ],
                "__init__": [
                    2497,
                    2426,
                    2467,
                    2523
                ],
                "super": [
                    2497,
                    2426,
                    2467,
                    2523
                ],
                "self.from_shape": [
                    2448,
                    2427,
                    2452,
                    2439
                ],
                "self.target_shape": [
                    2434,
                    2498,
                    2503,
                    2440,
                    2442,
                    2447,
                    2428
                ],
                "batch_axis": [
                    2475,
                    2436,
                    2470,
                    2431
                ],
                "C.output_variable": [
                    2472,
                    2433,
                    2502,
                    2527
                ],
                "self.inputs": [
                    2528,
                    2529,
                    2530,
                    2435,
                    2504,
                    2473,
                    2474
                ],
                "num_element": [
                    2447,
                    2441,
                    2449,
                    2439
                ],
                "arguments.shape": [
                    2439
                ],
                "arguments": [
                    2442,
                    2508,
                    2478,
                    2439
                ],
                "num_static_element": [
                    2440,
                    2441,
                    2449,
                    2448
                ],
                "num_batch": [
                    2441,
                    2442
                ],
                "as_shape": [
                    2442
                ],
                "arguments.data": [
                    2442,
                    2508,
                    2478
                ],
                "C.cntk_py.Value": [
                    2443,
                    2508,
                    2478,
                    2511,
                    2481,
                    2450
                ],
                "grad_array_view": [
                    2451,
                    2446
                ],
                "root_gradients.data": [
                    2481,
                    2446,
                    2511
                ],
                "root_gradients": [
                    2539,
                    2446,
                    2511,
                    2447,
                    2481
                ],
                "root_gradients.shape": [
                    2447
                ],
                "num_old_batch": [
                    2449,
                    2452
                ],
                "grad_array_view.as_shape": [
                    2451
                ],
                "batch_size": [
                    2498
                ],
                "arg": [
                    2523,
                    2518
                ],
                "self.when": [
                    2520,
                    2533
                ],
                "when": [
                    2520
                ],
                "self.execute": [
                    2521,
                    2534
                ],
                "execute": [
                    2521
                ],
                "dynamic_axes": [
                    2530
                ]
            },
            "filtered_variables_in_file": {
                "C.set_global_option": [
                    17
                ],
                "C": [
                    1024,
                    1028,
                    1029,
                    1030,
                    1031,
                    2052,
                    523,
                    2060,
                    17,
                    23,
                    1559,
                    1049,
                    1051,
                    1052,
                    1565,
                    1054,
                    543,
                    544,
                    33,
                    546,
                    1056,
                    1058,
                    1060,
                    1061,
                    1569,
                    1578,
                    2093,
                    1582,
                    2099,
                    2101,
                    1595,
                    2047,
                    2110,
                    2111,
                    1089,
                    1602,
                    579,
                    1606,
                    583,
                    2119,
                    585,
                    1098,
                    2120,
                    1615,
                    593,
                    1106,
                    1107,
                    1108,
                    1618,
                    2129,
                    601,
                    1114,
                    1115,
                    604,
                    93,
                    605,
                    95,
                    1630,
                    2141,
                    1635,
                    613,
                    2149,
                    2151,
                    106,
                    620,
                    1645,
                    1135,
                    1136,
                    2169,
                    2175,
                    1665,
                    2179,
                    1156,
                    2183,
                    2184,
                    2185,
                    663,
                    1690,
                    2203,
                    668,
                    162,
                    164,
                    678,
                    679,
                    169,
                    2218,
                    1197,
                    1201,
                    1713,
                    1715,
                    180,
                    2227,
                    1720,
                    1722,
                    1211,
                    2236,
                    194,
                    706,
                    707,
                    1220,
                    1222,
                    1226,
                    1740,
                    2252,
                    1742,
                    1747,
                    1749,
                    2263,
                    729,
                    2268,
                    1761,
                    1762,
                    2274,
                    1764,
                    1774,
                    2287,
                    241,
                    243,
                    1267,
                    1781,
                    1787,
                    2299,
                    1277,
                    2300,
                    1791,
                    2301,
                    2302,
                    2304,
                    1283,
                    1795,
                    2306,
                    1288,
                    266,
                    1297,
                    786,
                    1813,
                    1814,
                    1816,
                    281,
                    1818,
                    1307,
                    796,
                    1821,
                    799,
                    1823,
                    1313,
                    1824,
                    1318,
                    808,
                    809,
                    1837,
                    1839,
                    1332,
                    821,
                    313,
                    314,
                    315,
                    316,
                    826,
                    833,
                    1861,
                    838,
                    844,
                    845,
                    1870,
                    852,
                    2391,
                    858,
                    1375,
                    1376,
                    865,
                    1378,
                    1889,
                    2400,
                    2401,
                    870,
                    2402,
                    1896,
                    2403,
                    874,
                    2405,
                    364,
                    2409,
                    878,
                    1903,
                    1393,
                    882,
                    1907,
                    886,
                    1912,
                    1401,
                    890,
                    2424,
                    894,
                    1407,
                    2431,
                    2433,
                    898,
                    387,
                    1923,
                    902,
                    1418,
                    2443,
                    1422,
                    912,
                    401,
                    1425,
                    2450,
                    1428,
                    917,
                    918,
                    919,
                    2455,
                    1437,
                    928,
                    932,
                    421,
                    1446,
                    423,
                    1447,
                    937,
                    1450,
                    1451,
                    2470,
                    2472,
                    2478,
                    1457,
                    1458,
                    2481,
                    1460,
                    2484,
                    950,
                    957,
                    961,
                    451,
                    1475,
                    453,
                    965,
                    2502,
                    969,
                    1481,
                    2508,
                    973,
                    2511,
                    977,
                    2514,
                    981,
                    1496,
                    473,
                    985,
                    1497,
                    989,
                    2527,
                    993,
                    1505,
                    484,
                    485,
                    1513,
                    2041,
                    1530,
                    1023
                ],
                "b_any": [
                    2032,
                    1114,
                    19,
                    558
                ],
                "py_slice": [
                    2358,
                    20,
                    2325,
                    2356
                ],
                "dev": [
                    1525,
                    23,
                    24,
                    1660,
                    1501
                ],
                "C.device.use_default_device": [
                    23
                ],
                "C.device": [
                    23
                ],
                "dev.type": [
                    24,
                    1525,
                    1660,
                    1501
                ],
                "warnings.warn": [
                    25,
                    2418,
                    1116
                ],
                "warnings": [
                    25,
                    2418,
                    1116
                ],
                "_LEARNING_PHASE_PLACEHOLDER": [
                    33,
                    1987,
                    79,
                    1939,
                    1940,
                    61
                ],
                "C.constant": [
                    33,
                    364,
                    950,
                    2041,
                    2047
                ],
                "np.float32": [
                    480,
                    33,
                    129,
                    1935,
                    1937,
                    117,
                    377,
                    444,
                    125,
                    413
                ],
                "np": [
                    129,
                    131,
                    133,
                    2439,
                    2440,
                    909,
                    911,
                    400,
                    528,
                    1935,
                    1936,
                    1937,
                    1940,
                    2447,
                    2448,
                    410,
                    413,
                    33,
                    442,
                    444,
                    2122,
                    79,
                    472,
                    2139,
                    2140,
                    478,
                    375,
                    480,
                    121,
                    363,
                    497,
                    1780,
                    117,
                    119,
                    504,
                    377,
                    125,
                    510
                ],
                "_LEARNING_PHASE": [
                    1987,
                    35,
                    70,
                    78,
                    61
                ],
                "_UID_PREFIXES": [
                    56,
                    36,
                    55
                ],
                "defaultdict": [
                    36
                ],
                "grad_parameter_dict": [
                    952,
                    41,
                    1877,
                    1878
                ],
                "NAME_SCOPE_STACK": [
                    352,
                    49,
                    43,
                    51
                ],
                "NAME_SCOPE_STACK.append": [
                    49
                ],
                "name": [
                    276,
                    277,
                    285,
                    157,
                    158,
                    417,
                    418,
                    2467,
                    2216,
                    2217,
                    2218,
                    427,
                    49,
                    183,
                    448,
                    449,
                    2497,
                    457,
                    2523,
                    353,
                    355,
                    366,
                    497,
                    504,
                    2426,
                    510
                ],
                "NAME_SCOPE_STACK.pop": [
                    51
                ],
                "contextmanager": [
                    46
                ],
                "prefix": [
                    352,
                    354,
                    355,
                    55,
                    56
                ],
                "value": [
                    1932,
                    1934,
                    1935,
                    1936,
                    1937,
                    1940,
                    1944,
                    1949,
                    1950,
                    161,
                    163,
                    932,
                    165,
                    169,
                    170,
                    172,
                    173,
                    174,
                    181,
                    66,
                    69,
                    70,
                    2121,
                    2122,
                    2123,
                    1997,
                    1998,
                    2138,
                    2139,
                    2140,
                    2142,
                    363
                ],
                "_LEARNING_PHASE_PLACEHOLDER.value": [
                    1987,
                    1940,
                    79
                ],
                "np.asarray": [
                    2439,
                    2440,
                    79,
                    2447,
                    2448,
                    1940,
                    2140
                ],
                "training": [
                    98,
                    103,
                    104,
                    106,
                    112,
                    84,
                    85
                ],
                "learning_phase": [
                    85
                ],
                "uses_learning_phase": [
                    1304,
                    1336,
                    99,
                    1348,
                    1464,
                    107,
                    1434,
                    1236,
                    86,
                    88,
                    1274
                ],
                "x": [
                    1536,
                    2048,
                    514,
                    518,
                    1033,
                    522,
                    2060,
                    1551,
                    528,
                    2063,
                    2066,
                    533,
                    1046,
                    1531,
                    1557,
                    537,
                    2075,
                    1052,
                    1565,
                    2041,
                    2076,
                    544,
                    1056,
                    546,
                    1568,
                    1569,
                    2042,
                    550,
                    2087,
                    2088,
                    2089,
                    1578,
                    1581,
                    1582,
                    1585,
                    1074,
                    1586,
                    1076,
                    565,
                    2098,
                    2100,
                    568,
                    1081,
                    1593,
                    2102,
                    2104,
                    2109,
                    574,
                    1086,
                    2110,
                    1089,
                    578,
                    579,
                    1602,
                    1605,
                    1606,
                    2111,
                    2112,
                    585,
                    2114,
                    2119,
                    2120,
                    2122,
                    1102,
                    1615,
                    2123,
                    593,
                    1618,
                    1107,
                    1108,
                    1621,
                    1110,
                    2130,
                    2137,
                    1114,
                    1115,
                    1628,
                    93,
                    94,
                    2141,
                    1120,
                    1121,
                    2142,
                    99,
                    100,
                    1635,
                    1638,
                    615,
                    104,
                    106,
                    1645,
                    112,
                    624,
                    625,
                    626,
                    1136,
                    1140,
                    630,
                    631,
                    1141,
                    1648,
                    1649,
                    1656,
                    637,
                    638,
                    2175,
                    1665,
                    1155,
                    644,
                    645,
                    1156,
                    1667,
                    1672,
                    2179,
                    1162,
                    651,
                    652,
                    1166,
                    1679,
                    2192,
                    658,
                    662,
                    663,
                    1177,
                    1690,
                    2203,
                    668,
                    1692,
                    1182,
                    2205,
                    672,
                    673,
                    1700,
                    2212,
                    679,
                    1191,
                    2217,
                    1194,
                    2218,
                    1197,
                    1711,
                    1713,
                    1714,
                    691,
                    2227,
                    2228,
                    1720,
                    1721,
                    699,
                    1212,
                    701,
                    1213,
                    1728,
                    193,
                    194,
                    707,
                    1217,
                    1220,
                    1221,
                    1737,
                    1226,
                    716,
                    717,
                    1740,
                    1741,
                    2252,
                    2253,
                    2077,
                    1747,
                    1748,
                    2263,
                    728,
                    729,
                    2264,
                    732,
                    1756,
                    736,
                    1761,
                    1762,
                    739,
                    1764,
                    2274,
                    1766,
                    1767,
                    2275,
                    2279,
                    2280,
                    237,
                    1774,
                    2286,
                    2287,
                    241,
                    242,
                    243,
                    244,
                    753,
                    1780,
                    1781,
                    1782,
                    761,
                    250,
                    1783,
                    1787,
                    2293,
                    2302,
                    1791,
                    2304,
                    2306,
                    1795,
                    2307,
                    2311,
                    2313,
                    792,
                    281,
                    797,
                    286,
                    287,
                    288,
                    289,
                    809,
                    301,
                    813,
                    814,
                    305,
                    307,
                    820,
                    309,
                    313,
                    825,
                    320,
                    321,
                    832,
                    323,
                    325,
                    837,
                    336,
                    337,
                    339,
                    340,
                    341,
                    2387,
                    2391,
                    857,
                    858,
                    347,
                    864,
                    865,
                    2401,
                    2405,
                    870,
                    874,
                    878,
                    882,
                    886,
                    890,
                    894,
                    898,
                    902,
                    912,
                    1425,
                    1430,
                    924,
                    928,
                    936,
                    937,
                    957,
                    1469,
                    961,
                    1474,
                    1475,
                    1476,
                    965,
                    1480,
                    969,
                    1481,
                    1482,
                    973,
                    977,
                    1492,
                    981,
                    1496,
                    985,
                    989,
                    993,
                    1505,
                    1507,
                    1000,
                    1513,
                    490,
                    1514,
                    2025,
                    1005,
                    2026,
                    2027,
                    2031,
                    1009,
                    1521,
                    1011,
                    1013,
                    1017,
                    1530,
                    1019,
                    2047
                ],
                "C.cntk_py.Function": [
                    169,
                    241,
                    93,
                    95
                ],
                "C.cntk_py": [
                    1889,
                    169,
                    2443,
                    2508,
                    2478,
                    2511,
                    241,
                    2450,
                    2481,
                    93,
                    95
                ],
                "alt": [
                    96,
                    104,
                    106,
                    112,
                    95
                ],
                "x._uses_learning_phase": [
                    99,
                    287
                ],
                "result": [
                    2184,
                    2185,
                    2442,
                    2443,
                    1816,
                    1818,
                    797,
                    799,
                    803,
                    679,
                    936,
                    681,
                    682,
                    937,
                    1964,
                    1967,
                    1968,
                    565,
                    566,
                    2108,
                    2112,
                    2114,
                    2115,
                    585,
                    588,
                    589,
                    104,
                    106,
                    107,
                    108
                ],
                "C.element_select": [
                    833,
                    2179,
                    106,
                    821,
                    2169,
                    1437
                ],
                "result._uses_learning_phase": [
                    107
                ],
                "in_train_phase": [
                    112
                ],
                "dtype": [
                    129,
                    131,
                    260,
                    133,
                    261,
                    387,
                    2435,
                    138,
                    401,
                    406,
                    407,
                    154,
                    283,
                    155,
                    412,
                    413,
                    415,
                    426,
                    2474,
                    173,
                    174,
                    178,
                    182,
                    438,
                    439,
                    443,
                    444,
                    446,
                    456,
                    2504,
                    462,
                    463,
                    473,
                    479,
                    480,
                    2529,
                    482,
                    503,
                    376,
                    486,
                    359,
                    360,
                    504,
                    365,
                    494,
                    495,
                    496,
                    497,
                    116,
                    501,
                    118,
                    502,
                    120,
                    377,
                    379,
                    508,
                    509,
                    510
                ],
                "np.float64": [
                    1936,
                    131,
                    119
                ],
                "np.float16": [
                    121,
                    133
                ],
                "floatx": [
                    407,
                    261,
                    360,
                    2122,
                    463,
                    495,
                    502,
                    439,
                    155,
                    509
                ],
                "C.variables.Constant": [
                    162,
                    2120,
                    243,
                    2101,
                    313,
                    2111
                ],
                "C.variables": [
                    162,
                    164,
                    2119,
                    2120,
                    243,
                    1107,
                    2099,
                    2101,
                    313,
                    314,
                    315,
                    2141,
                    2110,
                    2111
                ],
                "C.variables.Parameter": [
                    164,
                    2119,
                    2099,
                    1107,
                    243,
                    315,
                    2141,
                    2110
                ],
                "value.value": [
                    165
                ],
                "shape": [
                    1074,
                    1076,
                    1081,
                    1086,
                    1106,
                    1108,
                    1112,
                    1121,
                    1124,
                    1126,
                    1127,
                    1131,
                    1133,
                    672,
                    674,
                    675,
                    676,
                    681,
                    1194,
                    172,
                    173,
                    1196,
                    691,
                    180,
                    696,
                    703,
                    705,
                    716,
                    205,
                    207,
                    719,
                    720,
                    722,
                    210,
                    212,
                    1233,
                    1234,
                    727,
                    216,
                    218,
                    1242,
                    221,
                    223,
                    736,
                    737,
                    1247,
                    227,
                    229,
                    232,
                    744,
                    234,
                    236,
                    237,
                    752,
                    1265,
                    262,
                    264,
                    267,
                    1296,
                    792,
                    794,
                    796,
                    286,
                    806,
                    808,
                    809,
                    320,
                    1344,
                    1345,
                    324,
                    327,
                    328,
                    339,
                    342,
                    343,
                    1368,
                    347,
                    348,
                    2402,
                    2405,
                    361,
                    362,
                    363,
                    2428,
                    381,
                    387,
                    391,
                    401,
                    422,
                    2473,
                    452,
                    464,
                    473,
                    2528,
                    485,
                    497,
                    504
                ],
                "value.shape": [
                    172,
                    1949
                ],
                "value.dtype": [
                    1936,
                    173,
                    1935
                ],
                "value.astype": [
                    1937,
                    174
                ],
                "v": [
                    1998,
                    1999,
                    2001,
                    2003,
                    180,
                    949,
                    950,
                    952,
                    184,
                    185,
                    186,
                    187
                ],
                "C.parameter": [
                    484,
                    451,
                    180,
                    421
                ],
                "_prepare_name": [
                    366,
                    183
                ],
                "v._keras_shape": [
                    184
                ],
                "v.shape": [
                    184,
                    950
                ],
                "v._uses_learning_phase": [
                    185
                ],
                "v.constraint": [
                    186
                ],
                "constraint": [
                    186
                ],
                "data_format": [
                    1536,
                    1541,
                    2054,
                    1672,
                    1161,
                    2317,
                    1547,
                    1165,
                    1677,
                    1679,
                    1680,
                    2065,
                    1170,
                    2190,
                    2192,
                    1557,
                    1558,
                    1686,
                    1176,
                    1561,
                    2073,
                    2193,
                    2199,
                    1181,
                    2077,
                    1187,
                    1700,
                    2085,
                    2212,
                    2089,
                    1706,
                    2346,
                    2222,
                    1711,
                    1585,
                    1591,
                    2360,
                    1593,
                    1594,
                    1597,
                    191,
                    1728,
                    1733,
                    1737,
                    2377,
                    203,
                    2251,
                    1487,
                    208,
                    2257,
                    1621,
                    214,
                    1495,
                    1626,
                    219,
                    1628,
                    1629,
                    1756,
                    225,
                    230,
                    1512,
                    1519,
                    1521,
                    1522,
                    1649,
                    1654,
                    1656,
                    1657
                ],
                "normalize_data_format": [
                    1541,
                    1733,
                    2085,
                    1706,
                    2346,
                    1677,
                    2190,
                    1487,
                    1519,
                    2317,
                    1654,
                    1591,
                    2073,
                    1626,
                    191
                ],
                "dims": [
                    224,
                    193,
                    194,
                    195,
                    1345,
                    1253,
                    198,
                    1350,
                    200,
                    1352,
                    202,
                    1234,
                    1140,
                    213,
                    1238,
                    1143,
                    1145
                ],
                "x.shape": [
                    522,
                    792,
                    537,
                    2076,
                    1568,
                    2088,
                    1194,
                    1581,
                    193,
                    194,
                    323,
                    578,
                    325,
                    1217,
                    1605,
                    2122,
                    339,
                    1114,
                    1115,
                    1638,
                    2026,
                    2031,
                    1648,
                    1780,
                    2042
                ],
                "C.InferredDimension": [
                    706,
                    194,
                    1923,
                    678,
                    808,
                    266,
                    523,
                    1135,
                    1106,
                    1114,
                    1211,
                    796
                ],
                "bias_dims": [
                    226,
                    197,
                    198,
                    231,
                    200,
                    204,
                    209,
                    215,
                    220
                ],
                "bias.shape": [
                    227,
                    197,
                    229,
                    232,
                    234,
                    236,
                    205,
                    207,
                    210,
                    212,
                    216,
                    218,
                    221,
                    223
                ],
                "bias": [
                    227,
                    197,
                    229,
                    232,
                    234,
                    236,
                    205,
                    237,
                    207,
                    210,
                    212,
                    216,
                    218,
                    221,
                    223
                ],
                "reshape": [
                    2374,
                    2313,
                    237,
                    1102,
                    2327,
                    2361,
                    2364
                ],
                "x.eval": [
                    242
                ],
                "x.value": [
                    2112,
                    2123,
                    244,
                    2102,
                    2142
                ],
                "ndim": [
                    737,
                    741,
                    263,
                    264,
                    2155,
                    2156,
                    781,
                    751,
                    1074,
                    1011,
                    1076,
                    1086,
                    1081,
                    1019,
                    1022
                ],
                "_": [
                    391,
                    264,
                    392,
                    522,
                    523,
                    1425,
                    794,
                    678,
                    808,
                    1198,
                    2351,
                    694,
                    695,
                    696,
                    702,
                    703,
                    706,
                    1988,
                    464,
                    465,
                    720,
                    1106,
                    2388,
                    2389,
                    2390,
                    1114,
                    1115,
                    1131,
                    1135,
                    1903,
                    381,
                    382
                ],
                "dynamic_dimension": [
                    266,
                    267
                ],
                "_get_cntk_version": [
                    600,
                    266,
                    2400
                ],
                "C.FreeDimension": [
                    706,
                    1923,
                    808,
                    266,
                    523,
                    1451,
                    1211,
                    1106,
                    1115,
                    796
                ],
                "cntk_shape": [
                    267,
                    268,
                    270,
                    274,
                    279,
                    282
                ],
                "s": [
                    1376,
                    1378,
                    1316,
                    1380,
                    1286,
                    1319,
                    1447,
                    1289,
                    267,
                    1427,
                    1428,
                    1437,
                    1373,
                    1374
                ],
                "dynamic_axis_num": [
                    274,
                    270,
                    279
                ],
                "C.input": [
                    281
                ],
                "_convert_string_dtype": [
                    482,
                    283,
                    496,
                    503,
                    379,
                    446,
                    415
                ],
                "sparse": [
                    284
                ],
                "x._keras_shape": [
                    1782,
                    337,
                    286
                ],
                "x._cntk_placeholder": [
                    288,
                    301
                ],
                "is_tensor": [
                    305
                ],
                "C.variables.Variable": [
                    314
                ],
                "C.ops.functions.Function": [
                    316
                ],
                "C.ops.functions": [
                    2514,
                    2484,
                    2455,
                    2424,
                    316
                ],
                "C.ops": [
                    1283,
                    1288,
                    1297,
                    2455,
                    1307,
                    1313,
                    1318,
                    1197,
                    2484,
                    316,
                    844,
                    2514,
                    601,
                    858,
                    604,
                    865,
                    1267,
                    2424,
                    1277
                ],
                "int_shape": [
                    2311,
                    1416,
                    528,
                    2320,
                    538,
                    924,
                    672,
                    550,
                    551,
                    2350,
                    691,
                    320,
                    1344,
                    716,
                    1233,
                    347,
                    736,
                    1252,
                    1140,
                    2164,
                    1017
                ],
                "num_dynamic": [
                    1920,
                    321,
                    324,
                    327,
                    328,
                    1919
                ],
                "_get_dynamic_axis_num": [
                    2075,
                    673,
                    2087,
                    1456,
                    825,
                    1213,
                    701,
                    321,
                    837,
                    1354,
                    717,
                    1110,
                    1374,
                    739,
                    1256,
                    2025,
                    2286,
                    624,
                    1141,
                    2293,
                    1400,
                    1406
                ],
                "non_dyn_shape": [
                    328,
                    322,
                    325,
                    327
                ],
                "i": [
                    1145,
                    1922,
                    1923,
                    779,
                    781,
                    782,
                    783,
                    1293,
                    1295,
                    1296,
                    1297,
                    2324,
                    2325,
                    2326,
                    1277,
                    1307,
                    1195,
                    1196,
                    1197,
                    1323,
                    1325,
                    1200,
                    1329,
                    2354,
                    1331,
                    2356,
                    1333,
                    1334,
                    2357,
                    577,
                    578,
                    323,
                    324,
                    325,
                    579,
                    327,
                    580,
                    581,
                    582,
                    583,
                    584,
                    725,
                    726,
                    727,
                    1143,
                    729,
                    730,
                    1125,
                    1126,
                    1127,
                    1128,
                    1131,
                    751,
                    752,
                    1265,
                    1266,
                    1267,
                    756,
                    2166,
                    759,
                    2168,
                    761,
                    762,
                    765,
                    766,
                    767
                ],
                "non_dyn_shape.append": [
                    325,
                    327
                ],
                "tensor.is_sparse": [
                    332
                ],
                "tensor": [
                    1932,
                    332,
                    1939,
                    1944,
                    1949,
                    1950
                ],
                "dynamic_shape": [
                    341,
                    342
                ],
                "a": [
                    2304,
                    612,
                    613,
                    614,
                    902,
                    619,
                    620,
                    779,
                    558,
                    780,
                    781,
                    2062,
                    2064,
                    341,
                    2298,
                    2299,
                    2300,
                    2302
                ],
                "x.dynamic_axes": [
                    2280,
                    2287,
                    753,
                    1425,
                    341,
                    761,
                    1469
                ],
                "join": [
                    352
                ],
                "default": [
                    354
                ],
                "np_value": [
                    363,
                    364
                ],
                "np.ones": [
                    504,
                    363
                ],
                "const": [
                    368,
                    369,
                    364,
                    367
                ],
                "const._keras_shape": [
                    367
                ],
                "const.shape": [
                    367
                ],
                "const._uses_learning_phase": [
                    368
                ],
                "seed": [
                    387,
                    440,
                    455,
                    472,
                    425,
                    486,
                    398,
                    400,
                    401,
                    442,
                    373,
                    470,
                    375,
                    408,
                    473,
                    410,
                    477,
                    478
                ],
                "np.random.randint": [
                    410,
                    400,
                    375,
                    472,
                    442,
                    478
                ],
                "np.random": [
                    410,
                    400,
                    375,
                    472,
                    442,
                    478
                ],
                "C.random.bernoulli": [
                    387
                ],
                "C.random": [
                    401,
                    387,
                    473
                ],
                "p": [
                    1440,
                    1922,
                    387,
                    451,
                    421,
                    1923,
                    2053,
                    458,
                    428,
                    2062,
                    2063,
                    1427,
                    1428,
                    1439
                ],
                "C.random.uniform": [
                    401
                ],
                "minval": [
                    401
                ],
                "maxval": [
                    401
                ],
                "scale": [
                    424,
                    428,
                    420,
                    454
                ],
                "high": [
                    420
                ],
                "low": [
                    428,
                    420
                ],
                "C.initializer.uniform": [
                    423
                ],
                "C.initializer": [
                    485,
                    453,
                    423
                ],
                "variable": [
                    932,
                    458,
                    428,
                    497,
                    504,
                    510
                ],
                "p.value": [
                    458,
                    428
                ],
                "C.initializer.normal": [
                    453
                ],
                "mean": [
                    1089,
                    1028,
                    1061,
                    1064,
                    458,
                    1067,
                    1040,
                    1009,
                    1074,
                    1075,
                    1013,
                    662,
                    664,
                    473,
                    1085
                ],
                "C.random.normal": [
                    473
                ],
                "stddev": [
                    473,
                    486
                ],
                "C.initializer.truncated_normal": [
                    485
                ],
                "_convert_dtype_string": [
                    490
                ],
                "x.dtype": [
                    490
                ],
                "ctype": [
                    496,
                    497,
                    504,
                    503
                ],
                "np.zeros": [
                    497
                ],
                "np.eye": [
                    510
                ],
                "size": [
                    510
                ],
                "zeros_like": [
                    1280,
                    836,
                    518,
                    1005,
                    1007,
                    824,
                    1085,
                    1310
                ],
                "np.prod": [
                    2439,
                    2440,
                    2447,
                    528,
                    2448,
                    1780
                ],
                "y.shape": [
                    585,
                    537,
                    586
                ],
                "y": [
                    537,
                    538,
                    543,
                    544,
                    546,
                    551,
                    565,
                    568,
                    571,
                    957,
                    575,
                    961,
                    965,
                    583,
                    585,
                    586,
                    969,
                    973,
                    977,
                    981,
                    985
                ],
                "y_shape": [
                    544,
                    551,
                    587,
                    557,
                    563,
                    570,
                    538,
                    539,
                    540,
                    541,
                    542
                ],
                "permutation": [
                    1810,
                    1811,
                    1812,
                    1813,
                    1814,
                    540,
                    541,
                    542,
                    543
                ],
                "C.transpose": [
                    2274,
                    1156,
                    2252,
                    2227,
                    2268,
                    1813,
                    1814,
                    1559,
                    2263,
                    1595,
                    2236,
                    1630,
                    543
                ],
                "C.times": [
                    544,
                    585,
                    546,
                    605
                ],
                "x_shape": [
                    1026,
                    550,
                    557,
                    563,
                    1017
                ],
                "axes": [
                    553,
                    554,
                    555,
                    557,
                    558,
                    561,
                    2385,
                    2386,
                    564,
                    565,
                    566,
                    1044,
                    568,
                    2387,
                    574,
                    575
                ],
                "transpose": [
                    568,
                    566
                ],
                "expand_dims": [
                    1254,
                    1417,
                    1327,
                    1551,
                    625,
                    1552,
                    1331,
                    1553,
                    2167,
                    571
                ],
                "normalized_axis": [
                    577,
                    581,
                    573,
                    574,
                    575
                ],
                "normalized_axis.append": [
                    574,
                    575
                ],
                "_normalize_axis": [
                    864,
                    1474,
                    1155,
                    644,
                    1191,
                    1097,
                    651,
                    813,
                    1009,
                    2387,
                    630,
                    857,
                    637,
                    574,
                    575
                ],
                "C.swapaxes": [
                    579,
                    583,
                    1513,
                    593,
                    1496,
                    1497
                ],
                "squeeze": [
                    1064,
                    1065,
                    588,
                    1586,
                    1299,
                    1269,
                    1308,
                    1278
                ],
                "C.ops.gather": [
                    601
                ],
                "reference": [
                    601,
                    603,
                    605
                ],
                "indices": [
                    601,
                    604,
                    2093
                ],
                "num_classes": [
                    603,
                    604,
                    2093
                ],
                "reference.shape": [
                    603,
                    605
                ],
                "one_hot_matrix": [
                    604,
                    605
                ],
                "C.ops.one_hot": [
                    604
                ],
                "keepdims": [
                    640,
                    609,
                    832,
                    647,
                    654,
                    816,
                    658,
                    820,
                    664,
                    633,
                    668
                ],
                "axis": [
                    1024,
                    1026,
                    1048,
                    1049,
                    1053,
                    1054,
                    1057,
                    1058,
                    2047,
                    1096,
                    1097,
                    1098,
                    609,
                    612,
                    617,
                    619,
                    630,
                    631,
                    633,
                    637,
                    638,
                    640,
                    1153,
                    1154,
                    1155,
                    644,
                    645,
                    1156,
                    647,
                    651,
                    652,
                    654,
                    658,
                    662,
                    664,
                    668,
                    674,
                    1191,
                    1192,
                    1196,
                    1197,
                    686,
                    687,
                    688,
                    689,
                    1201,
                    694,
                    2297,
                    2298,
                    1787,
                    769,
                    770,
                    771,
                    772,
                    773,
                    774,
                    2306,
                    776,
                    1800,
                    794,
                    1829,
                    813,
                    814,
                    816,
                    1840,
                    820,
                    832,
                    856,
                    857,
                    858,
                    859,
                    863,
                    864,
                    865,
                    866,
                    1473,
                    1474,
                    1475,
                    2039,
                    2041,
                    1019,
                    1020,
                    2045,
                    1022,
                    1023
                ],
                "reduce_axes": [
                    611,
                    614,
                    615
                ],
                "C.Axis": [
                    613,
                    2470,
                    620,
                    2287,
                    786,
                    852,
                    2299,
                    2300,
                    2431
                ],
                "reduce_axes.append": [
                    614
                ],
                "_reshape_dummy_dim": [
                    866,
                    615,
                    1075,
                    1077,
                    1082,
                    859,
                    1087
                ],
                "has_seq": [
                    618,
                    621,
                    623
                ],
                "nones": [
                    673,
                    705,
                    739,
                    676,
                    741,
                    680,
                    744,
                    1256,
                    1262,
                    624,
                    625,
                    752,
                    758,
                    760,
                    701,
                    766
                ],
                "output": [
                    640,
                    1280,
                    1283,
                    645,
                    1273,
                    647,
                    1801,
                    1162,
                    1163,
                    652,
                    1164,
                    654,
                    1166,
                    1167,
                    1168,
                    1291,
                    1807,
                    917,
                    918,
                    919,
                    920,
                    1177,
                    1178,
                    1179,
                    1180,
                    1301,
                    1182,
                    1183,
                    1184,
                    1185,
                    1303,
                    1310,
                    1313,
                    1813,
                    1821,
                    1823,
                    1824,
                    1321,
                    1830,
                    1836,
                    1837,
                    814,
                    1839,
                    816,
                    1816,
                    1840,
                    2370,
                    2372,
                    2374,
                    2379,
                    2381,
                    847,
                    858,
                    859,
                    2333,
                    865,
                    866,
                    2335,
                    2337,
                    631,
                    633,
                    1271,
                    638
                ],
                "_reduce_on_axis": [
                    645,
                    652,
                    814,
                    631,
                    638
                ],
                "_remove_dims": [
                    640,
                    647,
                    654,
                    816,
                    633
                ],
                "log": [
                    658
                ],
                "exp": [
                    658
                ],
                "m": [
                    1436,
                    1437,
                    662,
                    663
                ],
                "devs_squared": [
                    664,
                    663
                ],
                "C.square": [
                    1056,
                    1475,
                    1060,
                    870,
                    663
                ],
                "C.sqrt": [
                    1089,
                    1475,
                    668,
                    878
                ],
                "var": [
                    1089,
                    1076,
                    1077,
                    1080,
                    668
                ],
                "index": [
                    801,
                    674,
                    675,
                    802,
                    805,
                    806,
                    1218,
                    680,
                    1222,
                    1214,
                    1213,
                    798
                ],
                "shape.insert": [
                    675
                ],
                "new_shape": [
                    705,
                    706,
                    707,
                    676,
                    677,
                    678,
                    679,
                    1217,
                    1218,
                    1219,
                    1220,
                    1133,
                    1134,
                    1135,
                    1136
                ],
                "C.reshape": [
                    1028,
                    1029,
                    1030,
                    1031,
                    2185,
                    1559,
                    1818,
                    799,
                    679,
                    809,
                    1839,
                    1595,
                    707,
                    1220,
                    1108,
                    1630,
                    2402,
                    1136,
                    1781
                ],
                "result._keras_shape": [
                    681
                ],
                "_axis": [
                    770,
                    772,
                    774,
                    776,
                    778,
                    779,
                    781,
                    782,
                    783,
                    785,
                    786,
                    788,
                    794,
                    798,
                    805,
                    693,
                    696,
                    698,
                    702
                ],
                "_axis.append": [
                    696
                ],
                "n": [
                    1221,
                    711,
                    712,
                    713,
                    714,
                    719,
                    720,
                    722,
                    726,
                    1211,
                    1437
                ],
                "num_dynamic_axis": [
                    1154,
                    2058,
                    2064,
                    2075,
                    2076,
                    2077,
                    2087,
                    2088,
                    2089,
                    717,
                    725,
                    1110,
                    727,
                    1112,
                    729,
                    1124,
                    2025,
                    2026,
                    1131,
                    2027,
                    1134,
                    1141,
                    1147
                ],
                "rep": [
                    728,
                    1198,
                    726
                ],
                "tmp": [
                    728,
                    729,
                    1197,
                    1199
                ],
                "C.splice": [
                    1222,
                    1098,
                    1201,
                    1332,
                    729,
                    2041,
                    2047
                ],
                "cntk_axis": [
                    749,
                    783,
                    753,
                    756,
                    761,
                    765,
                    766
                ],
                "dynamic_axis_index": [
                    750,
                    752,
                    753,
                    754,
                    756,
                    758,
                    760,
                    761,
                    763
                ],
                "cntk_axis.append": [
                    753,
                    756
                ],
                "C.Axis.all_axes": [
                    786,
                    852
                ],
                "shape.count": [
                    796
                ],
                "reduce_result": [
                    832,
                    834,
                    835,
                    836,
                    837,
                    820,
                    822,
                    823,
                    824,
                    825
                ],
                "any_matrix": [
                    826,
                    828,
                    821
                ],
                "ones_like": [
                    835,
                    1000,
                    1002,
                    823,
                    1080
                ],
                "reduce_result.shape": [
                    825,
                    837
                ],
                "C.reduce_sum": [
                    826,
                    1475,
                    1821,
                    838
                ],
                "prod": [
                    832
                ],
                "all_matrix": [
                    840,
                    833,
                    838
                ],
                "C.ops.reduce_mean": [
                    844
                ],
                "C.equal": [
                    845,
                    957
                ],
                "argmax": [
                    849,
                    846
                ],
                "target": [
                    1824,
                    1837,
                    1839,
                    1840,
                    850,
                    1814,
                    919,
                    1816
                ],
                "C.ops.argmax": [
                    858
                ],
                "C.ops.argmin": [
                    865
                ],
                "C.abs": [
                    874,
                    1795,
                    898
                ],
                "C.exp": [
                    882
                ],
                "C.log": [
                    1824,
                    886,
                    919
                ],
                "C.round": [
                    890
                ],
                "C.sigmoid": [
                    917,
                    894
                ],
                "C.pow": [
                    902
                ],
                "max_value": [
                    1763,
                    1764,
                    906,
                    907,
                    908,
                    909,
                    912
                ],
                "min_value": [
                    906,
                    907,
                    910,
                    911,
                    912
                ],
                "np.inf": [
                    909,
                    911
                ],
                "C.clip": [
                    1764,
                    1481,
                    912,
                    918,
                    1823
                ],
                "from_logits": [
                    1840,
                    916,
                    1815
                ],
                "epsilon": [
                    1089,
                    1038,
                    1013,
                    918,
                    1823
                ],
                "C.assign": [
                    928,
                    937,
                    932,
                    1861
                ],
                "new_x": [
                    928
                ],
                "momentum": [
                    932
                ],
                "increment": [
                    936
                ],
                "variables": [
                    2148,
                    2149,
                    2151,
                    946,
                    947,
                    949
                ],
                "grads": [
                    1872,
                    948,
                    1876,
                    951,
                    953
                ],
                "g": [
                    1879,
                    1876,
                    1877,
                    950,
                    951,
                    952,
                    1878,
                    1886
                ],
                "grads.append": [
                    951
                ],
                "C.not_equal": [
                    961
                ],
                "C.greater": [
                    2179,
                    965
                ],
                "C.greater_equal": [
                    969
                ],
                "C.less": [
                    973
                ],
                "C.less_equal": [
                    977
                ],
                "C.element_max": [
                    981
                ],
                "C.element_min": [
                    985
                ],
                "C.sin": [
                    989
                ],
                "C.cos": [
                    993
                ],
                "gamma": [
                    1089,
                    998,
                    1030,
                    1000,
                    1002,
                    1004,
                    1007,
                    1013,
                    1079,
                    1080,
                    1081,
                    1082,
                    1022,
                    1023
                ],
                "beta": [
                    1024,
                    1089,
                    999,
                    1031,
                    1002,
                    1003,
                    1005,
                    1007,
                    1013,
                    1084,
                    1085,
                    1086,
                    1087
                ],
                "variant": [
                    1040,
                    1009,
                    1029,
                    1013
                ],
                "_moments": [
                    1009
                ],
                "reduction_axes": [
                    1009,
                    1011,
                    1020
                ],
                "normalized": [
                    1032,
                    1040,
                    1012
                ],
                "batch_normalization": [
                    1032,
                    1012
                ],
                "target_shape": [
                    1026,
                    1028,
                    1029,
                    1030,
                    1031,
                    1016,
                    1021
                ],
                "target_shape.append": [
                    1026,
                    1021
                ],
                "C.reduce_mean": [
                    1024,
                    1058,
                    1049,
                    1054,
                    1023
                ],
                "broadcast_mean": [
                    1034,
                    1028
                ],
                "broadcast_var": [
                    1035,
                    1029
                ],
                "broadcast_gamma": [
                    1037,
                    1030
                ],
                "broadcast_beta": [
                    1036,
                    1031
                ],
                "_axes": [
                    1057,
                    1064,
                    1065,
                    1044,
                    1048,
                    1053
                ],
                "shift": [
                    1056,
                    1061,
                    1045,
                    1046,
                    1049,
                    1051,
                    1052
                ],
                "C.stop_gradient": [
                    1051,
                    2149,
                    2151
                ],
                "shifted_mean": [
                    1060,
                    1052,
                    1061,
                    1054
                ],
                "C.minus": [
                    1056,
                    1052,
                    1060
                ],
                "variance_mean": [
                    1056,
                    1058,
                    1060
                ],
                "variance": [
                    1065,
                    1067,
                    1060
                ],
                "C.plus": [
                    1061
                ],
                "keep_dims": [
                    1063
                ],
                "tensors": [
                    1097,
                    1098,
                    1093
                ],
                "_reshape_batch": [
                    1121
                ],
                "pattern": [
                    1153,
                    2053,
                    2043,
                    2055,
                    2057,
                    2059,
                    2060,
                    2037,
                    1142,
                    2039,
                    1147,
                    2045,
                    1151
                ],
                "current_layout": [
                    1145,
                    1147,
                    1143
                ],
                "interpolation": [
                    1160
                ],
                "repeat_elements": [
                    1184,
                    1162,
                    1163,
                    1166,
                    1167,
                    1177,
                    1178,
                    1179,
                    1182,
                    1183
                ],
                "height_factor": [
                    1183,
                    1162,
                    1166,
                    1178
                ],
                "width_factor": [
                    1184,
                    1163,
                    1179,
                    1167
                ],
                "depth_factor": [
                    1177,
                    1182
                ],
                "slices": [
                    1193,
                    1201,
                    1199
                ],
                "C.ops.slice": [
                    1197,
                    1297,
                    1267,
                    1307,
                    1277
                ],
                "slices.append": [
                    1199
                ],
                "new_shape.insert": [
                    1218
                ],
                "temp": [
                    1221,
                    1222
                ],
                "C.tanh": [
                    1226
                ],
                "inputs": [
                    1344,
                    2020,
                    1382,
                    2361,
                    1256,
                    1354,
                    1930,
                    1388,
                    1357,
                    1932,
                    1233,
                    1297,
                    1267,
                    1846,
                    2327,
                    1369,
                    1370,
                    2364
                ],
                "constants": [
                    1248,
                    1249,
                    1411,
                    1361,
                    1396,
                    1365,
                    1302,
                    1366,
                    1272
                ],
                "mask": [
                    1251,
                    1252,
                    1413,
                    1254,
                    1415,
                    1416,
                    1417,
                    1418,
                    1445,
                    1360,
                    1306,
                    1307,
                    1276,
                    1277
                ],
                "mask_shape": [
                    1252,
                    1253
                ],
                "states": [
                    1316,
                    1445,
                    1286,
                    1258,
                    1322,
                    1292,
                    1420,
                    1425,
                    1427,
                    1302,
                    1272,
                    1337
                ],
                "initial_states": [
                    1258,
                    1373,
                    1358,
                    1455
                ],
                "outputs": [
                    1282,
                    1291,
                    1309,
                    1312,
                    1321,
                    1327,
                    1328,
                    1329,
                    1968,
                    1331,
                    1970,
                    1333,
                    1851,
                    1852,
                    1892,
                    1893,
                    1894,
                    2020,
                    1897,
                    1260,
                    1906,
                    1910,
                    1911,
                    1279
                ],
                "time_axis": [
                    1262,
                    1297,
                    1267,
                    1332,
                    1269,
                    1307,
                    1277,
                    1278
                ],
                "go_backwards": [
                    1414,
                    1383,
                    1390,
                    1359,
                    1264
                ],
                "current": [
                    1297,
                    1299,
                    1267,
                    1269,
                    1302,
                    1272
                ],
                "new_states": [
                    1316,
                    1286,
                    1320,
                    1290,
                    1322,
                    1292,
                    1301,
                    1429,
                    1271,
                    1437,
                    1439
                ],
                "step_function": [
                    1356,
                    1301,
                    1429,
                    1271
                ],
                "mask_slice": [
                    1313,
                    1283,
                    1319,
                    1289,
                    1307,
                    1308,
                    1277,
                    1278
                ],
                "prev_output": [
                    1280,
                    1312,
                    1282,
                    1283,
                    1313,
                    1310
                ],
                "C.ops.element_select": [
                    1288,
                    1313,
                    1283,
                    1318
                ],
                "return_states": [
                    1315,
                    1317,
                    1285,
                    1287,
                    1320,
                    1290
                ],
                "n_s": [
                    1440,
                    1441,
                    1442,
                    1443,
                    1316,
                    1286,
                    1319,
                    1289,
                    1438
                ],
                "return_states.append": [
                    1317,
                    1287
                ],
                "outputs.append": [
                    1321,
                    1291
                ],
                "final_output": [
                    1445,
                    1446,
                    1450,
                    1465,
                    1452,
                    1327,
                    1332,
                    1337
                ],
                "last_output": [
                    1446,
                    1464,
                    1465,
                    1328,
                    1333,
                    1336,
                    1337
                ],
                "output_slice": [
                    1331,
                    1332
                ],
                "last_output._uses_learning_phase": [
                    1336,
                    1464
                ],
                "unroll": [
                    1354,
                    1362
                ],
                "_static_rnn": [
                    1355
                ],
                "input_length": [
                    1363
                ],
                "num_time_step": [
                    1451,
                    1452,
                    1368,
                    1369,
                    1370
                ],
                "has_seq_axis": [
                    1369,
                    1413,
                    1382
                ],
                "inputs.shape": [
                    1370
                ],
                "initial": [
                    1376,
                    1378,
                    1380,
                    1420,
                    1372
                ],
                "initial.append": [
                    1376,
                    1378,
                    1380
                ],
                "C.to_batch": [
                    1376,
                    2403
                ],
                "C.user_function": [
                    2129,
                    1378,
                    1460,
                    2405
                ],
                "ConvertToBatch": [
                    1378,
                    2467
                ],
                "need_convert": [
                    1449,
                    1389,
                    1382,
                    1383
                ],
                "rnn_inputs": [
                    1445,
                    1418,
                    1388,
                    1391,
                    1393,
                    1401,
                    1407
                ],
                "reverse": [
                    1415,
                    1391
                ],
                "C.to_sequence": [
                    1393
                ],
                "rnn_constants": [
                    1409,
                    1411,
                    1395,
                    1430,
                    1404,
                    1407
                ],
                "constant": [
                    1409,
                    1396,
                    1397,
                    1399,
                    1406,
                    1407
                ],
                "new_c": [
                    1401,
                    1403,
                    1404,
                    1398
                ],
                "c": [
                    1400,
                    1401,
                    1403,
                    1399
                ],
                "new_c.append": [
                    1401,
                    1403
                ],
                "C.sequence.broadcast_as": [
                    1401,
                    1407
                ],
                "C.sequence": [
                    1446,
                    1447,
                    1450,
                    1428,
                    1401,
                    2301,
                    2302,
                    1407
                ],
                "rnn_constants.append": [
                    1409,
                    1404,
                    1407
                ],
                "C.to_sequence_like": [
                    1418
                ],
                "C.default_options": [
                    1422
                ],
                "place_holders": [
                    1425,
                    1427,
                    1439
                ],
                "C.placeholder": [
                    1425
                ],
                "past_values": [
                    1426,
                    1428,
                    1437,
                    1430
                ],
                "past_values.append": [
                    1428
                ],
                "C.sequence.past_value": [
                    1428
                ],
                "new_output": [
                    1432,
                    1442,
                    1443,
                    1429
                ],
                "o": [
                    1440,
                    1996,
                    1997,
                    1969,
                    1970,
                    2002,
                    1439
                ],
                "n_s.append": [
                    1440
                ],
                "o.replace_placeholders": [
                    1440
                ],
                "o.output": [
                    1440
                ],
                "final_states": [
                    1445,
                    1447
                ],
                "_recurrence": [
                    1445
                ],
                "C.sequence.last": [
                    1446,
                    1447
                ],
                "last_states": [
                    1455,
                    1447
                ],
                "C.sequence.unpack": [
                    1450
                ],
                "_reshape_sequence": [
                    1452
                ],
                "f_stats": [
                    1454,
                    1458,
                    1460,
                    1462,
                    1465
                ],
                "l_s": [
                    1455,
                    1456,
                    1458,
                    1460,
                    1462
                ],
                "i_s": [
                    1456,
                    1460,
                    1455
                ],
                "f_stats.append": [
                    1458,
                    1460,
                    1462
                ],
                "C.unpack_batch": [
                    2401,
                    1458
                ],
                "ConvertToStatic": [
                    2497,
                    1460
                ],
                "i_s.shape": [
                    1460
                ],
                "norm": [
                    1475,
                    1476
                ],
                "padding": [
                    1669,
                    1681,
                    2194,
                    2070,
                    2071,
                    2072,
                    1562,
                    2077,
                    1567,
                    1696,
                    1697,
                    1698,
                    2081,
                    2082,
                    2083,
                    2084,
                    2209,
                    2210,
                    2089,
                    1580,
                    1708,
                    1718,
                    1725,
                    1598,
                    2241,
                    2242,
                    2243,
                    1604,
                    2244,
                    2246,
                    1735,
                    2247,
                    1489,
                    1617,
                    1745,
                    1493,
                    1752,
                    1499,
                    1632,
                    1509,
                    1637,
                    2024,
                    2027,
                    1647,
                    1523,
                    1658,
                    1533
                ],
                "left_pad": [
                    1491,
                    1492
                ],
                "dilation_rate": [
                    1670,
                    1544,
                    1545,
                    1555,
                    1564,
                    1573,
                    1600,
                    1610,
                    1616,
                    1491,
                    1501,
                    1503,
                    1633,
                    1510,
                    1640,
                    1646,
                    1525,
                    1528,
                    1660,
                    1534,
                    1663
                ],
                "kernel.shape": [
                    1491
                ],
                "kernel": [
                    1666,
                    1680,
                    2193,
                    2320,
                    2331,
                    1691,
                    2204,
                    2350,
                    2236,
                    2237,
                    2368,
                    1491,
                    1497,
                    2268,
                    2269,
                    1506,
                    1522,
                    1657,
                    1530
                ],
                "temporal_padding": [
                    1492
                ],
                "_preprocess_border_mode": [
                    1632,
                    1735,
                    1708,
                    1681,
                    2194,
                    1523,
                    1658,
                    1562,
                    1499,
                    1598
                ],
                "C.convolution": [
                    1505,
                    1569,
                    1602,
                    1635,
                    1665,
                    1606,
                    1578,
                    1645,
                    1582,
                    1615,
                    1618,
                    1530,
                    1565
                ],
                "strides": [
                    1668,
                    1542,
                    1543,
                    2319,
                    1554,
                    1682,
                    2195,
                    1693,
                    1566,
                    2206,
                    1576,
                    1579,
                    2348,
                    1709,
                    1717,
                    1724,
                    1601,
                    1603,
                    1613,
                    1744,
                    2390,
                    1751,
                    2391,
                    1634,
                    1508,
                    1636,
                    1643,
                    1532
                ],
                "_preprocess_conv2d_input": [
                    1711,
                    2192,
                    1521,
                    1557,
                    1593,
                    1628
                ],
                "_preprocess_conv2d_kernel": [
                    1629,
                    2193,
                    1522,
                    1558,
                    1561,
                    1594,
                    1597
                ],
                "_postprocess_conv2d_output": [
                    1536,
                    1728,
                    2212,
                    1585,
                    1649,
                    1621
                ],
                "spatial_start_dim": [
                    1586,
                    1548,
                    1550,
                    1551
                ],
                "depthwise_kernel": [
                    1602,
                    1635,
                    1629,
                    1578,
                    1645,
                    1615,
                    1552,
                    1558,
                    1559,
                    1560,
                    1594,
                    1595,
                    1596,
                    1565,
                    1630,
                    1631
                ],
                "pointwise_kernel": [
                    1569,
                    1606,
                    1582,
                    1553,
                    1618,
                    1561,
                    1597
                ],
                "depthwise_kernel.shape": [
                    1560,
                    1596,
                    1631
                ],
                "_preprocess_conv3d_input": [
                    1656,
                    1737,
                    1679
                ],
                "_preprocess_conv3d_kernel": [
                    1680,
                    1657
                ],
                "_postprocess_conv3d_output": [
                    1672,
                    1756,
                    1700
                ],
                "output_shape": [
                    1699,
                    2211,
                    2349,
                    1684,
                    2197,
                    1687,
                    2200
                ],
                "transpose_shape": [
                    2200,
                    1687
                ],
                "C.convolution_transpose": [
                    1690,
                    2203
                ],
                "pool_size": [
                    1710,
                    1743,
                    1716,
                    1750,
                    1723
                ],
                "pool_mode": [
                    1739,
                    1712,
                    1746,
                    1719,
                    1754,
                    1727
                ],
                "C.pooling": [
                    1720,
                    1713,
                    1747,
                    1740
                ],
                "C.MAX_POOLING": [
                    1715,
                    1742
                ],
                "C.AVG_POOLING": [
                    1722,
                    1749
                ],
                "alpha": [
                    1760,
                    2176,
                    2179,
                    1765,
                    1766
                ],
                "negative_part": [
                    1761,
                    1766
                ],
                "C.relu": [
                    1761,
                    1762
                ],
                "level": [
                    1771,
                    1773,
                    1774
                ],
                "C.dropout": [
                    1774
                ],
                "dim": [
                    2032,
                    1780,
                    1782
                ],
                "C.softmax": [
                    1787
                ],
                "C.softplus": [
                    1791
                ],
                "axis_without_batch": [
                    1829,
                    1831,
                    1800,
                    1802,
                    1834,
                    1805,
                    1837,
                    1838,
                    1809,
                    1810,
                    1811,
                    1812
                ],
                "output_dimensions": [
                    1830,
                    1831,
                    1801,
                    1802,
                    1809,
                    1810,
                    1811
                ],
                "output.shape": [
                    1830,
                    1801,
                    1836,
                    1837,
                    1807,
                    1839
                ],
                "C.cross_entropy_with_softmax": [
                    1816
                ],
                "C.one_hot": [
                    2093,
                    1837,
                    2183
                ],
                "categorical_crossentropy": [
                    1840
                ],
                "self.placeholders": [
                    1932,
                    1846
                ],
                "self": [
                    2434,
                    2435,
                    2439,
                    2440,
                    2442,
                    1932,
                    2447,
                    2448,
                    2452,
                    1944,
                    1953,
                    1955,
                    2467,
                    2473,
                    2474,
                    1964,
                    1965,
                    2426,
                    1969,
                    1972,
                    1846,
                    1847,
                    1848,
                    1849,
                    1974,
                    1852,
                    2497,
                    1986,
                    2498,
                    1988,
                    1990,
                    1991,
                    2503,
                    2504,
                    1994,
                    1996,
                    2002,
                    2005,
                    2007,
                    2520,
                    2521,
                    2523,
                    2015,
                    2528,
                    2529,
                    2530,
                    2533,
                    2534,
                    1896,
                    1898,
                    1903,
                    1905,
                    1906,
                    1907,
                    1911,
                    1912,
                    1914,
                    2427,
                    2428
                ],
                "self.trainer": [
                    1953,
                    1896,
                    1964,
                    1905,
                    1847
                ],
                "self.unrelated_updates": [
                    1986,
                    1903,
                    2005,
                    2007,
                    1848,
                    2015
                ],
                "self.updates": [
                    1849
                ],
                "updates": [
                    1856,
                    1849,
                    1850,
                    2020
                ],
                "self.loss": [
                    1955,
                    1852
                ],
                "u_ops": [
                    1866,
                    1899,
                    1900,
                    1870,
                    1854
                ],
                "unrelated_updates": [
                    1900,
                    1868,
                    1902,
                    1903,
                    1855
                ],
                "update": [
                    1856,
                    1857,
                    1858,
                    1861,
                    1863
                ],
                "u": [
                    1861,
                    1863,
                    1865,
                    1866,
                    1868,
                    1870
                ],
                "u.arguments": [
                    1865
                ],
                "u_ops.append": [
                    1866
                ],
                "unrelated_updates.append": [
                    1868
                ],
                "update_func": [
                    1872,
                    1889,
                    1870
                ],
                "C.combine": [
                    1912,
                    1907,
                    1870,
                    1903
                ],
                "u.output": [
                    1870
                ],
                "update_func.find_all_with_name": [
                    1872
                ],
                "u_list": [
                    1888,
                    1889,
                    1874,
                    1879
                ],
                "p_list": [
                    1889,
                    1875,
                    1878
                ],
                "p_list.append": [
                    1878
                ],
                "u_list.append": [
                    1879
                ],
                "learner": [
                    1889,
                    1897
                ],
                "C.cntk_py.universal_learner": [
                    1889
                ],
                "criterion": [
                    1897,
                    1898,
                    1891
                ],
                "C.trainer.Trainer": [
                    1896
                ],
                "C.trainer": [
                    1896
                ],
                "self.trainer_output": [
                    1969,
                    1898,
                    1965
                ],
                "f.output": [
                    1898,
                    1906,
                    1911
                ],
                "f": [
                    1898,
                    1906,
                    1911
                ],
                "unrelated_updates.extend": [
                    1900
                ],
                "_.output": [
                    1903
                ],
                "self.metrics_outputs": [
                    1996,
                    1906,
                    1907,
                    2002,
                    1911,
                    1912
                ],
                "self.metrics_func": [
                    1988,
                    1990,
                    1991,
                    1994,
                    1907,
                    1972,
                    1974,
                    1912,
                    1914
                ],
                "placeholder": [
                    1921,
                    1918,
                    1919
                ],
                "get_num_dynamic_axis": [
                    1919
                ],
                "input_shape": [
                    1920,
                    1922
                ],
                "input.shape": [
                    1920,
                    2498,
                    2427
                ],
                "placeholder_shape": [
                    1921,
                    1922
                ],
                "placeholder.shape": [
                    1921
                ],
                "feed_dict": [
                    1956,
                    1957,
                    1931,
                    2008,
                    1975,
                    1976,
                    2009,
                    1950
                ],
                "self._is_input_shape_compatible": [
                    1944
                ],
                "tensor.shape": [
                    1949
                ],
                "updated": [
                    1952,
                    2016,
                    1999,
                    1970,
                    2003
                ],
                "input_dict": [
                    1954,
                    1957,
                    1989,
                    1994,
                    1965,
                    1973,
                    2006,
                    1976,
                    2009,
                    2015
                ],
                "argument": [
                    1955,
                    1956,
                    1957,
                    2533,
                    2534,
                    2536,
                    1962,
                    2007,
                    2008,
                    1974,
                    1975,
                    1976,
                    2009,
                    1980,
                    2014
                ],
                "self.loss.arguments": [
                    1955
                ],
                "argument.name": [
                    1962,
                    1980,
                    2014
                ],
                "self.trainer.train_minibatch": [
                    1964
                ],
                "updated.append": [
                    1970,
                    2003,
                    1999
                ],
                "self.metrics_func.arguments": [
                    1974
                ],
                "output_values": [
                    1988,
                    1994,
                    1995,
                    1997,
                    2001
                ],
                "self.metrics_func.forward": [
                    1988
                ],
                "self.metrics_func.outputs": [
                    1990,
                    1991
                ],
                "self.metrics_func.eval": [
                    1994
                ],
                "value.asarray": [
                    1998
                ],
                "output_values.asarray": [
                    2001
                ],
                "self.unrelated_updates.arguments": [
                    2007
                ],
                "self.unrelated_updates.eval": [
                    2015
                ],
                "Function": [
                    2020
                ],
                "kwargs": [
                    2020
                ],
                "pad": [
                    2089,
                    2027,
                    2077
                ],
                "base_shape": [
                    2031,
                    2032,
                    2036,
                    2038,
                    2042,
                    2044
                ],
                "prefix_shape": [
                    2040,
                    2041,
                    2038,
                    2039
                ],
                "postfix_shape": [
                    2044,
                    2045,
                    2046,
                    2047
                ],
                "pad_info": [
                    2053,
                    2062
                ],
                "C.pad": [
                    2060
                ],
                "_padding": [
                    2063
                ],
                "xs": [
                    2361,
                    2352,
                    2323,
                    2327,
                    2329,
                    2364,
                    2109,
                    2366
                ],
                "result.append": [
                    2112,
                    2114
                ],
                "np.full": [
                    2122
                ],
                "LambdaFunc": [
                    2130,
                    2523
                ],
                "message": [
                    2132
                ],
                "t": [
                    2136,
                    2137,
                    2138
                ],
                "tuples": [
                    2136
                ],
                "np.ndarray": [
                    2139
                ],
                "ndim_cond": [
                    2155,
                    2157,
                    2161,
                    2163,
                    2165,
                    2168
                ],
                "condition": [
                    2168,
                    2169,
                    2155,
                    2167
                ],
                "ndim_expr": [
                    2156,
                    2157,
                    2162,
                    2163,
                    2165
                ],
                "then_expression": [
                    2164,
                    2170,
                    2156
                ],
                "shape_expr": [
                    2168,
                    2164
                ],
                "ndim_diff": [
                    2165,
                    2166
                ],
                "tile": [
                    2168
                ],
                "else_expression": [
                    2171
                ],
                "res": [
                    2177,
                    2179,
                    2175
                ],
                "C.elu": [
                    2175
                ],
                "_targets": [
                    2184,
                    2183
                ],
                "targets": [
                    2183
                ],
                "predictions.shape": [
                    2183
                ],
                "predictions": [
                    2184,
                    2183
                ],
                "C.classification_error": [
                    2184
                ],
                "k": [
                    2184
                ],
                "x.name": [
                    2217
                ],
                "C.alias": [
                    2218
                ],
                "dim_ordering": [
                    2273
                ],
                "C.Axis.default_dynamic_axis": [
                    2287
                ],
                "C.Axis.default_batch_axis": [
                    2300,
                    2470,
                    2431
                ],
                "reduce_fun_name": [
                    2304,
                    2306,
                    2301,
                    2302
                ],
                "tmp_shape": [
                    2312,
                    2313,
                    2311
                ],
                "time_step": [
                    2312
                ],
                "stride": [
                    2325,
                    2326,
                    2319
                ],
                "kernel_shape": [
                    2320,
                    2321,
                    2350,
                    2351
                ],
                "output_length": [
                    2321,
                    2324
                ],
                "feature_dim": [
                    2351,
                    2321,
                    2328,
                    2362,
                    2365
                ],
                "filters": [
                    2321,
                    2375,
                    2351
                ],
                "slice_length": [
                    2325,
                    2327
                ],
                "kernel_size": [
                    2357,
                    2326,
                    2359
                ],
                "xs.append": [
                    2361,
                    2364,
                    2327
                ],
                "x_aggregate": [
                    2329,
                    2370,
                    2333,
                    2366
                ],
                "concatenate": [
                    2329,
                    2366
                ],
                "weight": [
                    2368,
                    2370,
                    2331,
                    2333
                ],
                "permute_dimensions": [
                    2368,
                    2337,
                    2379,
                    2331
                ],
                "stride_row": [
                    2348,
                    2357,
                    2356
                ],
                "stride_col": [
                    2348,
                    2358,
                    2359
                ],
                "output_row": [
                    2354,
                    2349,
                    2375
                ],
                "output_col": [
                    2355,
                    2349,
                    2375
                ],
                "j": [
                    2355,
                    2358,
                    2359
                ],
                "slice_row": [
                    2361,
                    2356,
                    2364
                ],
                "slice_col": [
                    2361,
                    2364,
                    2358
                ],
                "cntk_axes": [
                    2387,
                    2388,
                    2389,
                    2390,
                    2391
                ],
                "begin_index": [
                    2388,
                    2391
                ],
                "end_index": [
                    2389,
                    2391
                ],
                "C.slice": [
                    2391
                ],
                "const_a": [
                    2401,
                    2402,
                    2403
                ],
                "ReshapeBatch": [
                    2426,
                    2405
                ],
                "version": [
                    2409,
                    2410,
                    2411,
                    2413,
                    2414,
                    2416
                ],
                "C.__version__": [
                    2409
                ],
                "version.endswith": [
                    2410
                ],
                "replace": [
                    2414
                ],
                "C.ops.functions.UserFunction": [
                    2424,
                    2514,
                    2484,
                    2455
                ],
                "__init__": [
                    2497,
                    2426,
                    2467,
                    2523
                ],
                "self.from_shape": [
                    2448,
                    2427,
                    2452,
                    2439
                ],
                "self.target_shape": [
                    2434,
                    2498,
                    2503,
                    2440,
                    2442,
                    2447,
                    2428
                ],
                "batch_axis": [
                    2475,
                    2436,
                    2470,
                    2431
                ],
                "C.output_variable": [
                    2472,
                    2433,
                    2502,
                    2527
                ],
                "self.inputs": [
                    2528,
                    2529,
                    2530,
                    2435,
                    2504,
                    2473,
                    2474
                ],
                "num_element": [
                    2447,
                    2441,
                    2449,
                    2439
                ],
                "arguments.shape": [
                    2439
                ],
                "arguments": [
                    2442,
                    2508,
                    2478,
                    2439
                ],
                "num_static_element": [
                    2440,
                    2441,
                    2449,
                    2448
                ],
                "num_batch": [
                    2441,
                    2442
                ],
                "as_shape": [
                    2442
                ],
                "arguments.data": [
                    2442,
                    2508,
                    2478
                ],
                "C.cntk_py.Value": [
                    2443,
                    2508,
                    2478,
                    2511,
                    2481,
                    2450
                ],
                "grad_array_view": [
                    2451,
                    2446
                ],
                "root_gradients.data": [
                    2481,
                    2446,
                    2511
                ],
                "root_gradients": [
                    2539,
                    2446,
                    2511,
                    2447,
                    2481
                ],
                "root_gradients.shape": [
                    2447
                ],
                "num_old_batch": [
                    2449,
                    2452
                ],
                "grad_array_view.as_shape": [
                    2451
                ],
                "batch_size": [
                    2498
                ],
                "arg": [
                    2523,
                    2518
                ],
                "self.when": [
                    2520,
                    2533
                ],
                "when": [
                    2520
                ],
                "self.execute": [
                    2521,
                    2534
                ],
                "execute": [
                    2521
                ],
                "dynamic_axes": [
                    2530
                ]
            }
        },
        "/Volumes/SSD2T/bgp_envs_non_pandas/repos/keras_20/keras/backend/tensorflow_backend.py": {
            "buggy_functions": [
                {
                    "function_name": "_preprocess_conv2d_input",
                    "function_code": "def _preprocess_conv2d_input(x, data_format):\n    \"\"\"Transpose and cast the input before the conv2d.\n\n    # Arguments\n        x: input tensor.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    # tensorflow doesn't support float64 for conv layer before 1.8.0\n    if (dtype(x) == 'float64' and\n            StrictVersion(tf.__version__.split('-')[0]) < StrictVersion('1.8.0')):\n        x = tf.cast(x, 'float32')\n    tf_data_format = 'NHWC'\n    if data_format == 'channels_first':\n        if not _has_nchw_support():\n            x = tf.transpose(x, (0, 2, 3, 1))  # NCHW -> NHWC\n        else:\n            tf_data_format = 'NCHW'\n    return x, tf_data_format\n",
                    "decorators": [],
                    "docstring": "Transpose and cast the input before the conv2d.\n\n# Arguments\n    x: input tensor.\n    data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n\n# Returns\n    A tensor.",
                    "start_line": 3436,
                    "end_line": 3456,
                    "variables": {
                        "dtype": [
                            3447
                        ],
                        "x": [
                            3456,
                            3449,
                            3453,
                            3447
                        ],
                        "StrictVersion": [
                            3448
                        ],
                        "tf.__version__.split": [
                            3448
                        ],
                        "tf.__version__": [
                            3448
                        ],
                        "tf": [
                            3448,
                            3449,
                            3453
                        ],
                        "tf.cast": [
                            3449
                        ],
                        "tf_data_format": [
                            3456,
                            3450,
                            3455
                        ],
                        "data_format": [
                            3451
                        ],
                        "_has_nchw_support": [
                            3452
                        ],
                        "tf.transpose": [
                            3453
                        ]
                    },
                    "filtered_variables": {
                        "dtype": [
                            3447
                        ],
                        "x": [
                            3456,
                            3449,
                            3453,
                            3447
                        ],
                        "StrictVersion": [
                            3448
                        ],
                        "tf.__version__.split": [
                            3448
                        ],
                        "tf.__version__": [
                            3448
                        ],
                        "tf": [
                            3448,
                            3449,
                            3453
                        ],
                        "tf.cast": [
                            3449
                        ],
                        "tf_data_format": [
                            3456,
                            3450,
                            3455
                        ],
                        "data_format": [
                            3451
                        ],
                        "_has_nchw_support": [
                            3452
                        ],
                        "tf.transpose": [
                            3453
                        ]
                    },
                    "diff_line_number": 3436,
                    "class_data": null,
                    "variable_values": [
                        [
                            {},
                            {}
                        ]
                    ],
                    "angelic_variable_values": [
                        [
                            {},
                            {}
                        ]
                    ]
                },
                {
                    "function_name": "conv2d_transpose",
                    "function_code": "def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),\n                     padding='valid', data_format=None):\n    \"\"\"2D deconvolution (i.e. transposed convolution).\n\n    # Arguments\n        x: Tensor or variable.\n        kernel: kernel tensor.\n        output_shape: 1D int tensor for the output shape.\n        strides: strides tuple.\n        padding: string, `\"same\"` or `\"valid\"`.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n            Whether to use Theano or TensorFlow/CNTK data format\n            for inputs/kernels/outputs.\n\n    # Returns\n        A tensor, result of transposed 2D convolution.\n\n    # Raises\n        ValueError: If `data_format` is neither\n            `\"channels_last\"` nor `\"channels_first\"`.\n    \"\"\"\n    data_format = normalize_data_format(data_format)\n    if isinstance(output_shape, (tuple, list)):\n        output_shape = tf.stack(output_shape)\n\n    x, tf_data_format = _preprocess_conv2d_input(x, data_format)\n\n    if data_format == 'channels_first' and tf_data_format == 'NHWC':\n        output_shape = (output_shape[0],\n                        output_shape[2],\n                        output_shape[3],\n                        output_shape[1])\n    if output_shape[0] is None:\n        output_shape = (tf.shape(x)[0],) + tuple(output_shape[1:])\n        output_shape = tf.stack(list(output_shape))\n\n    padding = _preprocess_padding(padding)\n    if tf_data_format == 'NHWC':\n        strides = (1,) + strides + (1,)\n    else:\n        strides = (1, 1) + strides\n\n    x = tf.nn.conv2d_transpose(x, kernel, output_shape, strides,\n                               padding=padding,\n                               data_format=tf_data_format)\n    if data_format == 'channels_first' and tf_data_format == 'NHWC':\n        x = tf.transpose(x, (0, 3, 1, 2))  # NHWC -> NCHW\n    return x\n",
                    "decorators": [],
                    "docstring": "2D deconvolution (i.e. transposed convolution).\n\n# Arguments\n    x: Tensor or variable.\n    kernel: kernel tensor.\n    output_shape: 1D int tensor for the output shape.\n    strides: strides tuple.\n    padding: string, `\"same\"` or `\"valid\"`.\n    data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n        Whether to use Theano or TensorFlow/CNTK data format\n        for inputs/kernels/outputs.\n\n# Returns\n    A tensor, result of transposed 2D convolution.\n\n# Raises\n    ValueError: If `data_format` is neither\n        `\"channels_last\"` nor `\"channels_first\"`.",
                    "start_line": 3588,
                    "end_line": 3635,
                    "variables": {
                        "data_format": [
                            3609,
                            3633,
                            3613,
                            3615
                        ],
                        "normalize_data_format": [
                            3609
                        ],
                        "isinstance": [
                            3610
                        ],
                        "output_shape": [
                            3616,
                            3617,
                            3618,
                            3619,
                            3620,
                            3621,
                            3622,
                            3630,
                            3610,
                            3611
                        ],
                        "tuple": [
                            3610,
                            3621
                        ],
                        "list": [
                            3610,
                            3622
                        ],
                        "tf.stack": [
                            3611,
                            3622
                        ],
                        "tf": [
                            3621,
                            3622,
                            3630,
                            3634,
                            3611
                        ],
                        "x": [
                            3621,
                            3630,
                            3634,
                            3635,
                            3613
                        ],
                        "tf_data_format": [
                            3625,
                            3632,
                            3633,
                            3613,
                            3615
                        ],
                        "_preprocess_conv2d_input": [
                            3613
                        ],
                        "tf.shape": [
                            3621
                        ],
                        "padding": [
                            3624,
                            3631
                        ],
                        "_preprocess_padding": [
                            3624
                        ],
                        "strides": [
                            3626,
                            3628,
                            3630
                        ],
                        "tf.nn.conv2d_transpose": [
                            3630
                        ],
                        "tf.nn": [
                            3630
                        ],
                        "kernel": [
                            3630
                        ],
                        "tf.transpose": [
                            3634
                        ]
                    },
                    "filtered_variables": {
                        "data_format": [
                            3609,
                            3633,
                            3613,
                            3615
                        ],
                        "normalize_data_format": [
                            3609
                        ],
                        "output_shape": [
                            3616,
                            3617,
                            3618,
                            3619,
                            3620,
                            3621,
                            3622,
                            3630,
                            3610,
                            3611
                        ],
                        "tf.stack": [
                            3611,
                            3622
                        ],
                        "tf": [
                            3621,
                            3622,
                            3630,
                            3634,
                            3611
                        ],
                        "x": [
                            3621,
                            3630,
                            3634,
                            3635,
                            3613
                        ],
                        "tf_data_format": [
                            3625,
                            3632,
                            3633,
                            3613,
                            3615
                        ],
                        "_preprocess_conv2d_input": [
                            3613
                        ],
                        "tf.shape": [
                            3621
                        ],
                        "padding": [
                            3624,
                            3631
                        ],
                        "_preprocess_padding": [
                            3624
                        ],
                        "strides": [
                            3626,
                            3628,
                            3630
                        ],
                        "tf.nn.conv2d_transpose": [
                            3630
                        ],
                        "tf.nn": [
                            3630
                        ],
                        "kernel": [
                            3630
                        ],
                        "tf.transpose": [
                            3634
                        ]
                    },
                    "diff_line_number": 3589,
                    "class_data": null,
                    "variable_values": [
                        [
                            {},
                            {}
                        ]
                    ],
                    "angelic_variable_values": [
                        [
                            {},
                            {}
                        ]
                    ]
                }
            ],
            "inscope_functions": [
                "def get_uid(prefix=''):\n    \"\"\"Get the uid for the default graph.\n\n    # Arguments\n        prefix: An optional prefix of the graph.\n\n    # Returns\n        A unique identifier for the graph.\n    \"\"\"\n    global _GRAPH_UID_DICTS\n    graph = tf.get_default_graph()\n    if graph not in _GRAPH_UID_DICTS:\n        _GRAPH_UID_DICTS[graph] = defaultdict(int)\n    _GRAPH_UID_DICTS[graph][prefix] += 1\n    return _GRAPH_UID_DICTS[graph][prefix]",
                "def reset_uids():\n    \"\"\"Resets graph identifiers.\n    \"\"\"\n    global _GRAPH_UID_DICTS\n    _GRAPH_UID_DICTS = {}",
                "def clear_session():\n    \"\"\"Destroys the current TF graph and creates a new one.\n\n    Useful to avoid clutter from old models / layers.\n    \"\"\"\n    global _SESSION\n    global _GRAPH_LEARNING_PHASES\n    tf.reset_default_graph()\n    reset_uids()\n    _SESSION = None\n    phase = tf.placeholder_with_default(False,\n                                        shape=(),\n                                        name='keras_learning_phase')\n    _GRAPH_LEARNING_PHASES = {}\n    _GRAPH_LEARNING_PHASES[tf.get_default_graph()] = phase",
                "def manual_variable_initialization(value):\n    \"\"\"Sets the manual variable initialization flag.\n\n    This boolean flag determines whether\n    variables should be initialized\n    as they are instantiated (default), or if\n    the user should handle the initialization\n    (e.g. via `tf.initialize_all_variables()`).\n\n    # Arguments\n        value: Python boolean.\n    \"\"\"\n    global _MANUAL_VAR_INIT\n    _MANUAL_VAR_INIT = value",
                "def learning_phase():\n    \"\"\"Returns the learning phase flag.\n\n    The learning phase flag is a bool tensor (0 = test, 1 = train)\n    to be passed as input to any Keras function\n    that uses a different behavior at train time and test time.\n\n    # Returns\n        Learning phase (scalar integer tensor or Python integer).\n    \"\"\"\n    graph = tf.get_default_graph()\n    if graph not in _GRAPH_LEARNING_PHASES:\n        phase = tf.placeholder_with_default(False,\n                                            shape=(),\n                                            name='keras_learning_phase')\n        _GRAPH_LEARNING_PHASES[graph] = phase\n    return _GRAPH_LEARNING_PHASES[graph]",
                "def set_learning_phase(value):\n    \"\"\"Sets the learning phase to a fixed value.\n\n    # Arguments\n        value: Learning phase value, either 0 or 1 (integers).\n\n    # Raises\n        ValueError: if `value` is neither `0` nor `1`.\n    \"\"\"\n    global _GRAPH_LEARNING_PHASES\n    if value not in {0, 1}:\n        raise ValueError('Expected learning phase to be '\n                         '0 or 1.')\n    _GRAPH_LEARNING_PHASES[tf.get_default_graph()] = value",
                "def get_session():\n    \"\"\"Returns the TF session to be used by the backend.\n\n    If a default TensorFlow session is available, we will return it.\n\n    Else, we will return the global Keras session.\n\n    If no global Keras session exists at this point:\n    we will create a new global session.\n\n    Note that you can manually set the global session\n    via `K.set_session(sess)`.\n\n    # Returns\n        A TensorFlow session.\n    \"\"\"\n    global _SESSION\n\n    default_session = tf.get_default_session()\n\n    if default_session is not None:\n        session = default_session\n    else:\n        if _SESSION is None:\n            if not os.environ.get('OMP_NUM_THREADS'):\n                config = tf.ConfigProto(allow_soft_placement=True)\n            else:\n                num_thread = int(os.environ.get('OMP_NUM_THREADS'))\n                config = tf.ConfigProto(intra_op_parallelism_threads=num_thread,\n                                        allow_soft_placement=True)\n            _SESSION = tf.Session(config=config)\n        session = _SESSION\n    if not _MANUAL_VAR_INIT:\n        with session.graph.as_default():\n            variables = tf.global_variables()\n            candidate_vars = []\n            for v in variables:\n                if not getattr(v, '_keras_initialized', False):\n                    candidate_vars.append(v)\n            if candidate_vars:\n                # This step is expensive, so we only run it on variables\n                # not already marked as initialized.\n                is_initialized = session.run(\n                    [tf.is_variable_initialized(v) for v in candidate_vars])\n                uninitialized_vars = []\n                for flag, v in zip(is_initialized, candidate_vars):\n                    if not flag:\n                        uninitialized_vars.append(v)\n                    v._keras_initialized = True\n                if uninitialized_vars:\n                    session.run(tf.variables_initializer(uninitialized_vars))\n    # hack for list_devices() function.\n    # list_devices() function is not available under tensorflow r1.3.\n    if not hasattr(session, 'list_devices'):\n        session.list_devices = lambda: device_lib.list_local_devices()\n    return session",
                "def set_session(session):\n    \"\"\"Sets the global TensorFlow session.\n\n    # Arguments\n        session: A TF Session.\n    \"\"\"\n    global _SESSION\n    _SESSION = session",
                "def _get_current_tf_device():\n    \"\"\"Return explicit device of current context, otherwise returns `None`.\n\n    # Returns\n        If the current device scope is explicitly set, it returns a string with\n        the device (`CPU` or `GPU`). If the scope is not explicitly set, it will\n        return `None`.\n    \"\"\"\n    g = tf.get_default_graph()\n    op = _TfDeviceCaptureOp()\n    g._apply_device_functions(op)\n    return op.device",
                "def _is_current_explicit_device(device_type):\n    \"\"\"Check if the current device is explicitly set on the device type specified.\n\n    # Arguments\n        device_type: A string containing `GPU` or `CPU` (case-insensitive).\n\n    # Returns\n        A boolean indicating if the current device scope is explicitly set on the device type.\n\n    # Raises\n        ValueError: If the `device_type` string indicates an unsupported device.\n    \"\"\"\n    device_type = device_type.upper()\n    if device_type not in ['CPU', 'GPU']:\n        raise ValueError('`device_type` should be either \"CPU\" or \"GPU\".')\n    device = _get_current_tf_device()\n    return (device is not None and device.device_type == device_type.upper())",
                "def _get_available_gpus():\n    \"\"\"Get a list of available gpu devices (formatted as strings).\n\n    # Returns\n        A list of available GPU devices.\n    \"\"\"\n    global _LOCAL_DEVICES\n    if _LOCAL_DEVICES is None:\n        _LOCAL_DEVICES = get_session().list_devices()\n    return [x.name for x in _LOCAL_DEVICES if x.device_type == 'GPU']",
                "def _has_nchw_support():\n    \"\"\"Check whether the current scope supports NCHW ops.\n\n    TensorFlow does not support NCHW on CPU. Therefore we check if we are not explicitly put on\n    CPU, and have GPUs available. In this case there will be soft-placing on the GPU device.\n\n    # Returns\n        bool: if the current scope device placement would support nchw\n    \"\"\"\n    explicitly_on_cpu = _is_current_explicit_device('CPU')\n    gpus_available = len(_get_available_gpus()) > 0\n    return (not explicitly_on_cpu and gpus_available)",
                "def _to_tensor(x, dtype):\n    \"\"\"Convert the input `x` to a tensor of type `dtype`.\n\n    # Arguments\n        x: An object to be converted (numpy array, list, tensors).\n        dtype: The destination type.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.convert_to_tensor(x, dtype=dtype)",
                "def is_sparse(tensor):\n    \"\"\"Returns whether a tensor is a sparse tensor.\n\n    # Arguments\n        tensor: A tensor instance.\n\n    # Returns\n        A boolean.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> a = K.placeholder((2, 2), sparse=False)\n        >>> print(K.is_sparse(a))\n        False\n        >>> b = K.placeholder((2, 2), sparse=True)\n        >>> print(K.is_sparse(b))\n        True\n    ```\n    \"\"\"\n    return isinstance(tensor, tf.SparseTensor)",
                "def to_dense(tensor):\n    \"\"\"Converts a sparse tensor into a dense tensor and returns it.\n\n    # Arguments\n        tensor: A tensor instance (potentially sparse).\n\n    # Returns\n        A dense tensor.\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> b = K.placeholder((2, 2), sparse=True)\n        >>> print(K.is_sparse(b))\n        True\n        >>> c = K.to_dense(b)\n        >>> print(K.is_sparse(c))\n        False\n    ```\n    \"\"\"\n    if is_sparse(tensor):\n        return tf.sparse_tensor_to_dense(tensor)\n    else:\n        return tensor",
                "def variable(value, dtype=None, name=None, constraint=None):\n    \"\"\"Instantiates a variable and returns it.\n\n    # Arguments\n        value: Numpy array, initial value of the tensor.\n        dtype: Tensor type.\n        name: Optional name string for the tensor.\n        constraint: Optional projection function to be\n            applied to the variable after an optimizer update.\n\n    # Returns\n        A variable instance (with Keras metadata included).\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> val = np.array([[1, 2], [3, 4]])\n        >>> kvar = K.variable(value=val, dtype='float64', name='example_var')\n        >>> K.dtype(kvar)\n        'float64'\n        >>> print(kvar)\n        example_var\n        >>> K.eval(kvar)\n        array([[ 1.,  2.],\n               [ 3.,  4.]])\n    ```\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    if hasattr(value, 'tocoo'):\n        sparse_coo = value.tocoo()\n        indices = np.concatenate((np.expand_dims(sparse_coo.row, 1),\n                                  np.expand_dims(sparse_coo.col, 1)), 1)\n        v = tf.SparseTensor(indices=indices,\n                            values=sparse_coo.data,\n                            dense_shape=sparse_coo.shape)\n        v._keras_shape = sparse_coo.shape\n        v._uses_learning_phase = False\n        return v\n    v = tf.Variable(value, dtype=tf.as_dtype(dtype), name=name)\n    if isinstance(value, np.ndarray):\n        v._keras_shape = value.shape\n    elif hasattr(value, 'get_shape'):\n        v._keras_shape = int_shape(value)\n    v._uses_learning_phase = False\n    # TODO: move to Variable constructor when supported in public release.\n    try:\n        v.constraint = constraint\n    except AttributeError:\n        v._constraint = constraint\n    return v",
                "def constant(value, dtype=None, shape=None, name=None):\n    \"\"\"Creates a constant tensor.\n\n    # Arguments\n        value: A constant value (or list)\n        dtype: The type of the elements of the resulting tensor.\n        shape: Optional dimensions of resulting tensor.\n        name: Optional name for the tensor.\n\n    # Returns\n        A Constant Tensor.\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    return tf.constant(value, dtype=dtype, shape=shape, name=name)",
                "def is_keras_tensor(x):\n    \"\"\"Returns whether `x` is a Keras tensor.\n\n    A \"Keras tensor\" is a tensor that was returned by a Keras layer,\n    (`Layer` class) or by `Input`.\n\n    # Arguments\n        x: A candidate tensor.\n\n    # Returns\n        A boolean: Whether the argument is a Keras tensor.\n\n    # Raises\n        ValueError: In case `x` is not a symbolic tensor.\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> from keras.layers import Input, Dense\n        >>> np_var = numpy.array([1, 2])\n        >>> K.is_keras_tensor(np_var) # A numpy array is not a symbolic tensor.\n        ValueError\n        >>> k_var = tf.placeholder('float32', shape=(1,1))\n        >>> K.is_keras_tensor(k_var) # A variable indirectly created outside of keras is not a Keras tensor.\n        False\n        >>> keras_var = K.variable(np_var)\n        >>> K.is_keras_tensor(keras_var)  # A variable created with the keras backend is not a Keras tensor.\n        False\n        >>> keras_placeholder = K.placeholder(shape=(2, 4, 5))\n        >>> K.is_keras_tensor(keras_placeholder)  # A placeholder is not a Keras tensor.\n        False\n        >>> keras_input = Input([10])\n        >>> K.is_keras_tensor(keras_input) # An Input is a Keras tensor.\n        True\n        >>> keras_layer_output = Dense(10)(keras_input)\n        >>> K.is_keras_tensor(keras_layer_output) # Any Keras layer output is a Keras tensor.\n        True\n    ```\n    \"\"\"\n    if not is_tensor(x):\n        raise ValueError('Unexpectedly found an instance of type `' +\n                         str(type(x)) + '`. '\n                         'Expected a symbolic tensor instance.')\n    return hasattr(x, '_keras_history')",
                "def is_tensor(x):\n    return isinstance(x, tf_ops._TensorLike) or tf_ops.is_dense_tensor_like(x)",
                "def placeholder(shape=None, ndim=None, dtype=None, sparse=False, name=None):\n    \"\"\"Instantiates a placeholder tensor and returns it.\n\n    # Arguments\n        shape: Shape of the placeholder\n            (integer tuple, may include `None` entries).\n        ndim: Number of axes of the tensor.\n            At least one of {`shape`, `ndim`} must be specified.\n            If both are specified, `shape` is used.\n        dtype: Placeholder type.\n        sparse: Boolean, whether the placeholder should have a sparse type.\n        name: Optional name string for the placeholder.\n\n    # Returns\n        Tensor instance (with Keras metadata included).\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> input_ph = K.placeholder(shape=(2, 4, 5))\n        >>> input_ph._keras_shape\n        (2, 4, 5)\n        >>> input_ph\n        <tf.Tensor 'Placeholder_4:0' shape=(2, 4, 5) dtype=float32>\n    ```\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    if not shape:\n        if ndim:\n            shape = tuple([None for _ in range(ndim)])\n    if sparse:\n        x = tf.sparse_placeholder(dtype, shape=shape, name=name)\n    else:\n        x = tf.placeholder(dtype, shape=shape, name=name)\n    x._keras_shape = shape\n    x._uses_learning_phase = False\n    return x",
                "def is_placeholder(x):\n    \"\"\"Returns whether `x` is a placeholder.\n\n    # Arguments\n        x: A candidate placeholder.\n\n    # Returns\n        Boolean.\n    \"\"\"\n    try:\n        return x.op.type == 'Placeholder'\n    except AttributeError:\n        return False",
                "def shape(x):\n    \"\"\"Returns the symbolic shape of a tensor or variable.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A symbolic shape (which is itself a tensor).\n\n    # Examples\n    ```python\n        # TensorFlow example\n        >>> from keras import backend as K\n        >>> tf_session = K.get_session()\n        >>> val = np.array([[1, 2], [3, 4]])\n        >>> kvar = K.variable(value=val)\n        >>> inputs = keras.backend.placeholder(shape=(2, 4, 5))\n        >>> K.shape(kvar)\n        <tf.Tensor 'Shape_8:0' shape=(2,) dtype=int32>\n        >>> K.shape(inputs)\n        <tf.Tensor 'Shape_9:0' shape=(3,) dtype=int32>\n        # To get integer shape (Instead, you can use K.int_shape(x))\n        >>> K.shape(kvar).eval(session=tf_session)\n        array([2, 2], dtype=int32)\n        >>> K.shape(inputs).eval(session=tf_session)\n        array([2, 4, 5], dtype=int32)\n    ```\n    \"\"\"\n    return tf.shape(x)",
                "def int_shape(x):\n    \"\"\"Returns the shape of tensor or variable as a tuple of int or None entries.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tuple of integers (or None entries).\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> inputs = K.placeholder(shape=(2, 4, 5))\n        >>> K.int_shape(inputs)\n        (2, 4, 5)\n        >>> val = np.array([[1, 2], [3, 4]])\n        >>> kvar = K.variable(value=val)\n        >>> K.int_shape(kvar)\n        (2, 2)\n    ```\n    \"\"\"\n    if hasattr(x, '_keras_shape'):\n        return x._keras_shape\n    try:\n        return tuple(x.get_shape().as_list())\n    except ValueError:\n        return None",
                "def ndim(x):\n    \"\"\"Returns the number of axes in a tensor, as an integer.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        Integer (scalar), number of axes.\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> inputs = K.placeholder(shape=(2, 4, 5))\n        >>> val = np.array([[1, 2], [3, 4]])\n        >>> kvar = K.variable(value=val)\n        >>> K.ndim(inputs)\n        3\n        >>> K.ndim(kvar)\n        2\n    ```\n    \"\"\"\n    dims = x.get_shape()._dims\n    if dims is not None:\n        return len(dims)\n    return None",
                "def dtype(x):\n    \"\"\"Returns the dtype of a Keras tensor or variable, as a string.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        String, dtype of `x`.\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> K.dtype(K.placeholder(shape=(2,4,5)))\n        'float32'\n        >>> K.dtype(K.placeholder(shape=(2,4,5), dtype='float32'))\n        'float32'\n        >>> K.dtype(K.placeholder(shape=(2,4,5), dtype='float64'))\n        'float64'\n        # Keras variable\n        >>> kvar = K.variable(np.array([[1, 2], [3, 4]]))\n        >>> K.dtype(kvar)\n        'float32_ref'\n        >>> kvar = K.variable(np.array([[1, 2], [3, 4]]), dtype='float32')\n        >>> K.dtype(kvar)\n        'float32_ref'\n    ```\n    \"\"\"\n    return x.dtype.base_dtype.name",
                "def eval(x):\n    \"\"\"Evaluates the value of a variable.\n\n    # Arguments\n        x: A variable.\n\n    # Returns\n        A Numpy array.\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> kvar = K.variable(np.array([[1, 2], [3, 4]]), dtype='float32')\n        >>> K.eval(kvar)\n        array([[ 1.,  2.],\n               [ 3.,  4.]], dtype=float32)\n    ```\n    \"\"\"\n    return to_dense(x).eval(session=get_session())",
                "def zeros(shape, dtype=None, name=None):\n    \"\"\"Instantiates an all-zeros variable and returns it.\n\n    # Arguments\n        shape: Tuple of integers, shape of returned Keras variable\n        dtype: String, data type of returned Keras variable\n        name: String, name of returned Keras variable\n\n    # Returns\n        A variable (including Keras metadata), filled with `0.0`.\n        Note that if `shape` was symbolic, we cannot return a variable,\n        and will return a dynamically-shaped tensor instead.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> kvar = K.zeros((3,4))\n        >>> K.eval(kvar)\n        array([[ 0.,  0.,  0.,  0.],\n               [ 0.,  0.,  0.,  0.],\n               [ 0.,  0.,  0.,  0.]], dtype=float32)\n    ```\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    tf_dtype = tf.as_dtype(dtype)\n    v = tf.zeros(shape=shape, dtype=tf_dtype, name=name)\n    if py_all(v.get_shape().as_list()):\n        return variable(v, dtype=dtype, name=name)\n    return v",
                "def ones(shape, dtype=None, name=None):\n    \"\"\"Instantiates an all-ones variable and returns it.\n\n    # Arguments\n        shape: Tuple of integers, shape of returned Keras variable.\n        dtype: String, data type of returned Keras variable.\n        name: String, name of returned Keras variable.\n\n    # Returns\n        A Keras variable, filled with `1.0`.\n        Note that if `shape` was symbolic, we cannot return a variable,\n        and will return a dynamically-shaped tensor instead.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> kvar = K.ones((3,4))\n        >>> K.eval(kvar)\n        array([[ 1.,  1.,  1.,  1.],\n               [ 1.,  1.,  1.,  1.],\n               [ 1.,  1.,  1.,  1.]], dtype=float32)\n    ```\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    tf_dtype = tf.as_dtype(dtype)\n    v = tf.ones(shape=shape, dtype=tf_dtype, name=name)\n    if py_all(v.get_shape().as_list()):\n        return variable(v, dtype=dtype, name=name)\n    return v",
                "def eye(size, dtype=None, name=None):\n    \"\"\"Instantiate an identity matrix and returns it.\n\n    # Arguments\n        size: Integer, number of rows/columns.\n        dtype: String, data type of returned Keras variable.\n        name: String, name of returned Keras variable.\n\n    # Returns\n        A Keras variable, an identity matrix.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> kvar = K.eye(3)\n        >>> K.eval(kvar)\n        array([[ 1.,  0.,  0.],\n               [ 0.,  1.,  0.],\n               [ 0.,  0.,  1.]], dtype=float32)\n    ```\n\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    tf_dtype = tf.as_dtype(dtype)\n    return variable(tf.eye(size, dtype=tf_dtype), dtype, name)",
                "def zeros_like(x, dtype=None, name=None):\n    \"\"\"Instantiates an all-zeros variable of the same shape as another tensor.\n\n    # Arguments\n        x: Keras variable or Keras tensor.\n        dtype: String, dtype of returned Keras variable.\n             None uses the dtype of x.\n        name: String, name for the variable to create.\n\n    # Returns\n        A Keras variable with the shape of x filled with zeros.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> kvar = K.variable(np.random.random((2,3)))\n        >>> kvar_zeros = K.zeros_like(kvar)\n        >>> K.eval(kvar_zeros)\n        array([[ 0.,  0.,  0.],\n               [ 0.,  0.,  0.]], dtype=float32)\n    ```\n    \"\"\"\n    return tf.zeros_like(x, dtype=dtype, name=name)",
                "def ones_like(x, dtype=None, name=None):\n    \"\"\"Instantiates an all-ones variable of the same shape as another tensor.\n\n    # Arguments\n        x: Keras variable or tensor.\n        dtype: String, dtype of returned Keras variable.\n             None uses the dtype of x.\n        name: String, name for the variable to create.\n\n    # Returns\n        A Keras variable with the shape of x filled with ones.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> kvar = K.variable(np.random.random((2,3)))\n        >>> kvar_ones = K.ones_like(kvar)\n        >>> K.eval(kvar_ones)\n        array([[ 1.,  1.,  1.],\n               [ 1.,  1.,  1.]], dtype=float32)\n    ```\n    \"\"\"\n    return tf.ones_like(x, dtype=dtype, name=name)",
                "def identity(x, name=None):\n    \"\"\"Returns a tensor with the same content as the input tensor.\n\n    # Arguments\n        x: The input tensor.\n        name: String, name for the variable to create.\n\n    # Returns\n        A tensor of the same shape, type and content.\n    \"\"\"\n    return tf.identity(x, name)",
                "def random_uniform_variable(shape, low, high, dtype=None,\n                            name=None, seed=None):\n    \"\"\"Instantiates a variable with values drawn from a uniform distribution.\n\n    # Arguments\n        shape: Tuple of integers, shape of returned Keras variable.\n        low: Float, lower boundary of the output interval.\n        high: Float, upper boundary of the output interval.\n        dtype: String, dtype of returned Keras variable.\n        name: String, name of returned Keras variable.\n        seed: Integer, random seed.\n\n    # Returns\n        A Keras variable, filled with drawn samples.\n\n    # Example\n    ```python\n        # TensorFlow example\n        >>> kvar = K.random_uniform_variable((2,3), 0, 1)\n        >>> kvar\n        <tensorflow.python.ops.variables.Variable object at 0x10ab40b10>\n        >>> K.eval(kvar)\n        array([[ 0.10940075,  0.10047495,  0.476143  ],\n               [ 0.66137183,  0.00869417,  0.89220798]], dtype=float32)\n    ```\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    tf_dtype = tf.as_dtype(dtype)\n    if seed is None:\n        # ensure that randomness is conditioned by the Numpy RNG\n        seed = np.random.randint(10e8)\n    value = tf.random_uniform_initializer(\n        low, high, dtype=tf_dtype, seed=seed)(shape)\n    return variable(value, dtype=dtype, name=name)",
                "def random_normal_variable(shape, mean, scale, dtype=None,\n                           name=None, seed=None):\n    \"\"\"Instantiates a variable with values drawn from a normal distribution.\n\n    # Arguments\n        shape: Tuple of integers, shape of returned Keras variable.\n        mean: Float, mean of the normal distribution.\n        scale: Float, standard deviation of the normal distribution.\n        dtype: String, dtype of returned Keras variable.\n        name: String, name of returned Keras variable.\n        seed: Integer, random seed.\n\n    # Returns\n        A Keras variable, filled with drawn samples.\n\n    # Example\n    ```python\n        # TensorFlow example\n        >>> kvar = K.random_normal_variable((2,3), 0, 1)\n        >>> kvar\n        <tensorflow.python.ops.variables.Variable object at 0x10ab12dd0>\n        >>> K.eval(kvar)\n        array([[ 1.19591331,  0.68685907, -0.63814116],\n               [ 0.92629528,  0.28055015,  1.70484698]], dtype=float32)\n    ```\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    tf_dtype = tf.as_dtype(dtype)\n    if seed is None:\n        # ensure that randomness is conditioned by the Numpy RNG\n        seed = np.random.randint(10e8)\n    value = tf.random_normal_initializer(\n        mean, scale, dtype=tf_dtype, seed=seed)(shape)\n    return variable(value, dtype=dtype, name=name)",
                "def count_params(x):\n    \"\"\"Returns the static number of elements in a Keras variable or tensor.\n\n    # Arguments\n        x: Keras variable or tensor.\n\n    # Returns\n        Integer, the number of elements in `x`, i.e., the product of the\n        array's static dimensions.\n\n    # Example\n    ```python\n        >>> kvar = K.zeros((2,3))\n        >>> K.count_params(kvar)\n        6\n        >>> K.eval(kvar)\n        array([[ 0.,  0.,  0.],\n               [ 0.,  0.,  0.]], dtype=float32)\n    ```\n    \"\"\"\n    return np.prod(int_shape(x))",
                "def cast(x, dtype):\n    \"\"\"Casts a tensor to a different dtype and returns it.\n\n    You can cast a Keras variable but it still returns a Keras tensor.\n\n    # Arguments\n        x: Keras tensor (or variable).\n        dtype: String, either (`'float16'`, `'float32'`, or `'float64'`).\n\n    # Returns\n        Keras tensor with dtype `dtype`.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> input = K.placeholder((2, 3), dtype='float32')\n        >>> input\n        <tf.Tensor 'Placeholder_2:0' shape=(2, 3) dtype=float32>\n        # It doesn't work in-place as below.\n        >>> K.cast(input, dtype='float16')\n        <tf.Tensor 'Cast_1:0' shape=(2, 3) dtype=float16>\n        >>> input\n        <tf.Tensor 'Placeholder_2:0' shape=(2, 3) dtype=float32>\n        # you need to assign it.\n        >>> input = K.cast(input, dtype='float16')\n        >>> input\n        <tf.Tensor 'Cast_2:0' shape=(2, 3) dtype=float16>\n    ```\n    \"\"\"\n    return tf.cast(x, dtype)",
                "def update(x, new_x):\n    \"\"\"Update the value of `x` to `new_x`.\n\n    # Arguments\n        x: A `Variable`.\n        new_x: A tensor of same shape as `x`.\n\n    # Returns\n        The variable `x` updated.\n    \"\"\"\n    return tf.assign(x, new_x)",
                "def update_add(x, increment):\n    \"\"\"Update the value of `x` by adding `increment`.\n\n    # Arguments\n        x: A `Variable`.\n        increment: A tensor of same shape as `x`.\n\n    # Returns\n        The variable `x` updated.\n    \"\"\"\n    return tf.assign_add(x, increment)",
                "def update_sub(x, decrement):\n    \"\"\"Update the value of `x` by subtracting `decrement`.\n\n    # Arguments\n        x: A `Variable`.\n        decrement: A tensor of same shape as `x`.\n\n    # Returns\n        The variable `x` updated.\n    \"\"\"\n    return tf.assign_sub(x, decrement)",
                "def moving_average_update(x, value, momentum):\n    \"\"\"Compute the moving average of a variable.\n\n    # Arguments\n        x: A `Variable`.\n        value: A tensor with the same shape as `x`.\n        momentum: The moving average momentum.\n\n    # Returns\n        An operation to update the variable.\n    \"\"\"\n    return moving_averages.assign_moving_average(\n        x, value, momentum, zero_debias=True)",
                "def dot(x, y):\n    \"\"\"Multiplies 2 tensors (and/or variables) and returns a *tensor*.\n\n    When attempting to multiply a nD tensor\n    with a nD tensor, it reproduces the Theano behavior.\n    (e.g. `(2, 3) * (4, 3, 5) -> (2, 4, 5)`)\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A tensor, dot product of `x` and `y`.\n\n    # Examples\n    ```python\n        # dot product between tensors\n        >>> x = K.placeholder(shape=(2, 3))\n        >>> y = K.placeholder(shape=(3, 4))\n        >>> xy = K.dot(x, y)\n        >>> xy\n        <tf.Tensor 'MatMul_9:0' shape=(2, 4) dtype=float32>\n    ```\n\n    ```python\n        # dot product between tensors\n        >>> x = K.placeholder(shape=(32, 28, 3))\n        >>> y = K.placeholder(shape=(3, 4))\n        >>> xy = K.dot(x, y)\n        >>> xy\n        <tf.Tensor 'MatMul_9:0' shape=(32, 28, 4) dtype=float32>\n    ```\n\n    ```python\n        # Theano-like behavior example\n        >>> x = K.random_uniform_variable(shape=(2, 3), low=0, high=1)\n        >>> y = K.ones((4, 3, 5))\n        >>> xy = K.dot(x, y)\n        >>> K.int_shape(xy)\n        (2, 4, 5)\n    ```\n    \"\"\"\n    if ndim(x) is not None and (ndim(x) > 2 or ndim(y) > 2):\n        x_shape = []\n        for i, s in zip(int_shape(x), tf.unstack(tf.shape(x))):\n            if i is not None:\n                x_shape.append(i)\n            else:\n                x_shape.append(s)\n        x_shape = tuple(x_shape)\n        y_shape = []\n        for i, s in zip(int_shape(y), tf.unstack(tf.shape(y))):\n            if i is not None:\n                y_shape.append(i)\n            else:\n                y_shape.append(s)\n        y_shape = tuple(y_shape)\n        y_permute_dim = list(range(ndim(y)))\n        y_permute_dim = [y_permute_dim.pop(-2)] + y_permute_dim\n        xt = tf.reshape(x, [-1, x_shape[-1]])\n        yt = tf.reshape(tf.transpose(y, perm=y_permute_dim), [y_shape[-2], -1])\n        return tf.reshape(tf.matmul(xt, yt),\n                          x_shape[:-1] + y_shape[:-2] + y_shape[-1:])\n    if is_sparse(x):\n        out = tf.sparse_tensor_dense_matmul(x, y)\n    else:\n        out = tf.matmul(x, y)\n    return out",
                "def batch_dot(x, y, axes=None):\n    \"\"\"Batchwise dot product.\n\n    `batch_dot` is used to compute dot product of `x` and `y` when\n    `x` and `y` are data in batch, i.e. in a shape of\n    `(batch_size, :)`.\n    `batch_dot` results in a tensor or variable with less dimensions\n    than the input. If the number of dimensions is reduced to 1,\n    we use `expand_dims` to make sure that ndim is at least 2.\n\n    # Arguments\n        x: Keras tensor or variable with `ndim >= 2`.\n        y: Keras tensor or variable with `ndim >= 2`.\n        axes: list of (or single) int with target dimensions.\n            The lengths of `axes[0]` and `axes[1]` should be the same.\n\n    # Returns\n        A tensor with shape equal to the concatenation of `x`'s shape\n        (less the dimension that was summed over) and `y`'s shape\n        (less the batch dimension and the dimension that was summed over).\n        If the final rank is 1, we reshape it to `(batch_size, 1)`.\n\n    # Examples\n        Assume `x = [[1, 2], [3, 4]]` and `y = [[5, 6], [7, 8]]`\n        `batch_dot(x, y, axes=1) = [[17], [53]]` which is the main diagonal\n        of `x.dot(y.T)`, although we never have to calculate the off-diagonal\n        elements.\n\n        Shape inference:\n        Let `x`'s shape be `(100, 20)` and `y`'s shape be `(100, 30, 20)`.\n        If `axes` is (1, 2), to find the output shape of resultant tensor,\n            loop through each dimension in `x`'s shape and `y`'s shape:\n\n        * `x.shape[0]` : 100 : append to output shape\n        * `x.shape[1]` : 20 : do not append to output shape,\n            dimension 1 of `x` has been summed over. (`dot_axes[0]` = 1)\n        * `y.shape[0]` : 100 : do not append to output shape,\n            always ignore first dimension of `y`\n        * `y.shape[1]` : 30 : append to output shape\n        * `y.shape[2]` : 20 : do not append to output shape,\n            dimension 2 of `y` has been summed over. (`dot_axes[1]` = 2)\n        `output_shape` = `(100, 30)`\n\n    ```python\n        >>> x_batch = K.ones(shape=(32, 20, 1))\n        >>> y_batch = K.ones(shape=(32, 30, 20))\n        >>> xy_batch_dot = K.batch_dot(x_batch, y_batch, axes=[1, 2])\n        >>> K.int_shape(xy_batch_dot)\n        (32, 1, 30)\n    ```\n    \"\"\"\n    if isinstance(axes, int):\n        axes = (axes, axes)\n    x_ndim = ndim(x)\n    y_ndim = ndim(y)\n    if axes is None:\n        # behaves like tf.batch_matmul as default\n        axes = [x_ndim - 1, y_ndim - 2]\n    if py_any([isinstance(a, (list, tuple)) for a in axes]):\n        raise ValueError('Multiple target dimensions are not supported. ' +\n                         'Expected: None, int, (int, int), ' +\n                         'Provided: ' + str(axes))\n    if x_ndim > y_ndim:\n        diff = x_ndim - y_ndim\n        y = tf.reshape(y, tf.concat([tf.shape(y), [1] * (diff)], axis=0))\n    elif y_ndim > x_ndim:\n        diff = y_ndim - x_ndim\n        x = tf.reshape(x, tf.concat([tf.shape(x), [1] * (diff)], axis=0))\n    else:\n        diff = 0\n    if ndim(x) == 2 and ndim(y) == 2:\n        if axes[0] == axes[1]:\n            out = tf.reduce_sum(tf.multiply(x, y), axes[0])\n        else:\n            out = tf.reduce_sum(tf.multiply(tf.transpose(x, [1, 0]), y), axes[1])\n    else:\n        if axes is not None:\n            adj_x = None if axes[0] == ndim(x) - 1 else True\n            adj_y = True if axes[1] == ndim(y) - 1 else None\n        else:\n            adj_x = None\n            adj_y = None\n        out = tf.matmul(x, y, adjoint_a=adj_x, adjoint_b=adj_y)\n    if diff:\n        if x_ndim > y_ndim:\n            idx = x_ndim + y_ndim - 3\n        else:\n            idx = x_ndim - 1\n        out = tf.squeeze(out, list(range(idx, idx + diff)))\n    if ndim(out) == 1:\n        out = expand_dims(out, 1)\n    return out",
                "def transpose(x):\n    \"\"\"Transposes a tensor and returns it.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n\n    # Examples\n    ```python\n        >>> var = K.variable([[1, 2, 3], [4, 5, 6]])\n        >>> K.eval(var)\n        array([[ 1.,  2.,  3.],\n               [ 4.,  5.,  6.]], dtype=float32)\n        >>> var_transposed = K.transpose(var)\n        >>> K.eval(var_transposed)\n        array([[ 1.,  4.],\n               [ 2.,  5.],\n               [ 3.,  6.]], dtype=float32)\n    ```\n\n    ```python\n        >>> inputs = K.placeholder((2, 3))\n        >>> inputs\n        <tf.Tensor 'Placeholder_11:0' shape=(2, 3) dtype=float32>\n        >>> input_transposed = K.transpose(inputs)\n        >>> input_transposed\n        <tf.Tensor 'transpose_4:0' shape=(3, 2) dtype=float32>\n\n    ```\n    \"\"\"\n    return tf.transpose(x)",
                "def gather(reference, indices):\n    \"\"\"Retrieves the elements of indices `indices` in the tensor `reference`.\n\n    # Arguments\n        reference: A tensor.\n        indices: An integer tensor of indices.\n\n    # Returns\n        A tensor of same type as `reference`.\n    \"\"\"\n    return tf.nn.embedding_lookup(reference, indices)",
                "def max(x, axis=None, keepdims=False):\n    \"\"\"Maximum value in a tensor.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer, the axis to find maximum values.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1. If `keepdims` is `True`,\n            the reduced dimension is retained with length 1.\n\n    # Returns\n        A tensor with maximum values of `x`.\n    \"\"\"\n    return tf.reduce_max(x, axis, keepdims)",
                "def min(x, axis=None, keepdims=False):\n    \"\"\"Minimum value in a tensor.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer, the axis to find minimum values.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1. If `keepdims` is `True`,\n            the reduced dimension is retained with length 1.\n\n    # Returns\n        A tensor with miminum values of `x`.\n    \"\"\"\n    return tf.reduce_min(x, axis, keepdims)",
                "def sum(x, axis=None, keepdims=False):\n    \"\"\"Sum of the values in a tensor, alongside the specified axis.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer, the axis to sum over.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1. If `keepdims` is `True`,\n            the reduced dimension is retained with length 1.\n\n    # Returns\n        A tensor with sum of `x`.\n    \"\"\"\n    return tf.reduce_sum(x, axis, keepdims)",
                "def prod(x, axis=None, keepdims=False):\n    \"\"\"Multiplies the values in a tensor, alongside the specified axis.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer, the axis to compute the product.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1. If `keepdims` is `True`,\n            the reduced dimension is retained with length 1.\n\n    # Returns\n        A tensor with the product of elements of `x`.\n    \"\"\"\n    return tf.reduce_prod(x, axis, keepdims)",
                "def cumsum(x, axis=0):\n    \"\"\"Cumulative sum of the values in a tensor, alongside the specified axis.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer, the axis to compute the sum.\n\n    # Returns\n        A tensor of the cumulative sum of values of `x` along `axis`.\n    \"\"\"\n    return tf.cumsum(x, axis=axis)",
                "def cumprod(x, axis=0):\n    \"\"\"Cumulative product of the values in a tensor, alongside the specified axis.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer, the axis to compute the product.\n\n    # Returns\n        A tensor of the cumulative product of values of `x` along `axis`.\n    \"\"\"\n    return tf.cumprod(x, axis=axis)",
                "def var(x, axis=None, keepdims=False):\n    \"\"\"Variance of a tensor, alongside the specified axis.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer, the axis to compute the variance.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1. If `keepdims` is `True`,\n            the reduced dimension is retained with length 1.\n\n    # Returns\n        A tensor with the variance of elements of `x`.\n    \"\"\"\n    if x.dtype.base_dtype == tf.bool:\n        x = tf.cast(x, floatx())\n    m = tf.reduce_mean(x, axis, True)\n    devs_squared = tf.square(x - m)\n    return tf.reduce_mean(devs_squared,\n                          axis,\n                          keepdims)",
                "def std(x, axis=None, keepdims=False):\n    \"\"\"Standard deviation of a tensor, alongside the specified axis.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer, the axis to compute the standard deviation.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1. If `keepdims` is `True`,\n            the reduced dimension is retained with length 1.\n\n    # Returns\n        A tensor with the standard deviation of elements of `x`.\n    \"\"\"\n    return tf.sqrt(var(x, axis=axis, keepdims=keepdims))",
                "def mean(x, axis=None, keepdims=False):\n    \"\"\"Mean of a tensor, alongside the specified axis.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: A list of integer. Axes to compute the mean.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1 for each entry in `axis`. If `keepdims` is `True`,\n            the reduced dimensions are retained with length 1.\n\n    # Returns\n        A tensor with the mean of elements of `x`.\n    \"\"\"\n    if x.dtype.base_dtype == tf.bool:\n        x = tf.cast(x, floatx())\n    return tf.reduce_mean(x, axis, keepdims)",
                "def any(x, axis=None, keepdims=False):\n    \"\"\"Bitwise reduction (logical OR).\n\n    # Arguments\n        x: Tensor or variable.\n        axis: axis along which to perform the reduction.\n        keepdims: whether the drop or broadcast the reduction axes.\n\n    # Returns\n        A uint8 tensor (0s and 1s).\n    \"\"\"\n    x = tf.cast(x, tf.bool)\n    return tf.reduce_any(x, axis, keepdims)",
                "def all(x, axis=None, keepdims=False):\n    \"\"\"Bitwise reduction (logical AND).\n\n    # Arguments\n        x: Tensor or variable.\n        axis: axis along which to perform the reduction.\n        keepdims: whether the drop or broadcast the reduction axes.\n\n    # Returns\n        A uint8 tensor (0s and 1s).\n    \"\"\"\n    x = tf.cast(x, tf.bool)\n    return tf.reduce_all(x, axis, keepdims)",
                "def argmax(x, axis=-1):\n    \"\"\"Returns the index of the maximum value along an axis.\n\n    # Arguments\n        x: Tensor or variable.\n        axis: axis along which to perform the reduction.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.argmax(x, axis)",
                "def argmin(x, axis=-1):\n    \"\"\"Returns the index of the minimum value along an axis.\n\n    # Arguments\n        x: Tensor or variable.\n        axis: axis along which to perform the reduction.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.argmin(x, axis)",
                "def square(x):\n    \"\"\"Element-wise square.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.square(x)",
                "def abs(x):\n    \"\"\"Element-wise absolute value.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.abs(x)",
                "def sqrt(x):\n    \"\"\"Element-wise square root.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    zero = _to_tensor(0., x.dtype.base_dtype)\n    inf = _to_tensor(np.inf, x.dtype.base_dtype)\n    x = tf.clip_by_value(x, zero, inf)\n    return tf.sqrt(x)",
                "def exp(x):\n    \"\"\"Element-wise exponential.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.exp(x)",
                "def log(x):\n    \"\"\"Element-wise log.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.log(x)",
                "def logsumexp(x, axis=None, keepdims=False):\n    \"\"\"Computes log(sum(exp(elements across dimensions of a tensor))).\n\n    This function is more numerically stable than log(sum(exp(x))).\n    It avoids overflows caused by taking the exp of large inputs and\n    underflows caused by taking the log of small inputs.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer, the axis to reduce over.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1. If `keepdims` is `True`, the reduced dimension is\n            retained with length 1.\n\n    # Returns\n        The reduced tensor.\n    \"\"\"\n    return tf.reduce_logsumexp(x, axis, keepdims)",
                "def round(x):\n    \"\"\"Element-wise rounding to the closest integer.\n\n    In case of tie, the rounding mode used is \"half to even\".\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.round(x)",
                "def sign(x):\n    \"\"\"Element-wise sign.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.sign(x)",
                "def pow(x, a):\n    \"\"\"Element-wise exponentiation.\n\n    # Arguments\n        x: Tensor or variable.\n        a: Python integer.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.pow(x, a)",
                "def clip(x, min_value, max_value):\n    \"\"\"Element-wise value clipping.\n\n    # Arguments\n        x: Tensor or variable.\n        min_value: Python float or integer.\n        max_value: Python float or integer.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if max_value is not None and max_value < min_value:\n        max_value = min_value\n    if max_value is None:\n        max_value = np.inf\n    min_value = _to_tensor(min_value, x.dtype.base_dtype)\n    max_value = _to_tensor(max_value, x.dtype.base_dtype)\n    return tf.clip_by_value(x, min_value, max_value)",
                "def equal(x, y):\n    \"\"\"Element-wise equality between two tensors.\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A bool tensor.\n    \"\"\"\n    return tf.equal(x, y)",
                "def not_equal(x, y):\n    \"\"\"Element-wise inequality between two tensors.\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A bool tensor.\n    \"\"\"\n    return tf.not_equal(x, y)",
                "def greater(x, y):\n    \"\"\"Element-wise truth value of (x > y).\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A bool tensor.\n    \"\"\"\n    return tf.greater(x, y)",
                "def greater_equal(x, y):\n    \"\"\"Element-wise truth value of (x >= y).\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A bool tensor.\n    \"\"\"\n    return tf.greater_equal(x, y)",
                "def less(x, y):\n    \"\"\"Element-wise truth value of (x < y).\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A bool tensor.\n    \"\"\"\n    return tf.less(x, y)",
                "def less_equal(x, y):\n    \"\"\"Element-wise truth value of (x <= y).\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A bool tensor.\n    \"\"\"\n    return tf.less_equal(x, y)",
                "def maximum(x, y):\n    \"\"\"Element-wise maximum of two tensors.\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.maximum(x, y)",
                "def minimum(x, y):\n    \"\"\"Element-wise minimum of two tensors.\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.minimum(x, y)",
                "def sin(x):\n    \"\"\"Computes sin of x element-wise.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.sin(x)",
                "def cos(x):\n    \"\"\"Computes cos of x element-wise.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.cos(x)",
                "def _regular_normalize_batch_in_training(x, gamma, beta,\n                                         reduction_axes, epsilon=1e-3):\n    \"\"\"Non-fused version of `normalize_batch_in_training`.\n\n    # Arguments\n        x: Input tensor or variable.\n        gamma: Tensor by which to scale the input.\n        beta: Tensor with which to center the input.\n        reduction_axes: iterable of integers,\n            axes over which to normalize.\n        epsilon: Fuzz factor.\n\n    # Returns\n        A tuple length of 3, `(normalized_tensor, mean, variance)`.\n    \"\"\"\n    mean, var = tf.nn.moments(x, reduction_axes,\n                              None, None, False)\n    normed = tf.nn.batch_normalization(x, mean, var,\n                                       beta, gamma,\n                                       epsilon)\n    return normed, mean, var",
                "def _broadcast_normalize_batch_in_training(x, gamma, beta,\n                                           reduction_axes, epsilon=1e-3):\n    \"\"\"Non-fused, broadcast version of `normalize_batch_in_training`.\n\n    # Arguments\n        x: Input tensor or variable.\n        gamma: Tensor by which to scale the input.\n        beta: Tensor with which to center the input.\n        reduction_axes: iterable of integers,\n            axes over which to normalize.\n        epsilon: Fuzz factor.\n\n    # Returns\n        A tuple length of 3, `(normalized_tensor, mean, variance)`.\n    \"\"\"\n    mean, var = tf.nn.moments(x, reduction_axes,\n                              None, None, False)\n    target_shape = []\n    for axis in range(ndim(x)):\n        if axis in reduction_axes:\n            target_shape.append(1)\n        else:\n            target_shape.append(tf.shape(x)[axis])\n    target_shape = tf.stack(target_shape)\n\n    broadcast_mean = tf.reshape(mean, target_shape)\n    broadcast_var = tf.reshape(var, target_shape)\n    if gamma is None:\n        broadcast_gamma = None\n    else:\n        broadcast_gamma = tf.reshape(gamma, target_shape)\n    if beta is None:\n        broadcast_beta = None\n    else:\n        broadcast_beta = tf.reshape(beta, target_shape)\n\n    normed = tf.nn.batch_normalization(\n        x,\n        broadcast_mean,\n        broadcast_var,\n        broadcast_beta,\n        broadcast_gamma,\n        epsilon)\n    return normed, mean, var",
                "def _fused_normalize_batch_in_training(x, gamma, beta, reduction_axes,\n                                       epsilon=1e-3):\n    \"\"\"Fused version of `normalize_batch_in_training`.\n\n    # Arguments\n        x: Input tensor or variable.\n        gamma: Tensor by which to scale the input.\n        beta: Tensor with which to center the input.\n        reduction_axes: iterable of integers,\n            axes over which to normalize.\n        epsilon: Fuzz factor.\n\n    # Returns\n        A tuple length of 3, `(normalized_tensor, mean, variance)`.\n    \"\"\"\n    if list(reduction_axes) == [0, 1, 2]:\n        normalization_axis = 3\n        tf_data_format = 'NHWC'\n    else:\n        normalization_axis = 1\n        tf_data_format = 'NCHW'\n\n    if gamma is None:\n        gamma = tf.constant(1.0,\n                            dtype=x.dtype,\n                            shape=[x.get_shape()[normalization_axis]])\n    if beta is None:\n        beta = tf.constant(0.0,\n                           dtype=x.dtype,\n                           shape=[x.get_shape()[normalization_axis]])\n\n    return tf.nn.fused_batch_norm(\n        x,\n        gamma,\n        beta,\n        epsilon=epsilon,\n        data_format=tf_data_format)",
                "def normalize_batch_in_training(x, gamma, beta,\n                                reduction_axes, epsilon=1e-3):\n    \"\"\"Computes mean and std for batch then apply batch_normalization on batch.\n\n    # Arguments\n        x: Input tensor or variable.\n        gamma: Tensor by which to scale the input.\n        beta: Tensor with which to center the input.\n        reduction_axes: iterable of integers,\n            axes over which to normalize.\n        epsilon: Fuzz factor.\n\n    # Returns\n        A tuple length of 3, `(normalized_tensor, mean, variance)`.\n    \"\"\"\n    if ndim(x) == 4 and list(reduction_axes) in [[0, 1, 2], [0, 2, 3]]:\n        if not _has_nchw_support() and list(reduction_axes) == [0, 2, 3]:\n            return _broadcast_normalize_batch_in_training(x, gamma, beta,\n                                                          reduction_axes,\n                                                          epsilon=epsilon)\n        return _fused_normalize_batch_in_training(\n            x, gamma, beta, reduction_axes,\n            epsilon=epsilon)\n    else:\n        if sorted(reduction_axes) == list(range(ndim(x)))[:-1]:\n            return _regular_normalize_batch_in_training(x, gamma, beta,\n                                                        reduction_axes,\n                                                        epsilon=epsilon)\n        else:\n            return _broadcast_normalize_batch_in_training(x, gamma, beta,\n                                                          reduction_axes,\n                                                          epsilon=epsilon)",
                "def batch_normalization(x, mean, var, beta, gamma, axis=-1, epsilon=1e-3):\n    \"\"\"Applies batch normalization on x given mean, var, beta and gamma.\n\n    I.e. returns:\n    `output = (x - mean) / sqrt(var + epsilon) * gamma + beta`\n\n    # Arguments\n        x: Input tensor or variable.\n        mean: Mean of batch.\n        var: Variance of batch.\n        beta: Tensor with which to center the input.\n        gamma: Tensor by which to scale the input.\n        axis: Integer, the axis that should be normalized.\n            (typically the features axis).\n        epsilon: Fuzz factor.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if ndim(x) == 4:\n        # The CPU implementation of FusedBatchNorm only support NHWC\n        if axis == 1 or axis == -3:\n            tf_data_format = 'NCHW'\n        elif axis == 3 or axis == -1:\n            tf_data_format = 'NHWC'\n        else:\n            tf_data_format = None\n\n        if tf_data_format == 'NHWC' or tf_data_format == 'NCHW' and _has_nchw_support():\n            # The mean / var / beta / gamma may be processed by broadcast\n            # so it may have extra axes with 1, it is not needed and should be removed\n            if ndim(mean) > 1:\n                mean = tf.squeeze(mean)\n            if ndim(var) > 1:\n                var = tf.squeeze(var)\n            if beta is None:\n                beta = zeros_like(mean)\n            elif ndim(beta) > 1:\n                beta = tf.squeeze(beta)\n            if gamma is None:\n                gamma = ones_like(mean)\n            elif ndim(gamma) > 1:\n                gamma = tf.squeeze(gamma)\n            y, _, _ = tf.nn.fused_batch_norm(\n                x,\n                gamma,\n                beta,\n                epsilon=epsilon,\n                mean=mean,\n                variance=var,\n                data_format=tf_data_format,\n                is_training=False\n            )\n            return y\n    # default\n    return tf.nn.batch_normalization(x, mean, var, beta, gamma, epsilon)",
                "def concatenate(tensors, axis=-1):\n    \"\"\"Concatenates a list of tensors alongside the specified axis.\n\n    # Arguments\n        tensors: list of tensors to concatenate.\n        axis: concatenation axis.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if axis < 0:\n        rank = ndim(tensors[0])\n        if rank:\n            axis %= rank\n        else:\n            axis = 0\n\n    if py_all([is_sparse(x) for x in tensors]):\n        return tf.sparse_concat(axis, tensors)\n    else:\n        return tf.concat([to_dense(x) for x in tensors], axis)",
                "def reshape(x, shape):\n    \"\"\"Reshapes a tensor to the specified shape.\n\n    # Arguments\n        x: Tensor or variable.\n        shape: Target shape tuple.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.reshape(x, shape)",
                "def permute_dimensions(x, pattern):\n    \"\"\"Permutes axes in a tensor.\n\n    # Arguments\n        x: Tensor or variable.\n        pattern: A tuple of\n            dimension indices, e.g. `(0, 2, 1)`.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.transpose(x, perm=pattern)",
                "def resize_images(x,\n                  height_factor,\n                  width_factor,\n                  data_format,\n                  interpolation='nearest'):\n    \"\"\"Resizes the images contained in a 4D tensor.\n\n    # Arguments\n        x: Tensor or variable to resize.\n        height_factor: Positive integer.\n        width_factor: Positive integer.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n        interpolation: A string, one of `nearest` or `bilinear`.\n\n    # Returns\n        A tensor.\n\n    # Raises\n        ValueError: if `data_format` is neither `\"channels_last\"` or `\"channels_first\"`.\n    \"\"\"\n    if data_format == 'channels_first':\n        rows, cols = 2, 3\n    else:\n        rows, cols = 1, 2\n\n    original_shape = int_shape(x)\n    new_shape = tf.shape(x)[rows:cols + 1]\n    new_shape *= tf.constant(np.array([height_factor, width_factor], dtype='int32'))\n\n    if data_format == 'channels_first':\n        x = permute_dimensions(x, [0, 2, 3, 1])\n    if interpolation == 'nearest':\n        x = tf.image.resize_nearest_neighbor(x, new_shape)\n    elif interpolation == 'bilinear':\n        x = tf.image.resize_bilinear(x, new_shape)\n    else:\n        raise ValueError('interpolation should be one '\n                         'of \"nearest\" or \"bilinear\".')\n    if data_format == 'channels_first':\n        x = permute_dimensions(x, [0, 3, 1, 2])\n\n    if original_shape[rows] is None:\n        new_height = None\n    else:\n        new_height = original_shape[rows] * height_factor\n\n    if original_shape[cols] is None:\n        new_width = None\n    else:\n        new_width = original_shape[cols] * width_factor\n\n    output_shape = (None, new_height, new_width, None)\n    x.set_shape(transpose_shape(output_shape, data_format, spatial_axes=(1, 2)))\n    return x",
                "def resize_volumes(x, depth_factor, height_factor, width_factor, data_format):\n    \"\"\"Resizes the volume contained in a 5D tensor.\n\n    # Arguments\n        x: Tensor or variable to resize.\n        depth_factor: Positive integer.\n        height_factor: Positive integer.\n        width_factor: Positive integer.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n\n    # Returns\n        A tensor.\n\n    # Raises\n        ValueError: if `data_format` is neither `\"channels_last\"` or `\"channels_first\"`.\n    \"\"\"\n    if data_format == 'channels_first':\n        output = repeat_elements(x, depth_factor, axis=2)\n        output = repeat_elements(output, height_factor, axis=3)\n        output = repeat_elements(output, width_factor, axis=4)\n        return output\n    elif data_format == 'channels_last':\n        output = repeat_elements(x, depth_factor, axis=1)\n        output = repeat_elements(output, height_factor, axis=2)\n        output = repeat_elements(output, width_factor, axis=3)\n        return output\n    else:\n        raise ValueError('Unknown data_format: ' + str(data_format))",
                "def repeat_elements(x, rep, axis):\n    \"\"\"Repeats the elements of a tensor along an axis, like `np.repeat`.\n\n    If `x` has shape `(s1, s2, s3)` and `axis` is `1`, the output\n    will have shape `(s1, s2 * rep, s3)`.\n\n    # Arguments\n        x: Tensor or variable.\n        rep: Python integer, number of times to repeat.\n        axis: Axis along which to repeat.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    x_shape = x.get_shape().as_list()\n    # For static axis\n    if x_shape[axis] is not None:\n        # slices along the repeat axis\n        splits = tf.split(value=x, num_or_size_splits=x_shape[axis], axis=axis)\n        # repeat each slice the given number of reps\n        x_rep = [s for s in splits for _ in range(rep)]\n        return concatenate(x_rep, axis)\n\n    # Here we use tf.tile to mimic behavior of np.repeat so that\n    # we can handle dynamic shapes (that include None).\n    # To do that, we need an auxiliary axis to repeat elements along\n    # it and then merge them along the desired axis.\n\n    # Repeating\n    auxiliary_axis = axis + 1\n    x_shape = tf.shape(x)\n    x_rep = tf.expand_dims(x, axis=auxiliary_axis)\n    reps = np.ones(len(x.get_shape()) + 1)\n    reps[auxiliary_axis] = rep\n    x_rep = tf.tile(x_rep, reps)\n\n    # Merging\n    reps = np.delete(reps, auxiliary_axis)\n    reps[axis] = rep\n    reps = tf.constant(reps, dtype='int32')\n    x_shape = x_shape * reps\n    x_rep = tf.reshape(x_rep, x_shape)\n\n    # Fix shape representation\n    x_shape = x.get_shape().as_list()\n    x_rep.set_shape(x_shape)\n    x_rep._keras_shape = tuple(x_shape)\n    return x_rep",
                "def repeat(x, n):\n    \"\"\"Repeats a 2D tensor.\n\n    if `x` has shape (samples, dim) and `n` is `2`,\n    the output will have shape `(samples, 2, dim)`.\n\n    # Arguments\n        x: Tensor or variable.\n        n: Python integer, number of times to repeat.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    assert ndim(x) == 2\n    x = tf.expand_dims(x, 1)\n    pattern = tf.stack([1, n, 1])\n    return tf.tile(x, pattern)",
                "def arange(start, stop=None, step=1, dtype='int32'):\n    \"\"\"Creates a 1D tensor containing a sequence of integers.\n\n    The function arguments use the same convention as\n    Theano's arange: if only one argument is provided,\n    it is in fact the \"stop\" argument and \"start\" is 0.\n\n    The default type of the returned tensor is `'int32'` to\n    match TensorFlow's default.\n\n    # Arguments\n        start: Start value.\n        stop: Stop value.\n        step: Difference between two successive values.\n        dtype: Integer dtype to use.\n\n    # Returns\n        An integer tensor.\n\n    \"\"\"\n    # Match the behavior of numpy and Theano by returning an empty sequence.\n    if stop is None:\n        try:\n            if start < 0:\n                start = 0\n        except TypeError:\n            # Handle case where start is a tensor\n            start = tf.cond(start < 0,\n                            true_fn=lambda: tf.constant(0, dtype=start.dtype),\n                            false_fn=lambda: start)\n\n    result = tf.range(start, limit=stop, delta=step, name='arange')\n    if dtype != 'int32':\n        result = cast(result, dtype)\n    return result",
                "def tile(x, n):\n    \"\"\"Creates a tensor by tiling `x` by `n`.\n\n    # Arguments\n        x: A tensor or variable\n        n: A list of integer. The length must be the same as the number of\n            dimensions in `x`.\n\n    # Returns\n        A tiled tensor.\n    \"\"\"\n    if isinstance(n, int):\n        n = [n]\n    return tf.tile(x, n)",
                "def flatten(x):\n    \"\"\"Flatten a tensor.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A tensor, reshaped into 1-D\n    \"\"\"\n    return tf.reshape(x, [-1])",
                "def batch_flatten(x):\n    \"\"\"Turn a nD tensor into a 2D tensor with same 0th dimension.\n\n    In other words, it flattens each data samples of a batch.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    x = tf.reshape(x, tf.stack([-1, prod(shape(x)[1:])]))\n    return x",
                "def expand_dims(x, axis=-1):\n    \"\"\"Adds a 1-sized dimension at index \"axis\".\n\n    # Arguments\n        x: A tensor or variable.\n        axis: Position where to add a new axis.\n\n    # Returns\n        A tensor with expanded dimensions.\n    \"\"\"\n    return tf.expand_dims(x, axis)",
                "def squeeze(x, axis):\n    \"\"\"Removes a 1-dimension from the tensor at index \"axis\".\n\n    # Arguments\n        x: A tensor or variable.\n        axis: Axis to drop.\n\n    # Returns\n        A tensor with the same data as `x` but reduced dimensions.\n    \"\"\"\n    return tf.squeeze(x, [axis])",
                "def temporal_padding(x, padding=(1, 1)):\n    \"\"\"Pads the middle dimension of a 3D tensor.\n\n    # Arguments\n        x: Tensor or variable.\n        padding: Tuple of 2 integers, how many zeros to\n            add at the start and end of dim 1.\n\n    # Returns\n        A padded 3D tensor.\n    \"\"\"\n    assert len(padding) == 2\n    pattern = [[0, 0], [padding[0], padding[1]], [0, 0]]\n    return tf.pad(x, pattern)",
                "def spatial_2d_padding(x, padding=((1, 1), (1, 1)), data_format=None):\n    \"\"\"Pads the 2nd and 3rd dimensions of a 4D tensor.\n\n    # Arguments\n        x: Tensor or variable.\n        padding: Tuple of 2 tuples, padding pattern.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n\n    # Returns\n        A padded 4D tensor.\n\n    # Raises\n        ValueError: if `data_format` is neither `\"channels_last\"` or `\"channels_first\"`.\n    \"\"\"\n    assert len(padding) == 2\n    assert len(padding[0]) == 2\n    assert len(padding[1]) == 2\n    data_format = normalize_data_format(data_format)\n\n    pattern = [[0, 0],\n               list(padding[0]),\n               list(padding[1]),\n               [0, 0]]\n    pattern = transpose_shape(pattern, data_format, spatial_axes=(1, 2))\n    return tf.pad(x, pattern)",
                "def spatial_3d_padding(x, padding=((1, 1), (1, 1), (1, 1)), data_format=None):\n    \"\"\"Pads 5D tensor with zeros along the depth, height, width dimensions.\n\n    Pads these dimensions with respectively\n    \"padding[0]\", \"padding[1]\" and \"padding[2]\" zeros left and right.\n\n    For 'channels_last' data_format,\n    the 2nd, 3rd and 4th dimension will be padded.\n    For 'channels_first' data_format,\n    the 3rd, 4th and 5th dimension will be padded.\n\n    # Arguments\n        x: Tensor or variable.\n        padding: Tuple of 3 tuples, padding pattern.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n\n    # Returns\n        A padded 5D tensor.\n\n    # Raises\n        ValueError: if `data_format` is neither `\"channels_last\"` or `\"channels_first\"`.\n\n    \"\"\"\n    assert len(padding) == 3\n    assert len(padding[0]) == 2\n    assert len(padding[1]) == 2\n    assert len(padding[2]) == 2\n    data_format = normalize_data_format(data_format)\n\n    pattern = [\n        [0, 0],\n        [padding[0][0], padding[0][1]],\n        [padding[1][0], padding[1][1]],\n        [padding[2][0], padding[2][1]],\n        [0, 0]\n    ]\n    pattern = transpose_shape(pattern, data_format, spatial_axes=(1, 2, 3))\n\n    return tf.pad(x, pattern)",
                "def stack(x, axis=0):\n    \"\"\"Stacks a list of rank `R` tensors into a rank `R+1` tensor.\n\n    # Arguments\n        x: List of tensors.\n        axis: Axis along which to perform stacking.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.stack(x, axis=axis)",
                "def one_hot(indices, num_classes):\n    \"\"\"Computes the one-hot representation of an integer tensor.\n\n    # Arguments\n        indices: nD integer tensor of shape\n            `(batch_size, dim1, dim2, ... dim(n-1))`\n        num_classes: Integer, number of classes to consider.\n\n    # Returns\n        (n + 1)D one hot representation of the input\n        with shape `(batch_size, dim1, dim2, ... dim(n-1), num_classes)`\n    \"\"\"\n    return tf.one_hot(indices, depth=num_classes, axis=-1)",
                "def reverse(x, axes):\n    \"\"\"Reverses a tensor along the specified axes.\n\n    # Arguments\n        x: Tensor to reverse.\n        axes: Integer or iterable of integers.\n            Axes to reverse.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if isinstance(axes, int):\n        axes = [axes]\n    return tf.reverse(x, axes)",
                "def slice(x, start, size):\n    \"\"\"Extracts a slice from a tensor.\n\n    # Arguments\n        x: Input tensor.\n        start: Integer list/tuple or tensor\n            indicating the start indices of the slice\n            along each axis.\n        size: Integer list/tuple or tensor\n            indicating how many dimensions to slice\n            along each axis.\n\n    # Returns\n        Tensor `x[start[0]: start[0] + size[0],\n                  ...,\n                  start[-1]: start[-1] + size[-1]]`\n    \"\"\"\n    return tf.slice(x, start, size)",
                "def get_value(x):\n    \"\"\"Returns the value of a variable.\n\n    # Arguments\n        x: input variable.\n\n    # Returns\n        A Numpy array.\n    \"\"\"\n    return x.eval(session=get_session())",
                "def batch_get_value(ops):\n    \"\"\"Returns the value of more than one tensor variable.\n\n    # Arguments\n        ops: list of ops to run.\n\n    # Returns\n        A list of Numpy arrays.\n    \"\"\"\n    if ops:\n        return get_session().run(ops)\n    else:\n        return []",
                "def set_value(x, value):\n    \"\"\"Sets the value of a variable, from a Numpy array.\n\n    # Arguments\n        x: Tensor to set to a new value.\n        value: Value to set the tensor to, as a Numpy array\n            (of the same shape).\n    \"\"\"\n    value = np.asarray(value, dtype=dtype(x))\n    tf_dtype = tf.as_dtype(x.dtype.name.split('_')[0])\n    if hasattr(x, '_assign_placeholder'):\n        assign_placeholder = x._assign_placeholder\n        assign_op = x._assign_op\n    else:\n        assign_placeholder = tf.placeholder(tf_dtype, shape=value.shape)\n        assign_op = x.assign(assign_placeholder)\n        x._assign_placeholder = assign_placeholder\n        x._assign_op = assign_op\n    get_session().run(assign_op, feed_dict={assign_placeholder: value})",
                "def batch_set_value(tuples):\n    \"\"\"Sets the values of many tensor variables at once.\n\n    # Arguments\n        tuples: a list of tuples `(tensor, value)`.\n            `value` should be a Numpy array.\n    \"\"\"\n    if tuples:\n        assign_ops = []\n        feed_dict = {}\n        for x, value in tuples:\n            value = np.asarray(value, dtype=dtype(x))\n            tf_dtype = tf.as_dtype(x.dtype.name.split('_')[0])\n            if hasattr(x, '_assign_placeholder'):\n                assign_placeholder = x._assign_placeholder\n                assign_op = x._assign_op\n            else:\n                assign_placeholder = tf.placeholder(tf_dtype,\n                                                    shape=value.shape)\n                assign_op = x.assign(assign_placeholder)\n                x._assign_placeholder = assign_placeholder\n                x._assign_op = assign_op\n            assign_ops.append(assign_op)\n            feed_dict[assign_placeholder] = value\n        get_session().run(assign_ops, feed_dict=feed_dict)",
                "def get_variable_shape(x):\n    \"\"\"Returns the shape of a variable.\n\n    # Arguments\n        x: A variable.\n\n    # Returns\n        A tuple of integers.\n    \"\"\"\n    return int_shape(x)",
                "def print_tensor(x, message=''):\n    \"\"\"Prints `message` and the tensor value when evaluated.\n\n     Note that `print_tensor` returns a new tensor identical to `x`\n     which should be used in the following code. Otherwise the\n     print operation is not taken into account during evaluation.\n\n     # Example\n     ```python\n         >>> x = K.print_tensor(x, message=\"x is: \")\n     ```\n\n    # Arguments\n        x: Tensor to print.\n        message: Message to print jointly with the tensor.\n\n    # Returns\n        The same tensor `x`, unchanged.\n    \"\"\"\n    return tf.Print(x, [x], message)",
                "def function(inputs, outputs, updates=None, **kwargs):\n    \"\"\"Instantiates a Keras function.\n\n    # Arguments\n        inputs: List of placeholder tensors.\n        outputs: List of output tensors.\n        updates: List of update ops.\n        **kwargs: Passed to `tf.Session.run`.\n\n    # Returns\n        Output values as Numpy arrays.\n\n    # Raises\n        ValueError: if invalid kwargs are passed in.\n    \"\"\"\n    if kwargs:\n        for key in kwargs:\n            if not (has_arg(tf.Session.run, key, True) or has_arg(Function.__init__, key, True)):\n                msg = 'Invalid argument \"%s\" passed to K.function with TensorFlow backend' % key\n                raise ValueError(msg)\n    return Function(inputs, outputs, updates=updates, **kwargs)",
                "def gradients(loss, variables):\n    \"\"\"Returns the gradients of `loss` w.r.t. `variables`.\n\n    # Arguments\n        loss: Scalar tensor to minimize.\n        variables: List of variables.\n\n    # Returns\n        A gradients tensor.\n    \"\"\"\n    return tf.gradients(loss, variables, colocate_gradients_with_ops=True)",
                "def stop_gradient(variables):\n    \"\"\"Returns `variables` but with zero gradient w.r.t. every other variable.\n\n    # Arguments\n        variables: tensor or list of tensors to consider constant with respect\n            to any other variable.\n\n    # Returns\n        A single tensor or a list of tensors (depending on the passed argument)\n            that has constant gradient with respect to any other variable.\n    \"\"\"\n    if isinstance(variables, (list, tuple)):\n        return map(tf.stop_gradient, variables)\n    else:\n        return tf.stop_gradient(variables)",
                "def rnn(step_function, inputs, initial_states,\n        go_backwards=False, mask=None, constants=None,\n        unroll=False, input_length=None):\n    \"\"\"Iterates over the time dimension of a tensor.\n\n    # Arguments\n        step_function:\n            Parameters:\n                inputs: Tensor with shape (samples, ...) (no time dimension),\n                    representing input for the batch of samples at a certain\n                    time step.\n                states: List of tensors.\n            Returns:\n                outputs: Tensor with shape (samples, ...) (no time dimension),\n                new_states: List of tensors, same length and shapes\n                    as 'states'.\n        inputs: Tensor of temporal data of shape (samples, time, ...)\n            (at least 3D).\n        initial_states: Tensor with shape (samples, ...) (no time dimension),\n            containing the initial values for the states used in\n            the step function.\n        go_backwards: Boolean. If True, do the iteration over the time\n            dimension in reverse order and return the reversed sequence.\n        mask: Binary tensor with shape (samples, time),\n            with a zero for every element that is masked.\n        constants: A list of constant values passed at each step.\n        unroll: Whether to unroll the RNN or to use a symbolic loop\n            (`while_loop` or `scan` depending on backend).\n        input_length: Static number of timesteps in the input.\n\n    # Returns\n        A tuple, `(last_output, outputs, new_states)`.\n\n        last_output: The latest output of the rnn, of shape `(samples, ...)`\n        outputs: Tensor with shape `(samples, time, ...)` where each\n            entry `outputs[s, t]` is the output of the step function\n            at time `t` for sample `s`.\n        new_states: List of tensors, latest states returned by\n            the step function, of shape `(samples, ...)`.\n\n    # Raises\n        ValueError: If input dimension is less than 3.\n        ValueError: If `unroll` is `True`\n            but input timestep is not a fixed number.\n        ValueError: If `mask` is provided (not `None`)\n            but states is not provided (`len(states)` == 0).\n    \"\"\"\n    ndim = len(inputs.get_shape())\n    if ndim < 3:\n        raise ValueError('Input should be at least 3D.')\n\n    # Transpose to time-major, i.e.\n    # from (batch, time, ...) to (time, batch, ...)\n    axes = [1, 0] + list(range(2, ndim))\n    inputs = tf.transpose(inputs, (axes))\n\n    if mask is not None:\n        if mask.dtype != tf.bool:\n            mask = tf.cast(mask, tf.bool)\n        if len(mask.get_shape()) == ndim - 1:\n            mask = expand_dims(mask)\n        mask = tf.transpose(mask, axes)\n\n    if constants is None:\n        constants = []\n\n    global uses_learning_phase\n    uses_learning_phase = False\n\n    if unroll:\n        if not inputs.get_shape()[0]:\n            raise ValueError('Unrolling requires a '\n                             'fixed number of timesteps.')\n        states = initial_states\n        successive_states = []\n        successive_outputs = []\n\n        input_list = tf.unstack(inputs)\n        if go_backwards:\n            input_list.reverse()\n\n        if mask is not None:\n            mask_list = tf.unstack(mask)\n            if go_backwards:\n                mask_list.reverse()\n\n            for inp, mask_t in zip(input_list, mask_list):\n                output, new_states = step_function(inp, states + constants)\n                if getattr(output, '_uses_learning_phase', False):\n                    uses_learning_phase = True\n\n                # tf.where needs its condition tensor\n                # to be the same shape as its two\n                # result tensors, but in our case\n                # the condition (mask) tensor is\n                # (nsamples, 1), and A and B are (nsamples, ndimensions).\n                # So we need to\n                # broadcast the mask to match the shape of A and B.\n                # That's what the tile call does,\n                # it just repeats the mask along its second dimension\n                # n times.\n                tiled_mask_t = tf.tile(mask_t,\n                                       tf.stack([1, tf.shape(output)[1]]))\n\n                if not successive_outputs:\n                    prev_output = zeros_like(output)\n                else:\n                    prev_output = successive_outputs[-1]\n\n                output = tf.where(tiled_mask_t, output, prev_output)\n\n                return_states = []\n                for state, new_state in zip(states, new_states):\n                    # (see earlier comment for tile explanation)\n                    tiled_mask_t = tf.tile(mask_t,\n                                           tf.stack([1, tf.shape(new_state)[1]]))\n                    return_states.append(tf.where(tiled_mask_t,\n                                                  new_state,\n                                                  state))\n                states = return_states\n                successive_outputs.append(output)\n                successive_states.append(states)\n            last_output = successive_outputs[-1]\n            new_states = successive_states[-1]\n            outputs = tf.stack(successive_outputs)\n        else:\n            for inp in input_list:\n                output, states = step_function(inp, states + constants)\n                if getattr(output, '_uses_learning_phase', False):\n                    uses_learning_phase = True\n                successive_outputs.append(output)\n                successive_states.append(states)\n            last_output = successive_outputs[-1]\n            new_states = successive_states[-1]\n            outputs = tf.stack(successive_outputs)\n\n    else:\n        if go_backwards:\n            inputs = reverse(inputs, 0)\n\n        states = tuple(initial_states)\n\n        time_steps = tf.shape(inputs)[0]\n        outputs, _ = step_function(inputs[0], initial_states + constants)\n        output_ta = tensor_array_ops.TensorArray(\n            dtype=outputs.dtype,\n            size=time_steps,\n            tensor_array_name='output_ta')\n        input_ta = tensor_array_ops.TensorArray(\n            dtype=inputs.dtype,\n            size=time_steps,\n            tensor_array_name='input_ta')\n        input_ta = input_ta.unstack(inputs)\n        time = tf.constant(0, dtype='int32', name='time')\n\n        if mask is not None:\n            if not states:\n                raise ValueError('No initial states provided! '\n                                 'When using masking in an RNN, you should '\n                                 'provide initial states '\n                                 '(and your step function should return '\n                                 'as its first state at time `t` '\n                                 'the output at time `t-1`).')\n            if go_backwards:\n                mask = reverse(mask, 0)\n\n            mask_ta = tensor_array_ops.TensorArray(\n                dtype=tf.bool,\n                size=time_steps,\n                tensor_array_name='mask_ta')\n            mask_ta = mask_ta.unstack(mask)\n\n            def _step(time, output_ta_t, *states):\n                \"\"\"RNN step function.\n\n                # Arguments\n                    time: Current timestep value.\n                    output_ta_t: TensorArray.\n                    *states: List of states.\n\n                # Returns\n                    Tuple: `(time + 1,output_ta_t) + tuple(new_states)`\n                \"\"\"\n                current_input = input_ta.read(time)\n                mask_t = mask_ta.read(time)\n                output, new_states = step_function(current_input,\n                                                   tuple(states) +\n                                                   tuple(constants))\n                if getattr(output, '_uses_learning_phase', False):\n                    global uses_learning_phase\n                    uses_learning_phase = True\n                for state, new_state in zip(states, new_states):\n                    new_state.set_shape(state.get_shape())\n                tiled_mask_t = tf.tile(mask_t,\n                                       tf.stack([1, tf.shape(output)[1]]))\n                output = tf.where(tiled_mask_t, output, states[0])\n                new_states = [\n                    tf.where(tf.tile(mask_t, tf.stack([1, tf.shape(new_states[i])[1]])),\n                             new_states[i], states[i]) for i in range(len(states))\n                ]\n                output_ta_t = output_ta_t.write(time, output)\n                return (time + 1, output_ta_t) + tuple(new_states)\n        else:\n            def _step(time, output_ta_t, *states):\n                \"\"\"RNN step function.\n\n                # Arguments\n                    time: Current timestep value.\n                    output_ta_t: TensorArray.\n                    *states: List of states.\n\n                # Returns\n                    Tuple: `(time + 1,output_ta_t) + tuple(new_states)`\n                \"\"\"\n                current_input = input_ta.read(time)\n                output, new_states = step_function(current_input,\n                                                   tuple(states) +\n                                                   tuple(constants))\n                if getattr(output, '_uses_learning_phase', False):\n                    global uses_learning_phase\n                    uses_learning_phase = True\n                for state, new_state in zip(states, new_states):\n                    new_state.set_shape(state.get_shape())\n                output_ta_t = output_ta_t.write(time, output)\n                return (time + 1, output_ta_t) + tuple(new_states)\n\n        final_outputs = control_flow_ops.while_loop(\n            cond=lambda time, *_: time < time_steps,\n            body=_step,\n            loop_vars=(time, output_ta) + states,\n            parallel_iterations=32,\n            swap_memory=True,\n            maximum_iterations=input_length)\n        last_time = final_outputs[0]\n        output_ta = final_outputs[1]\n        new_states = final_outputs[2:]\n\n        outputs = output_ta.stack()\n        last_output = output_ta.read(last_time - 1)\n\n    axes = [1, 0] + list(range(2, len(outputs.get_shape())))\n    outputs = tf.transpose(outputs, axes)\n    last_output._uses_learning_phase = uses_learning_phase\n    return last_output, outputs, new_states",
                "def switch(condition, then_expression, else_expression):\n    \"\"\"Switches between two operations depending on a scalar value.\n\n    Note that both `then_expression` and `else_expression`\n    should be symbolic tensors of the *same shape*.\n\n    # Arguments\n        condition: tensor (`int` or `bool`).\n        then_expression: either a tensor, or a callable that returns a tensor.\n        else_expression: either a tensor, or a callable that returns a tensor.\n\n    # Returns\n        The selected tensor.\n\n    # Raises\n        ValueError: If rank of `condition` is greater than rank of expressions.\n    \"\"\"\n    if condition.dtype != tf.bool:\n        condition = tf.cast(condition, 'bool')\n    cond_ndim = ndim(condition)\n    if not cond_ndim:\n        if not callable(then_expression):\n            def then_expression_fn():\n                return then_expression\n        else:\n            then_expression_fn = then_expression\n        if not callable(else_expression):\n            def else_expression_fn():\n                return else_expression\n        else:\n            else_expression_fn = else_expression\n        x = tf.cond(condition,\n                    then_expression_fn,\n                    else_expression_fn)\n    else:\n        # tf.where needs its condition tensor\n        # to be the same shape as its two\n        # result tensors\n        if callable(then_expression):\n            then_expression = then_expression()\n        if callable(else_expression):\n            else_expression = else_expression()\n        expr_ndim = ndim(then_expression)\n        if cond_ndim > expr_ndim:\n            raise ValueError('Rank of `condition` should be less than or'\n                             ' equal to rank of `then_expression` and '\n                             '`else_expression`. ndim(condition)=' +\n                             str(cond_ndim) + ', ndim(then_expression)'\n                             '=' + str(expr_ndim))\n        if cond_ndim > 1:\n            ndim_diff = expr_ndim - cond_ndim\n            cond_shape = tf.concat([tf.shape(condition), [1] * ndim_diff], axis=0)\n            condition = tf.reshape(condition, cond_shape)\n            expr_shape = tf.shape(then_expression)\n            shape_diff = expr_shape - cond_shape\n            tile_shape = tf.where(shape_diff > 0, expr_shape, tf.ones_like(expr_shape))\n            condition = tf.tile(condition, tile_shape)\n        x = tf.where(condition, then_expression, else_expression)\n    return x",
                "def in_train_phase(x, alt, training=None):\n    \"\"\"Selects `x` in train phase, and `alt` otherwise.\n\n    Note that `alt` should have the *same shape* as `x`.\n\n    # Arguments\n        x: What to return in train phase\n            (tensor or callable that returns a tensor).\n        alt: What to return otherwise\n            (tensor or callable that returns a tensor).\n        training: Optional scalar tensor\n            (or Python boolean, or Python integer)\n            specifying the learning phase.\n\n    # Returns\n        Either `x` or `alt` based on the `training` flag.\n        the `training` flag defaults to `K.learning_phase()`.\n    \"\"\"\n    if training is None:\n        training = learning_phase()\n        uses_learning_phase = True\n    else:\n        uses_learning_phase = False\n\n    if training is 1 or training is True:\n        if callable(x):\n            return x()\n        else:\n            return x\n\n    elif training is 0 or training is False:\n        if callable(alt):\n            return alt()\n        else:\n            return alt\n\n    # else: assume learning phase is a placeholder tensor.\n    x = switch(training, x, alt)\n    if uses_learning_phase:\n        x._uses_learning_phase = True\n    return x",
                "def in_test_phase(x, alt, training=None):\n    \"\"\"Selects `x` in test phase, and `alt` otherwise.\n\n    Note that `alt` should have the *same shape* as `x`.\n\n    # Arguments\n        x: What to return in test phase\n            (tensor or callable that returns a tensor).\n        alt: What to return otherwise\n            (tensor or callable that returns a tensor).\n        training: Optional scalar tensor\n            (or Python boolean, or Python integer)\n            specifying the learning phase.\n\n    # Returns\n        Either `x` or `alt` based on `K.learning_phase`.\n    \"\"\"\n    return in_train_phase(alt, x, training=training)",
                "def relu(x, alpha=0., max_value=None):\n    \"\"\"Rectified linear unit.\n\n    With default values, it returns element-wise `max(x, 0)`.\n\n    # Arguments\n        x: A tensor or variable.\n        alpha: A scalar, slope of negative section (default=`0.`).\n        max_value: Saturation threshold.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if alpha != 0.:\n        x = tf.nn.leaky_relu(x, alpha)\n    else:\n        x = tf.nn.relu(x)\n\n    if max_value is not None:\n        max_value = _to_tensor(max_value, x.dtype.base_dtype)\n        x = tf.minimum(x, max_value)\n    return x",
                "def elu(x, alpha=1.):\n    \"\"\"Exponential linear unit.\n\n    # Arguments\n        x: A tensor or variable to compute the activation function for.\n        alpha: A scalar, slope of negative section.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    res = tf.nn.elu(x)\n    if alpha == 1:\n        return res\n    else:\n        return tf.where(x > 0, res, alpha * res)",
                "def softmax(x, axis=-1):\n    \"\"\"Softmax of a tensor.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: The dimension softmax would be performed on.\n            The default is -1 which indicates the last dimension.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.nn.softmax(x, axis=axis)",
                "def softplus(x):\n    \"\"\"Softplus of a tensor.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.nn.softplus(x)",
                "def softsign(x):\n    \"\"\"Softsign of a tensor.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.nn.softsign(x)",
                "def categorical_crossentropy(target, output, from_logits=False, axis=-1):\n    \"\"\"Categorical crossentropy between an output tensor and a target tensor.\n\n    # Arguments\n        target: A tensor of the same shape as `output`.\n        output: A tensor resulting from a softmax\n            (unless `from_logits` is True, in which\n            case `output` is expected to be the logits).\n        from_logits: Boolean, whether `output` is the\n            result of a softmax, or is a tensor of logits.\n        axis: Int specifying the channels axis. `axis=-1`\n            corresponds to data format `channels_last`,\n            and `axis=1` corresponds to data format\n            `channels_first`.\n\n    # Returns\n        Output tensor.\n\n    # Raises\n        ValueError: if `axis` is neither -1 nor one of\n            the axes of `output`.\n    \"\"\"\n    output_dimensions = list(range(len(output.get_shape())))\n    if axis != -1 and axis not in output_dimensions:\n        raise ValueError(\n            '{}{}{}'.format(\n                'Unexpected channels axis {}. '.format(axis),\n                'Expected to be -1 or one of the axes of `output`, ',\n                'which has {} dimensions.'.format(len(output.get_shape()))))\n    # Note: tf.nn.softmax_cross_entropy_with_logits\n    # expects logits, Keras expects probabilities.\n    if not from_logits:\n        # scale preds so that the class probas of each sample sum to 1\n        output /= tf.reduce_sum(output, axis, True)\n        # manual computation of crossentropy\n        _epsilon = _to_tensor(epsilon(), output.dtype.base_dtype)\n        output = tf.clip_by_value(output, _epsilon, 1. - _epsilon)\n        return - tf.reduce_sum(target * tf.log(output), axis)\n    else:\n        return tf.nn.softmax_cross_entropy_with_logits(labels=target,\n                                                       logits=output)",
                "def sparse_categorical_crossentropy(target, output, from_logits=False, axis=-1):\n    \"\"\"Categorical crossentropy with integer targets.\n\n    # Arguments\n        target: An integer tensor.\n        output: A tensor resulting from a softmax\n            (unless `from_logits` is True, in which\n            case `output` is expected to be the logits).\n        from_logits: Boolean, whether `output` is the\n            result of a softmax, or is a tensor of logits.\n        axis: Int specifying the channels axis. `axis=-1`\n            corresponds to data format `channels_last`,\n            and `axis=1` corresponds to data format\n            `channels_first`.\n\n    # Returns\n        Output tensor.\n\n    # Raises\n        ValueError: if `axis` is neither -1 nor one of\n            the axes of `output`.\n    \"\"\"\n    output_dimensions = list(range(len(output.get_shape())))\n    if axis != -1 and axis not in output_dimensions:\n        raise ValueError(\n            '{}{}{}'.format(\n                'Unexpected channels axis {}. '.format(axis),\n                'Expected to be -1 or one of the axes of `output`, ',\n                'which has {} dimensions.'.format(len(output.get_shape()))))\n    # If the channels are not in the last axis, move them to be there:\n    if axis != -1 and axis != output_dimensions[-1]:\n        permutation = output_dimensions[:axis] + output_dimensions[axis + 1:]\n        permutation += [axis]\n        output = tf.transpose(output, perm=permutation)\n\n    # Note: tf.nn.sparse_softmax_cross_entropy_with_logits\n    # expects logits, Keras expects probabilities.\n    if not from_logits:\n        _epsilon = _to_tensor(epsilon(), output.dtype.base_dtype)\n        output = tf.clip_by_value(output, _epsilon, 1 - _epsilon)\n        output = tf.log(output)\n\n    output_shape = output.get_shape()\n    targets = cast(flatten(target), 'int64')\n    logits = tf.reshape(output, [-1, int(output_shape[-1])])\n    res = tf.nn.sparse_softmax_cross_entropy_with_logits(\n        labels=targets,\n        logits=logits)\n    if len(output_shape) >= 3:\n        # if our output includes timestep dimension\n        # or spatial dimensions we need to reshape\n        return tf.reshape(res, tf.shape(output)[:-1])\n    else:\n        return res",
                "def binary_crossentropy(target, output, from_logits=False):\n    \"\"\"Binary crossentropy between an output tensor and a target tensor.\n\n    # Arguments\n        target: A tensor with the same shape as `output`.\n        output: A tensor.\n        from_logits: Whether `output` is expected to be a logits tensor.\n            By default, we consider that `output`\n            encodes a probability distribution.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    # Note: tf.nn.sigmoid_cross_entropy_with_logits\n    # expects logits, Keras expects probabilities.\n    if not from_logits:\n        # transform back to logits\n        _epsilon = _to_tensor(epsilon(), output.dtype.base_dtype)\n        output = tf.clip_by_value(output, _epsilon, 1 - _epsilon)\n        output = tf.log(output / (1 - output))\n\n    return tf.nn.sigmoid_cross_entropy_with_logits(labels=target,\n                                                   logits=output)",
                "def sigmoid(x):\n    \"\"\"Element-wise sigmoid.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.nn.sigmoid(x)",
                "def hard_sigmoid(x):\n    \"\"\"Segment-wise linear approximation of sigmoid.\n\n    Faster than sigmoid.\n    Returns `0.` if `x < -2.5`, `1.` if `x > 2.5`.\n    In `-2.5 <= x <= 2.5`, returns `0.2 * x + 0.5`.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    x = (0.2 * x) + 0.5\n    zero = _to_tensor(0., x.dtype.base_dtype)\n    one = _to_tensor(1., x.dtype.base_dtype)\n    x = tf.clip_by_value(x, zero, one)\n    return x",
                "def tanh(x):\n    \"\"\"Element-wise tanh.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.nn.tanh(x)",
                "def dropout(x, level, noise_shape=None, seed=None):\n    \"\"\"Sets entries in `x` to zero at random, while scaling the entire tensor.\n\n    # Arguments\n        x: tensor\n        level: fraction of the entries in the tensor\n            that will be set to 0.\n        noise_shape: shape for randomly generated keep/drop flags,\n            must be broadcastable to the shape of `x`\n        seed: random seed to ensure determinism.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    retain_prob = 1. - level\n    if seed is None:\n        seed = np.random.randint(10e6)\n    # the dummy 1. works around a TF bug\n    # (float32_ref vs. float32 incompatibility)\n    return tf.nn.dropout(x * 1., retain_prob, noise_shape, seed=seed)",
                "def l2_normalize(x, axis=None):\n    \"\"\"Normalizes a tensor wrt the L2 norm alongside the specified axis.\n\n    # Arguments\n        x: Tensor or variable.\n        axis: axis along which to perform normalization.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.nn.l2_normalize(x, axis=axis)",
                "def in_top_k(predictions, targets, k):\n    \"\"\"Returns whether the `targets` are in the top `k` `predictions`.\n\n    # Arguments\n        predictions: A tensor of shape `(batch_size, classes)` and type `float32`.\n        targets: A 1D tensor of length `batch_size` and type `int32` or `int64`.\n        k: An `int`, number of top elements to consider.\n\n    # Returns\n        A 1D tensor of length `batch_size` and type `bool`.\n        `output[i]` is `True` if `predictions[i, targets[i]]` is within top-`k`\n        values of `predictions[i]`.\n    \"\"\"\n    return tf.nn.in_top_k(predictions, targets, k)",
                "def _preprocess_conv1d_input(x, data_format):\n    \"\"\"Transpose and cast the input before the conv1d.\n\n    # Arguments\n        x: input tensor.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    # tensorflow doesn't support float64 for conv layer before 1.8.0\n    if (dtype(x) == 'float64' and\n            StrictVersion(tf.__version__.split('-')[0]) < StrictVersion('1.8.0')):\n        x = tf.cast(x, 'float32')\n    tf_data_format = 'NWC'  # to pass TF Conv2dNative operations\n    if data_format == 'channels_first':\n        if not _has_nchw_support():\n            x = tf.transpose(x, (0, 2, 1))  # NCW -> NWC\n        else:\n            tf_data_format = 'NCW'\n    return x, tf_data_format",
                "def _preprocess_conv2d_input(x, data_format):\n    \"\"\"Transpose and cast the input before the conv2d.\n\n    # Arguments\n        x: input tensor.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    # tensorflow doesn't support float64 for conv layer before 1.8.0\n    if (dtype(x) == 'float64' and\n            StrictVersion(tf.__version__.split('-')[0]) < StrictVersion('1.8.0')):\n        x = tf.cast(x, 'float32')\n    tf_data_format = 'NHWC'\n    if data_format == 'channels_first':\n        if not _has_nchw_support():\n            x = tf.transpose(x, (0, 2, 3, 1))  # NCHW -> NHWC\n        else:\n            tf_data_format = 'NCHW'\n    return x, tf_data_format",
                "def _preprocess_conv3d_input(x, data_format):\n    \"\"\"Transpose and cast the input before the conv3d.\n\n    # Arguments\n        x: input tensor.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    # tensorflow doesn't support float64 for conv layer before 1.8.0\n    if (dtype(x) == 'float64' and\n            StrictVersion(tf.__version__.split('-')[0]) < StrictVersion('1.8.0')):\n        x = tf.cast(x, 'float32')\n    tf_data_format = 'NDHWC'\n    if data_format == 'channels_first':\n        if not _has_nchw_support():\n            x = tf.transpose(x, (0, 2, 3, 4, 1))\n        else:\n            tf_data_format = 'NCDHW'\n    return x, tf_data_format",
                "def _preprocess_padding(padding):\n    \"\"\"Convert keras' padding to tensorflow's padding.\n\n    # Arguments\n        padding: string, `\"same\"` or `\"valid\"`.\n\n    # Returns\n        a string, `\"SAME\"` or `\"VALID\"`.\n\n    # Raises\n        ValueError: if `padding` is invalid.\n    \"\"\"\n    if padding == 'same':\n        padding = 'SAME'\n    elif padding == 'valid':\n        padding = 'VALID'\n    else:\n        raise ValueError('Invalid padding: ' + str(padding))\n    return padding",
                "def conv1d(x, kernel, strides=1, padding='valid',\n           data_format=None, dilation_rate=1):\n    \"\"\"1D convolution.\n\n    # Arguments\n        x: Tensor or variable.\n        kernel: kernel tensor.\n        strides: stride integer.\n        padding: string, `\"same\"`, `\"causal\"` or `\"valid\"`.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n        dilation_rate: integer dilate rate.\n\n    # Returns\n        A tensor, result of 1D convolution.\n\n    # Raises\n        ValueError: If `data_format` is neither\n            `\"channels_last\"` nor `\"channels_first\"`.\n    \"\"\"\n    data_format = normalize_data_format(data_format)\n\n    kernel_shape = kernel.get_shape().as_list()\n    if padding == 'causal':\n        if data_format != 'channels_last':\n            raise ValueError('When using causal padding in `conv1d`, '\n                             '`data_format` must be \"channels_last\" '\n                             '(temporal data).')\n        # causal (dilated) convolution:\n        left_pad = dilation_rate * (kernel_shape[0] - 1)\n        x = temporal_padding(x, (left_pad, 0))\n        padding = 'valid'\n    padding = _preprocess_padding(padding)\n    x, tf_data_format = _preprocess_conv1d_input(x, data_format)\n    x = tf.nn.convolution(\n        input=x,\n        filter=kernel,\n        dilation_rate=(dilation_rate,),\n        strides=(strides,),\n        padding=padding,\n        data_format=tf_data_format)\n\n    if data_format == 'channels_first' and tf_data_format == 'NWC':\n        x = tf.transpose(x, (0, 2, 1))  # NWC -> NCW\n    return x",
                "def conv2d(x, kernel, strides=(1, 1), padding='valid',\n           data_format=None, dilation_rate=(1, 1)):\n    \"\"\"2D convolution.\n\n    # Arguments\n        x: Tensor or variable.\n        kernel: kernel tensor.\n        strides: strides tuple.\n        padding: string, `\"same\"` or `\"valid\"`.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n            Whether to use Theano or TensorFlow/CNTK data format\n            for inputs/kernels/outputs.\n        dilation_rate: tuple of 2 integers.\n\n    # Returns\n        A tensor, result of 2D convolution.\n\n    # Raises\n        ValueError: If `data_format` is neither\n            `\"channels_last\"` nor `\"channels_first\"`.\n    \"\"\"\n    data_format = normalize_data_format(data_format)\n\n    x, tf_data_format = _preprocess_conv2d_input(x, data_format)\n\n    padding = _preprocess_padding(padding)\n    x = tf.nn.convolution(\n        input=x,\n        filter=kernel,\n        dilation_rate=dilation_rate,\n        strides=strides,\n        padding=padding,\n        data_format=tf_data_format)\n\n    if data_format == 'channels_first' and tf_data_format == 'NHWC':\n        x = tf.transpose(x, (0, 3, 1, 2))  # NHWC -> NCHW\n    return x",
                "def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),\n                     padding='valid', data_format=None):\n    \"\"\"2D deconvolution (i.e. transposed convolution).\n\n    # Arguments\n        x: Tensor or variable.\n        kernel: kernel tensor.\n        output_shape: 1D int tensor for the output shape.\n        strides: strides tuple.\n        padding: string, `\"same\"` or `\"valid\"`.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n            Whether to use Theano or TensorFlow/CNTK data format\n            for inputs/kernels/outputs.\n\n    # Returns\n        A tensor, result of transposed 2D convolution.\n\n    # Raises\n        ValueError: If `data_format` is neither\n            `\"channels_last\"` nor `\"channels_first\"`.\n    \"\"\"\n    data_format = normalize_data_format(data_format)\n    if isinstance(output_shape, (tuple, list)):\n        output_shape = tf.stack(output_shape)\n\n    x, tf_data_format = _preprocess_conv2d_input(x, data_format)\n\n    if data_format == 'channels_first' and tf_data_format == 'NHWC':\n        output_shape = (output_shape[0],\n                        output_shape[2],\n                        output_shape[3],\n                        output_shape[1])\n    if output_shape[0] is None:\n        output_shape = (tf.shape(x)[0],) + tuple(output_shape[1:])\n        output_shape = tf.stack(list(output_shape))\n\n    padding = _preprocess_padding(padding)\n    if tf_data_format == 'NHWC':\n        strides = (1,) + strides + (1,)\n    else:\n        strides = (1, 1) + strides\n\n    x = tf.nn.conv2d_transpose(x, kernel, output_shape, strides,\n                               padding=padding,\n                               data_format=tf_data_format)\n    if data_format == 'channels_first' and tf_data_format == 'NHWC':\n        x = tf.transpose(x, (0, 3, 1, 2))  # NHWC -> NCHW\n    return x",
                "def separable_conv1d(x, depthwise_kernel, pointwise_kernel, strides=1,\n                     padding='valid', data_format=None, dilation_rate=1):\n    \"\"\"1D convolution with separable filters.\n\n    # Arguments\n        x: input tensor\n        depthwise_kernel: convolution kernel for the depthwise convolution.\n        pointwise_kernel: kernel for the 1x1 convolution.\n        strides: stride integer.\n        padding: string, `\"same\"` or `\"valid\"`.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n        dilation_rate: integer dilation rate.\n\n    # Returns\n        Output tensor.\n\n    # Raises\n        ValueError: If `data_format` is neither\n            `\"channels_last\"` nor `\"channels_first\"`.\n    \"\"\"\n    data_format = normalize_data_format(data_format)\n    if isinstance(strides, int):\n        strides = (strides,)\n    if isinstance(dilation_rate, int):\n        dilation_rate = (dilation_rate,)\n\n    x, tf_data_format = _preprocess_conv1d_input(x, data_format)\n    if tf_data_format == 'NWC':\n        tf_data_format = 'NHWC'\n    else:\n        tf_data_format = 'NCHW'\n    padding = _preprocess_padding(padding)\n    if tf_data_format == 'NHWC':\n        spatial_start_dim = 1\n        strides = (1,) + strides * 2 + (1,)\n    else:\n        spatial_start_dim = 2\n        strides = (1, 1) + strides * 2\n    x = tf.expand_dims(x, spatial_start_dim)\n    depthwise_kernel = tf.expand_dims(depthwise_kernel, 0)\n    pointwise_kernel = tf.expand_dims(pointwise_kernel, 0)\n    dilation_rate = (1,) + dilation_rate\n\n    x = tf.nn.separable_conv2d(x, depthwise_kernel, pointwise_kernel,\n                               strides=strides,\n                               padding=padding,\n                               rate=dilation_rate,\n                               data_format=tf_data_format)\n\n    x = tf.squeeze(x, [spatial_start_dim])\n\n    if data_format == 'channels_first' and tf_data_format == 'NHWC':\n        x = tf.transpose(x, (0, 2, 1))  # NWC -> NCW\n\n    return x",
                "def separable_conv2d(x, depthwise_kernel, pointwise_kernel, strides=(1, 1),\n                     padding='valid', data_format=None, dilation_rate=(1, 1)):\n    \"\"\"2D convolution with separable filters.\n\n    # Arguments\n        x: input tensor\n        depthwise_kernel: convolution kernel for the depthwise convolution.\n        pointwise_kernel: kernel for the 1x1 convolution.\n        strides: strides tuple (length 2).\n        padding: string, `\"same\"` or `\"valid\"`.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n        dilation_rate: tuple of integers,\n            dilation rates for the separable convolution.\n\n    # Returns\n        Output tensor.\n\n    # Raises\n        ValueError: If `data_format` is neither\n            `\"channels_last\"` nor `\"channels_first\"`.\n    \"\"\"\n    data_format = normalize_data_format(data_format)\n\n    x, tf_data_format = _preprocess_conv2d_input(x, data_format)\n    padding = _preprocess_padding(padding)\n    if tf_data_format == 'NHWC':\n        strides = (1,) + strides + (1,)\n    else:\n        strides = (1, 1) + strides\n\n    x = tf.nn.separable_conv2d(x, depthwise_kernel, pointwise_kernel,\n                               strides=strides,\n                               padding=padding,\n                               rate=dilation_rate,\n                               data_format=tf_data_format)\n    if data_format == 'channels_first' and tf_data_format == 'NHWC':\n        x = tf.transpose(x, (0, 3, 1, 2))  # NHWC -> NCHW\n    return x",
                "def depthwise_conv2d(x, depthwise_kernel, strides=(1, 1), padding='valid',\n                     data_format=None, dilation_rate=(1, 1)):\n    \"\"\"2D convolution with separable filters.\n\n    # Arguments\n        x: input tensor\n        depthwise_kernel: convolution kernel for the depthwise convolution.\n        strides: strides tuple (length 2).\n        padding: string, `\"same\"` or `\"valid\"`.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n        dilation_rate: tuple of integers,\n            dilation rates for the separable convolution.\n\n    # Returns\n        Output tensor.\n\n    # Raises\n        ValueError: If `data_format` is neither\n            `\"channels_last\"` nor `\"channels_first\"`.\n    \"\"\"\n    data_format = normalize_data_format(data_format)\n\n    x, tf_data_format = _preprocess_conv2d_input(x, data_format)\n    padding = _preprocess_padding(padding)\n    if tf_data_format == 'NHWC':\n        strides = (1,) + strides + (1,)\n    else:\n        strides = (1, 1) + strides\n\n    x = tf.nn.depthwise_conv2d(x, depthwise_kernel,\n                               strides=strides,\n                               padding=padding,\n                               rate=dilation_rate,\n                               data_format=tf_data_format)\n    if data_format == 'channels_first' and tf_data_format == 'NHWC':\n        x = tf.transpose(x, (0, 3, 1, 2))  # NHWC -> NCHW\n    return x",
                "def conv3d(x, kernel, strides=(1, 1, 1), padding='valid',\n           data_format=None, dilation_rate=(1, 1, 1)):\n    \"\"\"3D convolution.\n\n    # Arguments\n        x: Tensor or variable.\n        kernel: kernel tensor.\n        strides: strides tuple.\n        padding: string, `\"same\"` or `\"valid\"`.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n            Whether to use Theano or TensorFlow/CNTK data format\n            for inputs/kernels/outputs.\n        dilation_rate: tuple of 3 integers.\n\n    # Returns\n        A tensor, result of 3D convolution.\n\n    # Raises\n        ValueError: If `data_format` is neither\n            `\"channels_last\"` nor `\"channels_first\"`.\n    \"\"\"\n    data_format = normalize_data_format(data_format)\n\n    x, tf_data_format = _preprocess_conv3d_input(x, data_format)\n    padding = _preprocess_padding(padding)\n    x = tf.nn.convolution(\n        input=x,\n        filter=kernel,\n        dilation_rate=dilation_rate,\n        strides=strides,\n        padding=padding,\n        data_format=tf_data_format)\n    if data_format == 'channels_first' and tf_data_format == 'NDHWC':\n        x = tf.transpose(x, (0, 4, 1, 2, 3))\n    return x",
                "def conv3d_transpose(x, kernel, output_shape, strides=(1, 1, 1),\n                     padding='valid', data_format=None):\n    \"\"\"3D deconvolution (i.e. transposed convolution).\n\n    # Arguments\n        x: input tensor.\n        kernel: kernel tensor.\n        output_shape: 1D int tensor for the output shape.\n        strides: strides tuple.\n        padding: string, \"same\" or \"valid\".\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n            Whether to use Theano or TensorFlow/CNTK data format\n            for inputs/kernels/outputs.\n\n    # Returns\n        A tensor, result of transposed 3D convolution.\n\n    # Raises\n        ValueError: If `data_format` is neither\n            `\"channels_last\"` nor `\"channels_first\"`.\n    \"\"\"\n    data_format = normalize_data_format(data_format)\n    if isinstance(output_shape, (tuple, list)):\n        output_shape = tf.stack(output_shape)\n\n    x, tf_data_format = _preprocess_conv3d_input(x, data_format)\n\n    if data_format == 'channels_first' and tf_data_format == 'NDHWC':\n        output_shape = (output_shape[0],\n                        output_shape[2],\n                        output_shape[3],\n                        output_shape[4],\n                        output_shape[1])\n    if output_shape[0] is None:\n        output_shape = (tf.shape(x)[0],) + tuple(output_shape[1:])\n        output_shape = tf.stack(list(output_shape))\n\n    padding = _preprocess_padding(padding)\n    if tf_data_format == 'NDHWC':\n        strides = (1,) + strides + (1,)\n    else:\n        strides = (1, 1) + strides\n\n    x = tf.nn.conv3d_transpose(x, kernel, output_shape, strides,\n                               padding=padding,\n                               data_format=tf_data_format)\n    if data_format == 'channels_first' and tf_data_format == 'NDHWC':\n        x = tf.transpose(x, (0, 4, 1, 2, 3))\n    return x",
                "def pool2d(x, pool_size, strides=(1, 1),\n           padding='valid', data_format=None,\n           pool_mode='max'):\n    \"\"\"2D Pooling.\n\n    # Arguments\n        x: Tensor or variable.\n        pool_size: tuple of 2 integers.\n        strides: tuple of 2 integers.\n        padding: string, `\"same\"` or `\"valid\"`.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n        pool_mode: string, `\"max\"` or `\"avg\"`.\n\n    # Returns\n        A tensor, result of 2D pooling.\n\n    # Raises\n        ValueError: if `data_format` is neither `\"channels_last\"` or `\"channels_first\"`.\n        ValueError: if `pool_mode` is neither `\"max\"` or `\"avg\"`.\n    \"\"\"\n    data_format = normalize_data_format(data_format)\n\n    x, tf_data_format = _preprocess_conv2d_input(x, data_format)\n    padding = _preprocess_padding(padding)\n    if tf_data_format == 'NHWC':\n        strides = (1,) + strides + (1,)\n        pool_size = (1,) + pool_size + (1,)\n    else:\n        strides = (1, 1) + strides\n        pool_size = (1, 1) + pool_size\n\n    if pool_mode == 'max':\n        x = tf.nn.max_pool(x, pool_size, strides,\n                           padding=padding,\n                           data_format=tf_data_format)\n    elif pool_mode == 'avg':\n        x = tf.nn.avg_pool(x, pool_size, strides,\n                           padding=padding,\n                           data_format=tf_data_format)\n    else:\n        raise ValueError('Invalid pool_mode: ' + str(pool_mode))\n\n    if data_format == 'channels_first' and tf_data_format == 'NHWC':\n        x = tf.transpose(x, (0, 3, 1, 2))  # NHWC -> NCHW\n    return x",
                "def pool3d(x, pool_size, strides=(1, 1, 1), padding='valid',\n           data_format=None, pool_mode='max'):\n    \"\"\"3D Pooling.\n\n    # Arguments\n        x: Tensor or variable.\n        pool_size: tuple of 3 integers.\n        strides: tuple of 3 integers.\n        padding: string, `\"same\"` or `\"valid\"`.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n        pool_mode: string, `\"max\"` or `\"avg\"`.\n\n    # Returns\n        A tensor, result of 3D pooling.\n\n    # Raises\n        ValueError: if `data_format` is neither `\"channels_last\"` or `\"channels_first\"`.\n        ValueError: if `pool_mode` is neither `\"max\"` or `\"avg\"`.\n    \"\"\"\n    data_format = normalize_data_format(data_format)\n\n    x, tf_data_format = _preprocess_conv3d_input(x, data_format)\n    padding = _preprocess_padding(padding)\n    if tf_data_format == 'NDHWC':\n        strides = (1,) + strides + (1,)\n        pool_size = (1,) + pool_size + (1,)\n    else:\n        strides = (1, 1) + strides\n        pool_size = (1, 1) + pool_size\n\n    if pool_mode == 'max':\n        x = tf.nn.max_pool3d(x, pool_size, strides,\n                             padding=padding,\n                             data_format=tf_data_format)\n    elif pool_mode == 'avg':\n        x = tf.nn.avg_pool3d(x, pool_size, strides,\n                             padding=padding,\n                             data_format=tf_data_format)\n    else:\n        raise ValueError('Invalid pool_mode: ' + str(pool_mode))\n\n    if data_format == 'channels_first' and tf_data_format == 'NDHWC':\n        x = tf.transpose(x, (0, 4, 1, 2, 3))\n    return x",
                "def bias_add(x, bias, data_format=None):\n    \"\"\"Adds a bias vector to a tensor.\n\n    # Arguments\n        x: Tensor or variable.\n        bias: Bias tensor to add.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n\n    # Returns\n        Output tensor.\n\n    # Raises\n        ValueError: In one of the two cases below:\n                    1. invalid `data_format` argument.\n                    2. invalid bias shape.\n                       the bias should be either a vector or\n                       a tensor with ndim(x) - 1 dimension\n    \"\"\"\n    data_format = normalize_data_format(data_format)\n    bias_shape = int_shape(bias)\n    if len(bias_shape) != 1 and len(bias_shape) != ndim(x) - 1:\n        raise ValueError('Unexpected bias dimensions %d, expect to be 1 or %d dimensions'\n                         % (len(bias_shape), ndim(x)))\n    if ndim(x) == 5:\n        if len(bias_shape) == 1:\n            new_shape = (1, 1, 1, 1, bias_shape[0])\n        else:\n            new_shape = (1,) + bias_shape\n        new_shape = transpose_shape(new_shape, data_format, spatial_axes=(1, 2, 3))\n        x += reshape(bias, new_shape)\n    elif ndim(x) == 4:\n        if data_format == 'channels_first':\n            if len(bias_shape) == 1:\n                if _has_nchw_support():\n                    x = tf.nn.bias_add(x, bias,\n                                       data_format='NCHW')\n                else:\n                    x += reshape(bias, (1, bias_shape[0], 1, 1))\n            else:\n                x += reshape(bias, (1, bias_shape[2]) + bias_shape[:2])\n        elif data_format == 'channels_last':\n            if len(bias_shape) == 1:\n                x = tf.nn.bias_add(x, bias,\n                                   data_format='NHWC')\n            else:\n                x += reshape(bias, (1,) + bias_shape)\n    elif ndim(x) == 3:\n        if len(bias_shape) == 1:\n            new_shape = (1, 1, bias_shape[0])\n        else:\n            new_shape = (1,) + bias_shape\n        new_shape = transpose_shape(new_shape, data_format, spatial_axes=(1,))\n        x += reshape(bias, new_shape)\n    else:\n        x = tf.nn.bias_add(x, bias)\n    return x",
                "def random_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n    \"\"\"Returns a tensor with normal distribution of values.\n\n    # Arguments\n        shape: A tuple of integers, the shape of tensor to create.\n        mean: A float, mean of the normal distribution to draw samples.\n        stddev: A float, standard deviation of the normal distribution\n            to draw samples.\n        dtype: String, dtype of returned tensor.\n        seed: Integer, random seed.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    if seed is None:\n        seed = np.random.randint(10e6)\n    return tf.random_normal(shape, mean=mean, stddev=stddev,\n                            dtype=dtype, seed=seed)",
                "def random_uniform(shape, minval=0.0, maxval=1.0, dtype=None, seed=None):\n    \"\"\"Returns a tensor with uniform distribution of values.\n\n    # Arguments\n        shape: A tuple of integers, the shape of tensor to create.\n        minval: A float, lower boundary of the uniform distribution\n            to draw samples.\n        maxval: A float, upper boundary of the uniform distribution\n            to draw samples.\n        dtype: String, dtype of returned tensor.\n        seed: Integer, random seed.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    if seed is None:\n        seed = np.random.randint(10e6)\n    return tf.random_uniform(shape, minval=minval, maxval=maxval,\n                             dtype=dtype, seed=seed)",
                "def random_binomial(shape, p=0.0, dtype=None, seed=None):\n    \"\"\"Returns a tensor with random binomial distribution of values.\n\n    # Arguments\n        shape: A tuple of integers, the shape of tensor to create.\n        p: A float, `0. <= p <= 1`, probability of binomial distribution.\n        dtype: String, dtype of returned tensor.\n        seed: Integer, random seed.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    if seed is None:\n        seed = np.random.randint(10e6)\n    return tf.where(tf.random_uniform(shape, dtype=dtype, seed=seed) <= p,\n                    tf.ones(shape, dtype=dtype),\n                    tf.zeros(shape, dtype=dtype))",
                "def truncated_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n    \"\"\"Returns a tensor with truncated random normal distribution of values.\n\n    The generated values follow a normal distribution\n    with specified mean and standard deviation,\n    except that values whose magnitude is more than\n    two standard deviations from the mean are dropped and re-picked.\n\n    # Arguments\n        shape: A tuple of integers, the shape of tensor to create.\n        mean: Mean of the values.\n        stddev: Standard deviation of the values.\n        dtype: String, dtype of returned tensor.\n        seed: Integer, random seed.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    if seed is None:\n        seed = np.random.randint(10e6)\n    return tf.truncated_normal(shape, mean, stddev, dtype=dtype, seed=seed)",
                "def ctc_label_dense_to_sparse(labels, label_lengths):\n    \"\"\"Converts CTC labels from dense to sparse.\n\n    # Arguments\n        labels: dense CTC labels.\n        label_lengths: length of the labels.\n\n    # Returns\n        A sparse tensor representation of the labels.\n    \"\"\"\n    label_shape = tf.shape(labels)\n    num_batches_tns = tf.stack([label_shape[0]])\n    max_num_labels_tns = tf.stack([label_shape[1]])\n\n    def range_less_than(_, current_input):\n        return tf.expand_dims(tf.range(label_shape[1]), 0) < tf.fill(\n            max_num_labels_tns, current_input)\n\n    init = tf.cast(tf.fill([1, label_shape[1]], 0), tf.bool)\n    dense_mask = functional_ops.scan(range_less_than, label_lengths,\n                                     initializer=init, parallel_iterations=1)\n    dense_mask = dense_mask[:, 0, :]\n\n    label_array = tf.reshape(tf.tile(tf.range(label_shape[1]), num_batches_tns),\n                             label_shape)\n    label_ind = tf.boolean_mask(label_array, dense_mask)\n\n    batch_array = tf.transpose(tf.reshape(tf.tile(tf.range(label_shape[0]),\n                                                  max_num_labels_tns), reverse(label_shape, 0)))\n    batch_ind = tf.boolean_mask(batch_array, dense_mask)\n    indices = tf.transpose(tf.reshape(concatenate([batch_ind, label_ind], axis=0), [2, -1]))\n\n    vals_sparse = tf.gather_nd(labels, indices)\n\n    return tf.SparseTensor(tf.to_int64(indices), vals_sparse, tf.to_int64(label_shape))",
                "def ctc_batch_cost(y_true, y_pred, input_length, label_length):\n    \"\"\"Runs CTC loss algorithm on each batch element.\n\n    # Arguments\n        y_true: tensor `(samples, max_string_length)`\n            containing the truth labels.\n        y_pred: tensor `(samples, time_steps, num_categories)`\n            containing the prediction, or output of the softmax.\n        input_length: tensor `(samples, 1)` containing the sequence length for\n            each batch item in `y_pred`.\n        label_length: tensor `(samples, 1)` containing the sequence length for\n            each batch item in `y_true`.\n\n    # Returns\n        Tensor with shape (samples,1) containing the\n            CTC loss of each element.\n    \"\"\"\n    label_length = tf.to_int32(tf.squeeze(label_length, axis=-1))\n    input_length = tf.to_int32(tf.squeeze(input_length, axis=-1))\n    sparse_labels = tf.to_int32(ctc_label_dense_to_sparse(y_true, label_length))\n\n    y_pred = tf.log(tf.transpose(y_pred, perm=[1, 0, 2]) + epsilon())\n\n    return tf.expand_dims(ctc.ctc_loss(inputs=y_pred,\n                                       labels=sparse_labels,\n                                       sequence_length=input_length), 1)",
                "def ctc_decode(y_pred, input_length, greedy=True, beam_width=100,\n               top_paths=1):\n    \"\"\"Decodes the output of a softmax.\n\n    Can use either greedy search (also known as best path)\n    or a constrained dictionary search.\n\n    # Arguments\n        y_pred: tensor `(samples, time_steps, num_categories)`\n            containing the prediction, or output of the softmax.\n        input_length: tensor `(samples, )` containing the sequence length for\n            each batch item in `y_pred`.\n        greedy: perform much faster best-path search if `true`.\n            This does not use a dictionary.\n        beam_width: if `greedy` is `false`: a beam search decoder will be used\n            with a beam of this width.\n        top_paths: if `greedy` is `false`,\n            how many of the most probable paths will be returned.\n\n    # Returns\n        Tuple:\n            List: if `greedy` is `true`, returns a list of one element that\n                contains the decoded sequence.\n                If `false`, returns the `top_paths` most probable\n                decoded sequences.\n                Important: blank labels are returned as `-1`.\n            Tensor `(top_paths, )` that contains\n                the log probability of each decoded sequence.\n    \"\"\"\n    y_pred = tf.log(tf.transpose(y_pred, perm=[1, 0, 2]) + epsilon())\n    input_length = tf.to_int32(input_length)\n\n    if greedy:\n        (decoded, log_prob) = ctc.ctc_greedy_decoder(\n            inputs=y_pred,\n            sequence_length=input_length)\n    else:\n        (decoded, log_prob) = ctc.ctc_beam_search_decoder(\n            inputs=y_pred,\n            sequence_length=input_length, beam_width=beam_width,\n            top_paths=top_paths)\n\n    decoded_dense = [tf.sparse_to_dense(st.indices, st.dense_shape, st.values, default_value=-1)\n                     for st in decoded]\n    return (decoded_dense, log_prob)",
                "def map_fn(fn, elems, name=None, dtype=None):\n    \"\"\"Map the function fn over the elements elems and return the outputs.\n\n    # Arguments\n        fn: Callable that will be called upon each element in elems\n        elems: tensor\n        name: A string name for the map node in the graph\n        dtype: Output data type.\n\n    # Returns\n        Tensor with dtype `dtype`.\n    \"\"\"\n    return tf.map_fn(fn, elems, name=name, dtype=dtype)",
                "def foldl(fn, elems, initializer=None, name=None):\n    \"\"\"Reduce elems using fn to combine them from left to right.\n\n    # Arguments\n        fn: Callable that will be called upon each element in elems and an\n            accumulator, for instance `lambda acc, x: acc + x`\n        elems: tensor\n        initializer: The first value used (`elems[0]` in case of None)\n        name: A string name for the foldl node in the graph\n\n    # Returns\n        Tensor with same type and shape as `initializer`.\n    \"\"\"\n    return tf.foldl(fn, elems, initializer=initializer, name=name)",
                "def foldr(fn, elems, initializer=None, name=None):\n    \"\"\"Reduce elems using fn to combine them from right to left.\n\n    # Arguments\n        fn: Callable that will be called upon each element in elems and an\n            accumulator, for instance `lambda acc, x: acc + x`\n        elems: tensor\n        initializer: The first value used (`elems[-1]` in case of None)\n        name: A string name for the foldr node in the graph\n\n    # Returns\n        Tensor with same type and shape as `initializer`.\n    \"\"\"\n    return tf.foldr(fn, elems, initializer=initializer, name=name)",
                "def local_conv1d(inputs, kernel, kernel_size, strides, data_format=None):\n    \"\"\"Apply 1D conv with un-shared weights.\n\n    # Arguments\n        inputs: 3D tensor with shape: (batch_size, steps, input_dim)\n        kernel: the unshared weight for convolution,\n                with shape (output_length, feature_dim, filters)\n        kernel_size: a tuple of a single integer,\n                     specifying the length of the 1D convolution window\n        strides: a tuple of a single integer,\n                 specifying the stride length of the convolution\n        data_format: the data format, channels_first or channels_last\n\n    # Returns\n        the tensor after 1d conv with un-shared weights, with shape (batch_size, output_length, filters)\n\n    # Raises\n        ValueError: If `data_format` is neither\n            `\"channels_last\"` nor `\"channels_first\"`.\n    \"\"\"\n    data_format = normalize_data_format(data_format)\n\n    stride = strides[0]\n    kernel_shape = int_shape(kernel)\n    output_length, feature_dim, filters = kernel_shape\n\n    xs = []\n    for i in range(output_length):\n        slice_length = py_slice(i * stride,\n                                i * stride + kernel_size[0])\n        xs.append(reshape(inputs[:, slice_length, :],\n                          (1, -1, feature_dim)))\n    x_aggregate = concatenate(xs, axis=0)\n    # Shape: `(output_length, batch_size, filters)`.\n    output = batch_dot(x_aggregate, kernel)\n    return permute_dimensions(output, (1, 0, 2))",
                "def local_conv2d(inputs, kernel, kernel_size, strides, output_shape, data_format=None):\n    \"\"\"Apply 2D conv with un-shared weights.\n\n    # Arguments\n        inputs: 4D tensor with shape:\n                (batch_size, filters, new_rows, new_cols)\n                if data_format='channels_first'\n                or 4D tensor with shape:\n                (batch_size, new_rows, new_cols, filters)\n                if data_format='channels_last'.\n        kernel: the unshared weight for convolution,\n                with shape (output_items, feature_dim, filters)\n        kernel_size: a tuple of 2 integers, specifying the\n                     width and height of the 2D convolution window.\n        strides: a tuple of 2 integers, specifying the strides\n                 of the convolution along the width and height.\n        output_shape: a tuple with (output_row, output_col)\n        data_format: the data format, channels_first or channels_last\n\n    # Returns\n        A 4d tensor with shape:\n        (batch_size, filters, new_rows, new_cols)\n        if data_format='channels_first'\n        or 4D tensor with shape:\n        (batch_size, new_rows, new_cols, filters)\n        if data_format='channels_last'.\n\n    # Raises\n        ValueError: if `data_format` is neither\n                    `channels_last` or `channels_first`.\n    \"\"\"\n    data_format = normalize_data_format(data_format)\n\n    stride_row, stride_col = strides\n    output_row, output_col = output_shape\n    kernel_shape = int_shape(kernel)\n    _, feature_dim, filters = kernel_shape\n\n    xs = []\n    for i in range(output_row):\n        for j in range(output_col):\n            slice_row = py_slice(i * stride_row,\n                                 i * stride_row + kernel_size[0])\n            slice_col = py_slice(j * stride_col,\n                                 j * stride_col + kernel_size[1])\n            if data_format == 'channels_first':\n                xs.append(reshape(inputs[:, :, slice_row, slice_col],\n                                  (1, -1, feature_dim)))\n            else:\n                xs.append(reshape(inputs[:, slice_row, slice_col, :],\n                                  (1, -1, feature_dim)))\n\n    x_aggregate = concatenate(xs, axis=0)\n    output = batch_dot(x_aggregate, kernel)\n    output = reshape(output,\n                     (output_row, output_col, -1, filters))\n\n    if data_format == 'channels_first':\n        output = permute_dimensions(output, (2, 3, 0, 1))\n    else:\n        output = permute_dimensions(output, (2, 0, 1, 3))\n    return output",
                "def __init__(self):\n    self.device = None",
                "def _set_device(self, device):\n    \"\"\"This method captures TF's explicit device scope setting.\"\"\"\n    self.device = device",
                "def __init__(self, inputs, outputs,\n             updates=None,\n             name=None,\n             **session_kwargs):\n    updates = updates or []\n    if not isinstance(inputs, (list, tuple)):\n        raise TypeError('`inputs` to a TensorFlow backend function '\n                        'should be a list or tuple.')\n    if not isinstance(outputs, (list, tuple)):\n        raise TypeError('`outputs` of a TensorFlow backend function '\n                        'should be a list or tuple.')\n    if not isinstance(updates, (list, tuple)):\n        raise TypeError('`updates` in a TensorFlow backend function '\n                        'should be a list or tuple.')\n    self.inputs = list(inputs)\n    self.outputs = list(outputs)\n    with tf.control_dependencies(self.outputs):\n        updates_ops = []\n        for update in updates:\n            if isinstance(update, tuple):\n                p, new_p = update\n                updates_ops.append(tf.assign(p, new_p))\n            else:\n                # assumed already an op\n                updates_ops.append(update)\n        self.updates_op = tf.group(*updates_ops)\n    self.name = name\n    # additional tensor substitutions\n    self.feed_dict = session_kwargs.pop('feed_dict', {})\n    # additional operations\n    self.fetches = session_kwargs.pop('fetches', [])\n    if not isinstance(self.fetches, list):\n        self.fetches = [self.fetches]\n    # The main use case of `fetches` being passed to a model is the ability\n    # to run custom updates\n    # (since the outputs of fetches are never returned).\n    # This requires us to wrap fetches in `identity` ops.\n    self.fetches = [tf.identity(x) for x in self.fetches]\n    self.session_kwargs = session_kwargs\n    if session_kwargs:\n        raise ValueError('Some keys in session_kwargs are not '\n                         'supported at this '\n                         'time: %s', session_kwargs.keys())\n    self._callable_fn = None\n    self._feed_arrays = None\n    self._feed_symbols = None\n    self._symbol_vals = None\n    self._session = None",
                "def _make_callable(self, feed_arrays, feed_symbols, symbol_vals, session):\n    \"\"\"Generates a callable that runs the graph.\n\n    # Arguments\n        feed_arrays: List of input tensors to be fed\n            Numpy arrays at runtime.\n        feed_symbols: List of input tensors to be fed\n            symbolic tensors at runtime.\n        symbol_vals: List of symbolic tensors to be fed to `feed_symbols`.\n        session: Session to use to generate the callable.\n\n    # Returns\n        Function that runs the graph according to the above options.\n    \"\"\"\n    # Prepare callable options.\n    callable_opts = config_pb2.CallableOptions()\n    # Handle external-data feed.\n    for x in feed_arrays:\n        callable_opts.feed.append(x.name)\n    if self.feed_dict:\n        for key in sorted(self.feed_dict.keys()):\n            callable_opts.feed.append(key.name)\n    # Handle symbolic feed.\n    for x, y in zip(feed_symbols, symbol_vals):\n        connection = callable_opts.tensor_connection.add()\n        if x.dtype != y.dtype:\n            y = tf.cast(y, dtype=x.dtype)\n        from_tensor = tf_ops._as_graph_element(y)\n        if from_tensor is None:\n            from_tensor = y\n        connection.from_tensor = from_tensor.name  # Data tensor\n        connection.to_tensor = x.name  # Placeholder\n    # Handle fetches.\n    for x in self.outputs + self.fetches:\n        callable_opts.fetch.append(x.name)\n    # Handle updates.\n    callable_opts.target.append(self.updates_op.name)\n    # Create callable.\n    callable_fn = session._make_callable_from_options(callable_opts)\n    # Cache parameters corresponding to the generated callable, so that\n    # we can detect future mismatches and refresh the callable.\n    self._callable_fn = callable_fn\n    self._feed_arrays = feed_arrays\n    self._feed_symbols = feed_symbols\n    self._symbol_vals = symbol_vals\n    self._session = session",
                "def _call(self, inputs):\n    if not isinstance(inputs, (list, tuple)):\n        raise TypeError('`inputs` should be a list or tuple.')\n\n    session = get_session()\n    feed_arrays = []\n    array_vals = []\n    feed_symbols = []\n    symbol_vals = []\n    for tensor, value in zip(self.inputs, inputs):\n        if value is None:\n            continue\n        if is_tensor(value):\n            # Case: feeding symbolic tensor.\n            feed_symbols.append(tensor)\n            symbol_vals.append(value)\n        else:\n            feed_arrays.append(tensor)\n            # We need to do array conversion and type casting\n            # at this level, since\n            # `callable_fn` only supports exact matches.\n            array_vals.append(\n                np.asarray(value,\n                           dtype=tf.as_dtype(tensor.dtype).as_numpy_dtype))\n    if self.feed_dict:\n        for key in sorted(self.feed_dict.keys()):\n            array_vals.append(\n                np.asarray(self.feed_dict[key],\n                           dtype=tf.as_dtype(key.dtype).as_numpy_dtype))\n\n    # Refresh callable if anything has changed.\n    if (self._callable_fn is None or\n            feed_arrays != self._feed_arrays or\n            symbol_vals != self._symbol_vals or\n            feed_symbols != self._feed_symbols or\n            session != self._session):\n        self._make_callable(feed_arrays,\n                            feed_symbols,\n                            symbol_vals,\n                            session)\n    fetched = self._callable_fn(*array_vals)\n    return fetched[:len(self.outputs)]",
                "def _legacy_call(self, inputs):\n    if not isinstance(inputs, (list, tuple)):\n        raise TypeError('`inputs` should be a list or tuple.')\n    feed_dict = self.feed_dict.copy()\n    for tensor, value in zip(self.inputs, inputs):\n        if is_sparse(tensor):\n            sparse_coo = value.tocoo()\n            indices = np.concatenate(\n                (np.expand_dims(sparse_coo.row, 1),\n                 np.expand_dims(sparse_coo.col, 1)), 1)\n            value = (indices, sparse_coo.data, sparse_coo.shape)\n        feed_dict[tensor] = value\n    fetches = self.outputs + [self.updates_op] + self.fetches\n    session = get_session()\n    updated = session.run(fetches=fetches, feed_dict=feed_dict,\n                          **self.session_kwargs)\n    return updated[:len(self.outputs)]",
                "def __call__(self, inputs):\n    if hasattr(get_session(), '_make_callable_from_options'):\n        if py_any(is_sparse(x) for x in self.inputs):\n            if py_any(is_tensor(x) for x in inputs):\n                raise ValueError(\n                    'Feeding from symbolic tensors is not '\n                    'supported with sparse inputs.')\n            return self._legacy_call(inputs)\n\n        return self._call(inputs)\n    else:\n        if py_any(is_tensor(x) for x in inputs):\n            raise ValueError(\n                'In order to feed symbolic tensors to a Keras model '\n                'in TensorFlow, you need tensorflow 1.8 or higher.')\n        return self._legacy_call(inputs)",
                "def range_less_than(_, current_input):\n    return tf.expand_dims(tf.range(label_shape[1]), 0) < tf.fill(\n        max_num_labels_tns, current_input)",
                "def _step(time, output_ta_t, *states):\n    \"\"\"RNN step function.\n\n    # Arguments\n        time: Current timestep value.\n        output_ta_t: TensorArray.\n        *states: List of states.\n\n    # Returns\n        Tuple: `(time + 1,output_ta_t) + tuple(new_states)`\n    \"\"\"\n    current_input = input_ta.read(time)\n    mask_t = mask_ta.read(time)\n    output, new_states = step_function(current_input,\n                                       tuple(states) +\n                                       tuple(constants))\n    if getattr(output, '_uses_learning_phase', False):\n        global uses_learning_phase\n        uses_learning_phase = True\n    for state, new_state in zip(states, new_states):\n        new_state.set_shape(state.get_shape())\n    tiled_mask_t = tf.tile(mask_t,\n                           tf.stack([1, tf.shape(output)[1]]))\n    output = tf.where(tiled_mask_t, output, states[0])\n    new_states = [\n        tf.where(tf.tile(mask_t, tf.stack([1, tf.shape(new_states[i])[1]])),\n                 new_states[i], states[i]) for i in range(len(states))\n    ]\n    output_ta_t = output_ta_t.write(time, output)\n    return (time + 1, output_ta_t) + tuple(new_states)",
                "def _step(time, output_ta_t, *states):\n    \"\"\"RNN step function.\n\n    # Arguments\n        time: Current timestep value.\n        output_ta_t: TensorArray.\n        *states: List of states.\n\n    # Returns\n        Tuple: `(time + 1,output_ta_t) + tuple(new_states)`\n    \"\"\"\n    current_input = input_ta.read(time)\n    output, new_states = step_function(current_input,\n                                       tuple(states) +\n                                       tuple(constants))\n    if getattr(output, '_uses_learning_phase', False):\n        global uses_learning_phase\n        uses_learning_phase = True\n    for state, new_state in zip(states, new_states):\n        new_state.set_shape(state.get_shape())\n    output_ta_t = output_ta_t.write(time, output)\n    return (time + 1, output_ta_t) + tuple(new_states)",
                "def then_expression_fn():\n    return then_expression",
                "def else_expression_fn():\n    return else_expression"
            ],
            "inscope_function_signatures": [
                "get_uid(prefix='')",
                "reset_uids()",
                "clear_session()",
                "manual_variable_initialization(value)",
                "learning_phase()",
                "set_learning_phase(value)",
                "get_session()",
                "set_session(session)",
                "_get_current_tf_device()",
                "_is_current_explicit_device(device_type)",
                "_get_available_gpus()",
                "_has_nchw_support()",
                "_to_tensor(x, dtype)",
                "is_sparse(tensor)",
                "to_dense(tensor)",
                "variable(value, dtype=None, name=None, constraint=None)",
                "constant(value, dtype=None, shape=None, name=None)",
                "is_keras_tensor(x)",
                "is_tensor(x)",
                "placeholder(shape=None, ndim=None, dtype=None, sparse=False, name=None)",
                "is_placeholder(x)",
                "shape(x)",
                "int_shape(x)",
                "ndim(x)",
                "dtype(x)",
                "eval(x)",
                "zeros(shape, dtype=None, name=None)",
                "ones(shape, dtype=None, name=None)",
                "eye(size, dtype=None, name=None)",
                "zeros_like(x, dtype=None, name=None)",
                "ones_like(x, dtype=None, name=None)",
                "identity(x, name=None)",
                "random_uniform_variable(shape, low, high, dtype=None, name=None, seed=None)",
                "random_normal_variable(shape, mean, scale, dtype=None, name=None, seed=None)",
                "count_params(x)",
                "cast(x, dtype)",
                "update(x, new_x)",
                "update_add(x, increment)",
                "update_sub(x, decrement)",
                "moving_average_update(x, value, momentum)",
                "dot(x, y)",
                "batch_dot(x, y, axes=None)",
                "transpose(x)",
                "gather(reference, indices)",
                "max(x, axis=None, keepdims=False)",
                "min(x, axis=None, keepdims=False)",
                "sum(x, axis=None, keepdims=False)",
                "prod(x, axis=None, keepdims=False)",
                "cumsum(x, axis=0)",
                "cumprod(x, axis=0)",
                "var(x, axis=None, keepdims=False)",
                "std(x, axis=None, keepdims=False)",
                "mean(x, axis=None, keepdims=False)",
                "any(x, axis=None, keepdims=False)",
                "all(x, axis=None, keepdims=False)",
                "argmax(x, axis=-1)",
                "argmin(x, axis=-1)",
                "square(x)",
                "abs(x)",
                "sqrt(x)",
                "exp(x)",
                "log(x)",
                "logsumexp(x, axis=None, keepdims=False)",
                "round(x)",
                "sign(x)",
                "pow(x, a)",
                "clip(x, min_value, max_value)",
                "equal(x, y)",
                "not_equal(x, y)",
                "greater(x, y)",
                "greater_equal(x, y)",
                "less(x, y)",
                "less_equal(x, y)",
                "maximum(x, y)",
                "minimum(x, y)",
                "sin(x)",
                "cos(x)",
                "_regular_normalize_batch_in_training(x, gamma, beta, reduction_axes, epsilon=0.001)",
                "_broadcast_normalize_batch_in_training(x, gamma, beta, reduction_axes, epsilon=0.001)",
                "_fused_normalize_batch_in_training(x, gamma, beta, reduction_axes, epsilon=0.001)",
                "normalize_batch_in_training(x, gamma, beta, reduction_axes, epsilon=0.001)",
                "batch_normalization(x, mean, var, beta, gamma, axis=-1, epsilon=0.001)",
                "concatenate(tensors, axis=-1)",
                "reshape(x, shape)",
                "permute_dimensions(x, pattern)",
                "resize_images(x, height_factor, width_factor, data_format, interpolation='nearest')",
                "resize_volumes(x, depth_factor, height_factor, width_factor, data_format)",
                "repeat_elements(x, rep, axis)",
                "repeat(x, n)",
                "arange(start, stop=None, step=1, dtype='int32')",
                "tile(x, n)",
                "flatten(x)",
                "batch_flatten(x)",
                "expand_dims(x, axis=-1)",
                "squeeze(x, axis)",
                "temporal_padding(x, padding=(1, 1))",
                "spatial_2d_padding(x, padding=((1, 1), (1, 1)), data_format=None)",
                "spatial_3d_padding(x, padding=((1, 1), (1, 1), (1, 1)), data_format=None)",
                "stack(x, axis=0)",
                "one_hot(indices, num_classes)",
                "reverse(x, axes)",
                "slice(x, start, size)",
                "get_value(x)",
                "batch_get_value(ops)",
                "set_value(x, value)",
                "batch_set_value(tuples)",
                "get_variable_shape(x)",
                "print_tensor(x, message='')",
                "function(inputs, outputs, updates=None, **kwargs)",
                "gradients(loss, variables)",
                "stop_gradient(variables)",
                "rnn(step_function, inputs, initial_states, go_backwards=False, mask=None, constants=None, unroll=False, input_length=None)",
                "switch(condition, then_expression, else_expression)",
                "in_train_phase(x, alt, training=None)",
                "in_test_phase(x, alt, training=None)",
                "relu(x, alpha=0.0, max_value=None)",
                "elu(x, alpha=1.0)",
                "softmax(x, axis=-1)",
                "softplus(x)",
                "softsign(x)",
                "categorical_crossentropy(target, output, from_logits=False, axis=-1)",
                "sparse_categorical_crossentropy(target, output, from_logits=False, axis=-1)",
                "binary_crossentropy(target, output, from_logits=False)",
                "sigmoid(x)",
                "hard_sigmoid(x)",
                "tanh(x)",
                "dropout(x, level, noise_shape=None, seed=None)",
                "l2_normalize(x, axis=None)",
                "in_top_k(predictions, targets, k)",
                "_preprocess_conv1d_input(x, data_format)",
                "_preprocess_conv2d_input(x, data_format)",
                "_preprocess_conv3d_input(x, data_format)",
                "_preprocess_padding(padding)",
                "conv1d(x, kernel, strides=1, padding='valid', data_format=None, dilation_rate=1)",
                "conv2d(x, kernel, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1))",
                "conv2d_transpose(x, kernel, output_shape, strides=(1, 1), padding='valid', data_format=None)",
                "separable_conv1d(x, depthwise_kernel, pointwise_kernel, strides=1, padding='valid', data_format=None, dilation_rate=1)",
                "separable_conv2d(x, depthwise_kernel, pointwise_kernel, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1))",
                "depthwise_conv2d(x, depthwise_kernel, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1))",
                "conv3d(x, kernel, strides=(1, 1, 1), padding='valid', data_format=None, dilation_rate=(1, 1, 1))",
                "conv3d_transpose(x, kernel, output_shape, strides=(1, 1, 1), padding='valid', data_format=None)",
                "pool2d(x, pool_size, strides=(1, 1), padding='valid', data_format=None, pool_mode='max')",
                "pool3d(x, pool_size, strides=(1, 1, 1), padding='valid', data_format=None, pool_mode='max')",
                "bias_add(x, bias, data_format=None)",
                "random_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None)",
                "random_uniform(shape, minval=0.0, maxval=1.0, dtype=None, seed=None)",
                "random_binomial(shape, p=0.0, dtype=None, seed=None)",
                "truncated_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None)",
                "ctc_label_dense_to_sparse(labels, label_lengths)",
                "ctc_batch_cost(y_true, y_pred, input_length, label_length)",
                "ctc_decode(y_pred, input_length, greedy=True, beam_width=100, top_paths=1)",
                "map_fn(fn, elems, name=None, dtype=None)",
                "foldl(fn, elems, initializer=None, name=None)",
                "foldr(fn, elems, initializer=None, name=None)",
                "local_conv1d(inputs, kernel, kernel_size, strides, data_format=None)",
                "local_conv2d(inputs, kernel, kernel_size, strides, output_shape, data_format=None)",
                "__init__(self)",
                "_set_device(self, device)",
                "__init__(self, inputs, outputs, updates=None, name=None, **session_kwargs)",
                "_make_callable(self, feed_arrays, feed_symbols, symbol_vals, session)",
                "_call(self, inputs)",
                "_legacy_call(self, inputs)",
                "__call__(self, inputs)",
                "range_less_than(_, current_input)",
                "_step(time, output_ta_t, *states)",
                "_step(time, output_ta_t, *states)",
                "then_expression_fn()",
                "else_expression_fn()"
            ],
            "variables_in_file": {
                "py_all": [
                    703,
                    735,
                    1933,
                    31
                ],
                "all": [
                    31
                ],
                "py_any": [
                    32,
                    2669,
                    2670,
                    2678,
                    1147
                ],
                "any": [
                    32
                ],
                "py_sum": [
                    33
                ],
                "sum": [
                    33
                ],
                "py_slice": [
                    4353,
                    34,
                    4355,
                    4302
                ],
                "slice": [
                    34
                ],
                "_SESSION": [
                    97,
                    40,
                    179,
                    186,
                    187,
                    221
                ],
                "_GRAPH_LEARNING_PHASES": [
                    132,
                    101,
                    102,
                    136,
                    137,
                    45,
                    153
                ],
                "_GRAPH_UID_DICTS": [
                    75,
                    76,
                    77,
                    78,
                    51,
                    85
                ],
                "_MANUAL_VAR_INIT": [
                    56,
                    188,
                    118
                ],
                "_LOCAL_DEVICES": [
                    277,
                    61,
                    278,
                    279
                ],
                "graph": [
                    131,
                    132,
                    136,
                    137,
                    74,
                    75,
                    76,
                    77,
                    78
                ],
                "tf.get_default_graph": [
                    131,
                    102,
                    74,
                    245,
                    153
                ],
                "tf": [
                    3584,
                    1538,
                    515,
                    517,
                    4103,
                    1550,
                    2070,
                    2585,
                    1563,
                    3611,
                    4123,
                    4124,
                    4125,
                    4128,
                    2082,
                    2083,
                    4131,
                    3621,
                    2086,
                    1063,
                    3622,
                    4136,
                    4138,
                    2091,
                    4140,
                    2093,
                    1070,
                    1583,
                    3630,
                    4142,
                    3634,
                    4143,
                    4145,
                    4147,
                    566,
                    1078,
                    1079,
                    1080,
                    3126,
                    1083,
                    1596,
                    1085,
                    3128,
                    3132,
                    2116,
                    2117,
                    2118,
                    2629,
                    4167,
                    1609,
                    74,
                    2634,
                    3146,
                    4168,
                    3150,
                    4169,
                    4171,
                    4173,
                    1622,
                    3164,
                    3676,
                    3677,
                    95,
                    3678,
                    3681,
                    98,
                    1635,
                    2148,
                    2149,
                    102,
                    3687,
                    2152,
                    3176,
                    3690,
                    4207,
                    1648,
                    4208,
                    3188,
                    2171,
                    4220,
                    1661,
                    1153,
                    131,
                    1156,
                    133,
                    2183,
                    1161,
                    1674,
                    1163,
                    3725,
                    2702,
                    4239,
                    1171,
                    3731,
                    2197,
                    1687,
                    3224,
                    153,
                    1177,
                    3227,
                    3228,
                    2718,
                    3230,
                    4255,
                    1699,
                    2211,
                    2733,
                    174,
                    1711,
                    2224,
                    2735,
                    4271,
                    3764,
                    181,
                    184,
                    186,
                    3770,
                    701,
                    190,
                    702,
                    1215,
                    1729,
                    2240,
                    1731,
                    3267,
                    199,
                    3273,
                    3274,
                    1228,
                    206,
                    3278,
                    3279,
                    3285,
                    3799,
                    1752,
                    2267,
                    733,
                    734,
                    1759,
                    1248,
                    1760,
                    1762,
                    1763,
                    3807,
                    1767,
                    2794,
                    1771,
                    3308,
                    1773,
                    2797,
                    2798,
                    3309,
                    1265,
                    2801,
                    3311,
                    245,
                    3834,
                    764,
                    765,
                    3324,
                    2817,
                    1282,
                    2308,
                    3845,
                    2822,
                    3846,
                    1806,
                    3343,
                    3854,
                    2321,
                    1810,
                    1299,
                    3858,
                    790,
                    1814,
                    2841,
                    2842,
                    3356,
                    1312,
                    2336,
                    2849,
                    2854,
                    2855,
                    2856,
                    1325,
                    815,
                    2352,
                    2864,
                    3378,
                    308,
                    3894,
                    2874,
                    3898,
                    828,
                    1342,
                    1343,
                    1344,
                    1345,
                    1346,
                    2882,
                    2372,
                    3391,
                    3905,
                    331,
                    2893,
                    3407,
                    1365,
                    859,
                    2907,
                    863,
                    1888,
                    3425,
                    1890,
                    355,
                    3426,
                    3940,
                    1382,
                    1383,
                    360,
                    1384,
                    1894,
                    1898,
                    1899,
                    3430,
                    2414,
                    3944,
                    3951,
                    2419,
                    2933,
                    1398,
                    1399,
                    1911,
                    2934,
                    2935,
                    2937,
                    3448,
                    3449,
                    3453,
                    896,
                    900,
                    1413,
                    1414,
                    2438,
                    2443,
                    396,
                    1934,
                    3471,
                    1936,
                    3472,
                    402,
                    1427,
                    3476,
                    3989,
                    1949,
                    3997,
                    1440,
                    2981,
                    4009,
                    1963,
                    1452,
                    430,
                    2484,
                    1464,
                    3003,
                    3004,
                    957,
                    4033,
                    1478,
                    1479,
                    1992,
                    1993,
                    3017,
                    973,
                    1998,
                    2000,
                    3536,
                    1491,
                    4056,
                    3545,
                    986,
                    3037,
                    2526,
                    1503,
                    3038,
                    3039,
                    3041,
                    2531,
                    3042,
                    3043,
                    999,
                    2535,
                    4076,
                    4077,
                    4078,
                    2547,
                    1524,
                    3575
                ],
                "defaultdict": [
                    76
                ],
                "int": [
                    3659,
                    76,
                    3661,
                    2350,
                    3278,
                    1140,
                    183,
                    2169
                ],
                "prefix": [
                    77,
                    78
                ],
                "tf.reset_default_graph": [
                    95
                ],
                "reset_uids": [
                    96
                ],
                "phase": [
                    136,
                    98,
                    133,
                    102
                ],
                "tf.placeholder_with_default": [
                    98,
                    133
                ],
                "value": [
                    900,
                    2436,
                    902,
                    2437,
                    392,
                    393,
                    2444,
                    2449,
                    402,
                    403,
                    404,
                    405,
                    150,
                    406,
                    153,
                    2423,
                    430,
                    2615,
                    2616,
                    2618,
                    2621,
                    2628,
                    2653,
                    863,
                    2655,
                    865,
                    2659,
                    2660,
                    2413,
                    2419,
                    118,
                    1014
                ],
                "ValueError": [
                    2049,
                    3976,
                    265,
                    3215,
                    2704,
                    151,
                    3499,
                    3258,
                    3902,
                    3527,
                    2897,
                    594,
                    2002,
                    3030,
                    473,
                    2789,
                    3948,
                    2671,
                    2550,
                    2679,
                    2811,
                    1148
                ],
                "default_session": [
                    176,
                    177,
                    174
                ],
                "tf.get_default_session": [
                    174
                ],
                "session": [
                    2597,
                    198,
                    2662,
                    2663,
                    2604,
                    206,
                    177,
                    209,
                    210,
                    211,
                    2610,
                    2641,
                    2645,
                    221,
                    187,
                    189
                ],
                "os.environ.get": [
                    180,
                    183
                ],
                "os.environ": [
                    180,
                    183
                ],
                "os": [
                    180,
                    183
                ],
                "config": [
                    184,
                    186,
                    181
                ],
                "tf.ConfigProto": [
                    184,
                    181
                ],
                "num_thread": [
                    184,
                    183
                ],
                "tf.Session": [
                    186,
                    2702
                ],
                "session.graph.as_default": [
                    189
                ],
                "session.graph": [
                    189
                ],
                "variables": [
                    192,
                    2732,
                    2733,
                    2735,
                    190,
                    2718
                ],
                "tf.global_variables": [
                    190
                ],
                "candidate_vars": [
                    194,
                    195,
                    199,
                    201,
                    191
                ],
                "v": [
                    396,
                    399,
                    400,
                    401,
                    402,
                    404,
                    406,
                    407,
                    410,
                    412,
                    413,
                    702,
                    703,
                    192,
                    193,
                    194,
                    704,
                    705,
                    199,
                    201,
                    203,
                    204,
                    734,
                    735,
                    736,
                    737
                ],
                "getattr": [
                    193,
                    2828,
                    2958,
                    2928,
                    2868
                ],
                "candidate_vars.append": [
                    194
                ],
                "is_initialized": [
                    201,
                    198
                ],
                "session.run": [
                    206,
                    198,
                    2663
                ],
                "tf.is_variable_initialized": [
                    199
                ],
                "uninitialized_vars": [
                    200,
                    203,
                    205,
                    206
                ],
                "flag": [
                    201,
                    202
                ],
                "zip": [
                    2852,
                    1063,
                    201,
                    2826,
                    1070,
                    2961,
                    2931,
                    2582,
                    2615,
                    2653
                ],
                "uninitialized_vars.append": [
                    203
                ],
                "v._keras_initialized": [
                    204
                ],
                "tf.variables_initializer": [
                    206
                ],
                "hasattr": [
                    2439,
                    392,
                    2668,
                    590,
                    2415,
                    209,
                    405,
                    476
                ],
                "session.list_devices": [
                    210
                ],
                "device_lib.list_local_devices": [
                    210
                ],
                "device_lib": [
                    210
                ],
                "object": [
                    2489,
                    226
                ],
                "self.device": [
                    234,
                    230
                ],
                "self": [
                    2578,
                    2579,
                    2592,
                    2595,
                    2600,
                    2601,
                    2602,
                    2603,
                    2604,
                    2682,
                    2615,
                    2630,
                    2631,
                    2633,
                    2637,
                    2638,
                    2639,
                    2640,
                    2641,
                    2642,
                    2646,
                    2647,
                    2524,
                    2525,
                    2526,
                    2652,
                    2653,
                    2661,
                    230,
                    2535,
                    2536,
                    2664,
                    234,
                    2538,
                    2540,
                    2541,
                    2542,
                    2665,
                    2669,
                    2674,
                    2547,
                    2548,
                    2676,
                    2553,
                    2554,
                    2555,
                    2556,
                    2557
                ],
                "device": [
                    267,
                    234,
                    266
                ],
                "g": [
                    245,
                    247
                ],
                "op": [
                    248,
                    246,
                    247
                ],
                "_TfDeviceCaptureOp": [
                    246
                ],
                "g._apply_device_functions": [
                    247
                ],
                "op.device": [
                    248
                ],
                "device_type": [
                    264,
                    267,
                    263
                ],
                "device_type.upper": [
                    267,
                    263
                ],
                "_get_current_tf_device": [
                    266
                ],
                "device.device_type": [
                    267
                ],
                "list_devices": [
                    278
                ],
                "get_session": [
                    2400,
                    673,
                    2662,
                    2668,
                    2450,
                    2387,
                    2610,
                    278,
                    2423
                ],
                "x.name": [
                    2577,
                    2593,
                    2590,
                    279
                ],
                "x": [
                    3072,
                    3073,
                    1538,
                    515,
                    3075,
                    517,
                    518,
                    519,
                    520,
                    3584,
                    3585,
                    3084,
                    1550,
                    3086,
                    2576,
                    2577,
                    2066,
                    3087,
                    533,
                    2070,
                    2582,
                    2584,
                    2585,
                    1563,
                    3613,
                    2590,
                    2592,
                    2593,
                    2082,
                    2083,
                    2084,
                    1061,
                    3107,
                    1063,
                    3621,
                    3977,
                    1581,
                    1582,
                    1583,
                    2096,
                    3630,
                    3634,
                    3635,
                    3978,
                    566,
                    1078,
                    3126,
                    3128,
                    1082,
                    1083,
                    1596,
                    1085,
                    3131,
                    3132,
                    3133,
                    2115,
                    2116,
                    3575,
                    2118,
                    1609,
                    3146,
                    590,
                    591,
                    3150,
                    593,
                    3664,
                    1622,
                    3164,
                    3676,
                    3681,
                    1635,
                    3687,
                    3176,
                    3690,
                    619,
                    3692,
                    2669,
                    2670,
                    1648,
                    3188,
                    1142,
                    2678,
                    2171,
                    1661,
                    1156,
                    3718,
                    1159,
                    2183,
                    1161,
                    1674,
                    1163,
                    652,
                    3725,
                    1166,
                    1171,
                    3731,
                    2197,
                    2198,
                    1687,
                    3732,
                    673,
                    1699,
                    2211,
                    3757,
                    1711,
                    2224,
                    3764,
                    3770,
                    3771,
                    1215,
                    2240,
                    1729,
                    1731,
                    3797,
                    3799,
                    1752,
                    3800,
                    1755,
                    2267,
                    1759,
                    1248,
                    3807,
                    3808,
                    1774,
                    1265,
                    3324,
                    3836,
                    1282,
                    2308,
                    3845,
                    3340,
                    3341,
                    3342,
                    1807,
                    1808,
                    2321,
                    3343,
                    1299,
                    1811,
                    1812,
                    790,
                    279,
                    1815,
                    3344,
                    3858,
                    3859,
                    3356,
                    1312,
                    3884,
                    1325,
                    1837,
                    815,
                    1839,
                    2352,
                    3378,
                    1843,
                    308,
                    1846,
                    1847,
                    3894,
                    3898,
                    1851,
                    828,
                    1342,
                    1343,
                    1344,
                    1345,
                    3391,
                    3905,
                    2372,
                    3906,
                    1875,
                    2387,
                    1365,
                    3930,
                    3424,
                    3426,
                    3940,
                    1382,
                    1383,
                    1384,
                    3430,
                    3433,
                    3944,
                    1900,
                    2413,
                    2414,
                    2415,
                    2416,
                    2417,
                    3951,
                    3952,
                    2420,
                    2421,
                    1398,
                    1399,
                    1911,
                    2422,
                    3447,
                    3449,
                    3453,
                    3456,
                    2436,
                    1413,
                    1414,
                    2437,
                    2438,
                    2439,
                    2440,
                    2441,
                    3975,
                    1933,
                    2445,
                    2446,
                    1936,
                    2447,
                    3470,
                    1427,
                    3472,
                    3476,
                    3984,
                    3479,
                    3985,
                    3989,
                    3992,
                    3994,
                    925,
                    1949,
                    2462,
                    1440,
                    3997,
                    4000,
                    4001,
                    4007,
                    4009,
                    4010,
                    1963,
                    1452,
                    2484,
                    1464,
                    957,
                    3854,
                    1476,
                    1477,
                    1478,
                    1479,
                    1991,
                    1992,
                    3017,
                    1996,
                    973,
                    1998,
                    3532,
                    2000,
                    3535,
                    3536,
                    1491,
                    3537,
                    2005,
                    472,
                    3545,
                    474,
                    986,
                    476,
                    3546,
                    1503,
                    480,
                    2018,
                    2019,
                    3043,
                    3044,
                    999,
                    2547,
                    1524,
                    3572,
                    1014,
                    2039,
                    3576,
                    2044
                ],
                "x.device_type": [
                    279
                ],
                "explicitly_on_cpu": [
                    291,
                    293
                ],
                "_is_current_explicit_device": [
                    291
                ],
                "gpus_available": [
                    292,
                    293
                ],
                "len": [
                    3975,
                    3977,
                    3979,
                    3213,
                    3219,
                    3987,
                    3996,
                    4002,
                    292,
                    2084,
                    2980,
                    3256,
                    2238,
                    3262,
                    2257,
                    2258,
                    2259,
                    3282,
                    2647,
                    2787,
                    2665,
                    621,
                    2799,
                    2293,
                    2294,
                    2295,
                    2296,
                    2938
                ],
                "_get_available_gpus": [
                    292
                ],
                "tf.convert_to_tensor": [
                    308
                ],
                "dtype": [
                    896,
                    515,
                    4099,
                    517,
                    390,
                    391,
                    902,
                    765,
                    2437,
                    4100,
                    4103,
                    3470,
                    4239,
                    402,
                    894,
                    790,
                    428,
                    429,
                    430,
                    815,
                    308,
                    699,
                    700,
                    701,
                    957,
                    4029,
                    704,
                    4030,
                    4034,
                    4052,
                    4053,
                    857,
                    858,
                    731,
                    732,
                    733,
                    859,
                    4057,
                    736,
                    865,
                    3424,
                    4072,
                    2153,
                    2154,
                    4073,
                    4076,
                    2413,
                    4077,
                    4078,
                    3447,
                    762,
                    763,
                    764,
                    509,
                    510,
                    895
                ],
                "isinstance": [
                    403,
                    3610,
                    2169,
                    2732,
                    2350,
                    2607,
                    331,
                    3659,
                    3661,
                    2515,
                    2518,
                    2521,
                    2650,
                    480,
                    2529,
                    2541,
                    1140,
                    3833,
                    1147
                ],
                "tensor": [
                    354,
                    355,
                    2660,
                    357,
                    2629,
                    331,
                    2615,
                    2620,
                    2653,
                    2654,
                    2623
                ],
                "tf.SparseTensor": [
                    4147,
                    331,
                    396
                ],
                "is_sparse": [
                    354,
                    2669,
                    1933,
                    1082,
                    2654
                ],
                "tf.sparse_tensor_to_dense": [
                    355
                ],
                "name_scope": [
                    360
                ],
                "tf.name_scope": [
                    360
                ],
                "floatx": [
                    700,
                    4100,
                    1343,
                    391,
                    1383,
                    4073,
                    429,
                    4030,
                    4053,
                    858,
                    763,
                    732,
                    510,
                    895
                ],
                "sparse_coo": [
                    2657,
                    2658,
                    2659,
                    393,
                    394,
                    395,
                    397,
                    398,
                    399,
                    2655
                ],
                "value.tocoo": [
                    393,
                    2655
                ],
                "indices": [
                    2336,
                    2656,
                    2659,
                    394,
                    1228,
                    396,
                    4143,
                    4145,
                    4147
                ],
                "np.concatenate": [
                    2656,
                    394
                ],
                "np": [
                    899,
                    2437,
                    4102,
                    394,
                    395,
                    403,
                    925,
                    2084,
                    2089,
                    1580,
                    3375,
                    4032,
                    2628,
                    1477,
                    1993,
                    2633,
                    4055,
                    862,
                    2656,
                    2657,
                    2658,
                    4075,
                    2413
                ],
                "np.expand_dims": [
                    2657,
                    394,
                    395,
                    2658
                ],
                "sparse_coo.row": [
                    2657,
                    394
                ],
                "sparse_coo.col": [
                    2658,
                    395
                ],
                "sparse_coo.data": [
                    2659,
                    397
                ],
                "sparse_coo.shape": [
                    2659,
                    398,
                    399
                ],
                "v._keras_shape": [
                    404,
                    406,
                    399
                ],
                "v._uses_learning_phase": [
                    400,
                    407
                ],
                "tf.Variable": [
                    402
                ],
                "tf.as_dtype": [
                    896,
                    2629,
                    2438,
                    701,
                    2634,
                    2414,
                    402,
                    859,
                    764,
                    733
                ],
                "name": [
                    704,
                    736,
                    865,
                    515,
                    517,
                    902,
                    2536,
                    734,
                    430,
                    815,
                    4239,
                    4271,
                    402,
                    790,
                    828,
                    765,
                    702,
                    4255
                ],
                "np.ndarray": [
                    403
                ],
                "value.shape": [
                    2444,
                    2419,
                    404
                ],
                "int_shape": [
                    3974,
                    1991,
                    1063,
                    4297,
                    1070,
                    406,
                    4347,
                    925,
                    2462
                ],
                "v.constraint": [
                    410
                ],
                "constraint": [
                    410,
                    412
                ],
                "AttributeError": [
                    411,
                    534
                ],
                "v._constraint": [
                    412
                ],
                "tf.constant": [
                    2149,
                    1993,
                    2091,
                    2893,
                    430,
                    1806,
                    1810
                ],
                "shape": [
                    864,
                    513,
                    4033,
                    515,
                    517,
                    518,
                    901,
                    4103,
                    4076,
                    734,
                    430,
                    4077,
                    4078,
                    2197,
                    4056,
                    1949,
                    702,
                    511
                ],
                "is_tensor": [
                    472,
                    2618,
                    2678,
                    2670
                ],
                "str": [
                    2049,
                    3499,
                    3948,
                    3902,
                    474,
                    3033,
                    3034,
                    1150
                ],
                "type": [
                    474
                ],
                "tf_ops._TensorLike": [
                    480
                ],
                "tf_ops": [
                    480,
                    2586
                ],
                "tf_ops.is_dense_tensor_like": [
                    480
                ],
                "ndim": [
                    512,
                    513,
                    1159,
                    1927,
                    3975,
                    3977,
                    3978,
                    1166,
                    1167,
                    3985,
                    1178,
                    4001,
                    1061,
                    1837,
                    1076,
                    1846,
                    3005,
                    2115,
                    1875,
                    3028,
                    1755,
                    1887,
                    1889,
                    2787,
                    2788,
                    1893,
                    1897,
                    2793,
                    2799,
                    1142,
                    1143
                ],
                "tuple": [
                    513,
                    3845,
                    2956,
                    2957,
                    2964,
                    3610,
                    3621,
                    1068,
                    2732,
                    2607,
                    2098,
                    1075,
                    2880,
                    593,
                    2515,
                    2518,
                    2521,
                    2650,
                    2529,
                    2926,
                    2927,
                    3833,
                    1147,
                    2941
                ],
                "_": [
                    513,
                    2883,
                    1899,
                    2072,
                    4348
                ],
                "range": [
                    4352,
                    513,
                    2980,
                    2793,
                    3213,
                    4301,
                    1076,
                    1846,
                    2072,
                    1177,
                    2938,
                    1755,
                    3256,
                    4351
                ],
                "sparse": [
                    514
                ],
                "tf.sparse_placeholder": [
                    515
                ],
                "tf.placeholder": [
                    2419,
                    2443,
                    517
                ],
                "x._keras_shape": [
                    518,
                    591
                ],
                "x._uses_learning_phase": [
                    3086,
                    519
                ],
                "x.op.type": [
                    533
                ],
                "x.op": [
                    533
                ],
                "tf.shape": [
                    1153,
                    1156,
                    3845,
                    2842,
                    4123,
                    2082,
                    3621,
                    1063,
                    2855,
                    1070,
                    566,
                    2882,
                    1992,
                    3285,
                    3037,
                    3039,
                    1759,
                    2934,
                    2937
                ],
                "as_list": [
                    3524,
                    2096,
                    593,
                    2066,
                    703,
                    735
                ],
                "x.get_shape": [
                    2084,
                    619,
                    1808,
                    593,
                    2066,
                    2096,
                    1812
                ],
                "dims": [
                    619,
                    620,
                    621
                ],
                "_dims": [
                    619
                ],
                "x.dtype.base_dtype.name": [
                    652
                ],
                "x.dtype.base_dtype": [
                    1476,
                    1477,
                    1382,
                    652,
                    1581,
                    1582,
                    3341,
                    3342,
                    3131,
                    1342
                ],
                "x.dtype": [
                    1476,
                    1477,
                    1382,
                    2438,
                    652,
                    1581,
                    1582,
                    1807,
                    2414,
                    3341,
                    3342,
                    1811,
                    2584,
                    2585,
                    3131,
                    1342
                ],
                "eval": [
                    673
                ],
                "to_dense": [
                    1936,
                    673
                ],
                "tf_dtype": [
                    864,
                    896,
                    901,
                    2438,
                    701,
                    765,
                    2443,
                    702,
                    2414,
                    2419,
                    859,
                    764,
                    733,
                    734
                ],
                "tf.zeros": [
                    4078,
                    702
                ],
                "v.get_shape": [
                    735,
                    703
                ],
                "variable": [
                    704,
                    736,
                    865,
                    902,
                    765
                ],
                "tf.ones": [
                    4077,
                    734
                ],
                "tf.eye": [
                    765
                ],
                "size": [
                    2372,
                    765
                ],
                "tf.zeros_like": [
                    790
                ],
                "tf.ones_like": [
                    3041,
                    815
                ],
                "tf.identity": [
                    2547,
                    828
                ],
                "seed": [
                    897,
                    899,
                    901,
                    4101,
                    4102,
                    4103,
                    3374,
                    3375,
                    3378,
                    4031,
                    4032,
                    4034,
                    4054,
                    4055,
                    4057,
                    860,
                    862,
                    864,
                    4074,
                    4075,
                    4076
                ],
                "np.random.randint": [
                    4032,
                    899,
                    4102,
                    4075,
                    3375,
                    4055,
                    862
                ],
                "np.random": [
                    4032,
                    899,
                    4102,
                    4075,
                    3375,
                    4055,
                    862
                ],
                "tf.random_uniform_initializer": [
                    863
                ],
                "low": [
                    864
                ],
                "high": [
                    864
                ],
                "tf.random_normal_initializer": [
                    900
                ],
                "mean": [
                    1888,
                    1729,
                    1762,
                    1731,
                    1892,
                    901,
                    1734,
                    4033,
                    1896,
                    4103,
                    1904,
                    1780,
                    1911,
                    1752,
                    1887
                ],
                "scale": [
                    901
                ],
                "np.prod": [
                    925
                ],
                "tf.cast": [
                    3426,
                    4131,
                    1413,
                    1383,
                    3449,
                    2798,
                    3472,
                    1398,
                    2585,
                    3004,
                    957,
                    1343
                ],
                "tf.assign": [
                    2531,
                    973
                ],
                "new_x": [
                    973
                ],
                "tf.assign_add": [
                    986
                ],
                "increment": [
                    986
                ],
                "tf.assign_sub": [
                    999
                ],
                "decrement": [
                    999
                ],
                "moving_averages.assign_moving_average": [
                    1013
                ],
                "moving_averages": [
                    1013
                ],
                "momentum": [
                    1014
                ],
                "y": [
                    1153,
                    1159,
                    1161,
                    1674,
                    1163,
                    1167,
                    1171,
                    2582,
                    1687,
                    2584,
                    2585,
                    2586,
                    2588,
                    1061,
                    1070,
                    1076,
                    1079,
                    1083,
                    1596,
                    1085,
                    1609,
                    1622,
                    1635,
                    1899,
                    1648,
                    1909,
                    1143,
                    1661
                ],
                "x_shape": [
                    2082,
                    1062,
                    1065,
                    1067,
                    1068,
                    2092,
                    2093,
                    2096,
                    2097,
                    2066,
                    2098,
                    2068,
                    1078,
                    2070,
                    1081
                ],
                "i": [
                    4353,
                    4354,
                    1063,
                    1064,
                    1065,
                    4301,
                    1070,
                    1071,
                    1072,
                    4302,
                    4303,
                    2937,
                    2938,
                    4351
                ],
                "s": [
                    1063,
                    1067,
                    1070,
                    1074,
                    2072
                ],
                "tf.unstack": [
                    2817,
                    2822,
                    1070,
                    1063
                ],
                "x_shape.append": [
                    1065,
                    1067
                ],
                "y_shape": [
                    1069,
                    1072,
                    1074,
                    1075,
                    1079,
                    1081
                ],
                "y_shape.append": [
                    1072,
                    1074
                ],
                "y_permute_dim": [
                    1076,
                    1077,
                    1079
                ],
                "list": [
                    1798,
                    3846,
                    3213,
                    1177,
                    3610,
                    2980,
                    3622,
                    2732,
                    1837,
                    1838,
                    2607,
                    1076,
                    1846,
                    3256,
                    2515,
                    2518,
                    2263,
                    2264,
                    2521,
                    2650,
                    2524,
                    2525,
                    2793,
                    2541,
                    3833,
                    1147
                ],
                "y_permute_dim.pop": [
                    1077
                ],
                "xt": [
                    1080,
                    1078
                ],
                "tf.reshape": [
                    1153,
                    1156,
                    2183,
                    2197,
                    1949,
                    4136,
                    4140,
                    2093,
                    4143,
                    1078,
                    1079,
                    1080,
                    3278,
                    3285,
                    3038,
                    1762,
                    1763,
                    1767,
                    1771
                ],
                "yt": [
                    1080,
                    1079
                ],
                "tf.transpose": [
                    3584,
                    1163,
                    3858,
                    3731,
                    3476,
                    2981,
                    1963,
                    4140,
                    4143,
                    3634,
                    1079,
                    3770,
                    1215,
                    3905,
                    3267,
                    4171,
                    3545,
                    3807,
                    3430,
                    2794,
                    3690,
                    3951,
                    4207,
                    2801,
                    3453
                ],
                "tf.matmul": [
                    1080,
                    1171,
                    1085
                ],
                "out": [
                    1161,
                    1163,
                    1179,
                    1171,
                    1177,
                    1178,
                    1083,
                    1180,
                    1085,
                    1086
                ],
                "tf.sparse_tensor_dense_matmul": [
                    1083
                ],
                "axes": [
                    1160,
                    1161,
                    1163,
                    1165,
                    1166,
                    1167,
                    2980,
                    2981,
                    2350,
                    2351,
                    2352,
                    2793,
                    2794,
                    2801,
                    1140,
                    1141,
                    1144,
                    1146,
                    1147,
                    1150
                ],
                "x_ndim": [
                    1152,
                    1154,
                    1155,
                    1173,
                    1142,
                    1174,
                    1176,
                    1146,
                    1151
                ],
                "y_ndim": [
                    1152,
                    1154,
                    1155,
                    1173,
                    1174,
                    1143,
                    1146,
                    1151
                ],
                "a": [
                    1563,
                    1147
                ],
                "diff": [
                    1152,
                    1153,
                    1155,
                    1156,
                    1158,
                    1172,
                    1177
                ],
                "tf.concat": [
                    1936,
                    1153,
                    1156,
                    3037
                ],
                "tf.reduce_sum": [
                    1282,
                    1161,
                    1163,
                    3224,
                    3228
                ],
                "tf.multiply": [
                    1161,
                    1163
                ],
                "adj_x": [
                    1169,
                    1171,
                    1166
                ],
                "adj_y": [
                    1170,
                    1171,
                    1167
                ],
                "idx": [
                    1176,
                    1177,
                    1174
                ],
                "tf.squeeze": [
                    1888,
                    1890,
                    1894,
                    3687,
                    4167,
                    4168,
                    1898,
                    2224,
                    1177
                ],
                "expand_dims": [
                    2800,
                    1179
                ],
                "tf.nn.embedding_lookup": [
                    1228
                ],
                "tf.nn": [
                    3725,
                    3854,
                    3989,
                    1814,
                    3356,
                    3997,
                    3230,
                    4009,
                    3630,
                    3378,
                    3764,
                    3126,
                    3894,
                    3128,
                    3898,
                    3391,
                    1729,
                    1731,
                    3575,
                    3146,
                    1228,
                    3279,
                    3407,
                    3536,
                    3799,
                    1752,
                    3164,
                    3681,
                    3940,
                    3176,
                    3944,
                    1899,
                    1773,
                    3311,
                    3188,
                    1911,
                    3324
                ],
                "reference": [
                    1228
                ],
                "tf.reduce_max": [
                    1248
                ],
                "axis": [
                    1282,
                    1414,
                    1926,
                    1929,
                    1931,
                    1934,
                    3214,
                    1936,
                    2321,
                    3217,
                    1299,
                    1427,
                    2068,
                    2070,
                    3224,
                    2073,
                    3228,
                    1312,
                    1440,
                    2081,
                    2211,
                    2090,
                    1325,
                    2224,
                    3257,
                    3260,
                    3391,
                    1344,
                    3264,
                    3265,
                    1347,
                    3266,
                    1365,
                    1877,
                    1879,
                    1755,
                    1756,
                    3164,
                    1759,
                    1248,
                    1384,
                    1265,
                    1524,
                    1399
                ],
                "keepdims": [
                    1248,
                    1282,
                    1348,
                    1414,
                    1384,
                    1265,
                    1299,
                    1524,
                    1365,
                    1399
                ],
                "tf.reduce_min": [
                    1265
                ],
                "tf.reduce_prod": [
                    1299
                ],
                "tf.cumsum": [
                    1312
                ],
                "tf.cumprod": [
                    1325
                ],
                "tf.bool": [
                    4131,
                    1413,
                    1382,
                    3003,
                    2797,
                    2798,
                    1398,
                    2907,
                    1342
                ],
                "m": [
                    1344,
                    1345
                ],
                "tf.reduce_mean": [
                    1344,
                    1346,
                    1384
                ],
                "devs_squared": [
                    1345,
                    1346
                ],
                "tf.square": [
                    1345,
                    1452
                ],
                "tf.sqrt": [
                    1365,
                    1479
                ],
                "var": [
                    1729,
                    1889,
                    1731,
                    1763,
                    1890,
                    1734,
                    1905,
                    1780,
                    1365,
                    1911,
                    1752
                ],
                "tf.reduce_any": [
                    1399
                ],
                "tf.reduce_all": [
                    1414
                ],
                "tf.argmax": [
                    1427
                ],
                "tf.argmin": [
                    1440
                ],
                "tf.abs": [
                    1464
                ],
                "zero": [
                    1476,
                    3341,
                    1478,
                    3343
                ],
                "_to_tensor": [
                    1476,
                    1477,
                    3272,
                    3307,
                    1581,
                    1582,
                    3341,
                    3342,
                    3226,
                    3131
                ],
                "inf": [
                    1477,
                    1478
                ],
                "np.inf": [
                    1580,
                    1477
                ],
                "tf.clip_by_value": [
                    1478,
                    3273,
                    3308,
                    1583,
                    3343,
                    3227
                ],
                "tf.exp": [
                    1491
                ],
                "tf.log": [
                    3274,
                    4171,
                    3309,
                    4207,
                    3228,
                    1503
                ],
                "tf.reduce_logsumexp": [
                    1524
                ],
                "tf.round": [
                    1538
                ],
                "tf.sign": [
                    1550
                ],
                "tf.pow": [
                    1563
                ],
                "max_value": [
                    1577,
                    1578,
                    1579,
                    1580,
                    1582,
                    1583,
                    3130,
                    3131,
                    3132
                ],
                "min_value": [
                    1577,
                    1578,
                    1581,
                    1583
                ],
                "tf.equal": [
                    1596
                ],
                "tf.not_equal": [
                    1609
                ],
                "tf.greater": [
                    1622
                ],
                "tf.greater_equal": [
                    1635
                ],
                "tf.less": [
                    1648
                ],
                "tf.less_equal": [
                    1661
                ],
                "tf.maximum": [
                    1674
                ],
                "tf.minimum": [
                    3132,
                    1687
                ],
                "tf.sin": [
                    1699
                ],
                "tf.cos": [
                    1711
                ],
                "tf.nn.moments": [
                    1752,
                    1729
                ],
                "reduction_axes": [
                    1729,
                    1798,
                    1852,
                    1837,
                    1838,
                    1840,
                    1848,
                    1843,
                    1846,
                    1752,
                    1756
                ],
                "normed": [
                    1731,
                    1780,
                    1773,
                    1734
                ],
                "tf.nn.batch_normalization": [
                    1731,
                    1773,
                    1911
                ],
                "beta": [
                    1891,
                    1732,
                    1892,
                    1893,
                    1894,
                    1768,
                    1771,
                    1902,
                    1839,
                    1911,
                    1809,
                    1810,
                    1843,
                    1847,
                    1817,
                    1851
                ],
                "gamma": [
                    1732,
                    1764,
                    1767,
                    1895,
                    1896,
                    1897,
                    1898,
                    1805,
                    1806,
                    1839,
                    1901,
                    1911,
                    1843,
                    1847,
                    1816,
                    1851
                ],
                "epsilon": [
                    1733,
                    3226,
                    3272,
                    3307,
                    4171,
                    1903,
                    4207,
                    1841,
                    1779,
                    1844,
                    1911,
                    1849,
                    1818,
                    1853
                ],
                "target_shape": [
                    1760,
                    1762,
                    1763,
                    1767,
                    1771,
                    1754,
                    1757,
                    1759
                ],
                "target_shape.append": [
                    1757,
                    1759
                ],
                "tf.stack": [
                    1760,
                    2117,
                    3622,
                    2855,
                    3834,
                    3846,
                    4124,
                    2864,
                    2321,
                    2197,
                    2934,
                    2937,
                    2842,
                    3611,
                    2874,
                    4125
                ],
                "broadcast_mean": [
                    1762,
                    1775
                ],
                "broadcast_var": [
                    1776,
                    1763
                ],
                "broadcast_gamma": [
                    1778,
                    1765,
                    1767
                ],
                "broadcast_beta": [
                    1769,
                    1771,
                    1777
                ],
                "normalization_axis": [
                    1808,
                    1802,
                    1812,
                    1799
                ],
                "tf_data_format": [
                    3456,
                    3718,
                    1800,
                    3720,
                    3849,
                    1803,
                    3856,
                    3473,
                    3729,
                    3730,
                    3857,
                    3478,
                    3479,
                    1819,
                    3613,
                    3615,
                    3625,
                    3884,
                    3757,
                    3886,
                    3759,
                    3632,
                    3633,
                    3768,
                    3769,
                    3896,
                    3900,
                    3904,
                    3535,
                    3664,
                    3665,
                    3666,
                    3668,
                    3797,
                    1878,
                    3542,
                    1880,
                    3544,
                    1882,
                    3670,
                    1884,
                    3805,
                    3806,
                    3930,
                    3932,
                    3427,
                    3685,
                    3942,
                    3432,
                    3433,
                    3689,
                    3583,
                    3946,
                    3950,
                    1906,
                    3572,
                    3450,
                    3836,
                    3581,
                    3838,
                    3455
                ],
                "tf.nn.fused_batch_norm": [
                    1899,
                    1814
                ],
                "_has_nchw_support": [
                    3429,
                    1884,
                    1838,
                    3475,
                    3988,
                    3452
                ],
                "_broadcast_normalize_batch_in_training": [
                    1851,
                    1839
                ],
                "_fused_normalize_batch_in_training": [
                    1842
                ],
                "sorted": [
                    2579,
                    1846,
                    2631
                ],
                "_regular_normalize_batch_in_training": [
                    1847
                ],
                "zeros_like": [
                    1892,
                    2845
                ],
                "ones_like": [
                    1896
                ],
                "rank": [
                    1928,
                    1929,
                    1927
                ],
                "tensors": [
                    1936,
                    1933,
                    1934,
                    1927
                ],
                "tf.sparse_concat": [
                    1934
                ],
                "pattern": [
                    2240,
                    2306,
                    2308,
                    2117,
                    2118,
                    1963,
                    2299,
                    2262,
                    2266,
                    2267,
                    2239
                ],
                "data_format": [
                    2049,
                    2306,
                    3716,
                    3973,
                    3718,
                    4357,
                    3983,
                    3857,
                    3474,
                    3730,
                    3986,
                    4369,
                    3609,
                    3995,
                    3613,
                    3615,
                    4006,
                    2043,
                    3882,
                    3755,
                    3884,
                    3757,
                    3633,
                    3769,
                    3904,
                    1986,
                    3522,
                    3526,
                    4294,
                    3658,
                    1995,
                    3535,
                    3664,
                    3795,
                    2004,
                    2260,
                    3797,
                    3544,
                    3928,
                    2266,
                    3930,
                    3806,
                    2018,
                    3428,
                    3689,
                    3950,
                    3570,
                    3572,
                    2038,
                    4343,
                    3832,
                    2297,
                    3451,
                    3836,
                    3838,
                    3583
                ],
                "rows": [
                    1987,
                    1989,
                    1992,
                    2007,
                    2010
                ],
                "cols": [
                    1987,
                    1989,
                    1992,
                    2012,
                    2015
                ],
                "original_shape": [
                    1991,
                    2007,
                    2010,
                    2012,
                    2015
                ],
                "new_shape": [
                    4003,
                    4005,
                    4006,
                    4007,
                    1992,
                    1993,
                    3980,
                    1998,
                    3982,
                    2000,
                    3983,
                    3984
                ],
                "np.array": [
                    1993
                ],
                "height_factor": [
                    2040,
                    1993,
                    2010,
                    2045
                ],
                "width_factor": [
                    1993,
                    2041,
                    2046,
                    2015
                ],
                "permute_dimensions": [
                    1996,
                    4370,
                    4372,
                    4309,
                    2005
                ],
                "interpolation": [
                    1997,
                    1999
                ],
                "tf.image.resize_nearest_neighbor": [
                    1998
                ],
                "tf.image": [
                    2000,
                    1998
                ],
                "tf.image.resize_bilinear": [
                    2000
                ],
                "new_height": [
                    2008,
                    2017,
                    2010
                ],
                "new_width": [
                    2017,
                    2013,
                    2015
                ],
                "output_shape": [
                    3840,
                    3841,
                    3842,
                    3843,
                    3844,
                    3845,
                    3846,
                    3854,
                    3610,
                    3611,
                    3616,
                    3617,
                    3618,
                    3619,
                    3620,
                    3621,
                    3622,
                    3630,
                    3276,
                    3278,
                    3282,
                    2017,
                    2018,
                    4346,
                    3833,
                    3834,
                    3839
                ],
                "x.set_shape": [
                    2018
                ],
                "transpose_shape": [
                    2018,
                    2306,
                    4006,
                    3983,
                    2266
                ],
                "output": [
                    2827,
                    2828,
                    2955,
                    2958,
                    3213,
                    4365,
                    4366,
                    4370,
                    2963,
                    3219,
                    4372,
                    4373,
                    3224,
                    2842,
                    3226,
                    3227,
                    2845,
                    3228,
                    3231,
                    2849,
                    2860,
                    2935,
                    2867,
                    2868,
                    2870,
                    3256,
                    3262,
                    3267,
                    2940,
                    3272,
                    3273,
                    3274,
                    3276,
                    3278,
                    4308,
                    3285,
                    4309,
                    3307,
                    3308,
                    2925,
                    3309,
                    2928,
                    3312,
                    2934,
                    2039,
                    2040,
                    2041,
                    2042,
                    2044,
                    2045,
                    2046,
                    2047
                ],
                "repeat_elements": [
                    2039,
                    2040,
                    2041,
                    2044,
                    2045,
                    2046
                ],
                "depth_factor": [
                    2044,
                    2039
                ],
                "splits": [
                    2072,
                    2070
                ],
                "tf.split": [
                    2070
                ],
                "x_rep": [
                    2083,
                    2086,
                    2093,
                    2097,
                    2098,
                    2099,
                    2072,
                    2073
                ],
                "rep": [
                    2072,
                    2090,
                    2085
                ],
                "concatenate": [
                    2073,
                    4306,
                    4364,
                    4143
                ],
                "auxiliary_axis": [
                    2081,
                    2083,
                    2085,
                    2089
                ],
                "tf.expand_dims": [
                    4128,
                    2083,
                    2116,
                    2211,
                    4173,
                    3676,
                    3677,
                    3678
                ],
                "reps": [
                    2084,
                    2085,
                    2086,
                    2089,
                    2090,
                    2091,
                    2092
                ],
                "np.ones": [
                    2084
                ],
                "tf.tile": [
                    2937,
                    3042,
                    2854,
                    2118,
                    2086,
                    4136,
                    4140,
                    2933,
                    2841,
                    2171
                ],
                "np.delete": [
                    2089
                ],
                "x_rep.set_shape": [
                    2097
                ],
                "x_rep._keras_shape": [
                    2098
                ],
                "n": [
                    2169,
                    2170,
                    2171,
                    2117
                ],
                "stop": [
                    2152,
                    2142
                ],
                "start": [
                    2144,
                    2145,
                    2148,
                    2149,
                    2150,
                    2372,
                    2152
                ],
                "TypeError": [
                    2146,
                    2608,
                    2516,
                    2519,
                    2522,
                    2651
                ],
                "tf.cond": [
                    3017,
                    2148
                ],
                "start.dtype": [
                    2149
                ],
                "result": [
                    2152,
                    2154,
                    2155
                ],
                "tf.range": [
                    2152,
                    4128,
                    4140,
                    4136
                ],
                "step": [
                    2152
                ],
                "cast": [
                    2154,
                    3277
                ],
                "prod": [
                    2197
                ],
                "padding": [
                    3719,
                    3848,
                    3727,
                    3855,
                    3494,
                    3495,
                    3496,
                    3497,
                    3624,
                    3499,
                    3500,
                    3885,
                    3758,
                    3631,
                    3766,
                    3895,
                    3899,
                    2238,
                    2239,
                    3525,
                    3533,
                    3534,
                    2257,
                    2258,
                    2259,
                    3541,
                    3669,
                    2263,
                    2264,
                    3798,
                    3931,
                    3804,
                    3683,
                    3941,
                    3945,
                    2293,
                    2294,
                    2295,
                    2296,
                    3574,
                    3580,
                    2301,
                    2302,
                    2303
                ],
                "tf.pad": [
                    2240,
                    2267,
                    2308
                ],
                "normalize_data_format": [
                    3522,
                    3716,
                    3973,
                    4294,
                    3658,
                    3755,
                    3882,
                    3609,
                    3570,
                    3795,
                    2260,
                    3928,
                    4343,
                    3832,
                    2297
                ],
                "tf.one_hot": [
                    2336
                ],
                "num_classes": [
                    2336
                ],
                "tf.reverse": [
                    2352
                ],
                "tf.slice": [
                    2372
                ],
                "x.eval": [
                    2387
                ],
                "ops": [
                    2400,
                    2399
                ],
                "run": [
                    2400,
                    2450,
                    2423
                ],
                "np.asarray": [
                    2633,
                    2628,
                    2413,
                    2437
                ],
                "x.dtype.name.split": [
                    2438,
                    2414
                ],
                "x.dtype.name": [
                    2438,
                    2414
                ],
                "assign_placeholder": [
                    2440,
                    2443,
                    2445,
                    2446,
                    2416,
                    2449,
                    2419,
                    2420,
                    2421,
                    2423
                ],
                "x._assign_placeholder": [
                    2416,
                    2440,
                    2421,
                    2446
                ],
                "assign_op": [
                    2441,
                    2445,
                    2447,
                    2448,
                    2417,
                    2420,
                    2422,
                    2423
                ],
                "x._assign_op": [
                    2417,
                    2441,
                    2422,
                    2447
                ],
                "x.assign": [
                    2420,
                    2445
                ],
                "tuples": [
                    2433,
                    2436
                ],
                "assign_ops": [
                    2448,
                    2434,
                    2450
                ],
                "feed_dict": [
                    2435,
                    2660,
                    2663,
                    2449,
                    2450,
                    2652
                ],
                "assign_ops.append": [
                    2448
                ],
                "tf.Print": [
                    2484
                ],
                "message": [
                    2484
                ],
                "updates": [
                    2528,
                    2521,
                    2514,
                    2705
                ],
                "inputs": [
                    2817,
                    4358,
                    4361,
                    2705,
                    2607,
                    2682,
                    2615,
                    2878,
                    2882,
                    2883,
                    2889,
                    2892,
                    4304,
                    2515,
                    2650,
                    2524,
                    2653,
                    2787,
                    2794,
                    2670,
                    2674,
                    2676,
                    2678,
                    2810
                ],
                "outputs": [
                    2977,
                    2883,
                    2980,
                    2885,
                    2981,
                    2983,
                    2864,
                    2705,
                    2518,
                    2874,
                    2525
                ],
                "self.inputs": [
                    2669,
                    2524,
                    2653,
                    2615
                ],
                "self.outputs": [
                    2592,
                    2661,
                    2665,
                    2647,
                    2525,
                    2526
                ],
                "tf.control_dependencies": [
                    2526
                ],
                "updates_ops": [
                    2535,
                    2531,
                    2534,
                    2527
                ],
                "update": [
                    2528,
                    2529,
                    2530,
                    2534
                ],
                "p": [
                    2530,
                    2531,
                    4076
                ],
                "new_p": [
                    2530,
                    2531
                ],
                "updates_ops.append": [
                    2531,
                    2534
                ],
                "self.updates_op": [
                    2595,
                    2661,
                    2535
                ],
                "tf.group": [
                    2535
                ],
                "self.name": [
                    2536
                ],
                "self.feed_dict": [
                    2630,
                    2631,
                    2633,
                    2538,
                    2578,
                    2579,
                    2652
                ],
                "session_kwargs.pop": [
                    2538,
                    2540
                ],
                "session_kwargs": [
                    2538,
                    2540,
                    2548,
                    2549,
                    2552
                ],
                "self.fetches": [
                    2592,
                    2661,
                    2540,
                    2541,
                    2542,
                    2547
                ],
                "self.session_kwargs": [
                    2664,
                    2548
                ],
                "session_kwargs.keys": [
                    2552
                ],
                "self._callable_fn": [
                    2600,
                    2553,
                    2637,
                    2646
                ],
                "self._feed_arrays": [
                    2601,
                    2554,
                    2638
                ],
                "self._feed_symbols": [
                    2640,
                    2602,
                    2555
                ],
                "self._symbol_vals": [
                    2603,
                    2556,
                    2639
                ],
                "self._session": [
                    2641,
                    2604,
                    2557
                ],
                "callable_opts": [
                    2593,
                    2595,
                    2597,
                    2574,
                    2577,
                    2580,
                    2583
                ],
                "config_pb2.CallableOptions": [
                    2574
                ],
                "config_pb2": [
                    2574
                ],
                "feed_arrays": [
                    2601,
                    2638,
                    2576,
                    2642,
                    2611,
                    2623
                ],
                "callable_opts.feed.append": [
                    2577,
                    2580
                ],
                "callable_opts.feed": [
                    2577,
                    2580
                ],
                "key": [
                    2631,
                    2633,
                    2634,
                    2701,
                    2702,
                    2703,
                    2579,
                    2580
                ],
                "self.feed_dict.keys": [
                    2579,
                    2631
                ],
                "key.name": [
                    2580
                ],
                "feed_symbols": [
                    2602,
                    2640,
                    2643,
                    2613,
                    2582,
                    2620
                ],
                "symbol_vals": [
                    2603,
                    2639,
                    2644,
                    2614,
                    2582,
                    2621
                ],
                "connection": [
                    2589,
                    2590,
                    2583
                ],
                "callable_opts.tensor_connection.add": [
                    2583
                ],
                "callable_opts.tensor_connection": [
                    2583
                ],
                "y.dtype": [
                    2584
                ],
                "from_tensor": [
                    2586,
                    2587,
                    2588,
                    2589
                ],
                "tf_ops._as_graph_element": [
                    2586
                ],
                "connection.from_tensor": [
                    2589
                ],
                "from_tensor.name": [
                    2589
                ],
                "connection.to_tensor": [
                    2590
                ],
                "callable_opts.fetch.append": [
                    2593
                ],
                "callable_opts.fetch": [
                    2593
                ],
                "callable_opts.target.append": [
                    2595
                ],
                "callable_opts.target": [
                    2595
                ],
                "self.updates_op.name": [
                    2595
                ],
                "callable_fn": [
                    2600,
                    2597
                ],
                "session._make_callable_from_options": [
                    2597
                ],
                "array_vals": [
                    2632,
                    2627,
                    2612,
                    2646
                ],
                "feed_symbols.append": [
                    2620
                ],
                "symbol_vals.append": [
                    2621
                ],
                "feed_arrays.append": [
                    2623
                ],
                "array_vals.append": [
                    2632,
                    2627
                ],
                "as_numpy_dtype": [
                    2634,
                    2629
                ],
                "tensor.dtype": [
                    2629
                ],
                "key.dtype": [
                    2634
                ],
                "self._make_callable": [
                    2642
                ],
                "fetched": [
                    2646,
                    2647
                ],
                "self.feed_dict.copy": [
                    2652
                ],
                "fetches": [
                    2661,
                    2663
                ],
                "updated": [
                    2665,
                    2663
                ],
                "self._legacy_call": [
                    2674,
                    2682
                ],
                "self._call": [
                    2676
                ],
                "kwargs": [
                    2705,
                    2700,
                    2701
                ],
                "has_arg": [
                    2702
                ],
                "tf.Session.run": [
                    2702
                ],
                "Function.__init__": [
                    2702
                ],
                "Function": [
                    2705,
                    2702
                ],
                "msg": [
                    2704,
                    2703
                ],
                "tf.gradients": [
                    2718
                ],
                "loss": [
                    2718
                ],
                "map": [
                    2733
                ],
                "tf.stop_gradient": [
                    2733,
                    2735
                ],
                "inputs.get_shape": [
                    2810,
                    2787
                ],
                "mask": [
                    2821,
                    2822,
                    2796,
                    2797,
                    2798,
                    2799,
                    2800,
                    2801,
                    2895,
                    2904,
                    2910
                ],
                "mask.dtype": [
                    2797
                ],
                "mask.get_shape": [
                    2799
                ],
                "constants": [
                    2883,
                    2827,
                    2957,
                    2927,
                    2867,
                    2803,
                    2804
                ],
                "uses_learning_phase": [
                    2982,
                    2829,
                    3085,
                    2960,
                    2930,
                    2869,
                    2807,
                    3067,
                    3069
                ],
                "unroll": [
                    2809
                ],
                "states": [
                    2880,
                    2852,
                    2859,
                    2827,
                    2861,
                    2926,
                    2935,
                    2896,
                    2956,
                    2961,
                    2867,
                    2931,
                    2871,
                    2969,
                    2938,
                    2813
                ],
                "initial_states": [
                    2880,
                    2883,
                    2813
                ],
                "successive_states": [
                    2861,
                    2863,
                    2871,
                    2873,
                    2814
                ],
                "successive_outputs": [
                    2860,
                    2862,
                    2864,
                    2815,
                    2870,
                    2872,
                    2874,
                    2844,
                    2847
                ],
                "input_list": [
                    2817,
                    2826,
                    2819,
                    2866
                ],
                "go_backwards": [
                    2818,
                    2877,
                    2903,
                    2823
                ],
                "input_list.reverse": [
                    2819
                ],
                "mask_list": [
                    2824,
                    2826,
                    2822
                ],
                "mask_list.reverse": [
                    2824
                ],
                "inp": [
                    2867,
                    2826,
                    2827,
                    2866
                ],
                "mask_t": [
                    2937,
                    2854,
                    2826,
                    2924,
                    2933,
                    2841
                ],
                "new_states": [
                    2937,
                    2852,
                    2983,
                    2827,
                    2955,
                    2925,
                    2863,
                    2961,
                    2931,
                    2964,
                    2936,
                    2873,
                    2938,
                    2941,
                    2975
                ],
                "step_function": [
                    2883,
                    2827,
                    2955,
                    2925,
                    2867
                ],
                "tiled_mask_t": [
                    2849,
                    2854,
                    2856,
                    2933,
                    2935,
                    2841
                ],
                "prev_output": [
                    2849,
                    2845,
                    2847
                ],
                "tf.where": [
                    2849,
                    3041,
                    3043,
                    2856,
                    4076,
                    3150,
                    2935,
                    2937
                ],
                "return_states": [
                    2856,
                    2859,
                    2851
                ],
                "state": [
                    2852,
                    2858,
                    2961,
                    2962,
                    2931,
                    2932
                ],
                "new_state": [
                    2852,
                    2855,
                    2857,
                    2961,
                    2962,
                    2931,
                    2932
                ],
                "return_states.append": [
                    2856
                ],
                "successive_outputs.append": [
                    2860,
                    2870
                ],
                "successive_states.append": [
                    2861,
                    2871
                ],
                "last_output": [
                    2978,
                    2982,
                    2983,
                    2862,
                    2872
                ],
                "reverse": [
                    2904,
                    4141,
                    2878
                ],
                "time_steps": [
                    2882,
                    2886,
                    2890,
                    2967,
                    2908
                ],
                "output_ta": [
                    2977,
                    2978,
                    2884,
                    2969,
                    2974
                ],
                "tensor_array_ops.TensorArray": [
                    2888,
                    2906,
                    2884
                ],
                "tensor_array_ops": [
                    2888,
                    2906,
                    2884
                ],
                "outputs.dtype": [
                    2885
                ],
                "input_ta": [
                    2888,
                    2954,
                    2923,
                    2892
                ],
                "inputs.dtype": [
                    2889
                ],
                "input_ta.unstack": [
                    2892
                ],
                "time": [
                    2954,
                    2923,
                    2924,
                    2893,
                    2963,
                    2964,
                    2967,
                    2969,
                    2940,
                    2941
                ],
                "mask_ta": [
                    2906,
                    2924,
                    2910
                ],
                "mask_ta.unstack": [
                    2910
                ],
                "current_input": [
                    4129,
                    2954,
                    2923,
                    2955,
                    2925
                ],
                "input_ta.read": [
                    2954,
                    2923
                ],
                "mask_ta.read": [
                    2924
                ],
                "new_state.set_shape": [
                    2962,
                    2932
                ],
                "state.get_shape": [
                    2962,
                    2932
                ],
                "output_ta_t": [
                    2964,
                    2963,
                    2940,
                    2941
                ],
                "output_ta_t.write": [
                    2963,
                    2940
                ],
                "final_outputs": [
                    2974,
                    2973,
                    2966,
                    2975
                ],
                "control_flow_ops.while_loop": [
                    2966
                ],
                "control_flow_ops": [
                    2966
                ],
                "_step": [
                    2968
                ],
                "input_length": [
                    4168,
                    4175,
                    4208,
                    4213,
                    4217,
                    2972
                ],
                "last_time": [
                    2978,
                    2973
                ],
                "output_ta.stack": [
                    2977
                ],
                "output_ta.read": [
                    2978
                ],
                "outputs.get_shape": [
                    2980
                ],
                "last_output._uses_learning_phase": [
                    2982
                ],
                "condition.dtype": [
                    3003
                ],
                "condition": [
                    3042,
                    3043,
                    3017,
                    3005,
                    3003,
                    3004,
                    3037,
                    3038
                ],
                "cond_ndim": [
                    3029,
                    3033,
                    3035,
                    3036,
                    3005,
                    3006
                ],
                "callable": [
                    3072,
                    3012,
                    3078,
                    3024,
                    3026,
                    3007
                ],
                "then_expression": [
                    3009,
                    3011,
                    3043,
                    3024,
                    3025,
                    3028,
                    3039,
                    3007
                ],
                "then_expression_fn": [
                    3018,
                    3011
                ],
                "else_expression": [
                    3043,
                    3012,
                    3014,
                    3016,
                    3026,
                    3027
                ],
                "else_expression_fn": [
                    3016,
                    3019
                ],
                "expr_ndim": [
                    3034,
                    3036,
                    3028,
                    3029
                ],
                "ndim_diff": [
                    3036,
                    3037
                ],
                "cond_shape": [
                    3040,
                    3037,
                    3038
                ],
                "expr_shape": [
                    3040,
                    3041,
                    3039
                ],
                "shape_diff": [
                    3040,
                    3041
                ],
                "tile_shape": [
                    3041,
                    3042
                ],
                "training": [
                    3107,
                    3077,
                    3084,
                    3065,
                    3066,
                    3071
                ],
                "learning_phase": [
                    3066
                ],
                "alt": [
                    3107,
                    3078,
                    3079,
                    3081,
                    3084
                ],
                "switch": [
                    3084
                ],
                "in_train_phase": [
                    3107
                ],
                "alpha": [
                    3150,
                    3147,
                    3125,
                    3126
                ],
                "tf.nn.leaky_relu": [
                    3126
                ],
                "tf.nn.relu": [
                    3128
                ],
                "res": [
                    3146,
                    3148,
                    3150,
                    3279,
                    3285,
                    3287
                ],
                "tf.nn.elu": [
                    3146
                ],
                "tf.nn.softmax": [
                    3164
                ],
                "tf.nn.softplus": [
                    3176
                ],
                "tf.nn.softsign": [
                    3188
                ],
                "output_dimensions": [
                    3264,
                    3265,
                    3213,
                    3214,
                    3256,
                    3257
                ],
                "output.get_shape": [
                    3276,
                    3213,
                    3219,
                    3256,
                    3262
                ],
                "format": [
                    3216,
                    3217,
                    3219,
                    3259,
                    3260,
                    3262
                ],
                "from_logits": [
                    3305,
                    3222,
                    3271
                ],
                "_epsilon": [
                    3272,
                    3273,
                    3307,
                    3308,
                    3226,
                    3227
                ],
                "output.dtype.base_dtype": [
                    3272,
                    3226,
                    3307
                ],
                "output.dtype": [
                    3272,
                    3226,
                    3307
                ],
                "target": [
                    3228,
                    3277,
                    3230,
                    3311
                ],
                "tf.nn.softmax_cross_entropy_with_logits": [
                    3230
                ],
                "permutation": [
                    3265,
                    3266,
                    3267
                ],
                "targets": [
                    3280,
                    3277,
                    3407
                ],
                "flatten": [
                    3277
                ],
                "logits": [
                    3281,
                    3278
                ],
                "tf.nn.sparse_softmax_cross_entropy_with_logits": [
                    3279
                ],
                "tf.nn.sigmoid_cross_entropy_with_logits": [
                    3311
                ],
                "tf.nn.sigmoid": [
                    3324
                ],
                "one": [
                    3342,
                    3343
                ],
                "tf.nn.tanh": [
                    3356
                ],
                "retain_prob": [
                    3378,
                    3373
                ],
                "level": [
                    3373
                ],
                "tf.nn.dropout": [
                    3378
                ],
                "noise_shape": [
                    3378
                ],
                "tf.nn.l2_normalize": [
                    3391
                ],
                "tf.nn.in_top_k": [
                    3407
                ],
                "predictions": [
                    3407
                ],
                "k": [
                    3407
                ],
                "StrictVersion": [
                    3448,
                    3425,
                    3471
                ],
                "tf.__version__.split": [
                    3448,
                    3425,
                    3471
                ],
                "tf.__version__": [
                    3448,
                    3425,
                    3471
                ],
                "kernel_shape": [
                    3524,
                    4297,
                    4298,
                    3531,
                    4347,
                    4348
                ],
                "kernel.get_shape": [
                    3524
                ],
                "kernel": [
                    3524,
                    4297,
                    3577,
                    3630,
                    3854,
                    4365,
                    3538,
                    4308,
                    3801,
                    4347
                ],
                "left_pad": [
                    3531,
                    3532
                ],
                "dilation_rate": [
                    3684,
                    3531,
                    3661,
                    3662,
                    3728,
                    3539,
                    3767,
                    3802,
                    3578,
                    3679
                ],
                "temporal_padding": [
                    3532
                ],
                "_preprocess_padding": [
                    3719,
                    3624,
                    3848,
                    3885,
                    3534,
                    3758,
                    3669,
                    3574,
                    3798,
                    3931
                ],
                "_preprocess_conv1d_input": [
                    3664,
                    3535
                ],
                "tf.nn.convolution": [
                    3536,
                    3799,
                    3575
                ],
                "strides": [
                    3721,
                    3850,
                    3723,
                    3852,
                    3726,
                    3854,
                    3626,
                    3628,
                    3630,
                    3887,
                    3760,
                    3762,
                    3890,
                    3765,
                    3894,
                    3898,
                    4296,
                    3659,
                    3660,
                    3540,
                    3672,
                    3675,
                    3803,
                    3933,
                    3936,
                    3682,
                    3940,
                    3944,
                    4345,
                    3579
                ],
                "_preprocess_conv2d_input": [
                    3718,
                    3884,
                    3757,
                    3572,
                    3613
                ],
                "tf.nn.conv2d_transpose": [
                    3630
                ],
                "spatial_start_dim": [
                    3674,
                    3676,
                    3687,
                    3671
                ],
                "depthwise_kernel": [
                    3681,
                    3764,
                    3677,
                    3725
                ],
                "pointwise_kernel": [
                    3681,
                    3725,
                    3678
                ],
                "tf.nn.separable_conv2d": [
                    3681,
                    3725
                ],
                "tf.nn.depthwise_conv2d": [
                    3764
                ],
                "_preprocess_conv3d_input": [
                    3930,
                    3836,
                    3797
                ],
                "tf.nn.conv3d_transpose": [
                    3854
                ],
                "pool_size": [
                    3937,
                    3940,
                    3944,
                    3888,
                    3891,
                    3894,
                    3898,
                    3934
                ],
                "pool_mode": [
                    3939,
                    3943,
                    3948,
                    3893,
                    3897,
                    3902
                ],
                "tf.nn.max_pool": [
                    3894
                ],
                "tf.nn.avg_pool": [
                    3898
                ],
                "tf.nn.max_pool3d": [
                    3940
                ],
                "tf.nn.avg_pool3d": [
                    3944
                ],
                "bias_shape": [
                    4000,
                    4002,
                    4003,
                    4005,
                    3974,
                    3975,
                    3977,
                    3979,
                    3980,
                    3982,
                    3987,
                    3992,
                    3994,
                    3996
                ],
                "bias": [
                    4000,
                    3974,
                    4007,
                    4009,
                    3984,
                    3989,
                    3992,
                    3994,
                    3997
                ],
                "reshape": [
                    4000,
                    4358,
                    4007,
                    4361,
                    4366,
                    3984,
                    4304,
                    3992,
                    3994
                ],
                "tf.nn.bias_add": [
                    4009,
                    3989,
                    3997
                ],
                "tf.random_normal": [
                    4033
                ],
                "stddev": [
                    4033,
                    4103
                ],
                "tf.random_uniform": [
                    4056,
                    4076
                ],
                "minval": [
                    4056
                ],
                "maxval": [
                    4056
                ],
                "tf.truncated_normal": [
                    4103
                ],
                "label_shape": [
                    4128,
                    4131,
                    4136,
                    4137,
                    4140,
                    4141,
                    4147,
                    4123,
                    4124,
                    4125
                ],
                "labels": [
                    4145,
                    4123
                ],
                "num_batches_tns": [
                    4136,
                    4124
                ],
                "max_num_labels_tns": [
                    4129,
                    4141,
                    4125
                ],
                "tf.fill": [
                    4128,
                    4131
                ],
                "init": [
                    4131,
                    4133
                ],
                "dense_mask": [
                    4142,
                    4138,
                    4132,
                    4134
                ],
                "functional_ops.scan": [
                    4132
                ],
                "functional_ops": [
                    4132
                ],
                "range_less_than": [
                    4132
                ],
                "label_lengths": [
                    4132
                ],
                "label_array": [
                    4136,
                    4138
                ],
                "label_ind": [
                    4138,
                    4143
                ],
                "tf.boolean_mask": [
                    4138,
                    4142
                ],
                "batch_array": [
                    4140,
                    4142
                ],
                "batch_ind": [
                    4142,
                    4143
                ],
                "vals_sparse": [
                    4145,
                    4147
                ],
                "tf.gather_nd": [
                    4145
                ],
                "tf.to_int64": [
                    4147
                ],
                "label_length": [
                    4169,
                    4167
                ],
                "tf.to_int32": [
                    4168,
                    4169,
                    4208,
                    4167
                ],
                "sparse_labels": [
                    4169,
                    4174
                ],
                "ctc_label_dense_to_sparse": [
                    4169
                ],
                "y_true": [
                    4169
                ],
                "y_pred": [
                    4171,
                    4173,
                    4207,
                    4212,
                    4216
                ],
                "ctc.ctc_loss": [
                    4173
                ],
                "ctc": [
                    4211,
                    4173,
                    4215
                ],
                "greedy": [
                    4210
                ],
                "decoded": [
                    4211,
                    4221,
                    4215
                ],
                "log_prob": [
                    4211,
                    4222,
                    4215
                ],
                "ctc.ctc_greedy_decoder": [
                    4211
                ],
                "ctc.ctc_beam_search_decoder": [
                    4215
                ],
                "beam_width": [
                    4217
                ],
                "top_paths": [
                    4218
                ],
                "decoded_dense": [
                    4220,
                    4222
                ],
                "tf.sparse_to_dense": [
                    4220
                ],
                "st.indices": [
                    4220
                ],
                "st": [
                    4220,
                    4221
                ],
                "st.dense_shape": [
                    4220
                ],
                "st.values": [
                    4220
                ],
                "tf.map_fn": [
                    4239
                ],
                "fn": [
                    4255,
                    4271,
                    4239
                ],
                "elems": [
                    4255,
                    4271,
                    4239
                ],
                "tf.foldl": [
                    4255
                ],
                "initializer": [
                    4271,
                    4255
                ],
                "tf.foldr": [
                    4271
                ],
                "stride": [
                    4296,
                    4302,
                    4303
                ],
                "output_length": [
                    4298,
                    4301
                ],
                "feature_dim": [
                    4359,
                    4298,
                    4362,
                    4305,
                    4348
                ],
                "filters": [
                    4298,
                    4348,
                    4367
                ],
                "xs": [
                    4358,
                    4361,
                    4300,
                    4364,
                    4304,
                    4306,
                    4350
                ],
                "slice_length": [
                    4304,
                    4302
                ],
                "kernel_size": [
                    4354,
                    4356,
                    4303
                ],
                "xs.append": [
                    4304,
                    4361,
                    4358
                ],
                "x_aggregate": [
                    4306,
                    4308,
                    4364,
                    4365
                ],
                "batch_dot": [
                    4308,
                    4365
                ],
                "stride_row": [
                    4345,
                    4354,
                    4353
                ],
                "stride_col": [
                    4345,
                    4355,
                    4356
                ],
                "output_row": [
                    4346,
                    4367,
                    4351
                ],
                "output_col": [
                    4352,
                    4346,
                    4367
                ],
                "j": [
                    4352,
                    4355,
                    4356
                ],
                "slice_row": [
                    4353,
                    4361,
                    4358
                ],
                "slice_col": [
                    4361,
                    4355,
                    4358
                ]
            },
            "filtered_variables_in_file": {
                "py_all": [
                    703,
                    735,
                    1933,
                    31
                ],
                "py_any": [
                    32,
                    2669,
                    2670,
                    2678,
                    1147
                ],
                "py_sum": [
                    33
                ],
                "py_slice": [
                    4353,
                    34,
                    4355,
                    4302
                ],
                "_SESSION": [
                    97,
                    40,
                    179,
                    186,
                    187,
                    221
                ],
                "_GRAPH_LEARNING_PHASES": [
                    132,
                    101,
                    102,
                    136,
                    137,
                    45,
                    153
                ],
                "_GRAPH_UID_DICTS": [
                    75,
                    76,
                    77,
                    78,
                    51,
                    85
                ],
                "_MANUAL_VAR_INIT": [
                    56,
                    188,
                    118
                ],
                "_LOCAL_DEVICES": [
                    277,
                    61,
                    278,
                    279
                ],
                "graph": [
                    131,
                    132,
                    136,
                    137,
                    74,
                    75,
                    76,
                    77,
                    78
                ],
                "tf.get_default_graph": [
                    131,
                    102,
                    74,
                    245,
                    153
                ],
                "tf": [
                    3584,
                    1538,
                    515,
                    517,
                    4103,
                    1550,
                    2070,
                    2585,
                    1563,
                    3611,
                    4123,
                    4124,
                    4125,
                    4128,
                    2082,
                    2083,
                    4131,
                    3621,
                    2086,
                    1063,
                    3622,
                    4136,
                    4138,
                    2091,
                    4140,
                    2093,
                    1070,
                    1583,
                    3630,
                    4142,
                    3634,
                    4143,
                    4145,
                    4147,
                    566,
                    1078,
                    1079,
                    1080,
                    3126,
                    1083,
                    1596,
                    1085,
                    3128,
                    3132,
                    2116,
                    2117,
                    2118,
                    2629,
                    4167,
                    1609,
                    74,
                    2634,
                    3146,
                    4168,
                    3150,
                    4169,
                    4171,
                    4173,
                    1622,
                    3164,
                    3676,
                    3677,
                    95,
                    3678,
                    3681,
                    98,
                    1635,
                    2148,
                    2149,
                    102,
                    3687,
                    2152,
                    3176,
                    3690,
                    4207,
                    1648,
                    4208,
                    3188,
                    2171,
                    4220,
                    1661,
                    1153,
                    131,
                    1156,
                    133,
                    2183,
                    1161,
                    1674,
                    1163,
                    3725,
                    2702,
                    4239,
                    1171,
                    3731,
                    2197,
                    1687,
                    3224,
                    153,
                    1177,
                    3227,
                    3228,
                    2718,
                    3230,
                    4255,
                    1699,
                    2211,
                    2733,
                    174,
                    1711,
                    2224,
                    2735,
                    4271,
                    3764,
                    181,
                    184,
                    186,
                    3770,
                    701,
                    190,
                    702,
                    1215,
                    1729,
                    2240,
                    1731,
                    3267,
                    199,
                    3273,
                    3274,
                    1228,
                    206,
                    3278,
                    3279,
                    3285,
                    3799,
                    1752,
                    2267,
                    733,
                    734,
                    1759,
                    1248,
                    1760,
                    1762,
                    1763,
                    3807,
                    1767,
                    2794,
                    1771,
                    3308,
                    1773,
                    2797,
                    2798,
                    3309,
                    1265,
                    2801,
                    3311,
                    245,
                    3834,
                    764,
                    765,
                    3324,
                    2817,
                    1282,
                    2308,
                    3845,
                    2822,
                    3846,
                    1806,
                    3343,
                    3854,
                    2321,
                    1810,
                    1299,
                    3858,
                    790,
                    1814,
                    2841,
                    2842,
                    3356,
                    1312,
                    2336,
                    2849,
                    2854,
                    2855,
                    2856,
                    1325,
                    815,
                    2352,
                    2864,
                    3378,
                    308,
                    3894,
                    2874,
                    3898,
                    828,
                    1342,
                    1343,
                    1344,
                    1345,
                    1346,
                    2882,
                    2372,
                    3391,
                    3905,
                    331,
                    2893,
                    3407,
                    1365,
                    859,
                    2907,
                    863,
                    1888,
                    3425,
                    1890,
                    355,
                    3426,
                    3940,
                    1382,
                    1383,
                    360,
                    1384,
                    1894,
                    1898,
                    1899,
                    3430,
                    2414,
                    3944,
                    3951,
                    2419,
                    2933,
                    1398,
                    1399,
                    1911,
                    2934,
                    2935,
                    2937,
                    3448,
                    3449,
                    3453,
                    896,
                    900,
                    1413,
                    1414,
                    2438,
                    2443,
                    396,
                    1934,
                    3471,
                    1936,
                    3472,
                    402,
                    1427,
                    3476,
                    3989,
                    1949,
                    3997,
                    1440,
                    2981,
                    4009,
                    1963,
                    1452,
                    430,
                    2484,
                    1464,
                    3003,
                    3004,
                    957,
                    4033,
                    1478,
                    1479,
                    1992,
                    1993,
                    3017,
                    973,
                    1998,
                    2000,
                    3536,
                    1491,
                    4056,
                    3545,
                    986,
                    3037,
                    2526,
                    1503,
                    3038,
                    3039,
                    3041,
                    2531,
                    3042,
                    3043,
                    999,
                    2535,
                    4076,
                    4077,
                    4078,
                    2547,
                    1524,
                    3575
                ],
                "defaultdict": [
                    76
                ],
                "prefix": [
                    77,
                    78
                ],
                "tf.reset_default_graph": [
                    95
                ],
                "reset_uids": [
                    96
                ],
                "phase": [
                    136,
                    98,
                    133,
                    102
                ],
                "tf.placeholder_with_default": [
                    98,
                    133
                ],
                "value": [
                    900,
                    2436,
                    902,
                    2437,
                    392,
                    393,
                    2444,
                    2449,
                    402,
                    403,
                    404,
                    405,
                    150,
                    406,
                    153,
                    2423,
                    430,
                    2615,
                    2616,
                    2618,
                    2621,
                    2628,
                    2653,
                    863,
                    2655,
                    865,
                    2659,
                    2660,
                    2413,
                    2419,
                    118,
                    1014
                ],
                "default_session": [
                    176,
                    177,
                    174
                ],
                "tf.get_default_session": [
                    174
                ],
                "session": [
                    2597,
                    198,
                    2662,
                    2663,
                    2604,
                    206,
                    177,
                    209,
                    210,
                    211,
                    2610,
                    2641,
                    2645,
                    221,
                    187,
                    189
                ],
                "os.environ.get": [
                    180,
                    183
                ],
                "os.environ": [
                    180,
                    183
                ],
                "os": [
                    180,
                    183
                ],
                "config": [
                    184,
                    186,
                    181
                ],
                "tf.ConfigProto": [
                    184,
                    181
                ],
                "num_thread": [
                    184,
                    183
                ],
                "tf.Session": [
                    186,
                    2702
                ],
                "session.graph.as_default": [
                    189
                ],
                "session.graph": [
                    189
                ],
                "variables": [
                    192,
                    2732,
                    2733,
                    2735,
                    190,
                    2718
                ],
                "tf.global_variables": [
                    190
                ],
                "candidate_vars": [
                    194,
                    195,
                    199,
                    201,
                    191
                ],
                "v": [
                    396,
                    399,
                    400,
                    401,
                    402,
                    404,
                    406,
                    407,
                    410,
                    412,
                    413,
                    702,
                    703,
                    192,
                    193,
                    194,
                    704,
                    705,
                    199,
                    201,
                    203,
                    204,
                    734,
                    735,
                    736,
                    737
                ],
                "candidate_vars.append": [
                    194
                ],
                "is_initialized": [
                    201,
                    198
                ],
                "session.run": [
                    206,
                    198,
                    2663
                ],
                "tf.is_variable_initialized": [
                    199
                ],
                "uninitialized_vars": [
                    200,
                    203,
                    205,
                    206
                ],
                "flag": [
                    201,
                    202
                ],
                "uninitialized_vars.append": [
                    203
                ],
                "v._keras_initialized": [
                    204
                ],
                "tf.variables_initializer": [
                    206
                ],
                "session.list_devices": [
                    210
                ],
                "device_lib.list_local_devices": [
                    210
                ],
                "device_lib": [
                    210
                ],
                "self.device": [
                    234,
                    230
                ],
                "self": [
                    2578,
                    2579,
                    2592,
                    2595,
                    2600,
                    2601,
                    2602,
                    2603,
                    2604,
                    2682,
                    2615,
                    2630,
                    2631,
                    2633,
                    2637,
                    2638,
                    2639,
                    2640,
                    2641,
                    2642,
                    2646,
                    2647,
                    2524,
                    2525,
                    2526,
                    2652,
                    2653,
                    2661,
                    230,
                    2535,
                    2536,
                    2664,
                    234,
                    2538,
                    2540,
                    2541,
                    2542,
                    2665,
                    2669,
                    2674,
                    2547,
                    2548,
                    2676,
                    2553,
                    2554,
                    2555,
                    2556,
                    2557
                ],
                "device": [
                    267,
                    234,
                    266
                ],
                "g": [
                    245,
                    247
                ],
                "op": [
                    248,
                    246,
                    247
                ],
                "_TfDeviceCaptureOp": [
                    246
                ],
                "g._apply_device_functions": [
                    247
                ],
                "op.device": [
                    248
                ],
                "device_type": [
                    264,
                    267,
                    263
                ],
                "device_type.upper": [
                    267,
                    263
                ],
                "_get_current_tf_device": [
                    266
                ],
                "device.device_type": [
                    267
                ],
                "list_devices": [
                    278
                ],
                "get_session": [
                    2400,
                    673,
                    2662,
                    2668,
                    2450,
                    2387,
                    2610,
                    278,
                    2423
                ],
                "x.name": [
                    2577,
                    2593,
                    2590,
                    279
                ],
                "x": [
                    3072,
                    3073,
                    1538,
                    515,
                    3075,
                    517,
                    518,
                    519,
                    520,
                    3584,
                    3585,
                    3084,
                    1550,
                    3086,
                    2576,
                    2577,
                    2066,
                    3087,
                    533,
                    2070,
                    2582,
                    2584,
                    2585,
                    1563,
                    3613,
                    2590,
                    2592,
                    2593,
                    2082,
                    2083,
                    2084,
                    1061,
                    3107,
                    1063,
                    3621,
                    3977,
                    1581,
                    1582,
                    1583,
                    2096,
                    3630,
                    3634,
                    3635,
                    3978,
                    566,
                    1078,
                    3126,
                    3128,
                    1082,
                    1083,
                    1596,
                    1085,
                    3131,
                    3132,
                    3133,
                    2115,
                    2116,
                    3575,
                    2118,
                    1609,
                    3146,
                    590,
                    591,
                    3150,
                    593,
                    3664,
                    1622,
                    3164,
                    3676,
                    3681,
                    1635,
                    3687,
                    3176,
                    3690,
                    619,
                    3692,
                    2669,
                    2670,
                    1648,
                    3188,
                    1142,
                    2678,
                    2171,
                    1661,
                    1156,
                    3718,
                    1159,
                    2183,
                    1161,
                    1674,
                    1163,
                    652,
                    3725,
                    1166,
                    1171,
                    3731,
                    2197,
                    2198,
                    1687,
                    3732,
                    673,
                    1699,
                    2211,
                    3757,
                    1711,
                    2224,
                    3764,
                    3770,
                    3771,
                    1215,
                    2240,
                    1729,
                    1731,
                    3797,
                    3799,
                    1752,
                    3800,
                    1755,
                    2267,
                    1759,
                    1248,
                    3807,
                    3808,
                    1774,
                    1265,
                    3324,
                    3836,
                    1282,
                    2308,
                    3845,
                    3340,
                    3341,
                    3342,
                    1807,
                    1808,
                    2321,
                    3343,
                    1299,
                    1811,
                    1812,
                    790,
                    279,
                    1815,
                    3344,
                    3858,
                    3859,
                    3356,
                    1312,
                    3884,
                    1325,
                    1837,
                    815,
                    1839,
                    2352,
                    3378,
                    1843,
                    308,
                    1846,
                    1847,
                    3894,
                    3898,
                    1851,
                    828,
                    1342,
                    1343,
                    1344,
                    1345,
                    3391,
                    3905,
                    2372,
                    3906,
                    1875,
                    2387,
                    1365,
                    3930,
                    3424,
                    3426,
                    3940,
                    1382,
                    1383,
                    1384,
                    3430,
                    3433,
                    3944,
                    1900,
                    2413,
                    2414,
                    2415,
                    2416,
                    2417,
                    3951,
                    3952,
                    2420,
                    2421,
                    1398,
                    1399,
                    1911,
                    2422,
                    3447,
                    3449,
                    3453,
                    3456,
                    2436,
                    1413,
                    1414,
                    2437,
                    2438,
                    2439,
                    2440,
                    2441,
                    3975,
                    1933,
                    2445,
                    2446,
                    1936,
                    2447,
                    3470,
                    1427,
                    3472,
                    3476,
                    3984,
                    3479,
                    3985,
                    3989,
                    3992,
                    3994,
                    925,
                    1949,
                    2462,
                    1440,
                    3997,
                    4000,
                    4001,
                    4007,
                    4009,
                    4010,
                    1963,
                    1452,
                    2484,
                    1464,
                    957,
                    3854,
                    1476,
                    1477,
                    1478,
                    1479,
                    1991,
                    1992,
                    3017,
                    1996,
                    973,
                    1998,
                    3532,
                    2000,
                    3535,
                    3536,
                    1491,
                    3537,
                    2005,
                    472,
                    3545,
                    474,
                    986,
                    476,
                    3546,
                    1503,
                    480,
                    2018,
                    2019,
                    3043,
                    3044,
                    999,
                    2547,
                    1524,
                    3572,
                    1014,
                    2039,
                    3576,
                    2044
                ],
                "x.device_type": [
                    279
                ],
                "explicitly_on_cpu": [
                    291,
                    293
                ],
                "_is_current_explicit_device": [
                    291
                ],
                "gpus_available": [
                    292,
                    293
                ],
                "_get_available_gpus": [
                    292
                ],
                "tf.convert_to_tensor": [
                    308
                ],
                "dtype": [
                    896,
                    515,
                    4099,
                    517,
                    390,
                    391,
                    902,
                    765,
                    2437,
                    4100,
                    4103,
                    3470,
                    4239,
                    402,
                    894,
                    790,
                    428,
                    429,
                    430,
                    815,
                    308,
                    699,
                    700,
                    701,
                    957,
                    4029,
                    704,
                    4030,
                    4034,
                    4052,
                    4053,
                    857,
                    858,
                    731,
                    732,
                    733,
                    859,
                    4057,
                    736,
                    865,
                    3424,
                    4072,
                    2153,
                    2154,
                    4073,
                    4076,
                    2413,
                    4077,
                    4078,
                    3447,
                    762,
                    763,
                    764,
                    509,
                    510,
                    895
                ],
                "tensor": [
                    354,
                    355,
                    2660,
                    357,
                    2629,
                    331,
                    2615,
                    2620,
                    2653,
                    2654,
                    2623
                ],
                "tf.SparseTensor": [
                    4147,
                    331,
                    396
                ],
                "is_sparse": [
                    354,
                    2669,
                    1933,
                    1082,
                    2654
                ],
                "tf.sparse_tensor_to_dense": [
                    355
                ],
                "name_scope": [
                    360
                ],
                "tf.name_scope": [
                    360
                ],
                "floatx": [
                    700,
                    4100,
                    1343,
                    391,
                    1383,
                    4073,
                    429,
                    4030,
                    4053,
                    858,
                    763,
                    732,
                    510,
                    895
                ],
                "sparse_coo": [
                    2657,
                    2658,
                    2659,
                    393,
                    394,
                    395,
                    397,
                    398,
                    399,
                    2655
                ],
                "value.tocoo": [
                    393,
                    2655
                ],
                "indices": [
                    2336,
                    2656,
                    2659,
                    394,
                    1228,
                    396,
                    4143,
                    4145,
                    4147
                ],
                "np.concatenate": [
                    2656,
                    394
                ],
                "np": [
                    899,
                    2437,
                    4102,
                    394,
                    395,
                    403,
                    925,
                    2084,
                    2089,
                    1580,
                    3375,
                    4032,
                    2628,
                    1477,
                    1993,
                    2633,
                    4055,
                    862,
                    2656,
                    2657,
                    2658,
                    4075,
                    2413
                ],
                "np.expand_dims": [
                    2657,
                    394,
                    395,
                    2658
                ],
                "sparse_coo.row": [
                    2657,
                    394
                ],
                "sparse_coo.col": [
                    2658,
                    395
                ],
                "sparse_coo.data": [
                    2659,
                    397
                ],
                "sparse_coo.shape": [
                    2659,
                    398,
                    399
                ],
                "v._keras_shape": [
                    404,
                    406,
                    399
                ],
                "v._uses_learning_phase": [
                    400,
                    407
                ],
                "tf.Variable": [
                    402
                ],
                "tf.as_dtype": [
                    896,
                    2629,
                    2438,
                    701,
                    2634,
                    2414,
                    402,
                    859,
                    764,
                    733
                ],
                "name": [
                    704,
                    736,
                    865,
                    515,
                    517,
                    902,
                    2536,
                    734,
                    430,
                    815,
                    4239,
                    4271,
                    402,
                    790,
                    828,
                    765,
                    702,
                    4255
                ],
                "np.ndarray": [
                    403
                ],
                "value.shape": [
                    2444,
                    2419,
                    404
                ],
                "int_shape": [
                    3974,
                    1991,
                    1063,
                    4297,
                    1070,
                    406,
                    4347,
                    925,
                    2462
                ],
                "v.constraint": [
                    410
                ],
                "constraint": [
                    410,
                    412
                ],
                "v._constraint": [
                    412
                ],
                "tf.constant": [
                    2149,
                    1993,
                    2091,
                    2893,
                    430,
                    1806,
                    1810
                ],
                "shape": [
                    864,
                    513,
                    4033,
                    515,
                    517,
                    518,
                    901,
                    4103,
                    4076,
                    734,
                    430,
                    4077,
                    4078,
                    2197,
                    4056,
                    1949,
                    702,
                    511
                ],
                "is_tensor": [
                    472,
                    2618,
                    2678,
                    2670
                ],
                "tf_ops._TensorLike": [
                    480
                ],
                "tf_ops": [
                    480,
                    2586
                ],
                "tf_ops.is_dense_tensor_like": [
                    480
                ],
                "ndim": [
                    512,
                    513,
                    1159,
                    1927,
                    3975,
                    3977,
                    3978,
                    1166,
                    1167,
                    3985,
                    1178,
                    4001,
                    1061,
                    1837,
                    1076,
                    1846,
                    3005,
                    2115,
                    1875,
                    3028,
                    1755,
                    1887,
                    1889,
                    2787,
                    2788,
                    1893,
                    1897,
                    2793,
                    2799,
                    1142,
                    1143
                ],
                "_": [
                    513,
                    2883,
                    1899,
                    2072,
                    4348
                ],
                "sparse": [
                    514
                ],
                "tf.sparse_placeholder": [
                    515
                ],
                "tf.placeholder": [
                    2419,
                    2443,
                    517
                ],
                "x._keras_shape": [
                    518,
                    591
                ],
                "x._uses_learning_phase": [
                    3086,
                    519
                ],
                "x.op.type": [
                    533
                ],
                "x.op": [
                    533
                ],
                "tf.shape": [
                    1153,
                    1156,
                    3845,
                    2842,
                    4123,
                    2082,
                    3621,
                    1063,
                    2855,
                    1070,
                    566,
                    2882,
                    1992,
                    3285,
                    3037,
                    3039,
                    1759,
                    2934,
                    2937
                ],
                "as_list": [
                    3524,
                    2096,
                    593,
                    2066,
                    703,
                    735
                ],
                "x.get_shape": [
                    2084,
                    619,
                    1808,
                    593,
                    2066,
                    2096,
                    1812
                ],
                "dims": [
                    619,
                    620,
                    621
                ],
                "_dims": [
                    619
                ],
                "x.dtype.base_dtype.name": [
                    652
                ],
                "x.dtype.base_dtype": [
                    1476,
                    1477,
                    1382,
                    652,
                    1581,
                    1582,
                    3341,
                    3342,
                    3131,
                    1342
                ],
                "x.dtype": [
                    1476,
                    1477,
                    1382,
                    2438,
                    652,
                    1581,
                    1582,
                    1807,
                    2414,
                    3341,
                    3342,
                    1811,
                    2584,
                    2585,
                    3131,
                    1342
                ],
                "to_dense": [
                    1936,
                    673
                ],
                "tf_dtype": [
                    864,
                    896,
                    901,
                    2438,
                    701,
                    765,
                    2443,
                    702,
                    2414,
                    2419,
                    859,
                    764,
                    733,
                    734
                ],
                "tf.zeros": [
                    4078,
                    702
                ],
                "v.get_shape": [
                    735,
                    703
                ],
                "variable": [
                    704,
                    736,
                    865,
                    902,
                    765
                ],
                "tf.ones": [
                    4077,
                    734
                ],
                "tf.eye": [
                    765
                ],
                "size": [
                    2372,
                    765
                ],
                "tf.zeros_like": [
                    790
                ],
                "tf.ones_like": [
                    3041,
                    815
                ],
                "tf.identity": [
                    2547,
                    828
                ],
                "seed": [
                    897,
                    899,
                    901,
                    4101,
                    4102,
                    4103,
                    3374,
                    3375,
                    3378,
                    4031,
                    4032,
                    4034,
                    4054,
                    4055,
                    4057,
                    860,
                    862,
                    864,
                    4074,
                    4075,
                    4076
                ],
                "np.random.randint": [
                    4032,
                    899,
                    4102,
                    4075,
                    3375,
                    4055,
                    862
                ],
                "np.random": [
                    4032,
                    899,
                    4102,
                    4075,
                    3375,
                    4055,
                    862
                ],
                "tf.random_uniform_initializer": [
                    863
                ],
                "low": [
                    864
                ],
                "high": [
                    864
                ],
                "tf.random_normal_initializer": [
                    900
                ],
                "mean": [
                    1888,
                    1729,
                    1762,
                    1731,
                    1892,
                    901,
                    1734,
                    4033,
                    1896,
                    4103,
                    1904,
                    1780,
                    1911,
                    1752,
                    1887
                ],
                "scale": [
                    901
                ],
                "np.prod": [
                    925
                ],
                "tf.cast": [
                    3426,
                    4131,
                    1413,
                    1383,
                    3449,
                    2798,
                    3472,
                    1398,
                    2585,
                    3004,
                    957,
                    1343
                ],
                "tf.assign": [
                    2531,
                    973
                ],
                "new_x": [
                    973
                ],
                "tf.assign_add": [
                    986
                ],
                "increment": [
                    986
                ],
                "tf.assign_sub": [
                    999
                ],
                "decrement": [
                    999
                ],
                "moving_averages.assign_moving_average": [
                    1013
                ],
                "moving_averages": [
                    1013
                ],
                "momentum": [
                    1014
                ],
                "y": [
                    1153,
                    1159,
                    1161,
                    1674,
                    1163,
                    1167,
                    1171,
                    2582,
                    1687,
                    2584,
                    2585,
                    2586,
                    2588,
                    1061,
                    1070,
                    1076,
                    1079,
                    1083,
                    1596,
                    1085,
                    1609,
                    1622,
                    1635,
                    1899,
                    1648,
                    1909,
                    1143,
                    1661
                ],
                "x_shape": [
                    2082,
                    1062,
                    1065,
                    1067,
                    1068,
                    2092,
                    2093,
                    2096,
                    2097,
                    2066,
                    2098,
                    2068,
                    1078,
                    2070,
                    1081
                ],
                "i": [
                    4353,
                    4354,
                    1063,
                    1064,
                    1065,
                    4301,
                    1070,
                    1071,
                    1072,
                    4302,
                    4303,
                    2937,
                    2938,
                    4351
                ],
                "s": [
                    1063,
                    1067,
                    1070,
                    1074,
                    2072
                ],
                "tf.unstack": [
                    2817,
                    2822,
                    1070,
                    1063
                ],
                "x_shape.append": [
                    1065,
                    1067
                ],
                "y_shape": [
                    1069,
                    1072,
                    1074,
                    1075,
                    1079,
                    1081
                ],
                "y_shape.append": [
                    1072,
                    1074
                ],
                "y_permute_dim": [
                    1076,
                    1077,
                    1079
                ],
                "y_permute_dim.pop": [
                    1077
                ],
                "xt": [
                    1080,
                    1078
                ],
                "tf.reshape": [
                    1153,
                    1156,
                    2183,
                    2197,
                    1949,
                    4136,
                    4140,
                    2093,
                    4143,
                    1078,
                    1079,
                    1080,
                    3278,
                    3285,
                    3038,
                    1762,
                    1763,
                    1767,
                    1771
                ],
                "yt": [
                    1080,
                    1079
                ],
                "tf.transpose": [
                    3584,
                    1163,
                    3858,
                    3731,
                    3476,
                    2981,
                    1963,
                    4140,
                    4143,
                    3634,
                    1079,
                    3770,
                    1215,
                    3905,
                    3267,
                    4171,
                    3545,
                    3807,
                    3430,
                    2794,
                    3690,
                    3951,
                    4207,
                    2801,
                    3453
                ],
                "tf.matmul": [
                    1080,
                    1171,
                    1085
                ],
                "out": [
                    1161,
                    1163,
                    1179,
                    1171,
                    1177,
                    1178,
                    1083,
                    1180,
                    1085,
                    1086
                ],
                "tf.sparse_tensor_dense_matmul": [
                    1083
                ],
                "axes": [
                    1160,
                    1161,
                    1163,
                    1165,
                    1166,
                    1167,
                    2980,
                    2981,
                    2350,
                    2351,
                    2352,
                    2793,
                    2794,
                    2801,
                    1140,
                    1141,
                    1144,
                    1146,
                    1147,
                    1150
                ],
                "x_ndim": [
                    1152,
                    1154,
                    1155,
                    1173,
                    1142,
                    1174,
                    1176,
                    1146,
                    1151
                ],
                "y_ndim": [
                    1152,
                    1154,
                    1155,
                    1173,
                    1174,
                    1143,
                    1146,
                    1151
                ],
                "a": [
                    1563,
                    1147
                ],
                "diff": [
                    1152,
                    1153,
                    1155,
                    1156,
                    1158,
                    1172,
                    1177
                ],
                "tf.concat": [
                    1936,
                    1153,
                    1156,
                    3037
                ],
                "tf.reduce_sum": [
                    1282,
                    1161,
                    1163,
                    3224,
                    3228
                ],
                "tf.multiply": [
                    1161,
                    1163
                ],
                "adj_x": [
                    1169,
                    1171,
                    1166
                ],
                "adj_y": [
                    1170,
                    1171,
                    1167
                ],
                "idx": [
                    1176,
                    1177,
                    1174
                ],
                "tf.squeeze": [
                    1888,
                    1890,
                    1894,
                    3687,
                    4167,
                    4168,
                    1898,
                    2224,
                    1177
                ],
                "expand_dims": [
                    2800,
                    1179
                ],
                "tf.nn.embedding_lookup": [
                    1228
                ],
                "tf.nn": [
                    3725,
                    3854,
                    3989,
                    1814,
                    3356,
                    3997,
                    3230,
                    4009,
                    3630,
                    3378,
                    3764,
                    3126,
                    3894,
                    3128,
                    3898,
                    3391,
                    1729,
                    1731,
                    3575,
                    3146,
                    1228,
                    3279,
                    3407,
                    3536,
                    3799,
                    1752,
                    3164,
                    3681,
                    3940,
                    3176,
                    3944,
                    1899,
                    1773,
                    3311,
                    3188,
                    1911,
                    3324
                ],
                "reference": [
                    1228
                ],
                "tf.reduce_max": [
                    1248
                ],
                "axis": [
                    1282,
                    1414,
                    1926,
                    1929,
                    1931,
                    1934,
                    3214,
                    1936,
                    2321,
                    3217,
                    1299,
                    1427,
                    2068,
                    2070,
                    3224,
                    2073,
                    3228,
                    1312,
                    1440,
                    2081,
                    2211,
                    2090,
                    1325,
                    2224,
                    3257,
                    3260,
                    3391,
                    1344,
                    3264,
                    3265,
                    1347,
                    3266,
                    1365,
                    1877,
                    1879,
                    1755,
                    1756,
                    3164,
                    1759,
                    1248,
                    1384,
                    1265,
                    1524,
                    1399
                ],
                "keepdims": [
                    1248,
                    1282,
                    1348,
                    1414,
                    1384,
                    1265,
                    1299,
                    1524,
                    1365,
                    1399
                ],
                "tf.reduce_min": [
                    1265
                ],
                "tf.reduce_prod": [
                    1299
                ],
                "tf.cumsum": [
                    1312
                ],
                "tf.cumprod": [
                    1325
                ],
                "tf.bool": [
                    4131,
                    1413,
                    1382,
                    3003,
                    2797,
                    2798,
                    1398,
                    2907,
                    1342
                ],
                "m": [
                    1344,
                    1345
                ],
                "tf.reduce_mean": [
                    1344,
                    1346,
                    1384
                ],
                "devs_squared": [
                    1345,
                    1346
                ],
                "tf.square": [
                    1345,
                    1452
                ],
                "tf.sqrt": [
                    1365,
                    1479
                ],
                "var": [
                    1729,
                    1889,
                    1731,
                    1763,
                    1890,
                    1734,
                    1905,
                    1780,
                    1365,
                    1911,
                    1752
                ],
                "tf.reduce_any": [
                    1399
                ],
                "tf.reduce_all": [
                    1414
                ],
                "tf.argmax": [
                    1427
                ],
                "tf.argmin": [
                    1440
                ],
                "tf.abs": [
                    1464
                ],
                "zero": [
                    1476,
                    3341,
                    1478,
                    3343
                ],
                "_to_tensor": [
                    1476,
                    1477,
                    3272,
                    3307,
                    1581,
                    1582,
                    3341,
                    3342,
                    3226,
                    3131
                ],
                "inf": [
                    1477,
                    1478
                ],
                "np.inf": [
                    1580,
                    1477
                ],
                "tf.clip_by_value": [
                    1478,
                    3273,
                    3308,
                    1583,
                    3343,
                    3227
                ],
                "tf.exp": [
                    1491
                ],
                "tf.log": [
                    3274,
                    4171,
                    3309,
                    4207,
                    3228,
                    1503
                ],
                "tf.reduce_logsumexp": [
                    1524
                ],
                "tf.round": [
                    1538
                ],
                "tf.sign": [
                    1550
                ],
                "tf.pow": [
                    1563
                ],
                "max_value": [
                    1577,
                    1578,
                    1579,
                    1580,
                    1582,
                    1583,
                    3130,
                    3131,
                    3132
                ],
                "min_value": [
                    1577,
                    1578,
                    1581,
                    1583
                ],
                "tf.equal": [
                    1596
                ],
                "tf.not_equal": [
                    1609
                ],
                "tf.greater": [
                    1622
                ],
                "tf.greater_equal": [
                    1635
                ],
                "tf.less": [
                    1648
                ],
                "tf.less_equal": [
                    1661
                ],
                "tf.maximum": [
                    1674
                ],
                "tf.minimum": [
                    3132,
                    1687
                ],
                "tf.sin": [
                    1699
                ],
                "tf.cos": [
                    1711
                ],
                "tf.nn.moments": [
                    1752,
                    1729
                ],
                "reduction_axes": [
                    1729,
                    1798,
                    1852,
                    1837,
                    1838,
                    1840,
                    1848,
                    1843,
                    1846,
                    1752,
                    1756
                ],
                "normed": [
                    1731,
                    1780,
                    1773,
                    1734
                ],
                "tf.nn.batch_normalization": [
                    1731,
                    1773,
                    1911
                ],
                "beta": [
                    1891,
                    1732,
                    1892,
                    1893,
                    1894,
                    1768,
                    1771,
                    1902,
                    1839,
                    1911,
                    1809,
                    1810,
                    1843,
                    1847,
                    1817,
                    1851
                ],
                "gamma": [
                    1732,
                    1764,
                    1767,
                    1895,
                    1896,
                    1897,
                    1898,
                    1805,
                    1806,
                    1839,
                    1901,
                    1911,
                    1843,
                    1847,
                    1816,
                    1851
                ],
                "epsilon": [
                    1733,
                    3226,
                    3272,
                    3307,
                    4171,
                    1903,
                    4207,
                    1841,
                    1779,
                    1844,
                    1911,
                    1849,
                    1818,
                    1853
                ],
                "target_shape": [
                    1760,
                    1762,
                    1763,
                    1767,
                    1771,
                    1754,
                    1757,
                    1759
                ],
                "target_shape.append": [
                    1757,
                    1759
                ],
                "tf.stack": [
                    1760,
                    2117,
                    3622,
                    2855,
                    3834,
                    3846,
                    4124,
                    2864,
                    2321,
                    2197,
                    2934,
                    2937,
                    2842,
                    3611,
                    2874,
                    4125
                ],
                "broadcast_mean": [
                    1762,
                    1775
                ],
                "broadcast_var": [
                    1776,
                    1763
                ],
                "broadcast_gamma": [
                    1778,
                    1765,
                    1767
                ],
                "broadcast_beta": [
                    1769,
                    1771,
                    1777
                ],
                "normalization_axis": [
                    1808,
                    1802,
                    1812,
                    1799
                ],
                "tf_data_format": [
                    3456,
                    3718,
                    1800,
                    3720,
                    3849,
                    1803,
                    3856,
                    3473,
                    3729,
                    3730,
                    3857,
                    3478,
                    3479,
                    1819,
                    3613,
                    3615,
                    3625,
                    3884,
                    3757,
                    3886,
                    3759,
                    3632,
                    3633,
                    3768,
                    3769,
                    3896,
                    3900,
                    3904,
                    3535,
                    3664,
                    3665,
                    3666,
                    3668,
                    3797,
                    1878,
                    3542,
                    1880,
                    3544,
                    1882,
                    3670,
                    1884,
                    3805,
                    3806,
                    3930,
                    3932,
                    3427,
                    3685,
                    3942,
                    3432,
                    3433,
                    3689,
                    3583,
                    3946,
                    3950,
                    1906,
                    3572,
                    3450,
                    3836,
                    3581,
                    3838,
                    3455
                ],
                "tf.nn.fused_batch_norm": [
                    1899,
                    1814
                ],
                "_has_nchw_support": [
                    3429,
                    1884,
                    1838,
                    3475,
                    3988,
                    3452
                ],
                "_broadcast_normalize_batch_in_training": [
                    1851,
                    1839
                ],
                "_fused_normalize_batch_in_training": [
                    1842
                ],
                "_regular_normalize_batch_in_training": [
                    1847
                ],
                "zeros_like": [
                    1892,
                    2845
                ],
                "ones_like": [
                    1896
                ],
                "rank": [
                    1928,
                    1929,
                    1927
                ],
                "tensors": [
                    1936,
                    1933,
                    1934,
                    1927
                ],
                "tf.sparse_concat": [
                    1934
                ],
                "pattern": [
                    2240,
                    2306,
                    2308,
                    2117,
                    2118,
                    1963,
                    2299,
                    2262,
                    2266,
                    2267,
                    2239
                ],
                "data_format": [
                    2049,
                    2306,
                    3716,
                    3973,
                    3718,
                    4357,
                    3983,
                    3857,
                    3474,
                    3730,
                    3986,
                    4369,
                    3609,
                    3995,
                    3613,
                    3615,
                    4006,
                    2043,
                    3882,
                    3755,
                    3884,
                    3757,
                    3633,
                    3769,
                    3904,
                    1986,
                    3522,
                    3526,
                    4294,
                    3658,
                    1995,
                    3535,
                    3664,
                    3795,
                    2004,
                    2260,
                    3797,
                    3544,
                    3928,
                    2266,
                    3930,
                    3806,
                    2018,
                    3428,
                    3689,
                    3950,
                    3570,
                    3572,
                    2038,
                    4343,
                    3832,
                    2297,
                    3451,
                    3836,
                    3838,
                    3583
                ],
                "rows": [
                    1987,
                    1989,
                    1992,
                    2007,
                    2010
                ],
                "cols": [
                    1987,
                    1989,
                    1992,
                    2012,
                    2015
                ],
                "original_shape": [
                    1991,
                    2007,
                    2010,
                    2012,
                    2015
                ],
                "new_shape": [
                    4003,
                    4005,
                    4006,
                    4007,
                    1992,
                    1993,
                    3980,
                    1998,
                    3982,
                    2000,
                    3983,
                    3984
                ],
                "np.array": [
                    1993
                ],
                "height_factor": [
                    2040,
                    1993,
                    2010,
                    2045
                ],
                "width_factor": [
                    1993,
                    2041,
                    2046,
                    2015
                ],
                "permute_dimensions": [
                    1996,
                    4370,
                    4372,
                    4309,
                    2005
                ],
                "interpolation": [
                    1997,
                    1999
                ],
                "tf.image.resize_nearest_neighbor": [
                    1998
                ],
                "tf.image": [
                    2000,
                    1998
                ],
                "tf.image.resize_bilinear": [
                    2000
                ],
                "new_height": [
                    2008,
                    2017,
                    2010
                ],
                "new_width": [
                    2017,
                    2013,
                    2015
                ],
                "output_shape": [
                    3840,
                    3841,
                    3842,
                    3843,
                    3844,
                    3845,
                    3846,
                    3854,
                    3610,
                    3611,
                    3616,
                    3617,
                    3618,
                    3619,
                    3620,
                    3621,
                    3622,
                    3630,
                    3276,
                    3278,
                    3282,
                    2017,
                    2018,
                    4346,
                    3833,
                    3834,
                    3839
                ],
                "x.set_shape": [
                    2018
                ],
                "transpose_shape": [
                    2018,
                    2306,
                    4006,
                    3983,
                    2266
                ],
                "output": [
                    2827,
                    2828,
                    2955,
                    2958,
                    3213,
                    4365,
                    4366,
                    4370,
                    2963,
                    3219,
                    4372,
                    4373,
                    3224,
                    2842,
                    3226,
                    3227,
                    2845,
                    3228,
                    3231,
                    2849,
                    2860,
                    2935,
                    2867,
                    2868,
                    2870,
                    3256,
                    3262,
                    3267,
                    2940,
                    3272,
                    3273,
                    3274,
                    3276,
                    3278,
                    4308,
                    3285,
                    4309,
                    3307,
                    3308,
                    2925,
                    3309,
                    2928,
                    3312,
                    2934,
                    2039,
                    2040,
                    2041,
                    2042,
                    2044,
                    2045,
                    2046,
                    2047
                ],
                "repeat_elements": [
                    2039,
                    2040,
                    2041,
                    2044,
                    2045,
                    2046
                ],
                "depth_factor": [
                    2044,
                    2039
                ],
                "splits": [
                    2072,
                    2070
                ],
                "tf.split": [
                    2070
                ],
                "x_rep": [
                    2083,
                    2086,
                    2093,
                    2097,
                    2098,
                    2099,
                    2072,
                    2073
                ],
                "rep": [
                    2072,
                    2090,
                    2085
                ],
                "concatenate": [
                    2073,
                    4306,
                    4364,
                    4143
                ],
                "auxiliary_axis": [
                    2081,
                    2083,
                    2085,
                    2089
                ],
                "tf.expand_dims": [
                    4128,
                    2083,
                    2116,
                    2211,
                    4173,
                    3676,
                    3677,
                    3678
                ],
                "reps": [
                    2084,
                    2085,
                    2086,
                    2089,
                    2090,
                    2091,
                    2092
                ],
                "np.ones": [
                    2084
                ],
                "tf.tile": [
                    2937,
                    3042,
                    2854,
                    2118,
                    2086,
                    4136,
                    4140,
                    2933,
                    2841,
                    2171
                ],
                "np.delete": [
                    2089
                ],
                "x_rep.set_shape": [
                    2097
                ],
                "x_rep._keras_shape": [
                    2098
                ],
                "n": [
                    2169,
                    2170,
                    2171,
                    2117
                ],
                "stop": [
                    2152,
                    2142
                ],
                "start": [
                    2144,
                    2145,
                    2148,
                    2149,
                    2150,
                    2372,
                    2152
                ],
                "tf.cond": [
                    3017,
                    2148
                ],
                "start.dtype": [
                    2149
                ],
                "result": [
                    2152,
                    2154,
                    2155
                ],
                "tf.range": [
                    2152,
                    4128,
                    4140,
                    4136
                ],
                "step": [
                    2152
                ],
                "cast": [
                    2154,
                    3277
                ],
                "prod": [
                    2197
                ],
                "padding": [
                    3719,
                    3848,
                    3727,
                    3855,
                    3494,
                    3495,
                    3496,
                    3497,
                    3624,
                    3499,
                    3500,
                    3885,
                    3758,
                    3631,
                    3766,
                    3895,
                    3899,
                    2238,
                    2239,
                    3525,
                    3533,
                    3534,
                    2257,
                    2258,
                    2259,
                    3541,
                    3669,
                    2263,
                    2264,
                    3798,
                    3931,
                    3804,
                    3683,
                    3941,
                    3945,
                    2293,
                    2294,
                    2295,
                    2296,
                    3574,
                    3580,
                    2301,
                    2302,
                    2303
                ],
                "tf.pad": [
                    2240,
                    2267,
                    2308
                ],
                "normalize_data_format": [
                    3522,
                    3716,
                    3973,
                    4294,
                    3658,
                    3755,
                    3882,
                    3609,
                    3570,
                    3795,
                    2260,
                    3928,
                    4343,
                    3832,
                    2297
                ],
                "tf.one_hot": [
                    2336
                ],
                "num_classes": [
                    2336
                ],
                "tf.reverse": [
                    2352
                ],
                "tf.slice": [
                    2372
                ],
                "x.eval": [
                    2387
                ],
                "ops": [
                    2400,
                    2399
                ],
                "run": [
                    2400,
                    2450,
                    2423
                ],
                "np.asarray": [
                    2633,
                    2628,
                    2413,
                    2437
                ],
                "x.dtype.name.split": [
                    2438,
                    2414
                ],
                "x.dtype.name": [
                    2438,
                    2414
                ],
                "assign_placeholder": [
                    2440,
                    2443,
                    2445,
                    2446,
                    2416,
                    2449,
                    2419,
                    2420,
                    2421,
                    2423
                ],
                "x._assign_placeholder": [
                    2416,
                    2440,
                    2421,
                    2446
                ],
                "assign_op": [
                    2441,
                    2445,
                    2447,
                    2448,
                    2417,
                    2420,
                    2422,
                    2423
                ],
                "x._assign_op": [
                    2417,
                    2441,
                    2422,
                    2447
                ],
                "x.assign": [
                    2420,
                    2445
                ],
                "tuples": [
                    2433,
                    2436
                ],
                "assign_ops": [
                    2448,
                    2434,
                    2450
                ],
                "feed_dict": [
                    2435,
                    2660,
                    2663,
                    2449,
                    2450,
                    2652
                ],
                "assign_ops.append": [
                    2448
                ],
                "tf.Print": [
                    2484
                ],
                "message": [
                    2484
                ],
                "updates": [
                    2528,
                    2521,
                    2514,
                    2705
                ],
                "inputs": [
                    2817,
                    4358,
                    4361,
                    2705,
                    2607,
                    2682,
                    2615,
                    2878,
                    2882,
                    2883,
                    2889,
                    2892,
                    4304,
                    2515,
                    2650,
                    2524,
                    2653,
                    2787,
                    2794,
                    2670,
                    2674,
                    2676,
                    2678,
                    2810
                ],
                "outputs": [
                    2977,
                    2883,
                    2980,
                    2885,
                    2981,
                    2983,
                    2864,
                    2705,
                    2518,
                    2874,
                    2525
                ],
                "self.inputs": [
                    2669,
                    2524,
                    2653,
                    2615
                ],
                "self.outputs": [
                    2592,
                    2661,
                    2665,
                    2647,
                    2525,
                    2526
                ],
                "tf.control_dependencies": [
                    2526
                ],
                "updates_ops": [
                    2535,
                    2531,
                    2534,
                    2527
                ],
                "update": [
                    2528,
                    2529,
                    2530,
                    2534
                ],
                "p": [
                    2530,
                    2531,
                    4076
                ],
                "new_p": [
                    2530,
                    2531
                ],
                "updates_ops.append": [
                    2531,
                    2534
                ],
                "self.updates_op": [
                    2595,
                    2661,
                    2535
                ],
                "tf.group": [
                    2535
                ],
                "self.name": [
                    2536
                ],
                "self.feed_dict": [
                    2630,
                    2631,
                    2633,
                    2538,
                    2578,
                    2579,
                    2652
                ],
                "session_kwargs.pop": [
                    2538,
                    2540
                ],
                "session_kwargs": [
                    2538,
                    2540,
                    2548,
                    2549,
                    2552
                ],
                "self.fetches": [
                    2592,
                    2661,
                    2540,
                    2541,
                    2542,
                    2547
                ],
                "self.session_kwargs": [
                    2664,
                    2548
                ],
                "session_kwargs.keys": [
                    2552
                ],
                "self._callable_fn": [
                    2600,
                    2553,
                    2637,
                    2646
                ],
                "self._feed_arrays": [
                    2601,
                    2554,
                    2638
                ],
                "self._feed_symbols": [
                    2640,
                    2602,
                    2555
                ],
                "self._symbol_vals": [
                    2603,
                    2556,
                    2639
                ],
                "self._session": [
                    2641,
                    2604,
                    2557
                ],
                "callable_opts": [
                    2593,
                    2595,
                    2597,
                    2574,
                    2577,
                    2580,
                    2583
                ],
                "config_pb2.CallableOptions": [
                    2574
                ],
                "config_pb2": [
                    2574
                ],
                "feed_arrays": [
                    2601,
                    2638,
                    2576,
                    2642,
                    2611,
                    2623
                ],
                "callable_opts.feed.append": [
                    2577,
                    2580
                ],
                "callable_opts.feed": [
                    2577,
                    2580
                ],
                "key": [
                    2631,
                    2633,
                    2634,
                    2701,
                    2702,
                    2703,
                    2579,
                    2580
                ],
                "self.feed_dict.keys": [
                    2579,
                    2631
                ],
                "key.name": [
                    2580
                ],
                "feed_symbols": [
                    2602,
                    2640,
                    2643,
                    2613,
                    2582,
                    2620
                ],
                "symbol_vals": [
                    2603,
                    2639,
                    2644,
                    2614,
                    2582,
                    2621
                ],
                "connection": [
                    2589,
                    2590,
                    2583
                ],
                "callable_opts.tensor_connection.add": [
                    2583
                ],
                "callable_opts.tensor_connection": [
                    2583
                ],
                "y.dtype": [
                    2584
                ],
                "from_tensor": [
                    2586,
                    2587,
                    2588,
                    2589
                ],
                "tf_ops._as_graph_element": [
                    2586
                ],
                "connection.from_tensor": [
                    2589
                ],
                "from_tensor.name": [
                    2589
                ],
                "connection.to_tensor": [
                    2590
                ],
                "callable_opts.fetch.append": [
                    2593
                ],
                "callable_opts.fetch": [
                    2593
                ],
                "callable_opts.target.append": [
                    2595
                ],
                "callable_opts.target": [
                    2595
                ],
                "self.updates_op.name": [
                    2595
                ],
                "callable_fn": [
                    2600,
                    2597
                ],
                "session._make_callable_from_options": [
                    2597
                ],
                "array_vals": [
                    2632,
                    2627,
                    2612,
                    2646
                ],
                "feed_symbols.append": [
                    2620
                ],
                "symbol_vals.append": [
                    2621
                ],
                "feed_arrays.append": [
                    2623
                ],
                "array_vals.append": [
                    2632,
                    2627
                ],
                "as_numpy_dtype": [
                    2634,
                    2629
                ],
                "tensor.dtype": [
                    2629
                ],
                "key.dtype": [
                    2634
                ],
                "self._make_callable": [
                    2642
                ],
                "fetched": [
                    2646,
                    2647
                ],
                "self.feed_dict.copy": [
                    2652
                ],
                "fetches": [
                    2661,
                    2663
                ],
                "updated": [
                    2665,
                    2663
                ],
                "self._legacy_call": [
                    2674,
                    2682
                ],
                "self._call": [
                    2676
                ],
                "kwargs": [
                    2705,
                    2700,
                    2701
                ],
                "has_arg": [
                    2702
                ],
                "tf.Session.run": [
                    2702
                ],
                "Function.__init__": [
                    2702
                ],
                "Function": [
                    2705,
                    2702
                ],
                "msg": [
                    2704,
                    2703
                ],
                "tf.gradients": [
                    2718
                ],
                "loss": [
                    2718
                ],
                "tf.stop_gradient": [
                    2733,
                    2735
                ],
                "inputs.get_shape": [
                    2810,
                    2787
                ],
                "mask": [
                    2821,
                    2822,
                    2796,
                    2797,
                    2798,
                    2799,
                    2800,
                    2801,
                    2895,
                    2904,
                    2910
                ],
                "mask.dtype": [
                    2797
                ],
                "mask.get_shape": [
                    2799
                ],
                "constants": [
                    2883,
                    2827,
                    2957,
                    2927,
                    2867,
                    2803,
                    2804
                ],
                "uses_learning_phase": [
                    2982,
                    2829,
                    3085,
                    2960,
                    2930,
                    2869,
                    2807,
                    3067,
                    3069
                ],
                "unroll": [
                    2809
                ],
                "states": [
                    2880,
                    2852,
                    2859,
                    2827,
                    2861,
                    2926,
                    2935,
                    2896,
                    2956,
                    2961,
                    2867,
                    2931,
                    2871,
                    2969,
                    2938,
                    2813
                ],
                "initial_states": [
                    2880,
                    2883,
                    2813
                ],
                "successive_states": [
                    2861,
                    2863,
                    2871,
                    2873,
                    2814
                ],
                "successive_outputs": [
                    2860,
                    2862,
                    2864,
                    2815,
                    2870,
                    2872,
                    2874,
                    2844,
                    2847
                ],
                "input_list": [
                    2817,
                    2826,
                    2819,
                    2866
                ],
                "go_backwards": [
                    2818,
                    2877,
                    2903,
                    2823
                ],
                "input_list.reverse": [
                    2819
                ],
                "mask_list": [
                    2824,
                    2826,
                    2822
                ],
                "mask_list.reverse": [
                    2824
                ],
                "inp": [
                    2867,
                    2826,
                    2827,
                    2866
                ],
                "mask_t": [
                    2937,
                    2854,
                    2826,
                    2924,
                    2933,
                    2841
                ],
                "new_states": [
                    2937,
                    2852,
                    2983,
                    2827,
                    2955,
                    2925,
                    2863,
                    2961,
                    2931,
                    2964,
                    2936,
                    2873,
                    2938,
                    2941,
                    2975
                ],
                "step_function": [
                    2883,
                    2827,
                    2955,
                    2925,
                    2867
                ],
                "tiled_mask_t": [
                    2849,
                    2854,
                    2856,
                    2933,
                    2935,
                    2841
                ],
                "prev_output": [
                    2849,
                    2845,
                    2847
                ],
                "tf.where": [
                    2849,
                    3041,
                    3043,
                    2856,
                    4076,
                    3150,
                    2935,
                    2937
                ],
                "return_states": [
                    2856,
                    2859,
                    2851
                ],
                "state": [
                    2852,
                    2858,
                    2961,
                    2962,
                    2931,
                    2932
                ],
                "new_state": [
                    2852,
                    2855,
                    2857,
                    2961,
                    2962,
                    2931,
                    2932
                ],
                "return_states.append": [
                    2856
                ],
                "successive_outputs.append": [
                    2860,
                    2870
                ],
                "successive_states.append": [
                    2861,
                    2871
                ],
                "last_output": [
                    2978,
                    2982,
                    2983,
                    2862,
                    2872
                ],
                "reverse": [
                    2904,
                    4141,
                    2878
                ],
                "time_steps": [
                    2882,
                    2886,
                    2890,
                    2967,
                    2908
                ],
                "output_ta": [
                    2977,
                    2978,
                    2884,
                    2969,
                    2974
                ],
                "tensor_array_ops.TensorArray": [
                    2888,
                    2906,
                    2884
                ],
                "tensor_array_ops": [
                    2888,
                    2906,
                    2884
                ],
                "outputs.dtype": [
                    2885
                ],
                "input_ta": [
                    2888,
                    2954,
                    2923,
                    2892
                ],
                "inputs.dtype": [
                    2889
                ],
                "input_ta.unstack": [
                    2892
                ],
                "time": [
                    2954,
                    2923,
                    2924,
                    2893,
                    2963,
                    2964,
                    2967,
                    2969,
                    2940,
                    2941
                ],
                "mask_ta": [
                    2906,
                    2924,
                    2910
                ],
                "mask_ta.unstack": [
                    2910
                ],
                "current_input": [
                    4129,
                    2954,
                    2923,
                    2955,
                    2925
                ],
                "input_ta.read": [
                    2954,
                    2923
                ],
                "mask_ta.read": [
                    2924
                ],
                "new_state.set_shape": [
                    2962,
                    2932
                ],
                "state.get_shape": [
                    2962,
                    2932
                ],
                "output_ta_t": [
                    2964,
                    2963,
                    2940,
                    2941
                ],
                "output_ta_t.write": [
                    2963,
                    2940
                ],
                "final_outputs": [
                    2974,
                    2973,
                    2966,
                    2975
                ],
                "control_flow_ops.while_loop": [
                    2966
                ],
                "control_flow_ops": [
                    2966
                ],
                "_step": [
                    2968
                ],
                "input_length": [
                    4168,
                    4175,
                    4208,
                    4213,
                    4217,
                    2972
                ],
                "last_time": [
                    2978,
                    2973
                ],
                "output_ta.stack": [
                    2977
                ],
                "output_ta.read": [
                    2978
                ],
                "outputs.get_shape": [
                    2980
                ],
                "last_output._uses_learning_phase": [
                    2982
                ],
                "condition.dtype": [
                    3003
                ],
                "condition": [
                    3042,
                    3043,
                    3017,
                    3005,
                    3003,
                    3004,
                    3037,
                    3038
                ],
                "cond_ndim": [
                    3029,
                    3033,
                    3035,
                    3036,
                    3005,
                    3006
                ],
                "then_expression": [
                    3009,
                    3011,
                    3043,
                    3024,
                    3025,
                    3028,
                    3039,
                    3007
                ],
                "then_expression_fn": [
                    3018,
                    3011
                ],
                "else_expression": [
                    3043,
                    3012,
                    3014,
                    3016,
                    3026,
                    3027
                ],
                "else_expression_fn": [
                    3016,
                    3019
                ],
                "expr_ndim": [
                    3034,
                    3036,
                    3028,
                    3029
                ],
                "ndim_diff": [
                    3036,
                    3037
                ],
                "cond_shape": [
                    3040,
                    3037,
                    3038
                ],
                "expr_shape": [
                    3040,
                    3041,
                    3039
                ],
                "shape_diff": [
                    3040,
                    3041
                ],
                "tile_shape": [
                    3041,
                    3042
                ],
                "training": [
                    3107,
                    3077,
                    3084,
                    3065,
                    3066,
                    3071
                ],
                "learning_phase": [
                    3066
                ],
                "alt": [
                    3107,
                    3078,
                    3079,
                    3081,
                    3084
                ],
                "switch": [
                    3084
                ],
                "in_train_phase": [
                    3107
                ],
                "alpha": [
                    3150,
                    3147,
                    3125,
                    3126
                ],
                "tf.nn.leaky_relu": [
                    3126
                ],
                "tf.nn.relu": [
                    3128
                ],
                "res": [
                    3146,
                    3148,
                    3150,
                    3279,
                    3285,
                    3287
                ],
                "tf.nn.elu": [
                    3146
                ],
                "tf.nn.softmax": [
                    3164
                ],
                "tf.nn.softplus": [
                    3176
                ],
                "tf.nn.softsign": [
                    3188
                ],
                "output_dimensions": [
                    3264,
                    3265,
                    3213,
                    3214,
                    3256,
                    3257
                ],
                "output.get_shape": [
                    3276,
                    3213,
                    3219,
                    3256,
                    3262
                ],
                "from_logits": [
                    3305,
                    3222,
                    3271
                ],
                "_epsilon": [
                    3272,
                    3273,
                    3307,
                    3308,
                    3226,
                    3227
                ],
                "output.dtype.base_dtype": [
                    3272,
                    3226,
                    3307
                ],
                "output.dtype": [
                    3272,
                    3226,
                    3307
                ],
                "target": [
                    3228,
                    3277,
                    3230,
                    3311
                ],
                "tf.nn.softmax_cross_entropy_with_logits": [
                    3230
                ],
                "permutation": [
                    3265,
                    3266,
                    3267
                ],
                "targets": [
                    3280,
                    3277,
                    3407
                ],
                "flatten": [
                    3277
                ],
                "logits": [
                    3281,
                    3278
                ],
                "tf.nn.sparse_softmax_cross_entropy_with_logits": [
                    3279
                ],
                "tf.nn.sigmoid_cross_entropy_with_logits": [
                    3311
                ],
                "tf.nn.sigmoid": [
                    3324
                ],
                "one": [
                    3342,
                    3343
                ],
                "tf.nn.tanh": [
                    3356
                ],
                "retain_prob": [
                    3378,
                    3373
                ],
                "level": [
                    3373
                ],
                "tf.nn.dropout": [
                    3378
                ],
                "noise_shape": [
                    3378
                ],
                "tf.nn.l2_normalize": [
                    3391
                ],
                "tf.nn.in_top_k": [
                    3407
                ],
                "predictions": [
                    3407
                ],
                "k": [
                    3407
                ],
                "StrictVersion": [
                    3448,
                    3425,
                    3471
                ],
                "tf.__version__.split": [
                    3448,
                    3425,
                    3471
                ],
                "tf.__version__": [
                    3448,
                    3425,
                    3471
                ],
                "kernel_shape": [
                    3524,
                    4297,
                    4298,
                    3531,
                    4347,
                    4348
                ],
                "kernel.get_shape": [
                    3524
                ],
                "kernel": [
                    3524,
                    4297,
                    3577,
                    3630,
                    3854,
                    4365,
                    3538,
                    4308,
                    3801,
                    4347
                ],
                "left_pad": [
                    3531,
                    3532
                ],
                "dilation_rate": [
                    3684,
                    3531,
                    3661,
                    3662,
                    3728,
                    3539,
                    3767,
                    3802,
                    3578,
                    3679
                ],
                "temporal_padding": [
                    3532
                ],
                "_preprocess_padding": [
                    3719,
                    3624,
                    3848,
                    3885,
                    3534,
                    3758,
                    3669,
                    3574,
                    3798,
                    3931
                ],
                "_preprocess_conv1d_input": [
                    3664,
                    3535
                ],
                "tf.nn.convolution": [
                    3536,
                    3799,
                    3575
                ],
                "strides": [
                    3721,
                    3850,
                    3723,
                    3852,
                    3726,
                    3854,
                    3626,
                    3628,
                    3630,
                    3887,
                    3760,
                    3762,
                    3890,
                    3765,
                    3894,
                    3898,
                    4296,
                    3659,
                    3660,
                    3540,
                    3672,
                    3675,
                    3803,
                    3933,
                    3936,
                    3682,
                    3940,
                    3944,
                    4345,
                    3579
                ],
                "_preprocess_conv2d_input": [
                    3718,
                    3884,
                    3757,
                    3572,
                    3613
                ],
                "tf.nn.conv2d_transpose": [
                    3630
                ],
                "spatial_start_dim": [
                    3674,
                    3676,
                    3687,
                    3671
                ],
                "depthwise_kernel": [
                    3681,
                    3764,
                    3677,
                    3725
                ],
                "pointwise_kernel": [
                    3681,
                    3725,
                    3678
                ],
                "tf.nn.separable_conv2d": [
                    3681,
                    3725
                ],
                "tf.nn.depthwise_conv2d": [
                    3764
                ],
                "_preprocess_conv3d_input": [
                    3930,
                    3836,
                    3797
                ],
                "tf.nn.conv3d_transpose": [
                    3854
                ],
                "pool_size": [
                    3937,
                    3940,
                    3944,
                    3888,
                    3891,
                    3894,
                    3898,
                    3934
                ],
                "pool_mode": [
                    3939,
                    3943,
                    3948,
                    3893,
                    3897,
                    3902
                ],
                "tf.nn.max_pool": [
                    3894
                ],
                "tf.nn.avg_pool": [
                    3898
                ],
                "tf.nn.max_pool3d": [
                    3940
                ],
                "tf.nn.avg_pool3d": [
                    3944
                ],
                "bias_shape": [
                    4000,
                    4002,
                    4003,
                    4005,
                    3974,
                    3975,
                    3977,
                    3979,
                    3980,
                    3982,
                    3987,
                    3992,
                    3994,
                    3996
                ],
                "bias": [
                    4000,
                    3974,
                    4007,
                    4009,
                    3984,
                    3989,
                    3992,
                    3994,
                    3997
                ],
                "reshape": [
                    4000,
                    4358,
                    4007,
                    4361,
                    4366,
                    3984,
                    4304,
                    3992,
                    3994
                ],
                "tf.nn.bias_add": [
                    4009,
                    3989,
                    3997
                ],
                "tf.random_normal": [
                    4033
                ],
                "stddev": [
                    4033,
                    4103
                ],
                "tf.random_uniform": [
                    4056,
                    4076
                ],
                "minval": [
                    4056
                ],
                "maxval": [
                    4056
                ],
                "tf.truncated_normal": [
                    4103
                ],
                "label_shape": [
                    4128,
                    4131,
                    4136,
                    4137,
                    4140,
                    4141,
                    4147,
                    4123,
                    4124,
                    4125
                ],
                "labels": [
                    4145,
                    4123
                ],
                "num_batches_tns": [
                    4136,
                    4124
                ],
                "max_num_labels_tns": [
                    4129,
                    4141,
                    4125
                ],
                "tf.fill": [
                    4128,
                    4131
                ],
                "init": [
                    4131,
                    4133
                ],
                "dense_mask": [
                    4142,
                    4138,
                    4132,
                    4134
                ],
                "functional_ops.scan": [
                    4132
                ],
                "functional_ops": [
                    4132
                ],
                "range_less_than": [
                    4132
                ],
                "label_lengths": [
                    4132
                ],
                "label_array": [
                    4136,
                    4138
                ],
                "label_ind": [
                    4138,
                    4143
                ],
                "tf.boolean_mask": [
                    4138,
                    4142
                ],
                "batch_array": [
                    4140,
                    4142
                ],
                "batch_ind": [
                    4142,
                    4143
                ],
                "vals_sparse": [
                    4145,
                    4147
                ],
                "tf.gather_nd": [
                    4145
                ],
                "tf.to_int64": [
                    4147
                ],
                "label_length": [
                    4169,
                    4167
                ],
                "tf.to_int32": [
                    4168,
                    4169,
                    4208,
                    4167
                ],
                "sparse_labels": [
                    4169,
                    4174
                ],
                "ctc_label_dense_to_sparse": [
                    4169
                ],
                "y_true": [
                    4169
                ],
                "y_pred": [
                    4171,
                    4173,
                    4207,
                    4212,
                    4216
                ],
                "ctc.ctc_loss": [
                    4173
                ],
                "ctc": [
                    4211,
                    4173,
                    4215
                ],
                "greedy": [
                    4210
                ],
                "decoded": [
                    4211,
                    4221,
                    4215
                ],
                "log_prob": [
                    4211,
                    4222,
                    4215
                ],
                "ctc.ctc_greedy_decoder": [
                    4211
                ],
                "ctc.ctc_beam_search_decoder": [
                    4215
                ],
                "beam_width": [
                    4217
                ],
                "top_paths": [
                    4218
                ],
                "decoded_dense": [
                    4220,
                    4222
                ],
                "tf.sparse_to_dense": [
                    4220
                ],
                "st.indices": [
                    4220
                ],
                "st": [
                    4220,
                    4221
                ],
                "st.dense_shape": [
                    4220
                ],
                "st.values": [
                    4220
                ],
                "tf.map_fn": [
                    4239
                ],
                "fn": [
                    4255,
                    4271,
                    4239
                ],
                "elems": [
                    4255,
                    4271,
                    4239
                ],
                "tf.foldl": [
                    4255
                ],
                "initializer": [
                    4271,
                    4255
                ],
                "tf.foldr": [
                    4271
                ],
                "stride": [
                    4296,
                    4302,
                    4303
                ],
                "output_length": [
                    4298,
                    4301
                ],
                "feature_dim": [
                    4359,
                    4298,
                    4362,
                    4305,
                    4348
                ],
                "filters": [
                    4298,
                    4348,
                    4367
                ],
                "xs": [
                    4358,
                    4361,
                    4300,
                    4364,
                    4304,
                    4306,
                    4350
                ],
                "slice_length": [
                    4304,
                    4302
                ],
                "kernel_size": [
                    4354,
                    4356,
                    4303
                ],
                "xs.append": [
                    4304,
                    4361,
                    4358
                ],
                "x_aggregate": [
                    4306,
                    4308,
                    4364,
                    4365
                ],
                "batch_dot": [
                    4308,
                    4365
                ],
                "stride_row": [
                    4345,
                    4354,
                    4353
                ],
                "stride_col": [
                    4345,
                    4355,
                    4356
                ],
                "output_row": [
                    4346,
                    4367,
                    4351
                ],
                "output_col": [
                    4352,
                    4346,
                    4367
                ],
                "j": [
                    4352,
                    4355,
                    4356
                ],
                "slice_row": [
                    4353,
                    4361,
                    4358
                ],
                "slice_col": [
                    4361,
                    4355,
                    4358
                ]
            }
        },
        "/Volumes/SSD2T/bgp_envs_non_pandas/repos/keras_20/keras/backend/theano_backend.py": {
            "buggy_functions": [
                {
                    "function_name": "conv2d_transpose",
                    "function_code": "def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),\n                     padding='valid', data_format=None):\n    \"\"\"2D deconvolution (transposed convolution).\n\n    # Arguments\n        kernel: kernel tensor.\n        output_shape: desired dimensions of output.\n        strides: strides tuple.\n        padding: string, \"same\" or \"valid\".\n        data_format: \"channels_last\" or \"channels_first\".\n            Whether to use Theano or TensorFlow data format\n        in inputs/kernels/outputs.\n\n    # Raises\n        ValueError: if using an even kernel size with padding 'same'.\n    \"\"\"\n    flip_filters = False\n    data_format = normalize_data_format(data_format)\n\n    if data_format == 'channels_last':\n        output_shape = (output_shape[0],\n                        output_shape[3],\n                        output_shape[1],\n                        output_shape[2])\n\n    kernel_shape = int_shape(kernel)\n    if kernel_shape is None:\n        kernel_shape = kernel.eval().shape  # in case of a shared variable\n\n    if padding == 'same' and kernel_shape[0] % 2 == 0:\n        raise ValueError('In `Conv2DTranspose`, with padding mode `same`, '\n                         'even kernel sizes are not supported with Theano. '\n                         'You can set `kernel_size` to an odd number.')\n\n    kernel_shape = _preprocess_conv2d_filter_shape(kernel_shape, data_format)\n\n    x = _preprocess_conv2d_input(x, data_format)\n    kernel = _preprocess_conv2d_kernel(kernel, data_format)\n\n    th_padding = _preprocess_padding(padding)\n    op = T.nnet.abstract_conv.AbstractConv2d_gradInputs(imshp=None,\n                                                        kshp=kernel_shape,\n                                                        subsample=strides,\n                                                        border_mode=th_padding,\n                                                        filter_flip=not flip_filters)\n    conv_out = op(kernel, x, output_shape[2:])\n    conv_out = _postprocess_conv2d_output(conv_out, x, padding,\n                                          kernel_shape, strides, data_format)\n    return conv_out\n",
                    "decorators": [],
                    "docstring": "2D deconvolution (transposed convolution).\n\n# Arguments\n    kernel: kernel tensor.\n    output_shape: desired dimensions of output.\n    strides: strides tuple.\n    padding: string, \"same\" or \"valid\".\n    data_format: \"channels_last\" or \"channels_first\".\n        Whether to use Theano or TensorFlow data format\n    in inputs/kernels/outputs.\n\n# Raises\n    ValueError: if using an even kernel size with padding 'same'.",
                    "start_line": 2136,
                    "end_line": 2184,
                    "variables": {
                        "flip_filters": [
                            2152,
                            2180
                        ],
                        "data_format": [
                            2183,
                            2153,
                            2155,
                            2170,
                            2172,
                            2173
                        ],
                        "normalize_data_format": [
                            2153
                        ],
                        "output_shape": [
                            2181,
                            2156,
                            2157,
                            2158,
                            2159
                        ],
                        "kernel_shape": [
                            2177,
                            2183,
                            2161,
                            2162,
                            2163,
                            2165,
                            2170
                        ],
                        "int_shape": [
                            2161
                        ],
                        "kernel": [
                            2161,
                            2163,
                            2173,
                            2181
                        ],
                        "shape": [
                            2163
                        ],
                        "kernel.eval": [
                            2163
                        ],
                        "padding": [
                            2165,
                            2182,
                            2175
                        ],
                        "ValueError": [
                            2166
                        ],
                        "_preprocess_conv2d_filter_shape": [
                            2170
                        ],
                        "x": [
                            2172,
                            2181,
                            2182
                        ],
                        "_preprocess_conv2d_input": [
                            2172
                        ],
                        "_preprocess_conv2d_kernel": [
                            2173
                        ],
                        "th_padding": [
                            2179,
                            2175
                        ],
                        "_preprocess_padding": [
                            2175
                        ],
                        "op": [
                            2176,
                            2181
                        ],
                        "T.nnet.abstract_conv.AbstractConv2d_gradInputs": [
                            2176
                        ],
                        "T.nnet.abstract_conv": [
                            2176
                        ],
                        "T.nnet": [
                            2176
                        ],
                        "T": [
                            2176
                        ],
                        "strides": [
                            2178,
                            2183
                        ],
                        "conv_out": [
                            2184,
                            2181,
                            2182
                        ],
                        "_postprocess_conv2d_output": [
                            2182
                        ]
                    },
                    "filtered_variables": {
                        "flip_filters": [
                            2152,
                            2180
                        ],
                        "data_format": [
                            2183,
                            2153,
                            2155,
                            2170,
                            2172,
                            2173
                        ],
                        "normalize_data_format": [
                            2153
                        ],
                        "output_shape": [
                            2181,
                            2156,
                            2157,
                            2158,
                            2159
                        ],
                        "kernel_shape": [
                            2177,
                            2183,
                            2161,
                            2162,
                            2163,
                            2165,
                            2170
                        ],
                        "int_shape": [
                            2161
                        ],
                        "kernel": [
                            2161,
                            2163,
                            2173,
                            2181
                        ],
                        "shape": [
                            2163
                        ],
                        "kernel.eval": [
                            2163
                        ],
                        "padding": [
                            2165,
                            2182,
                            2175
                        ],
                        "_preprocess_conv2d_filter_shape": [
                            2170
                        ],
                        "x": [
                            2172,
                            2181,
                            2182
                        ],
                        "_preprocess_conv2d_input": [
                            2172
                        ],
                        "_preprocess_conv2d_kernel": [
                            2173
                        ],
                        "th_padding": [
                            2179,
                            2175
                        ],
                        "_preprocess_padding": [
                            2175
                        ],
                        "op": [
                            2176,
                            2181
                        ],
                        "T.nnet.abstract_conv.AbstractConv2d_gradInputs": [
                            2176
                        ],
                        "T.nnet.abstract_conv": [
                            2176
                        ],
                        "T.nnet": [
                            2176
                        ],
                        "T": [
                            2176
                        ],
                        "strides": [
                            2178,
                            2183
                        ],
                        "conv_out": [
                            2184,
                            2181,
                            2182
                        ],
                        "_postprocess_conv2d_output": [
                            2182
                        ]
                    },
                    "diff_line_number": 2137,
                    "class_data": null,
                    "variable_values": [
                        [
                            {},
                            {}
                        ]
                    ],
                    "angelic_variable_values": [
                        [
                            {},
                            {}
                        ]
                    ]
                }
            ],
            "inscope_functions": [
                "def learning_phase():\n    # False = test, True = train\n    return _LEARNING_PHASE",
                "def set_learning_phase(value):\n    global _LEARNING_PHASE\n    if value not in {0, 1}:\n        raise ValueError('Expected learning phase to be '\n                         '0 or 1.')\n    _LEARNING_PHASE = value",
                "def get_uid(prefix=''):\n    \"\"\"Provides a unique UID given a string prefix.\n\n    # Arguments\n        prefix: string.\n\n    # Returns\n        An integer.\n\n    # Example\n    ```python\n        >>> keras.backend.get_uid('dense')\n        1\n        >>> keras.backend.get_uid('dense')\n        2\n    ```\n\n    \"\"\"\n    _UID_PREFIXES[prefix] += 1\n    return _UID_PREFIXES[prefix]",
                "def reset_uids():\n    global _UID_PREFIXES\n    _UID_PREFIXES = defaultdict(int)",
                "def _assert_sparse_module():\n    if not th_sparse_module:\n        raise ImportError(\"Failed to import theano.sparse\\n\"\n                          \"You probably need to pip install nose-parameterized\")",
                "def is_sparse(tensor):\n    return th_sparse_module and isinstance(tensor.type, th_sparse_module.SparseType)",
                "def to_dense(tensor):\n    if is_sparse(tensor):\n        return th_sparse_module.dense_from_sparse(tensor)\n    else:\n        return tensor",
                "def _is_explicit_shape(shape):\n    if hasattr(shape, '__iter__'):\n        for x in shape:\n            if x is not None:\n                if not isinstance(x, int):\n                    return False\n        return True\n    return False",
                "@contextmanager\ndef name_scope(name):\n    global NAME_SCOPE_STACK\n    NAME_SCOPE_STACK.append(name)\n    yield\n    NAME_SCOPE_STACK.pop()",
                "def _prepare_name(name, default):\n    prefix = '/'.join(NAME_SCOPE_STACK)\n    if name is None:\n        return prefix + '/' + default\n    return prefix + '/' + name",
                "def variable(value, dtype=None, name=None, constraint=None):\n    \"\"\"Instantiates a variable and returns it.\n\n    # Arguments\n        value: Numpy array, initial value of the tensor.\n        dtype: Tensor type.\n        name: Optional name string for the tensor.\n        constraint: Optional projection function to be\n            applied to the variable after an optimizer update.\n\n    # Returns\n        A variable instance (with Keras metadata included).\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    if hasattr(value, 'tocoo'):\n        _assert_sparse_module()\n        variable = th_sparse_module.as_sparse_variable(\n            value, name=_prepare_name(name, 'variable'))\n    else:\n        if isinstance(value, (theano.tensor.TensorVariable,\n                              theano.tensor.sharedvar.TensorSharedVariable,\n                              theano.tensor.TensorConstant)):\n            # Support for RandomStreams().normal(), .uniform().\n            value = value.eval()\n        value = np.asarray(value, dtype=dtype)\n        variable = theano.shared(value=value,\n                                 name=_prepare_name(name, 'variable'),\n                                 strict=False)\n    variable._keras_shape = value.shape\n    variable._uses_learning_phase = False\n    variable.constraint = constraint\n    return variable",
                "def constant(value, dtype=None, shape=None, name=None):\n    if dtype is None:\n        dtype = floatx()\n    if shape is None:\n        shape = ()\n    np_value = value * np.ones(shape)\n    const = T.constant(np_value,\n                       dtype=dtype,\n                       name=_prepare_name(name, 'constant'))\n    const._keras_shape = shape\n    const._uses_learning_phase = False\n    return const",
                "def is_keras_tensor(x):\n    \"\"\"Returns whether `x` is a Keras tensor.\n\n    A \"Keras tensor\" is a tensor that was returned by a Keras layer,\n    (`Layer` class) or by `Input`.\n\n    # Arguments\n        x: A candidate tensor.\n\n    # Returns\n        A boolean: Whether the argument is a Keras tensor.\n\n    # Raises\n        ValueError: In case `x` is not a symbolic tensor.\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> from keras.layers import Input, Dense\n        >>> np_var = numpy.array([1, 2])\n        >>> K.is_keras_tensor(np_var) # A numpy array is not a symbolic tensor.\n        ValueError\n        >>> k_var = tf.placeholder('float32', shape=(1,1))\n        >>> K.is_keras_tensor(k_var) # A variable indirectly created outside of keras is not a Keras tensor.\n        False\n        >>> keras_var = K.variable(np_var)\n        >>> K.is_keras_tensor(keras_var)  # A variable created with the keras backend is not a Keras tensor.\n        False\n        >>> keras_placeholder = K.placeholder(shape=(2, 4, 5))\n        >>> K.is_keras_tensor(keras_placeholder)  # A placeholder is not a Keras tensor.\n        False\n        >>> keras_input = Input([10])\n        >>> K.is_keras_tensor(keras_input) # An Input is a Keras tensor.\n        True\n        >>> keras_layer_output = Dense(10)(keras_input)\n        >>> K.is_keras_tensor(keras_layer_output) # Any Keras layer output is a Keras tensor.\n        True\n    ```\n    \"\"\"\n    if not is_tensor(x):\n        raise ValueError('Unexpectedly found an instance of type `' +\n                         str(type(x)) + '`. '\n                         'Expected a symbolic tensor instance.')\n    return hasattr(x, '_keras_history')",
                "def is_tensor(x):\n    return isinstance(x, (T.TensorVariable,\n                          T.sharedvar.TensorSharedVariable))",
                "def placeholder(shape=None, ndim=None, dtype=None, sparse=False, name=None):\n    \"\"\"Instantiate an input data placeholder variable.\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    if shape is None and ndim is None:\n        raise ValueError('Specify either a shape or ndim value.')\n    if shape is not None:\n        ndim = len(shape)\n    else:\n        shape = tuple([None for _ in range(ndim)])\n\n    name = _prepare_name(name, 'placeholder')\n    broadcast = (False,) * ndim\n    if sparse:\n        _assert_sparse_module()\n        x = th_sparse_module.csr_matrix(name=name, dtype=dtype)\n    else:\n        x = T.TensorType(dtype, broadcast)(name)\n    x._keras_shape = shape\n    x._uses_learning_phase = False\n    x._theano_placeholder = True\n    return x",
                "def is_placeholder(x):\n    \"\"\"Returns whether `x` is a placeholder.\n\n    # Arguments\n        x: A candidate placeholder.\n\n    # Returns\n        Boolean.\n    \"\"\"\n    return hasattr(x, '_theano_placeholder') and x._theano_placeholder",
                "def shape(x):\n    \"\"\"Returns the shape of a tensor.\n\n    Warning: type returned will be different for\n    Theano backend (Theano tensor type) and TF backend (TF TensorShape).\n    \"\"\"\n    return x.shape",
                "def int_shape(x):\n    \"\"\"Returns the shape of a Keras tensor or a Keras variable as a tuple of\n    integers or None entries.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tuple of integers (or None entries).\n    \"\"\"\n    if hasattr(x, '_keras_shape'):\n        return x._keras_shape\n    else:\n        return None",
                "def ndim(x):\n    return x.ndim",
                "def dtype(x):\n    return x.dtype",
                "def eval(x):\n    \"\"\"Returns the value of a tensor.\n    \"\"\"\n    return to_dense(x).eval()",
                "def zeros(shape, dtype=None, name=None):\n    \"\"\"Instantiates an all-zeros variable.\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    return variable(np.zeros(shape), dtype, name)",
                "def ones(shape, dtype=None, name=None):\n    \"\"\"Instantiates an all-ones variable.\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    return variable(np.ones(shape), dtype, name)",
                "def eye(size, dtype=None, name=None):\n    \"\"\"Instantiates an identity matrix.\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    return variable(np.eye(size), dtype, name)",
                "def ones_like(x, dtype=None, name=None):\n    return T.ones_like(x, dtype=dtype)",
                "def zeros_like(x, dtype=None, name=None):\n    return T.zeros_like(x, dtype=dtype)",
                "def identity(x, name=None):\n    \"\"\"Returns a tensor with the same content as the input tensor.\n\n    # Arguments\n        x: The input tensor.\n        name: String, name for the variable to create.\n\n    # Returns\n        A tensor of the same shape, type and content.\n    \"\"\"\n    return x.copy(name=name)",
                "def random_uniform_variable(shape, low, high, dtype=None, name=None):\n    return variable(np.random.uniform(low=low, high=high, size=shape),\n                    dtype=dtype, name=name)",
                "def random_normal_variable(shape, mean, scale, dtype=None, name=None):\n    return variable(np.random.normal(loc=0.0, scale=scale, size=shape),\n                    dtype=dtype, name=name)",
                "def count_params(x):\n    \"\"\"Returns the number of scalars in a tensor.\n\n    Return: numpy integer.\n    \"\"\"\n    # We don't want those compilation to show up in Theano profiler.\n    f = theano.function([], x.shape, profile=False)\n    return np.prod(f())",
                "def cast(x, dtype):\n    return T.cast(x, dtype)",
                "def update(x, new_x):\n    return (x, new_x)",
                "def update_add(x, increment):\n    return (x, x + increment)",
                "def update_sub(x, decrement):\n    return (x, x - decrement)",
                "def moving_average_update(variable, value, momentum):\n    return (variable, variable * momentum + value * (1. - momentum))",
                "def dot(x, y):\n    if is_sparse(x):\n        out = th_sparse_module.basic.structured_dot(x, y)\n    else:\n        out = T.dot(x, y)\n    if hasattr(x, '_keras_shape') and hasattr(y, '_keras_shape'):\n        x_shape = list(x._keras_shape)\n        y_shape = list(y._keras_shape)\n        if len(x_shape) > 0:\n            x_shape.pop()\n        if len(y_shape) == 1:\n            y_shape.pop()\n        elif len(y_shape) > 1:\n            y_shape.pop(-2)\n        out._keras_shape = tuple(x_shape + y_shape)\n    return out",
                "def batch_dot(x, y, axes=None):\n    \"\"\"Batchwise dot product.\n\n    batch_dot results in a tensor with less dimensions than the input.\n    If the number of dimensions is reduced to 1, we use `expand_dims` to\n    make sure that ndim is at least 2.\n\n    # Arguments\n        x, y: tensors with ndim >= 2\n        axes: list (or single) int with target dimensions\n\n    # Returns\n        A tensor with shape equal to the concatenation of x's shape\n        (less the dimension that was summed over) and y's shape\n        (less the batch dimension and the dimension that was summed over).\n        If the final rank is 1, we reshape it to (batch_size, 1).\n\n    # Examples\n        Assume x = [[1, 2], [3, 4]]   and y = [[5, 6], [7, 8]]\n        batch_dot(x, y, axes=1) = [[17, 53]] which is the main diagonal\n        of x.dot(y.T), although we never have to calculate the off-diagonal\n        elements.\n\n        Shape inference:\n        Let x's shape be (100, 20) and y's shape be (100, 30, 20).\n        If dot_axes is (1, 2), to find the output shape of resultant tensor,\n            loop through each dimension in x's shape and y's shape:\n        x.shape[0] : 100 : append to output shape\n        x.shape[1] : 20 : do not append to output shape,\n            dimension 1 of x has been summed over. (dot_axes[0] = 1)\n        y.shape[0] : 100 : do not append to output shape,\n            always ignore first dimension of y\n        y.shape[1] : 30 : append to output shape\n        y.shape[2] : 20 : do not append to output shape,\n            dimension 2 of y has been summed over. (dot_axes[1] = 2)\n\n        output_shape = (100, 30)\n    \"\"\"\n    if isinstance(axes, int):\n        axes = (axes, axes)\n    if axes is None:\n        # behaves like tf.batch_matmul as default\n        axes = [x.ndim - 1, y.ndim - 2]\n    if py_any([isinstance(a, (list, tuple)) for a in axes]):\n        raise ValueError('Multiple target dimensions are not supported. ' +\n                         'Expected: None, int, (int, int), ' +\n                         'Provided: ' + str(axes))\n    if isinstance(axes, tuple):\n        axes = list(axes)\n\n    # workaround because theano doesn't accept axes\n    # which contains the batch axis (0)\n    if axes[0] == 0:\n        x = transpose(x)\n        axes[0] = x.ndim - 1\n    if axes[1] == 0:\n        y = transpose(y)\n        axes[1] = y.ndim - 1\n\n    out = T.batched_tensordot(x, y, axes=axes)\n    if ndim(out) == 1:\n        out = expand_dims(out, 1)\n\n    if hasattr(x, '_keras_shape') and hasattr(y, '_keras_shape'):\n        shape = []\n        for axis in range(len(x._keras_shape)):\n            if axis != axes[0]:\n                shape.append(x._keras_shape[axis])\n        for axis in range(1, len(y._keras_shape)):\n            if axis != axes[1]:\n                shape.append(y._keras_shape[axis])\n        if len(shape) == 1:\n            shape.append(1)     # Expand dims if ndim == 1\n        out._keras_shape = tuple(shape)\n    return out",
                "def transpose(x):\n    y = T.transpose(x)\n    if hasattr(x, '_keras_shape'):\n        y._keras_shape = tuple(reversed(x._keras_shape))\n    return y",
                "def gather(reference, indices):\n    \"\"\"Retrieves the elements of indices `indices` in the tensor `reference`.\n\n    # Arguments\n        reference: A tensor.\n        indices: An integer tensor of indices.\n\n    # Returns\n        A tensor of same type as `reference`.\n    \"\"\"\n    y = reference[indices]\n    if hasattr(reference, '_keras_shape') and hasattr(indices, '_keras_shape'):\n        y._keras_shape = indices._keras_shape + reference._keras_shape[1:]\n    return y",
                "def max(x, axis=None, keepdims=False):\n    return T.max(x, axis=axis, keepdims=keepdims)",
                "def min(x, axis=None, keepdims=False):\n    return T.min(x, axis=axis, keepdims=keepdims)",
                "def sum(x, axis=None, keepdims=False):\n    \"\"\"Sum of the values in a tensor, alongside the specified axis.\n    \"\"\"\n    return T.sum(x, axis=axis, keepdims=keepdims)",
                "def prod(x, axis=None, keepdims=False):\n    \"\"\"Multiply the values in a tensor, alongside the specified axis.\n    \"\"\"\n    return T.prod(x, axis=axis, keepdims=keepdims)",
                "def cumsum(x, axis=0):\n    \"\"\"Cumulative sum of the values in a tensor, alongside the specified axis.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer, the axis to compute the sum.\n\n    # Returns\n        A tensor of the cumulative sum of values of `x` along `axis`.\n    \"\"\"\n    return T.extra_ops.cumsum(x, axis=axis)",
                "def cumprod(x, axis=0):\n    \"\"\"Cumulative product of the values in a tensor, alongside the specified axis.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer, the axis to compute the product.\n\n    # Returns\n        A tensor of the cumulative product of values of `x` along `axis`.\n    \"\"\"\n    return T.extra_ops.cumprod(x, axis=axis)",
                "def mean(x, axis=None, keepdims=False):\n    \"\"\"Mean of a tensor, alongside the specified axis.\n    \"\"\"\n    dtype = None\n    # bool is available since theano v0.9dev\n    if 'int' in x.dtype or x.dtype == 'bool':\n        dtype = floatx()\n    return T.mean(x, axis=axis, keepdims=keepdims, dtype=dtype)",
                "def std(x, axis=None, keepdims=False):\n    return T.std(x, axis=axis, keepdims=keepdims)",
                "def var(x, axis=None, keepdims=False):\n    return T.var(x, axis=axis, keepdims=keepdims)",
                "def any(x, axis=None, keepdims=False):\n    \"\"\"Bitwise reduction (logical OR).\n    \"\"\"\n    y = T.any(x, axis=axis, keepdims=keepdims)\n    if hasattr(x, '_keras_shape'):\n        if axis is None:\n            y._keras_shape = (1,) * len(x._keras_shape) if keepdims else (1,)\n        else:\n            if isinstance(axis, int):\n                axis_list = [axis]\n            else:\n                axis_list = list(set(int(a) for a in axis))\n            keras_shape_list = list(x._keras_shape)\n            if keepdims:\n                for a in axis_list:\n                    keras_shape_list[a] = 1\n            else:\n                for a in axis_list[::-1]:\n                    keras_shape_list.pop(a)\n                if not keras_shape_list:\n                    keras_shape_list = (1,)\n            y._keras_shape = tuple(keras_shape_list)\n    return y",
                "def all(x, axis=None, keepdims=False):\n    \"\"\"Bitwise reduction (logical AND).\n    \"\"\"\n    y = T.all(x, axis=axis, keepdims=keepdims)\n    if hasattr(x, '_keras_shape'):\n        if axis is None:\n            y._keras_shape = (1,) * len(x._keras_shape) if keepdims else (1,)\n        else:\n            if isinstance(axis, int):\n                axis_list = [axis]\n            else:\n                axis_list = list(set(int(a) for a in axis))\n            keras_shape_list = list(x._keras_shape)\n            if keepdims:\n                for a in axis_list:\n                    keras_shape_list[a] = 1\n            else:\n                for a in axis_list[::-1]:\n                    keras_shape_list.pop(a)\n                if not keras_shape_list:\n                    keras_shape_list = (1,)\n            y._keras_shape = tuple(keras_shape_list)\n    return y",
                "def argmax(x, axis=-1):\n    return T.argmax(x, axis=axis, keepdims=False)",
                "def argmin(x, axis=-1):\n    return T.argmin(x, axis=axis, keepdims=False)",
                "def square(x):\n    return T.sqr(x)",
                "def abs(x):\n    return T.abs_(x)",
                "def sqrt(x):\n    x = T.clip(x, 0., np.inf)\n    return T.sqrt(x)",
                "def exp(x):\n    return T.exp(x)",
                "def log(x):\n    return T.log(x)",
                "def logsumexp(x, axis=None, keepdims=False):\n    \"\"\"Computes log(sum(exp(elements across dimensions of a tensor))).\n\n    This function is more numerically stable than log(sum(exp(x))).\n    It avoids overflows caused by taking the exp of large inputs and\n    underflows caused by taking the log of small inputs.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer, the axis to reduce over.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1. If `keepdims` is `True`, the reduced dimension is\n            retained with length 1.\n\n    # Returns\n        The reduced tensor.\n    \"\"\"\n    # Theano has a built-in optimization for logsumexp (see https://github.com/Theano/Theano/pull/4736)\n    # so we can just write the expression directly:\n    return T.log(T.sum(T.exp(x), axis=axis, keepdims=keepdims))",
                "def round(x):\n    return T.round(x, mode='half_to_even')",
                "def sign(x):\n    return T.sgn(x)",
                "def pow(x, a):\n    return T.pow(x, a)",
                "def clip(x, min_value, max_value):\n    if max_value is not None and max_value < min_value:\n        max_value = min_value\n    if max_value is None:\n        max_value = np.inf\n    return T.clip(x, min_value, max_value)",
                "def equal(x, y):\n    return T.eq(x, y)",
                "def not_equal(x, y):\n    z = T.neq(x, y)\n    if hasattr(x, '_keras_shape'):\n        z._keras_shape = x._keras_shape\n    elif hasattr(y, '_keras_shape'):\n        z._keras_shape = y._keras_shape\n    return z",
                "def greater(x, y):\n    return T.gt(x, y)",
                "def greater_equal(x, y):\n    return T.ge(x, y)",
                "def less(x, y):\n    return T.lt(x, y)",
                "def less_equal(x, y):\n    return T.le(x, y)",
                "def maximum(x, y):\n    return T.maximum(x, y)",
                "def minimum(x, y):\n    return T.minimum(x, y)",
                "def sin(x):\n    return T.sin(x)",
                "def cos(x):\n    return T.cos(x)",
                "def normalize_batch_in_training(x, gamma, beta,\n                                reduction_axes, epsilon=1e-3):\n    \"\"\"Computes mean and std for batch then apply batch_normalization on batch.\n    \"\"\"\n    # TODO remove this if statement when Theano without\n    # T.nnet.bn.batch_normalization_train is deprecated\n    if not hasattr(T.nnet.bn, 'batch_normalization_train'):\n        return _old_normalize_batch_in_training(x, gamma, beta, reduction_axes, epsilon)\n\n    if gamma is None:\n        if beta is None:\n            gamma = ones_like(x)\n        else:\n            gamma = ones_like(beta)\n    if beta is None:\n        if gamma is None:\n            beta = zeros_like(x)\n        beta = zeros_like(gamma)\n\n    normed, mean, stdinv = T.nnet.bn.batch_normalization_train(\n        x, gamma, beta, reduction_axes, epsilon)\n\n    return normed, mean, T.inv(stdinv ** 2)",
                "def batch_normalization(x, mean, var, beta, gamma, axis=-1, epsilon=1e-3):\n    \"\"\"Apply batch normalization on x given mean, var, beta and gamma.\n    \"\"\"\n    # TODO remove this if statement when Theano without\n    # T.nnet.bn.batch_normalization_test is deprecated\n    if not hasattr(T.nnet.bn, 'batch_normalization_test'):\n        return _old_batch_normalization(x, mean, var, beta, gamma, epsilon)\n\n    if gamma is None:\n        gamma = ones_like(var)\n    if beta is None:\n        beta = zeros_like(mean)\n\n    if mean.ndim == 1:\n        # based on TensorFlow's default: normalize along rightmost dimension\n        reduction_axes = list(range(x.ndim - 1))\n    else:\n        reduction_axes = [i for i in range(x.ndim) if mean.broadcastable[i]]\n\n    return T.nnet.bn.batch_normalization_test(\n        x, gamma, beta, mean, var, reduction_axes, epsilon)",
                "def _old_normalize_batch_in_training(x, gamma, beta, reduction_axes,\n                                     epsilon=1e-3):  # pragma: no cover\n    \"\"\"Computes mean and std for batch then apply batch_normalization on batch.\n    \"\"\"\n    if gamma is None:\n        gamma = ones_like(x)\n    if beta is None:\n        beta = zeros_like(x)\n\n    dev = theano.config.device\n    use_cudnn = ndim(x) < 5 and reduction_axes == [0, 2, 3] and (dev.startswith('cuda') or dev.startswith('gpu'))\n    if use_cudnn:\n        broadcast_beta = beta.dimshuffle('x', 0, 'x', 'x')\n        broadcast_gamma = gamma.dimshuffle('x', 0, 'x', 'x')\n        try:\n            normed, mean, stdinv = theano.sandbox.cuda.dnn.dnn_batch_normalization_train(\n                x, broadcast_gamma, broadcast_beta, 'spatial', epsilon)\n            normed = theano.tensor.as_tensor_variable(normed)\n            mean = theano.tensor.as_tensor_variable(mean)\n            stdinv = theano.tensor.as_tensor_variable(stdinv)\n            var = T.inv(stdinv ** 2)\n            return normed, T.flatten(mean), T.flatten(var)\n        except AttributeError:\n            pass\n\n    var = x.var(reduction_axes)\n    mean = x.mean(reduction_axes)\n\n    target_shape = []\n    for axis in range(ndim(x)):\n        if axis in reduction_axes:\n            target_shape.append(1)\n        else:\n            target_shape.append(x.shape[axis])\n    target_shape = T.stack(*target_shape)\n\n    broadcast_mean = T.reshape(mean, target_shape)\n    broadcast_var = T.reshape(var, target_shape)\n    broadcast_beta = T.reshape(beta, target_shape)\n    broadcast_gamma = T.reshape(gamma, target_shape)\n    normed = batch_normalization(x, broadcast_mean, broadcast_var,\n                                 broadcast_beta, broadcast_gamma,\n                                 epsilon)\n    return normed, mean, var",
                "def _old_batch_normalization(x, mean, var, beta, gamma,\n                             epsilon=1e-3):  # pragma: no cover\n    \"\"\"Apply batch normalization on x given mean, var, beta and gamma.\n    \"\"\"\n    if gamma is None:\n        gamma = ones_like(var)\n    if beta is None:\n        beta = zeros_like(mean)\n\n    if mean.ndim == 1 and x.ndim > 1:\n        # in TensorFlow's batch_normalization, if the parameters are vectors\n        # the batch normalization should be applied along the rightmost axis.\n        # Theano expects the parameters to always have x.ndim dimensions.\n        shuffle_pattern = ['x'] * (x.ndim - 1) + [0]\n        mean = mean.dimshuffle(shuffle_pattern)\n        var = var.dimshuffle(shuffle_pattern)\n        beta = beta.dimshuffle(shuffle_pattern)\n        gamma = gamma.dimshuffle(shuffle_pattern)\n\n    ndim = x.ndim\n    dev = theano.config.device\n    use_cudnn = ndim < 5 and (dev.startswith('cuda') or dev.startswith('gpu'))\n    if use_cudnn:\n        try:\n            axis = mean.broadcastable.index(False)\n            if axis != 1:\n                shuffle_pattern = list(range(ndim))\n                shuffle_pattern[1] = shuffle_pattern[axis]\n                shuffle_pattern[axis] = 1\n                result = theano.sandbox.cuda.dnn.dnn_batch_normalization_test(\n                    x.dimshuffle(shuffle_pattern),\n                    gamma.dimshuffle(shuffle_pattern),\n                    beta.dimshuffle(shuffle_pattern),\n                    mean.dimshuffle(shuffle_pattern),\n                    var.dimshuffle(shuffle_pattern),\n                    'spatial', epsilon).dimshuffle(shuffle_pattern)\n            else:\n                result = theano.sandbox.cuda.dnn.dnn_batch_normalization_test(\n                    x, gamma, beta, mean, var, 'spatial', epsilon)\n            return theano.tensor.as_tensor_variable(result)\n        except AttributeError:\n            pass\n        except ValueError:\n            pass\n    return T.nnet.bn.batch_normalization(x, gamma, beta, mean, sqrt(var + epsilon),\n                                         mode='high_mem')",
                "def concatenate(tensors, axis=-1):\n    if py_all([is_sparse(x) for x in tensors]):\n        axis = axis % ndim(tensors[0])\n        if axis == 0:\n            output = th_sparse_module.basic.vstack(tensors, format='csr')\n        elif axis == 1:\n            output = th_sparse_module.basic.hstack(tensors, format='csr')\n        else:\n            raise ValueError('Invalid concat axis for sparse matrix:', axis)\n    else:\n        output = T.concatenate([to_dense(x) for x in tensors], axis=axis)\n\n    if py_all([hasattr(tensor, '_keras_shape') for tensor in tensors]):\n        input_shapes = [tensor._keras_shape for tensor in tensors]\n        output_shape = list(input_shapes[0])\n        for shape in input_shapes[1:]:\n            if output_shape[axis] is None or shape[axis] is None:\n                output_shape[axis] = None\n                break\n            output_shape[axis] += shape[axis]\n        output._keras_shape = tuple(output_shape)\n\n    return output",
                "def reshape(x, shape):\n    y = T.reshape(x, shape)\n    shape = tuple(x if isinstance(x, int) and x > 0 else None for x in shape)\n    y._keras_shape = shape\n    if hasattr(x, '_uses_learning_phase'):\n        y._uses_learning_phase = x._uses_learning_phase\n    else:\n        y._uses_learning_phase = False\n    return y",
                "def permute_dimensions(x, pattern):\n    \"\"\"Transpose dimensions.\n\n    pattern should be a tuple or list of\n    dimension indices, e.g. [0, 2, 1].\n    \"\"\"\n    pattern = tuple(pattern)\n    y = x.dimshuffle(pattern)\n    if hasattr(x, '_keras_shape'):\n        y._keras_shape = tuple(np.asarray(x._keras_shape)[list(pattern)])\n    return y",
                "def repeat_elements(x, rep, axis):\n    \"\"\"Repeat the elements of a tensor along an axis, like np.repeat.\n\n    If x has shape (s1, s2, s3) and axis=1, the output\n    will have shape (s1, s2 * rep, s3).\n    \"\"\"\n    y = T.repeat(x, rep, axis=axis)\n    if hasattr(x, '_keras_shape'):\n        y._keras_shape = list(x._keras_shape)\n        repeat_dim = x._keras_shape[axis]\n        if repeat_dim is not None:\n                y._keras_shape[axis] = repeat_dim * rep\n        y._keras_shape = tuple(y._keras_shape)\n    return y",
                "def resize_images(x,\n                  height_factor,\n                  width_factor,\n                  data_format,\n                  interpolation='nearest'):\n    \"\"\"Resize the images contained in a 4D tensor of shape\n    - [batch, channels, height, width] (for 'channels_first' data_format)\n    - [batch, height, width, channels] (for 'channels_last' data_format)\n    by a factor of (height_factor, width_factor). Both factors should be\n    positive integers.\n    \"\"\"\n    if data_format == 'channels_first':\n        axis_1 = 2\n        axis_2 = 3\n    elif data_format == 'channels_last':\n        axis_1 = 1\n        axis_2 = 2\n    else:\n        raise ValueError('Invalid data_format:', data_format)\n\n    if interpolation == 'nearest':\n        output = repeat_elements(x, height_factor, axis=axis_1)\n        output = repeat_elements(output, width_factor, axis=axis_2)\n    elif interpolation == 'bilinear':\n        if not (height_factor == width_factor == 2):\n            raise NotImplementedError(\n                'Bilinear upscaling with factors other than (2, 2)'\n                'is not available when using the Theano backend.')\n        if data_format == 'channels_last':\n            output = permute_dimensions(x, [0, 3, 1, 2])\n        else:\n            output = x\n        output = T.nnet.abstract_conv.bilinear_upsampling(output,\n                                                          ratio=height_factor)\n        if data_format == 'channels_last':\n            output = permute_dimensions(output, [0, 2, 3, 1])\n        if hasattr(x, '_keras_shape'):\n            output._keras_shape = list(x._keras_shape)\n            output._keras_shape[axis_1] *= height_factor\n            output._keras_shape[axis_2] *= width_factor\n            output._keras_shape = tuple(output._keras_shape)\n    else:\n        raise ValueError('interpolation should be one of \"nearest\" or \"bilinear\".')\n\n    return output",
                "def resize_volumes(x, depth_factor, height_factor, width_factor, data_format):\n    \"\"\"Resize the volume contained in a 5D tensor of shape\n    - [batch, channels, depth, height, width] (for 'channels_first' data_format)\n    - [batch, depth, height, width, channels] (for 'channels_last' data_format)\n    by a factor of (depth_factor, height_factor, width_factor).\n    Both factors should be positive integers.\n    \"\"\"\n    if data_format == 'channels_first':\n        output = repeat_elements(x, depth_factor, axis=2)\n        output = repeat_elements(output, height_factor, axis=3)\n        output = repeat_elements(output, width_factor, axis=4)\n        return output\n    elif data_format == 'channels_last':\n        output = repeat_elements(x, depth_factor, axis=1)\n        output = repeat_elements(output, height_factor, axis=2)\n        output = repeat_elements(output, width_factor, axis=3)\n        return output\n    else:\n        raise ValueError('Invalid data_format:', data_format)",
                "def repeat(x, n):\n    \"\"\"Repeat a 2D tensor.\n\n    If x has shape (samples, dim) and n=2,\n    the output will have shape (samples, 2, dim).\n    \"\"\"\n    assert x.ndim == 2\n    y = x.dimshuffle((0, 'x', 1))\n    y = T.extra_ops.repeat(y, n, axis=1)\n    if hasattr(x, '_keras_shape'):\n        shape = list(x._keras_shape)\n        shape.insert(1, n)\n        y._keras_shape = tuple(shape)\n\n    return y",
                "def arange(start, stop=None, step=1, dtype='int32'):\n    \"\"\"Creates a 1-D tensor containing a sequence of integers.\n\n    The function arguments use the same convention as\n    Theano's arange: if only one argument is provided,\n    it is in fact the \"stop\" argument.\n\n    The default type of the returned tensor is 'int32' to\n    match TensorFlow's default.\n    \"\"\"\n    return T.arange(start, stop=stop, step=step, dtype=dtype)",
                "def tile(x, n):\n    y = T.tile(x, n)\n    if hasattr(x, '_keras_shape'):\n        if _is_explicit_shape(n):\n            output_shape = x._keras_shape[:-len(n)]\n            for i, j in zip(x._keras_shape, n):\n                if i is None:\n                    output_shape += (None,)\n                else:\n                    output_shape += (i * j,)\n        elif isinstance(n, int):\n            output_shape = x._keras_shape[:-1]\n            if x._keras_shape[-1] is None:\n                output_shape += (None,)\n            else:\n                output_shape += (x._keras_shape[-1] * n,)\n        else:\n            # symbolic n\n            if n.ndim == 0:\n                # n is a scalar\n                output_shape = x._keras_shape[:-1] + (None,)\n            elif hasattr(n, '_keras_shape'):\n                # n is a vector\n                n_size = n._keras_shape[0]\n                output_shape = x._keras_shape[:-n_size] + (None,) * n_size\n            else:\n                output_shape = (None,) * x.ndim\n        y._keras_shape = output_shape\n    return y",
                "def flatten(x):\n    y = T.flatten(x)\n    if hasattr(x, '_keras_shape'):\n        if None in x._keras_shape:\n            y._keras_shape = (None,)\n        else:\n            y._keras_shape = (np.prod(x._keras_shape), )\n    return y",
                "def batch_flatten(x):\n    \"\"\"Turn a n-D tensor into a 2D tensor where\n    the first dimension is conserved.\n    \"\"\"\n    y = T.reshape(x, (x.shape[0], T.prod(x.shape[1:])))\n    if hasattr(x, '_keras_shape'):\n        if None in x._keras_shape[1:]:\n            y._keras_shape = (x._keras_shape[0], None)\n        else:\n            y._keras_shape = (x._keras_shape[0], np.prod(x._keras_shape[1:]))\n    return y",
                "def expand_dims(x, axis=-1):\n    \"\"\"Add a 1-sized dimension at index \"dim\".\n    \"\"\"\n    pattern = [i for i in range(x.type.ndim)]\n    if axis < 0:\n        if x.type.ndim == 0:\n            axis = 0\n        else:\n            axis = axis % x.type.ndim + 1\n    pattern.insert(axis, 'x')\n    y = x.dimshuffle(pattern)\n    if hasattr(x, '_keras_shape'):\n        shape = list(x._keras_shape)\n        shape.insert(axis, 1)\n        y._keras_shape = tuple(shape)\n    return y",
                "def squeeze(x, axis):\n    \"\"\"Remove a 1-dimension from the tensor at index \"axis\".\n    \"\"\"\n    shape = list(x.shape)\n    shape.pop(axis)\n    y = T.reshape(x, tuple(shape))\n    if hasattr(x, '_keras_shape'):\n        kshape = list(x._keras_shape)\n        kshape.pop(axis)\n        y._keras_shape = tuple(kshape)\n    return y",
                "def temporal_padding(x, padding=(1, 1)):\n    \"\"\"Pad the middle dimension of a 3D tensor\n    with \"padding\" zeros left and right.\n\n    Apologies for the inane API, but Theano makes this\n    really hard.\n    \"\"\"\n    assert len(padding) == 2\n    input_shape = x.shape\n    output_shape = (input_shape[0],\n                    input_shape[1] + padding[0] + padding[1],\n                    input_shape[2])\n    output = T.zeros(output_shape)\n    result = T.set_subtensor(output[:, padding[0]:x.shape[1] + padding[0], :], x)\n    if hasattr(x, '_keras_shape'):\n        result._keras_shape = (x._keras_shape[0],\n                               x._keras_shape[1] + py_sum(padding),\n                               x._keras_shape[2])\n    return result",
                "def spatial_2d_padding(x, padding=((1, 1), (1, 1)), data_format=None):\n    \"\"\"Pad the 2nd and 3rd dimensions of a 4D tensor\n    with \"padding[0]\" and \"padding[1]\" (resp.) zeros left and right.\n    \"\"\"\n    assert len(padding) == 2\n    assert len(padding[0]) == 2\n    assert len(padding[1]) == 2\n    top_pad, bottom_pad = padding[0]\n    left_pad, right_pad = padding[1]\n    data_format = normalize_data_format(data_format)\n\n    input_shape = x.shape\n    if data_format == 'channels_first':\n        output_shape = (input_shape[0],\n                        input_shape[1],\n                        input_shape[2] + top_pad + bottom_pad,\n                        input_shape[3] + left_pad + right_pad)\n        output = T.zeros(output_shape)\n        indices = (py_slice(None),\n                   py_slice(None),\n                   py_slice(top_pad, input_shape[2] + top_pad),\n                   py_slice(left_pad, input_shape[3] + left_pad))\n\n    else:\n        output_shape = (input_shape[0],\n                        input_shape[1] + top_pad + bottom_pad,\n                        input_shape[2] + left_pad + right_pad,\n                        input_shape[3])\n        output = T.zeros(output_shape)\n        indices = (py_slice(None),\n                   py_slice(top_pad, input_shape[1] + top_pad),\n                   py_slice(left_pad, input_shape[2] + left_pad),\n                   py_slice(None))\n    y = T.set_subtensor(output[indices], x)\n    if hasattr(x, '_keras_shape'):\n        if data_format == 'channels_first':\n            if x._keras_shape[2] is not None:\n                h = x._keras_shape[2] + top_pad + bottom_pad\n            else:\n                h = None\n            if x._keras_shape[3] is not None:\n                w = x._keras_shape[3] + left_pad + right_pad\n            else:\n                w = None\n            output_keras_shape = (x._keras_shape[0],\n                                  x._keras_shape[1],\n                                  h,\n                                  w)\n        else:\n            if x._keras_shape[1] is not None:\n                h = x._keras_shape[1] + top_pad + bottom_pad\n            else:\n                h = None\n            if x._keras_shape[2] is not None:\n                w = x._keras_shape[2] + left_pad + right_pad\n            else:\n                w = None\n            output_keras_shape = (x._keras_shape[0],\n                                  h,\n                                  w,\n                                  x._keras_shape[3])\n        y._keras_shape = output_keras_shape\n    return y",
                "def spatial_3d_padding(x, padding=((1, 1), (1, 1), (1, 1)), data_format=None):\n    \"\"\"Pad the 2nd, 3rd and 4th dimensions of a 5D tensor\n    with \"padding[0]\", \"padding[1]\" and \"padding[2]\" (resp.) zeros left and right.\n    \"\"\"\n    data_format = normalize_data_format(data_format)\n\n    input_shape = x.shape\n    if data_format == 'channels_first':\n        output_shape = (input_shape[0],\n                        input_shape[1],\n                        input_shape[2] + padding[0][0] + padding[0][1],\n                        input_shape[3] + padding[1][0] + padding[1][1],\n                        input_shape[4] + padding[2][0] + padding[2][1])\n        output = T.zeros(output_shape)\n        indices = (py_slice(None),\n                   py_slice(None),\n                   py_slice(padding[0][0], input_shape[2] + padding[0][0]),\n                   py_slice(padding[1][0], input_shape[3] + padding[1][0]),\n                   py_slice(padding[2][0], input_shape[4] + padding[2][0]))\n\n    else:\n        output_shape = (input_shape[0],\n                        input_shape[1] + padding[0][0] + padding[0][1],\n                        input_shape[2] + padding[1][0] + padding[1][1],\n                        input_shape[3] + padding[2][0] + padding[2][1],\n                        input_shape[4])\n        output = T.zeros(output_shape)\n        indices = (py_slice(None),\n                   py_slice(padding[0][0], input_shape[1] + padding[0][0]),\n                   py_slice(padding[1][0], input_shape[2] + padding[1][0]),\n                   py_slice(padding[2][0], input_shape[3] + padding[2][0]),\n                   py_slice(None))\n    y = T.set_subtensor(output[indices], x)\n    if hasattr(x, '_keras_shape'):\n        if data_format == 'channels_first':\n            if x._keras_shape[2] is not None:\n                h = x._keras_shape[2] + padding[0][0] + padding[0][1]\n            else:\n                h = None\n            if x._keras_shape[3] is not None:\n                w = x._keras_shape[3] + padding[1][0] + padding[1][1]\n            else:\n                w = None\n            if x._keras_shape[4] is not None:\n                d = x._keras_shape[4] + padding[2][0] + padding[2][1]\n            else:\n                d = None\n            output_keras_shape = (x._keras_shape[0],\n                                  x._keras_shape[1],\n                                  h,\n                                  w,\n                                  d)\n        else:\n            if x._keras_shape[1] is not None:\n                h = x._keras_shape[1] + padding[0][0] + padding[0][1]\n            else:\n                h = None\n            if x._keras_shape[2] is not None:\n                w = x._keras_shape[2] + padding[1][0] + padding[1][1]\n            else:\n                w = None\n            if x._keras_shape[3] is not None:\n                d = x._keras_shape[3] + padding[2][0] + padding[2][1]\n            else:\n                d = None\n            output_keras_shape = (x._keras_shape[0],\n                                  h,\n                                  w,\n                                  d,\n                                  x._keras_shape[4])\n        y._keras_shape = output_keras_shape\n    return y",
                "def stack(x, axis=0):\n    return T.stack(x, axis=axis)",
                "def one_hot(indices, num_classes):\n    \"\"\"Input: nD integer tensor of shape (batch_size, dim1, dim2, ... dim(n-1))\n    Output: (n + 1)D one hot representation of the input\n    with shape (batch_size, dim1, dim2, ... dim(n-1), num_classes)\n    \"\"\"\n    input_shape = tuple((indices.shape[i] for i in range(indices.ndim)))\n    indices = T.flatten(indices)\n    oh = T.extra_ops.to_one_hot(indices, num_classes)\n    oh = T.reshape(oh, input_shape + (num_classes,))\n    return oh",
                "def reverse(x, axes):\n    \"\"\"Reverse a tensor along the specified axes\n    \"\"\"\n    if isinstance(axes, int):\n        axes = [axes]\n    slices = [py_slice(None, None, -1) if i in axes else py_slice(None, None, None) for i in range(x.ndim)]\n    return x[slices]",
                "def slice(x, start, size):\n    raise NotImplementedError",
                "def pattern_broadcast(x, broadcastable):\n    return T.patternbroadcast(x, broadcastable)",
                "def get_value(x):\n    if not hasattr(x, 'get_value'):\n        raise TypeError('`get_value` can only be called on a variable. '\n                        'If you have an expression instead, use `eval()`.')\n    return x.get_value()",
                "def batch_get_value(xs):\n    \"\"\"Returns the value of more than one tensor variable,\n    as a list of Numpy arrays.\n    \"\"\"\n    return [get_value(x) for x in xs]",
                "def set_value(x, value):\n    x.set_value(np.asarray(value, dtype=x.dtype))",
                "def batch_set_value(tuples):\n    for x, value in tuples:\n        x.set_value(np.asarray(value, dtype=x.dtype))",
                "def get_variable_shape(x):\n    return x.get_value(borrow=True, return_internal_type=True).shape",
                "def print_tensor(x, message=''):\n    \"\"\"Print the message and the tensor when evaluated and return the same\n    tensor.\n    \"\"\"\n    p_op = Print(message)\n    return p_op(x)",
                "def function(inputs, outputs, updates=[], **kwargs):\n    if len(kwargs) > 0:\n        for key in kwargs.keys():\n            if not has_arg(theano.function, key, True):\n                msg = 'Invalid argument \"%s\" passed to K.function with Theano backend' % key\n                raise ValueError(msg)\n    return Function(inputs, outputs, updates=updates, **kwargs)",
                "def gradients(loss, variables):\n    return T.grad(loss, variables)",
                "def stop_gradient(variables):\n    \"\"\"Returns `variables` but with zero gradient w.r.t. every other variable.\n\n    # Arguments\n        variables: tensor or list of tensors to consider constant with respect\n            to any other variable.\n\n    # Returns\n        A single tensor or a list of tensors (depending on the passed argument)\n            that has constant gradient with respect to any other variable.\n    \"\"\"\n    if isinstance(variables, (list, tuple)):\n        return map(theano.gradient.disconnected_grad, variables)\n    else:\n        return theano.gradient.disconnected_grad(variables)",
                "def rnn(step_function, inputs, initial_states,\n        go_backwards=False, mask=None, constants=None,\n        unroll=False, input_length=None):\n    \"\"\"Iterates over the time dimension of a tensor.\n\n    # Arguments\n        step_function:\n            Parameters:\n                inputs: Tensor with shape (samples, ...) (no time dimension),\n                    representing input for the batch of samples at a certain\n                    time step.\n                states: List of tensors.\n            Returns:\n                outputs: Tensor with shape (samples, ...) (no time dimension),\n                new_states: List of tensors, same length and shapes\n                    as 'states'.\n        inputs: Tensor of temporal data of shape (samples, time, ...)\n            (at least 3D).\n        initial_states: Tensor with shape (samples, ...) (no time dimension),\n            containing the initial values for the states used in\n            the step function.\n        go_backwards: Boolean. If True, do the iteration over the time\n            dimension in reverse order and return the reversed sequence.\n        mask: Binary tensor with shape (samples, time),\n            with a zero for every element that is masked.\n        constants: A list of constant values passed at each step.\n        unroll: Whether to unroll the RNN or to use a symbolic loop\n            (`while_loop` or `scan` depending on backend).\n        input_length: Static number of timesteps in the input.\n            Must be specified if using `unroll`.\n\n    # Returns\n        A tuple (last_output, outputs, new_states).\n\n        last_output: The latest output of the rnn, of shape `(samples, ...)`\n        outputs: Tensor with shape `(samples, time, ...)` where each\n            entry `outputs[s, t]` is the output of the step function\n            at time `t` for sample `s`.\n        new_states: List of tensors, latest states returned by\n            the step function, of shape `(samples, ...)`.\n    \"\"\"\n    ndim = inputs.ndim\n    assert ndim >= 3, 'Input should be at least 3D.'\n\n    if unroll:\n        if input_length is None:\n            raise ValueError('When specifying `unroll=True`, '\n                             'an `input_length` '\n                             'must be provided to `rnn`.')\n\n    axes = [1, 0] + list(range(2, ndim))\n    inputs = inputs.dimshuffle(axes)\n\n    if constants is None:\n        constants = []\n\n    global uses_learning_phase\n    uses_learning_phase = False\n\n    if mask is not None:\n        if mask.ndim == ndim - 1:\n            mask = expand_dims(mask)\n        assert mask.ndim == ndim\n        mask = mask.dimshuffle(axes)\n\n        if unroll:\n            indices = list(range(input_length))\n            if go_backwards:\n                indices = indices[::-1]\n\n            successive_outputs = []\n            successive_states = []\n            states = initial_states\n            for i in indices:\n                output, new_states = step_function(inputs[i], states + constants)\n                if getattr(output, '_uses_learning_phase', False):\n                    uses_learning_phase = True\n\n                if len(successive_outputs) == 0:\n                    prev_output = zeros_like(output)\n                else:\n                    prev_output = successive_outputs[-1]\n\n                output = T.switch(mask[i], output, prev_output)\n                kept_states = []\n                for state, new_state in zip(states, new_states):\n                    kept_states.append(T.switch(mask[i], new_state, state))\n                states = kept_states\n\n                successive_outputs.append(output)\n                successive_states.append(states)\n\n            outputs = T.stack(*successive_outputs)\n            states = []\n            for i in range(len(successive_states[-1])):\n                states.append(T.stack(*[states_at_step[i] for states_at_step in successive_states]))\n        else:\n            # build an all-zero tensor of shape (samples, output_dim)\n            initial_output = step_function(inputs[0], initial_states + constants)[0] * 0\n            # Theano gets confused by broadcasting patterns in the scan op\n            initial_output = T.unbroadcast(initial_output, 0, 1)\n            if len(initial_states) > 0:\n                initial_states[0] = T.unbroadcast(initial_states[0], 0, 1)\n\n            def _step(inputs, mask, output_tm1, *states):\n                outputs, new_states = step_function(inputs, states)\n                if getattr(outputs, '_uses_learning_phase', False):\n                    global uses_learning_phase\n                    uses_learning_phase = True\n                # output previous output if masked.\n                outputs = T.switch(mask, outputs, output_tm1)\n                return_states = []\n                for state, new_state in zip(states, new_states):\n                    return_states.append(T.switch(mask, new_state, state))\n                return [outputs] + return_states\n\n            results, _ = theano.scan(\n                _step,\n                sequences=[inputs, mask],\n                outputs_info=[initial_output] + initial_states,\n                non_sequences=constants,\n                go_backwards=go_backwards)\n\n            # deal with Theano API inconsistency\n            if isinstance(results, list):\n                outputs = results[0]\n                states = results[1:]\n            else:\n                outputs = results\n                states = []\n    else:\n        if unroll:\n            indices = list(range(input_length))\n            if go_backwards:\n                indices = indices[::-1]\n\n            successive_outputs = []\n            successive_states = []\n            states = initial_states\n            for i in indices:\n                outputs, states = step_function(inputs[i], states + constants)\n                if getattr(outputs, '_uses_learning_phase', False):\n                    uses_learning_phase = True\n                successive_outputs.append(outputs)\n                successive_states.append(states)\n            outputs = T.stack(*successive_outputs)\n            states = []\n            for i in range(len(successive_states[-1])):\n                states.append(T.stack(*[states_at_step[i] for states_at_step in successive_states]))\n\n        else:\n            def _step(inputs, *states):\n                outputs, new_states = step_function(inputs, states)\n                if getattr(outputs, '_uses_learning_phase', False):\n                    global uses_learning_phase\n                    uses_learning_phase = True\n                return [outputs] + new_states\n\n            # Theano likes to make shape==1 dimensions\n            # in the initial states (outputs_info) broadcastable\n            if len(initial_states) > 0:\n                initial_states[0] = T.unbroadcast(initial_states[0], 0, 1)\n\n            results, _ = theano.scan(\n                _step,\n                sequences=inputs,\n                outputs_info=[None] + initial_states,\n                non_sequences=constants,\n                go_backwards=go_backwards)\n\n            # deal with Theano API inconsistency\n            if isinstance(results, list):\n                outputs = results[0]\n                states = results[1:]\n            else:\n                outputs = results\n                states = []\n\n    outputs = T.squeeze(outputs)\n    last_output = outputs[-1]\n\n    axes = [1, 0] + list(range(2, outputs.ndim))\n    outputs = outputs.dimshuffle(axes)\n    states = [T.squeeze(state[-1]) for state in states]\n    last_output._uses_learning_phase = uses_learning_phase\n    return last_output, outputs, states",
                "def switch(condition, then_expression, else_expression):\n    \"\"\"Switches between two operations depending on a scalar value.\n\n    Note that both `then_expression` and `else_expression`\n    should be symbolic tensors of the *same shape*.\n\n    # Arguments\n        condition: scalar tensor (`int` or `bool`).\n        then_expression: either a tensor, or a callable that returns a tensor.\n        else_expression: either a tensor, or a callable that returns a tensor.\n\n    # Returns\n        The selected tensor.\n    \"\"\"\n    if callable(then_expression):\n        then_expression = then_expression()\n    if callable(else_expression):\n        else_expression = else_expression()\n    cond_ndim = ndim(condition)\n    expr_ndim = ndim(then_expression)\n    if cond_ndim < expr_ndim:\n        ndim_diff = expr_ndim - cond_ndim\n        for _ in range(ndim_diff):\n            condition = expand_dims(condition)\n    return T.switch(condition, then_expression, else_expression)",
                "def in_train_phase(x, alt, training=None):\n    \"\"\"Selects `x` in train phase, and `alt` otherwise.\n\n    Note that `alt` should have the *same shape* as `x`.\n\n    # Returns\n        Either `x` or `alt` based on the `training` flag.\n        the `training` flag defaults to `K.learning_phase()`.\n    \"\"\"\n    if training is None:\n        training = learning_phase()\n        uses_learning_phase = True\n    else:\n        uses_learning_phase = False\n\n    if training is 1 or training is True:\n        if callable(x):\n            return x()\n        else:\n            return x\n\n    elif training is 0 or training is False:\n        if callable(alt):\n            return alt()\n        else:\n            return alt\n\n    if callable(x):\n        x = x()\n    if callable(alt):\n        alt = alt()\n\n    # else: assume learning phase is a placeholder tensor.\n    x = ifelse(training, x, alt)\n    if uses_learning_phase:\n        x._uses_learning_phase = True\n    return x",
                "def in_test_phase(x, alt, training=None):\n    \"\"\"Selects `x` in test phase, and `alt` otherwise.\n    Note that `alt` should have the *same shape* as `x`.\n\n    # Returns\n        Either `x` or `alt` based on `K.learning_phase`.\n    \"\"\"\n    return in_train_phase(alt, x, training=training)",
                "def _assert_has_capability(module, func):\n    if not hasattr(module, func):\n        raise EnvironmentError(\n            'It looks like like your version of '\n            'Theano is out of date. '\n            'Install the latest version with:\\n'\n            'pip install git+git://github.com/Theano/Theano.git '\n            '--upgrade --no-deps')",
                "def elu(x, alpha=1.0):\n    \"\"\" Exponential linear unit\n\n    # Arguments\n        x: Tensor to compute the activation function for.\n        alpha: scalar\n    \"\"\"\n    _assert_has_capability(T.nnet, 'elu')\n    return T.nnet.elu(x, alpha)",
                "def relu(x, alpha=0., max_value=None):\n    _assert_has_capability(T.nnet, 'relu')\n    x = T.nnet.relu(x, alpha)\n    if max_value is not None:\n        x = T.minimum(x, max_value)\n    return x",
                "def softmax(x, axis=-1):\n    if axis == -1 or axis == x.ndim - 1:\n        return T.nnet.softmax(x)\n    return T.exp(x - x.max()) / T.exp(\n        x - x.max()).sum(axis=axis, keepdims=True)",
                "def softplus(x):\n    return T.nnet.softplus(x)",
                "def softsign(x):\n    return T_softsign(x)",
                "def categorical_crossentropy(target, output, from_logits=False, axis=-1):\n    output_dimensions = list(range(len(int_shape(output))))\n    if axis != -1 and axis not in output_dimensions:\n        raise ValueError(\n            '{}{}{}'.format(\n                'Unexpected channels axis {}. '.format(axis),\n                'Expected to be -1 or one of the axes of `output`, ',\n                'which has {} dimensions.'.format(len(int_shape(output)))))\n    # If the channels are not in the last axis, move them to be there:\n    if axis != -1 and axis != output_dimensions[-1]:\n        permutation = output_dimensions[:axis]\n        permutation += output_dimensions[axis + 1:] + [axis]\n        output = permute_dimensions(output, permutation)\n        target = permute_dimensions(target, permutation)\n    if from_logits:\n        output = T.nnet.softmax(output)\n    else:\n        # scale preds so that the class probas of each sample sum to 1\n        output /= output.sum(axis=-1, keepdims=True)\n    # avoid numerical instability with _EPSILON clipping\n    output = T.clip(output, epsilon(), 1.0 - epsilon())\n    return T.nnet.categorical_crossentropy(output, target)",
                "def sparse_categorical_crossentropy(target, output, from_logits=False, axis=-1):\n    output_dimensions = list(range(len(int_shape(output))))\n    if axis != -1 and axis not in output_dimensions:\n        raise ValueError(\n            '{}{}{}'.format(\n                'Unexpected channels axis {}. '.format(axis),\n                'Expected to be -1 or one of the axes of `output`, ',\n                'which has {} dimensions.'.format(len(int_shape(output)))))\n    # If the channels are not in the last axis, move them to be there:\n    if axis != -1 and axis != output_dimensions[-1]:\n        permutation = output_dimensions[:axis]\n        permutation += output_dimensions[axis + 1:] + [axis]\n        output = permute_dimensions(output, permutation)\n        target = permute_dimensions(target, permutation)\n    target = T.cast(T.flatten(target), 'int32')\n    target = T.extra_ops.to_one_hot(target, nb_class=output.shape[-1])\n    target = reshape(target, shape(output))\n    return categorical_crossentropy(target, output, from_logits, axis=-1)",
                "def binary_crossentropy(target, output, from_logits=False):\n    if from_logits:\n        output = T.nnet.sigmoid(output)\n    # avoid numerical instability with _EPSILON clipping\n    output = T.clip(output, epsilon(), 1.0 - epsilon())\n    return T.nnet.binary_crossentropy(output, target)",
                "def sigmoid(x):\n    return T.nnet.sigmoid(x)",
                "def hard_sigmoid(x):\n    return T.nnet.hard_sigmoid(x)",
                "def tanh(x):\n    return T.tanh(x)",
                "def dropout(x, level, noise_shape=None, seed=None):\n    \"\"\"Sets entries in `x` to zero at random,\n    while scaling the entire tensor.\n\n    # Arguments\n        x: tensor\n        level: fraction of the entries in the tensor\n            that will be set to 0.\n        noise_shape: shape for randomly generated keep/drop flags,\n            must be broadcastable to the shape of `x`\n        seed: random seed to ensure determinism.\n    \"\"\"\n    if level < 0. or level >= 1:\n        raise ValueError('Dropout level must be in interval [0, 1[.')\n    if seed is None:\n        seed = np.random.randint(1, 10e6)\n    if isinstance(noise_shape, list):\n        noise_shape = tuple(noise_shape)\n\n    rng = RandomStreams(seed=seed)\n    retain_prob = 1. - level\n\n    if noise_shape is None:\n        random_tensor = rng.binomial(x.shape, p=retain_prob, dtype=x.dtype)\n    else:\n        random_tensor = rng.binomial(noise_shape, p=retain_prob, dtype=x.dtype)\n        random_tensor = T.patternbroadcast(random_tensor,\n                                           [dim == 1 for dim in noise_shape])\n    x *= random_tensor\n    x /= retain_prob\n    return x",
                "def l2_normalize(x, axis=None):\n    square_sum = T.sum(T.square(x), axis=axis, keepdims=True)\n    norm = T.sqrt(T.maximum(square_sum, epsilon()))\n    return x / norm",
                "def in_top_k(predictions, targets, k):\n    \"\"\"Returns whether the `targets` are in the top `k` `predictions`.\n\n    # Arguments\n        predictions: A tensor of shape `(batch_size, classes)` and type `float32`.\n        targets: A 1D tensor of length `batch_size` and type `int32` or `int64`.\n        k: An `int`, number of top elements to consider.\n\n    # Returns\n        A 1D tensor of length `batch_size` and type `bool`.\n        `output[i]` is `True` if `predictions[i, targets[i]]` is within top-`k`\n        values of `predictions[i]`.\n    \"\"\"\n    # handle k < 1 and k >= predictions.shape[1] cases to match TF behavior\n    if k < 1:\n        # dtype='bool' is only available since Theano 0.9.0\n        try:\n            return T.zeros_like(targets, dtype='bool')\n        except TypeError:\n            return T.zeros_like(targets, dtype='int8')\n\n    if k >= int_shape(predictions)[1]:\n        try:\n            return T.ones_like(targets, dtype='bool')\n        except TypeError:\n            return T.ones_like(targets, dtype='int8')\n\n    predictions_k = T.sort(predictions)[:, -k]\n    targets_values = predictions[T.arange(targets.shape[0]), targets]\n    return T.ge(targets_values, predictions_k)",
                "def _preprocess_conv2d_input(x, data_format):\n    if data_format == 'channels_last':\n        # TF uses the last dimension as channel dimension,\n        # instead of the 2nd one.\n        # TH input shape: (samples, input_depth, rows, cols)\n        # TF input shape: (samples, rows, cols, input_depth)\n        x = x.dimshuffle((0, 3, 1, 2))\n    return x",
                "def _preprocess_conv3d_input(x, data_format):\n    if data_format == 'channels_last':\n        # TF uses the last dimension as channel dimension,\n        # instead of the 2nd one.\n        # TH input shape: (samples, input_depth, rows, cols, slices)\n        # TF input shape: (samples, rows, cols, slices, input_depth)\n        x = x.dimshuffle((0, 4, 1, 2, 3))\n    return x",
                "def _preprocess_conv2d_kernel(kernel, data_format):\n    # As of Keras 2.0.0, all kernels are normalized\n    # on the format `(rows, cols, input_depth, depth)`,\n    # independently of `data_format`.\n    # Theano expects `(depth, input_depth, rows, cols)`.\n    kernel = kernel.dimshuffle((3, 2, 0, 1))\n    return kernel",
                "def _preprocess_conv2d_depthwise_kernel(kernel, kernel_shape, data_format):\n    # As of Keras 2.0.0, all kernels are normalized\n    # on the format `(rows, cols, input_depth, depth)`,\n    # independently of `data_format`.\n    # Theano expects `(input_depth * depth, 1, rows, cols)` for depthwise convolution.\n    kernel = kernel[::-1, ::-1, :, :]\n    kernel = kernel.dimshuffle((2, 3, 0, 1))\n    kernel = reshape(kernel, kernel_shape)\n    return kernel",
                "def _preprocess_conv3d_kernel(kernel, data_format):\n    # As of Keras 2.0.0, all kernels are normalized\n    # on the format `(space, input_depth, depth)`,\n    # independently of `data_format`.\n    # Theano expects `(depth, input_depth, space)`.\n    kernel = kernel.dimshuffle((4, 3, 0, 1, 2))\n    return kernel",
                "def _preprocess_padding(padding):\n    if padding == 'same':\n        th_padding = 'half'\n    elif padding == 'valid':\n        th_padding = 'valid'\n    elif padding == 'full':\n        th_padding = 'full'\n    else:\n        raise ValueError('Border mode not supported:', str(padding))\n    return th_padding",
                "def _preprocess_conv2d_image_shape(image_shape, data_format):\n    # Theano might not accept long type\n    def int_or_none(value):\n        try:\n            return int(value)\n        except TypeError:\n            return None\n    if data_format == 'channels_last':\n        if image_shape:\n            image_shape = transpose_shape(image_shape, 'channels_first',\n                                          spatial_axes=(1, 2))\n    if image_shape is not None:\n        image_shape = tuple(int_or_none(v) for v in image_shape)\n    return image_shape",
                "def _preprocess_conv3d_volume_shape(volume_shape, data_format):\n    # Theano might not accept long type\n    def int_or_none(value):\n        try:\n            return int(value)\n        except TypeError:\n            return None\n    if data_format == 'channels_last':\n        if volume_shape:\n            volume_shape = (volume_shape[0], volume_shape[4],\n                            volume_shape[1], volume_shape[2], volume_shape[3])\n    if volume_shape is not None:\n        volume_shape = tuple(int_or_none(v) for v in volume_shape)\n    return volume_shape",
                "def _preprocess_conv2d_filter_shape(filter_shape, data_format):\n    # Theano might not accept long type\n    def int_or_none(value):\n        try:\n            return int(value)\n        except TypeError:\n            return None\n    if filter_shape:\n        filter_shape = (filter_shape[3], filter_shape[2],\n                        filter_shape[0], filter_shape[1])\n    if filter_shape is not None:\n        filter_shape = tuple(int_or_none(v) for v in filter_shape)\n    return filter_shape",
                "def _preprocess_conv2d_depthwise_filter_shape(filter_shape, data_format):\n    # Theano might not accept long type\n    def int_or_none(value):\n        try:\n            return int(value)\n        except TypeError:\n            return None\n    if filter_shape:\n        filter_shape = (filter_shape[3] * filter_shape[2], 1,\n                        filter_shape[0], filter_shape[1])\n    if filter_shape is not None:\n        filter_shape = tuple(int_or_none(v) for v in filter_shape)\n    return filter_shape",
                "def _preprocess_conv3d_filter_shape(filter_shape, data_format):\n    # Theano might not accept long type\n    def int_or_none(value):\n        try:\n            return int(value)\n        except TypeError:\n            return None\n    if filter_shape:\n        filter_shape = (filter_shape[4], filter_shape[3],\n                        filter_shape[0], filter_shape[1], filter_shape[2])\n    if filter_shape is not None:\n        filter_shape = tuple(int_or_none(v) for v in filter_shape)\n    return filter_shape",
                "def _postprocess_conv2d_output(conv_out, x,\n                               padding, kernel_shape,\n                               strides, data_format):\n    if padding == 'same':\n        if kernel_shape[2] % 2 == 0:\n            conv_out = conv_out[:, :, :(x.shape[2] + strides[0] - 1) // strides[0], :]\n        if kernel_shape[3] % 2 == 0:\n            conv_out = conv_out[:, :, :, :(x.shape[3] + strides[1] - 1) // strides[1]]\n    if data_format == 'channels_last':\n        conv_out = conv_out.dimshuffle((0, 2, 3, 1))\n    return conv_out",
                "def _postprocess_conv3d_output(conv_out, x,\n                               padding, kernel_shape,\n                               strides, data_format):\n    if padding == 'same':\n        if kernel_shape[2] % 2 == 0:\n            conv_out = conv_out[:, :, :(x.shape[2] + strides[0] - 1) // strides[0], :, :]\n        if kernel_shape[3] % 2 == 0:\n            conv_out = conv_out[:, :, :, :(x.shape[3] + strides[1] - 1) // strides[1], :]\n        if kernel_shape[4] % 2 == 0:\n            conv_out = conv_out[:, :, :, :, :(x.shape[4] + strides[2] - 1) // strides[2]]\n    if data_format == 'channels_last':\n        conv_out = conv_out.dimshuffle((0, 2, 3, 4, 1))\n    return conv_out",
                "def conv1d(x, kernel, strides=1, padding='valid',\n           data_format=None, dilation_rate=1):\n    \"\"\"1D convolution.\n\n    # Arguments\n        kernel: kernel tensor.\n        strides: stride integer.\n        padding: string, `\"same\"`, `\"causal\"` or `\"valid\"`.\n        data_format: string, one of \"channels_last\", \"channels_first\"\n        dilation_rate: integer.\n    \"\"\"\n    data_format = normalize_data_format(data_format)\n\n    kernel_shape = int_shape(kernel)\n    if padding == 'causal':\n        # causal (dilated) convolution:\n        if not kernel_shape:\n            raise AttributeError('Causal padding requires kernel._keras_shape set.')\n        left_pad = dilation_rate * (kernel_shape[0] - 1)\n        x = temporal_padding(x, (left_pad, 0))\n        padding = 'valid'\n    shape = int_shape(x)\n    if data_format == 'channels_last':\n        # original shape: (batch, length, input_dim)\n        # add dim to x to have (batch, length, 1, input_dim)\n        x = expand_dims(x, 2)\n        # update x._keras_shape\n        if shape is not None:\n            x._keras_shape = (shape[0], shape[1], 1, shape[2])\n    else:\n        # original shape: (batch, input_dim, length)\n        # add dim to x to have (batch, input_dim, length, 1)\n        x = expand_dims(x, 3)\n        # update x._keras_shape\n        if shape is not None:\n            x._keras_shape = (shape[0], shape[1], shape[2], 1)\n    # update dilation rate, strides\n    dilation_rate = (dilation_rate, 1)\n    strides = (strides, 1)\n    # add dim to kernel (always same format independently of data_format)\n    # i.e. (rows, 1, input_depth, depth)\n    kernel = expand_dims(kernel, 1)\n    output = conv2d(x, kernel,\n                    strides=strides, padding=padding,\n                    data_format=data_format, dilation_rate=dilation_rate)\n    # remove added dim\n    if data_format == 'channels_last':\n        output = squeeze(output, 2)\n    else:\n        output = squeeze(output, 3)\n    return output",
                "def conv2d(x, kernel, strides=(1, 1), padding='valid',\n           data_format=None, dilation_rate=(1, 1)):\n    \"\"\"2D convolution.\n\n    # Arguments\n        kernel: kernel tensor.\n        strides: strides tuple.\n        padding: string, \"same\" or \"valid\".\n        data_format: \"channels_last\" or \"channels_first\".\n            Whether to use Theano or TensorFlow data format\n        in inputs/kernels/outputs.\n    \"\"\"\n    data_format = normalize_data_format(data_format)\n\n    image_shape = _preprocess_conv2d_image_shape(int_shape(x), data_format)\n    kernel_shape = int_shape(kernel)\n    if kernel_shape is None:\n        kernel_shape = kernel.eval().shape  # in case of a shared variable\n    kernel_shape = _preprocess_conv2d_filter_shape(kernel_shape, data_format)\n\n    x = _preprocess_conv2d_input(x, data_format)\n    kernel = _preprocess_conv2d_kernel(kernel, data_format)\n    th_padding = _preprocess_padding(padding)\n\n    conv_out = T.nnet.conv2d(x, kernel,\n                             border_mode=th_padding,\n                             subsample=strides,\n                             input_shape=image_shape,\n                             filter_shape=kernel_shape,\n                             filter_dilation=dilation_rate)\n    conv_out = _postprocess_conv2d_output(conv_out, x, padding,\n                                          kernel_shape, strides, data_format)\n    return conv_out",
                "def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),\n                     padding='valid', data_format=None):\n    \"\"\"2D deconvolution (transposed convolution).\n\n    # Arguments\n        kernel: kernel tensor.\n        output_shape: desired dimensions of output.\n        strides: strides tuple.\n        padding: string, \"same\" or \"valid\".\n        data_format: \"channels_last\" or \"channels_first\".\n            Whether to use Theano or TensorFlow data format\n        in inputs/kernels/outputs.\n\n    # Raises\n        ValueError: if using an even kernel size with padding 'same'.\n    \"\"\"\n    flip_filters = False\n    data_format = normalize_data_format(data_format)\n\n    if data_format == 'channels_last':\n        output_shape = (output_shape[0],\n                        output_shape[3],\n                        output_shape[1],\n                        output_shape[2])\n\n    kernel_shape = int_shape(kernel)\n    if kernel_shape is None:\n        kernel_shape = kernel.eval().shape  # in case of a shared variable\n\n    if padding == 'same' and kernel_shape[0] % 2 == 0:\n        raise ValueError('In `Conv2DTranspose`, with padding mode `same`, '\n                         'even kernel sizes are not supported with Theano. '\n                         'You can set `kernel_size` to an odd number.')\n\n    kernel_shape = _preprocess_conv2d_filter_shape(kernel_shape, data_format)\n\n    x = _preprocess_conv2d_input(x, data_format)\n    kernel = _preprocess_conv2d_kernel(kernel, data_format)\n\n    th_padding = _preprocess_padding(padding)\n    op = T.nnet.abstract_conv.AbstractConv2d_gradInputs(imshp=None,\n                                                        kshp=kernel_shape,\n                                                        subsample=strides,\n                                                        border_mode=th_padding,\n                                                        filter_flip=not flip_filters)\n    conv_out = op(kernel, x, output_shape[2:])\n    conv_out = _postprocess_conv2d_output(conv_out, x, padding,\n                                          kernel_shape, strides, data_format)\n    return conv_out",
                "def separable_conv1d(x, depthwise_kernel, pointwise_kernel, strides=1,\n                     padding='valid', data_format=None, dilation_rate=1):\n    \"\"\"1D convolution with separable filters.\n\n    # Arguments\n        x: input tensor\n        depthwise_kernel: convolution kernel for the depthwise convolution.\n        pointwise_kernel: kernel for the 1x1 convolution.\n        strides: strides integer.\n        padding: string, `\"same\"` or `\"valid\"`.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n        dilation_rate: integer dilation rate.\n\n    # Returns\n        Output tensor.\n\n    # Raises\n        ValueError: if `data_format` is neither `\"channels_last\"` or `\"channels_first\"`.\n    \"\"\"\n    data_format = normalize_data_format(data_format)\n    if isinstance(strides, int):\n        strides = (strides,)\n    if isinstance(dilation_rate, int):\n        dilation_rate = (dilation_rate,)\n\n    if data_format == 'channels_last':\n        spatial_start_dim = 2\n    else:\n        spatial_start_dim = 3\n    x = expand_dims(x, spatial_start_dim)\n    depthwise_kernel = expand_dims(depthwise_kernel, 1)\n    pointwise_kernel = expand_dims(pointwise_kernel, 1)\n    strides = strides + (1,)\n    dilation_rate = dilation_rate + (1,)\n\n    image_shape = _preprocess_conv2d_image_shape(int_shape(x), data_format)\n    depthwise_kernel_shape = int_shape(depthwise_kernel)\n    if depthwise_kernel_shape is None:\n        depthwise_kernel_shape = depthwise_kernel.eval().shape  # in case of a shared variable\n    depthwise_kernel_shape = _preprocess_conv2d_depthwise_filter_shape(depthwise_kernel_shape, data_format)\n    pointwise_kernel_shape = int_shape(pointwise_kernel)\n    if pointwise_kernel_shape is None:\n        pointwise_kernel_shape = pointwise_kernel.eval().shape  # in case of a shared variable\n    pointwise_kernel_shape = _preprocess_conv2d_filter_shape(pointwise_kernel_shape, data_format)\n\n    x = _preprocess_conv2d_input(x, data_format)\n    depthwise_kernel = _preprocess_conv2d_depthwise_kernel(depthwise_kernel, depthwise_kernel_shape, data_format)\n    pointwise_kernel = _preprocess_conv2d_kernel(pointwise_kernel, data_format)\n    th_padding = _preprocess_padding(padding)\n\n    conv_out = T.nnet.conv2d(x, depthwise_kernel,\n                             border_mode=th_padding,\n                             subsample=strides,\n                             input_shape=image_shape,\n                             filter_shape=depthwise_kernel_shape,\n                             filter_dilation=dilation_rate,\n                             num_groups=image_shape[1])\n    conv_out = T.nnet.conv2d(conv_out, pointwise_kernel,\n                             border_mode=th_padding,\n                             subsample=(1, 1),\n                             input_shape=None,\n                             filter_shape=pointwise_kernel_shape,\n                             filter_dilation=dilation_rate)\n    conv_out = _postprocess_conv2d_output(conv_out, x, padding,\n                                          pointwise_kernel_shape,\n                                          strides, data_format)\n    conv_out = squeeze(conv_out, spatial_start_dim)\n    return conv_out",
                "def separable_conv2d(x, depthwise_kernel, pointwise_kernel, strides=(1, 1),\n                     padding='valid', data_format=None, dilation_rate=(1, 1)):\n    \"\"\"2D convolution with separable filters.\n\n    # Arguments\n        x: input tensor\n        depthwise_kernel: convolution kernel for the depthwise convolution.\n        pointwise_kernel: kernel for the 1x1 convolution.\n        strides: strides tuple (length 2).\n        padding: string, `\"same\"` or `\"valid\"`.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n        dilation_rate: tuple of integers,\n            dilation rates for the separable convolution.\n\n    # Returns\n        Output tensor.\n\n    # Raises\n        ValueError: if `data_format` is neither `\"channels_last\"` or `\"channels_first\"`.\n    \"\"\"\n    data_format = normalize_data_format(data_format)\n\n    image_shape = _preprocess_conv2d_image_shape(int_shape(x), data_format)\n    depthwise_kernel_shape = int_shape(depthwise_kernel)\n    if depthwise_kernel_shape is None:\n        depthwise_kernel_shape = depthwise_kernel.eval().shape  # in case of a shared variable\n    depthwise_kernel_shape = _preprocess_conv2d_depthwise_filter_shape(depthwise_kernel_shape, data_format)\n    pointwise_kernel_shape = int_shape(pointwise_kernel)\n    if pointwise_kernel_shape is None:\n        pointwise_kernel_shape = pointwise_kernel.eval().shape  # in case of a shared variable\n    pointwise_kernel_shape = _preprocess_conv2d_filter_shape(pointwise_kernel_shape, data_format)\n\n    x = _preprocess_conv2d_input(x, data_format)\n    depthwise_kernel = _preprocess_conv2d_depthwise_kernel(depthwise_kernel, depthwise_kernel_shape, data_format)\n    pointwise_kernel = _preprocess_conv2d_kernel(pointwise_kernel, data_format)\n    th_padding = _preprocess_padding(padding)\n\n    conv_out = T.nnet.conv2d(x, depthwise_kernel,\n                             border_mode=th_padding,\n                             subsample=strides,\n                             input_shape=image_shape,\n                             filter_shape=depthwise_kernel_shape,\n                             filter_dilation=dilation_rate,\n                             num_groups=image_shape[1])\n    conv_out = T.nnet.conv2d(conv_out, pointwise_kernel,\n                             border_mode=th_padding,\n                             subsample=(1, 1),\n                             input_shape=None,\n                             filter_shape=pointwise_kernel_shape,\n                             filter_dilation=dilation_rate)\n    conv_out = _postprocess_conv2d_output(conv_out, x, padding,\n                                          pointwise_kernel_shape,\n                                          strides, data_format)\n    return conv_out",
                "def depthwise_conv2d(x, depthwise_kernel, strides=(1, 1), padding='valid',\n                     data_format=None, dilation_rate=(1, 1)):\n    \"\"\"2D convolution with separable filters.\n\n    # Arguments\n        x: input tensor\n        depthwise_kernel: convolution kernel for the depthwise convolution.\n        strides: strides tuple (length 2).\n        padding: string, `\"same\"` or `\"valid\"`.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n        dilation_rate: tuple of integers,\n            dilation rates for the separable convolution.\n\n    # Returns\n        Output tensor.\n\n    # Raises\n        ValueError: if `data_format` is neither `\"channels_last\"` or `\"channels_first\"`.\n    \"\"\"\n    data_format = normalize_data_format(data_format)\n\n    image_shape = _preprocess_conv2d_image_shape(int_shape(x), data_format)\n    depthwise_kernel_shape = int_shape(depthwise_kernel)\n    if depthwise_kernel_shape is None:\n        depthwise_kernel_shape = depthwise_kernel.eval().shape  # in case of a shared variable\n    depthwise_kernel_shape = _preprocess_conv2d_depthwise_filter_shape(depthwise_kernel_shape, data_format)\n\n    x = _preprocess_conv2d_input(x, data_format)\n    depthwise_kernel = _preprocess_conv2d_depthwise_kernel(depthwise_kernel, depthwise_kernel_shape, data_format)\n    th_padding = _preprocess_padding(padding)\n\n    conv_out = T.nnet.conv2d(x, depthwise_kernel,\n                             border_mode=th_padding,\n                             subsample=strides,\n                             input_shape=image_shape,\n                             filter_shape=depthwise_kernel_shape,\n                             filter_dilation=dilation_rate,\n                             num_groups=image_shape[1])\n    conv_out = _postprocess_conv2d_output(conv_out, x, padding,\n                                          depthwise_kernel_shape, strides, data_format)\n    return conv_out",
                "def conv3d(x, kernel, strides=(1, 1, 1),\n           padding='valid', data_format=None,\n           dilation_rate=(1, 1, 1)):\n    \"\"\"3D convolution.\n\n    # Arguments\n        kernel: kernel tensor.\n        strides: strides tuple.\n        padding: string, \"same\" or \"valid\".\n        data_format: \"channels_last\" or \"channels_first\".\n            Whether to use Theano or TensorFlow data format\n        in inputs/kernels/outputs.\n    \"\"\"\n    data_format = normalize_data_format(data_format)\n\n    volume_shape = _preprocess_conv3d_volume_shape(int_shape(x), data_format)\n    kernel_shape = int_shape(kernel)\n    if kernel_shape is None:\n        kernel_shape = kernel.eval().shape  # in case of a shared variable\n    kernel_shape = _preprocess_conv3d_filter_shape(kernel_shape, data_format)\n\n    x = _preprocess_conv3d_input(x, data_format)\n    kernel = _preprocess_conv3d_kernel(kernel, data_format)\n    th_padding = _preprocess_padding(padding)\n\n    conv_out = T.nnet.conv3d(x, kernel,\n                             border_mode=th_padding,\n                             subsample=strides,\n                             input_shape=volume_shape,\n                             filter_shape=kernel_shape,\n                             filter_dilation=dilation_rate)\n    conv_out = _postprocess_conv3d_output(conv_out, x, padding,\n                                          kernel_shape, strides, data_format)\n    return conv_out",
                "def conv3d_transpose(x, kernel, output_shape, strides=(1, 1, 1),\n                     padding='valid', data_format=None):\n    \"\"\"3D deconvolution (transposed convolution).\n\n    # Arguments\n        kernel: kernel tensor.\n        output_shape: desired dimensions of output.\n        strides: strides tuple.\n        padding: string, \"same\" or \"valid\".\n        data_format: \"channels_last\" or \"channels_first\".\n            Whether to use Theano or TensorFlow data format\n        in inputs/kernels/outputs.\n\n    # Raises\n        ValueError: if using an even kernel size with padding 'same'.\n    \"\"\"\n    flip_filters = False\n    data_format = normalize_data_format(data_format)\n\n    if data_format == 'channels_last':\n        output_shape = (output_shape[0],\n                        output_shape[4],\n                        output_shape[1],\n                        output_shape[2],\n                        output_shape[3])\n\n    kernel_shape = int_shape(kernel)\n    if kernel_shape is None:\n        kernel_shape = kernel.eval().shape  # in case of a shared variable\n\n    if padding == 'same' and kernel_shape[0] % 2 == 0:\n        raise ValueError('In `Conv3DTranspose`, with padding mode `same`, '\n                         'even kernel sizes are not supported with Theano. '\n                         'You can set `kernel_size` to an odd number.')\n\n    kernel_shape = _preprocess_conv3d_filter_shape(kernel_shape, data_format)\n\n    x = _preprocess_conv3d_input(x, data_format)\n    kernel = _preprocess_conv3d_kernel(kernel, data_format)\n\n    th_padding = _preprocess_padding(padding)\n    op = T.nnet.abstract_conv.AbstractConv3d_gradInputs(imshp=None,\n                                                        kshp=kernel_shape,\n                                                        subsample=strides,\n                                                        border_mode=th_padding,\n                                                        filter_flip=not flip_filters)\n    conv_out = op(kernel, x, output_shape[2:])\n    conv_out = _postprocess_conv3d_output(conv_out, x, padding,\n                                          kernel_shape, strides, data_format)\n    return conv_out",
                "def pool2d(x, pool_size, strides=(1, 1), padding='valid',\n           data_format=None, pool_mode='max'):\n    data_format = normalize_data_format(data_format)\n\n    assert pool_size[0] >= 1 and pool_size[1] >= 1\n\n    if padding == 'same':\n        w_pad = pool_size[0] - 2 if pool_size[0] > 2 and pool_size[0] % 2 == 1 else pool_size[0] - 1\n        h_pad = pool_size[1] - 2 if pool_size[1] > 2 and pool_size[1] % 2 == 1 else pool_size[1] - 1\n        pad = (w_pad, h_pad)\n    elif padding == 'valid':\n        pad = (0, 0)\n    else:\n        raise ValueError('Invalid border mode:', padding)\n\n    if data_format == 'channels_last':\n        x = x.dimshuffle((0, 3, 1, 2))\n\n    if pool_mode == 'max':\n        pool_out = pool.pool_2d(x, ws=pool_size, stride=strides,\n                                ignore_border=True,\n                                pad=pad,\n                                mode='max')\n    elif pool_mode == 'avg':\n        pool_out = pool.pool_2d(x, ws=pool_size, stride=strides,\n                                ignore_border=True,\n                                pad=pad,\n                                mode='average_exc_pad')\n    else:\n        raise ValueError('Invalid pooling mode:', pool_mode)\n    if padding == 'same':\n        expected_width = (x.shape[2] + strides[0] - 1) // strides[0]\n        expected_height = (x.shape[3] + strides[1] - 1) // strides[1]\n        pool_out = pool_out[:, :,\n                            : expected_width,\n                            : expected_height]\n\n    if data_format == 'channels_last':\n        pool_out = pool_out.dimshuffle((0, 2, 3, 1))\n    return pool_out",
                "def pool3d(x, pool_size, strides=(1, 1, 1), padding='valid',\n           data_format=None, pool_mode='max'):\n    data_format = normalize_data_format(data_format)\n\n    if padding == 'same':\n        w_pad = pool_size[0] - 2 if pool_size[0] % 2 == 1 else pool_size[0] - 1\n        h_pad = pool_size[1] - 2 if pool_size[1] % 2 == 1 else pool_size[1] - 1\n        d_pad = pool_size[2] - 2 if pool_size[2] % 2 == 1 else pool_size[2] - 1\n        pad = (w_pad, h_pad, d_pad)\n    elif padding == 'valid':\n        pad = (0, 0, 0)\n    else:\n        raise ValueError('Invalid padding:', padding)\n\n    if data_format == 'channels_last':\n        x = x.dimshuffle((0, 4, 1, 2, 3))\n\n    if pool_mode == 'max':\n        pool_out = pool.pool_3d(x, ws=pool_size, stride=strides,\n                                ignore_border=True,\n                                pad=pad,\n                                mode='max')\n    elif pool_mode == 'avg':\n        pool_out = pool.pool_3d(x, ws=pool_size, stride=strides,\n                                ignore_border=True,\n                                pad=pad,\n                                mode='average_exc_pad')\n    else:\n        raise ValueError('Invalid pooling mode:', pool_mode)\n\n    if padding == 'same':\n        expected_width = (x.shape[2] + strides[0] - 1) // strides[0]\n        expected_height = (x.shape[3] + strides[1] - 1) // strides[1]\n        expected_depth = (x.shape[4] + strides[2] - 1) // strides[2]\n\n        pool_out = pool_out[:, :,\n                            : expected_width,\n                            : expected_height,\n                            : expected_depth]\n\n    if data_format == 'channels_last':\n        pool_out = pool_out.dimshuffle((0, 2, 3, 4, 1))\n    return pool_out",
                "def bias_add(x, bias, data_format=None):\n    data_format = normalize_data_format(data_format)\n    if ndim(bias) != 1 and ndim(bias) != ndim(x) - 1:\n        raise ValueError('Unexpected bias dimensions %d, '\n                         'expect to be 1 or %d dimensions'\n                         % (ndim(bias), ndim(x) - 1))\n    bias_shape = tuple(bias.shape)\n    if ndim(x) == 5:\n        if data_format == 'channels_first':\n            if ndim(bias) == 1:\n                x += reshape(bias, (1, bias_shape[0], 1, 1, 1))\n            else:\n                x += reshape(bias, (1, bias_shape[3]) + bias_shape[:3])\n        elif data_format == 'channels_last':\n            if ndim(bias) == 1:\n                x += reshape(bias, (1, 1, 1, 1, bias_shape[0]))\n            else:\n                x += reshape(bias, (1,) + bias_shape)\n    elif ndim(x) == 4:\n        if data_format == 'channels_first':\n            if ndim(bias) == 1:\n                x += reshape(bias, (1, bias_shape[0], 1, 1))\n            else:\n                x += reshape(bias, (1, bias_shape[2]) + bias_shape[:2])\n        elif data_format == 'channels_last':\n            if ndim(bias) == 1:\n                x += reshape(bias, (1, 1, 1, bias_shape[0]))\n            else:\n                x += reshape(bias, (1,) + bias_shape)\n    elif ndim(x) == 3:\n        if data_format == 'channels_first':\n            if ndim(bias) == 1:\n                x += reshape(bias, (1, bias_shape[0], 1))\n            else:\n                x += reshape(bias, (1, bias_shape[1], bias_shape[0]))\n        elif data_format == 'channels_last':\n            if ndim(bias) == 1:\n                x += reshape(bias, (1, 1, bias_shape[0]))\n            else:\n                x += reshape(bias, (1,) + bias_shape)\n    else:\n        x += bias\n    return x",
                "def random_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n    if dtype is None:\n        dtype = floatx()\n    if seed is None:\n        seed = np.random.randint(1, 10e6)\n    rng = RandomStreams(seed=seed)\n    return rng.normal(size=shape, avg=mean, std=stddev, dtype=dtype)",
                "def random_uniform(shape, minval=0.0, maxval=1.0, dtype=None, seed=None):\n    if dtype is None:\n        dtype = floatx()\n    if seed is None:\n        seed = np.random.randint(1, 10e6)\n    rng = RandomStreams(seed=seed)\n    return rng.uniform(shape, low=minval, high=maxval, dtype=dtype)",
                "def random_binomial(shape, p=0.0, dtype=None, seed=None):\n    if dtype is None:\n        dtype = floatx()\n    if seed is None:\n        seed = np.random.randint(1, 10e6)\n    rng = RandomStreams(seed=seed)\n    return rng.binomial(shape, p=p, dtype=dtype)",
                "def truncated_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n    if dtype is None:\n        dtype = floatx()\n    if seed is None:\n        seed = np.random.randint(1, 10e6)\n    rng = RandomStreams(seed=seed)\n\n    try:\n        return rng.normal(size=shape, avg=mean, std=stddev, dtype=dtype,\n                          truncate=True)\n    except TypeError:\n        normal_t = rng.normal(size=shape, avg=mean, std=stddev, dtype=dtype)\n        # Poor man's truncated normal: we literally clip the tensor\n        return T.clip(normal_t, mean - 2 * stddev, mean + 2 * stddev)",
                "def ctc_interleave_blanks(Y):\n    Y_ = T.alloc(-1, Y.shape[0] * 2 + 1)\n    Y_ = T.set_subtensor(Y_[T.arange(Y.shape[0]) * 2 + 1], Y)\n    return Y_",
                "def ctc_create_skip_idxs(Y):\n    skip_idxs = T.arange((Y.shape[0] - 3) // 2) * 2 + 1\n    non_repeats = T.neq(Y[skip_idxs], Y[skip_idxs + 2])\n    return skip_idxs[non_repeats.nonzero()]",
                "def ctc_update_log_p(skip_idxs, zeros, active, log_p_curr, log_p_prev):\n    active_skip_idxs = skip_idxs[(skip_idxs < active).nonzero()]\n    active_next = T.cast(T.minimum(\n        T.maximum(\n            active + 1,\n            T.max(T.concatenate([active_skip_idxs, [-1]])) + 2 + 1\n        ), log_p_curr.shape[0]), 'int32')\n\n    common_factor = T.max(log_p_prev[:active])\n    p_prev = T.exp(log_p_prev[:active] - common_factor)\n    _p_prev = zeros[:active_next]\n    # copy over\n    _p_prev = T.set_subtensor(_p_prev[:active], p_prev)\n    # previous transitions\n    _p_prev = T.inc_subtensor(_p_prev[1:], _p_prev[:-1])\n    # skip transitions\n    _p_prev = T.inc_subtensor(_p_prev[active_skip_idxs + 2], p_prev[active_skip_idxs])\n    updated_log_p_prev = T.log(_p_prev) + common_factor\n\n    log_p_next = T.set_subtensor(\n        zeros[:active_next],\n        log_p_curr[:active_next] + updated_log_p_prev\n    )\n    return active_next, log_p_next",
                "def ctc_path_probs(predict, Y, alpha=1e-4):\n    smoothed_predict = (1 - alpha) * predict[:, Y] + alpha * np.float32(1.) / Y.shape[0]\n    L = T.log(smoothed_predict)\n    zeros = T.zeros_like(L[0])\n    log_first = zeros\n\n    f_skip_idxs = ctc_create_skip_idxs(Y)\n    b_skip_idxs = ctc_create_skip_idxs(Y[::-1])  # there should be a shortcut to calculating this\n\n    def step(log_f_curr, log_b_curr, f_active, log_f_prev, b_active, log_b_prev):\n        f_active_next, log_f_next = ctc_update_log_p(f_skip_idxs, zeros, f_active, log_f_curr, log_f_prev)\n        b_active_next, log_b_next = ctc_update_log_p(b_skip_idxs, zeros, b_active, log_b_curr, log_b_prev)\n        return f_active_next, log_f_next, b_active_next, log_b_next\n\n    [f_active, log_f_probs, b_active, log_b_probs], _ = theano.scan(\n        step, sequences=[L, L[::-1, ::-1]], outputs_info=[np.int32(1), log_first, np.int32(1), log_first])\n\n    idxs = T.arange(L.shape[1]).dimshuffle('x', 0)\n    mask = (idxs < f_active.dimshuffle(0, 'x')) & (idxs < b_active.dimshuffle(0, 'x'))[::-1, ::-1]\n    log_probs = log_f_probs + log_b_probs[::-1, ::-1] - L\n    return log_probs, mask",
                "def ctc_cost(predict, Y):\n    log_probs, mask = ctc_path_probs(predict, ctc_interleave_blanks(Y))\n    common_factor = T.max(log_probs)\n    total_log_prob = T.log(T.sum(T.exp(log_probs - common_factor)[mask.nonzero()])) + common_factor\n    return -total_log_prob",
                "def ctc_batch_cost(y_true, y_pred, input_length, label_length):\n    \"\"\"Runs CTC loss algorithm on each batch element.\n\n    # Arguments\n        y_true: tensor (samples, max_string_length) containing the truth labels\n        y_pred: tensor (samples, time_steps, num_categories) containing the prediction,\n                or output of the softmax\n        input_length: tensor (samples,1) containing the sequence length for\n                each batch item in y_pred\n        label_length: tensor (samples,1) containing the sequence length for\n                each batch item in y_true\n\n    # Returns\n        Tensor with shape (samples,1) containing the\n            CTC loss of each element\n    \"\"\"\n\n    def ctc_step(y_true_step, y_pred_step, input_length_step, label_length_step):\n        y_pred_step = y_pred_step[0: input_length_step[0]]\n        y_true_step = y_true_step[0:label_length_step[0]]\n        return ctc_cost(y_pred_step, y_true_step)\n\n    ret, _ = theano.scan(\n        fn=ctc_step,\n        outputs_info=None,\n        sequences=[y_true, y_pred, input_length, label_length]\n    )\n\n    ret = ret.dimshuffle('x', 0)\n    return ret",
                "def map_fn(fn, elems, name=None, dtype=None):\n    \"\"\"Map the function fn over the elements elems and return the outputs.\n\n    # Arguments\n        fn: Callable that will be called upon each element in elems\n        elems: tensor, at least 2 dimensional\n        name: A string name for the map node in the graph\n\n    # Returns\n        Tensor with first dimension equal to the elems and second depending on\n        fn\n    \"\"\"\n    return theano.map(fn, elems, name=name)[0]",
                "def foldl(fn, elems, initializer=None, name=None):\n    \"\"\"Reduce elems using fn to combine them from left to right.\n\n    # Arguments\n        fn: Callable that will be called upon each element in elems and an\n            accumulator, for instance lambda acc, x: acc + x\n        elems: tensor\n        initializer: The first value used (elems[0] in case of None)\n        name: A string name for the foldl node in the graph\n\n    # Returns\n        Same type and shape as initializer\n    \"\"\"\n    if initializer is None:\n        initializer = elems[0]\n        elems = elems[1:]\n\n    # We need to change the order of the arguments because theano accepts x as\n    # first parameter and accumulator as second\n    return theano.foldl(lambda x, acc: fn(acc, x),\n                        elems, initializer, name=name)[0]",
                "def foldr(fn, elems, initializer=None, name=None):\n    \"\"\"Reduce elems using fn to combine them from right to left.\n\n    # Arguments\n        fn: Callable that will be called upon each element in elems and an\n            accumulator, for instance lambda acc, x: acc + x\n        elems: tensor\n        initializer: The first value used (elems[-1] in case of None)\n        name: A string name for the foldr node in the graph\n\n    # Returns\n        Same type and shape as initializer\n    \"\"\"\n    if initializer is None:\n        initializer = elems[-1]\n        elems = elems[:-1]\n\n    # We need to change the order of the arguments because theano accepts x as\n    # first parameter and accumulator as second\n    return theano.foldr(lambda x, acc: fn(acc, x),\n                        elems, initializer, name=name)[0]",
                "def local_conv1d(inputs, kernel, kernel_size, strides, data_format=None):\n    data_format = normalize_data_format(data_format)\n\n    stride = strides[0]\n    kernel_shape = int_shape(kernel)\n    output_length, feature_dim, filters = kernel_shape\n\n    xs = []\n    for i in range(output_length):\n        slice_length = py_slice(i * stride,\n                                i * stride + kernel_size[0])\n        xs.append(reshape(inputs[:, slice_length, :],\n                          (1, -1, feature_dim)))\n    x_aggregate = concatenate(xs, axis=0)\n    # Shape: `(output_length, batch_size, filters)`.\n    output = batch_dot(x_aggregate, kernel)\n    return permute_dimensions(output, (1, 0, 2))",
                "def local_conv2d(inputs, kernel, kernel_size, strides, output_shape, data_format=None):\n    data_format = normalize_data_format(data_format)\n\n    stride_row, stride_col = strides\n    output_row, output_col = output_shape\n    kernel_shape = int_shape(kernel)\n    _, feature_dim, filters = kernel_shape\n\n    if data_format == 'channels_first':\n        output = []\n        for i in range(output_row):\n            for j in range(output_col):\n                slice_row = py_slice(i * stride_row,\n                                     i * stride_row + kernel_size[0])\n                slice_col = py_slice(j * stride_col,\n                                     j * stride_col + kernel_size[1])\n                x_flatten = reshape(inputs[:, :, slice_row, slice_col],\n                                    (1, -1, feature_dim))\n                output.append(dot(x_flatten,\n                                  kernel[i * output_col + j, :, :]))\n        output = concatenate(output, axis=0)\n        output = reshape(output,\n                         (output_row, output_col, -1, filters))\n        output = permute_dimensions(output, (2, 3, 0, 1))\n    else:\n        xs = []\n        for i in range(output_row):\n            for j in range(output_col):\n                slice_row = py_slice(i * stride_row,\n                                     i * stride_row + kernel_size[0])\n                slice_col = py_slice(j * stride_col,\n                                     j * stride_col + kernel_size[1])\n                xs.append(reshape(inputs[:, slice_row, slice_col, :],\n                                  (1, -1, feature_dim)))\n\n        x_aggregate = concatenate(xs, axis=0)\n        output = batch_dot(x_aggregate, kernel)\n        output = reshape(output,\n                         (output_row, output_col, -1, filters))\n        output = permute_dimensions(output, (2, 0, 1, 3))\n    return output",
                "def __init__(self, inputs, outputs, updates=[], name=None, **kwargs):\n    unique_variables_to_update = {}\n    for v, nv in updates:\n        if v not in unique_variables_to_update:\n            unique_variables_to_update[v] = nv\n    updates = unique_variables_to_update.items()\n    self.function = theano.function(inputs, outputs, updates=updates,\n                                    allow_input_downcast=True,\n                                    on_unused_input='ignore',\n                                    name=name,\n                                    **kwargs)\n    self.name = name",
                "def __call__(self, inputs):\n    assert isinstance(inputs, (list, tuple))\n    return self.function(*inputs)",
                "def int_or_none(value):\n    try:\n        return int(value)\n    except TypeError:\n        return None",
                "def int_or_none(value):\n    try:\n        return int(value)\n    except TypeError:\n        return None",
                "def int_or_none(value):\n    try:\n        return int(value)\n    except TypeError:\n        return None",
                "def int_or_none(value):\n    try:\n        return int(value)\n    except TypeError:\n        return None",
                "def int_or_none(value):\n    try:\n        return int(value)\n    except TypeError:\n        return None",
                "def step(log_f_curr, log_b_curr, f_active, log_f_prev, b_active, log_b_prev):\n    f_active_next, log_f_next = ctc_update_log_p(f_skip_idxs, zeros, f_active, log_f_curr, log_f_prev)\n    b_active_next, log_b_next = ctc_update_log_p(b_skip_idxs, zeros, b_active, log_b_curr, log_b_prev)\n    return f_active_next, log_f_next, b_active_next, log_b_next",
                "def ctc_step(y_true_step, y_pred_step, input_length_step, label_length_step):\n    y_pred_step = y_pred_step[0: input_length_step[0]]\n    y_true_step = y_true_step[0:label_length_step[0]]\n    return ctc_cost(y_pred_step, y_true_step)",
                "def _step(inputs, mask, output_tm1, *states):\n    outputs, new_states = step_function(inputs, states)\n    if getattr(outputs, '_uses_learning_phase', False):\n        global uses_learning_phase\n        uses_learning_phase = True\n    # output previous output if masked.\n    outputs = T.switch(mask, outputs, output_tm1)\n    return_states = []\n    for state, new_state in zip(states, new_states):\n        return_states.append(T.switch(mask, new_state, state))\n    return [outputs] + return_states",
                "def _step(inputs, *states):\n    outputs, new_states = step_function(inputs, states)\n    if getattr(outputs, '_uses_learning_phase', False):\n        global uses_learning_phase\n        uses_learning_phase = True\n    return [outputs] + new_states"
            ],
            "inscope_function_signatures": [
                "learning_phase()",
                "set_learning_phase(value)",
                "get_uid(prefix='')",
                "reset_uids()",
                "_assert_sparse_module()",
                "is_sparse(tensor)",
                "to_dense(tensor)",
                "_is_explicit_shape(shape)",
                "name_scope(name)",
                "_prepare_name(name, default)",
                "variable(value, dtype=None, name=None, constraint=None)",
                "constant(value, dtype=None, shape=None, name=None)",
                "is_keras_tensor(x)",
                "is_tensor(x)",
                "placeholder(shape=None, ndim=None, dtype=None, sparse=False, name=None)",
                "is_placeholder(x)",
                "shape(x)",
                "int_shape(x)",
                "ndim(x)",
                "dtype(x)",
                "eval(x)",
                "zeros(shape, dtype=None, name=None)",
                "ones(shape, dtype=None, name=None)",
                "eye(size, dtype=None, name=None)",
                "ones_like(x, dtype=None, name=None)",
                "zeros_like(x, dtype=None, name=None)",
                "identity(x, name=None)",
                "random_uniform_variable(shape, low, high, dtype=None, name=None)",
                "random_normal_variable(shape, mean, scale, dtype=None, name=None)",
                "count_params(x)",
                "cast(x, dtype)",
                "update(x, new_x)",
                "update_add(x, increment)",
                "update_sub(x, decrement)",
                "moving_average_update(variable, value, momentum)",
                "dot(x, y)",
                "batch_dot(x, y, axes=None)",
                "transpose(x)",
                "gather(reference, indices)",
                "max(x, axis=None, keepdims=False)",
                "min(x, axis=None, keepdims=False)",
                "sum(x, axis=None, keepdims=False)",
                "prod(x, axis=None, keepdims=False)",
                "cumsum(x, axis=0)",
                "cumprod(x, axis=0)",
                "mean(x, axis=None, keepdims=False)",
                "std(x, axis=None, keepdims=False)",
                "var(x, axis=None, keepdims=False)",
                "any(x, axis=None, keepdims=False)",
                "all(x, axis=None, keepdims=False)",
                "argmax(x, axis=-1)",
                "argmin(x, axis=-1)",
                "square(x)",
                "abs(x)",
                "sqrt(x)",
                "exp(x)",
                "log(x)",
                "logsumexp(x, axis=None, keepdims=False)",
                "round(x)",
                "sign(x)",
                "pow(x, a)",
                "clip(x, min_value, max_value)",
                "equal(x, y)",
                "not_equal(x, y)",
                "greater(x, y)",
                "greater_equal(x, y)",
                "less(x, y)",
                "less_equal(x, y)",
                "maximum(x, y)",
                "minimum(x, y)",
                "sin(x)",
                "cos(x)",
                "normalize_batch_in_training(x, gamma, beta, reduction_axes, epsilon=0.001)",
                "batch_normalization(x, mean, var, beta, gamma, axis=-1, epsilon=0.001)",
                "_old_normalize_batch_in_training(x, gamma, beta, reduction_axes, epsilon=0.001)",
                "_old_batch_normalization(x, mean, var, beta, gamma, epsilon=0.001)",
                "concatenate(tensors, axis=-1)",
                "reshape(x, shape)",
                "permute_dimensions(x, pattern)",
                "repeat_elements(x, rep, axis)",
                "resize_images(x, height_factor, width_factor, data_format, interpolation='nearest')",
                "resize_volumes(x, depth_factor, height_factor, width_factor, data_format)",
                "repeat(x, n)",
                "arange(start, stop=None, step=1, dtype='int32')",
                "tile(x, n)",
                "flatten(x)",
                "batch_flatten(x)",
                "expand_dims(x, axis=-1)",
                "squeeze(x, axis)",
                "temporal_padding(x, padding=(1, 1))",
                "spatial_2d_padding(x, padding=((1, 1), (1, 1)), data_format=None)",
                "spatial_3d_padding(x, padding=((1, 1), (1, 1), (1, 1)), data_format=None)",
                "stack(x, axis=0)",
                "one_hot(indices, num_classes)",
                "reverse(x, axes)",
                "slice(x, start, size)",
                "pattern_broadcast(x, broadcastable)",
                "get_value(x)",
                "batch_get_value(xs)",
                "set_value(x, value)",
                "batch_set_value(tuples)",
                "get_variable_shape(x)",
                "print_tensor(x, message='')",
                "function(inputs, outputs, updates=[], **kwargs)",
                "gradients(loss, variables)",
                "stop_gradient(variables)",
                "rnn(step_function, inputs, initial_states, go_backwards=False, mask=None, constants=None, unroll=False, input_length=None)",
                "switch(condition, then_expression, else_expression)",
                "in_train_phase(x, alt, training=None)",
                "in_test_phase(x, alt, training=None)",
                "_assert_has_capability(module, func)",
                "elu(x, alpha=1.0)",
                "relu(x, alpha=0.0, max_value=None)",
                "softmax(x, axis=-1)",
                "softplus(x)",
                "softsign(x)",
                "categorical_crossentropy(target, output, from_logits=False, axis=-1)",
                "sparse_categorical_crossentropy(target, output, from_logits=False, axis=-1)",
                "binary_crossentropy(target, output, from_logits=False)",
                "sigmoid(x)",
                "hard_sigmoid(x)",
                "tanh(x)",
                "dropout(x, level, noise_shape=None, seed=None)",
                "l2_normalize(x, axis=None)",
                "in_top_k(predictions, targets, k)",
                "_preprocess_conv2d_input(x, data_format)",
                "_preprocess_conv3d_input(x, data_format)",
                "_preprocess_conv2d_kernel(kernel, data_format)",
                "_preprocess_conv2d_depthwise_kernel(kernel, kernel_shape, data_format)",
                "_preprocess_conv3d_kernel(kernel, data_format)",
                "_preprocess_padding(padding)",
                "_preprocess_conv2d_image_shape(image_shape, data_format)",
                "_preprocess_conv3d_volume_shape(volume_shape, data_format)",
                "_preprocess_conv2d_filter_shape(filter_shape, data_format)",
                "_preprocess_conv2d_depthwise_filter_shape(filter_shape, data_format)",
                "_preprocess_conv3d_filter_shape(filter_shape, data_format)",
                "_postprocess_conv2d_output(conv_out, x, padding, kernel_shape, strides, data_format)",
                "_postprocess_conv3d_output(conv_out, x, padding, kernel_shape, strides, data_format)",
                "conv1d(x, kernel, strides=1, padding='valid', data_format=None, dilation_rate=1)",
                "conv2d(x, kernel, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1))",
                "conv2d_transpose(x, kernel, output_shape, strides=(1, 1), padding='valid', data_format=None)",
                "separable_conv1d(x, depthwise_kernel, pointwise_kernel, strides=1, padding='valid', data_format=None, dilation_rate=1)",
                "separable_conv2d(x, depthwise_kernel, pointwise_kernel, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1))",
                "depthwise_conv2d(x, depthwise_kernel, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1))",
                "conv3d(x, kernel, strides=(1, 1, 1), padding='valid', data_format=None, dilation_rate=(1, 1, 1))",
                "conv3d_transpose(x, kernel, output_shape, strides=(1, 1, 1), padding='valid', data_format=None)",
                "pool2d(x, pool_size, strides=(1, 1), padding='valid', data_format=None, pool_mode='max')",
                "pool3d(x, pool_size, strides=(1, 1, 1), padding='valid', data_format=None, pool_mode='max')",
                "bias_add(x, bias, data_format=None)",
                "random_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None)",
                "random_uniform(shape, minval=0.0, maxval=1.0, dtype=None, seed=None)",
                "random_binomial(shape, p=0.0, dtype=None, seed=None)",
                "truncated_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None)",
                "ctc_interleave_blanks(Y)",
                "ctc_create_skip_idxs(Y)",
                "ctc_update_log_p(skip_idxs, zeros, active, log_p_curr, log_p_prev)",
                "ctc_path_probs(predict, Y, alpha=0.0001)",
                "ctc_cost(predict, Y)",
                "ctc_batch_cost(y_true, y_pred, input_length, label_length)",
                "map_fn(fn, elems, name=None, dtype=None)",
                "foldl(fn, elems, initializer=None, name=None)",
                "foldr(fn, elems, initializer=None, name=None)",
                "local_conv1d(inputs, kernel, kernel_size, strides, data_format=None)",
                "local_conv2d(inputs, kernel, kernel_size, strides, output_shape, data_format=None)",
                "__init__(self, inputs, outputs, updates=[], name=None, **kwargs)",
                "__call__(self, inputs)",
                "int_or_none(value)",
                "int_or_none(value)",
                "int_or_none(value)",
                "int_or_none(value)",
                "int_or_none(value)",
                "step(log_f_curr, log_b_curr, f_active, log_f_prev, b_active, log_b_prev)",
                "ctc_step(y_true_step, y_pred_step, input_length_step, label_length_step)",
                "_step(inputs, mask, output_tm1, *states)",
                "_step(inputs, *states)"
            ],
            "variables_in_file": {
                "ImportError": [
                    88,
                    19,
                    15
                ],
                "th_sparse_module": [
                    98,
                    907,
                    909,
                    16,
                    148,
                    405,
                    87,
                    247,
                    93
                ],
                "py_all": [
                    904,
                    915,
                    31
                ],
                "all": [
                    31
                ],
                "py_any": [
                    32,
                    464
                ],
                "any": [
                    32
                ],
                "py_sum": [
                    33,
                    1167
                ],
                "sum": [
                    33,
                    1733
                ],
                "py_slice": [
                    2824,
                    2826,
                    2840,
                    2842,
                    34,
                    1190,
                    1191,
                    1192,
                    1193,
                    1201,
                    1202,
                    1203,
                    1204,
                    1332,
                    1251,
                    1252,
                    1253,
                    1254,
                    1255,
                    1264,
                    1265,
                    1266,
                    1267,
                    1268,
                    2802
                ],
                "slice": [
                    34
                ],
                "theano.config.floatX": [
                    38
                ],
                "theano.config": [
                    814,
                    873,
                    38
                ],
                "theano": [
                    1551,
                    1428,
                    1430,
                    151,
                    152,
                    153,
                    157,
                    2720,
                    38,
                    814,
                    820,
                    822,
                    823,
                    824,
                    2744,
                    1598,
                    2766,
                    2789,
                    873,
                    1391,
                    368,
                    882,
                    2681,
                    890,
                    892,
                    1406
                ],
                "floatx": [
                    576,
                    38,
                    327,
                    168,
                    2599,
                    235,
                    2608,
                    145,
                    2581,
                    311,
                    2590,
                    319
                ],
                "_LEARNING_PHASE": [
                    53,
                    45,
                    39
                ],
                "T.scalar": [
                    39
                ],
                "T": [
                    1537,
                    1545,
                    1548,
                    525,
                    529,
                    1044,
                    535,
                    541,
                    39,
                    1063,
                    554,
                    1067,
                    1580,
                    1583,
                    567,
                    2619,
                    1596,
                    577,
                    581,
                    2630,
                    2631,
                    585,
                    1098,
                    2636,
                    1613,
                    2125,
                    591,
                    2637,
                    1618,
                    2643,
                    2644,
                    2646,
                    1111,
                    2649,
                    2650,
                    2653,
                    2655,
                    2657,
                    2658,
                    2660,
                    616,
                    2669,
                    2670,
                    1647,
                    1143,
                    2684,
                    639,
                    2176,
                    643,
                    2692,
                    2693,
                    647,
                    651,
                    1163,
                    1164,
                    655,
                    656,
                    660,
                    664,
                    1189,
                    172,
                    687,
                    1200,
                    691,
                    1205,
                    1718,
                    695,
                    1719,
                    699,
                    1723,
                    1724,
                    1726,
                    2237,
                    707,
                    1732,
                    1733,
                    2244,
                    711,
                    1738,
                    715,
                    724,
                    728,
                    732,
                    736,
                    1760,
                    1250,
                    227,
                    228,
                    740,
                    1765,
                    1766,
                    744,
                    748,
                    1263,
                    752,
                    1269,
                    2294,
                    1783,
                    1784,
                    761,
                    249,
                    2301,
                    1791,
                    1793,
                    1794,
                    774,
                    1798,
                    777,
                    1802,
                    1806,
                    785,
                    799,
                    1312,
                    2344,
                    1321,
                    1322,
                    1323,
                    1835,
                    1843,
                    1844,
                    825,
                    826,
                    1341,
                    839,
                    841,
                    842,
                    843,
                    332,
                    844,
                    1865,
                    1867,
                    336,
                    1871,
                    1873,
                    1875,
                    1876,
                    1877,
                    2381,
                    373,
                    897,
                    2433,
                    1413,
                    913,
                    407,
                    929,
                    958,
                    480,
                    1000,
                    1518,
                    1521,
                    499,
                    1527,
                    1530,
                    1535
                ],
                "_UID_PREFIXES": [
                    40,
                    80,
                    74,
                    75
                ],
                "defaultdict": [
                    40,
                    80
                ],
                "int": [
                    2209,
                    930,
                    1979,
                    40,
                    1994,
                    107,
                    459,
                    621,
                    1963,
                    80,
                    624,
                    1330,
                    596,
                    1076,
                    599,
                    2009,
                    1947,
                    2207
                ],
                "value": [
                    392,
                    146,
                    149,
                    151,
                    1947,
                    155,
                    156,
                    157,
                    160,
                    171,
                    1963,
                    50,
                    53,
                    1979,
                    1994,
                    1361,
                    1365,
                    1366,
                    2009
                ],
                "ValueError": [
                    1408,
                    1033,
                    911,
                    1939,
                    2457,
                    1822,
                    2473,
                    51,
                    2498,
                    1481,
                    465,
                    2514,
                    1748,
                    986,
                    220,
                    2534,
                    1772,
                    237,
                    1010,
                    2166,
                    2423,
                    895
                ],
                "prefix": [
                    128,
                    74,
                    75,
                    125,
                    127
                ],
                "isinstance": [
                    1427,
                    1559,
                    151,
                    2207,
                    1825,
                    930,
                    2209,
                    1330,
                    1076,
                    1606,
                    459,
                    464,
                    468,
                    596,
                    93,
                    227,
                    107,
                    621,
                    1399
                ],
                "tensor.type": [
                    93
                ],
                "tensor": [
                    97,
                    98,
                    100,
                    915,
                    916,
                    93
                ],
                "th_sparse_module.SparseType": [
                    93
                ],
                "is_sparse": [
                    904,
                    97,
                    404
                ],
                "th_sparse_module.dense_from_sparse": [
                    98
                ],
                "hasattr": [
                    516,
                    265,
                    1165,
                    785,
                    146,
                    915,
                    1045,
                    408,
                    287,
                    932,
                    1702,
                    1068,
                    947,
                    1206,
                    959,
                    1087,
                    1347,
                    1099,
                    716,
                    718,
                    592,
                    1112,
                    223,
                    484,
                    104,
                    617,
                    1131,
                    1004,
                    500,
                    1270,
                    1144,
                    761
                ],
                "shape": [
                    2069,
                    918,
                    919,
                    1046,
                    1047,
                    922,
                    1048,
                    2075,
                    2076,
                    2585,
                    929,
                    930,
                    931,
                    2082,
                    2083,
                    2337,
                    2594,
                    169,
                    170,
                    171,
                    2286,
                    2603,
                    175,
                    2225,
                    2229,
                    2614,
                    312,
                    2617,
                    320,
                    2118,
                    2374,
                    1143,
                    1370,
                    2282,
                    353,
                    485,
                    358,
                    104,
                    105,
                    488,
                    491,
                    236,
                    492,
                    238,
                    239,
                    493,
                    241,
                    494,
                    1132,
                    1133,
                    1134,
                    1141,
                    1142,
                    2163,
                    1785,
                    250,
                    2420
                ],
                "x": [
                    2067,
                    2069,
                    2073,
                    2076,
                    2080,
                    2083,
                    2090,
                    2115,
                    2121,
                    2125,
                    2131,
                    105,
                    106,
                    107,
                    2172,
                    2181,
                    2182,
                    2216,
                    2222,
                    2232,
                    2237,
                    2250,
                    219,
                    221,
                    223,
                    227,
                    2279,
                    2289,
                    2294,
                    247,
                    249,
                    250,
                    251,
                    252,
                    253,
                    2307,
                    265,
                    274,
                    2334,
                    287,
                    288,
                    2340,
                    294,
                    2344,
                    298,
                    2351,
                    304,
                    2371,
                    2377,
                    332,
                    2381,
                    336,
                    2387,
                    349,
                    368,
                    373,
                    380,
                    2429,
                    384,
                    388,
                    2438,
                    2439,
                    404,
                    405,
                    407,
                    408,
                    409,
                    2460,
                    2463,
                    2468,
                    2475,
                    2476,
                    2501,
                    2504,
                    2509,
                    463,
                    2517,
                    2518,
                    2519,
                    474,
                    475,
                    480,
                    484,
                    2533,
                    486,
                    488,
                    2536,
                    2538,
                    2541,
                    2543,
                    2546,
                    499,
                    500,
                    501,
                    2548,
                    2549,
                    2552,
                    2554,
                    2557,
                    2559,
                    2560,
                    2563,
                    2565,
                    2568,
                    2570,
                    2572,
                    525,
                    2573,
                    529,
                    535,
                    541,
                    554,
                    567,
                    575,
                    577,
                    581,
                    585,
                    591,
                    592,
                    594,
                    600,
                    616,
                    617,
                    619,
                    625,
                    639,
                    643,
                    647,
                    651,
                    655,
                    656,
                    660,
                    664,
                    687,
                    691,
                    695,
                    699,
                    707,
                    711,
                    715,
                    716,
                    717,
                    2766,
                    724,
                    728,
                    732,
                    736,
                    740,
                    2789,
                    744,
                    748,
                    752,
                    762,
                    766,
                    771,
                    775,
                    786,
                    795,
                    797,
                    800,
                    810,
                    812,
                    815,
                    821,
                    830,
                    831,
                    834,
                    838,
                    845,
                    862,
                    866,
                    872,
                    883,
                    891,
                    897,
                    904,
                    913,
                    929,
                    930,
                    932,
                    933,
                    946,
                    947,
                    948,
                    958,
                    959,
                    960,
                    961,
                    989,
                    997,
                    999,
                    1004,
                    1005,
                    1023,
                    1028,
                    1042,
                    1043,
                    1045,
                    1046,
                    1067,
                    1068,
                    1070,
                    1071,
                    1077,
                    1078,
                    1081,
                    1086,
                    1090,
                    1092,
                    1098,
                    1099,
                    1100,
                    1103,
                    1111,
                    1112,
                    1113,
                    1114,
                    1116,
                    1123,
                    1125,
                    1128,
                    1130,
                    1131,
                    1132,
                    1141,
                    1143,
                    1144,
                    1145,
                    1159,
                    1164,
                    1165,
                    1166,
                    1167,
                    1168,
                    1183,
                    1205,
                    1206,
                    1208,
                    1209,
                    1212,
                    1213,
                    1216,
                    1217,
                    1221,
                    1222,
                    1225,
                    1226,
                    1229,
                    1232,
                    1243,
                    1269,
                    1270,
                    1272,
                    1273,
                    1276,
                    1277,
                    1280,
                    1281,
                    1284,
                    1285,
                    1290,
                    1291,
                    1294,
                    1295,
                    1298,
                    1299,
                    1302,
                    1306,
                    1312,
                    1332,
                    1333,
                    1341,
                    1347,
                    1350,
                    1357,
                    1361,
                    1365,
                    1366,
                    1370,
                    1378,
                    1666,
                    1667,
                    1669,
                    1677,
                    1678,
                    1683,
                    1685,
                    1686,
                    1696,
                    1719,
                    1724,
                    1726,
                    1727,
                    1731,
                    1732,
                    1733,
                    1734,
                    1738,
                    1742,
                    1798,
                    1802,
                    1806,
                    1832,
                    1834,
                    1837,
                    1838,
                    1839,
                    1843,
                    1845,
                    1888,
                    1889,
                    1898,
                    1899,
                    2025,
                    2027,
                    2038,
                    2040,
                    2042
                ],
                "NAME_SCOPE_STACK": [
                    113,
                    125,
                    121,
                    119
                ],
                "NAME_SCOPE_STACK.append": [
                    119
                ],
                "name": [
                    128,
                    149,
                    158,
                    174,
                    2744,
                    312,
                    320,
                    328,
                    2767,
                    247,
                    349,
                    354,
                    2790,
                    359,
                    1394,
                    243,
                    1396,
                    119,
                    249,
                    126
                ],
                "NAME_SCOPE_STACK.pop": [
                    121
                ],
                "contextmanager": [
                    116
                ],
                "join": [
                    125
                ],
                "default": [
                    127
                ],
                "dtype": [
                    144,
                    145,
                    2580,
                    2581,
                    2585,
                    156,
                    2589,
                    2590,
                    2594,
                    2598,
                    167,
                    168,
                    1063,
                    2599,
                    2603,
                    173,
                    2607,
                    2608,
                    310,
                    311,
                    312,
                    2614,
                    2617,
                    573,
                    318,
                    319,
                    320,
                    576,
                    577,
                    326,
                    327,
                    328,
                    332,
                    336,
                    354,
                    359,
                    234,
                    235,
                    373,
                    247,
                    249
                ],
                "_assert_sparse_module": [
                    147,
                    246
                ],
                "variable": [
                    160,
                    161,
                    162,
                    163,
                    320,
                    353,
                    358,
                    328,
                    392,
                    148,
                    312,
                    157
                ],
                "th_sparse_module.as_sparse_variable": [
                    148
                ],
                "_prepare_name": [
                    243,
                    174,
                    149,
                    158
                ],
                "theano.tensor.TensorVariable": [
                    151
                ],
                "theano.tensor": [
                    824,
                    822,
                    823,
                    152,
                    153,
                    892,
                    151
                ],
                "theano.tensor.sharedvar.TensorSharedVariable": [
                    152
                ],
                "theano.tensor.sharedvar": [
                    152
                ],
                "theano.tensor.TensorConstant": [
                    153
                ],
                "value.eval": [
                    155
                ],
                "np.asarray": [
                    1361,
                    948,
                    156,
                    1366
                ],
                "np": [
                    655,
                    2583,
                    156,
                    1824,
                    2592,
                    2601,
                    171,
                    2610,
                    948,
                    312,
                    320,
                    706,
                    328,
                    1103,
                    1361,
                    1366,
                    1116,
                    353,
                    358,
                    2668,
                    369,
                    2682
                ],
                "theano.shared": [
                    157
                ],
                "variable._keras_shape": [
                    160
                ],
                "value.shape": [
                    160
                ],
                "variable._uses_learning_phase": [
                    161
                ],
                "variable.constraint": [
                    162
                ],
                "constraint": [
                    162
                ],
                "np_value": [
                    171,
                    172
                ],
                "np.ones": [
                    320,
                    171
                ],
                "const": [
                    176,
                    177,
                    172,
                    175
                ],
                "T.constant": [
                    172
                ],
                "const._keras_shape": [
                    175
                ],
                "const._uses_learning_phase": [
                    176
                ],
                "is_tensor": [
                    219
                ],
                "str": [
                    467,
                    1939,
                    221
                ],
                "type": [
                    221
                ],
                "T.TensorVariable": [
                    227
                ],
                "T.sharedvar.TensorSharedVariable": [
                    228
                ],
                "T.sharedvar": [
                    228
                ],
                "ndim": [
                    2560,
                    2562,
                    2567,
                    905,
                    815,
                    834,
                    1476,
                    1477,
                    1485,
                    1495,
                    1497,
                    481,
                    2533,
                    872,
                    1641,
                    874,
                    1642,
                    236,
                    2536,
                    2538,
                    239,
                    879,
                    241,
                    2540,
                    2545,
                    244,
                    2549,
                    2551,
                    2556
                ],
                "len": [
                    1536,
                    1158,
                    1176,
                    1177,
                    1178,
                    411,
                    413,
                    415,
                    1070,
                    1582,
                    1595,
                    594,
                    1746,
                    1752,
                    486,
                    489,
                    1513,
                    619,
                    492,
                    1770,
                    239,
                    1776,
                    1529,
                    1404
                ],
                "tuple": [
                    1427,
                    1048,
                    923,
                    417,
                    930,
                    1826,
                    1955,
                    1320,
                    945,
                    1971,
                    948,
                    1986,
                    964,
                    464,
                    2001,
                    468,
                    2016,
                    609,
                    2537,
                    494,
                    1134,
                    1008,
                    241,
                    501,
                    1143,
                    634,
                    1147,
                    1399
                ],
                "_": [
                    2720,
                    2818,
                    1645,
                    1551,
                    241,
                    2681,
                    1598
                ],
                "range": [
                    2822,
                    2823,
                    2838,
                    2839,
                    795,
                    797,
                    1567,
                    1320,
                    1582,
                    1332,
                    834,
                    1485,
                    1616,
                    1746,
                    1501,
                    1123,
                    486,
                    489,
                    1770,
                    1645,
                    879,
                    241,
                    2801,
                    1529
                ],
                "broadcast": [
                    249,
                    244
                ],
                "sparse": [
                    245
                ],
                "th_sparse_module.csr_matrix": [
                    247
                ],
                "T.TensorType": [
                    249
                ],
                "x._keras_shape": [
                    1280,
                    1281,
                    1284,
                    1273,
                    1285,
                    1290,
                    1291,
                    1166,
                    1167,
                    1168,
                    1294,
                    1295,
                    1298,
                    1299,
                    1046,
                    1302,
                    409,
                    1306,
                    2076,
                    288,
                    2083,
                    1070,
                    1071,
                    948,
                    1077,
                    1078,
                    1208,
                    1081,
                    1209,
                    1212,
                    1213,
                    1086,
                    960,
                    961,
                    1090,
                    1216,
                    1217,
                    1221,
                    1222,
                    1225,
                    1226,
                    1100,
                    717,
                    1229,
                    1103,
                    1232,
                    594,
                    600,
                    1113,
                    1114,
                    1116,
                    486,
                    488,
                    619,
                    1132,
                    1005,
                    625,
                    501,
                    1272,
                    1145,
                    250,
                    1276,
                    1277
                ],
                "x._uses_learning_phase": [
                    251,
                    933,
                    1685
                ],
                "x._theano_placeholder": [
                    265,
                    252
                ],
                "x.shape": [
                    1159,
                    1164,
                    274,
                    1183,
                    1832,
                    2475,
                    2476,
                    838,
                    2517,
                    2518,
                    1111,
                    2519,
                    1243,
                    2025,
                    2027,
                    368,
                    1141,
                    2038,
                    2040,
                    2042
                ],
                "x.ndim": [
                    866,
                    1731,
                    1092,
                    294,
                    872,
                    463,
                    1042,
                    1332,
                    475,
                    795,
                    797,
                    862
                ],
                "x.dtype": [
                    1832,
                    298,
                    1834,
                    1361,
                    1366,
                    575
                ],
                "eval": [
                    304
                ],
                "to_dense": [
                    304,
                    913
                ],
                "np.zeros": [
                    312
                ],
                "np.eye": [
                    328
                ],
                "size": [
                    328
                ],
                "T.ones_like": [
                    1873,
                    332,
                    1871
                ],
                "T.zeros_like": [
                    336,
                    1865,
                    1867,
                    2670
                ],
                "x.copy": [
                    349
                ],
                "np.random.uniform": [
                    353
                ],
                "np.random": [
                    1824,
                    353,
                    2592,
                    358,
                    2601,
                    2610,
                    2583
                ],
                "low": [
                    353
                ],
                "high": [
                    353
                ],
                "np.random.normal": [
                    358
                ],
                "scale": [
                    358
                ],
                "f": [
                    368,
                    369
                ],
                "theano.function": [
                    368,
                    1406,
                    1391
                ],
                "np.prod": [
                    369,
                    1116,
                    1103
                ],
                "T.cast": [
                    2643,
                    373,
                    1783
                ],
                "new_x": [
                    380
                ],
                "increment": [
                    384
                ],
                "decrement": [
                    388
                ],
                "momentum": [
                    392
                ],
                "out": [
                    480,
                    417,
                    418,
                    481,
                    482,
                    494,
                    495,
                    405,
                    407
                ],
                "th_sparse_module.basic.structured_dot": [
                    405
                ],
                "th_sparse_module.basic": [
                    907,
                    405,
                    909
                ],
                "y": [
                    515,
                    517,
                    518,
                    1147,
                    1043,
                    1044,
                    405,
                    407,
                    408,
                    1048,
                    410,
                    1050,
                    1307,
                    1308,
                    929,
                    931,
                    933,
                    935,
                    936,
                    1067,
                    946,
                    948,
                    949,
                    1205,
                    958,
                    960,
                    963,
                    964,
                    965,
                    1093,
                    711,
                    1094,
                    1098,
                    715,
                    1101,
                    718,
                    463,
                    591,
                    719,
                    594,
                    1103,
                    724,
                    1104,
                    1233,
                    1111,
                    728,
                    1234,
                    1114,
                    732,
                    477,
                    478,
                    1116,
                    480,
                    609,
                    610,
                    736,
                    484,
                    740,
                    1117,
                    616,
                    489,
                    744,
                    491,
                    619,
                    1130,
                    1134,
                    1135,
                    499,
                    501,
                    502,
                    1143,
                    1269,
                    634,
                    635,
                    1148
                ],
                "T.dot": [
                    407
                ],
                "x_shape": [
                    417,
                    409,
                    411,
                    412
                ],
                "list": [
                    1427,
                    917,
                    1046,
                    1559,
                    409,
                    410,
                    795,
                    1567,
                    1825,
                    948,
                    960,
                    1606,
                    1485,
                    464,
                    1616,
                    1746,
                    469,
                    599,
                    600,
                    1501,
                    1770,
                    1132,
                    1005,
                    879,
                    624,
                    625,
                    1141,
                    1399,
                    1145
                ],
                "y_shape": [
                    416,
                    417,
                    410,
                    413,
                    414,
                    415
                ],
                "y._keras_shape": [
                    517,
                    1048,
                    410,
                    1307,
                    931,
                    948,
                    960,
                    963,
                    964,
                    1093,
                    1101,
                    719,
                    1103,
                    1233,
                    594,
                    1114,
                    1116,
                    609,
                    489,
                    491,
                    619,
                    1134,
                    501,
                    634,
                    1147
                ],
                "x_shape.pop": [
                    412
                ],
                "y_shape.pop": [
                    416,
                    414
                ],
                "out._keras_shape": [
                    417,
                    494
                ],
                "axes": [
                    1330,
                    1331,
                    1332,
                    459,
                    460,
                    461,
                    1485,
                    463,
                    464,
                    1486,
                    1616,
                    467,
                    468,
                    469,
                    1617,
                    473,
                    1498,
                    475,
                    476,
                    478,
                    480,
                    487,
                    490
                ],
                "y.ndim": [
                    478,
                    463
                ],
                "a": [
                    631,
                    464,
                    624,
                    699,
                    627,
                    628,
                    630,
                    599,
                    602,
                    603,
                    605,
                    606
                ],
                "transpose": [
                    474,
                    477
                ],
                "T.batched_tensordot": [
                    480
                ],
                "expand_dims": [
                    2080,
                    482,
                    2216,
                    2089,
                    2217,
                    2218,
                    1646,
                    1496,
                    2073
                ],
                "axis": [
                    643,
                    905,
                    906,
                    908,
                    525,
                    911,
                    529,
                    913,
                    535,
                    919,
                    920,
                    922,
                    541,
                    1312,
                    1126,
                    554,
                    1128,
                    687,
                    1129,
                    1843,
                    567,
                    958,
                    577,
                    834,
                    835,
                    961,
                    581,
                    838,
                    963,
                    1731,
                    585,
                    1734,
                    591,
                    1771,
                    593,
                    1747,
                    596,
                    597,
                    1750,
                    599,
                    1754,
                    1755,
                    1756,
                    1124,
                    486,
                    487,
                    488,
                    489,
                    490,
                    491,
                    616,
                    618,
                    621,
                    622,
                    624,
                    877,
                    878,
                    880,
                    881,
                    1133,
                    1142,
                    1774,
                    1778,
                    1779,
                    1146,
                    1780,
                    639
                ],
                "shape.append": [
                    488,
                    491,
                    493
                ],
                "T.transpose": [
                    499
                ],
                "reversed": [
                    501
                ],
                "reference": [
                    515,
                    516,
                    517
                ],
                "indices": [
                    1569,
                    515,
                    516,
                    517,
                    1190,
                    1251,
                    1320,
                    1321,
                    1322,
                    1508,
                    1567,
                    1574,
                    1264,
                    1201,
                    1205,
                    1269,
                    1501,
                    1503
                ],
                "indices._keras_shape": [
                    517
                ],
                "reference._keras_shape": [
                    517
                ],
                "T.max": [
                    2649,
                    2692,
                    525,
                    2646
                ],
                "keepdims": [
                    577,
                    581,
                    616,
                    585,
                    619,
                    525,
                    591,
                    687,
                    529,
                    594,
                    626,
                    535,
                    601,
                    541
                ],
                "T.min": [
                    529
                ],
                "T.sum": [
                    687,
                    1843,
                    2693,
                    535
                ],
                "T.prod": [
                    541,
                    1111
                ],
                "T.extra_ops.cumsum": [
                    554
                ],
                "T.extra_ops": [
                    554,
                    1322,
                    1044,
                    567,
                    1784
                ],
                "T.extra_ops.cumprod": [
                    567
                ],
                "T.mean": [
                    577
                ],
                "T.std": [
                    581
                ],
                "T.var": [
                    585
                ],
                "T.any": [
                    591
                ],
                "axis_list": [
                    622,
                    624,
                    627,
                    597,
                    630,
                    599,
                    602,
                    605
                ],
                "set": [
                    624,
                    599
                ],
                "keras_shape_list": [
                    608,
                    609,
                    632,
                    625,
                    628,
                    631,
                    600,
                    633,
                    634,
                    603,
                    606,
                    607
                ],
                "keras_shape_list.pop": [
                    606,
                    631
                ],
                "T.all": [
                    616
                ],
                "T.argmax": [
                    639
                ],
                "T.argmin": [
                    643
                ],
                "T.sqr": [
                    647
                ],
                "T.abs_": [
                    651
                ],
                "T.clip": [
                    1793,
                    707,
                    1765,
                    655,
                    2619
                ],
                "np.inf": [
                    706,
                    655
                ],
                "T.sqrt": [
                    656,
                    1844
                ],
                "T.exp": [
                    1733,
                    2693,
                    687,
                    660,
                    2650
                ],
                "T.log": [
                    2658,
                    2693,
                    2669,
                    687,
                    664
                ],
                "T.round": [
                    691
                ],
                "T.sgn": [
                    695
                ],
                "T.pow": [
                    699
                ],
                "max_value": [
                    704,
                    705,
                    706,
                    707,
                    1725,
                    1726,
                    703
                ],
                "min_value": [
                    704,
                    707,
                    703
                ],
                "T.eq": [
                    711
                ],
                "z": [
                    720,
                    715,
                    717,
                    719
                ],
                "T.neq": [
                    715,
                    2637
                ],
                "z._keras_shape": [
                    717,
                    719
                ],
                "T.gt": [
                    724
                ],
                "T.ge": [
                    728,
                    1877
                ],
                "T.lt": [
                    732
                ],
                "T.le": [
                    736
                ],
                "T.maximum": [
                    740,
                    1844,
                    2644
                ],
                "T.minimum": [
                    744,
                    2643,
                    1726
                ],
                "T.sin": [
                    748
                ],
                "T.cos": [
                    752
                ],
                "T.nnet.bn": [
                    897,
                    774,
                    785,
                    761,
                    799
                ],
                "T.nnet": [
                    2176,
                    897,
                    1794,
                    2433,
                    774,
                    1798,
                    1802,
                    785,
                    799,
                    2344,
                    1718,
                    1719,
                    1723,
                    1724,
                    2237,
                    1732,
                    2244,
                    1738,
                    2125,
                    2381,
                    1760,
                    1766,
                    1000,
                    2294,
                    761,
                    2301,
                    1791
                ],
                "_old_normalize_batch_in_training": [
                    762
                ],
                "gamma": [
                    768,
                    897,
                    770,
                    772,
                    775,
                    786,
                    788,
                    789,
                    800,
                    809,
                    810,
                    818,
                    844,
                    857,
                    858,
                    870,
                    884,
                    762,
                    891,
                    764,
                    766
                ],
                "beta": [
                    768,
                    769,
                    897,
                    771,
                    772,
                    775,
                    786,
                    790,
                    791,
                    800,
                    811,
                    812,
                    817,
                    843,
                    859,
                    860,
                    869,
                    885,
                    762,
                    891,
                    765
                ],
                "reduction_axes": [
                    800,
                    835,
                    775,
                    815,
                    762,
                    795,
                    797,
                    830,
                    831
                ],
                "epsilon": [
                    800,
                    897,
                    1793,
                    1765,
                    775,
                    847,
                    786,
                    1844,
                    821,
                    888,
                    762,
                    891
                ],
                "ones_like": [
                    768,
                    810,
                    789,
                    858,
                    766
                ],
                "zeros_like": [
                    771,
                    772,
                    1514,
                    812,
                    791,
                    860
                ],
                "normed": [
                    774,
                    777,
                    845,
                    848,
                    820,
                    822,
                    826
                ],
                "mean": [
                    897,
                    774,
                    777,
                    786,
                    791,
                    793,
                    2585,
                    797,
                    800,
                    820,
                    2614,
                    823,
                    2617,
                    826,
                    2619,
                    831,
                    841,
                    848,
                    860,
                    862,
                    867,
                    877,
                    886,
                    891
                ],
                "stdinv": [
                    774,
                    777,
                    820,
                    824,
                    825
                ],
                "T.nnet.bn.batch_normalization_train": [
                    774
                ],
                "T.inv": [
                    777,
                    825
                ],
                "_old_batch_normalization": [
                    786
                ],
                "var": [
                    800,
                    897,
                    868,
                    842,
                    848,
                    786,
                    789,
                    887,
                    825,
                    826,
                    891,
                    858,
                    830
                ],
                "mean.ndim": [
                    793,
                    862
                ],
                "i": [
                    2822,
                    2824,
                    2825,
                    2831,
                    2838,
                    2840,
                    2841,
                    797,
                    1574,
                    1575,
                    1320,
                    1582,
                    1071,
                    1072,
                    1583,
                    1075,
                    1332,
                    1123,
                    1508,
                    1509,
                    1518,
                    1521,
                    2801,
                    2802,
                    2803,
                    1529,
                    1530
                ],
                "mean.broadcastable": [
                    877,
                    797
                ],
                "T.nnet.bn.batch_normalization_test": [
                    799
                ],
                "dev": [
                    873,
                    874,
                    814,
                    815
                ],
                "theano.config.device": [
                    873,
                    814
                ],
                "use_cudnn": [
                    816,
                    874,
                    875,
                    815
                ],
                "dev.startswith": [
                    874,
                    815
                ],
                "broadcast_beta": [
                    817,
                    843,
                    821,
                    846
                ],
                "beta.dimshuffle": [
                    817,
                    885,
                    869
                ],
                "broadcast_gamma": [
                    818,
                    844,
                    821,
                    846
                ],
                "gamma.dimshuffle": [
                    818,
                    884,
                    870
                ],
                "theano.sandbox.cuda.dnn.dnn_batch_normalization_train": [
                    820
                ],
                "theano.sandbox.cuda.dnn": [
                    882,
                    820,
                    890
                ],
                "theano.sandbox.cuda": [
                    882,
                    820,
                    890
                ],
                "theano.sandbox": [
                    882,
                    820,
                    890
                ],
                "theano.tensor.as_tensor_variable": [
                    824,
                    892,
                    822,
                    823
                ],
                "T.flatten": [
                    1321,
                    826,
                    1098,
                    1783
                ],
                "AttributeError": [
                    2065,
                    827,
                    893
                ],
                "x.var": [
                    830
                ],
                "x.mean": [
                    831
                ],
                "target_shape": [
                    833,
                    836,
                    838,
                    839,
                    841,
                    842,
                    843,
                    844
                ],
                "target_shape.append": [
                    836,
                    838
                ],
                "T.stack": [
                    1312,
                    839,
                    1580,
                    1583,
                    1527,
                    1530
                ],
                "broadcast_mean": [
                    841,
                    845
                ],
                "T.reshape": [
                    929,
                    841,
                    842,
                    843,
                    844,
                    1323,
                    1143,
                    1111
                ],
                "broadcast_var": [
                    842,
                    845
                ],
                "batch_normalization": [
                    845
                ],
                "shuffle_pattern": [
                    866,
                    867,
                    868,
                    869,
                    870,
                    879,
                    880,
                    881,
                    883,
                    884,
                    885,
                    886,
                    887,
                    888
                ],
                "mean.dimshuffle": [
                    867,
                    886
                ],
                "var.dimshuffle": [
                    868,
                    887
                ],
                "mean.broadcastable.index": [
                    877
                ],
                "result": [
                    1164,
                    1166,
                    1169,
                    882,
                    890,
                    892
                ],
                "dimshuffle": [
                    882,
                    2684
                ],
                "theano.sandbox.cuda.dnn.dnn_batch_normalization_test": [
                    882,
                    890
                ],
                "x.dimshuffle": [
                    1888,
                    2501,
                    1130,
                    1898,
                    946,
                    1043,
                    883,
                    2460
                ],
                "T.nnet.bn.batch_normalization": [
                    897
                ],
                "sqrt": [
                    897
                ],
                "tensors": [
                    904,
                    905,
                    907,
                    909,
                    913,
                    915,
                    916
                ],
                "output": [
                    1024,
                    1025,
                    1026,
                    1793,
                    1028,
                    1029,
                    1030,
                    1031,
                    1794,
                    2821,
                    907,
                    1163,
                    909,
                    1164,
                    2830,
                    1784,
                    913,
                    2832,
                    2833,
                    2835,
                    923,
                    925,
                    2848,
                    2849,
                    2851,
                    2852,
                    1189,
                    2090,
                    2095,
                    1200,
                    2097,
                    2098,
                    1791,
                    2808,
                    1205,
                    1766,
                    2809,
                    1746,
                    1752,
                    989,
                    990,
                    1757,
                    1760,
                    1250,
                    1763,
                    997,
                    1509,
                    999,
                    1000,
                    1510,
                    1514,
                    1003,
                    1765,
                    1005,
                    1006,
                    1007,
                    1008,
                    1263,
                    1518,
                    1770,
                    1012,
                    1269,
                    1524,
                    1776,
                    1781,
                    1785,
                    1786,
                    1023
                ],
                "th_sparse_module.basic.vstack": [
                    907
                ],
                "th_sparse_module.basic.hstack": [
                    909
                ],
                "T.concatenate": [
                    913,
                    2646
                ],
                "input_shapes": [
                    916,
                    917,
                    918
                ],
                "tensor._keras_shape": [
                    916
                ],
                "output_shape": [
                    2816,
                    2181,
                    2438,
                    1160,
                    1163,
                    917,
                    919,
                    920,
                    922,
                    923,
                    1185,
                    1189,
                    1196,
                    1070,
                    1200,
                    1073,
                    1075,
                    1077,
                    1079,
                    1081,
                    1086,
                    1090,
                    1092,
                    1093,
                    1245,
                    1250,
                    1258,
                    2156,
                    2157,
                    2158,
                    1263,
                    2159,
                    2412,
                    2413,
                    2414,
                    2415,
                    2416
                ],
                "output._keras_shape": [
                    1005,
                    1006,
                    1007,
                    1008,
                    923
                ],
                "y._uses_learning_phase": [
                    933,
                    935
                ],
                "pattern": [
                    1123,
                    1129,
                    1130,
                    945,
                    946,
                    948
                ],
                "T.repeat": [
                    958
                ],
                "rep": [
                    963,
                    958
                ],
                "repeat_dim": [
                    961,
                    962,
                    963
                ],
                "data_format": [
                    2561,
                    1027,
                    2566,
                    1033,
                    2059,
                    2070,
                    2092,
                    2094,
                    2555,
                    2113,
                    2115,
                    2119,
                    2121,
                    2122,
                    2132,
                    2153,
                    2155,
                    2170,
                    2172,
                    2173,
                    2183,
                    1181,
                    2206,
                    1184,
                    2212,
                    2222,
                    2226,
                    2230,
                    1207,
                    2232,
                    2233,
                    2234,
                    2252,
                    1241,
                    1244,
                    2277,
                    2279,
                    2794,
                    2283,
                    2287,
                    2289,
                    2290,
                    2291,
                    1271,
                    2813,
                    2820,
                    2309,
                    2332,
                    2334,
                    2338,
                    2340,
                    2341,
                    2352,
                    2369,
                    2371,
                    2375,
                    2377,
                    2378,
                    2388,
                    1883,
                    1893,
                    2409,
                    2411,
                    2427,
                    2429,
                    2430,
                    2440,
                    2446,
                    2459,
                    1950,
                    1966,
                    2481,
                    2488,
                    2500,
                    979,
                    982,
                    986,
                    2526,
                    996,
                    2532,
                    1002,
                    2539,
                    2028,
                    2544,
                    2550,
                    2043,
                    1022
                ],
                "axis_1": [
                    980,
                    989,
                    1006,
                    983
                ],
                "axis_2": [
                    984,
                    981,
                    990,
                    1007
                ],
                "interpolation": [
                    988,
                    991
                ],
                "repeat_elements": [
                    1024,
                    1025,
                    1028,
                    1029,
                    1030,
                    989,
                    990,
                    1023
                ],
                "height_factor": [
                    992,
                    1024,
                    1029,
                    1001,
                    1006,
                    989
                ],
                "width_factor": [
                    992,
                    1025,
                    1030,
                    1007,
                    990
                ],
                "NotImplementedError": [
                    993,
                    1337
                ],
                "permute_dimensions": [
                    2851,
                    997,
                    1003,
                    2835,
                    1781,
                    1782,
                    2809,
                    1757,
                    1758
                ],
                "T.nnet.abstract_conv.bilinear_upsampling": [
                    1000
                ],
                "T.nnet.abstract_conv": [
                    1000,
                    2433,
                    2176
                ],
                "depth_factor": [
                    1028,
                    1023
                ],
                "T.extra_ops.repeat": [
                    1044
                ],
                "n": [
                    1089,
                    1067,
                    1069,
                    1070,
                    1071,
                    1044,
                    1076,
                    1047,
                    1081,
                    1084,
                    1087
                ],
                "shape.insert": [
                    1133,
                    1047
                ],
                "T.arange": [
                    2631,
                    1063,
                    2636,
                    1876,
                    2684
                ],
                "start": [
                    1063
                ],
                "stop": [
                    1063
                ],
                "step": [
                    2682,
                    1063
                ],
                "T.tile": [
                    1067
                ],
                "_is_explicit_shape": [
                    1069
                ],
                "j": [
                    2823,
                    2826,
                    2827,
                    1071,
                    2831,
                    1075,
                    2839,
                    2842,
                    2843
                ],
                "zip": [
                    1520,
                    1547,
                    1071
                ],
                "n.ndim": [
                    1084
                ],
                "n_size": [
                    1089,
                    1090
                ],
                "n._keras_shape": [
                    1089
                ],
                "x.type.ndim": [
                    1128,
                    1123,
                    1125
                ],
                "x.type": [
                    1128,
                    1123,
                    1125
                ],
                "pattern.insert": [
                    1129
                ],
                "shape.pop": [
                    1142
                ],
                "kshape": [
                    1145,
                    1146,
                    1147
                ],
                "kshape.pop": [
                    1146
                ],
                "padding": [
                    2432,
                    1281,
                    2307,
                    1158,
                    2182,
                    2439,
                    1161,
                    1291,
                    1164,
                    1932,
                    1934,
                    1167,
                    1295,
                    1936,
                    2062,
                    1299,
                    1939,
                    2068,
                    2450,
                    2454,
                    1176,
                    1177,
                    1178,
                    1179,
                    1180,
                    2457,
                    2342,
                    2474,
                    2091,
                    2351,
                    2490,
                    2235,
                    2495,
                    2498,
                    2250,
                    2123,
                    2379,
                    2131,
                    2387,
                    2516,
                    1247,
                    1248,
                    1249,
                    1253,
                    1254,
                    1255,
                    2023,
                    1259,
                    1260,
                    1261,
                    1265,
                    1266,
                    1267,
                    2036,
                    2165,
                    2292,
                    2422,
                    1273,
                    1277,
                    2175
                ],
                "input_shape": [
                    1159,
                    1160,
                    1161,
                    1162,
                    1183,
                    1185,
                    1186,
                    1187,
                    1188,
                    1192,
                    1193,
                    1320,
                    1323,
                    1196,
                    1197,
                    1198,
                    1199,
                    1202,
                    1203,
                    1243,
                    1245,
                    1246,
                    1247,
                    1248,
                    1249,
                    1253,
                    1254,
                    1255,
                    1258,
                    1259,
                    1260,
                    1261,
                    1262,
                    1265,
                    1266,
                    1267
                ],
                "T.zeros": [
                    1250,
                    1189,
                    1163,
                    1263,
                    1200
                ],
                "T.set_subtensor": [
                    2660,
                    2631,
                    1164,
                    1269,
                    1205,
                    2653
                ],
                "result._keras_shape": [
                    1166
                ],
                "top_pad": [
                    1187,
                    1222,
                    1192,
                    1197,
                    1202,
                    1209,
                    1179
                ],
                "bottom_pad": [
                    1187,
                    1222,
                    1197,
                    1209,
                    1179
                ],
                "left_pad": [
                    1188,
                    1193,
                    1226,
                    1198,
                    2066,
                    1203,
                    2067,
                    1180,
                    1213
                ],
                "right_pad": [
                    1188,
                    1226,
                    1198,
                    1180,
                    1213
                ],
                "normalize_data_format": [
                    2113,
                    2369,
                    2532,
                    2277,
                    2153,
                    2409,
                    2059,
                    2794,
                    2813,
                    2446,
                    2488,
                    1241,
                    2332,
                    1181,
                    2206
                ],
                "h": [
                    1218,
                    1273,
                    1222,
                    1286,
                    1224,
                    1291,
                    1293,
                    1230,
                    1275,
                    1303,
                    1209,
                    1211
                ],
                "w": [
                    1219,
                    1279,
                    1287,
                    1226,
                    1228,
                    1231,
                    1295,
                    1297,
                    1304,
                    1277,
                    1213,
                    1215
                ],
                "output_keras_shape": [
                    1216,
                    1284,
                    1229,
                    1233,
                    1302,
                    1307
                ],
                "d": [
                    1281,
                    1283,
                    1288,
                    1299,
                    1301,
                    1305
                ],
                "indices.shape": [
                    1320
                ],
                "indices.ndim": [
                    1320
                ],
                "oh": [
                    1322,
                    1323,
                    1324
                ],
                "T.extra_ops.to_one_hot": [
                    1784,
                    1322
                ],
                "num_classes": [
                    1322,
                    1323
                ],
                "slices": [
                    1332,
                    1333
                ],
                "T.patternbroadcast": [
                    1835,
                    1341
                ],
                "broadcastable": [
                    1341
                ],
                "TypeError": [
                    1348,
                    1866,
                    1980,
                    1964,
                    1995,
                    1872,
                    2616,
                    2010,
                    1948
                ],
                "x.get_value": [
                    1370,
                    1350
                ],
                "get_value": [
                    1357
                ],
                "xs": [
                    1357,
                    2800,
                    2804,
                    2837,
                    2806,
                    2844,
                    2847
                ],
                "x.set_value": [
                    1361,
                    1366
                ],
                "tuples": [
                    1365
                ],
                "p_op": [
                    1377,
                    1378
                ],
                "Print": [
                    1377
                ],
                "message": [
                    1377
                ],
                "object": [
                    1383
                ],
                "unique_variables_to_update": [
                    1386,
                    1388,
                    1389,
                    1390
                ],
                "v": [
                    2016,
                    1986,
                    1955,
                    1387,
                    1388,
                    1389,
                    2001,
                    1971
                ],
                "nv": [
                    1387,
                    1389
                ],
                "updates": [
                    1409,
                    1387,
                    1390,
                    1391
                ],
                "unique_variables_to_update.items": [
                    1390
                ],
                "self.function": [
                    1400,
                    1391
                ],
                "self": [
                    1400,
                    1396,
                    1391
                ],
                "inputs": [
                    1600,
                    1409,
                    1476,
                    1509,
                    1540,
                    1575,
                    2828,
                    1486,
                    1391,
                    1553,
                    1587,
                    2804,
                    1399,
                    1400,
                    2844,
                    1533
                ],
                "outputs": [
                    1409,
                    1540,
                    1541,
                    1545,
                    1549,
                    1560,
                    1563,
                    1575,
                    1576,
                    1578,
                    1580,
                    1587,
                    1588,
                    1591,
                    1607,
                    1610,
                    1613,
                    1614,
                    1616,
                    1617,
                    1620,
                    1391,
                    1527
                ],
                "kwargs": [
                    1409,
                    1395,
                    1404,
                    1405
                ],
                "self.name": [
                    1396
                ],
                "key": [
                    1405,
                    1406,
                    1407
                ],
                "kwargs.keys": [
                    1405
                ],
                "has_arg": [
                    1406
                ],
                "msg": [
                    1408,
                    1407
                ],
                "Function": [
                    1409
                ],
                "T.grad": [
                    1413
                ],
                "loss": [
                    1413
                ],
                "variables": [
                    1427,
                    1428,
                    1413,
                    1430
                ],
                "map": [
                    1428
                ],
                "theano.gradient.disconnected_grad": [
                    1428,
                    1430
                ],
                "theano.gradient": [
                    1428,
                    1430
                ],
                "inputs.ndim": [
                    1476
                ],
                "unroll": [
                    1500,
                    1566,
                    1479
                ],
                "input_length": [
                    1480,
                    2723,
                    1501,
                    1567
                ],
                "inputs.dimshuffle": [
                    1486
                ],
                "constants": [
                    1602,
                    1509,
                    1575,
                    1488,
                    1489,
                    1555,
                    1533
                ],
                "uses_learning_phase": [
                    1543,
                    1511,
                    1577,
                    1619,
                    1492,
                    1684,
                    1590,
                    1661,
                    1663
                ],
                "mask": [
                    2691,
                    2693,
                    1545,
                    1548,
                    1518,
                    1521,
                    1553,
                    1494,
                    1495,
                    1496,
                    1497,
                    1498,
                    2685,
                    2687
                ],
                "mask.ndim": [
                    1497,
                    1495
                ],
                "mask.dimshuffle": [
                    1498
                ],
                "go_backwards": [
                    1568,
                    1603,
                    1556,
                    1502
                ],
                "successive_outputs": [
                    1505,
                    1571,
                    1513,
                    1578,
                    1516,
                    1580,
                    1524,
                    1527
                ],
                "successive_states": [
                    1506,
                    1572,
                    1579,
                    1582,
                    1583,
                    1525,
                    1529,
                    1530
                ],
                "states": [
                    1540,
                    1547,
                    1561,
                    1564,
                    1573,
                    1575,
                    1579,
                    1581,
                    1583,
                    1587,
                    1608,
                    1611,
                    1618,
                    1620,
                    1507,
                    1509,
                    1520,
                    1522,
                    1525,
                    1528,
                    1530
                ],
                "initial_states": [
                    1536,
                    1537,
                    1601,
                    1507,
                    1573,
                    1554,
                    1595,
                    1596,
                    1533
                ],
                "new_states": [
                    1540,
                    1509,
                    1547,
                    1520,
                    1587,
                    1591
                ],
                "step_function": [
                    1540,
                    1509,
                    1575,
                    1587,
                    1533
                ],
                "getattr": [
                    1576,
                    1588,
                    1541,
                    1510
                ],
                "prev_output": [
                    1514,
                    1516,
                    1518
                ],
                "T.switch": [
                    1545,
                    1548,
                    1518,
                    1647,
                    1521
                ],
                "kept_states": [
                    1521,
                    1522,
                    1519
                ],
                "state": [
                    1547,
                    1548,
                    1520,
                    1521,
                    1618
                ],
                "new_state": [
                    1520,
                    1521,
                    1547,
                    1548
                ],
                "kept_states.append": [
                    1521
                ],
                "successive_outputs.append": [
                    1578,
                    1524
                ],
                "successive_states.append": [
                    1579,
                    1525
                ],
                "states.append": [
                    1530,
                    1583
                ],
                "states_at_step": [
                    1530,
                    1583
                ],
                "initial_output": [
                    1554,
                    1533,
                    1535
                ],
                "T.unbroadcast": [
                    1537,
                    1596,
                    1535
                ],
                "output_tm1": [
                    1545
                ],
                "return_states": [
                    1546,
                    1548,
                    1549
                ],
                "return_states.append": [
                    1548
                ],
                "results": [
                    1606,
                    1607,
                    1608,
                    1610,
                    1551,
                    1559,
                    1560,
                    1561,
                    1563,
                    1598
                ],
                "theano.scan": [
                    2720,
                    2681,
                    1598,
                    1551
                ],
                "_step": [
                    1552,
                    1599
                ],
                "T.squeeze": [
                    1618,
                    1613
                ],
                "last_output": [
                    1619,
                    1620,
                    1614
                ],
                "outputs.ndim": [
                    1616
                ],
                "outputs.dimshuffle": [
                    1617
                ],
                "last_output._uses_learning_phase": [
                    1619
                ],
                "callable": [
                    1666,
                    1637,
                    1639,
                    1672,
                    1677,
                    1679
                ],
                "then_expression": [
                    1642,
                    1637,
                    1638,
                    1647
                ],
                "else_expression": [
                    1640,
                    1647,
                    1639
                ],
                "cond_ndim": [
                    1641,
                    1643,
                    1644
                ],
                "condition": [
                    1641,
                    1646,
                    1647
                ],
                "expr_ndim": [
                    1642,
                    1643,
                    1644
                ],
                "ndim_diff": [
                    1644,
                    1645
                ],
                "training": [
                    1696,
                    1665,
                    1671,
                    1683,
                    1659,
                    1660
                ],
                "learning_phase": [
                    1660
                ],
                "alt": [
                    1696,
                    1672,
                    1673,
                    1675,
                    1679,
                    1680,
                    1683
                ],
                "ifelse": [
                    1683
                ],
                "in_train_phase": [
                    1696
                ],
                "module": [
                    1702
                ],
                "func": [
                    1702
                ],
                "EnvironmentError": [
                    1703
                ],
                "_assert_has_capability": [
                    1723,
                    1718
                ],
                "T.nnet.elu": [
                    1719
                ],
                "alpha": [
                    2668,
                    1724,
                    1719
                ],
                "T.nnet.relu": [
                    1724
                ],
                "T.nnet.softmax": [
                    1760,
                    1732
                ],
                "x.max": [
                    1733,
                    1734
                ],
                "T.nnet.softplus": [
                    1738
                ],
                "T_softsign": [
                    1742
                ],
                "output_dimensions": [
                    1770,
                    1771,
                    1746,
                    1747,
                    1778,
                    1779,
                    1780,
                    1754,
                    1755,
                    1756
                ],
                "int_shape": [
                    2817,
                    2061,
                    2069,
                    2334,
                    2335,
                    2222,
                    2223,
                    2227,
                    2115,
                    2116,
                    2371,
                    2372,
                    1869,
                    1746,
                    1752,
                    2279,
                    2280,
                    1770,
                    2284,
                    2797,
                    1776,
                    2161,
                    2418
                ],
                "format": [
                    1773,
                    1774,
                    1776,
                    1749,
                    1750,
                    1752
                ],
                "permutation": [
                    1779,
                    1780,
                    1781,
                    1782,
                    1755,
                    1756,
                    1757,
                    1758
                ],
                "target": [
                    1794,
                    1766,
                    1782,
                    1783,
                    1784,
                    1785,
                    1786,
                    1758
                ],
                "from_logits": [
                    1786,
                    1790,
                    1759
                ],
                "output.sum": [
                    1763
                ],
                "T.nnet.categorical_crossentropy": [
                    1766
                ],
                "output.shape": [
                    1784
                ],
                "reshape": [
                    2563,
                    2565,
                    2568,
                    2570,
                    2828,
                    2833,
                    2844,
                    2849,
                    2541,
                    2543,
                    2546,
                    2548,
                    2804,
                    2552,
                    1785,
                    2554,
                    2557,
                    1918,
                    2559
                ],
                "categorical_crossentropy": [
                    1786
                ],
                "T.nnet.sigmoid": [
                    1798,
                    1791
                ],
                "T.nnet.binary_crossentropy": [
                    1794
                ],
                "T.nnet.hard_sigmoid": [
                    1802
                ],
                "T.tanh": [
                    1806
                ],
                "level": [
                    1829,
                    1821
                ],
                "seed": [
                    1824,
                    2592,
                    2593,
                    1828,
                    2600,
                    2601,
                    2602,
                    2591,
                    2609,
                    2610,
                    2611,
                    2582,
                    2583,
                    2584,
                    1823
                ],
                "np.random.randint": [
                    1824,
                    2592,
                    2601,
                    2610,
                    2583
                ],
                "noise_shape": [
                    1825,
                    1826,
                    1831,
                    1834,
                    1836
                ],
                "rng": [
                    2593,
                    2594,
                    1828,
                    1832,
                    1834,
                    2602,
                    2603,
                    2617,
                    2611,
                    2614,
                    2584,
                    2585
                ],
                "RandomStreams": [
                    2593,
                    1828,
                    2602,
                    2611,
                    2584
                ],
                "retain_prob": [
                    1832,
                    1834,
                    1829,
                    1838
                ],
                "random_tensor": [
                    1832,
                    1834,
                    1835,
                    1837
                ],
                "rng.binomial": [
                    1832,
                    1834,
                    2603
                ],
                "dim": [
                    1836
                ],
                "square_sum": [
                    1843,
                    1844
                ],
                "T.square": [
                    1843
                ],
                "norm": [
                    1844,
                    1845
                ],
                "k": [
                    1875,
                    1869,
                    1862
                ],
                "targets": [
                    1865,
                    1867,
                    1871,
                    1873,
                    1876
                ],
                "predictions": [
                    1875,
                    1876,
                    1869
                ],
                "predictions_k": [
                    1875,
                    1877
                ],
                "T.sort": [
                    1875
                ],
                "targets_values": [
                    1876,
                    1877
                ],
                "targets.shape": [
                    1876
                ],
                "kernel": [
                    2817,
                    2181,
                    2438,
                    1927,
                    1928,
                    2061,
                    2831,
                    2848,
                    2089,
                    2090,
                    1917,
                    2430,
                    2116,
                    2372,
                    2118,
                    2374,
                    2122,
                    2378,
                    2125,
                    2381,
                    2797,
                    2161,
                    2418,
                    1907,
                    1908,
                    2163,
                    2420,
                    2808,
                    1916,
                    2173,
                    1918,
                    1919
                ],
                "kernel.dimshuffle": [
                    1907,
                    1917,
                    1927
                ],
                "kernel_shape": [
                    2177,
                    2434,
                    2817,
                    2818,
                    2183,
                    2440,
                    2061,
                    2064,
                    2066,
                    2427,
                    2116,
                    2117,
                    2118,
                    2119,
                    2372,
                    2373,
                    2374,
                    2375,
                    2129,
                    2385,
                    2132,
                    2388,
                    2024,
                    2026,
                    2797,
                    2798,
                    2161,
                    2162,
                    2163,
                    2418,
                    2037,
                    2165,
                    2039,
                    2419,
                    2041,
                    2170,
                    2420,
                    2422,
                    1918
                ],
                "th_padding": [
                    2432,
                    2179,
                    2436,
                    1933,
                    1935,
                    1937,
                    1940,
                    2342,
                    2345,
                    2235,
                    2238,
                    2245,
                    2123,
                    2379,
                    2126,
                    2382,
                    2292,
                    2295,
                    2302,
                    2175
                ],
                "image_shape": [
                    1952,
                    2240,
                    1954,
                    1955,
                    1956,
                    2115,
                    2243,
                    2279,
                    2347,
                    2222,
                    2350,
                    2128,
                    2297,
                    2300,
                    2334,
                    1951
                ],
                "transpose_shape": [
                    1952
                ],
                "int_or_none": [
                    2016,
                    1986,
                    1955,
                    2001,
                    1971
                ],
                "volume_shape": [
                    2371,
                    1967,
                    1968,
                    1969,
                    1970,
                    1971,
                    1972,
                    2384
                ],
                "filter_shape": [
                    1984,
                    1985,
                    1986,
                    1987,
                    2016,
                    2017,
                    1997,
                    1998,
                    1999,
                    2000,
                    2001,
                    2002,
                    2014,
                    2015,
                    2012,
                    2013,
                    1982,
                    1983
                ],
                "conv_out": [
                    2307,
                    2181,
                    2182,
                    2310,
                    2184,
                    2438,
                    2439,
                    2441,
                    2344,
                    2351,
                    2353,
                    2301,
                    2237,
                    2244,
                    2250,
                    2125,
                    2253,
                    2254,
                    2381,
                    2131,
                    2387,
                    2133,
                    2389,
                    2025,
                    2027,
                    2029,
                    2030,
                    2038,
                    2294,
                    2040,
                    2042,
                    2044,
                    2045
                ],
                "strides": [
                    2178,
                    2435,
                    2309,
                    2183,
                    2440,
                    2040,
                    2207,
                    2208,
                    2463,
                    2468,
                    2086,
                    2346,
                    2091,
                    2219,
                    2475,
                    2476,
                    2352,
                    2239,
                    2504,
                    2252,
                    2509,
                    2127,
                    2383,
                    2132,
                    2388,
                    2517,
                    2518,
                    2519,
                    2025,
                    2027,
                    2796,
                    2038,
                    2296,
                    2042,
                    2815
                ],
                "conv_out.dimshuffle": [
                    2044,
                    2029
                ],
                "dilation_rate": [
                    2209,
                    2210,
                    2242,
                    2306,
                    2085,
                    2249,
                    2092,
                    2220,
                    2349,
                    2066,
                    2130,
                    2386,
                    2299
                ],
                "temporal_padding": [
                    2067
                ],
                "conv2d": [
                    2090
                ],
                "squeeze": [
                    2097,
                    2253,
                    2095
                ],
                "_preprocess_conv2d_image_shape": [
                    2115,
                    2334,
                    2222,
                    2279
                ],
                "kernel.eval": [
                    2374,
                    2163,
                    2420,
                    2118
                ],
                "_preprocess_conv2d_filter_shape": [
                    2170,
                    2287,
                    2230,
                    2119
                ],
                "_preprocess_conv2d_input": [
                    2340,
                    2121,
                    2289,
                    2232,
                    2172
                ],
                "_preprocess_conv2d_kernel": [
                    2234,
                    2122,
                    2291,
                    2173
                ],
                "_preprocess_padding": [
                    2432,
                    2342,
                    2123,
                    2379,
                    2292,
                    2235,
                    2175
                ],
                "T.nnet.conv2d": [
                    2244,
                    2344,
                    2125,
                    2294,
                    2237,
                    2301
                ],
                "_postprocess_conv2d_output": [
                    2307,
                    2182,
                    2250,
                    2351,
                    2131
                ],
                "flip_filters": [
                    2152,
                    2180,
                    2437,
                    2408
                ],
                "op": [
                    2176,
                    2433,
                    2181,
                    2438
                ],
                "T.nnet.abstract_conv.AbstractConv2d_gradInputs": [
                    2176
                ],
                "spatial_start_dim": [
                    2216,
                    2253,
                    2213,
                    2215
                ],
                "depthwise_kernel": [
                    2337,
                    2341,
                    2280,
                    2217,
                    2282,
                    2344,
                    2223,
                    2225,
                    2290,
                    2294,
                    2233,
                    2237,
                    2335
                ],
                "pointwise_kernel": [
                    2244,
                    2218,
                    2284,
                    2286,
                    2227,
                    2291,
                    2229,
                    2234,
                    2301
                ],
                "depthwise_kernel_shape": [
                    2335,
                    2336,
                    2337,
                    2338,
                    2341,
                    2348,
                    2223,
                    2224,
                    2225,
                    2226,
                    2352,
                    2233,
                    2241,
                    2280,
                    2281,
                    2282,
                    2283,
                    2290,
                    2298
                ],
                "depthwise_kernel.eval": [
                    2225,
                    2282,
                    2337
                ],
                "_preprocess_conv2d_depthwise_filter_shape": [
                    2226,
                    2283,
                    2338
                ],
                "pointwise_kernel_shape": [
                    2305,
                    2308,
                    2248,
                    2251,
                    2284,
                    2285,
                    2286,
                    2287,
                    2227,
                    2228,
                    2229,
                    2230
                ],
                "pointwise_kernel.eval": [
                    2229,
                    2286
                ],
                "_preprocess_conv2d_depthwise_kernel": [
                    2233,
                    2290,
                    2341
                ],
                "_preprocess_conv3d_volume_shape": [
                    2371
                ],
                "_preprocess_conv3d_filter_shape": [
                    2427,
                    2375
                ],
                "_preprocess_conv3d_input": [
                    2377,
                    2429
                ],
                "_preprocess_conv3d_kernel": [
                    2378,
                    2430
                ],
                "T.nnet.conv3d": [
                    2381
                ],
                "_postprocess_conv3d_output": [
                    2387,
                    2439
                ],
                "T.nnet.abstract_conv.AbstractConv3d_gradInputs": [
                    2433
                ],
                "pool_size": [
                    2468,
                    2504,
                    2509,
                    2448,
                    2451,
                    2452,
                    2491,
                    2492,
                    2493,
                    2463
                ],
                "w_pad": [
                    2451,
                    2491,
                    2453,
                    2494
                ],
                "h_pad": [
                    2492,
                    2452,
                    2453,
                    2494
                ],
                "pad": [
                    2496,
                    2465,
                    2470,
                    2506,
                    2511,
                    2453,
                    2455,
                    2494
                ],
                "pool_mode": [
                    2467,
                    2503,
                    2473,
                    2508,
                    2514,
                    2462
                ],
                "pool_out": [
                    2528,
                    2468,
                    2504,
                    2527,
                    2477,
                    2509,
                    2482,
                    2483,
                    2521,
                    2463
                ],
                "pool.pool_2d": [
                    2468,
                    2463
                ],
                "pool": [
                    2504,
                    2468,
                    2509,
                    2463
                ],
                "expected_width": [
                    2522,
                    2475,
                    2517,
                    2478
                ],
                "expected_height": [
                    2523,
                    2476,
                    2518,
                    2479
                ],
                "pool_out.dimshuffle": [
                    2482,
                    2527
                ],
                "d_pad": [
                    2493,
                    2494
                ],
                "pool.pool_3d": [
                    2504,
                    2509
                ],
                "expected_depth": [
                    2524,
                    2519
                ],
                "bias": [
                    2562,
                    2563,
                    2565,
                    2567,
                    2568,
                    2570,
                    2572,
                    2533,
                    2536,
                    2537,
                    2540,
                    2541,
                    2543,
                    2545,
                    2546,
                    2548,
                    2551,
                    2552,
                    2554,
                    2556,
                    2557,
                    2559
                ],
                "bias_shape": [
                    2563,
                    2565,
                    2568,
                    2537,
                    2570,
                    2541,
                    2543,
                    2546,
                    2548,
                    2552,
                    2554,
                    2557,
                    2559
                ],
                "bias.shape": [
                    2537
                ],
                "rng.normal": [
                    2585,
                    2614,
                    2617
                ],
                "stddev": [
                    2585,
                    2619,
                    2614,
                    2617
                ],
                "rng.uniform": [
                    2594
                ],
                "minval": [
                    2594
                ],
                "maxval": [
                    2594
                ],
                "p": [
                    2603
                ],
                "normal_t": [
                    2617,
                    2619
                ],
                "Y_": [
                    2632,
                    2630,
                    2631
                ],
                "T.alloc": [
                    2630
                ],
                "Y.shape": [
                    2668,
                    2636,
                    2630,
                    2631
                ],
                "Y": [
                    2691,
                    2630,
                    2631,
                    2668,
                    2636,
                    2637,
                    2673,
                    2674
                ],
                "skip_idxs": [
                    2642,
                    2636,
                    2637,
                    2638
                ],
                "non_repeats": [
                    2637,
                    2638
                ],
                "non_repeats.nonzero": [
                    2638
                ],
                "active_skip_idxs": [
                    2657,
                    2642,
                    2646
                ],
                "nonzero": [
                    2642
                ],
                "active": [
                    2642,
                    2645,
                    2649,
                    2650,
                    2653
                ],
                "active_next": [
                    2661,
                    2662,
                    2664,
                    2643,
                    2651
                ],
                "log_p_curr.shape": [
                    2647
                ],
                "log_p_curr": [
                    2662,
                    2647
                ],
                "common_factor": [
                    2658,
                    2692,
                    2693,
                    2649,
                    2650
                ],
                "log_p_prev": [
                    2649,
                    2650
                ],
                "p_prev": [
                    2657,
                    2650,
                    2653
                ],
                "_p_prev": [
                    2657,
                    2658,
                    2651,
                    2653,
                    2655
                ],
                "zeros": [
                    2661,
                    2670,
                    2671,
                    2677,
                    2678,
                    2651
                ],
                "T.inc_subtensor": [
                    2657,
                    2655
                ],
                "updated_log_p_prev": [
                    2658,
                    2662
                ],
                "log_p_next": [
                    2664,
                    2660
                ],
                "smoothed_predict": [
                    2668,
                    2669
                ],
                "predict": [
                    2691,
                    2668
                ],
                "np.float32": [
                    2668
                ],
                "L": [
                    2669,
                    2670,
                    2682,
                    2684,
                    2686
                ],
                "log_first": [
                    2682,
                    2671
                ],
                "f_skip_idxs": [
                    2673,
                    2677
                ],
                "ctc_create_skip_idxs": [
                    2673,
                    2674
                ],
                "b_skip_idxs": [
                    2674,
                    2678
                ],
                "f_active_next": [
                    2677,
                    2679
                ],
                "log_f_next": [
                    2677,
                    2679
                ],
                "ctc_update_log_p": [
                    2677,
                    2678
                ],
                "f_active": [
                    2681,
                    2685,
                    2677
                ],
                "log_f_curr": [
                    2677
                ],
                "log_f_prev": [
                    2677
                ],
                "b_active_next": [
                    2678,
                    2679
                ],
                "log_b_next": [
                    2678,
                    2679
                ],
                "b_active": [
                    2681,
                    2685,
                    2678
                ],
                "log_b_curr": [
                    2678
                ],
                "log_b_prev": [
                    2678
                ],
                "log_f_probs": [
                    2681,
                    2686
                ],
                "log_b_probs": [
                    2681,
                    2686
                ],
                "np.int32": [
                    2682
                ],
                "idxs": [
                    2684,
                    2685
                ],
                "L.shape": [
                    2684
                ],
                "f_active.dimshuffle": [
                    2685
                ],
                "b_active.dimshuffle": [
                    2685
                ],
                "log_probs": [
                    2691,
                    2692,
                    2693,
                    2686,
                    2687
                ],
                "ctc_path_probs": [
                    2691
                ],
                "ctc_interleave_blanks": [
                    2691
                ],
                "total_log_prob": [
                    2693,
                    2694
                ],
                "mask.nonzero": [
                    2693
                ],
                "y_pred_step": [
                    2716,
                    2718
                ],
                "input_length_step": [
                    2716
                ],
                "y_true_step": [
                    2717,
                    2718
                ],
                "label_length_step": [
                    2717
                ],
                "ctc_cost": [
                    2718
                ],
                "ret": [
                    2720,
                    2726,
                    2727
                ],
                "ctc_step": [
                    2721
                ],
                "y_true": [
                    2723
                ],
                "y_pred": [
                    2723
                ],
                "label_length": [
                    2723
                ],
                "ret.dimshuffle": [
                    2726
                ],
                "theano.map": [
                    2744
                ],
                "fn": [
                    2744,
                    2789,
                    2766
                ],
                "elems": [
                    2784,
                    2785,
                    2790,
                    2761,
                    2762,
                    2767,
                    2744
                ],
                "initializer": [
                    2784,
                    2790,
                    2760,
                    2761,
                    2767,
                    2783
                ],
                "theano.foldl": [
                    2766
                ],
                "acc": [
                    2789,
                    2766
                ],
                "theano.foldr": [
                    2789
                ],
                "stride": [
                    2802,
                    2803,
                    2796
                ],
                "output_length": [
                    2801,
                    2798
                ],
                "feature_dim": [
                    2818,
                    2829,
                    2798,
                    2805,
                    2845
                ],
                "filters": [
                    2818,
                    2834,
                    2850,
                    2798
                ],
                "slice_length": [
                    2802,
                    2804
                ],
                "kernel_size": [
                    2825,
                    2827,
                    2803,
                    2841,
                    2843
                ],
                "xs.append": [
                    2804,
                    2844
                ],
                "x_aggregate": [
                    2808,
                    2848,
                    2806,
                    2847
                ],
                "concatenate": [
                    2832,
                    2806,
                    2847
                ],
                "batch_dot": [
                    2808,
                    2848
                ],
                "stride_row": [
                    2824,
                    2825,
                    2840,
                    2841,
                    2815
                ],
                "stride_col": [
                    2826,
                    2827,
                    2842,
                    2843,
                    2815
                ],
                "output_row": [
                    2816,
                    2850,
                    2822,
                    2834,
                    2838
                ],
                "output_col": [
                    2816,
                    2850,
                    2823,
                    2831,
                    2834,
                    2839
                ],
                "slice_row": [
                    2824,
                    2840,
                    2828,
                    2844
                ],
                "slice_col": [
                    2826,
                    2842,
                    2828,
                    2844
                ],
                "x_flatten": [
                    2828,
                    2830
                ],
                "output.append": [
                    2830
                ],
                "dot": [
                    2830
                ]
            },
            "filtered_variables_in_file": {
                "th_sparse_module": [
                    98,
                    907,
                    909,
                    16,
                    148,
                    405,
                    87,
                    247,
                    93
                ],
                "py_all": [
                    904,
                    915,
                    31
                ],
                "py_any": [
                    32,
                    464
                ],
                "py_sum": [
                    33,
                    1167
                ],
                "py_slice": [
                    2824,
                    2826,
                    2840,
                    2842,
                    34,
                    1190,
                    1191,
                    1192,
                    1193,
                    1201,
                    1202,
                    1203,
                    1204,
                    1332,
                    1251,
                    1252,
                    1253,
                    1254,
                    1255,
                    1264,
                    1265,
                    1266,
                    1267,
                    1268,
                    2802
                ],
                "theano.config.floatX": [
                    38
                ],
                "theano.config": [
                    814,
                    873,
                    38
                ],
                "theano": [
                    1551,
                    1428,
                    1430,
                    151,
                    152,
                    153,
                    157,
                    2720,
                    38,
                    814,
                    820,
                    822,
                    823,
                    824,
                    2744,
                    1598,
                    2766,
                    2789,
                    873,
                    1391,
                    368,
                    882,
                    2681,
                    890,
                    892,
                    1406
                ],
                "floatx": [
                    576,
                    38,
                    327,
                    168,
                    2599,
                    235,
                    2608,
                    145,
                    2581,
                    311,
                    2590,
                    319
                ],
                "_LEARNING_PHASE": [
                    53,
                    45,
                    39
                ],
                "T.scalar": [
                    39
                ],
                "T": [
                    1537,
                    1545,
                    1548,
                    525,
                    529,
                    1044,
                    535,
                    541,
                    39,
                    1063,
                    554,
                    1067,
                    1580,
                    1583,
                    567,
                    2619,
                    1596,
                    577,
                    581,
                    2630,
                    2631,
                    585,
                    1098,
                    2636,
                    1613,
                    2125,
                    591,
                    2637,
                    1618,
                    2643,
                    2644,
                    2646,
                    1111,
                    2649,
                    2650,
                    2653,
                    2655,
                    2657,
                    2658,
                    2660,
                    616,
                    2669,
                    2670,
                    1647,
                    1143,
                    2684,
                    639,
                    2176,
                    643,
                    2692,
                    2693,
                    647,
                    651,
                    1163,
                    1164,
                    655,
                    656,
                    660,
                    664,
                    1189,
                    172,
                    687,
                    1200,
                    691,
                    1205,
                    1718,
                    695,
                    1719,
                    699,
                    1723,
                    1724,
                    1726,
                    2237,
                    707,
                    1732,
                    1733,
                    2244,
                    711,
                    1738,
                    715,
                    724,
                    728,
                    732,
                    736,
                    1760,
                    1250,
                    227,
                    228,
                    740,
                    1765,
                    1766,
                    744,
                    748,
                    1263,
                    752,
                    1269,
                    2294,
                    1783,
                    1784,
                    761,
                    249,
                    2301,
                    1791,
                    1793,
                    1794,
                    774,
                    1798,
                    777,
                    1802,
                    1806,
                    785,
                    799,
                    1312,
                    2344,
                    1321,
                    1322,
                    1323,
                    1835,
                    1843,
                    1844,
                    825,
                    826,
                    1341,
                    839,
                    841,
                    842,
                    843,
                    332,
                    844,
                    1865,
                    1867,
                    336,
                    1871,
                    1873,
                    1875,
                    1876,
                    1877,
                    2381,
                    373,
                    897,
                    2433,
                    1413,
                    913,
                    407,
                    929,
                    958,
                    480,
                    1000,
                    1518,
                    1521,
                    499,
                    1527,
                    1530,
                    1535
                ],
                "_UID_PREFIXES": [
                    40,
                    80,
                    74,
                    75
                ],
                "defaultdict": [
                    40,
                    80
                ],
                "value": [
                    392,
                    146,
                    149,
                    151,
                    1947,
                    155,
                    156,
                    157,
                    160,
                    171,
                    1963,
                    50,
                    53,
                    1979,
                    1994,
                    1361,
                    1365,
                    1366,
                    2009
                ],
                "prefix": [
                    128,
                    74,
                    75,
                    125,
                    127
                ],
                "tensor.type": [
                    93
                ],
                "tensor": [
                    97,
                    98,
                    100,
                    915,
                    916,
                    93
                ],
                "th_sparse_module.SparseType": [
                    93
                ],
                "is_sparse": [
                    904,
                    97,
                    404
                ],
                "th_sparse_module.dense_from_sparse": [
                    98
                ],
                "shape": [
                    2069,
                    918,
                    919,
                    1046,
                    1047,
                    922,
                    1048,
                    2075,
                    2076,
                    2585,
                    929,
                    930,
                    931,
                    2082,
                    2083,
                    2337,
                    2594,
                    169,
                    170,
                    171,
                    2286,
                    2603,
                    175,
                    2225,
                    2229,
                    2614,
                    312,
                    2617,
                    320,
                    2118,
                    2374,
                    1143,
                    1370,
                    2282,
                    353,
                    485,
                    358,
                    104,
                    105,
                    488,
                    491,
                    236,
                    492,
                    238,
                    239,
                    493,
                    241,
                    494,
                    1132,
                    1133,
                    1134,
                    1141,
                    1142,
                    2163,
                    1785,
                    250,
                    2420
                ],
                "x": [
                    2067,
                    2069,
                    2073,
                    2076,
                    2080,
                    2083,
                    2090,
                    2115,
                    2121,
                    2125,
                    2131,
                    105,
                    106,
                    107,
                    2172,
                    2181,
                    2182,
                    2216,
                    2222,
                    2232,
                    2237,
                    2250,
                    219,
                    221,
                    223,
                    227,
                    2279,
                    2289,
                    2294,
                    247,
                    249,
                    250,
                    251,
                    252,
                    253,
                    2307,
                    265,
                    274,
                    2334,
                    287,
                    288,
                    2340,
                    294,
                    2344,
                    298,
                    2351,
                    304,
                    2371,
                    2377,
                    332,
                    2381,
                    336,
                    2387,
                    349,
                    368,
                    373,
                    380,
                    2429,
                    384,
                    388,
                    2438,
                    2439,
                    404,
                    405,
                    407,
                    408,
                    409,
                    2460,
                    2463,
                    2468,
                    2475,
                    2476,
                    2501,
                    2504,
                    2509,
                    463,
                    2517,
                    2518,
                    2519,
                    474,
                    475,
                    480,
                    484,
                    2533,
                    486,
                    488,
                    2536,
                    2538,
                    2541,
                    2543,
                    2546,
                    499,
                    500,
                    501,
                    2548,
                    2549,
                    2552,
                    2554,
                    2557,
                    2559,
                    2560,
                    2563,
                    2565,
                    2568,
                    2570,
                    2572,
                    525,
                    2573,
                    529,
                    535,
                    541,
                    554,
                    567,
                    575,
                    577,
                    581,
                    585,
                    591,
                    592,
                    594,
                    600,
                    616,
                    617,
                    619,
                    625,
                    639,
                    643,
                    647,
                    651,
                    655,
                    656,
                    660,
                    664,
                    687,
                    691,
                    695,
                    699,
                    707,
                    711,
                    715,
                    716,
                    717,
                    2766,
                    724,
                    728,
                    732,
                    736,
                    740,
                    2789,
                    744,
                    748,
                    752,
                    762,
                    766,
                    771,
                    775,
                    786,
                    795,
                    797,
                    800,
                    810,
                    812,
                    815,
                    821,
                    830,
                    831,
                    834,
                    838,
                    845,
                    862,
                    866,
                    872,
                    883,
                    891,
                    897,
                    904,
                    913,
                    929,
                    930,
                    932,
                    933,
                    946,
                    947,
                    948,
                    958,
                    959,
                    960,
                    961,
                    989,
                    997,
                    999,
                    1004,
                    1005,
                    1023,
                    1028,
                    1042,
                    1043,
                    1045,
                    1046,
                    1067,
                    1068,
                    1070,
                    1071,
                    1077,
                    1078,
                    1081,
                    1086,
                    1090,
                    1092,
                    1098,
                    1099,
                    1100,
                    1103,
                    1111,
                    1112,
                    1113,
                    1114,
                    1116,
                    1123,
                    1125,
                    1128,
                    1130,
                    1131,
                    1132,
                    1141,
                    1143,
                    1144,
                    1145,
                    1159,
                    1164,
                    1165,
                    1166,
                    1167,
                    1168,
                    1183,
                    1205,
                    1206,
                    1208,
                    1209,
                    1212,
                    1213,
                    1216,
                    1217,
                    1221,
                    1222,
                    1225,
                    1226,
                    1229,
                    1232,
                    1243,
                    1269,
                    1270,
                    1272,
                    1273,
                    1276,
                    1277,
                    1280,
                    1281,
                    1284,
                    1285,
                    1290,
                    1291,
                    1294,
                    1295,
                    1298,
                    1299,
                    1302,
                    1306,
                    1312,
                    1332,
                    1333,
                    1341,
                    1347,
                    1350,
                    1357,
                    1361,
                    1365,
                    1366,
                    1370,
                    1378,
                    1666,
                    1667,
                    1669,
                    1677,
                    1678,
                    1683,
                    1685,
                    1686,
                    1696,
                    1719,
                    1724,
                    1726,
                    1727,
                    1731,
                    1732,
                    1733,
                    1734,
                    1738,
                    1742,
                    1798,
                    1802,
                    1806,
                    1832,
                    1834,
                    1837,
                    1838,
                    1839,
                    1843,
                    1845,
                    1888,
                    1889,
                    1898,
                    1899,
                    2025,
                    2027,
                    2038,
                    2040,
                    2042
                ],
                "NAME_SCOPE_STACK": [
                    113,
                    125,
                    121,
                    119
                ],
                "NAME_SCOPE_STACK.append": [
                    119
                ],
                "name": [
                    128,
                    149,
                    158,
                    174,
                    2744,
                    312,
                    320,
                    328,
                    2767,
                    247,
                    349,
                    354,
                    2790,
                    359,
                    1394,
                    243,
                    1396,
                    119,
                    249,
                    126
                ],
                "NAME_SCOPE_STACK.pop": [
                    121
                ],
                "contextmanager": [
                    116
                ],
                "join": [
                    125
                ],
                "default": [
                    127
                ],
                "dtype": [
                    144,
                    145,
                    2580,
                    2581,
                    2585,
                    156,
                    2589,
                    2590,
                    2594,
                    2598,
                    167,
                    168,
                    1063,
                    2599,
                    2603,
                    173,
                    2607,
                    2608,
                    310,
                    311,
                    312,
                    2614,
                    2617,
                    573,
                    318,
                    319,
                    320,
                    576,
                    577,
                    326,
                    327,
                    328,
                    332,
                    336,
                    354,
                    359,
                    234,
                    235,
                    373,
                    247,
                    249
                ],
                "_assert_sparse_module": [
                    147,
                    246
                ],
                "variable": [
                    160,
                    161,
                    162,
                    163,
                    320,
                    353,
                    358,
                    328,
                    392,
                    148,
                    312,
                    157
                ],
                "th_sparse_module.as_sparse_variable": [
                    148
                ],
                "_prepare_name": [
                    243,
                    174,
                    149,
                    158
                ],
                "theano.tensor.TensorVariable": [
                    151
                ],
                "theano.tensor": [
                    824,
                    822,
                    823,
                    152,
                    153,
                    892,
                    151
                ],
                "theano.tensor.sharedvar.TensorSharedVariable": [
                    152
                ],
                "theano.tensor.sharedvar": [
                    152
                ],
                "theano.tensor.TensorConstant": [
                    153
                ],
                "value.eval": [
                    155
                ],
                "np.asarray": [
                    1361,
                    948,
                    156,
                    1366
                ],
                "np": [
                    655,
                    2583,
                    156,
                    1824,
                    2592,
                    2601,
                    171,
                    2610,
                    948,
                    312,
                    320,
                    706,
                    328,
                    1103,
                    1361,
                    1366,
                    1116,
                    353,
                    358,
                    2668,
                    369,
                    2682
                ],
                "theano.shared": [
                    157
                ],
                "variable._keras_shape": [
                    160
                ],
                "value.shape": [
                    160
                ],
                "variable._uses_learning_phase": [
                    161
                ],
                "variable.constraint": [
                    162
                ],
                "constraint": [
                    162
                ],
                "np_value": [
                    171,
                    172
                ],
                "np.ones": [
                    320,
                    171
                ],
                "const": [
                    176,
                    177,
                    172,
                    175
                ],
                "T.constant": [
                    172
                ],
                "const._keras_shape": [
                    175
                ],
                "const._uses_learning_phase": [
                    176
                ],
                "is_tensor": [
                    219
                ],
                "T.TensorVariable": [
                    227
                ],
                "T.sharedvar.TensorSharedVariable": [
                    228
                ],
                "T.sharedvar": [
                    228
                ],
                "ndim": [
                    2560,
                    2562,
                    2567,
                    905,
                    815,
                    834,
                    1476,
                    1477,
                    1485,
                    1495,
                    1497,
                    481,
                    2533,
                    872,
                    1641,
                    874,
                    1642,
                    236,
                    2536,
                    2538,
                    239,
                    879,
                    241,
                    2540,
                    2545,
                    244,
                    2549,
                    2551,
                    2556
                ],
                "_": [
                    2720,
                    2818,
                    1645,
                    1551,
                    241,
                    2681,
                    1598
                ],
                "broadcast": [
                    249,
                    244
                ],
                "sparse": [
                    245
                ],
                "th_sparse_module.csr_matrix": [
                    247
                ],
                "T.TensorType": [
                    249
                ],
                "x._keras_shape": [
                    1280,
                    1281,
                    1284,
                    1273,
                    1285,
                    1290,
                    1291,
                    1166,
                    1167,
                    1168,
                    1294,
                    1295,
                    1298,
                    1299,
                    1046,
                    1302,
                    409,
                    1306,
                    2076,
                    288,
                    2083,
                    1070,
                    1071,
                    948,
                    1077,
                    1078,
                    1208,
                    1081,
                    1209,
                    1212,
                    1213,
                    1086,
                    960,
                    961,
                    1090,
                    1216,
                    1217,
                    1221,
                    1222,
                    1225,
                    1226,
                    1100,
                    717,
                    1229,
                    1103,
                    1232,
                    594,
                    600,
                    1113,
                    1114,
                    1116,
                    486,
                    488,
                    619,
                    1132,
                    1005,
                    625,
                    501,
                    1272,
                    1145,
                    250,
                    1276,
                    1277
                ],
                "x._uses_learning_phase": [
                    251,
                    933,
                    1685
                ],
                "x._theano_placeholder": [
                    265,
                    252
                ],
                "x.shape": [
                    1159,
                    1164,
                    274,
                    1183,
                    1832,
                    2475,
                    2476,
                    838,
                    2517,
                    2518,
                    1111,
                    2519,
                    1243,
                    2025,
                    2027,
                    368,
                    1141,
                    2038,
                    2040,
                    2042
                ],
                "x.ndim": [
                    866,
                    1731,
                    1092,
                    294,
                    872,
                    463,
                    1042,
                    1332,
                    475,
                    795,
                    797,
                    862
                ],
                "x.dtype": [
                    1832,
                    298,
                    1834,
                    1361,
                    1366,
                    575
                ],
                "to_dense": [
                    304,
                    913
                ],
                "np.zeros": [
                    312
                ],
                "np.eye": [
                    328
                ],
                "size": [
                    328
                ],
                "T.ones_like": [
                    1873,
                    332,
                    1871
                ],
                "T.zeros_like": [
                    336,
                    1865,
                    1867,
                    2670
                ],
                "x.copy": [
                    349
                ],
                "np.random.uniform": [
                    353
                ],
                "np.random": [
                    1824,
                    353,
                    2592,
                    358,
                    2601,
                    2610,
                    2583
                ],
                "low": [
                    353
                ],
                "high": [
                    353
                ],
                "np.random.normal": [
                    358
                ],
                "scale": [
                    358
                ],
                "f": [
                    368,
                    369
                ],
                "theano.function": [
                    368,
                    1406,
                    1391
                ],
                "np.prod": [
                    369,
                    1116,
                    1103
                ],
                "T.cast": [
                    2643,
                    373,
                    1783
                ],
                "new_x": [
                    380
                ],
                "increment": [
                    384
                ],
                "decrement": [
                    388
                ],
                "momentum": [
                    392
                ],
                "out": [
                    480,
                    417,
                    418,
                    481,
                    482,
                    494,
                    495,
                    405,
                    407
                ],
                "th_sparse_module.basic.structured_dot": [
                    405
                ],
                "th_sparse_module.basic": [
                    907,
                    405,
                    909
                ],
                "y": [
                    515,
                    517,
                    518,
                    1147,
                    1043,
                    1044,
                    405,
                    407,
                    408,
                    1048,
                    410,
                    1050,
                    1307,
                    1308,
                    929,
                    931,
                    933,
                    935,
                    936,
                    1067,
                    946,
                    948,
                    949,
                    1205,
                    958,
                    960,
                    963,
                    964,
                    965,
                    1093,
                    711,
                    1094,
                    1098,
                    715,
                    1101,
                    718,
                    463,
                    591,
                    719,
                    594,
                    1103,
                    724,
                    1104,
                    1233,
                    1111,
                    728,
                    1234,
                    1114,
                    732,
                    477,
                    478,
                    1116,
                    480,
                    609,
                    610,
                    736,
                    484,
                    740,
                    1117,
                    616,
                    489,
                    744,
                    491,
                    619,
                    1130,
                    1134,
                    1135,
                    499,
                    501,
                    502,
                    1143,
                    1269,
                    634,
                    635,
                    1148
                ],
                "T.dot": [
                    407
                ],
                "x_shape": [
                    417,
                    409,
                    411,
                    412
                ],
                "y_shape": [
                    416,
                    417,
                    410,
                    413,
                    414,
                    415
                ],
                "y._keras_shape": [
                    517,
                    1048,
                    410,
                    1307,
                    931,
                    948,
                    960,
                    963,
                    964,
                    1093,
                    1101,
                    719,
                    1103,
                    1233,
                    594,
                    1114,
                    1116,
                    609,
                    489,
                    491,
                    619,
                    1134,
                    501,
                    634,
                    1147
                ],
                "x_shape.pop": [
                    412
                ],
                "y_shape.pop": [
                    416,
                    414
                ],
                "out._keras_shape": [
                    417,
                    494
                ],
                "axes": [
                    1330,
                    1331,
                    1332,
                    459,
                    460,
                    461,
                    1485,
                    463,
                    464,
                    1486,
                    1616,
                    467,
                    468,
                    469,
                    1617,
                    473,
                    1498,
                    475,
                    476,
                    478,
                    480,
                    487,
                    490
                ],
                "y.ndim": [
                    478,
                    463
                ],
                "a": [
                    631,
                    464,
                    624,
                    699,
                    627,
                    628,
                    630,
                    599,
                    602,
                    603,
                    605,
                    606
                ],
                "transpose": [
                    474,
                    477
                ],
                "T.batched_tensordot": [
                    480
                ],
                "expand_dims": [
                    2080,
                    482,
                    2216,
                    2089,
                    2217,
                    2218,
                    1646,
                    1496,
                    2073
                ],
                "axis": [
                    643,
                    905,
                    906,
                    908,
                    525,
                    911,
                    529,
                    913,
                    535,
                    919,
                    920,
                    922,
                    541,
                    1312,
                    1126,
                    554,
                    1128,
                    687,
                    1129,
                    1843,
                    567,
                    958,
                    577,
                    834,
                    835,
                    961,
                    581,
                    838,
                    963,
                    1731,
                    585,
                    1734,
                    591,
                    1771,
                    593,
                    1747,
                    596,
                    597,
                    1750,
                    599,
                    1754,
                    1755,
                    1756,
                    1124,
                    486,
                    487,
                    488,
                    489,
                    490,
                    491,
                    616,
                    618,
                    621,
                    622,
                    624,
                    877,
                    878,
                    880,
                    881,
                    1133,
                    1142,
                    1774,
                    1778,
                    1779,
                    1146,
                    1780,
                    639
                ],
                "shape.append": [
                    488,
                    491,
                    493
                ],
                "T.transpose": [
                    499
                ],
                "reference": [
                    515,
                    516,
                    517
                ],
                "indices": [
                    1569,
                    515,
                    516,
                    517,
                    1190,
                    1251,
                    1320,
                    1321,
                    1322,
                    1508,
                    1567,
                    1574,
                    1264,
                    1201,
                    1205,
                    1269,
                    1501,
                    1503
                ],
                "indices._keras_shape": [
                    517
                ],
                "reference._keras_shape": [
                    517
                ],
                "T.max": [
                    2649,
                    2692,
                    525,
                    2646
                ],
                "keepdims": [
                    577,
                    581,
                    616,
                    585,
                    619,
                    525,
                    591,
                    687,
                    529,
                    594,
                    626,
                    535,
                    601,
                    541
                ],
                "T.min": [
                    529
                ],
                "T.sum": [
                    687,
                    1843,
                    2693,
                    535
                ],
                "T.prod": [
                    541,
                    1111
                ],
                "T.extra_ops.cumsum": [
                    554
                ],
                "T.extra_ops": [
                    554,
                    1322,
                    1044,
                    567,
                    1784
                ],
                "T.extra_ops.cumprod": [
                    567
                ],
                "T.mean": [
                    577
                ],
                "T.std": [
                    581
                ],
                "T.var": [
                    585
                ],
                "T.any": [
                    591
                ],
                "axis_list": [
                    622,
                    624,
                    627,
                    597,
                    630,
                    599,
                    602,
                    605
                ],
                "keras_shape_list": [
                    608,
                    609,
                    632,
                    625,
                    628,
                    631,
                    600,
                    633,
                    634,
                    603,
                    606,
                    607
                ],
                "keras_shape_list.pop": [
                    606,
                    631
                ],
                "T.all": [
                    616
                ],
                "T.argmax": [
                    639
                ],
                "T.argmin": [
                    643
                ],
                "T.sqr": [
                    647
                ],
                "T.abs_": [
                    651
                ],
                "T.clip": [
                    1793,
                    707,
                    1765,
                    655,
                    2619
                ],
                "np.inf": [
                    706,
                    655
                ],
                "T.sqrt": [
                    656,
                    1844
                ],
                "T.exp": [
                    1733,
                    2693,
                    687,
                    660,
                    2650
                ],
                "T.log": [
                    2658,
                    2693,
                    2669,
                    687,
                    664
                ],
                "T.round": [
                    691
                ],
                "T.sgn": [
                    695
                ],
                "T.pow": [
                    699
                ],
                "max_value": [
                    704,
                    705,
                    706,
                    707,
                    1725,
                    1726,
                    703
                ],
                "min_value": [
                    704,
                    707,
                    703
                ],
                "T.eq": [
                    711
                ],
                "z": [
                    720,
                    715,
                    717,
                    719
                ],
                "T.neq": [
                    715,
                    2637
                ],
                "z._keras_shape": [
                    717,
                    719
                ],
                "T.gt": [
                    724
                ],
                "T.ge": [
                    728,
                    1877
                ],
                "T.lt": [
                    732
                ],
                "T.le": [
                    736
                ],
                "T.maximum": [
                    740,
                    1844,
                    2644
                ],
                "T.minimum": [
                    744,
                    2643,
                    1726
                ],
                "T.sin": [
                    748
                ],
                "T.cos": [
                    752
                ],
                "T.nnet.bn": [
                    897,
                    774,
                    785,
                    761,
                    799
                ],
                "T.nnet": [
                    2176,
                    897,
                    1794,
                    2433,
                    774,
                    1798,
                    1802,
                    785,
                    799,
                    2344,
                    1718,
                    1719,
                    1723,
                    1724,
                    2237,
                    1732,
                    2244,
                    1738,
                    2125,
                    2381,
                    1760,
                    1766,
                    1000,
                    2294,
                    761,
                    2301,
                    1791
                ],
                "_old_normalize_batch_in_training": [
                    762
                ],
                "gamma": [
                    768,
                    897,
                    770,
                    772,
                    775,
                    786,
                    788,
                    789,
                    800,
                    809,
                    810,
                    818,
                    844,
                    857,
                    858,
                    870,
                    884,
                    762,
                    891,
                    764,
                    766
                ],
                "beta": [
                    768,
                    769,
                    897,
                    771,
                    772,
                    775,
                    786,
                    790,
                    791,
                    800,
                    811,
                    812,
                    817,
                    843,
                    859,
                    860,
                    869,
                    885,
                    762,
                    891,
                    765
                ],
                "reduction_axes": [
                    800,
                    835,
                    775,
                    815,
                    762,
                    795,
                    797,
                    830,
                    831
                ],
                "epsilon": [
                    800,
                    897,
                    1793,
                    1765,
                    775,
                    847,
                    786,
                    1844,
                    821,
                    888,
                    762,
                    891
                ],
                "ones_like": [
                    768,
                    810,
                    789,
                    858,
                    766
                ],
                "zeros_like": [
                    771,
                    772,
                    1514,
                    812,
                    791,
                    860
                ],
                "normed": [
                    774,
                    777,
                    845,
                    848,
                    820,
                    822,
                    826
                ],
                "mean": [
                    897,
                    774,
                    777,
                    786,
                    791,
                    793,
                    2585,
                    797,
                    800,
                    820,
                    2614,
                    823,
                    2617,
                    826,
                    2619,
                    831,
                    841,
                    848,
                    860,
                    862,
                    867,
                    877,
                    886,
                    891
                ],
                "stdinv": [
                    774,
                    777,
                    820,
                    824,
                    825
                ],
                "T.nnet.bn.batch_normalization_train": [
                    774
                ],
                "T.inv": [
                    777,
                    825
                ],
                "_old_batch_normalization": [
                    786
                ],
                "var": [
                    800,
                    897,
                    868,
                    842,
                    848,
                    786,
                    789,
                    887,
                    825,
                    826,
                    891,
                    858,
                    830
                ],
                "mean.ndim": [
                    793,
                    862
                ],
                "i": [
                    2822,
                    2824,
                    2825,
                    2831,
                    2838,
                    2840,
                    2841,
                    797,
                    1574,
                    1575,
                    1320,
                    1582,
                    1071,
                    1072,
                    1583,
                    1075,
                    1332,
                    1123,
                    1508,
                    1509,
                    1518,
                    1521,
                    2801,
                    2802,
                    2803,
                    1529,
                    1530
                ],
                "mean.broadcastable": [
                    877,
                    797
                ],
                "T.nnet.bn.batch_normalization_test": [
                    799
                ],
                "dev": [
                    873,
                    874,
                    814,
                    815
                ],
                "theano.config.device": [
                    873,
                    814
                ],
                "use_cudnn": [
                    816,
                    874,
                    875,
                    815
                ],
                "dev.startswith": [
                    874,
                    815
                ],
                "broadcast_beta": [
                    817,
                    843,
                    821,
                    846
                ],
                "beta.dimshuffle": [
                    817,
                    885,
                    869
                ],
                "broadcast_gamma": [
                    818,
                    844,
                    821,
                    846
                ],
                "gamma.dimshuffle": [
                    818,
                    884,
                    870
                ],
                "theano.sandbox.cuda.dnn.dnn_batch_normalization_train": [
                    820
                ],
                "theano.sandbox.cuda.dnn": [
                    882,
                    820,
                    890
                ],
                "theano.sandbox.cuda": [
                    882,
                    820,
                    890
                ],
                "theano.sandbox": [
                    882,
                    820,
                    890
                ],
                "theano.tensor.as_tensor_variable": [
                    824,
                    892,
                    822,
                    823
                ],
                "T.flatten": [
                    1321,
                    826,
                    1098,
                    1783
                ],
                "x.var": [
                    830
                ],
                "x.mean": [
                    831
                ],
                "target_shape": [
                    833,
                    836,
                    838,
                    839,
                    841,
                    842,
                    843,
                    844
                ],
                "target_shape.append": [
                    836,
                    838
                ],
                "T.stack": [
                    1312,
                    839,
                    1580,
                    1583,
                    1527,
                    1530
                ],
                "broadcast_mean": [
                    841,
                    845
                ],
                "T.reshape": [
                    929,
                    841,
                    842,
                    843,
                    844,
                    1323,
                    1143,
                    1111
                ],
                "broadcast_var": [
                    842,
                    845
                ],
                "batch_normalization": [
                    845
                ],
                "shuffle_pattern": [
                    866,
                    867,
                    868,
                    869,
                    870,
                    879,
                    880,
                    881,
                    883,
                    884,
                    885,
                    886,
                    887,
                    888
                ],
                "mean.dimshuffle": [
                    867,
                    886
                ],
                "var.dimshuffle": [
                    868,
                    887
                ],
                "mean.broadcastable.index": [
                    877
                ],
                "result": [
                    1164,
                    1166,
                    1169,
                    882,
                    890,
                    892
                ],
                "dimshuffle": [
                    882,
                    2684
                ],
                "theano.sandbox.cuda.dnn.dnn_batch_normalization_test": [
                    882,
                    890
                ],
                "x.dimshuffle": [
                    1888,
                    2501,
                    1130,
                    1898,
                    946,
                    1043,
                    883,
                    2460
                ],
                "T.nnet.bn.batch_normalization": [
                    897
                ],
                "sqrt": [
                    897
                ],
                "tensors": [
                    904,
                    905,
                    907,
                    909,
                    913,
                    915,
                    916
                ],
                "output": [
                    1024,
                    1025,
                    1026,
                    1793,
                    1028,
                    1029,
                    1030,
                    1031,
                    1794,
                    2821,
                    907,
                    1163,
                    909,
                    1164,
                    2830,
                    1784,
                    913,
                    2832,
                    2833,
                    2835,
                    923,
                    925,
                    2848,
                    2849,
                    2851,
                    2852,
                    1189,
                    2090,
                    2095,
                    1200,
                    2097,
                    2098,
                    1791,
                    2808,
                    1205,
                    1766,
                    2809,
                    1746,
                    1752,
                    989,
                    990,
                    1757,
                    1760,
                    1250,
                    1763,
                    997,
                    1509,
                    999,
                    1000,
                    1510,
                    1514,
                    1003,
                    1765,
                    1005,
                    1006,
                    1007,
                    1008,
                    1263,
                    1518,
                    1770,
                    1012,
                    1269,
                    1524,
                    1776,
                    1781,
                    1785,
                    1786,
                    1023
                ],
                "th_sparse_module.basic.vstack": [
                    907
                ],
                "th_sparse_module.basic.hstack": [
                    909
                ],
                "T.concatenate": [
                    913,
                    2646
                ],
                "input_shapes": [
                    916,
                    917,
                    918
                ],
                "tensor._keras_shape": [
                    916
                ],
                "output_shape": [
                    2816,
                    2181,
                    2438,
                    1160,
                    1163,
                    917,
                    919,
                    920,
                    922,
                    923,
                    1185,
                    1189,
                    1196,
                    1070,
                    1200,
                    1073,
                    1075,
                    1077,
                    1079,
                    1081,
                    1086,
                    1090,
                    1092,
                    1093,
                    1245,
                    1250,
                    1258,
                    2156,
                    2157,
                    2158,
                    1263,
                    2159,
                    2412,
                    2413,
                    2414,
                    2415,
                    2416
                ],
                "output._keras_shape": [
                    1005,
                    1006,
                    1007,
                    1008,
                    923
                ],
                "y._uses_learning_phase": [
                    933,
                    935
                ],
                "pattern": [
                    1123,
                    1129,
                    1130,
                    945,
                    946,
                    948
                ],
                "T.repeat": [
                    958
                ],
                "rep": [
                    963,
                    958
                ],
                "repeat_dim": [
                    961,
                    962,
                    963
                ],
                "data_format": [
                    2561,
                    1027,
                    2566,
                    1033,
                    2059,
                    2070,
                    2092,
                    2094,
                    2555,
                    2113,
                    2115,
                    2119,
                    2121,
                    2122,
                    2132,
                    2153,
                    2155,
                    2170,
                    2172,
                    2173,
                    2183,
                    1181,
                    2206,
                    1184,
                    2212,
                    2222,
                    2226,
                    2230,
                    1207,
                    2232,
                    2233,
                    2234,
                    2252,
                    1241,
                    1244,
                    2277,
                    2279,
                    2794,
                    2283,
                    2287,
                    2289,
                    2290,
                    2291,
                    1271,
                    2813,
                    2820,
                    2309,
                    2332,
                    2334,
                    2338,
                    2340,
                    2341,
                    2352,
                    2369,
                    2371,
                    2375,
                    2377,
                    2378,
                    2388,
                    1883,
                    1893,
                    2409,
                    2411,
                    2427,
                    2429,
                    2430,
                    2440,
                    2446,
                    2459,
                    1950,
                    1966,
                    2481,
                    2488,
                    2500,
                    979,
                    982,
                    986,
                    2526,
                    996,
                    2532,
                    1002,
                    2539,
                    2028,
                    2544,
                    2550,
                    2043,
                    1022
                ],
                "axis_1": [
                    980,
                    989,
                    1006,
                    983
                ],
                "axis_2": [
                    984,
                    981,
                    990,
                    1007
                ],
                "interpolation": [
                    988,
                    991
                ],
                "repeat_elements": [
                    1024,
                    1025,
                    1028,
                    1029,
                    1030,
                    989,
                    990,
                    1023
                ],
                "height_factor": [
                    992,
                    1024,
                    1029,
                    1001,
                    1006,
                    989
                ],
                "width_factor": [
                    992,
                    1025,
                    1030,
                    1007,
                    990
                ],
                "permute_dimensions": [
                    2851,
                    997,
                    1003,
                    2835,
                    1781,
                    1782,
                    2809,
                    1757,
                    1758
                ],
                "T.nnet.abstract_conv.bilinear_upsampling": [
                    1000
                ],
                "T.nnet.abstract_conv": [
                    1000,
                    2433,
                    2176
                ],
                "depth_factor": [
                    1028,
                    1023
                ],
                "T.extra_ops.repeat": [
                    1044
                ],
                "n": [
                    1089,
                    1067,
                    1069,
                    1070,
                    1071,
                    1044,
                    1076,
                    1047,
                    1081,
                    1084,
                    1087
                ],
                "shape.insert": [
                    1133,
                    1047
                ],
                "T.arange": [
                    2631,
                    1063,
                    2636,
                    1876,
                    2684
                ],
                "start": [
                    1063
                ],
                "stop": [
                    1063
                ],
                "step": [
                    2682,
                    1063
                ],
                "T.tile": [
                    1067
                ],
                "_is_explicit_shape": [
                    1069
                ],
                "j": [
                    2823,
                    2826,
                    2827,
                    1071,
                    2831,
                    1075,
                    2839,
                    2842,
                    2843
                ],
                "n.ndim": [
                    1084
                ],
                "n_size": [
                    1089,
                    1090
                ],
                "n._keras_shape": [
                    1089
                ],
                "x.type.ndim": [
                    1128,
                    1123,
                    1125
                ],
                "x.type": [
                    1128,
                    1123,
                    1125
                ],
                "pattern.insert": [
                    1129
                ],
                "shape.pop": [
                    1142
                ],
                "kshape": [
                    1145,
                    1146,
                    1147
                ],
                "kshape.pop": [
                    1146
                ],
                "padding": [
                    2432,
                    1281,
                    2307,
                    1158,
                    2182,
                    2439,
                    1161,
                    1291,
                    1164,
                    1932,
                    1934,
                    1167,
                    1295,
                    1936,
                    2062,
                    1299,
                    1939,
                    2068,
                    2450,
                    2454,
                    1176,
                    1177,
                    1178,
                    1179,
                    1180,
                    2457,
                    2342,
                    2474,
                    2091,
                    2351,
                    2490,
                    2235,
                    2495,
                    2498,
                    2250,
                    2123,
                    2379,
                    2131,
                    2387,
                    2516,
                    1247,
                    1248,
                    1249,
                    1253,
                    1254,
                    1255,
                    2023,
                    1259,
                    1260,
                    1261,
                    1265,
                    1266,
                    1267,
                    2036,
                    2165,
                    2292,
                    2422,
                    1273,
                    1277,
                    2175
                ],
                "input_shape": [
                    1159,
                    1160,
                    1161,
                    1162,
                    1183,
                    1185,
                    1186,
                    1187,
                    1188,
                    1192,
                    1193,
                    1320,
                    1323,
                    1196,
                    1197,
                    1198,
                    1199,
                    1202,
                    1203,
                    1243,
                    1245,
                    1246,
                    1247,
                    1248,
                    1249,
                    1253,
                    1254,
                    1255,
                    1258,
                    1259,
                    1260,
                    1261,
                    1262,
                    1265,
                    1266,
                    1267
                ],
                "T.zeros": [
                    1250,
                    1189,
                    1163,
                    1263,
                    1200
                ],
                "T.set_subtensor": [
                    2660,
                    2631,
                    1164,
                    1269,
                    1205,
                    2653
                ],
                "result._keras_shape": [
                    1166
                ],
                "top_pad": [
                    1187,
                    1222,
                    1192,
                    1197,
                    1202,
                    1209,
                    1179
                ],
                "bottom_pad": [
                    1187,
                    1222,
                    1197,
                    1209,
                    1179
                ],
                "left_pad": [
                    1188,
                    1193,
                    1226,
                    1198,
                    2066,
                    1203,
                    2067,
                    1180,
                    1213
                ],
                "right_pad": [
                    1188,
                    1226,
                    1198,
                    1180,
                    1213
                ],
                "normalize_data_format": [
                    2113,
                    2369,
                    2532,
                    2277,
                    2153,
                    2409,
                    2059,
                    2794,
                    2813,
                    2446,
                    2488,
                    1241,
                    2332,
                    1181,
                    2206
                ],
                "h": [
                    1218,
                    1273,
                    1222,
                    1286,
                    1224,
                    1291,
                    1293,
                    1230,
                    1275,
                    1303,
                    1209,
                    1211
                ],
                "w": [
                    1219,
                    1279,
                    1287,
                    1226,
                    1228,
                    1231,
                    1295,
                    1297,
                    1304,
                    1277,
                    1213,
                    1215
                ],
                "output_keras_shape": [
                    1216,
                    1284,
                    1229,
                    1233,
                    1302,
                    1307
                ],
                "d": [
                    1281,
                    1283,
                    1288,
                    1299,
                    1301,
                    1305
                ],
                "indices.shape": [
                    1320
                ],
                "indices.ndim": [
                    1320
                ],
                "oh": [
                    1322,
                    1323,
                    1324
                ],
                "T.extra_ops.to_one_hot": [
                    1784,
                    1322
                ],
                "num_classes": [
                    1322,
                    1323
                ],
                "slices": [
                    1332,
                    1333
                ],
                "T.patternbroadcast": [
                    1835,
                    1341
                ],
                "broadcastable": [
                    1341
                ],
                "x.get_value": [
                    1370,
                    1350
                ],
                "get_value": [
                    1357
                ],
                "xs": [
                    1357,
                    2800,
                    2804,
                    2837,
                    2806,
                    2844,
                    2847
                ],
                "x.set_value": [
                    1361,
                    1366
                ],
                "tuples": [
                    1365
                ],
                "p_op": [
                    1377,
                    1378
                ],
                "Print": [
                    1377
                ],
                "message": [
                    1377
                ],
                "unique_variables_to_update": [
                    1386,
                    1388,
                    1389,
                    1390
                ],
                "v": [
                    2016,
                    1986,
                    1955,
                    1387,
                    1388,
                    1389,
                    2001,
                    1971
                ],
                "nv": [
                    1387,
                    1389
                ],
                "updates": [
                    1409,
                    1387,
                    1390,
                    1391
                ],
                "unique_variables_to_update.items": [
                    1390
                ],
                "self.function": [
                    1400,
                    1391
                ],
                "self": [
                    1400,
                    1396,
                    1391
                ],
                "inputs": [
                    1600,
                    1409,
                    1476,
                    1509,
                    1540,
                    1575,
                    2828,
                    1486,
                    1391,
                    1553,
                    1587,
                    2804,
                    1399,
                    1400,
                    2844,
                    1533
                ],
                "outputs": [
                    1409,
                    1540,
                    1541,
                    1545,
                    1549,
                    1560,
                    1563,
                    1575,
                    1576,
                    1578,
                    1580,
                    1587,
                    1588,
                    1591,
                    1607,
                    1610,
                    1613,
                    1614,
                    1616,
                    1617,
                    1620,
                    1391,
                    1527
                ],
                "kwargs": [
                    1409,
                    1395,
                    1404,
                    1405
                ],
                "self.name": [
                    1396
                ],
                "key": [
                    1405,
                    1406,
                    1407
                ],
                "kwargs.keys": [
                    1405
                ],
                "has_arg": [
                    1406
                ],
                "msg": [
                    1408,
                    1407
                ],
                "Function": [
                    1409
                ],
                "T.grad": [
                    1413
                ],
                "loss": [
                    1413
                ],
                "variables": [
                    1427,
                    1428,
                    1413,
                    1430
                ],
                "theano.gradient.disconnected_grad": [
                    1428,
                    1430
                ],
                "theano.gradient": [
                    1428,
                    1430
                ],
                "inputs.ndim": [
                    1476
                ],
                "unroll": [
                    1500,
                    1566,
                    1479
                ],
                "input_length": [
                    1480,
                    2723,
                    1501,
                    1567
                ],
                "inputs.dimshuffle": [
                    1486
                ],
                "constants": [
                    1602,
                    1509,
                    1575,
                    1488,
                    1489,
                    1555,
                    1533
                ],
                "uses_learning_phase": [
                    1543,
                    1511,
                    1577,
                    1619,
                    1492,
                    1684,
                    1590,
                    1661,
                    1663
                ],
                "mask": [
                    2691,
                    2693,
                    1545,
                    1548,
                    1518,
                    1521,
                    1553,
                    1494,
                    1495,
                    1496,
                    1497,
                    1498,
                    2685,
                    2687
                ],
                "mask.ndim": [
                    1497,
                    1495
                ],
                "mask.dimshuffle": [
                    1498
                ],
                "go_backwards": [
                    1568,
                    1603,
                    1556,
                    1502
                ],
                "successive_outputs": [
                    1505,
                    1571,
                    1513,
                    1578,
                    1516,
                    1580,
                    1524,
                    1527
                ],
                "successive_states": [
                    1506,
                    1572,
                    1579,
                    1582,
                    1583,
                    1525,
                    1529,
                    1530
                ],
                "states": [
                    1540,
                    1547,
                    1561,
                    1564,
                    1573,
                    1575,
                    1579,
                    1581,
                    1583,
                    1587,
                    1608,
                    1611,
                    1618,
                    1620,
                    1507,
                    1509,
                    1520,
                    1522,
                    1525,
                    1528,
                    1530
                ],
                "initial_states": [
                    1536,
                    1537,
                    1601,
                    1507,
                    1573,
                    1554,
                    1595,
                    1596,
                    1533
                ],
                "new_states": [
                    1540,
                    1509,
                    1547,
                    1520,
                    1587,
                    1591
                ],
                "step_function": [
                    1540,
                    1509,
                    1575,
                    1587,
                    1533
                ],
                "prev_output": [
                    1514,
                    1516,
                    1518
                ],
                "T.switch": [
                    1545,
                    1548,
                    1518,
                    1647,
                    1521
                ],
                "kept_states": [
                    1521,
                    1522,
                    1519
                ],
                "state": [
                    1547,
                    1548,
                    1520,
                    1521,
                    1618
                ],
                "new_state": [
                    1520,
                    1521,
                    1547,
                    1548
                ],
                "kept_states.append": [
                    1521
                ],
                "successive_outputs.append": [
                    1578,
                    1524
                ],
                "successive_states.append": [
                    1579,
                    1525
                ],
                "states.append": [
                    1530,
                    1583
                ],
                "states_at_step": [
                    1530,
                    1583
                ],
                "initial_output": [
                    1554,
                    1533,
                    1535
                ],
                "T.unbroadcast": [
                    1537,
                    1596,
                    1535
                ],
                "output_tm1": [
                    1545
                ],
                "return_states": [
                    1546,
                    1548,
                    1549
                ],
                "return_states.append": [
                    1548
                ],
                "results": [
                    1606,
                    1607,
                    1608,
                    1610,
                    1551,
                    1559,
                    1560,
                    1561,
                    1563,
                    1598
                ],
                "theano.scan": [
                    2720,
                    2681,
                    1598,
                    1551
                ],
                "_step": [
                    1552,
                    1599
                ],
                "T.squeeze": [
                    1618,
                    1613
                ],
                "last_output": [
                    1619,
                    1620,
                    1614
                ],
                "outputs.ndim": [
                    1616
                ],
                "outputs.dimshuffle": [
                    1617
                ],
                "last_output._uses_learning_phase": [
                    1619
                ],
                "then_expression": [
                    1642,
                    1637,
                    1638,
                    1647
                ],
                "else_expression": [
                    1640,
                    1647,
                    1639
                ],
                "cond_ndim": [
                    1641,
                    1643,
                    1644
                ],
                "condition": [
                    1641,
                    1646,
                    1647
                ],
                "expr_ndim": [
                    1642,
                    1643,
                    1644
                ],
                "ndim_diff": [
                    1644,
                    1645
                ],
                "training": [
                    1696,
                    1665,
                    1671,
                    1683,
                    1659,
                    1660
                ],
                "learning_phase": [
                    1660
                ],
                "alt": [
                    1696,
                    1672,
                    1673,
                    1675,
                    1679,
                    1680,
                    1683
                ],
                "ifelse": [
                    1683
                ],
                "in_train_phase": [
                    1696
                ],
                "module": [
                    1702
                ],
                "func": [
                    1702
                ],
                "_assert_has_capability": [
                    1723,
                    1718
                ],
                "T.nnet.elu": [
                    1719
                ],
                "alpha": [
                    2668,
                    1724,
                    1719
                ],
                "T.nnet.relu": [
                    1724
                ],
                "T.nnet.softmax": [
                    1760,
                    1732
                ],
                "x.max": [
                    1733,
                    1734
                ],
                "T.nnet.softplus": [
                    1738
                ],
                "T_softsign": [
                    1742
                ],
                "output_dimensions": [
                    1770,
                    1771,
                    1746,
                    1747,
                    1778,
                    1779,
                    1780,
                    1754,
                    1755,
                    1756
                ],
                "int_shape": [
                    2817,
                    2061,
                    2069,
                    2334,
                    2335,
                    2222,
                    2223,
                    2227,
                    2115,
                    2116,
                    2371,
                    2372,
                    1869,
                    1746,
                    1752,
                    2279,
                    2280,
                    1770,
                    2284,
                    2797,
                    1776,
                    2161,
                    2418
                ],
                "permutation": [
                    1779,
                    1780,
                    1781,
                    1782,
                    1755,
                    1756,
                    1757,
                    1758
                ],
                "target": [
                    1794,
                    1766,
                    1782,
                    1783,
                    1784,
                    1785,
                    1786,
                    1758
                ],
                "from_logits": [
                    1786,
                    1790,
                    1759
                ],
                "output.sum": [
                    1763
                ],
                "T.nnet.categorical_crossentropy": [
                    1766
                ],
                "output.shape": [
                    1784
                ],
                "reshape": [
                    2563,
                    2565,
                    2568,
                    2570,
                    2828,
                    2833,
                    2844,
                    2849,
                    2541,
                    2543,
                    2546,
                    2548,
                    2804,
                    2552,
                    1785,
                    2554,
                    2557,
                    1918,
                    2559
                ],
                "categorical_crossentropy": [
                    1786
                ],
                "T.nnet.sigmoid": [
                    1798,
                    1791
                ],
                "T.nnet.binary_crossentropy": [
                    1794
                ],
                "T.nnet.hard_sigmoid": [
                    1802
                ],
                "T.tanh": [
                    1806
                ],
                "level": [
                    1829,
                    1821
                ],
                "seed": [
                    1824,
                    2592,
                    2593,
                    1828,
                    2600,
                    2601,
                    2602,
                    2591,
                    2609,
                    2610,
                    2611,
                    2582,
                    2583,
                    2584,
                    1823
                ],
                "np.random.randint": [
                    1824,
                    2592,
                    2601,
                    2610,
                    2583
                ],
                "noise_shape": [
                    1825,
                    1826,
                    1831,
                    1834,
                    1836
                ],
                "rng": [
                    2593,
                    2594,
                    1828,
                    1832,
                    1834,
                    2602,
                    2603,
                    2617,
                    2611,
                    2614,
                    2584,
                    2585
                ],
                "RandomStreams": [
                    2593,
                    1828,
                    2602,
                    2611,
                    2584
                ],
                "retain_prob": [
                    1832,
                    1834,
                    1829,
                    1838
                ],
                "random_tensor": [
                    1832,
                    1834,
                    1835,
                    1837
                ],
                "rng.binomial": [
                    1832,
                    1834,
                    2603
                ],
                "dim": [
                    1836
                ],
                "square_sum": [
                    1843,
                    1844
                ],
                "T.square": [
                    1843
                ],
                "norm": [
                    1844,
                    1845
                ],
                "k": [
                    1875,
                    1869,
                    1862
                ],
                "targets": [
                    1865,
                    1867,
                    1871,
                    1873,
                    1876
                ],
                "predictions": [
                    1875,
                    1876,
                    1869
                ],
                "predictions_k": [
                    1875,
                    1877
                ],
                "T.sort": [
                    1875
                ],
                "targets_values": [
                    1876,
                    1877
                ],
                "targets.shape": [
                    1876
                ],
                "kernel": [
                    2817,
                    2181,
                    2438,
                    1927,
                    1928,
                    2061,
                    2831,
                    2848,
                    2089,
                    2090,
                    1917,
                    2430,
                    2116,
                    2372,
                    2118,
                    2374,
                    2122,
                    2378,
                    2125,
                    2381,
                    2797,
                    2161,
                    2418,
                    1907,
                    1908,
                    2163,
                    2420,
                    2808,
                    1916,
                    2173,
                    1918,
                    1919
                ],
                "kernel.dimshuffle": [
                    1907,
                    1917,
                    1927
                ],
                "kernel_shape": [
                    2177,
                    2434,
                    2817,
                    2818,
                    2183,
                    2440,
                    2061,
                    2064,
                    2066,
                    2427,
                    2116,
                    2117,
                    2118,
                    2119,
                    2372,
                    2373,
                    2374,
                    2375,
                    2129,
                    2385,
                    2132,
                    2388,
                    2024,
                    2026,
                    2797,
                    2798,
                    2161,
                    2162,
                    2163,
                    2418,
                    2037,
                    2165,
                    2039,
                    2419,
                    2041,
                    2170,
                    2420,
                    2422,
                    1918
                ],
                "th_padding": [
                    2432,
                    2179,
                    2436,
                    1933,
                    1935,
                    1937,
                    1940,
                    2342,
                    2345,
                    2235,
                    2238,
                    2245,
                    2123,
                    2379,
                    2126,
                    2382,
                    2292,
                    2295,
                    2302,
                    2175
                ],
                "image_shape": [
                    1952,
                    2240,
                    1954,
                    1955,
                    1956,
                    2115,
                    2243,
                    2279,
                    2347,
                    2222,
                    2350,
                    2128,
                    2297,
                    2300,
                    2334,
                    1951
                ],
                "transpose_shape": [
                    1952
                ],
                "int_or_none": [
                    2016,
                    1986,
                    1955,
                    2001,
                    1971
                ],
                "volume_shape": [
                    2371,
                    1967,
                    1968,
                    1969,
                    1970,
                    1971,
                    1972,
                    2384
                ],
                "filter_shape": [
                    1984,
                    1985,
                    1986,
                    1987,
                    2016,
                    2017,
                    1997,
                    1998,
                    1999,
                    2000,
                    2001,
                    2002,
                    2014,
                    2015,
                    2012,
                    2013,
                    1982,
                    1983
                ],
                "conv_out": [
                    2307,
                    2181,
                    2182,
                    2310,
                    2184,
                    2438,
                    2439,
                    2441,
                    2344,
                    2351,
                    2353,
                    2301,
                    2237,
                    2244,
                    2250,
                    2125,
                    2253,
                    2254,
                    2381,
                    2131,
                    2387,
                    2133,
                    2389,
                    2025,
                    2027,
                    2029,
                    2030,
                    2038,
                    2294,
                    2040,
                    2042,
                    2044,
                    2045
                ],
                "strides": [
                    2178,
                    2435,
                    2309,
                    2183,
                    2440,
                    2040,
                    2207,
                    2208,
                    2463,
                    2468,
                    2086,
                    2346,
                    2091,
                    2219,
                    2475,
                    2476,
                    2352,
                    2239,
                    2504,
                    2252,
                    2509,
                    2127,
                    2383,
                    2132,
                    2388,
                    2517,
                    2518,
                    2519,
                    2025,
                    2027,
                    2796,
                    2038,
                    2296,
                    2042,
                    2815
                ],
                "conv_out.dimshuffle": [
                    2044,
                    2029
                ],
                "dilation_rate": [
                    2209,
                    2210,
                    2242,
                    2306,
                    2085,
                    2249,
                    2092,
                    2220,
                    2349,
                    2066,
                    2130,
                    2386,
                    2299
                ],
                "temporal_padding": [
                    2067
                ],
                "conv2d": [
                    2090
                ],
                "squeeze": [
                    2097,
                    2253,
                    2095
                ],
                "_preprocess_conv2d_image_shape": [
                    2115,
                    2334,
                    2222,
                    2279
                ],
                "kernel.eval": [
                    2374,
                    2163,
                    2420,
                    2118
                ],
                "_preprocess_conv2d_filter_shape": [
                    2170,
                    2287,
                    2230,
                    2119
                ],
                "_preprocess_conv2d_input": [
                    2340,
                    2121,
                    2289,
                    2232,
                    2172
                ],
                "_preprocess_conv2d_kernel": [
                    2234,
                    2122,
                    2291,
                    2173
                ],
                "_preprocess_padding": [
                    2432,
                    2342,
                    2123,
                    2379,
                    2292,
                    2235,
                    2175
                ],
                "T.nnet.conv2d": [
                    2244,
                    2344,
                    2125,
                    2294,
                    2237,
                    2301
                ],
                "_postprocess_conv2d_output": [
                    2307,
                    2182,
                    2250,
                    2351,
                    2131
                ],
                "flip_filters": [
                    2152,
                    2180,
                    2437,
                    2408
                ],
                "op": [
                    2176,
                    2433,
                    2181,
                    2438
                ],
                "T.nnet.abstract_conv.AbstractConv2d_gradInputs": [
                    2176
                ],
                "spatial_start_dim": [
                    2216,
                    2253,
                    2213,
                    2215
                ],
                "depthwise_kernel": [
                    2337,
                    2341,
                    2280,
                    2217,
                    2282,
                    2344,
                    2223,
                    2225,
                    2290,
                    2294,
                    2233,
                    2237,
                    2335
                ],
                "pointwise_kernel": [
                    2244,
                    2218,
                    2284,
                    2286,
                    2227,
                    2291,
                    2229,
                    2234,
                    2301
                ],
                "depthwise_kernel_shape": [
                    2335,
                    2336,
                    2337,
                    2338,
                    2341,
                    2348,
                    2223,
                    2224,
                    2225,
                    2226,
                    2352,
                    2233,
                    2241,
                    2280,
                    2281,
                    2282,
                    2283,
                    2290,
                    2298
                ],
                "depthwise_kernel.eval": [
                    2225,
                    2282,
                    2337
                ],
                "_preprocess_conv2d_depthwise_filter_shape": [
                    2226,
                    2283,
                    2338
                ],
                "pointwise_kernel_shape": [
                    2305,
                    2308,
                    2248,
                    2251,
                    2284,
                    2285,
                    2286,
                    2287,
                    2227,
                    2228,
                    2229,
                    2230
                ],
                "pointwise_kernel.eval": [
                    2229,
                    2286
                ],
                "_preprocess_conv2d_depthwise_kernel": [
                    2233,
                    2290,
                    2341
                ],
                "_preprocess_conv3d_volume_shape": [
                    2371
                ],
                "_preprocess_conv3d_filter_shape": [
                    2427,
                    2375
                ],
                "_preprocess_conv3d_input": [
                    2377,
                    2429
                ],
                "_preprocess_conv3d_kernel": [
                    2378,
                    2430
                ],
                "T.nnet.conv3d": [
                    2381
                ],
                "_postprocess_conv3d_output": [
                    2387,
                    2439
                ],
                "T.nnet.abstract_conv.AbstractConv3d_gradInputs": [
                    2433
                ],
                "pool_size": [
                    2468,
                    2504,
                    2509,
                    2448,
                    2451,
                    2452,
                    2491,
                    2492,
                    2493,
                    2463
                ],
                "w_pad": [
                    2451,
                    2491,
                    2453,
                    2494
                ],
                "h_pad": [
                    2492,
                    2452,
                    2453,
                    2494
                ],
                "pad": [
                    2496,
                    2465,
                    2470,
                    2506,
                    2511,
                    2453,
                    2455,
                    2494
                ],
                "pool_mode": [
                    2467,
                    2503,
                    2473,
                    2508,
                    2514,
                    2462
                ],
                "pool_out": [
                    2528,
                    2468,
                    2504,
                    2527,
                    2477,
                    2509,
                    2482,
                    2483,
                    2521,
                    2463
                ],
                "pool.pool_2d": [
                    2468,
                    2463
                ],
                "pool": [
                    2504,
                    2468,
                    2509,
                    2463
                ],
                "expected_width": [
                    2522,
                    2475,
                    2517,
                    2478
                ],
                "expected_height": [
                    2523,
                    2476,
                    2518,
                    2479
                ],
                "pool_out.dimshuffle": [
                    2482,
                    2527
                ],
                "d_pad": [
                    2493,
                    2494
                ],
                "pool.pool_3d": [
                    2504,
                    2509
                ],
                "expected_depth": [
                    2524,
                    2519
                ],
                "bias": [
                    2562,
                    2563,
                    2565,
                    2567,
                    2568,
                    2570,
                    2572,
                    2533,
                    2536,
                    2537,
                    2540,
                    2541,
                    2543,
                    2545,
                    2546,
                    2548,
                    2551,
                    2552,
                    2554,
                    2556,
                    2557,
                    2559
                ],
                "bias_shape": [
                    2563,
                    2565,
                    2568,
                    2537,
                    2570,
                    2541,
                    2543,
                    2546,
                    2548,
                    2552,
                    2554,
                    2557,
                    2559
                ],
                "bias.shape": [
                    2537
                ],
                "rng.normal": [
                    2585,
                    2614,
                    2617
                ],
                "stddev": [
                    2585,
                    2619,
                    2614,
                    2617
                ],
                "rng.uniform": [
                    2594
                ],
                "minval": [
                    2594
                ],
                "maxval": [
                    2594
                ],
                "p": [
                    2603
                ],
                "normal_t": [
                    2617,
                    2619
                ],
                "Y_": [
                    2632,
                    2630,
                    2631
                ],
                "T.alloc": [
                    2630
                ],
                "Y.shape": [
                    2668,
                    2636,
                    2630,
                    2631
                ],
                "Y": [
                    2691,
                    2630,
                    2631,
                    2668,
                    2636,
                    2637,
                    2673,
                    2674
                ],
                "skip_idxs": [
                    2642,
                    2636,
                    2637,
                    2638
                ],
                "non_repeats": [
                    2637,
                    2638
                ],
                "non_repeats.nonzero": [
                    2638
                ],
                "active_skip_idxs": [
                    2657,
                    2642,
                    2646
                ],
                "nonzero": [
                    2642
                ],
                "active": [
                    2642,
                    2645,
                    2649,
                    2650,
                    2653
                ],
                "active_next": [
                    2661,
                    2662,
                    2664,
                    2643,
                    2651
                ],
                "log_p_curr.shape": [
                    2647
                ],
                "log_p_curr": [
                    2662,
                    2647
                ],
                "common_factor": [
                    2658,
                    2692,
                    2693,
                    2649,
                    2650
                ],
                "log_p_prev": [
                    2649,
                    2650
                ],
                "p_prev": [
                    2657,
                    2650,
                    2653
                ],
                "_p_prev": [
                    2657,
                    2658,
                    2651,
                    2653,
                    2655
                ],
                "zeros": [
                    2661,
                    2670,
                    2671,
                    2677,
                    2678,
                    2651
                ],
                "T.inc_subtensor": [
                    2657,
                    2655
                ],
                "updated_log_p_prev": [
                    2658,
                    2662
                ],
                "log_p_next": [
                    2664,
                    2660
                ],
                "smoothed_predict": [
                    2668,
                    2669
                ],
                "predict": [
                    2691,
                    2668
                ],
                "np.float32": [
                    2668
                ],
                "L": [
                    2669,
                    2670,
                    2682,
                    2684,
                    2686
                ],
                "log_first": [
                    2682,
                    2671
                ],
                "f_skip_idxs": [
                    2673,
                    2677
                ],
                "ctc_create_skip_idxs": [
                    2673,
                    2674
                ],
                "b_skip_idxs": [
                    2674,
                    2678
                ],
                "f_active_next": [
                    2677,
                    2679
                ],
                "log_f_next": [
                    2677,
                    2679
                ],
                "ctc_update_log_p": [
                    2677,
                    2678
                ],
                "f_active": [
                    2681,
                    2685,
                    2677
                ],
                "log_f_curr": [
                    2677
                ],
                "log_f_prev": [
                    2677
                ],
                "b_active_next": [
                    2678,
                    2679
                ],
                "log_b_next": [
                    2678,
                    2679
                ],
                "b_active": [
                    2681,
                    2685,
                    2678
                ],
                "log_b_curr": [
                    2678
                ],
                "log_b_prev": [
                    2678
                ],
                "log_f_probs": [
                    2681,
                    2686
                ],
                "log_b_probs": [
                    2681,
                    2686
                ],
                "np.int32": [
                    2682
                ],
                "idxs": [
                    2684,
                    2685
                ],
                "L.shape": [
                    2684
                ],
                "f_active.dimshuffle": [
                    2685
                ],
                "b_active.dimshuffle": [
                    2685
                ],
                "log_probs": [
                    2691,
                    2692,
                    2693,
                    2686,
                    2687
                ],
                "ctc_path_probs": [
                    2691
                ],
                "ctc_interleave_blanks": [
                    2691
                ],
                "total_log_prob": [
                    2693,
                    2694
                ],
                "mask.nonzero": [
                    2693
                ],
                "y_pred_step": [
                    2716,
                    2718
                ],
                "input_length_step": [
                    2716
                ],
                "y_true_step": [
                    2717,
                    2718
                ],
                "label_length_step": [
                    2717
                ],
                "ctc_cost": [
                    2718
                ],
                "ret": [
                    2720,
                    2726,
                    2727
                ],
                "ctc_step": [
                    2721
                ],
                "y_true": [
                    2723
                ],
                "y_pred": [
                    2723
                ],
                "label_length": [
                    2723
                ],
                "ret.dimshuffle": [
                    2726
                ],
                "theano.map": [
                    2744
                ],
                "fn": [
                    2744,
                    2789,
                    2766
                ],
                "elems": [
                    2784,
                    2785,
                    2790,
                    2761,
                    2762,
                    2767,
                    2744
                ],
                "initializer": [
                    2784,
                    2790,
                    2760,
                    2761,
                    2767,
                    2783
                ],
                "theano.foldl": [
                    2766
                ],
                "acc": [
                    2789,
                    2766
                ],
                "theano.foldr": [
                    2789
                ],
                "stride": [
                    2802,
                    2803,
                    2796
                ],
                "output_length": [
                    2801,
                    2798
                ],
                "feature_dim": [
                    2818,
                    2829,
                    2798,
                    2805,
                    2845
                ],
                "filters": [
                    2818,
                    2834,
                    2850,
                    2798
                ],
                "slice_length": [
                    2802,
                    2804
                ],
                "kernel_size": [
                    2825,
                    2827,
                    2803,
                    2841,
                    2843
                ],
                "xs.append": [
                    2804,
                    2844
                ],
                "x_aggregate": [
                    2808,
                    2848,
                    2806,
                    2847
                ],
                "concatenate": [
                    2832,
                    2806,
                    2847
                ],
                "batch_dot": [
                    2808,
                    2848
                ],
                "stride_row": [
                    2824,
                    2825,
                    2840,
                    2841,
                    2815
                ],
                "stride_col": [
                    2826,
                    2827,
                    2842,
                    2843,
                    2815
                ],
                "output_row": [
                    2816,
                    2850,
                    2822,
                    2834,
                    2838
                ],
                "output_col": [
                    2816,
                    2850,
                    2823,
                    2831,
                    2834,
                    2839
                ],
                "slice_row": [
                    2824,
                    2840,
                    2828,
                    2844
                ],
                "slice_col": [
                    2826,
                    2842,
                    2828,
                    2844
                ],
                "x_flatten": [
                    2828,
                    2830
                ],
                "output.append": [
                    2830
                ],
                "dot": [
                    2830
                ]
            }
        },
        "/Volumes/SSD2T/bgp_envs_non_pandas/repos/keras_20/keras/layers/convolutional.py": {
            "buggy_functions": [
                {
                    "function_name": "__init__",
                    "function_code": "@interfaces.legacy_deconv2d_support\ndef __init__(self, filters,\n             kernel_size,\n             strides=(1, 1),\n             padding='valid',\n             output_padding=None,\n             data_format=None,\n             activation=None,\n             use_bias=True,\n             kernel_initializer='glorot_uniform',\n             bias_initializer='zeros',\n             kernel_regularizer=None,\n             bias_regularizer=None,\n             activity_regularizer=None,\n             kernel_constraint=None,\n             bias_constraint=None,\n             **kwargs):\n    super(Conv2DTranspose, self).__init__(\n        filters,\n        kernel_size,\n        strides=strides,\n        padding=padding,\n        data_format=data_format,\n        activation=activation,\n        use_bias=use_bias,\n        kernel_initializer=kernel_initializer,\n        bias_initializer=bias_initializer,\n        kernel_regularizer=kernel_regularizer,\n        bias_regularizer=bias_regularizer,\n        activity_regularizer=activity_regularizer,\n        kernel_constraint=kernel_constraint,\n        bias_constraint=bias_constraint,\n        **kwargs)\n\n    self.output_padding = output_padding\n    if self.output_padding is not None:\n        self.output_padding = conv_utils.normalize_tuple(\n            self.output_padding, 2, 'output_padding')\n        for stride, out_pad in zip(self.strides, self.output_padding):\n            if out_pad >= stride:\n                raise ValueError('Stride ' + str(self.strides) + ' must be '\n                                 'greater than output padding ' +\n                                 str(self.output_padding))\n",
                    "decorators": [
                        "interfaces.legacy_deconv2d_support"
                    ],
                    "docstring": null,
                    "start_line": 727,
                    "end_line": 769,
                    "variables": {
                        "__init__": [
                            744
                        ],
                        "super": [
                            744
                        ],
                        "Conv2DTranspose": [
                            744
                        ],
                        "self": [
                            769,
                            744,
                            761,
                            762,
                            763,
                            764,
                            765,
                            767
                        ],
                        "filters": [
                            745
                        ],
                        "kernel_size": [
                            746
                        ],
                        "strides": [
                            747
                        ],
                        "padding": [
                            748
                        ],
                        "data_format": [
                            749
                        ],
                        "activation": [
                            750
                        ],
                        "use_bias": [
                            751
                        ],
                        "kernel_initializer": [
                            752
                        ],
                        "bias_initializer": [
                            753
                        ],
                        "kernel_regularizer": [
                            754
                        ],
                        "bias_regularizer": [
                            755
                        ],
                        "activity_regularizer": [
                            756
                        ],
                        "kernel_constraint": [
                            757
                        ],
                        "bias_constraint": [
                            758
                        ],
                        "kwargs": [
                            759
                        ],
                        "self.output_padding": [
                            769,
                            761,
                            762,
                            763,
                            764,
                            765
                        ],
                        "output_padding": [
                            761
                        ],
                        "conv_utils.normalize_tuple": [
                            763
                        ],
                        "conv_utils": [
                            763
                        ],
                        "stride": [
                            765,
                            766
                        ],
                        "out_pad": [
                            765,
                            766
                        ],
                        "zip": [
                            765
                        ],
                        "self.strides": [
                            765,
                            767
                        ],
                        "ValueError": [
                            767
                        ],
                        "str": [
                            769,
                            767
                        ],
                        "interfaces.legacy_deconv2d_support": [
                            727
                        ],
                        "interfaces": [
                            727
                        ]
                    },
                    "filtered_variables": {
                        "__init__": [
                            744
                        ],
                        "Conv2DTranspose": [
                            744
                        ],
                        "self": [
                            769,
                            744,
                            761,
                            762,
                            763,
                            764,
                            765,
                            767
                        ],
                        "filters": [
                            745
                        ],
                        "kernel_size": [
                            746
                        ],
                        "strides": [
                            747
                        ],
                        "padding": [
                            748
                        ],
                        "data_format": [
                            749
                        ],
                        "activation": [
                            750
                        ],
                        "use_bias": [
                            751
                        ],
                        "kernel_initializer": [
                            752
                        ],
                        "bias_initializer": [
                            753
                        ],
                        "kernel_regularizer": [
                            754
                        ],
                        "bias_regularizer": [
                            755
                        ],
                        "activity_regularizer": [
                            756
                        ],
                        "kernel_constraint": [
                            757
                        ],
                        "bias_constraint": [
                            758
                        ],
                        "kwargs": [
                            759
                        ],
                        "self.output_padding": [
                            769,
                            761,
                            762,
                            763,
                            764,
                            765
                        ],
                        "output_padding": [
                            761
                        ],
                        "conv_utils.normalize_tuple": [
                            763
                        ],
                        "conv_utils": [
                            763
                        ],
                        "stride": [
                            765,
                            766
                        ],
                        "out_pad": [
                            765,
                            766
                        ],
                        "self.strides": [
                            765,
                            767
                        ],
                        "interfaces.legacy_deconv2d_support": [
                            727
                        ],
                        "interfaces": [
                            727
                        ]
                    },
                    "diff_line_number": 733,
                    "class_data": {
                        "signature": "class Conv2DTranspose(Conv2D)",
                        "docstring": "Transposed convolution layer (sometimes called Deconvolution).\n\nThe need for transposed convolutions generally arises\nfrom the desire to use a transformation going in the opposite direction\nof a normal convolution, i.e., from something that has the shape of the\noutput of some convolution to something that has the shape of its input\nwhile maintaining a connectivity pattern that is compatible with\nsaid convolution.\n\nWhen using this layer as the first layer in a model,\nprovide the keyword argument `input_shape`\n(tuple of integers, does not include the sample axis),\ne.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures\nin `data_format=\"channels_last\"`.\n\n# Arguments\n    filters: Integer, the dimensionality of the output space\n        (i.e. the number of output filters in the convolution).\n    kernel_size: An integer or tuple/list of 2 integers, specifying the\n        height and width of the 2D convolution window.\n        Can be a single integer to specify the same value for\n        all spatial dimensions.\n    strides: An integer or tuple/list of 2 integers,\n        specifying the strides of the convolution\n        along the height and width.\n        Can be a single integer to specify the same value for\n        all spatial dimensions.\n        Specifying any stride value != 1 is incompatible with specifying\n        any `dilation_rate` value != 1.\n    padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n    output_padding: An integer or tuple/list of 2 integers,\n        specifying the amount of padding along the height and width\n        of the output tensor.\n        Can be a single integer to specify the same value for all\n        spatial dimensions.\n        The amount of output padding along a given dimension must be\n        lower than the stride along that same dimension.\n        If set to `None` (default), the output shape is inferred.\n    data_format: A string,\n        one of `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs.\n        `\"channels_last\"` corresponds to inputs with shape\n        `(batch, height, width, channels)` while `\"channels_first\"`\n        corresponds to inputs with shape\n        `(batch, channels, height, width)`.\n        It defaults to the `image_data_format` value found in your\n        Keras config file at `~/.keras/keras.json`.\n        If you never set it, then it will be \"channels_last\".\n    dilation_rate: an integer or tuple/list of 2 integers, specifying\n        the dilation rate to use for dilated convolution.\n        Can be a single integer to specify the same value for\n        all spatial dimensions.\n        Currently, specifying any `dilation_rate` value != 1 is\n        incompatible with specifying any stride value != 1.\n    activation: Activation function to use\n        (see [activations](../activations.md)).\n        If you don't specify anything, no activation is applied\n        (ie. \"linear\" activation: `a(x) = x`).\n    use_bias: Boolean, whether the layer uses a bias vector.\n    kernel_initializer: Initializer for the `kernel` weights matrix\n        (see [initializers](../initializers.md)).\n    bias_initializer: Initializer for the bias vector\n        (see [initializers](../initializers.md)).\n    kernel_regularizer: Regularizer function applied to\n        the `kernel` weights matrix\n        (see [regularizer](../regularizers.md)).\n    bias_regularizer: Regularizer function applied to the bias vector\n        (see [regularizer](../regularizers.md)).\n    activity_regularizer: Regularizer function applied to\n        the output of the layer (its \"activation\").\n        (see [regularizer](../regularizers.md)).\n    kernel_constraint: Constraint function applied to the kernel matrix\n        (see [constraints](../constraints.md)).\n    bias_constraint: Constraint function applied to the bias vector\n        (see [constraints](../constraints.md)).\n\n# Input shape\n    4D tensor with shape:\n    `(batch, channels, rows, cols)`\n    if `data_format` is `\"channels_first\"`\n    or 4D tensor with shape:\n    `(batch, rows, cols, channels)`\n    if `data_format` is `\"channels_last\"`.\n\n# Output shape\n    4D tensor with shape:\n    `(batch, filters, new_rows, new_cols)`\n    if `data_format` is `\"channels_first\"`\n    or 4D tensor with shape:\n    `(batch, new_rows, new_cols, filters)`\n    if `data_format` is `\"channels_last\"`.\n    `rows` and `cols` values might have changed due to padding.\n    If `output_padding` is specified:\n\n    ```\n    new_rows = (rows - 1) * strides[0] + kernel_size[0] - 2 * padding[0] + output_padding[0]\n    new_cols = (cols - 1) * strides[1] + kernel_size[1] - 2 * padding[1] + output_padding[1]\n    ```\n\n# References\n    - [A guide to convolution arithmetic for deep learning](https://arxiv.org/abs/1603.07285v1)\n    - [Deconvolutional Networks](http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf)",
                        "constructor_docstring": null,
                        "functions": [
                            "@interfaces.legacy_deconv2d_support\ndef __init__(self, filters, kernel_size, strides=(1, 1), padding='valid', output_padding=None, data_format=None, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs):\n    super(Conv2DTranspose, self).__init__(filters, kernel_size, strides=strides, padding=padding, data_format=data_format, activation=activation, use_bias=use_bias, kernel_initializer=kernel_initializer, bias_initializer=bias_initializer, kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer, activity_regularizer=activity_regularizer, kernel_constraint=kernel_constraint, bias_constraint=bias_constraint, **kwargs)\n    self.output_padding = output_padding\n    if self.output_padding is not None:\n        self.output_padding = conv_utils.normalize_tuple(self.output_padding, 2, 'output_padding')\n        for stride, out_pad in zip(self.strides, self.output_padding):\n            if out_pad >= stride:\n                raise ValueError('Stride ' + str(self.strides) + ' must be greater than output padding ' + str(self.output_padding))",
                            "def build(self, input_shape):\n    if len(input_shape) != 4:\n        raise ValueError('Inputs should have rank ' + str(4) + '; Received input shape:', str(input_shape))\n    if self.data_format == 'channels_first':\n        channel_axis = 1\n    else:\n        channel_axis = -1\n    if input_shape[channel_axis] is None:\n        raise ValueError('The channel dimension of the inputs should be defined. Found `None`.')\n    input_dim = input_shape[channel_axis]\n    kernel_shape = self.kernel_size + (self.filters, input_dim)\n    self.kernel = self.add_weight(shape=kernel_shape, initializer=self.kernel_initializer, name='kernel', regularizer=self.kernel_regularizer, constraint=self.kernel_constraint)\n    if self.use_bias:\n        self.bias = self.add_weight(shape=(self.filters,), initializer=self.bias_initializer, name='bias', regularizer=self.bias_regularizer, constraint=self.bias_constraint)\n    else:\n        self.bias = None\n    self.input_spec = InputSpec(ndim=4, axes={channel_axis: input_dim})\n    self.built = True",
                            "def call(self, inputs):\n    input_shape = K.shape(inputs)\n    batch_size = input_shape[0]\n    if self.data_format == 'channels_first':\n        h_axis, w_axis = (2, 3)\n    else:\n        h_axis, w_axis = (1, 2)\n    height, width = (input_shape[h_axis], input_shape[w_axis])\n    kernel_h, kernel_w = self.kernel_size\n    stride_h, stride_w = self.strides\n    if self.output_padding is None:\n        out_pad_h = out_pad_w = None\n    else:\n        out_pad_h, out_pad_w = self.output_padding\n    out_height = conv_utils.deconv_length(height, stride_h, kernel_h, self.padding, out_pad_h)\n    out_width = conv_utils.deconv_length(width, stride_w, kernel_w, self.padding, out_pad_w)\n    if self.data_format == 'channels_first':\n        output_shape = (batch_size, self.filters, out_height, out_width)\n    else:\n        output_shape = (batch_size, out_height, out_width, self.filters)\n    outputs = K.conv2d_transpose(inputs, self.kernel, output_shape, self.strides, padding=self.padding, data_format=self.data_format)\n    if self.use_bias:\n        outputs = K.bias_add(outputs, self.bias, data_format=self.data_format)\n    if self.activation is not None:\n        return self.activation(outputs)\n    return outputs",
                            "def compute_output_shape(self, input_shape):\n    output_shape = list(input_shape)\n    if self.data_format == 'channels_first':\n        c_axis, h_axis, w_axis = (1, 2, 3)\n    else:\n        c_axis, h_axis, w_axis = (3, 1, 2)\n    kernel_h, kernel_w = self.kernel_size\n    stride_h, stride_w = self.strides\n    if self.output_padding is None:\n        out_pad_h = out_pad_w = None\n    else:\n        out_pad_h, out_pad_w = self.output_padding\n    output_shape[c_axis] = self.filters\n    output_shape[h_axis] = conv_utils.deconv_length(output_shape[h_axis], stride_h, kernel_h, self.padding, out_pad_h)\n    output_shape[w_axis] = conv_utils.deconv_length(output_shape[w_axis], stride_w, kernel_w, self.padding, out_pad_w)\n    return tuple(output_shape)",
                            "def get_config(self):\n    config = super(Conv2DTranspose, self).get_config()\n    config.pop('dilation_rate')\n    config['output_padding'] = self.output_padding\n    return config"
                        ],
                        "constructor_variables": [
                            "output_padding"
                        ],
                        "class_level_variables": [],
                        "class_decorators": [],
                        "function_signatures": [
                            "__init__(self, filters, kernel_size, strides=(1, 1), padding='valid', output_padding=None, data_format=None, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)",
                            "build(self, input_shape)",
                            "call(self, inputs)",
                            "compute_output_shape(self, input_shape)",
                            "get_config(self)"
                        ]
                    },
                    "variable_values": [
                        [
                            {},
                            {}
                        ]
                    ],
                    "angelic_variable_values": [
                        [
                            {},
                            {}
                        ]
                    ]
                },
                {
                    "function_name": "call",
                    "function_code": "def call(self, inputs):\n    input_shape = K.shape(inputs)\n    batch_size = input_shape[0]\n    if self.data_format == 'channels_first':\n        h_axis, w_axis = 2, 3\n    else:\n        h_axis, w_axis = 1, 2\n\n    height, width = input_shape[h_axis], input_shape[w_axis]\n    kernel_h, kernel_w = self.kernel_size\n    stride_h, stride_w = self.strides\n    if self.output_padding is None:\n        out_pad_h = out_pad_w = None\n    else:\n        out_pad_h, out_pad_w = self.output_padding\n\n    # Infer the dynamic output shape:\n    out_height = conv_utils.deconv_length(height,\n                                          stride_h, kernel_h,\n                                          self.padding,\n                                          out_pad_h)\n    out_width = conv_utils.deconv_length(width,\n                                         stride_w, kernel_w,\n                                         self.padding,\n                                         out_pad_w)\n    if self.data_format == 'channels_first':\n        output_shape = (batch_size, self.filters, out_height, out_width)\n    else:\n        output_shape = (batch_size, out_height, out_width, self.filters)\n\n    outputs = K.conv2d_transpose(\n        inputs,\n        self.kernel,\n        output_shape,\n        self.strides,\n        padding=self.padding,\n        data_format=self.data_format)\n\n    if self.use_bias:\n        outputs = K.bias_add(\n            outputs,\n            self.bias,\n            data_format=self.data_format)\n\n    if self.activation is not None:\n        return self.activation(outputs)\n    return outputs\n",
                    "decorators": [],
                    "docstring": null,
                    "start_line": 803,
                    "end_line": 849,
                    "variables": {
                        "input_shape": [
                            811,
                            804,
                            805
                        ],
                        "K.shape": [
                            804
                        ],
                        "K": [
                            833,
                            842,
                            804
                        ],
                        "inputs": [
                            834,
                            804
                        ],
                        "batch_size": [
                            829,
                            805,
                            831
                        ],
                        "self.data_format": [
                            828,
                            845,
                            806,
                            839
                        ],
                        "self": [
                            806,
                            812,
                            813,
                            814,
                            817,
                            822,
                            826,
                            828,
                            829,
                            831,
                            835,
                            837,
                            838,
                            839,
                            841,
                            844,
                            845,
                            847,
                            848
                        ],
                        "h_axis": [
                            809,
                            811,
                            807
                        ],
                        "w_axis": [
                            809,
                            811,
                            807
                        ],
                        "height": [
                            811,
                            820
                        ],
                        "width": [
                            824,
                            811
                        ],
                        "kernel_h": [
                            812,
                            821
                        ],
                        "kernel_w": [
                            825,
                            812
                        ],
                        "self.kernel_size": [
                            812
                        ],
                        "stride_h": [
                            821,
                            813
                        ],
                        "stride_w": [
                            825,
                            813
                        ],
                        "self.strides": [
                            837,
                            813
                        ],
                        "self.output_padding": [
                            817,
                            814
                        ],
                        "out_pad_h": [
                            817,
                            823,
                            815
                        ],
                        "out_pad_w": [
                            817,
                            827,
                            815
                        ],
                        "out_height": [
                            820,
                            829,
                            831
                        ],
                        "conv_utils.deconv_length": [
                            824,
                            820
                        ],
                        "conv_utils": [
                            824,
                            820
                        ],
                        "self.padding": [
                            838,
                            826,
                            822
                        ],
                        "out_width": [
                            824,
                            829,
                            831
                        ],
                        "output_shape": [
                            836,
                            829,
                            831
                        ],
                        "self.filters": [
                            829,
                            831
                        ],
                        "outputs": [
                            833,
                            842,
                            843,
                            848,
                            849
                        ],
                        "K.conv2d_transpose": [
                            833
                        ],
                        "self.kernel": [
                            835
                        ],
                        "self.use_bias": [
                            841
                        ],
                        "K.bias_add": [
                            842
                        ],
                        "self.bias": [
                            844
                        ],
                        "self.activation": [
                            848,
                            847
                        ]
                    },
                    "filtered_variables": {
                        "input_shape": [
                            811,
                            804,
                            805
                        ],
                        "K.shape": [
                            804
                        ],
                        "K": [
                            833,
                            842,
                            804
                        ],
                        "inputs": [
                            834,
                            804
                        ],
                        "batch_size": [
                            829,
                            805,
                            831
                        ],
                        "self.data_format": [
                            828,
                            845,
                            806,
                            839
                        ],
                        "self": [
                            806,
                            812,
                            813,
                            814,
                            817,
                            822,
                            826,
                            828,
                            829,
                            831,
                            835,
                            837,
                            838,
                            839,
                            841,
                            844,
                            845,
                            847,
                            848
                        ],
                        "h_axis": [
                            809,
                            811,
                            807
                        ],
                        "w_axis": [
                            809,
                            811,
                            807
                        ],
                        "height": [
                            811,
                            820
                        ],
                        "width": [
                            824,
                            811
                        ],
                        "kernel_h": [
                            812,
                            821
                        ],
                        "kernel_w": [
                            825,
                            812
                        ],
                        "self.kernel_size": [
                            812
                        ],
                        "stride_h": [
                            821,
                            813
                        ],
                        "stride_w": [
                            825,
                            813
                        ],
                        "self.strides": [
                            837,
                            813
                        ],
                        "self.output_padding": [
                            817,
                            814
                        ],
                        "out_pad_h": [
                            817,
                            823,
                            815
                        ],
                        "out_pad_w": [
                            817,
                            827,
                            815
                        ],
                        "out_height": [
                            820,
                            829,
                            831
                        ],
                        "conv_utils.deconv_length": [
                            824,
                            820
                        ],
                        "conv_utils": [
                            824,
                            820
                        ],
                        "self.padding": [
                            838,
                            826,
                            822
                        ],
                        "out_width": [
                            824,
                            829,
                            831
                        ],
                        "output_shape": [
                            836,
                            829,
                            831
                        ],
                        "self.filters": [
                            829,
                            831
                        ],
                        "outputs": [
                            833,
                            842,
                            843,
                            848,
                            849
                        ],
                        "K.conv2d_transpose": [
                            833
                        ],
                        "self.kernel": [
                            835
                        ],
                        "self.use_bias": [
                            841
                        ],
                        "K.bias_add": [
                            842
                        ],
                        "self.bias": [
                            844
                        ],
                        "self.activation": [
                            848,
                            847
                        ]
                    },
                    "diff_line_number": 823,
                    "class_data": {
                        "signature": "class Conv2DTranspose(Conv2D)",
                        "docstring": "Transposed convolution layer (sometimes called Deconvolution).\n\nThe need for transposed convolutions generally arises\nfrom the desire to use a transformation going in the opposite direction\nof a normal convolution, i.e., from something that has the shape of the\noutput of some convolution to something that has the shape of its input\nwhile maintaining a connectivity pattern that is compatible with\nsaid convolution.\n\nWhen using this layer as the first layer in a model,\nprovide the keyword argument `input_shape`\n(tuple of integers, does not include the sample axis),\ne.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures\nin `data_format=\"channels_last\"`.\n\n# Arguments\n    filters: Integer, the dimensionality of the output space\n        (i.e. the number of output filters in the convolution).\n    kernel_size: An integer or tuple/list of 2 integers, specifying the\n        height and width of the 2D convolution window.\n        Can be a single integer to specify the same value for\n        all spatial dimensions.\n    strides: An integer or tuple/list of 2 integers,\n        specifying the strides of the convolution\n        along the height and width.\n        Can be a single integer to specify the same value for\n        all spatial dimensions.\n        Specifying any stride value != 1 is incompatible with specifying\n        any `dilation_rate` value != 1.\n    padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n    output_padding: An integer or tuple/list of 2 integers,\n        specifying the amount of padding along the height and width\n        of the output tensor.\n        Can be a single integer to specify the same value for all\n        spatial dimensions.\n        The amount of output padding along a given dimension must be\n        lower than the stride along that same dimension.\n        If set to `None` (default), the output shape is inferred.\n    data_format: A string,\n        one of `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs.\n        `\"channels_last\"` corresponds to inputs with shape\n        `(batch, height, width, channels)` while `\"channels_first\"`\n        corresponds to inputs with shape\n        `(batch, channels, height, width)`.\n        It defaults to the `image_data_format` value found in your\n        Keras config file at `~/.keras/keras.json`.\n        If you never set it, then it will be \"channels_last\".\n    dilation_rate: an integer or tuple/list of 2 integers, specifying\n        the dilation rate to use for dilated convolution.\n        Can be a single integer to specify the same value for\n        all spatial dimensions.\n        Currently, specifying any `dilation_rate` value != 1 is\n        incompatible with specifying any stride value != 1.\n    activation: Activation function to use\n        (see [activations](../activations.md)).\n        If you don't specify anything, no activation is applied\n        (ie. \"linear\" activation: `a(x) = x`).\n    use_bias: Boolean, whether the layer uses a bias vector.\n    kernel_initializer: Initializer for the `kernel` weights matrix\n        (see [initializers](../initializers.md)).\n    bias_initializer: Initializer for the bias vector\n        (see [initializers](../initializers.md)).\n    kernel_regularizer: Regularizer function applied to\n        the `kernel` weights matrix\n        (see [regularizer](../regularizers.md)).\n    bias_regularizer: Regularizer function applied to the bias vector\n        (see [regularizer](../regularizers.md)).\n    activity_regularizer: Regularizer function applied to\n        the output of the layer (its \"activation\").\n        (see [regularizer](../regularizers.md)).\n    kernel_constraint: Constraint function applied to the kernel matrix\n        (see [constraints](../constraints.md)).\n    bias_constraint: Constraint function applied to the bias vector\n        (see [constraints](../constraints.md)).\n\n# Input shape\n    4D tensor with shape:\n    `(batch, channels, rows, cols)`\n    if `data_format` is `\"channels_first\"`\n    or 4D tensor with shape:\n    `(batch, rows, cols, channels)`\n    if `data_format` is `\"channels_last\"`.\n\n# Output shape\n    4D tensor with shape:\n    `(batch, filters, new_rows, new_cols)`\n    if `data_format` is `\"channels_first\"`\n    or 4D tensor with shape:\n    `(batch, new_rows, new_cols, filters)`\n    if `data_format` is `\"channels_last\"`.\n    `rows` and `cols` values might have changed due to padding.\n    If `output_padding` is specified:\n\n    ```\n    new_rows = (rows - 1) * strides[0] + kernel_size[0] - 2 * padding[0] + output_padding[0]\n    new_cols = (cols - 1) * strides[1] + kernel_size[1] - 2 * padding[1] + output_padding[1]\n    ```\n\n# References\n    - [A guide to convolution arithmetic for deep learning](https://arxiv.org/abs/1603.07285v1)\n    - [Deconvolutional Networks](http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf)",
                        "constructor_docstring": null,
                        "functions": [
                            "@interfaces.legacy_deconv2d_support\ndef __init__(self, filters, kernel_size, strides=(1, 1), padding='valid', output_padding=None, data_format=None, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs):\n    super(Conv2DTranspose, self).__init__(filters, kernel_size, strides=strides, padding=padding, data_format=data_format, activation=activation, use_bias=use_bias, kernel_initializer=kernel_initializer, bias_initializer=bias_initializer, kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer, activity_regularizer=activity_regularizer, kernel_constraint=kernel_constraint, bias_constraint=bias_constraint, **kwargs)\n    self.output_padding = output_padding\n    if self.output_padding is not None:\n        self.output_padding = conv_utils.normalize_tuple(self.output_padding, 2, 'output_padding')\n        for stride, out_pad in zip(self.strides, self.output_padding):\n            if out_pad >= stride:\n                raise ValueError('Stride ' + str(self.strides) + ' must be greater than output padding ' + str(self.output_padding))",
                            "def build(self, input_shape):\n    if len(input_shape) != 4:\n        raise ValueError('Inputs should have rank ' + str(4) + '; Received input shape:', str(input_shape))\n    if self.data_format == 'channels_first':\n        channel_axis = 1\n    else:\n        channel_axis = -1\n    if input_shape[channel_axis] is None:\n        raise ValueError('The channel dimension of the inputs should be defined. Found `None`.')\n    input_dim = input_shape[channel_axis]\n    kernel_shape = self.kernel_size + (self.filters, input_dim)\n    self.kernel = self.add_weight(shape=kernel_shape, initializer=self.kernel_initializer, name='kernel', regularizer=self.kernel_regularizer, constraint=self.kernel_constraint)\n    if self.use_bias:\n        self.bias = self.add_weight(shape=(self.filters,), initializer=self.bias_initializer, name='bias', regularizer=self.bias_regularizer, constraint=self.bias_constraint)\n    else:\n        self.bias = None\n    self.input_spec = InputSpec(ndim=4, axes={channel_axis: input_dim})\n    self.built = True",
                            "def call(self, inputs):\n    input_shape = K.shape(inputs)\n    batch_size = input_shape[0]\n    if self.data_format == 'channels_first':\n        h_axis, w_axis = (2, 3)\n    else:\n        h_axis, w_axis = (1, 2)\n    height, width = (input_shape[h_axis], input_shape[w_axis])\n    kernel_h, kernel_w = self.kernel_size\n    stride_h, stride_w = self.strides\n    if self.output_padding is None:\n        out_pad_h = out_pad_w = None\n    else:\n        out_pad_h, out_pad_w = self.output_padding\n    out_height = conv_utils.deconv_length(height, stride_h, kernel_h, self.padding, out_pad_h)\n    out_width = conv_utils.deconv_length(width, stride_w, kernel_w, self.padding, out_pad_w)\n    if self.data_format == 'channels_first':\n        output_shape = (batch_size, self.filters, out_height, out_width)\n    else:\n        output_shape = (batch_size, out_height, out_width, self.filters)\n    outputs = K.conv2d_transpose(inputs, self.kernel, output_shape, self.strides, padding=self.padding, data_format=self.data_format)\n    if self.use_bias:\n        outputs = K.bias_add(outputs, self.bias, data_format=self.data_format)\n    if self.activation is not None:\n        return self.activation(outputs)\n    return outputs",
                            "def compute_output_shape(self, input_shape):\n    output_shape = list(input_shape)\n    if self.data_format == 'channels_first':\n        c_axis, h_axis, w_axis = (1, 2, 3)\n    else:\n        c_axis, h_axis, w_axis = (3, 1, 2)\n    kernel_h, kernel_w = self.kernel_size\n    stride_h, stride_w = self.strides\n    if self.output_padding is None:\n        out_pad_h = out_pad_w = None\n    else:\n        out_pad_h, out_pad_w = self.output_padding\n    output_shape[c_axis] = self.filters\n    output_shape[h_axis] = conv_utils.deconv_length(output_shape[h_axis], stride_h, kernel_h, self.padding, out_pad_h)\n    output_shape[w_axis] = conv_utils.deconv_length(output_shape[w_axis], stride_w, kernel_w, self.padding, out_pad_w)\n    return tuple(output_shape)",
                            "def get_config(self):\n    config = super(Conv2DTranspose, self).get_config()\n    config.pop('dilation_rate')\n    config['output_padding'] = self.output_padding\n    return config"
                        ],
                        "constructor_variables": [
                            "output_padding"
                        ],
                        "class_level_variables": [],
                        "class_decorators": [],
                        "function_signatures": [
                            "__init__(self, filters, kernel_size, strides=(1, 1), padding='valid', output_padding=None, data_format=None, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)",
                            "build(self, input_shape)",
                            "call(self, inputs)",
                            "compute_output_shape(self, input_shape)",
                            "get_config(self)"
                        ]
                    },
                    "variable_values": [
                        [
                            {},
                            {}
                        ]
                    ],
                    "angelic_variable_values": [
                        [
                            {},
                            {}
                        ]
                    ]
                },
                {
                    "function_name": "compute_output_shape",
                    "function_code": "def compute_output_shape(self, input_shape):\n    output_shape = list(input_shape)\n    if self.data_format == 'channels_first':\n        c_axis, h_axis, w_axis = 1, 2, 3\n    else:\n        c_axis, h_axis, w_axis = 3, 1, 2\n\n    kernel_h, kernel_w = self.kernel_size\n    stride_h, stride_w = self.strides\n    if self.output_padding is None:\n        out_pad_h = out_pad_w = None\n    else:\n        out_pad_h, out_pad_w = self.output_padding\n\n    output_shape[c_axis] = self.filters\n    output_shape[h_axis] = conv_utils.deconv_length(output_shape[h_axis],\n                                                    stride_h,\n                                                    kernel_h,\n                                                    self.padding,\n                                                    out_pad_h)\n    output_shape[w_axis] = conv_utils.deconv_length(output_shape[w_axis],\n                                                    stride_w,\n                                                    kernel_w,\n                                                    self.padding,\n                                                    out_pad_w)\n    return tuple(output_shape)\n",
                    "decorators": [],
                    "docstring": null,
                    "start_line": 851,
                    "end_line": 876,
                    "variables": {
                        "output_shape": [
                            865,
                            866,
                            871,
                            876,
                            852
                        ],
                        "list": [
                            852
                        ],
                        "input_shape": [
                            852
                        ],
                        "self.data_format": [
                            853
                        ],
                        "self": [
                            865,
                            869,
                            874,
                            853,
                            858,
                            859,
                            860,
                            863
                        ],
                        "c_axis": [
                            856,
                            865,
                            854
                        ],
                        "h_axis": [
                            856,
                            866,
                            854
                        ],
                        "w_axis": [
                            856,
                            854,
                            871
                        ],
                        "kernel_h": [
                            858,
                            868
                        ],
                        "kernel_w": [
                            873,
                            858
                        ],
                        "self.kernel_size": [
                            858
                        ],
                        "stride_h": [
                            867,
                            859
                        ],
                        "stride_w": [
                            872,
                            859
                        ],
                        "self.strides": [
                            859
                        ],
                        "self.output_padding": [
                            860,
                            863
                        ],
                        "out_pad_h": [
                            861,
                            870,
                            863
                        ],
                        "out_pad_w": [
                            875,
                            861,
                            863
                        ],
                        "self.filters": [
                            865
                        ],
                        "conv_utils.deconv_length": [
                            866,
                            871
                        ],
                        "conv_utils": [
                            866,
                            871
                        ],
                        "self.padding": [
                            874,
                            869
                        ],
                        "tuple": [
                            876
                        ]
                    },
                    "filtered_variables": {
                        "output_shape": [
                            865,
                            866,
                            871,
                            876,
                            852
                        ],
                        "input_shape": [
                            852
                        ],
                        "self.data_format": [
                            853
                        ],
                        "self": [
                            865,
                            869,
                            874,
                            853,
                            858,
                            859,
                            860,
                            863
                        ],
                        "c_axis": [
                            856,
                            865,
                            854
                        ],
                        "h_axis": [
                            856,
                            866,
                            854
                        ],
                        "w_axis": [
                            856,
                            854,
                            871
                        ],
                        "kernel_h": [
                            858,
                            868
                        ],
                        "kernel_w": [
                            873,
                            858
                        ],
                        "self.kernel_size": [
                            858
                        ],
                        "stride_h": [
                            867,
                            859
                        ],
                        "stride_w": [
                            872,
                            859
                        ],
                        "self.strides": [
                            859
                        ],
                        "self.output_padding": [
                            860,
                            863
                        ],
                        "out_pad_h": [
                            861,
                            870,
                            863
                        ],
                        "out_pad_w": [
                            875,
                            861,
                            863
                        ],
                        "self.filters": [
                            865
                        ],
                        "conv_utils.deconv_length": [
                            866,
                            871
                        ],
                        "conv_utils": [
                            866,
                            871
                        ],
                        "self.padding": [
                            874,
                            869
                        ]
                    },
                    "diff_line_number": 870,
                    "class_data": {
                        "signature": "class Conv2DTranspose(Conv2D)",
                        "docstring": "Transposed convolution layer (sometimes called Deconvolution).\n\nThe need for transposed convolutions generally arises\nfrom the desire to use a transformation going in the opposite direction\nof a normal convolution, i.e., from something that has the shape of the\noutput of some convolution to something that has the shape of its input\nwhile maintaining a connectivity pattern that is compatible with\nsaid convolution.\n\nWhen using this layer as the first layer in a model,\nprovide the keyword argument `input_shape`\n(tuple of integers, does not include the sample axis),\ne.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures\nin `data_format=\"channels_last\"`.\n\n# Arguments\n    filters: Integer, the dimensionality of the output space\n        (i.e. the number of output filters in the convolution).\n    kernel_size: An integer or tuple/list of 2 integers, specifying the\n        height and width of the 2D convolution window.\n        Can be a single integer to specify the same value for\n        all spatial dimensions.\n    strides: An integer or tuple/list of 2 integers,\n        specifying the strides of the convolution\n        along the height and width.\n        Can be a single integer to specify the same value for\n        all spatial dimensions.\n        Specifying any stride value != 1 is incompatible with specifying\n        any `dilation_rate` value != 1.\n    padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n    output_padding: An integer or tuple/list of 2 integers,\n        specifying the amount of padding along the height and width\n        of the output tensor.\n        Can be a single integer to specify the same value for all\n        spatial dimensions.\n        The amount of output padding along a given dimension must be\n        lower than the stride along that same dimension.\n        If set to `None` (default), the output shape is inferred.\n    data_format: A string,\n        one of `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs.\n        `\"channels_last\"` corresponds to inputs with shape\n        `(batch, height, width, channels)` while `\"channels_first\"`\n        corresponds to inputs with shape\n        `(batch, channels, height, width)`.\n        It defaults to the `image_data_format` value found in your\n        Keras config file at `~/.keras/keras.json`.\n        If you never set it, then it will be \"channels_last\".\n    dilation_rate: an integer or tuple/list of 2 integers, specifying\n        the dilation rate to use for dilated convolution.\n        Can be a single integer to specify the same value for\n        all spatial dimensions.\n        Currently, specifying any `dilation_rate` value != 1 is\n        incompatible with specifying any stride value != 1.\n    activation: Activation function to use\n        (see [activations](../activations.md)).\n        If you don't specify anything, no activation is applied\n        (ie. \"linear\" activation: `a(x) = x`).\n    use_bias: Boolean, whether the layer uses a bias vector.\n    kernel_initializer: Initializer for the `kernel` weights matrix\n        (see [initializers](../initializers.md)).\n    bias_initializer: Initializer for the bias vector\n        (see [initializers](../initializers.md)).\n    kernel_regularizer: Regularizer function applied to\n        the `kernel` weights matrix\n        (see [regularizer](../regularizers.md)).\n    bias_regularizer: Regularizer function applied to the bias vector\n        (see [regularizer](../regularizers.md)).\n    activity_regularizer: Regularizer function applied to\n        the output of the layer (its \"activation\").\n        (see [regularizer](../regularizers.md)).\n    kernel_constraint: Constraint function applied to the kernel matrix\n        (see [constraints](../constraints.md)).\n    bias_constraint: Constraint function applied to the bias vector\n        (see [constraints](../constraints.md)).\n\n# Input shape\n    4D tensor with shape:\n    `(batch, channels, rows, cols)`\n    if `data_format` is `\"channels_first\"`\n    or 4D tensor with shape:\n    `(batch, rows, cols, channels)`\n    if `data_format` is `\"channels_last\"`.\n\n# Output shape\n    4D tensor with shape:\n    `(batch, filters, new_rows, new_cols)`\n    if `data_format` is `\"channels_first\"`\n    or 4D tensor with shape:\n    `(batch, new_rows, new_cols, filters)`\n    if `data_format` is `\"channels_last\"`.\n    `rows` and `cols` values might have changed due to padding.\n    If `output_padding` is specified:\n\n    ```\n    new_rows = (rows - 1) * strides[0] + kernel_size[0] - 2 * padding[0] + output_padding[0]\n    new_cols = (cols - 1) * strides[1] + kernel_size[1] - 2 * padding[1] + output_padding[1]\n    ```\n\n# References\n    - [A guide to convolution arithmetic for deep learning](https://arxiv.org/abs/1603.07285v1)\n    - [Deconvolutional Networks](http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf)",
                        "constructor_docstring": null,
                        "functions": [
                            "@interfaces.legacy_deconv2d_support\ndef __init__(self, filters, kernel_size, strides=(1, 1), padding='valid', output_padding=None, data_format=None, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs):\n    super(Conv2DTranspose, self).__init__(filters, kernel_size, strides=strides, padding=padding, data_format=data_format, activation=activation, use_bias=use_bias, kernel_initializer=kernel_initializer, bias_initializer=bias_initializer, kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer, activity_regularizer=activity_regularizer, kernel_constraint=kernel_constraint, bias_constraint=bias_constraint, **kwargs)\n    self.output_padding = output_padding\n    if self.output_padding is not None:\n        self.output_padding = conv_utils.normalize_tuple(self.output_padding, 2, 'output_padding')\n        for stride, out_pad in zip(self.strides, self.output_padding):\n            if out_pad >= stride:\n                raise ValueError('Stride ' + str(self.strides) + ' must be greater than output padding ' + str(self.output_padding))",
                            "def build(self, input_shape):\n    if len(input_shape) != 4:\n        raise ValueError('Inputs should have rank ' + str(4) + '; Received input shape:', str(input_shape))\n    if self.data_format == 'channels_first':\n        channel_axis = 1\n    else:\n        channel_axis = -1\n    if input_shape[channel_axis] is None:\n        raise ValueError('The channel dimension of the inputs should be defined. Found `None`.')\n    input_dim = input_shape[channel_axis]\n    kernel_shape = self.kernel_size + (self.filters, input_dim)\n    self.kernel = self.add_weight(shape=kernel_shape, initializer=self.kernel_initializer, name='kernel', regularizer=self.kernel_regularizer, constraint=self.kernel_constraint)\n    if self.use_bias:\n        self.bias = self.add_weight(shape=(self.filters,), initializer=self.bias_initializer, name='bias', regularizer=self.bias_regularizer, constraint=self.bias_constraint)\n    else:\n        self.bias = None\n    self.input_spec = InputSpec(ndim=4, axes={channel_axis: input_dim})\n    self.built = True",
                            "def call(self, inputs):\n    input_shape = K.shape(inputs)\n    batch_size = input_shape[0]\n    if self.data_format == 'channels_first':\n        h_axis, w_axis = (2, 3)\n    else:\n        h_axis, w_axis = (1, 2)\n    height, width = (input_shape[h_axis], input_shape[w_axis])\n    kernel_h, kernel_w = self.kernel_size\n    stride_h, stride_w = self.strides\n    if self.output_padding is None:\n        out_pad_h = out_pad_w = None\n    else:\n        out_pad_h, out_pad_w = self.output_padding\n    out_height = conv_utils.deconv_length(height, stride_h, kernel_h, self.padding, out_pad_h)\n    out_width = conv_utils.deconv_length(width, stride_w, kernel_w, self.padding, out_pad_w)\n    if self.data_format == 'channels_first':\n        output_shape = (batch_size, self.filters, out_height, out_width)\n    else:\n        output_shape = (batch_size, out_height, out_width, self.filters)\n    outputs = K.conv2d_transpose(inputs, self.kernel, output_shape, self.strides, padding=self.padding, data_format=self.data_format)\n    if self.use_bias:\n        outputs = K.bias_add(outputs, self.bias, data_format=self.data_format)\n    if self.activation is not None:\n        return self.activation(outputs)\n    return outputs",
                            "def compute_output_shape(self, input_shape):\n    output_shape = list(input_shape)\n    if self.data_format == 'channels_first':\n        c_axis, h_axis, w_axis = (1, 2, 3)\n    else:\n        c_axis, h_axis, w_axis = (3, 1, 2)\n    kernel_h, kernel_w = self.kernel_size\n    stride_h, stride_w = self.strides\n    if self.output_padding is None:\n        out_pad_h = out_pad_w = None\n    else:\n        out_pad_h, out_pad_w = self.output_padding\n    output_shape[c_axis] = self.filters\n    output_shape[h_axis] = conv_utils.deconv_length(output_shape[h_axis], stride_h, kernel_h, self.padding, out_pad_h)\n    output_shape[w_axis] = conv_utils.deconv_length(output_shape[w_axis], stride_w, kernel_w, self.padding, out_pad_w)\n    return tuple(output_shape)",
                            "def get_config(self):\n    config = super(Conv2DTranspose, self).get_config()\n    config.pop('dilation_rate')\n    config['output_padding'] = self.output_padding\n    return config"
                        ],
                        "constructor_variables": [
                            "output_padding"
                        ],
                        "class_level_variables": [],
                        "class_decorators": [],
                        "function_signatures": [
                            "__init__(self, filters, kernel_size, strides=(1, 1), padding='valid', output_padding=None, data_format=None, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)",
                            "build(self, input_shape)",
                            "call(self, inputs)",
                            "compute_output_shape(self, input_shape)",
                            "get_config(self)"
                        ]
                    },
                    "variable_values": [
                        [
                            {
                                "output_shape": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "input_shape": {
                                    "variable_value": "(2, 5, 6, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "4"
                                },
                                "self.data_format": {
                                    "variable_value": "'channels_last'",
                                    "variable_type": "str",
                                    "variable_shape": "13"
                                },
                                "self": {
                                    "variable_value": "<keras.layers.convolutional.Conv2DTranspose object at 0x123c99710>",
                                    "variable_type": "Conv2DTranspose",
                                    "variable_shape": null
                                },
                                "c_axis": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "h_axis": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "w_axis": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "kernel_h": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "kernel_w": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.kernel_size": {
                                    "variable_value": "(3, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "stride_h": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "stride_w": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.strides": {
                                    "variable_value": "(1, 1)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "self.output_padding": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "out_pad_h": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "out_pad_w": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.filters": {
                                    "variable_value": "2",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "conv_utils.deconv_length": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "conv_utils": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.padding": {
                                    "variable_value": "'same'",
                                    "variable_type": "str",
                                    "variable_shape": "4"
                                }
                            },
                            {
                                "output_shape": {
                                    "variable_value": "[2, 5, 6, 2]",
                                    "variable_type": "list",
                                    "variable_shape": "4"
                                },
                                "input_shape": {
                                    "variable_value": "(2, 5, 6, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "4"
                                },
                                "self.data_format": {
                                    "variable_value": "'channels_last'",
                                    "variable_type": "str",
                                    "variable_shape": "13"
                                },
                                "self": {
                                    "variable_value": "<keras.layers.convolutional.Conv2DTranspose object at 0x123c99710>",
                                    "variable_type": "Conv2DTranspose",
                                    "variable_shape": null
                                },
                                "c_axis": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "h_axis": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "w_axis": {
                                    "variable_value": "2",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "kernel_h": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "kernel_w": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "self.kernel_size": {
                                    "variable_value": "(3, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "stride_h": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "stride_w": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "self.strides": {
                                    "variable_value": "(1, 1)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "self.output_padding": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "out_pad_h": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "out_pad_w": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self.filters": {
                                    "variable_value": "2",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "conv_utils.deconv_length": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "conv_utils": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.padding": {
                                    "variable_value": "'same'",
                                    "variable_type": "str",
                                    "variable_shape": "4"
                                }
                            }
                        ],
                        [
                            {
                                "output_shape": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "input_shape": {
                                    "variable_value": "(None, 5, 6, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "4"
                                },
                                "self.data_format": {
                                    "variable_value": "'channels_last'",
                                    "variable_type": "str",
                                    "variable_shape": "13"
                                },
                                "self": {
                                    "variable_value": "<keras.layers.convolutional.Conv2DTranspose object at 0x123c99710>",
                                    "variable_type": "Conv2DTranspose",
                                    "variable_shape": null
                                },
                                "c_axis": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "h_axis": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "w_axis": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "kernel_h": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "kernel_w": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.kernel_size": {
                                    "variable_value": "(3, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "stride_h": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "stride_w": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.strides": {
                                    "variable_value": "(1, 1)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "self.output_padding": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "out_pad_h": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "out_pad_w": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.filters": {
                                    "variable_value": "2",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "conv_utils.deconv_length": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "conv_utils": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.padding": {
                                    "variable_value": "'same'",
                                    "variable_type": "str",
                                    "variable_shape": "4"
                                }
                            },
                            {
                                "output_shape": {
                                    "variable_value": "[None, 5, 6, 2]",
                                    "variable_type": "list",
                                    "variable_shape": "4"
                                },
                                "input_shape": {
                                    "variable_value": "(None, 5, 6, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "4"
                                },
                                "self.data_format": {
                                    "variable_value": "'channels_last'",
                                    "variable_type": "str",
                                    "variable_shape": "13"
                                },
                                "self": {
                                    "variable_value": "<keras.layers.convolutional.Conv2DTranspose object at 0x123c99710>",
                                    "variable_type": "Conv2DTranspose",
                                    "variable_shape": null
                                },
                                "c_axis": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "h_axis": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "w_axis": {
                                    "variable_value": "2",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "kernel_h": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "kernel_w": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "self.kernel_size": {
                                    "variable_value": "(3, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "stride_h": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "stride_w": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "self.strides": {
                                    "variable_value": "(1, 1)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "self.output_padding": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "out_pad_h": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "out_pad_w": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self.filters": {
                                    "variable_value": "2",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "conv_utils.deconv_length": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "conv_utils": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.padding": {
                                    "variable_value": "'same'",
                                    "variable_type": "str",
                                    "variable_shape": "4"
                                }
                            }
                        ],
                        [
                            {
                                "output_shape": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "input_shape": {
                                    "variable_value": "(None, 5, 6, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "4"
                                },
                                "self.data_format": {
                                    "variable_value": "'channels_last'",
                                    "variable_type": "str",
                                    "variable_shape": "13"
                                },
                                "self": {
                                    "variable_value": "<keras.layers.convolutional.Conv2DTranspose object at 0x123d7d890>",
                                    "variable_type": "Conv2DTranspose",
                                    "variable_shape": null
                                },
                                "c_axis": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "h_axis": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "w_axis": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "kernel_h": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "kernel_w": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.kernel_size": {
                                    "variable_value": "(3, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "stride_h": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "stride_w": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.strides": {
                                    "variable_value": "(1, 1)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "self.output_padding": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "out_pad_h": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "out_pad_w": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.filters": {
                                    "variable_value": "2",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "conv_utils.deconv_length": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "conv_utils": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.padding": {
                                    "variable_value": "'same'",
                                    "variable_type": "str",
                                    "variable_shape": "4"
                                }
                            },
                            {
                                "output_shape": {
                                    "variable_value": "[None, 5, 6, 2]",
                                    "variable_type": "list",
                                    "variable_shape": "4"
                                },
                                "input_shape": {
                                    "variable_value": "(None, 5, 6, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "4"
                                },
                                "self.data_format": {
                                    "variable_value": "'channels_last'",
                                    "variable_type": "str",
                                    "variable_shape": "13"
                                },
                                "self": {
                                    "variable_value": "<keras.layers.convolutional.Conv2DTranspose object at 0x123d7d890>",
                                    "variable_type": "Conv2DTranspose",
                                    "variable_shape": null
                                },
                                "c_axis": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "h_axis": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "w_axis": {
                                    "variable_value": "2",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "kernel_h": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "kernel_w": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "self.kernel_size": {
                                    "variable_value": "(3, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "stride_h": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "stride_w": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "self.strides": {
                                    "variable_value": "(1, 1)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "self.output_padding": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "out_pad_h": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "out_pad_w": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self.filters": {
                                    "variable_value": "2",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "conv_utils.deconv_length": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "conv_utils": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.padding": {
                                    "variable_value": "'same'",
                                    "variable_type": "str",
                                    "variable_shape": "4"
                                }
                            }
                        ],
                        [
                            {
                                "output_shape": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "input_shape": {
                                    "variable_value": "(2, 5, 6, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "4"
                                },
                                "self.data_format": {
                                    "variable_value": "'channels_last'",
                                    "variable_type": "str",
                                    "variable_shape": "13"
                                },
                                "self": {
                                    "variable_value": "<keras.layers.convolutional.Conv2DTranspose object at 0x123fae950>",
                                    "variable_type": "Conv2DTranspose",
                                    "variable_shape": null
                                },
                                "c_axis": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "h_axis": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "w_axis": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "kernel_h": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "kernel_w": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.kernel_size": {
                                    "variable_value": "(3, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "stride_h": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "stride_w": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.strides": {
                                    "variable_value": "(1, 1)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "self.output_padding": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "out_pad_h": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "out_pad_w": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.filters": {
                                    "variable_value": "2",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "conv_utils.deconv_length": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "conv_utils": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.padding": {
                                    "variable_value": "'same'",
                                    "variable_type": "str",
                                    "variable_shape": "4"
                                }
                            },
                            {
                                "output_shape": {
                                    "variable_value": "[2, 5, 6, 2]",
                                    "variable_type": "list",
                                    "variable_shape": "4"
                                },
                                "input_shape": {
                                    "variable_value": "(2, 5, 6, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "4"
                                },
                                "self.data_format": {
                                    "variable_value": "'channels_last'",
                                    "variable_type": "str",
                                    "variable_shape": "13"
                                },
                                "self": {
                                    "variable_value": "<keras.layers.convolutional.Conv2DTranspose object at 0x123fae950>",
                                    "variable_type": "Conv2DTranspose",
                                    "variable_shape": null
                                },
                                "c_axis": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "h_axis": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "w_axis": {
                                    "variable_value": "2",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "kernel_h": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "kernel_w": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "self.kernel_size": {
                                    "variable_value": "(3, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "stride_h": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "stride_w": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "self.strides": {
                                    "variable_value": "(1, 1)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "self.output_padding": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "out_pad_h": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "out_pad_w": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self.filters": {
                                    "variable_value": "2",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "conv_utils.deconv_length": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "conv_utils": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.padding": {
                                    "variable_value": "'same'",
                                    "variable_type": "str",
                                    "variable_shape": "4"
                                }
                            }
                        ],
                        [
                            {
                                "output_shape": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "input_shape": {
                                    "variable_value": "(2, 5, 6, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "4"
                                },
                                "self.data_format": {
                                    "variable_value": "'channels_last'",
                                    "variable_type": "str",
                                    "variable_shape": "13"
                                },
                                "self": {
                                    "variable_value": "<keras.layers.convolutional.Conv2DTranspose object at 0x124462d90>",
                                    "variable_type": "Conv2DTranspose",
                                    "variable_shape": null
                                },
                                "c_axis": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "h_axis": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "w_axis": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "kernel_h": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "kernel_w": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.kernel_size": {
                                    "variable_value": "(3, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "stride_h": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "stride_w": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.strides": {
                                    "variable_value": "(1, 1)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "self.output_padding": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "out_pad_h": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "out_pad_w": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.filters": {
                                    "variable_value": "2",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "conv_utils.deconv_length": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "conv_utils": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.padding": {
                                    "variable_value": "'same'",
                                    "variable_type": "str",
                                    "variable_shape": "4"
                                }
                            },
                            {
                                "output_shape": {
                                    "variable_value": "[2, 5, 6, 2]",
                                    "variable_type": "list",
                                    "variable_shape": "4"
                                },
                                "input_shape": {
                                    "variable_value": "(2, 5, 6, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "4"
                                },
                                "self.data_format": {
                                    "variable_value": "'channels_last'",
                                    "variable_type": "str",
                                    "variable_shape": "13"
                                },
                                "self": {
                                    "variable_value": "<keras.layers.convolutional.Conv2DTranspose object at 0x124462d90>",
                                    "variable_type": "Conv2DTranspose",
                                    "variable_shape": null
                                },
                                "c_axis": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "h_axis": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "w_axis": {
                                    "variable_value": "2",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "kernel_h": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "kernel_w": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "self.kernel_size": {
                                    "variable_value": "(3, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "stride_h": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "stride_w": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "self.strides": {
                                    "variable_value": "(1, 1)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "self.output_padding": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "out_pad_h": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "out_pad_w": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self.filters": {
                                    "variable_value": "2",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "conv_utils.deconv_length": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "conv_utils": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.padding": {
                                    "variable_value": "'same'",
                                    "variable_type": "str",
                                    "variable_shape": "4"
                                }
                            }
                        ],
                        [
                            {
                                "output_shape": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "input_shape": {
                                    "variable_value": "(1, 4, 4, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "4"
                                },
                                "self.data_format": {
                                    "variable_value": "'channels_last'",
                                    "variable_type": "str",
                                    "variable_shape": "13"
                                },
                                "self": {
                                    "variable_value": "<keras.layers.convolutional.Conv2DTranspose object at 0x123c8d610>",
                                    "variable_type": "Conv2DTranspose",
                                    "variable_shape": null
                                },
                                "c_axis": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "h_axis": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "w_axis": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "kernel_h": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "kernel_w": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.kernel_size": {
                                    "variable_value": "(3, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "stride_h": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "stride_w": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.strides": {
                                    "variable_value": "(1, 1)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "self.output_padding": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "out_pad_h": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "out_pad_w": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.filters": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "conv_utils.deconv_length": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "conv_utils": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.padding": {
                                    "variable_value": "'same'",
                                    "variable_type": "str",
                                    "variable_shape": "4"
                                }
                            },
                            {
                                "output_shape": {
                                    "variable_value": "[1, 4, 4, 1]",
                                    "variable_type": "list",
                                    "variable_shape": "4"
                                },
                                "input_shape": {
                                    "variable_value": "(1, 4, 4, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "4"
                                },
                                "self.data_format": {
                                    "variable_value": "'channels_last'",
                                    "variable_type": "str",
                                    "variable_shape": "13"
                                },
                                "self": {
                                    "variable_value": "<keras.layers.convolutional.Conv2DTranspose object at 0x123c8d610>",
                                    "variable_type": "Conv2DTranspose",
                                    "variable_shape": null
                                },
                                "c_axis": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "h_axis": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "w_axis": {
                                    "variable_value": "2",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "kernel_h": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "kernel_w": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "self.kernel_size": {
                                    "variable_value": "(3, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "stride_h": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "stride_w": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "self.strides": {
                                    "variable_value": "(1, 1)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "self.output_padding": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "out_pad_h": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "out_pad_w": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self.filters": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "conv_utils.deconv_length": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "conv_utils": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.padding": {
                                    "variable_value": "'same'",
                                    "variable_type": "str",
                                    "variable_shape": "4"
                                }
                            }
                        ],
                        [
                            {
                                "output_shape": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "input_shape": {
                                    "variable_value": "(None, 4, 4, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "4"
                                },
                                "self.data_format": {
                                    "variable_value": "'channels_last'",
                                    "variable_type": "str",
                                    "variable_shape": "13"
                                },
                                "self": {
                                    "variable_value": "<keras.layers.convolutional.Conv2DTranspose object at 0x123c8d610>",
                                    "variable_type": "Conv2DTranspose",
                                    "variable_shape": null
                                },
                                "c_axis": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "h_axis": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "w_axis": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "kernel_h": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "kernel_w": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.kernel_size": {
                                    "variable_value": "(3, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "stride_h": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "stride_w": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.strides": {
                                    "variable_value": "(1, 1)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "self.output_padding": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "out_pad_h": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "out_pad_w": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.filters": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "conv_utils.deconv_length": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "conv_utils": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.padding": {
                                    "variable_value": "'same'",
                                    "variable_type": "str",
                                    "variable_shape": "4"
                                }
                            },
                            {
                                "output_shape": {
                                    "variable_value": "[None, 4, 4, 1]",
                                    "variable_type": "list",
                                    "variable_shape": "4"
                                },
                                "input_shape": {
                                    "variable_value": "(None, 4, 4, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "4"
                                },
                                "self.data_format": {
                                    "variable_value": "'channels_last'",
                                    "variable_type": "str",
                                    "variable_shape": "13"
                                },
                                "self": {
                                    "variable_value": "<keras.layers.convolutional.Conv2DTranspose object at 0x123c8d610>",
                                    "variable_type": "Conv2DTranspose",
                                    "variable_shape": null
                                },
                                "c_axis": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "h_axis": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "w_axis": {
                                    "variable_value": "2",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "kernel_h": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "kernel_w": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "self.kernel_size": {
                                    "variable_value": "(3, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "stride_h": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "stride_w": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "self.strides": {
                                    "variable_value": "(1, 1)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "self.output_padding": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "out_pad_h": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "out_pad_w": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self.filters": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "conv_utils.deconv_length": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "conv_utils": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.padding": {
                                    "variable_value": "'same'",
                                    "variable_type": "str",
                                    "variable_shape": "4"
                                }
                            }
                        ]
                    ],
                    "angelic_variable_values": [
                        [
                            {
                                "output_shape": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "input_shape": {
                                    "variable_value": "(2, 5, 6, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "4"
                                },
                                "self.data_format": {
                                    "variable_value": "'channels_last'",
                                    "variable_type": "str",
                                    "variable_shape": "13"
                                },
                                "self": {
                                    "variable_value": "<keras.layers.convolutional.Conv2DTranspose object at 0x12b3faa10>",
                                    "variable_type": "Conv2DTranspose",
                                    "variable_shape": null
                                },
                                "c_axis": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "h_axis": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "w_axis": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "kernel_h": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "kernel_w": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.kernel_size": {
                                    "variable_value": "(3, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "stride_h": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "stride_w": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.strides": {
                                    "variable_value": "(1, 1)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "self.output_padding": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "out_pad_h": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "out_pad_w": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.filters": {
                                    "variable_value": "2",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "conv_utils.deconv_length": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "conv_utils": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.padding": {
                                    "variable_value": "'same'",
                                    "variable_type": "str",
                                    "variable_shape": "4"
                                },
                                "self.dilation_rate": {
                                    "variable_value": "(2, 2)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                }
                            },
                            {
                                "output_shape": {
                                    "variable_value": "[2, 5, 6, 2]",
                                    "variable_type": "list",
                                    "variable_shape": "4"
                                },
                                "input_shape": {
                                    "variable_value": "(2, 5, 6, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "4"
                                },
                                "self.data_format": {
                                    "variable_value": "'channels_last'",
                                    "variable_type": "str",
                                    "variable_shape": "13"
                                },
                                "self": {
                                    "variable_value": "<keras.layers.convolutional.Conv2DTranspose object at 0x12b3faa10>",
                                    "variable_type": "Conv2DTranspose",
                                    "variable_shape": null
                                },
                                "c_axis": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "h_axis": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "w_axis": {
                                    "variable_value": "2",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "kernel_h": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "kernel_w": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "self.kernel_size": {
                                    "variable_value": "(3, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "stride_h": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "stride_w": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "self.strides": {
                                    "variable_value": "(1, 1)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "self.output_padding": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "out_pad_h": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "out_pad_w": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self.filters": {
                                    "variable_value": "2",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "conv_utils.deconv_length": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "conv_utils": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.padding": {
                                    "variable_value": "'same'",
                                    "variable_type": "str",
                                    "variable_shape": "4"
                                },
                                "self.dilation_rate": {
                                    "variable_value": "(2, 2)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                }
                            }
                        ],
                        [
                            {
                                "output_shape": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "input_shape": {
                                    "variable_value": "(None, 5, 6, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "4"
                                },
                                "self.data_format": {
                                    "variable_value": "'channels_last'",
                                    "variable_type": "str",
                                    "variable_shape": "13"
                                },
                                "self": {
                                    "variable_value": "<keras.layers.convolutional.Conv2DTranspose object at 0x12b3faa10>",
                                    "variable_type": "Conv2DTranspose",
                                    "variable_shape": null
                                },
                                "c_axis": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "h_axis": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "w_axis": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "kernel_h": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "kernel_w": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.kernel_size": {
                                    "variable_value": "(3, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "stride_h": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "stride_w": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.strides": {
                                    "variable_value": "(1, 1)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "self.output_padding": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "out_pad_h": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "out_pad_w": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.filters": {
                                    "variable_value": "2",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "conv_utils.deconv_length": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "conv_utils": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.padding": {
                                    "variable_value": "'same'",
                                    "variable_type": "str",
                                    "variable_shape": "4"
                                },
                                "self.dilation_rate": {
                                    "variable_value": "(2, 2)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                }
                            },
                            {
                                "output_shape": {
                                    "variable_value": "[None, 5, 6, 2]",
                                    "variable_type": "list",
                                    "variable_shape": "4"
                                },
                                "input_shape": {
                                    "variable_value": "(None, 5, 6, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "4"
                                },
                                "self.data_format": {
                                    "variable_value": "'channels_last'",
                                    "variable_type": "str",
                                    "variable_shape": "13"
                                },
                                "self": {
                                    "variable_value": "<keras.layers.convolutional.Conv2DTranspose object at 0x12b3faa10>",
                                    "variable_type": "Conv2DTranspose",
                                    "variable_shape": null
                                },
                                "c_axis": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "h_axis": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "w_axis": {
                                    "variable_value": "2",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "kernel_h": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "kernel_w": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "self.kernel_size": {
                                    "variable_value": "(3, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "stride_h": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "stride_w": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "self.strides": {
                                    "variable_value": "(1, 1)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "self.output_padding": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "out_pad_h": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "out_pad_w": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self.filters": {
                                    "variable_value": "2",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "conv_utils.deconv_length": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "conv_utils": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.padding": {
                                    "variable_value": "'same'",
                                    "variable_type": "str",
                                    "variable_shape": "4"
                                },
                                "self.dilation_rate": {
                                    "variable_value": "(2, 2)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                }
                            }
                        ],
                        [
                            {
                                "output_shape": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "input_shape": {
                                    "variable_value": "(None, 5, 6, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "4"
                                },
                                "self.data_format": {
                                    "variable_value": "'channels_last'",
                                    "variable_type": "str",
                                    "variable_shape": "13"
                                },
                                "self": {
                                    "variable_value": "<keras.layers.convolutional.Conv2DTranspose object at 0x12b4f0dd0>",
                                    "variable_type": "Conv2DTranspose",
                                    "variable_shape": null
                                },
                                "c_axis": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "h_axis": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "w_axis": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "kernel_h": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "kernel_w": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.kernel_size": {
                                    "variable_value": "(3, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "stride_h": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "stride_w": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.strides": {
                                    "variable_value": "(1, 1)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "self.output_padding": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "out_pad_h": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "out_pad_w": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.filters": {
                                    "variable_value": "2",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "conv_utils.deconv_length": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "conv_utils": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.padding": {
                                    "variable_value": "'same'",
                                    "variable_type": "str",
                                    "variable_shape": "4"
                                },
                                "self.dilation_rate": {
                                    "variable_value": "(2, 2)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                }
                            },
                            {
                                "output_shape": {
                                    "variable_value": "[None, 5, 6, 2]",
                                    "variable_type": "list",
                                    "variable_shape": "4"
                                },
                                "input_shape": {
                                    "variable_value": "(None, 5, 6, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "4"
                                },
                                "self.data_format": {
                                    "variable_value": "'channels_last'",
                                    "variable_type": "str",
                                    "variable_shape": "13"
                                },
                                "self": {
                                    "variable_value": "<keras.layers.convolutional.Conv2DTranspose object at 0x12b4f0dd0>",
                                    "variable_type": "Conv2DTranspose",
                                    "variable_shape": null
                                },
                                "c_axis": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "h_axis": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "w_axis": {
                                    "variable_value": "2",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "kernel_h": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "kernel_w": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "self.kernel_size": {
                                    "variable_value": "(3, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "stride_h": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "stride_w": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "self.strides": {
                                    "variable_value": "(1, 1)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "self.output_padding": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "out_pad_h": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "out_pad_w": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self.filters": {
                                    "variable_value": "2",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "conv_utils.deconv_length": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "conv_utils": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.padding": {
                                    "variable_value": "'same'",
                                    "variable_type": "str",
                                    "variable_shape": "4"
                                },
                                "self.dilation_rate": {
                                    "variable_value": "(2, 2)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                }
                            }
                        ],
                        [
                            {
                                "output_shape": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "input_shape": {
                                    "variable_value": "(2, 5, 6, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "4"
                                },
                                "self.data_format": {
                                    "variable_value": "'channels_last'",
                                    "variable_type": "str",
                                    "variable_shape": "13"
                                },
                                "self": {
                                    "variable_value": "<keras.layers.convolutional.Conv2DTranspose object at 0x12bac4390>",
                                    "variable_type": "Conv2DTranspose",
                                    "variable_shape": null
                                },
                                "c_axis": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "h_axis": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "w_axis": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "kernel_h": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "kernel_w": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.kernel_size": {
                                    "variable_value": "(3, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "stride_h": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "stride_w": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.strides": {
                                    "variable_value": "(1, 1)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "self.output_padding": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "out_pad_h": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "out_pad_w": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.filters": {
                                    "variable_value": "2",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "conv_utils.deconv_length": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "conv_utils": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.padding": {
                                    "variable_value": "'same'",
                                    "variable_type": "str",
                                    "variable_shape": "4"
                                },
                                "self.dilation_rate": {
                                    "variable_value": "(2, 2)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                }
                            },
                            {
                                "output_shape": {
                                    "variable_value": "[2, 5, 6, 2]",
                                    "variable_type": "list",
                                    "variable_shape": "4"
                                },
                                "input_shape": {
                                    "variable_value": "(2, 5, 6, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "4"
                                },
                                "self.data_format": {
                                    "variable_value": "'channels_last'",
                                    "variable_type": "str",
                                    "variable_shape": "13"
                                },
                                "self": {
                                    "variable_value": "<keras.layers.convolutional.Conv2DTranspose object at 0x12bac4390>",
                                    "variable_type": "Conv2DTranspose",
                                    "variable_shape": null
                                },
                                "c_axis": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "h_axis": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "w_axis": {
                                    "variable_value": "2",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "kernel_h": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "kernel_w": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "self.kernel_size": {
                                    "variable_value": "(3, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "stride_h": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "stride_w": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "self.strides": {
                                    "variable_value": "(1, 1)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "self.output_padding": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "out_pad_h": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "out_pad_w": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self.filters": {
                                    "variable_value": "2",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "conv_utils.deconv_length": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "conv_utils": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.padding": {
                                    "variable_value": "'same'",
                                    "variable_type": "str",
                                    "variable_shape": "4"
                                },
                                "self.dilation_rate": {
                                    "variable_value": "(2, 2)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                }
                            }
                        ],
                        [
                            {
                                "output_shape": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "input_shape": {
                                    "variable_value": "(2, 5, 6, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "4"
                                },
                                "self.data_format": {
                                    "variable_value": "'channels_last'",
                                    "variable_type": "str",
                                    "variable_shape": "13"
                                },
                                "self": {
                                    "variable_value": "<keras.layers.convolutional.Conv2DTranspose object at 0x12bba3cd0>",
                                    "variable_type": "Conv2DTranspose",
                                    "variable_shape": null
                                },
                                "c_axis": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "h_axis": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "w_axis": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "kernel_h": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "kernel_w": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.kernel_size": {
                                    "variable_value": "(3, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "stride_h": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "stride_w": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.strides": {
                                    "variable_value": "(1, 1)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "self.output_padding": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "out_pad_h": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "out_pad_w": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.filters": {
                                    "variable_value": "2",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "conv_utils.deconv_length": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "conv_utils": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.padding": {
                                    "variable_value": "'same'",
                                    "variable_type": "str",
                                    "variable_shape": "4"
                                },
                                "self.dilation_rate": {
                                    "variable_value": "(2, 2)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                }
                            },
                            {
                                "output_shape": {
                                    "variable_value": "[2, 5, 6, 2]",
                                    "variable_type": "list",
                                    "variable_shape": "4"
                                },
                                "input_shape": {
                                    "variable_value": "(2, 5, 6, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "4"
                                },
                                "self.data_format": {
                                    "variable_value": "'channels_last'",
                                    "variable_type": "str",
                                    "variable_shape": "13"
                                },
                                "self": {
                                    "variable_value": "<keras.layers.convolutional.Conv2DTranspose object at 0x12bba3cd0>",
                                    "variable_type": "Conv2DTranspose",
                                    "variable_shape": null
                                },
                                "c_axis": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "h_axis": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "w_axis": {
                                    "variable_value": "2",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "kernel_h": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "kernel_w": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "self.kernel_size": {
                                    "variable_value": "(3, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "stride_h": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "stride_w": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "self.strides": {
                                    "variable_value": "(1, 1)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "self.output_padding": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "out_pad_h": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "out_pad_w": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self.filters": {
                                    "variable_value": "2",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "conv_utils.deconv_length": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "conv_utils": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.padding": {
                                    "variable_value": "'same'",
                                    "variable_type": "str",
                                    "variable_shape": "4"
                                },
                                "self.dilation_rate": {
                                    "variable_value": "(2, 2)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                }
                            }
                        ],
                        [
                            {
                                "output_shape": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "input_shape": {
                                    "variable_value": "(1, 4, 4, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "4"
                                },
                                "self.data_format": {
                                    "variable_value": "'channels_last'",
                                    "variable_type": "str",
                                    "variable_shape": "13"
                                },
                                "self": {
                                    "variable_value": "<keras.layers.convolutional.Conv2DTranspose object at 0x12b3fa590>",
                                    "variable_type": "Conv2DTranspose",
                                    "variable_shape": null
                                },
                                "c_axis": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "h_axis": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "w_axis": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "kernel_h": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "kernel_w": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.kernel_size": {
                                    "variable_value": "(3, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "stride_h": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "stride_w": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.strides": {
                                    "variable_value": "(1, 1)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "self.output_padding": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "out_pad_h": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "out_pad_w": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.filters": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "conv_utils.deconv_length": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "conv_utils": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.padding": {
                                    "variable_value": "'same'",
                                    "variable_type": "str",
                                    "variable_shape": "4"
                                },
                                "self.dilation_rate": {
                                    "variable_value": "(2, 2)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                }
                            },
                            {
                                "output_shape": {
                                    "variable_value": "[1, 4, 4, 1]",
                                    "variable_type": "list",
                                    "variable_shape": "4"
                                },
                                "input_shape": {
                                    "variable_value": "(1, 4, 4, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "4"
                                },
                                "self.data_format": {
                                    "variable_value": "'channels_last'",
                                    "variable_type": "str",
                                    "variable_shape": "13"
                                },
                                "self": {
                                    "variable_value": "<keras.layers.convolutional.Conv2DTranspose object at 0x12b3fa590>",
                                    "variable_type": "Conv2DTranspose",
                                    "variable_shape": null
                                },
                                "c_axis": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "h_axis": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "w_axis": {
                                    "variable_value": "2",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "kernel_h": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "kernel_w": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "self.kernel_size": {
                                    "variable_value": "(3, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "stride_h": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "stride_w": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "self.strides": {
                                    "variable_value": "(1, 1)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "self.output_padding": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "out_pad_h": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "out_pad_w": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self.filters": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "conv_utils.deconv_length": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "conv_utils": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.padding": {
                                    "variable_value": "'same'",
                                    "variable_type": "str",
                                    "variable_shape": "4"
                                },
                                "self.dilation_rate": {
                                    "variable_value": "(2, 2)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                }
                            }
                        ],
                        [
                            {
                                "output_shape": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "input_shape": {
                                    "variable_value": "(None, 4, 4, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "4"
                                },
                                "self.data_format": {
                                    "variable_value": "'channels_last'",
                                    "variable_type": "str",
                                    "variable_shape": "13"
                                },
                                "self": {
                                    "variable_value": "<keras.layers.convolutional.Conv2DTranspose object at 0x12b3fa590>",
                                    "variable_type": "Conv2DTranspose",
                                    "variable_shape": null
                                },
                                "c_axis": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "h_axis": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "w_axis": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "kernel_h": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "kernel_w": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.kernel_size": {
                                    "variable_value": "(3, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "stride_h": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "stride_w": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.strides": {
                                    "variable_value": "(1, 1)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "self.output_padding": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "out_pad_h": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "out_pad_w": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.filters": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "conv_utils.deconv_length": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "conv_utils": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.padding": {
                                    "variable_value": "'same'",
                                    "variable_type": "str",
                                    "variable_shape": "4"
                                },
                                "self.dilation_rate": {
                                    "variable_value": "(2, 2)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                }
                            },
                            {
                                "output_shape": {
                                    "variable_value": "[None, 4, 4, 1]",
                                    "variable_type": "list",
                                    "variable_shape": "4"
                                },
                                "input_shape": {
                                    "variable_value": "(None, 4, 4, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "4"
                                },
                                "self.data_format": {
                                    "variable_value": "'channels_last'",
                                    "variable_type": "str",
                                    "variable_shape": "13"
                                },
                                "self": {
                                    "variable_value": "<keras.layers.convolutional.Conv2DTranspose object at 0x12b3fa590>",
                                    "variable_type": "Conv2DTranspose",
                                    "variable_shape": null
                                },
                                "c_axis": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "h_axis": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "w_axis": {
                                    "variable_value": "2",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "kernel_h": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "kernel_w": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "self.kernel_size": {
                                    "variable_value": "(3, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "stride_h": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "stride_w": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "self.strides": {
                                    "variable_value": "(1, 1)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "self.output_padding": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "out_pad_h": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "out_pad_w": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self.filters": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "conv_utils.deconv_length": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "conv_utils": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.padding": {
                                    "variable_value": "'same'",
                                    "variable_type": "str",
                                    "variable_shape": "4"
                                },
                                "self.dilation_rate": {
                                    "variable_value": "(2, 2)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                }
                            }
                        ],
                        [
                            {
                                "output_shape": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "input_shape": {
                                    "variable_value": "(None, 4, 4, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "4"
                                },
                                "self.data_format": {
                                    "variable_value": "'channels_last'",
                                    "variable_type": "str",
                                    "variable_shape": "13"
                                },
                                "self": {
                                    "variable_value": "<keras.layers.convolutional.Conv2DTranspose object at 0x12bb5c950>",
                                    "variable_type": "Conv2DTranspose",
                                    "variable_shape": null
                                },
                                "c_axis": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "h_axis": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "w_axis": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "kernel_h": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "kernel_w": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.kernel_size": {
                                    "variable_value": "(3, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "stride_h": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "stride_w": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.strides": {
                                    "variable_value": "(1, 1)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "self.output_padding": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "out_pad_h": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "out_pad_w": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.filters": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "conv_utils.deconv_length": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "conv_utils": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.padding": {
                                    "variable_value": "'same'",
                                    "variable_type": "str",
                                    "variable_shape": "4"
                                },
                                "self.dilation_rate": {
                                    "variable_value": "(2, 2)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                }
                            },
                            {
                                "output_shape": {
                                    "variable_value": "[None, 4, 4, 1]",
                                    "variable_type": "list",
                                    "variable_shape": "4"
                                },
                                "input_shape": {
                                    "variable_value": "(None, 4, 4, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "4"
                                },
                                "self.data_format": {
                                    "variable_value": "'channels_last'",
                                    "variable_type": "str",
                                    "variable_shape": "13"
                                },
                                "self": {
                                    "variable_value": "<keras.layers.convolutional.Conv2DTranspose object at 0x12bb5c950>",
                                    "variable_type": "Conv2DTranspose",
                                    "variable_shape": null
                                },
                                "c_axis": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "h_axis": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "w_axis": {
                                    "variable_value": "2",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "kernel_h": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "kernel_w": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "self.kernel_size": {
                                    "variable_value": "(3, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "stride_h": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "stride_w": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "self.strides": {
                                    "variable_value": "(1, 1)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "self.output_padding": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "out_pad_h": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "out_pad_w": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self.filters": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "conv_utils.deconv_length": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "conv_utils": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.padding": {
                                    "variable_value": "'same'",
                                    "variable_type": "str",
                                    "variable_shape": "4"
                                },
                                "self.dilation_rate": {
                                    "variable_value": "(2, 2)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                }
                            }
                        ],
                        [
                            {
                                "output_shape": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "input_shape": {
                                    "variable_value": "(1, 4, 4, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "4"
                                },
                                "self.data_format": {
                                    "variable_value": "'channels_last'",
                                    "variable_type": "str",
                                    "variable_shape": "13"
                                },
                                "self": {
                                    "variable_value": "<keras.layers.convolutional.Conv2DTranspose object at 0x12bce6750>",
                                    "variable_type": "Conv2DTranspose",
                                    "variable_shape": null
                                },
                                "c_axis": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "h_axis": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "w_axis": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "kernel_h": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "kernel_w": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.kernel_size": {
                                    "variable_value": "(3, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "stride_h": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "stride_w": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.strides": {
                                    "variable_value": "(1, 1)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "self.output_padding": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "out_pad_h": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "out_pad_w": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.filters": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "conv_utils.deconv_length": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "conv_utils": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.padding": {
                                    "variable_value": "'same'",
                                    "variable_type": "str",
                                    "variable_shape": "4"
                                },
                                "self.dilation_rate": {
                                    "variable_value": "(2, 2)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                }
                            },
                            {
                                "output_shape": {
                                    "variable_value": "[1, 4, 4, 1]",
                                    "variable_type": "list",
                                    "variable_shape": "4"
                                },
                                "input_shape": {
                                    "variable_value": "(1, 4, 4, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "4"
                                },
                                "self.data_format": {
                                    "variable_value": "'channels_last'",
                                    "variable_type": "str",
                                    "variable_shape": "13"
                                },
                                "self": {
                                    "variable_value": "<keras.layers.convolutional.Conv2DTranspose object at 0x12bce6750>",
                                    "variable_type": "Conv2DTranspose",
                                    "variable_shape": null
                                },
                                "c_axis": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "h_axis": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "w_axis": {
                                    "variable_value": "2",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "kernel_h": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "kernel_w": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "self.kernel_size": {
                                    "variable_value": "(3, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "stride_h": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "stride_w": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "self.strides": {
                                    "variable_value": "(1, 1)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "self.output_padding": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "out_pad_h": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "out_pad_w": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self.filters": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "conv_utils.deconv_length": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "conv_utils": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.padding": {
                                    "variable_value": "'same'",
                                    "variable_type": "str",
                                    "variable_shape": "4"
                                },
                                "self.dilation_rate": {
                                    "variable_value": "(2, 2)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                }
                            }
                        ],
                        [
                            {
                                "output_shape": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "input_shape": {
                                    "variable_value": "(1, 4, 4, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "4"
                                },
                                "self.data_format": {
                                    "variable_value": "'channels_last'",
                                    "variable_type": "str",
                                    "variable_shape": "13"
                                },
                                "self": {
                                    "variable_value": "<keras.layers.convolutional.Conv2DTranspose object at 0x12bdaed50>",
                                    "variable_type": "Conv2DTranspose",
                                    "variable_shape": null
                                },
                                "c_axis": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "h_axis": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "w_axis": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "kernel_h": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "kernel_w": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.kernel_size": {
                                    "variable_value": "(3, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "stride_h": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "stride_w": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.strides": {
                                    "variable_value": "(1, 1)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "self.output_padding": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "out_pad_h": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "out_pad_w": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.filters": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "conv_utils.deconv_length": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "conv_utils": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.padding": {
                                    "variable_value": "'same'",
                                    "variable_type": "str",
                                    "variable_shape": "4"
                                },
                                "self.dilation_rate": {
                                    "variable_value": "(2, 2)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                }
                            },
                            {
                                "output_shape": {
                                    "variable_value": "[1, 4, 4, 1]",
                                    "variable_type": "list",
                                    "variable_shape": "4"
                                },
                                "input_shape": {
                                    "variable_value": "(1, 4, 4, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "4"
                                },
                                "self.data_format": {
                                    "variable_value": "'channels_last'",
                                    "variable_type": "str",
                                    "variable_shape": "13"
                                },
                                "self": {
                                    "variable_value": "<keras.layers.convolutional.Conv2DTranspose object at 0x12bdaed50>",
                                    "variable_type": "Conv2DTranspose",
                                    "variable_shape": null
                                },
                                "c_axis": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "h_axis": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "w_axis": {
                                    "variable_value": "2",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "kernel_h": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "kernel_w": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "self.kernel_size": {
                                    "variable_value": "(3, 3)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "stride_h": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "stride_w": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "self.strides": {
                                    "variable_value": "(1, 1)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "self.output_padding": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "out_pad_h": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "out_pad_w": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "self.filters": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "conv_utils.deconv_length": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "conv_utils": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.padding": {
                                    "variable_value": "'same'",
                                    "variable_type": "str",
                                    "variable_shape": "4"
                                },
                                "self.dilation_rate": {
                                    "variable_value": "(2, 2)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                }
                            }
                        ]
                    ]
                },
                {
                    "function_name": "get_config",
                    "function_code": "def get_config(self):\n    config = super(Conv2DTranspose, self).get_config()\n    config.pop('dilation_rate')\n    config['output_padding'] = self.output_padding\n    return config\n",
                    "decorators": [],
                    "docstring": null,
                    "start_line": 878,
                    "end_line": 882,
                    "variables": {
                        "config": [
                            880,
                            881,
                            882,
                            879
                        ],
                        "get_config": [
                            879
                        ],
                        "super": [
                            879
                        ],
                        "Conv2DTranspose": [
                            879
                        ],
                        "self": [
                            881,
                            879
                        ],
                        "config.pop": [
                            880
                        ],
                        "self.output_padding": [
                            881
                        ]
                    },
                    "filtered_variables": {
                        "config": [
                            880,
                            881,
                            882,
                            879
                        ],
                        "get_config": [
                            879
                        ],
                        "Conv2DTranspose": [
                            879
                        ],
                        "self": [
                            881,
                            879
                        ],
                        "config.pop": [
                            880
                        ],
                        "self.output_padding": [
                            881
                        ]
                    },
                    "diff_line_number": 880,
                    "class_data": {
                        "signature": "class Conv2DTranspose(Conv2D)",
                        "docstring": "Transposed convolution layer (sometimes called Deconvolution).\n\nThe need for transposed convolutions generally arises\nfrom the desire to use a transformation going in the opposite direction\nof a normal convolution, i.e., from something that has the shape of the\noutput of some convolution to something that has the shape of its input\nwhile maintaining a connectivity pattern that is compatible with\nsaid convolution.\n\nWhen using this layer as the first layer in a model,\nprovide the keyword argument `input_shape`\n(tuple of integers, does not include the sample axis),\ne.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures\nin `data_format=\"channels_last\"`.\n\n# Arguments\n    filters: Integer, the dimensionality of the output space\n        (i.e. the number of output filters in the convolution).\n    kernel_size: An integer or tuple/list of 2 integers, specifying the\n        height and width of the 2D convolution window.\n        Can be a single integer to specify the same value for\n        all spatial dimensions.\n    strides: An integer or tuple/list of 2 integers,\n        specifying the strides of the convolution\n        along the height and width.\n        Can be a single integer to specify the same value for\n        all spatial dimensions.\n        Specifying any stride value != 1 is incompatible with specifying\n        any `dilation_rate` value != 1.\n    padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n    output_padding: An integer or tuple/list of 2 integers,\n        specifying the amount of padding along the height and width\n        of the output tensor.\n        Can be a single integer to specify the same value for all\n        spatial dimensions.\n        The amount of output padding along a given dimension must be\n        lower than the stride along that same dimension.\n        If set to `None` (default), the output shape is inferred.\n    data_format: A string,\n        one of `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs.\n        `\"channels_last\"` corresponds to inputs with shape\n        `(batch, height, width, channels)` while `\"channels_first\"`\n        corresponds to inputs with shape\n        `(batch, channels, height, width)`.\n        It defaults to the `image_data_format` value found in your\n        Keras config file at `~/.keras/keras.json`.\n        If you never set it, then it will be \"channels_last\".\n    dilation_rate: an integer or tuple/list of 2 integers, specifying\n        the dilation rate to use for dilated convolution.\n        Can be a single integer to specify the same value for\n        all spatial dimensions.\n        Currently, specifying any `dilation_rate` value != 1 is\n        incompatible with specifying any stride value != 1.\n    activation: Activation function to use\n        (see [activations](../activations.md)).\n        If you don't specify anything, no activation is applied\n        (ie. \"linear\" activation: `a(x) = x`).\n    use_bias: Boolean, whether the layer uses a bias vector.\n    kernel_initializer: Initializer for the `kernel` weights matrix\n        (see [initializers](../initializers.md)).\n    bias_initializer: Initializer for the bias vector\n        (see [initializers](../initializers.md)).\n    kernel_regularizer: Regularizer function applied to\n        the `kernel` weights matrix\n        (see [regularizer](../regularizers.md)).\n    bias_regularizer: Regularizer function applied to the bias vector\n        (see [regularizer](../regularizers.md)).\n    activity_regularizer: Regularizer function applied to\n        the output of the layer (its \"activation\").\n        (see [regularizer](../regularizers.md)).\n    kernel_constraint: Constraint function applied to the kernel matrix\n        (see [constraints](../constraints.md)).\n    bias_constraint: Constraint function applied to the bias vector\n        (see [constraints](../constraints.md)).\n\n# Input shape\n    4D tensor with shape:\n    `(batch, channels, rows, cols)`\n    if `data_format` is `\"channels_first\"`\n    or 4D tensor with shape:\n    `(batch, rows, cols, channels)`\n    if `data_format` is `\"channels_last\"`.\n\n# Output shape\n    4D tensor with shape:\n    `(batch, filters, new_rows, new_cols)`\n    if `data_format` is `\"channels_first\"`\n    or 4D tensor with shape:\n    `(batch, new_rows, new_cols, filters)`\n    if `data_format` is `\"channels_last\"`.\n    `rows` and `cols` values might have changed due to padding.\n    If `output_padding` is specified:\n\n    ```\n    new_rows = (rows - 1) * strides[0] + kernel_size[0] - 2 * padding[0] + output_padding[0]\n    new_cols = (cols - 1) * strides[1] + kernel_size[1] - 2 * padding[1] + output_padding[1]\n    ```\n\n# References\n    - [A guide to convolution arithmetic for deep learning](https://arxiv.org/abs/1603.07285v1)\n    - [Deconvolutional Networks](http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf)",
                        "constructor_docstring": null,
                        "functions": [
                            "@interfaces.legacy_deconv2d_support\ndef __init__(self, filters, kernel_size, strides=(1, 1), padding='valid', output_padding=None, data_format=None, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs):\n    super(Conv2DTranspose, self).__init__(filters, kernel_size, strides=strides, padding=padding, data_format=data_format, activation=activation, use_bias=use_bias, kernel_initializer=kernel_initializer, bias_initializer=bias_initializer, kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer, activity_regularizer=activity_regularizer, kernel_constraint=kernel_constraint, bias_constraint=bias_constraint, **kwargs)\n    self.output_padding = output_padding\n    if self.output_padding is not None:\n        self.output_padding = conv_utils.normalize_tuple(self.output_padding, 2, 'output_padding')\n        for stride, out_pad in zip(self.strides, self.output_padding):\n            if out_pad >= stride:\n                raise ValueError('Stride ' + str(self.strides) + ' must be greater than output padding ' + str(self.output_padding))",
                            "def build(self, input_shape):\n    if len(input_shape) != 4:\n        raise ValueError('Inputs should have rank ' + str(4) + '; Received input shape:', str(input_shape))\n    if self.data_format == 'channels_first':\n        channel_axis = 1\n    else:\n        channel_axis = -1\n    if input_shape[channel_axis] is None:\n        raise ValueError('The channel dimension of the inputs should be defined. Found `None`.')\n    input_dim = input_shape[channel_axis]\n    kernel_shape = self.kernel_size + (self.filters, input_dim)\n    self.kernel = self.add_weight(shape=kernel_shape, initializer=self.kernel_initializer, name='kernel', regularizer=self.kernel_regularizer, constraint=self.kernel_constraint)\n    if self.use_bias:\n        self.bias = self.add_weight(shape=(self.filters,), initializer=self.bias_initializer, name='bias', regularizer=self.bias_regularizer, constraint=self.bias_constraint)\n    else:\n        self.bias = None\n    self.input_spec = InputSpec(ndim=4, axes={channel_axis: input_dim})\n    self.built = True",
                            "def call(self, inputs):\n    input_shape = K.shape(inputs)\n    batch_size = input_shape[0]\n    if self.data_format == 'channels_first':\n        h_axis, w_axis = (2, 3)\n    else:\n        h_axis, w_axis = (1, 2)\n    height, width = (input_shape[h_axis], input_shape[w_axis])\n    kernel_h, kernel_w = self.kernel_size\n    stride_h, stride_w = self.strides\n    if self.output_padding is None:\n        out_pad_h = out_pad_w = None\n    else:\n        out_pad_h, out_pad_w = self.output_padding\n    out_height = conv_utils.deconv_length(height, stride_h, kernel_h, self.padding, out_pad_h)\n    out_width = conv_utils.deconv_length(width, stride_w, kernel_w, self.padding, out_pad_w)\n    if self.data_format == 'channels_first':\n        output_shape = (batch_size, self.filters, out_height, out_width)\n    else:\n        output_shape = (batch_size, out_height, out_width, self.filters)\n    outputs = K.conv2d_transpose(inputs, self.kernel, output_shape, self.strides, padding=self.padding, data_format=self.data_format)\n    if self.use_bias:\n        outputs = K.bias_add(outputs, self.bias, data_format=self.data_format)\n    if self.activation is not None:\n        return self.activation(outputs)\n    return outputs",
                            "def compute_output_shape(self, input_shape):\n    output_shape = list(input_shape)\n    if self.data_format == 'channels_first':\n        c_axis, h_axis, w_axis = (1, 2, 3)\n    else:\n        c_axis, h_axis, w_axis = (3, 1, 2)\n    kernel_h, kernel_w = self.kernel_size\n    stride_h, stride_w = self.strides\n    if self.output_padding is None:\n        out_pad_h = out_pad_w = None\n    else:\n        out_pad_h, out_pad_w = self.output_padding\n    output_shape[c_axis] = self.filters\n    output_shape[h_axis] = conv_utils.deconv_length(output_shape[h_axis], stride_h, kernel_h, self.padding, out_pad_h)\n    output_shape[w_axis] = conv_utils.deconv_length(output_shape[w_axis], stride_w, kernel_w, self.padding, out_pad_w)\n    return tuple(output_shape)",
                            "def get_config(self):\n    config = super(Conv2DTranspose, self).get_config()\n    config.pop('dilation_rate')\n    config['output_padding'] = self.output_padding\n    return config"
                        ],
                        "constructor_variables": [
                            "output_padding"
                        ],
                        "class_level_variables": [],
                        "class_decorators": [],
                        "function_signatures": [
                            "__init__(self, filters, kernel_size, strides=(1, 1), padding='valid', output_padding=None, data_format=None, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)",
                            "build(self, input_shape)",
                            "call(self, inputs)",
                            "compute_output_shape(self, input_shape)",
                            "get_config(self)"
                        ]
                    },
                    "variable_values": [
                        [
                            {
                                "config": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "get_config": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "Conv2DTranspose": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self": {
                                    "variable_value": "<keras.layers.convolutional.Conv2DTranspose object at 0x12634a5d0>",
                                    "variable_type": "Conv2DTranspose",
                                    "variable_shape": null
                                },
                                "config.pop": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.output_padding": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                }
                            },
                            {
                                "config": {
                                    "variable_value": "{'name': 'conv2d_transpose_1', 'trainable': True, 'filters': 2, 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None, 'output_padding': None}",
                                    "variable_type": "dict",
                                    "variable_shape": "17"
                                },
                                "get_config": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "Conv2DTranspose": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self": {
                                    "variable_value": "<keras.layers.convolutional.Conv2DTranspose object at 0x12634a5d0>",
                                    "variable_type": "Conv2DTranspose",
                                    "variable_shape": null
                                },
                                "config.pop": {
                                    "variable_value": "<built-in method pop of dict object at 0x12643e9b0>",
                                    "variable_type": "builtin_function_or_method",
                                    "variable_shape": null
                                },
                                "self.output_padding": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                }
                            }
                        ],
                        [
                            {
                                "config": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "get_config": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "Conv2DTranspose": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self": {
                                    "variable_value": "<keras.layers.convolutional.Conv2DTranspose object at 0x12634a5d0>",
                                    "variable_type": "Conv2DTranspose",
                                    "variable_shape": null
                                },
                                "config.pop": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.output_padding": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                }
                            },
                            {
                                "config": {
                                    "variable_value": "{'name': 'conv2d_transpose_1', 'trainable': True, 'filters': 2, 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None, 'output_padding': None}",
                                    "variable_type": "dict",
                                    "variable_shape": "17"
                                },
                                "get_config": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "Conv2DTranspose": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self": {
                                    "variable_value": "<keras.layers.convolutional.Conv2DTranspose object at 0x12634a5d0>",
                                    "variable_type": "Conv2DTranspose",
                                    "variable_shape": null
                                },
                                "config.pop": {
                                    "variable_value": "<built-in method pop of dict object at 0x126a4deb0>",
                                    "variable_type": "builtin_function_or_method",
                                    "variable_shape": null
                                },
                                "self.output_padding": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                }
                            }
                        ],
                        [
                            {
                                "config": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "get_config": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "Conv2DTranspose": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self": {
                                    "variable_value": "<keras.layers.convolutional.Conv2DTranspose object at 0x126a4cdd0>",
                                    "variable_type": "Conv2DTranspose",
                                    "variable_shape": null
                                },
                                "config.pop": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self.output_padding": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                }
                            },
                            {
                                "config": {
                                    "variable_value": "{'name': 'conv2d_transpose_1', 'trainable': True, 'batch_input_shape': (2, 5, 6, 3), 'dtype': 'float32', 'filters': 2, 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None, 'output_padding': None}",
                                    "variable_type": "dict",
                                    "variable_shape": "19"
                                },
                                "get_config": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "Conv2DTranspose": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self": {
                                    "variable_value": "<keras.layers.convolutional.Conv2DTranspose object at 0x126a4cdd0>",
                                    "variable_type": "Conv2DTranspose",
                                    "variable_shape": null
                                },
                                "config.pop": {
                                    "variable_value": "<built-in method pop of dict object at 0x126a67730>",
                                    "variable_type": "builtin_function_or_method",
                                    "variable_shape": null
                                },
                                "self.output_padding": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                }
                            }
                        ]
                    ]
                }
            ],
            "inscope_functions": [
                "def __init__(self, rank,\n             filters,\n             kernel_size,\n             strides=1,\n             padding='valid',\n             data_format=None,\n             dilation_rate=1,\n             activation=None,\n             use_bias=True,\n             kernel_initializer='glorot_uniform',\n             bias_initializer='zeros',\n             kernel_regularizer=None,\n             bias_regularizer=None,\n             activity_regularizer=None,\n             kernel_constraint=None,\n             bias_constraint=None,\n             **kwargs):\n    super(_Conv, self).__init__(**kwargs)\n    self.rank = rank\n    self.filters = filters\n    self.kernel_size = conv_utils.normalize_tuple(kernel_size, rank, 'kernel_size')\n    self.strides = conv_utils.normalize_tuple(strides, rank, 'strides')\n    self.padding = conv_utils.normalize_padding(padding)\n    self.data_format = K.normalize_data_format(data_format)\n    self.dilation_rate = conv_utils.normalize_tuple(dilation_rate, rank, 'dilation_rate')\n    self.activation = activations.get(activation)\n    self.use_bias = use_bias\n    self.kernel_initializer = initializers.get(kernel_initializer)\n    self.bias_initializer = initializers.get(bias_initializer)\n    self.kernel_regularizer = regularizers.get(kernel_regularizer)\n    self.bias_regularizer = regularizers.get(bias_regularizer)\n    self.activity_regularizer = regularizers.get(activity_regularizer)\n    self.kernel_constraint = constraints.get(kernel_constraint)\n    self.bias_constraint = constraints.get(bias_constraint)\n    self.input_spec = InputSpec(ndim=self.rank + 2)",
                "def build(self, input_shape):\n    if self.data_format == 'channels_first':\n        channel_axis = 1\n    else:\n        channel_axis = -1\n    if input_shape[channel_axis] is None:\n        raise ValueError('The channel dimension of the inputs '\n                         'should be defined. Found `None`.')\n    input_dim = input_shape[channel_axis]\n    kernel_shape = self.kernel_size + (input_dim, self.filters)\n\n    self.kernel = self.add_weight(shape=kernel_shape,\n                                  initializer=self.kernel_initializer,\n                                  name='kernel',\n                                  regularizer=self.kernel_regularizer,\n                                  constraint=self.kernel_constraint)\n    if self.use_bias:\n        self.bias = self.add_weight(shape=(self.filters,),\n                                    initializer=self.bias_initializer,\n                                    name='bias',\n                                    regularizer=self.bias_regularizer,\n                                    constraint=self.bias_constraint)\n    else:\n        self.bias = None\n    # Set input spec.\n    self.input_spec = InputSpec(ndim=self.rank + 2,\n                                axes={channel_axis: input_dim})\n    self.built = True",
                "def call(self, inputs):\n    if self.rank == 1:\n        outputs = K.conv1d(\n            inputs,\n            self.kernel,\n            strides=self.strides[0],\n            padding=self.padding,\n            data_format=self.data_format,\n            dilation_rate=self.dilation_rate[0])\n    if self.rank == 2:\n        outputs = K.conv2d(\n            inputs,\n            self.kernel,\n            strides=self.strides,\n            padding=self.padding,\n            data_format=self.data_format,\n            dilation_rate=self.dilation_rate)\n    if self.rank == 3:\n        outputs = K.conv3d(\n            inputs,\n            self.kernel,\n            strides=self.strides,\n            padding=self.padding,\n            data_format=self.data_format,\n            dilation_rate=self.dilation_rate)\n\n    if self.use_bias:\n        outputs = K.bias_add(\n            outputs,\n            self.bias,\n            data_format=self.data_format)\n\n    if self.activation is not None:\n        return self.activation(outputs)\n    return outputs",
                "def compute_output_shape(self, input_shape):\n    if self.data_format == 'channels_last':\n        space = input_shape[1:-1]\n        new_space = []\n        for i in range(len(space)):\n            new_dim = conv_utils.conv_output_length(\n                space[i],\n                self.kernel_size[i],\n                padding=self.padding,\n                stride=self.strides[i],\n                dilation=self.dilation_rate[i])\n            new_space.append(new_dim)\n        return (input_shape[0],) + tuple(new_space) + (self.filters,)\n    if self.data_format == 'channels_first':\n        space = input_shape[2:]\n        new_space = []\n        for i in range(len(space)):\n            new_dim = conv_utils.conv_output_length(\n                space[i],\n                self.kernel_size[i],\n                padding=self.padding,\n                stride=self.strides[i],\n                dilation=self.dilation_rate[i])\n            new_space.append(new_dim)\n        return (input_shape[0], self.filters) + tuple(new_space)",
                "def get_config(self):\n    config = {\n        'rank': self.rank,\n        'filters': self.filters,\n        'kernel_size': self.kernel_size,\n        'strides': self.strides,\n        'padding': self.padding,\n        'data_format': self.data_format,\n        'dilation_rate': self.dilation_rate,\n        'activation': activations.serialize(self.activation),\n        'use_bias': self.use_bias,\n        'kernel_initializer': initializers.serialize(self.kernel_initializer),\n        'bias_initializer': initializers.serialize(self.bias_initializer),\n        'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n        'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n        'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n        'kernel_constraint': constraints.serialize(self.kernel_constraint),\n        'bias_constraint': constraints.serialize(self.bias_constraint)\n    }\n    base_config = super(_Conv, self).get_config()\n    return dict(list(base_config.items()) + list(config.items()))",
                "@interfaces.legacy_conv1d_support\ndef __init__(self, filters,\n             kernel_size,\n             strides=1,\n             padding='valid',\n             data_format='channels_last',\n             dilation_rate=1,\n             activation=None,\n             use_bias=True,\n             kernel_initializer='glorot_uniform',\n             bias_initializer='zeros',\n             kernel_regularizer=None,\n             bias_regularizer=None,\n             activity_regularizer=None,\n             kernel_constraint=None,\n             bias_constraint=None,\n             **kwargs):\n    if padding == 'causal':\n        if data_format != 'channels_last':\n            raise ValueError('When using causal padding in `Conv1D`, '\n                             '`data_format` must be \"channels_last\" '\n                             '(temporal data).')\n    super(Conv1D, self).__init__(\n        rank=1,\n        filters=filters,\n        kernel_size=kernel_size,\n        strides=strides,\n        padding=padding,\n        data_format=data_format,\n        dilation_rate=dilation_rate,\n        activation=activation,\n        use_bias=use_bias,\n        kernel_initializer=kernel_initializer,\n        bias_initializer=bias_initializer,\n        kernel_regularizer=kernel_regularizer,\n        bias_regularizer=bias_regularizer,\n        activity_regularizer=activity_regularizer,\n        kernel_constraint=kernel_constraint,\n        bias_constraint=bias_constraint,\n        **kwargs)",
                "def get_config(self):\n    config = super(Conv1D, self).get_config()\n    config.pop('rank')\n    return config",
                "@interfaces.legacy_conv2d_support\ndef __init__(self, filters,\n             kernel_size,\n             strides=(1, 1),\n             padding='valid',\n             data_format=None,\n             dilation_rate=(1, 1),\n             activation=None,\n             use_bias=True,\n             kernel_initializer='glorot_uniform',\n             bias_initializer='zeros',\n             kernel_regularizer=None,\n             bias_regularizer=None,\n             activity_regularizer=None,\n             kernel_constraint=None,\n             bias_constraint=None,\n             **kwargs):\n    super(Conv2D, self).__init__(\n        rank=2,\n        filters=filters,\n        kernel_size=kernel_size,\n        strides=strides,\n        padding=padding,\n        data_format=data_format,\n        dilation_rate=dilation_rate,\n        activation=activation,\n        use_bias=use_bias,\n        kernel_initializer=kernel_initializer,\n        bias_initializer=bias_initializer,\n        kernel_regularizer=kernel_regularizer,\n        bias_regularizer=bias_regularizer,\n        activity_regularizer=activity_regularizer,\n        kernel_constraint=kernel_constraint,\n        bias_constraint=bias_constraint,\n        **kwargs)",
                "def get_config(self):\n    config = super(Conv2D, self).get_config()\n    config.pop('rank')\n    return config",
                "@interfaces.legacy_conv3d_support\ndef __init__(self, filters,\n             kernel_size,\n             strides=(1, 1, 1),\n             padding='valid',\n             data_format=None,\n             dilation_rate=(1, 1, 1),\n             activation=None,\n             use_bias=True,\n             kernel_initializer='glorot_uniform',\n             bias_initializer='zeros',\n             kernel_regularizer=None,\n             bias_regularizer=None,\n             activity_regularizer=None,\n             kernel_constraint=None,\n             bias_constraint=None,\n             **kwargs):\n    super(Conv3D, self).__init__(\n        rank=3,\n        filters=filters,\n        kernel_size=kernel_size,\n        strides=strides,\n        padding=padding,\n        data_format=data_format,\n        dilation_rate=dilation_rate,\n        activation=activation,\n        use_bias=use_bias,\n        kernel_initializer=kernel_initializer,\n        bias_initializer=bias_initializer,\n        kernel_regularizer=kernel_regularizer,\n        bias_regularizer=bias_regularizer,\n        activity_regularizer=activity_regularizer,\n        kernel_constraint=kernel_constraint,\n        bias_constraint=bias_constraint,\n        **kwargs)",
                "def get_config(self):\n    config = super(Conv3D, self).get_config()\n    config.pop('rank')\n    return config",
                "@interfaces.legacy_deconv2d_support\ndef __init__(self, filters,\n             kernel_size,\n             strides=(1, 1),\n             padding='valid',\n             output_padding=None,\n             data_format=None,\n             activation=None,\n             use_bias=True,\n             kernel_initializer='glorot_uniform',\n             bias_initializer='zeros',\n             kernel_regularizer=None,\n             bias_regularizer=None,\n             activity_regularizer=None,\n             kernel_constraint=None,\n             bias_constraint=None,\n             **kwargs):\n    super(Conv2DTranspose, self).__init__(\n        filters,\n        kernel_size,\n        strides=strides,\n        padding=padding,\n        data_format=data_format,\n        activation=activation,\n        use_bias=use_bias,\n        kernel_initializer=kernel_initializer,\n        bias_initializer=bias_initializer,\n        kernel_regularizer=kernel_regularizer,\n        bias_regularizer=bias_regularizer,\n        activity_regularizer=activity_regularizer,\n        kernel_constraint=kernel_constraint,\n        bias_constraint=bias_constraint,\n        **kwargs)\n\n    self.output_padding = output_padding\n    if self.output_padding is not None:\n        self.output_padding = conv_utils.normalize_tuple(\n            self.output_padding, 2, 'output_padding')\n        for stride, out_pad in zip(self.strides, self.output_padding):\n            if out_pad >= stride:\n                raise ValueError('Stride ' + str(self.strides) + ' must be '\n                                 'greater than output padding ' +\n                                 str(self.output_padding))",
                "def build(self, input_shape):\n    if len(input_shape) != 4:\n        raise ValueError('Inputs should have rank ' +\n                         str(4) +\n                         '; Received input shape:', str(input_shape))\n    if self.data_format == 'channels_first':\n        channel_axis = 1\n    else:\n        channel_axis = -1\n    if input_shape[channel_axis] is None:\n        raise ValueError('The channel dimension of the inputs '\n                         'should be defined. Found `None`.')\n    input_dim = input_shape[channel_axis]\n    kernel_shape = self.kernel_size + (self.filters, input_dim)\n\n    self.kernel = self.add_weight(shape=kernel_shape,\n                                  initializer=self.kernel_initializer,\n                                  name='kernel',\n                                  regularizer=self.kernel_regularizer,\n                                  constraint=self.kernel_constraint)\n    if self.use_bias:\n        self.bias = self.add_weight(shape=(self.filters,),\n                                    initializer=self.bias_initializer,\n                                    name='bias',\n                                    regularizer=self.bias_regularizer,\n                                    constraint=self.bias_constraint)\n    else:\n        self.bias = None\n    # Set input spec.\n    self.input_spec = InputSpec(ndim=4, axes={channel_axis: input_dim})\n    self.built = True",
                "def call(self, inputs):\n    input_shape = K.shape(inputs)\n    batch_size = input_shape[0]\n    if self.data_format == 'channels_first':\n        h_axis, w_axis = 2, 3\n    else:\n        h_axis, w_axis = 1, 2\n\n    height, width = input_shape[h_axis], input_shape[w_axis]\n    kernel_h, kernel_w = self.kernel_size\n    stride_h, stride_w = self.strides\n    if self.output_padding is None:\n        out_pad_h = out_pad_w = None\n    else:\n        out_pad_h, out_pad_w = self.output_padding\n\n    # Infer the dynamic output shape:\n    out_height = conv_utils.deconv_length(height,\n                                          stride_h, kernel_h,\n                                          self.padding,\n                                          out_pad_h)\n    out_width = conv_utils.deconv_length(width,\n                                         stride_w, kernel_w,\n                                         self.padding,\n                                         out_pad_w)\n    if self.data_format == 'channels_first':\n        output_shape = (batch_size, self.filters, out_height, out_width)\n    else:\n        output_shape = (batch_size, out_height, out_width, self.filters)\n\n    outputs = K.conv2d_transpose(\n        inputs,\n        self.kernel,\n        output_shape,\n        self.strides,\n        padding=self.padding,\n        data_format=self.data_format)\n\n    if self.use_bias:\n        outputs = K.bias_add(\n            outputs,\n            self.bias,\n            data_format=self.data_format)\n\n    if self.activation is not None:\n        return self.activation(outputs)\n    return outputs",
                "def compute_output_shape(self, input_shape):\n    output_shape = list(input_shape)\n    if self.data_format == 'channels_first':\n        c_axis, h_axis, w_axis = 1, 2, 3\n    else:\n        c_axis, h_axis, w_axis = 3, 1, 2\n\n    kernel_h, kernel_w = self.kernel_size\n    stride_h, stride_w = self.strides\n    if self.output_padding is None:\n        out_pad_h = out_pad_w = None\n    else:\n        out_pad_h, out_pad_w = self.output_padding\n\n    output_shape[c_axis] = self.filters\n    output_shape[h_axis] = conv_utils.deconv_length(output_shape[h_axis],\n                                                    stride_h,\n                                                    kernel_h,\n                                                    self.padding,\n                                                    out_pad_h)\n    output_shape[w_axis] = conv_utils.deconv_length(output_shape[w_axis],\n                                                    stride_w,\n                                                    kernel_w,\n                                                    self.padding,\n                                                    out_pad_w)\n    return tuple(output_shape)",
                "def get_config(self):\n    config = super(Conv2DTranspose, self).get_config()\n    config.pop('dilation_rate')\n    config['output_padding'] = self.output_padding\n    return config",
                "def __init__(self, filters,\n             kernel_size,\n             strides=(1, 1, 1),\n             padding='valid',\n             output_padding=None,\n             data_format=None,\n             activation=None,\n             use_bias=True,\n             kernel_initializer='glorot_uniform',\n             bias_initializer='zeros',\n             kernel_regularizer=None,\n             bias_regularizer=None,\n             activity_regularizer=None,\n             kernel_constraint=None,\n             bias_constraint=None,\n             **kwargs):\n    super(Conv3DTranspose, self).__init__(\n        filters,\n        kernel_size,\n        strides=strides,\n        padding=padding,\n        data_format=data_format,\n        activation=activation,\n        use_bias=use_bias,\n        kernel_initializer=kernel_initializer,\n        bias_initializer=bias_initializer,\n        kernel_regularizer=kernel_regularizer,\n        bias_regularizer=bias_regularizer,\n        activity_regularizer=activity_regularizer,\n        kernel_constraint=kernel_constraint,\n        bias_constraint=bias_constraint,\n        **kwargs)\n\n    self.output_padding = output_padding\n    if self.output_padding is not None:\n        self.output_padding = conv_utils.normalize_tuple(\n            self.output_padding, 3, 'output_padding')\n        for stride, out_pad in zip(self.strides, self.output_padding):\n            if out_pad >= stride:\n                raise ValueError('Stride ' + str(self.strides) + ' must be '\n                                 'greater than output padding ' +\n                                 str(self.output_padding))",
                "def build(self, input_shape):\n    if len(input_shape) != 5:\n        raise ValueError('Inputs should have rank ' +\n                         str(5) +\n                         '; Received input shape:', str(input_shape))\n    if self.data_format == 'channels_first':\n        channel_axis = 1\n    else:\n        channel_axis = -1\n    if input_shape[channel_axis] is None:\n        raise ValueError('The channel dimension of the inputs '\n                         'should be defined. Found `None`.')\n    input_dim = input_shape[channel_axis]\n    kernel_shape = self.kernel_size + (self.filters, input_dim)\n\n    self.kernel = self.add_weight(shape=kernel_shape,\n                                  initializer=self.kernel_initializer,\n                                  name='kernel',\n                                  regularizer=self.kernel_regularizer,\n                                  constraint=self.kernel_constraint)\n    if self.use_bias:\n        self.bias = self.add_weight(shape=(self.filters,),\n                                    initializer=self.bias_initializer,\n                                    name='bias',\n                                    regularizer=self.bias_regularizer,\n                                    constraint=self.bias_constraint)\n    else:\n        self.bias = None\n    # Set input spec.\n    self.input_spec = InputSpec(ndim=5, axes={channel_axis: input_dim})\n    self.built = True",
                "def call(self, inputs):\n    input_shape = K.shape(inputs)\n    batch_size = input_shape[0]\n    if self.data_format == 'channels_first':\n        d_axis, h_axis, w_axis = 2, 3, 4\n    else:\n        d_axis, h_axis, w_axis = 1, 2, 3\n\n    depth = input_shape[d_axis]\n    height = input_shape[h_axis]\n    width = input_shape[w_axis]\n\n    kernel_d, kernel_h, kernel_w = self.kernel_size\n    stride_d, stride_h, stride_w = self.strides\n    if self.output_padding is None:\n        out_pad_d = out_pad_h = out_pad_w = None\n    else:\n        out_pad_d, out_pad_h, out_pad_w = self.output_padding\n\n    # Infer the dynamic output shape:\n    out_depth = conv_utils.deconv_length(depth,\n                                         stride_d, kernel_d,\n                                         self.padding,\n                                         out_pad_d)\n    out_height = conv_utils.deconv_length(height,\n                                          stride_h, kernel_h,\n                                          self.padding,\n                                          out_pad_h)\n    out_width = conv_utils.deconv_length(width,\n                                         stride_w, kernel_w,\n                                         self.padding,\n                                         out_pad_w)\n\n    if self.data_format == 'channels_first':\n        output_shape = (batch_size, self.filters, out_depth, out_height, out_width)\n    else:\n        output_shape = (batch_size, out_depth, out_height, out_width, self.filters)\n\n    outputs = K.conv3d_transpose(inputs,\n                                 self.kernel,\n                                 output_shape,\n                                 self.strides,\n                                 padding=self.padding,\n                                 data_format=self.data_format)\n\n    if self.use_bias:\n        outputs = K.bias_add(\n            outputs,\n            self.bias,\n            data_format=self.data_format)\n\n    if self.activation is not None:\n        return self.activation(outputs)\n    return outputs",
                "def compute_output_shape(self, input_shape):\n    output_shape = list(input_shape)\n    if self.data_format == 'channels_first':\n        c_axis, d_axis, h_axis, w_axis = 1, 2, 3, 4\n    else:\n        c_axis, d_axis, h_axis, w_axis = 4, 1, 2, 3\n\n    kernel_d, kernel_h, kernel_w = self.kernel_size\n    stride_d, stride_h, stride_w = self.strides\n    if self.output_padding is None:\n        out_pad_d = out_pad_h = out_pad_w = None\n    else:\n        out_pad_d, out_pad_h, out_pad_w = self.output_padding\n\n    output_shape[c_axis] = self.filters\n    output_shape[d_axis] = conv_utils.deconv_length(output_shape[d_axis],\n                                                    stride_d,\n                                                    kernel_d,\n                                                    self.padding,\n                                                    out_pad_d)\n    output_shape[h_axis] = conv_utils.deconv_length(output_shape[h_axis],\n                                                    stride_h,\n                                                    kernel_h,\n                                                    self.padding,\n                                                    out_pad_h)\n    output_shape[w_axis] = conv_utils.deconv_length(output_shape[w_axis],\n                                                    stride_w,\n                                                    kernel_w,\n                                                    self.padding,\n                                                    out_pad_w)\n\n    return tuple(output_shape)",
                "def get_config(self):\n    config = super(Conv3DTranspose, self).get_config()\n    config.pop('dilation_rate')\n    config['output_padding'] = self.output_padding\n    return config",
                "def __init__(self, rank,\n             filters,\n             kernel_size,\n             strides=1,\n             padding='valid',\n             data_format=None,\n             dilation_rate=1,\n             depth_multiplier=1,\n             activation=None,\n             use_bias=True,\n             depthwise_initializer='glorot_uniform',\n             pointwise_initializer='glorot_uniform',\n             bias_initializer='zeros',\n             depthwise_regularizer=None,\n             pointwise_regularizer=None,\n             bias_regularizer=None,\n             activity_regularizer=None,\n             depthwise_constraint=None,\n             pointwise_constraint=None,\n             bias_constraint=None,\n             **kwargs):\n    super(_SeparableConv, self).__init__(\n        rank=rank,\n        filters=filters,\n        kernel_size=kernel_size,\n        strides=strides,\n        padding=padding,\n        data_format=data_format,\n        dilation_rate=dilation_rate,\n        activation=activation,\n        use_bias=use_bias,\n        bias_initializer=bias_initializer,\n        bias_regularizer=bias_regularizer,\n        activity_regularizer=activity_regularizer,\n        bias_constraint=bias_constraint,\n        **kwargs)\n    self.depth_multiplier = depth_multiplier\n    self.depthwise_initializer = initializers.get(depthwise_initializer)\n    self.pointwise_initializer = initializers.get(pointwise_initializer)\n    self.depthwise_regularizer = regularizers.get(depthwise_regularizer)\n    self.pointwise_regularizer = regularizers.get(pointwise_regularizer)\n    self.depthwise_constraint = constraints.get(depthwise_constraint)\n    self.pointwise_constraint = constraints.get(pointwise_constraint)",
                "def build(self, input_shape):\n    if len(input_shape) < self.rank + 2:\n        raise ValueError('Inputs to `SeparableConv' + str(self.rank) + 'D` '\n                         'should have rank ' + str(self.rank + 2) + '. '\n                         'Received input shape:', str(input_shape))\n    channel_axis = 1 if self.data_format == 'channels_first' else -1\n    if input_shape[channel_axis] is None:\n        raise ValueError('The channel dimension of the inputs '\n                         'should be defined. Found `None`.')\n    input_dim = int(input_shape[channel_axis])\n    depthwise_kernel_shape = self.kernel_size + (input_dim, self.depth_multiplier)\n    pointwise_kernel_shape = (1,) * self.rank + (self.depth_multiplier * input_dim, self.filters)\n\n    self.depthwise_kernel = self.add_weight(\n        shape=depthwise_kernel_shape,\n        initializer=self.depthwise_initializer,\n        name='depthwise_kernel',\n        regularizer=self.depthwise_regularizer,\n        constraint=self.depthwise_constraint)\n    self.pointwise_kernel = self.add_weight(\n        shape=pointwise_kernel_shape,\n        initializer=self.pointwise_initializer,\n        name='pointwise_kernel',\n        regularizer=self.pointwise_regularizer,\n        constraint=self.pointwise_constraint)\n\n    if self.use_bias:\n        self.bias = self.add_weight(shape=(self.filters,),\n                                    initializer=self.bias_initializer,\n                                    name='bias',\n                                    regularizer=self.bias_regularizer,\n                                    constraint=self.bias_constraint)\n    else:\n        self.bias = None\n    # Set input spec.\n    self.input_spec = InputSpec(ndim=self.rank + 2,\n                                axes={channel_axis: input_dim})\n    self.built = True",
                "def call(self, inputs):\n    if self.rank == 1:\n        outputs = K.separable_conv1d(\n            inputs,\n            self.depthwise_kernel,\n            self.pointwise_kernel,\n            data_format=self.data_format,\n            strides=self.strides,\n            padding=self.padding,\n            dilation_rate=self.dilation_rate)\n    if self.rank == 2:\n        outputs = K.separable_conv2d(\n            inputs,\n            self.depthwise_kernel,\n            self.pointwise_kernel,\n            data_format=self.data_format,\n            strides=self.strides,\n            padding=self.padding,\n            dilation_rate=self.dilation_rate)\n\n    if self.use_bias:\n        outputs = K.bias_add(\n            outputs,\n            self.bias,\n            data_format=self.data_format)\n\n    if self.activation is not None:\n        return self.activation(outputs)\n    return outputs",
                "def get_config(self):\n    config = super(_SeparableConv, self).get_config()\n    config.pop('rank')\n    config.pop('kernel_initializer')\n    config.pop('kernel_regularizer')\n    config.pop('kernel_constraint')\n    config['depth_multiplier'] = self.depth_multiplier\n    config['depthwise_initializer'] = initializers.serialize(self.depthwise_initializer)\n    config['pointwise_initializer'] = initializers.serialize(self.pointwise_initializer)\n    config['depthwise_regularizer'] = regularizers.serialize(self.depthwise_regularizer)\n    config['pointwise_regularizer'] = regularizers.serialize(self.pointwise_regularizer)\n    config['depthwise_constraint'] = constraints.serialize(self.depthwise_constraint)\n    config['pointwise_constraint'] = constraints.serialize(self.pointwise_constraint)\n    return config",
                "def __init__(self, filters,\n             kernel_size,\n             strides=1,\n             padding='valid',\n             data_format=None,\n             dilation_rate=1,\n             depth_multiplier=1,\n             activation=None,\n             use_bias=True,\n             depthwise_initializer='glorot_uniform',\n             pointwise_initializer='glorot_uniform',\n             bias_initializer='zeros',\n             depthwise_regularizer=None,\n             pointwise_regularizer=None,\n             bias_regularizer=None,\n             activity_regularizer=None,\n             depthwise_constraint=None,\n             pointwise_constraint=None,\n             bias_constraint=None,\n             **kwargs):\n    super(SeparableConv1D, self).__init__(\n        rank=1,\n        filters=filters,\n        kernel_size=kernel_size,\n        strides=strides,\n        padding=padding,\n        data_format=data_format,\n        dilation_rate=dilation_rate,\n        depth_multiplier=depth_multiplier,\n        activation=activation,\n        use_bias=use_bias,\n        depthwise_initializer=depthwise_initializer,\n        pointwise_initializer=pointwise_initializer,\n        bias_initializer=bias_initializer,\n        depthwise_regularizer=depthwise_regularizer,\n        pointwise_regularizer=pointwise_regularizer,\n        bias_regularizer=bias_regularizer,\n        activity_regularizer=activity_regularizer,\n        depthwise_constraint=depthwise_constraint,\n        pointwise_constraint=pointwise_constraint,\n        bias_constraint=bias_constraint,\n        **kwargs)",
                "@interfaces.legacy_separable_conv2d_support\ndef __init__(self, filters,\n             kernel_size,\n             strides=(1, 1),\n             padding='valid',\n             data_format=None,\n             dilation_rate=(1, 1),\n             depth_multiplier=1,\n             activation=None,\n             use_bias=True,\n             depthwise_initializer='glorot_uniform',\n             pointwise_initializer='glorot_uniform',\n             bias_initializer='zeros',\n             depthwise_regularizer=None,\n             pointwise_regularizer=None,\n             bias_regularizer=None,\n             activity_regularizer=None,\n             depthwise_constraint=None,\n             pointwise_constraint=None,\n             bias_constraint=None,\n             **kwargs):\n    super(SeparableConv2D, self).__init__(\n        rank=2,\n        filters=filters,\n        kernel_size=kernel_size,\n        strides=strides,\n        padding=padding,\n        data_format=data_format,\n        dilation_rate=dilation_rate,\n        depth_multiplier=depth_multiplier,\n        activation=activation,\n        use_bias=use_bias,\n        depthwise_initializer=depthwise_initializer,\n        pointwise_initializer=pointwise_initializer,\n        bias_initializer=bias_initializer,\n        depthwise_regularizer=depthwise_regularizer,\n        pointwise_regularizer=pointwise_regularizer,\n        bias_regularizer=bias_regularizer,\n        activity_regularizer=activity_regularizer,\n        depthwise_constraint=depthwise_constraint,\n        pointwise_constraint=pointwise_constraint,\n        bias_constraint=bias_constraint,\n        **kwargs)",
                "def __init__(self,\n             kernel_size,\n             strides=(1, 1),\n             padding='valid',\n             depth_multiplier=1,\n             data_format=None,\n             activation=None,\n             use_bias=True,\n             depthwise_initializer='glorot_uniform',\n             bias_initializer='zeros',\n             depthwise_regularizer=None,\n             bias_regularizer=None,\n             activity_regularizer=None,\n             depthwise_constraint=None,\n             bias_constraint=None,\n             **kwargs):\n    super(DepthwiseConv2D, self).__init__(\n        filters=None,\n        kernel_size=kernel_size,\n        strides=strides,\n        padding=padding,\n        data_format=data_format,\n        activation=activation,\n        use_bias=use_bias,\n        bias_regularizer=bias_regularizer,\n        activity_regularizer=activity_regularizer,\n        bias_constraint=bias_constraint,\n        **kwargs)\n    self.depth_multiplier = depth_multiplier\n    self.depthwise_initializer = initializers.get(depthwise_initializer)\n    self.depthwise_regularizer = regularizers.get(depthwise_regularizer)\n    self.depthwise_constraint = constraints.get(depthwise_constraint)\n    self.bias_initializer = initializers.get(bias_initializer)",
                "def build(self, input_shape):\n    if len(input_shape) < 4:\n        raise ValueError('Inputs to `DepthwiseConv2D` should have rank 4. '\n                         'Received input shape:', str(input_shape))\n    if self.data_format == 'channels_first':\n        channel_axis = 1\n    else:\n        channel_axis = 3\n    if input_shape[channel_axis] is None:\n        raise ValueError('The channel dimension of the inputs to '\n                         '`DepthwiseConv2D` '\n                         'should be defined. Found `None`.')\n    input_dim = int(input_shape[channel_axis])\n    depthwise_kernel_shape = (self.kernel_size[0],\n                              self.kernel_size[1],\n                              input_dim,\n                              self.depth_multiplier)\n\n    self.depthwise_kernel = self.add_weight(\n        shape=depthwise_kernel_shape,\n        initializer=self.depthwise_initializer,\n        name='depthwise_kernel',\n        regularizer=self.depthwise_regularizer,\n        constraint=self.depthwise_constraint)\n\n    if self.use_bias:\n        self.bias = self.add_weight(shape=(input_dim * self.depth_multiplier,),\n                                    initializer=self.bias_initializer,\n                                    name='bias',\n                                    regularizer=self.bias_regularizer,\n                                    constraint=self.bias_constraint)\n    else:\n        self.bias = None\n    # Set input spec.\n    self.input_spec = InputSpec(ndim=4, axes={channel_axis: input_dim})\n    self.built = True",
                "def call(self, inputs, training=None):\n    outputs = K.depthwise_conv2d(\n        inputs,\n        self.depthwise_kernel,\n        strides=self.strides,\n        padding=self.padding,\n        dilation_rate=self.dilation_rate,\n        data_format=self.data_format)\n\n    if self.use_bias:\n        outputs = K.bias_add(\n            outputs,\n            self.bias,\n            data_format=self.data_format)\n\n    if self.activation is not None:\n        return self.activation(outputs)\n\n    return outputs",
                "def compute_output_shape(self, input_shape):\n    if self.data_format == 'channels_first':\n        rows = input_shape[2]\n        cols = input_shape[3]\n        out_filters = input_shape[1] * self.depth_multiplier\n    elif self.data_format == 'channels_last':\n        rows = input_shape[1]\n        cols = input_shape[2]\n        out_filters = input_shape[3] * self.depth_multiplier\n\n    rows = conv_utils.conv_output_length(rows, self.kernel_size[0],\n                                         self.padding,\n                                         self.strides[0])\n    cols = conv_utils.conv_output_length(cols, self.kernel_size[1],\n                                         self.padding,\n                                         self.strides[1])\n    if self.data_format == 'channels_first':\n        return (input_shape[0], out_filters, rows, cols)\n    elif self.data_format == 'channels_last':\n        return (input_shape[0], rows, cols, out_filters)",
                "def get_config(self):\n    config = super(DepthwiseConv2D, self).get_config()\n    config.pop('filters')\n    config.pop('kernel_initializer')\n    config.pop('kernel_regularizer')\n    config.pop('kernel_constraint')\n    config['depth_multiplier'] = self.depth_multiplier\n    config['depthwise_initializer'] = initializers.serialize(self.depthwise_initializer)\n    config['depthwise_regularizer'] = regularizers.serialize(self.depthwise_regularizer)\n    config['depthwise_constraint'] = constraints.serialize(self.depthwise_constraint)\n    return config",
                "@interfaces.legacy_upsampling1d_support\ndef __init__(self, size=2, **kwargs):\n    super(UpSampling1D, self).__init__(**kwargs)\n    self.size = int(size)\n    self.input_spec = InputSpec(ndim=3)",
                "def compute_output_shape(self, input_shape):\n    size = self.size * input_shape[1] if input_shape[1] is not None else None\n    return (input_shape[0], size, input_shape[2])",
                "def call(self, inputs):\n    output = K.repeat_elements(inputs, self.size, axis=1)\n    return output",
                "def get_config(self):\n    config = {'size': self.size}\n    base_config = super(UpSampling1D, self).get_config()\n    return dict(list(base_config.items()) + list(config.items()))",
                "@interfaces.legacy_upsampling2d_support\ndef __init__(self, size=(2, 2), data_format=None, interpolation='nearest', **kwargs):\n    super(UpSampling2D, self).__init__(**kwargs)\n    self.data_format = K.normalize_data_format(data_format)\n    self.size = conv_utils.normalize_tuple(size, 2, 'size')\n    self.input_spec = InputSpec(ndim=4)\n    if interpolation not in ['nearest', 'bilinear']:\n        raise ValueError('interpolation should be one '\n                         'of \"nearest\" or \"bilinear\".')\n    self.interpolation = interpolation",
                "def compute_output_shape(self, input_shape):\n    if self.data_format == 'channels_first':\n        height = self.size[0] * input_shape[2] if input_shape[2] is not None else None\n        width = self.size[1] * input_shape[3] if input_shape[3] is not None else None\n        return (input_shape[0],\n                input_shape[1],\n                height,\n                width)\n    elif self.data_format == 'channels_last':\n        height = self.size[0] * input_shape[1] if input_shape[1] is not None else None\n        width = self.size[1] * input_shape[2] if input_shape[2] is not None else None\n        return (input_shape[0],\n                height,\n                width,\n                input_shape[3])",
                "def call(self, inputs):\n    return K.resize_images(inputs, self.size[0], self.size[1],\n                           self.data_format, self.interpolation)",
                "def get_config(self):\n    config = {'size': self.size,\n              'data_format': self.data_format}\n    base_config = super(UpSampling2D, self).get_config()\n    return dict(list(base_config.items()) + list(config.items()))",
                "@interfaces.legacy_upsampling3d_support\ndef __init__(self, size=(2, 2, 2), data_format=None, **kwargs):\n    self.data_format = K.normalize_data_format(data_format)\n    self.size = conv_utils.normalize_tuple(size, 3, 'size')\n    self.input_spec = InputSpec(ndim=5)\n    super(UpSampling3D, self).__init__(**kwargs)",
                "def compute_output_shape(self, input_shape):\n    if self.data_format == 'channels_first':\n        dim1 = self.size[0] * input_shape[2] if input_shape[2] is not None else None\n        dim2 = self.size[1] * input_shape[3] if input_shape[3] is not None else None\n        dim3 = self.size[2] * input_shape[4] if input_shape[4] is not None else None\n        return (input_shape[0],\n                input_shape[1],\n                dim1,\n                dim2,\n                dim3)\n    elif self.data_format == 'channels_last':\n        dim1 = self.size[0] * input_shape[1] if input_shape[1] is not None else None\n        dim2 = self.size[1] * input_shape[2] if input_shape[2] is not None else None\n        dim3 = self.size[2] * input_shape[3] if input_shape[3] is not None else None\n        return (input_shape[0],\n                dim1,\n                dim2,\n                dim3,\n                input_shape[4])",
                "def call(self, inputs):\n    return K.resize_volumes(inputs,\n                            self.size[0], self.size[1], self.size[2],\n                            self.data_format)",
                "def get_config(self):\n    config = {'size': self.size,\n              'data_format': self.data_format}\n    base_config = super(UpSampling3D, self).get_config()\n    return dict(list(base_config.items()) + list(config.items()))",
                "def __init__(self, padding, data_format=None, **kwargs):\n    # self.rank is 1 for ZeroPadding1D, 2 for ZeroPadding2D.\n    self.rank = len(padding)\n    self.padding = padding\n    self.data_format = K.normalize_data_format(data_format)\n    self.input_spec = InputSpec(ndim=self.rank + 2)\n    super(_ZeroPadding, self).__init__(**kwargs)",
                "def call(self, inputs):\n    raise NotImplementedError",
                "def compute_output_shape(self, input_shape):\n    padding_all_dims = ((0, 0),) + self.padding + ((0, 0),)\n    spatial_axes = list(range(1, 1 + self.rank))\n    padding_all_dims = transpose_shape(padding_all_dims,\n                                       self.data_format,\n                                       spatial_axes)\n    output_shape = list(input_shape)\n    for dim in range(len(output_shape)):\n        if output_shape[dim] is not None:\n            output_shape[dim] += sum(padding_all_dims[dim])\n    return tuple(output_shape)",
                "def get_config(self):\n    config = {'padding': self.padding,\n              'data_format': self.data_format}\n    base_config = super(_ZeroPadding, self).get_config()\n    return dict(list(base_config.items()) + list(config.items()))",
                "def __init__(self, padding=1, **kwargs):\n    normalized_padding = (conv_utils.normalize_tuple(padding, 2, 'padding'),)\n    super(ZeroPadding1D, self).__init__(normalized_padding,\n                                        'channels_last',\n                                        **kwargs)",
                "def call(self, inputs):\n    return K.temporal_padding(inputs, padding=self.padding[0])",
                "def get_config(self):\n    config = super(ZeroPadding1D, self).get_config()\n    config['padding'] = config['padding'][0]\n    config.pop('data_format')\n    return config",
                "@interfaces.legacy_zeropadding2d_support\ndef __init__(self,\n             padding=(1, 1),\n             data_format=None,\n             **kwargs):\n    if isinstance(padding, int):\n        normalized_padding = ((padding, padding), (padding, padding))\n    elif hasattr(padding, '__len__'):\n        if len(padding) != 2:\n            raise ValueError('`padding` should have two elements. '\n                             'Found: ' + str(padding))\n        height_padding = conv_utils.normalize_tuple(padding[0], 2,\n                                                    '1st entry of padding')\n        width_padding = conv_utils.normalize_tuple(padding[1], 2,\n                                                   '2nd entry of padding')\n        normalized_padding = (height_padding, width_padding)\n    else:\n        raise ValueError('`padding` should be either an int, '\n                         'a tuple of 2 ints '\n                         '(symmetric_height_pad, symmetric_width_pad), '\n                         'or a tuple of 2 tuples of 2 ints '\n                         '((top_pad, bottom_pad), (left_pad, right_pad)). '\n                         'Found: ' + str(padding))\n    super(ZeroPadding2D, self).__init__(normalized_padding,\n                                        data_format,\n                                        **kwargs)",
                "def call(self, inputs):\n    return K.spatial_2d_padding(inputs,\n                                padding=self.padding,\n                                data_format=self.data_format)",
                "@interfaces.legacy_zeropadding3d_support\ndef __init__(self, padding=(1, 1, 1), data_format=None, **kwargs):\n    if isinstance(padding, int):\n        normalized_padding = ((padding, padding), (padding, padding), (padding, padding))\n    elif hasattr(padding, '__len__'):\n        if len(padding) != 3:\n            raise ValueError('`padding` should have 3 elements. '\n                             'Found: ' + str(padding))\n        dim1_padding = conv_utils.normalize_tuple(padding[0], 2,\n                                                  '1st entry of padding')\n        dim2_padding = conv_utils.normalize_tuple(padding[1], 2,\n                                                  '2nd entry of padding')\n        dim3_padding = conv_utils.normalize_tuple(padding[2], 2,\n                                                  '3rd entry of padding')\n        normalized_padding = (dim1_padding, dim2_padding, dim3_padding)\n    else:\n        raise ValueError('`padding` should be either an int, '\n                         'a tuple of 3 ints '\n                         '(symmetric_dim1_pad, symmetric_dim2_pad, symmetric_dim3_pad), '\n                         'or a tuple of 3 tuples of 2 ints '\n                         '((left_dim1_pad, right_dim1_pad),'\n                         ' (left_dim2_pad, right_dim2_pad),'\n                         ' (left_dim3_pad, right_dim2_pad)). '\n                         'Found: ' + str(padding))\n    super(ZeroPadding3D, self).__init__(normalized_padding,\n                                        data_format,\n                                        **kwargs)",
                "def call(self, inputs):\n    return K.spatial_3d_padding(inputs,\n                                padding=self.padding,\n                                data_format=self.data_format)",
                "def __init__(self, cropping,\n             data_format=None,\n             **kwargs):\n    super(_Cropping, self).__init__(**kwargs)\n    # self.rank is 1 for Cropping1D, 2 for Cropping2D...\n    self.rank = len(cropping)\n    self.cropping = cropping\n    self.data_format = K.normalize_data_format(data_format)\n    self.input_spec = InputSpec(ndim=2 + self.rank)",
                "def call(self, inputs):\n    slices_dims = []\n    for start, end in self.cropping:\n        if end == 0:\n            end = None\n        else:\n            end = -end\n        slices_dims.append(slice(start, end))\n\n    slices = [slice(None)] + slices_dims + [slice(None)]\n    slices = tuple(slices)\n    spatial_axes = list(range(1, 1 + self.rank))\n    slices = transpose_shape(slices, self.data_format, spatial_axes)\n    return inputs[slices]",
                "def compute_output_shape(self, input_shape):\n    cropping_all_dims = ((0, 0),) + self.cropping + ((0, 0),)\n    spatial_axes = list(range(1, 1 + self.rank))\n    cropping_all_dims = transpose_shape(cropping_all_dims,\n                                        self.data_format,\n                                        spatial_axes)\n    output_shape = list(input_shape)\n    for dim in range(len(output_shape)):\n        if output_shape[dim] is not None:\n            output_shape[dim] -= sum(cropping_all_dims[dim])\n    return tuple(output_shape)",
                "def get_config(self):\n    config = {'cropping': self.cropping,\n              'data_format': self.data_format}\n    base_config = super(_Cropping, self).get_config()\n    return dict(list(base_config.items()) + list(config.items()))",
                "def __init__(self, cropping=(1, 1), **kwargs):\n    normalized_cropping = (conv_utils.normalize_tuple(cropping, 2, 'cropping'),)\n    super(Cropping1D, self).__init__(normalized_cropping,\n                                     'channels_last',\n                                     **kwargs)",
                "def get_config(self):\n    base_config = super(Cropping1D, self).get_config()\n    base_config.pop('data_format')\n    base_config['cropping'] = base_config['cropping'][0]\n    return base_config",
                "@interfaces.legacy_cropping2d_support\ndef __init__(self, cropping=((0, 0), (0, 0)),\n             data_format=None, **kwargs):\n    if isinstance(cropping, int):\n        normalized_cropping = ((cropping, cropping), (cropping, cropping))\n    elif hasattr(cropping, '__len__'):\n        if len(cropping) != 2:\n            raise ValueError('`cropping` should have two elements. '\n                             'Found: ' + str(cropping))\n        height_cropping = conv_utils.normalize_tuple(\n            cropping[0], 2,\n            '1st entry of cropping')\n        width_cropping = conv_utils.normalize_tuple(\n            cropping[1], 2,\n            '2nd entry of cropping')\n        normalized_cropping = (height_cropping, width_cropping)\n    else:\n        raise ValueError('`cropping` should be either an int, '\n                         'a tuple of 2 ints '\n                         '(symmetric_height_crop, symmetric_width_crop), '\n                         'or a tuple of 2 tuples of 2 ints '\n                         '((top_crop, bottom_crop), (left_crop, right_crop)). '\n                         'Found: ' + str(cropping))\n    super(Cropping2D, self).__init__(normalized_cropping,\n                                     data_format,\n                                     **kwargs)",
                "@interfaces.legacy_cropping3d_support\ndef __init__(self, cropping=((1, 1), (1, 1), (1, 1)),\n             data_format=None, **kwargs):\n    self.data_format = K.normalize_data_format(data_format)\n    if isinstance(cropping, int):\n        normalized_cropping = ((cropping, cropping),\n                               (cropping, cropping),\n                               (cropping, cropping))\n    elif hasattr(cropping, '__len__'):\n        if len(cropping) != 3:\n            raise ValueError('`cropping` should have 3 elements. '\n                             'Found: ' + str(cropping))\n        dim1_cropping = conv_utils.normalize_tuple(cropping[0], 2,\n                                                   '1st entry of cropping')\n        dim2_cropping = conv_utils.normalize_tuple(cropping[1], 2,\n                                                   '2nd entry of cropping')\n        dim3_cropping = conv_utils.normalize_tuple(cropping[2], 2,\n                                                   '3rd entry of cropping')\n        normalized_cropping = (dim1_cropping, dim2_cropping, dim3_cropping)\n    else:\n        raise ValueError('`cropping` should be either an int, '\n                         'a tuple of 3 ints '\n                         '(symmetric_dim1_crop, symmetric_dim2_crop, symmetric_dim3_crop), '\n                         'or a tuple of 3 tuples of 2 ints '\n                         '((left_dim1_crop, right_dim1_crop),'\n                         ' (left_dim2_crop, right_dim2_crop),'\n                         ' (left_dim3_crop, right_dim2_crop)). '\n                         'Found: ' + str(cropping))\n    super(Cropping3D, self).__init__(normalized_cropping,\n                                     data_format,\n                                     **kwargs)"
            ],
            "inscope_function_signatures": [
                "__init__(self, rank, filters, kernel_size, strides=1, padding='valid', data_format=None, dilation_rate=1, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)",
                "build(self, input_shape)",
                "call(self, inputs)",
                "compute_output_shape(self, input_shape)",
                "get_config(self)",
                "__init__(self, filters, kernel_size, strides=1, padding='valid', data_format='channels_last', dilation_rate=1, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)",
                "get_config(self)",
                "__init__(self, filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)",
                "get_config(self)",
                "__init__(self, filters, kernel_size, strides=(1, 1, 1), padding='valid', data_format=None, dilation_rate=(1, 1, 1), activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)",
                "get_config(self)",
                "__init__(self, filters, kernel_size, strides=(1, 1), padding='valid', output_padding=None, data_format=None, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)",
                "build(self, input_shape)",
                "call(self, inputs)",
                "compute_output_shape(self, input_shape)",
                "get_config(self)",
                "__init__(self, filters, kernel_size, strides=(1, 1, 1), padding='valid', output_padding=None, data_format=None, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)",
                "build(self, input_shape)",
                "call(self, inputs)",
                "compute_output_shape(self, input_shape)",
                "get_config(self)",
                "__init__(self, rank, filters, kernel_size, strides=1, padding='valid', data_format=None, dilation_rate=1, depth_multiplier=1, activation=None, use_bias=True, depthwise_initializer='glorot_uniform', pointwise_initializer='glorot_uniform', bias_initializer='zeros', depthwise_regularizer=None, pointwise_regularizer=None, bias_regularizer=None, activity_regularizer=None, depthwise_constraint=None, pointwise_constraint=None, bias_constraint=None, **kwargs)",
                "build(self, input_shape)",
                "call(self, inputs)",
                "get_config(self)",
                "__init__(self, filters, kernel_size, strides=1, padding='valid', data_format=None, dilation_rate=1, depth_multiplier=1, activation=None, use_bias=True, depthwise_initializer='glorot_uniform', pointwise_initializer='glorot_uniform', bias_initializer='zeros', depthwise_regularizer=None, pointwise_regularizer=None, bias_regularizer=None, activity_regularizer=None, depthwise_constraint=None, pointwise_constraint=None, bias_constraint=None, **kwargs)",
                "__init__(self, filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), depth_multiplier=1, activation=None, use_bias=True, depthwise_initializer='glorot_uniform', pointwise_initializer='glorot_uniform', bias_initializer='zeros', depthwise_regularizer=None, pointwise_regularizer=None, bias_regularizer=None, activity_regularizer=None, depthwise_constraint=None, pointwise_constraint=None, bias_constraint=None, **kwargs)",
                "__init__(self, kernel_size, strides=(1, 1), padding='valid', depth_multiplier=1, data_format=None, activation=None, use_bias=True, depthwise_initializer='glorot_uniform', bias_initializer='zeros', depthwise_regularizer=None, bias_regularizer=None, activity_regularizer=None, depthwise_constraint=None, bias_constraint=None, **kwargs)",
                "build(self, input_shape)",
                "call(self, inputs, training=None)",
                "compute_output_shape(self, input_shape)",
                "get_config(self)",
                "__init__(self, size=2, **kwargs)",
                "compute_output_shape(self, input_shape)",
                "call(self, inputs)",
                "get_config(self)",
                "__init__(self, size=(2, 2), data_format=None, interpolation='nearest', **kwargs)",
                "compute_output_shape(self, input_shape)",
                "call(self, inputs)",
                "get_config(self)",
                "__init__(self, size=(2, 2, 2), data_format=None, **kwargs)",
                "compute_output_shape(self, input_shape)",
                "call(self, inputs)",
                "get_config(self)",
                "__init__(self, padding, data_format=None, **kwargs)",
                "call(self, inputs)",
                "compute_output_shape(self, input_shape)",
                "get_config(self)",
                "__init__(self, padding=1, **kwargs)",
                "call(self, inputs)",
                "get_config(self)",
                "__init__(self, padding=(1, 1), data_format=None, **kwargs)",
                "call(self, inputs)",
                "__init__(self, padding=(1, 1, 1), data_format=None, **kwargs)",
                "call(self, inputs)",
                "__init__(self, cropping, data_format=None, **kwargs)",
                "call(self, inputs)",
                "compute_output_shape(self, input_shape)",
                "get_config(self)",
                "__init__(self, cropping=(1, 1), **kwargs)",
                "get_config(self)",
                "__init__(self, cropping=((0, 0), (0, 0)), data_format=None, **kwargs)",
                "__init__(self, cropping=((1, 1), (1, 1), (1, 1)), data_format=None, **kwargs)"
            ],
            "variables_in_file": {
                "Layer": [
                    2053,
                    1868,
                    2284,
                    1903,
                    1979,
                    31
                ],
                "__init__": [
                    2304,
                    1282,
                    1943,
                    2200,
                    2455,
                    2075,
                    2366,
                    2120,
                    338,
                    597,
                    469,
                    1885,
                    1501,
                    1759,
                    2528,
                    2274,
                    2019,
                    744,
                    105,
                    1642,
                    1007
                ],
                "super": [
                    2304,
                    2049,
                    1282,
                    1155,
                    1943,
                    2200,
                    2455,
                    2075,
                    2341,
                    2095,
                    1975,
                    2366,
                    1856,
                    2371,
                    2120,
                    2128,
                    338,
                    469,
                    597,
                    1885,
                    1501,
                    1759,
                    1375,
                    2528,
                    2274,
                    2019,
                    358,
                    744,
                    105,
                    234,
                    489,
                    617,
                    1642,
                    1899,
                    879,
                    1007
                ],
                "_Conv": [
                    105,
                    234,
                    363,
                    1161,
                    238,
                    494
                ],
                "self": [
                    2048,
                    2049,
                    2071,
                    2072,
                    2073,
                    2074,
                    2075,
                    2081,
                    2082,
                    2084,
                    2093,
                    2094,
                    2095,
                    2120,
                    2125,
                    2128,
                    105,
                    106,
                    107,
                    108,
                    109,
                    110,
                    111,
                    112,
                    113,
                    114,
                    115,
                    116,
                    117,
                    118,
                    119,
                    120,
                    121,
                    122,
                    125,
                    133,
                    135,
                    136,
                    138,
                    139,
                    140,
                    141,
                    142,
                    144,
                    145,
                    147,
                    149,
                    151,
                    2200,
                    154,
                    157,
                    158,
                    159,
                    160,
                    161,
                    162,
                    2206,
                    2207,
                    165,
                    166,
                    167,
                    168,
                    169,
                    170,
                    173,
                    174,
                    175,
                    176,
                    177,
                    179,
                    182,
                    183,
                    185,
                    186,
                    190,
                    196,
                    197,
                    198,
                    199,
                    201,
                    202,
                    208,
                    209,
                    210,
                    211,
                    213,
                    217,
                    218,
                    219,
                    220,
                    221,
                    222,
                    223,
                    224,
                    225,
                    226,
                    227,
                    228,
                    229,
                    230,
                    231,
                    232,
                    2274,
                    234,
                    2280,
                    2281,
                    2304,
                    2306,
                    2307,
                    2308,
                    2309,
                    2313,
                    2322,
                    2323,
                    2327,
                    2328,
                    2330,
                    2339,
                    2340,
                    2341,
                    2366,
                    2371,
                    338,
                    358,
                    2455,
                    2503,
                    469,
                    2528,
                    489,
                    597,
                    617,
                    744,
                    761,
                    762,
                    763,
                    764,
                    765,
                    767,
                    769,
                    776,
                    784,
                    786,
                    787,
                    789,
                    790,
                    791,
                    792,
                    793,
                    795,
                    796,
                    798,
                    800,
                    801,
                    806,
                    812,
                    813,
                    814,
                    817,
                    822,
                    826,
                    828,
                    829,
                    831,
                    835,
                    837,
                    838,
                    839,
                    841,
                    844,
                    845,
                    847,
                    848,
                    853,
                    858,
                    859,
                    860,
                    863,
                    865,
                    869,
                    874,
                    879,
                    881,
                    1007,
                    1024,
                    1025,
                    1026,
                    1027,
                    1028,
                    1030,
                    1032,
                    1039,
                    1047,
                    1049,
                    1050,
                    1052,
                    1053,
                    1054,
                    1055,
                    1056,
                    1058,
                    1059,
                    1061,
                    1063,
                    1064,
                    1069,
                    1078,
                    1079,
                    1080,
                    1083,
                    1088,
                    1092,
                    1096,
                    1099,
                    1100,
                    1102,
                    1105,
                    1107,
                    1108,
                    1109,
                    1111,
                    1114,
                    1115,
                    1117,
                    1118,
                    1123,
                    1128,
                    1129,
                    1130,
                    1133,
                    1135,
                    1139,
                    1144,
                    1149,
                    1155,
                    1157,
                    1282,
                    1297,
                    1298,
                    1299,
                    1300,
                    1301,
                    1302,
                    1303,
                    1306,
                    1307,
                    1308,
                    1310,
                    1315,
                    1316,
                    1318,
                    1320,
                    1322,
                    1323,
                    1324,
                    1326,
                    1328,
                    1329,
                    1331,
                    1332,
                    1333,
                    1335,
                    1336,
                    1338,
                    1340,
                    1342,
                    1345,
                    1348,
                    1349,
                    1350,
                    1351,
                    1352,
                    1353,
                    1354,
                    1357,
                    1358,
                    1359,
                    1360,
                    1361,
                    1362,
                    1364,
                    1367,
                    1368,
                    1370,
                    1371,
                    1375,
                    1380,
                    1381,
                    1382,
                    1383,
                    1384,
                    1385,
                    1386,
                    1501,
                    1642,
                    1759,
                    1771,
                    1772,
                    1773,
                    1774,
                    1775,
                    1781,
                    1790,
                    1791,
                    1793,
                    1795,
                    1797,
                    1799,
                    1800,
                    1802,
                    1803,
                    1804,
                    1806,
                    1807,
                    1809,
                    1811,
                    1812,
                    1817,
                    1818,
                    1819,
                    1820,
                    1821,
                    1823,
                    1826,
                    1827,
                    1829,
                    1830,
                    1835,
                    1838,
                    1839,
                    1842,
                    1844,
                    1845,
                    1846,
                    1847,
                    1848,
                    1849,
                    1850,
                    1852,
                    1856,
                    1861,
                    1862,
                    1863,
                    1864,
                    1885,
                    1886,
                    1887,
                    1890,
                    1894,
                    1898,
                    1899,
                    1943,
                    1944,
                    1945,
                    1946,
                    1950,
                    1953,
                    1954,
                    1955,
                    1960,
                    1961,
                    1962,
                    1969,
                    1970,
                    1973,
                    1974,
                    1975,
                    2016,
                    2017,
                    2018,
                    2019,
                    2022,
                    2023,
                    2024,
                    2025,
                    2031,
                    2032,
                    2033,
                    2034,
                    2043,
                    2044,
                    2047
                ],
                "kwargs": [
                    2304,
                    1296,
                    1943,
                    2457,
                    2202,
                    2075,
                    2368,
                    2122,
                    1885,
                    2530,
                    355,
                    2019,
                    2276,
                    614,
                    486,
                    105,
                    1770,
                    1522,
                    759,
                    1022,
                    1663
                ],
                "self.rank": [
                    2306,
                    2309,
                    2322,
                    149,
                    2071,
                    2328,
                    2074,
                    154,
                    1306,
                    1307,
                    1308,
                    162,
                    2082,
                    1316,
                    170,
                    1340,
                    1345,
                    1354,
                    217,
                    106,
                    122
                ],
                "rank": [
                    1283,
                    106,
                    108,
                    109,
                    112
                ],
                "self.filters": [
                    865,
                    1316,
                    133,
                    201,
                    107,
                    1100,
                    141,
                    1102,
                    1135,
                    784,
                    1332,
                    213,
                    1047,
                    792,
                    218,
                    1055,
                    829,
                    831
                ],
                "filters": [
                    471,
                    1284,
                    745,
                    107,
                    1644,
                    1008,
                    340,
                    599,
                    1503
                ],
                "self.kernel_size": [
                    1315,
                    196,
                    133,
                    1128,
                    108,
                    812,
                    1847,
                    208,
                    784,
                    1844,
                    1078,
                    1047,
                    858,
                    219,
                    1790,
                    1791
                ],
                "conv_utils.normalize_tuple": [
                    1026,
                    2441,
                    2188,
                    2444,
                    2190,
                    1945,
                    2365,
                    2119,
                    2512,
                    2258,
                    2514,
                    2260,
                    2516,
                    2262,
                    2017,
                    108,
                    109,
                    112,
                    763
                ],
                "conv_utils": [
                    1026,
                    2441,
                    2188,
                    2444,
                    2190,
                    1945,
                    820,
                    1844,
                    1847,
                    824,
                    2365,
                    1086,
                    194,
                    1090,
                    1094,
                    2119,
                    206,
                    2512,
                    2258,
                    2514,
                    2260,
                    2516,
                    2262,
                    2017,
                    866,
                    871,
                    108,
                    109,
                    110,
                    112,
                    1136,
                    1141,
                    1146,
                    763
                ],
                "kernel_size": [
                    1504,
                    1761,
                    1285,
                    746,
                    600,
                    108,
                    1645,
                    1009,
                    341,
                    472
                ],
                "self.strides": [
                    1028,
                    1030,
                    1818,
                    158,
                    166,
                    813,
                    174,
                    1846,
                    1079,
                    1849,
                    837,
                    198,
                    1351,
                    1360,
                    210,
                    1107,
                    859,
                    220,
                    1129,
                    109,
                    765,
                    767
                ],
                "strides": [
                    1505,
                    1762,
                    1286,
                    747,
                    473,
                    109,
                    1646,
                    1010,
                    342,
                    601
                ],
                "self.padding": [
                    2072,
                    1819,
                    2206,
                    159,
                    2081,
                    167,
                    2093,
                    175,
                    1845,
                    822,
                    1848,
                    826,
                    1088,
                    1092,
                    197,
                    838,
                    1096,
                    1352,
                    2125,
                    209,
                    1361,
                    1108,
                    221,
                    869,
                    2280,
                    874,
                    110,
                    1139,
                    1144,
                    1149
                ],
                "conv_utils.normalize_padding": [
                    110
                ],
                "padding": [
                    2182,
                    1287,
                    2183,
                    2184,
                    2185,
                    2187,
                    2188,
                    2190,
                    2071,
                    2072,
                    2199,
                    2119,
                    2252,
                    333,
                    2253,
                    2254,
                    2255,
                    2257,
                    2258,
                    2260,
                    2262,
                    343,
                    602,
                    474,
                    2273,
                    1506,
                    1763,
                    748,
                    110,
                    1647,
                    1011
                ],
                "self.data_format": [
                    2048,
                    2308,
                    776,
                    1039,
                    2323,
                    1944,
                    2073,
                    2330,
                    1821,
                    1310,
                    2207,
                    160,
                    1953,
                    1827,
                    2084,
                    2340,
                    806,
                    168,
                    1960,
                    1835,
                    1069,
                    2094,
                    1839,
                    176,
                    1970,
                    1974,
                    183,
                    1850,
                    828,
                    1852,
                    190,
                    1350,
                    839,
                    2503,
                    202,
                    1099,
                    845,
                    1359,
                    853,
                    1109,
                    1368,
                    1115,
                    222,
                    2016,
                    1123,
                    2022,
                    2281,
                    111,
                    2031,
                    1781,
                    2044,
                    125
                ],
                "K.normalize_data_format": [
                    2016,
                    2308,
                    2503,
                    111,
                    1944,
                    2073
                ],
                "K": [
                    2308,
                    1815,
                    1944,
                    2073,
                    155,
                    2205,
                    1824,
                    163,
                    804,
                    171,
                    1067,
                    1969,
                    180,
                    833,
                    1346,
                    2503,
                    842,
                    1355,
                    2125,
                    1104,
                    1365,
                    1112,
                    2016,
                    1894,
                    2279,
                    111,
                    2042
                ],
                "data_format": [
                    2308,
                    1288,
                    2456,
                    2201,
                    1944,
                    2073,
                    2503,
                    334,
                    344,
                    475,
                    603,
                    2016,
                    2529,
                    1507,
                    1764,
                    2275,
                    749,
                    111,
                    1648,
                    1012
                ],
                "self.dilation_rate": [
                    161,
                    199,
                    169,
                    1353,
                    112,
                    177,
                    1362,
                    211,
                    1820,
                    223
                ],
                "dilation_rate": [
                    1508,
                    1289,
                    112,
                    1649,
                    345,
                    476,
                    604
                ],
                "self.activation": [
                    224,
                    1829,
                    1830,
                    1370,
                    847,
                    848,
                    113,
                    185,
                    186,
                    1371,
                    1117,
                    1118
                ],
                "activations.get": [
                    113
                ],
                "activations": [
                    224,
                    113
                ],
                "activation": [
                    477,
                    1765,
                    1510,
                    1290,
                    750,
                    113,
                    1651,
                    1013,
                    346,
                    605
                ],
                "self.use_bias": [
                    225,
                    841,
                    1802,
                    140,
                    114,
                    179,
                    1331,
                    1364,
                    1111,
                    791,
                    1054,
                    1823
                ],
                "use_bias": [
                    478,
                    1766,
                    1511,
                    1291,
                    751,
                    114,
                    1652,
                    1014,
                    347,
                    606
                ],
                "self.kernel_initializer": [
                    226,
                    136,
                    787,
                    115,
                    1050
                ],
                "initializers.get": [
                    1772,
                    1775,
                    1298,
                    1299,
                    115,
                    116
                ],
                "initializers": [
                    226,
                    227,
                    1381,
                    1382,
                    1862,
                    1772,
                    1775,
                    1298,
                    115,
                    116,
                    1299
                ],
                "kernel_initializer": [
                    479,
                    752,
                    115,
                    1015,
                    348,
                    607
                ],
                "self.bias_initializer": [
                    1056,
                    227,
                    1804,
                    142,
                    1775,
                    116,
                    1333,
                    793
                ],
                "bias_initializer": [
                    480,
                    608,
                    1514,
                    1292,
                    1775,
                    753,
                    116,
                    1655,
                    1016,
                    349
                ],
                "self.kernel_regularizer": [
                    228,
                    138,
                    789,
                    117,
                    1052
                ],
                "regularizers.get": [
                    1773,
                    1300,
                    1301,
                    117,
                    118,
                    119
                ],
                "regularizers": [
                    228,
                    229,
                    230,
                    1383,
                    1384,
                    1863,
                    1773,
                    1300,
                    117,
                    118,
                    119,
                    1301
                ],
                "kernel_regularizer": [
                    481,
                    609,
                    754,
                    117,
                    1017,
                    350
                ],
                "self.bias_regularizer": [
                    1058,
                    229,
                    1806,
                    144,
                    118,
                    1335,
                    795
                ],
                "bias_regularizer": [
                    482,
                    610,
                    1767,
                    1293,
                    1517,
                    755,
                    118,
                    1658,
                    1018,
                    351
                ],
                "self.activity_regularizer": [
                    230,
                    119
                ],
                "activity_regularizer": [
                    352,
                    611,
                    483,
                    1768,
                    1659,
                    1294,
                    1518,
                    756,
                    119,
                    1019
                ],
                "self.kernel_constraint": [
                    231,
                    139,
                    790,
                    120,
                    1053
                ],
                "constraints.get": [
                    1774,
                    1302,
                    1303,
                    120,
                    121
                ],
                "constraints": [
                    231,
                    232,
                    1385,
                    1386,
                    1864,
                    1774,
                    1302,
                    1303,
                    120,
                    121
                ],
                "kernel_constraint": [
                    353,
                    484,
                    612,
                    757,
                    120,
                    1020
                ],
                "self.bias_constraint": [
                    1059,
                    232,
                    1807,
                    145,
                    1336,
                    121,
                    796
                ],
                "bias_constraint": [
                    354,
                    613,
                    485,
                    1769,
                    1295,
                    1521,
                    758,
                    121,
                    1021,
                    1662
                ],
                "self.input_spec": [
                    800,
                    2018,
                    2074,
                    2309,
                    1063,
                    1811,
                    149,
                    122,
                    1340,
                    1946,
                    1887
                ],
                "InputSpec": [
                    800,
                    2018,
                    2074,
                    2309,
                    1063,
                    1811,
                    149,
                    122,
                    1340,
                    1946,
                    1887
                ],
                "channel_axis": [
                    128,
                    129,
                    132,
                    777,
                    779,
                    780,
                    783,
                    1040,
                    1042,
                    1043,
                    1811,
                    150,
                    1046,
                    1310,
                    1311,
                    800,
                    1314,
                    1063,
                    1341,
                    1782,
                    1784,
                    1785,
                    1789,
                    126
                ],
                "input_shape": [
                    2086,
                    129,
                    132,
                    772,
                    775,
                    1035,
                    780,
                    1038,
                    783,
                    1043,
                    1963,
                    1046,
                    1306,
                    2332,
                    1309,
                    1311,
                    1314,
                    1954,
                    804,
                    805,
                    1955,
                    1956,
                    1957,
                    1961,
                    1962,
                    811,
                    1067,
                    1068,
                    1836,
                    1837,
                    1838,
                    1840,
                    1074,
                    1075,
                    1076,
                    1841,
                    1842,
                    1966,
                    1851,
                    1853,
                    191,
                    201,
                    203,
                    852,
                    213,
                    1122,
                    1890,
                    1891,
                    2023,
                    2024,
                    2025,
                    2026,
                    2027,
                    2032,
                    2033,
                    1778,
                    2034,
                    1780,
                    2035,
                    2039,
                    1785,
                    1789
                ],
                "ValueError": [
                    130,
                    773,
                    1030,
                    2439,
                    2186,
                    1036,
                    781,
                    2449,
                    2194,
                    1044,
                    1307,
                    1948,
                    1312,
                    2510,
                    335,
                    2256,
                    2520,
                    2266,
                    1779,
                    1786,
                    767
                ],
                "input_dim": [
                    800,
                    1792,
                    1314,
                    1315,
                    132,
                    133,
                    1316,
                    1063,
                    1789,
                    1803,
                    783,
                    784,
                    1811,
                    1047,
                    150,
                    1046,
                    1341
                ],
                "kernel_shape": [
                    133,
                    135,
                    784,
                    786,
                    1047,
                    1049
                ],
                "self.kernel": [
                    835,
                    165,
                    135,
                    173,
                    1105,
                    786,
                    1049,
                    157
                ],
                "self.add_weight": [
                    1795,
                    1318,
                    135,
                    1803,
                    1324,
                    141,
                    786,
                    1332,
                    792,
                    1049,
                    1055
                ],
                "self.bias": [
                    1826,
                    1061,
                    1803,
                    844,
                    141,
                    1338,
                    1809,
                    147,
                    1332,
                    182,
                    1367,
                    792,
                    1114,
                    798,
                    1055
                ],
                "self.built": [
                    801,
                    1064,
                    1812,
                    151,
                    1342
                ],
                "outputs": [
                    1815,
                    155,
                    1824,
                    1825,
                    163,
                    1830,
                    1832,
                    171,
                    180,
                    181,
                    186,
                    187,
                    833,
                    1346,
                    842,
                    843,
                    1355,
                    848,
                    849,
                    1104,
                    1365,
                    1366,
                    1112,
                    1113,
                    1371,
                    1372,
                    1118,
                    1119
                ],
                "K.conv1d": [
                    155
                ],
                "inputs": [
                    834,
                    1347,
                    164,
                    804,
                    1894,
                    2279,
                    1067,
                    172,
                    1356,
                    2125,
                    1104,
                    1969,
                    2324,
                    1816,
                    2042,
                    156,
                    2205
                ],
                "K.conv2d": [
                    163
                ],
                "K.conv3d": [
                    171
                ],
                "K.bias_add": [
                    1824,
                    842,
                    180,
                    1365,
                    1112
                ],
                "space": [
                    193,
                    195,
                    203,
                    205,
                    207,
                    191
                ],
                "new_space": [
                    192,
                    200,
                    201,
                    204,
                    212,
                    213
                ],
                "i": [
                    193,
                    195,
                    196,
                    198,
                    199,
                    205,
                    207,
                    208,
                    210,
                    211
                ],
                "range": [
                    193,
                    2082,
                    2087,
                    205,
                    2322,
                    2328,
                    2333
                ],
                "len": [
                    193,
                    2306,
                    772,
                    2438,
                    2087,
                    2185,
                    1035,
                    205,
                    2509,
                    2255,
                    1778,
                    2071,
                    1306,
                    2333
                ],
                "new_dim": [
                    200,
                    194,
                    212,
                    206
                ],
                "conv_utils.conv_output_length": [
                    194,
                    1844,
                    206,
                    1847
                ],
                "new_space.append": [
                    200,
                    212
                ],
                "tuple": [
                    1152,
                    2336,
                    201,
                    2090,
                    876,
                    2321,
                    213
                ],
                "config": [
                    2050,
                    1155,
                    1156,
                    1157,
                    1158,
                    2339,
                    2342,
                    1382,
                    2093,
                    1383,
                    2096,
                    1384,
                    1973,
                    1976,
                    1385,
                    1386,
                    1856,
                    1857,
                    1858,
                    1859,
                    1860,
                    1861,
                    1862,
                    1863,
                    1864,
                    1865,
                    1898,
                    2128,
                    2129,
                    2130,
                    2131,
                    216,
                    1375,
                    1376,
                    1377,
                    1378,
                    1379,
                    1380,
                    1381,
                    358,
                    359,
                    360,
                    489,
                    490,
                    235,
                    491,
                    617,
                    618,
                    619,
                    879,
                    880,
                    881,
                    882,
                    1387,
                    1900,
                    2047
                ],
                "activations.serialize": [
                    224
                ],
                "initializers.serialize": [
                    226,
                    227,
                    1381,
                    1862,
                    1382
                ],
                "regularizers.serialize": [
                    228,
                    229,
                    230,
                    1383,
                    1384,
                    1863
                ],
                "constraints.serialize": [
                    231,
                    232,
                    1385,
                    1386,
                    1864
                ],
                "base_config": [
                    2049,
                    2050,
                    2371,
                    2372,
                    2341,
                    2342,
                    2373,
                    2374,
                    234,
                    1899,
                    235,
                    1900,
                    2095,
                    2096,
                    1975,
                    1976
                ],
                "get_config": [
                    1856,
                    2049,
                    1155,
                    2371,
                    2341,
                    358,
                    489,
                    234,
                    617,
                    1899,
                    879,
                    2095,
                    2128,
                    1975,
                    1375
                ],
                "dict": [
                    2050,
                    2342,
                    235,
                    1900,
                    2096,
                    1976
                ],
                "list": [
                    2328,
                    1122,
                    2050,
                    2082,
                    2086,
                    2342,
                    235,
                    1900,
                    2096,
                    2322,
                    852,
                    1976,
                    2332
                ],
                "base_config.items": [
                    2050,
                    2342,
                    235,
                    1900,
                    2096,
                    1976
                ],
                "config.items": [
                    2050,
                    2342,
                    235,
                    1900,
                    2096,
                    1976
                ],
                "Conv1D": [
                    338,
                    358,
                    2535
                ],
                "interfaces.legacy_conv1d_support": [
                    316
                ],
                "interfaces": [
                    2432,
                    2177,
                    452,
                    580,
                    2500,
                    2250,
                    1621,
                    1941,
                    727,
                    1883,
                    316,
                    2014
                ],
                "config.pop": [
                    1376,
                    1377,
                    1378,
                    1379,
                    1156,
                    1857,
                    1858,
                    359,
                    1859,
                    1860,
                    490,
                    618,
                    880,
                    2130
                ],
                "Conv2D": [
                    1666,
                    2536,
                    489,
                    622,
                    469
                ],
                "interfaces.legacy_conv2d_support": [
                    452
                ],
                "Conv3D": [
                    617,
                    885,
                    2537,
                    597
                ],
                "interfaces.legacy_conv3d_support": [
                    580
                ],
                "Conv2DTranspose": [
                    744,
                    2540,
                    2541,
                    879
                ],
                "self.output_padding": [
                    1024,
                    769,
                    1025,
                    1026,
                    1027,
                    1028,
                    1157,
                    1032,
                    814,
                    817,
                    1080,
                    1083,
                    860,
                    863,
                    1130,
                    1133,
                    881,
                    761,
                    762,
                    763,
                    764,
                    765
                ],
                "output_padding": [
                    1024,
                    761
                ],
                "stride": [
                    1029,
                    1028,
                    765,
                    766
                ],
                "out_pad": [
                    1029,
                    1028,
                    765,
                    766
                ],
                "zip": [
                    1028,
                    765
                ],
                "str": [
                    769,
                    1030,
                    775,
                    774,
                    1032,
                    2440,
                    2187,
                    1037,
                    1038,
                    2454,
                    2199,
                    1307,
                    1308,
                    1309,
                    2511,
                    2257,
                    2527,
                    2273,
                    1780,
                    767
                ],
                "interfaces.legacy_deconv2d_support": [
                    727
                ],
                "K.shape": [
                    1067,
                    804
                ],
                "batch_size": [
                    805,
                    1100,
                    1068,
                    1102,
                    829,
                    831
                ],
                "h_axis": [
                    866,
                    1124,
                    1126,
                    807,
                    809,
                    811,
                    1070,
                    1072,
                    1075,
                    1141,
                    854,
                    856
                ],
                "w_axis": [
                    1124,
                    1126,
                    807,
                    871,
                    809,
                    811,
                    1070,
                    1072,
                    1076,
                    854,
                    856,
                    1146
                ],
                "height": [
                    1954,
                    1090,
                    1958,
                    1961,
                    811,
                    1964,
                    1075,
                    820
                ],
                "width": [
                    1955,
                    1094,
                    1959,
                    1962,
                    811,
                    1965,
                    1076,
                    824
                ],
                "kernel_h": [
                    1091,
                    868,
                    1128,
                    812,
                    821,
                    1078,
                    1143,
                    858
                ],
                "kernel_w": [
                    1095,
                    1128,
                    873,
                    812,
                    1078,
                    825,
                    858,
                    1148
                ],
                "stride_h": [
                    867,
                    1091,
                    1129,
                    813,
                    821,
                    1142,
                    1079,
                    859
                ],
                "stride_w": [
                    1095,
                    872,
                    1129,
                    1147,
                    813,
                    1079,
                    825,
                    859
                ],
                "out_pad_h": [
                    1145,
                    1093,
                    870,
                    1131,
                    1133,
                    815,
                    817,
                    823,
                    1081,
                    1083,
                    861,
                    863
                ],
                "out_pad_w": [
                    1083,
                    1097,
                    875,
                    1131,
                    1133,
                    815,
                    817,
                    1081,
                    827,
                    861,
                    1150,
                    863
                ],
                "out_height": [
                    1090,
                    1100,
                    1102,
                    820,
                    829,
                    831
                ],
                "conv_utils.deconv_length": [
                    866,
                    1090,
                    1094,
                    871,
                    1136,
                    820,
                    1141,
                    824,
                    1146,
                    1086
                ],
                "out_width": [
                    1094,
                    1100,
                    1102,
                    824,
                    829,
                    831
                ],
                "output_shape": [
                    1152,
                    2332,
                    2333,
                    2334,
                    2335,
                    2336,
                    2086,
                    2087,
                    2088,
                    2089,
                    2090,
                    829,
                    831,
                    836,
                    1100,
                    1102,
                    1106,
                    852,
                    865,
                    866,
                    1122,
                    871,
                    876,
                    1135,
                    1136,
                    1141,
                    1146
                ],
                "K.conv2d_transpose": [
                    833
                ],
                "c_axis": [
                    865,
                    1124,
                    1126,
                    1135,
                    854,
                    856
                ],
                "Conv3DTranspose": [
                    1155,
                    2542,
                    1007
                ],
                "d_axis": [
                    1124,
                    1126,
                    1070,
                    1072,
                    1136,
                    1074
                ],
                "depth": [
                    1074,
                    1086
                ],
                "kernel_d": [
                    1128,
                    1138,
                    1078,
                    1087
                ],
                "stride_d": [
                    1129,
                    1137,
                    1087,
                    1079
                ],
                "out_pad_d": [
                    1089,
                    1131,
                    1133,
                    1140,
                    1081,
                    1083
                ],
                "out_depth": [
                    1102,
                    1100,
                    1086
                ],
                "K.conv3d_transpose": [
                    1104
                ],
                "_SeparableConv": [
                    1282,
                    1525,
                    1390,
                    1375
                ],
                "self.depth_multiplier": [
                    1793,
                    1315,
                    1380,
                    1316,
                    1861,
                    1771,
                    1803,
                    1838,
                    1297,
                    1842
                ],
                "depth_multiplier": [
                    1297,
                    1650,
                    1771,
                    1509
                ],
                "self.depthwise_initializer": [
                    1797,
                    1381,
                    1862,
                    1320,
                    1772,
                    1298
                ],
                "depthwise_initializer": [
                    1512,
                    1298,
                    1772,
                    1653
                ],
                "self.pointwise_initializer": [
                    1382,
                    1299,
                    1326
                ],
                "pointwise_initializer": [
                    1513,
                    1299,
                    1654
                ],
                "self.depthwise_regularizer": [
                    1799,
                    1383,
                    1863,
                    1322,
                    1773,
                    1300
                ],
                "depthwise_regularizer": [
                    1656,
                    1515,
                    1300,
                    1773
                ],
                "self.pointwise_regularizer": [
                    1328,
                    1384,
                    1301
                ],
                "pointwise_regularizer": [
                    1657,
                    1516,
                    1301
                ],
                "self.depthwise_constraint": [
                    1800,
                    1385,
                    1864,
                    1323,
                    1774,
                    1302
                ],
                "depthwise_constraint": [
                    1774,
                    1660,
                    1302,
                    1519
                ],
                "self.pointwise_constraint": [
                    1329,
                    1386,
                    1303
                ],
                "pointwise_constraint": [
                    1520,
                    1661,
                    1303
                ],
                "int": [
                    1314,
                    2435,
                    2182,
                    2504,
                    2252,
                    1789,
                    1886
                ],
                "depthwise_kernel_shape": [
                    1315,
                    1796,
                    1790,
                    1319
                ],
                "pointwise_kernel_shape": [
                    1316,
                    1325
                ],
                "self.depthwise_kernel": [
                    1795,
                    1348,
                    1318,
                    1357,
                    1817
                ],
                "self.pointwise_kernel": [
                    1324,
                    1349,
                    1358
                ],
                "K.separable_conv1d": [
                    1346
                ],
                "K.separable_conv2d": [
                    1355
                ],
                "SeparableConv1D": [
                    2538,
                    1501
                ],
                "SeparableConv2D": [
                    1642,
                    2539
                ],
                "interfaces.legacy_separable_conv2d_support": [
                    1621
                ],
                "DepthwiseConv2D": [
                    1856,
                    1759
                ],
                "K.depthwise_conv2d": [
                    1815
                ],
                "rows": [
                    1836,
                    1840,
                    1844,
                    1851,
                    1853
                ],
                "cols": [
                    1837,
                    1841,
                    1847,
                    1851,
                    1853
                ],
                "out_filters": [
                    1842,
                    1851,
                    1853,
                    1838
                ],
                "UpSampling1D": [
                    1899,
                    1885
                ],
                "self.size": [
                    1945,
                    1954,
                    1955,
                    1961,
                    1962,
                    1969,
                    1973,
                    1886,
                    2017,
                    1890,
                    1894,
                    2023,
                    2024,
                    2025,
                    1898,
                    2032,
                    2033,
                    2034,
                    2043,
                    2047
                ],
                "size": [
                    2017,
                    1890,
                    1891,
                    1945,
                    1886
                ],
                "interfaces.legacy_upsampling1d_support": [
                    1883
                ],
                "output": [
                    1894,
                    1895
                ],
                "K.repeat_elements": [
                    1894
                ],
                "UpSampling2D": [
                    1975,
                    1943
                ],
                "interpolation": [
                    1947,
                    1950
                ],
                "self.interpolation": [
                    1970,
                    1950
                ],
                "interfaces.legacy_upsampling2d_support": [
                    1941
                ],
                "K.resize_images": [
                    1969
                ],
                "UpSampling3D": [
                    2049,
                    2019
                ],
                "interfaces.legacy_upsampling3d_support": [
                    2014
                ],
                "dim1": [
                    2032,
                    2028,
                    2036,
                    2023
                ],
                "dim2": [
                    2024,
                    2033,
                    2029,
                    2037
                ],
                "dim3": [
                    2038,
                    2025,
                    2034,
                    2030
                ],
                "K.resize_volumes": [
                    2042
                ],
                "_ZeroPadding": [
                    2210,
                    2095,
                    2099,
                    2134,
                    2075
                ],
                "NotImplementedError": [
                    2078
                ],
                "padding_all_dims": [
                    2081,
                    2083,
                    2089
                ],
                "spatial_axes": [
                    2082,
                    2085,
                    2322,
                    2323,
                    2328,
                    2331
                ],
                "transpose_shape": [
                    2323,
                    2329,
                    2083
                ],
                "dim": [
                    2087,
                    2088,
                    2089,
                    2333,
                    2334,
                    2335
                ],
                "sum": [
                    2089,
                    2335
                ],
                "normalized_padding": [
                    2274,
                    2183,
                    2120,
                    2119,
                    2253,
                    2192,
                    2200,
                    2264
                ],
                "ZeroPadding1D": [
                    2120,
                    2128
                ],
                "K.temporal_padding": [
                    2125
                ],
                "isinstance": [
                    2504,
                    2435,
                    2252,
                    2182
                ],
                "hasattr": [
                    2184,
                    2508,
                    2437,
                    2254
                ],
                "height_padding": [
                    2192,
                    2188
                ],
                "width_padding": [
                    2192,
                    2190
                ],
                "ZeroPadding2D": [
                    2200
                ],
                "interfaces.legacy_zeropadding2d_support": [
                    2177
                ],
                "K.spatial_2d_padding": [
                    2205
                ],
                "dim1_padding": [
                    2264,
                    2258
                ],
                "dim2_padding": [
                    2264,
                    2260
                ],
                "dim3_padding": [
                    2264,
                    2262
                ],
                "ZeroPadding3D": [
                    2274
                ],
                "interfaces.legacy_zeropadding3d_support": [
                    2250
                ],
                "K.spatial_3d_padding": [
                    2279
                ],
                "_Cropping": [
                    2304,
                    2341,
                    2345,
                    2377,
                    2460
                ],
                "cropping": [
                    2306,
                    2307,
                    2436,
                    2435,
                    2437,
                    2438,
                    2440,
                    2442,
                    2445,
                    2454,
                    2365,
                    2504,
                    2505,
                    2506,
                    2507,
                    2508,
                    2509,
                    2511,
                    2512,
                    2514,
                    2516,
                    2527
                ],
                "self.cropping": [
                    2339,
                    2313,
                    2307,
                    2327
                ],
                "slices_dims": [
                    2312,
                    2320,
                    2318
                ],
                "start": [
                    2313,
                    2318
                ],
                "end": [
                    2313,
                    2314,
                    2315,
                    2317,
                    2318
                ],
                "slices_dims.append": [
                    2318
                ],
                "slice": [
                    2320,
                    2318
                ],
                "slices": [
                    2320,
                    2321,
                    2323,
                    2324
                ],
                "cropping_all_dims": [
                    2329,
                    2335,
                    2327
                ],
                "normalized_cropping": [
                    2528,
                    2436,
                    2505,
                    2447,
                    2518,
                    2455,
                    2365,
                    2366
                ],
                "Cropping1D": [
                    2371,
                    2366
                ],
                "base_config.pop": [
                    2372
                ],
                "height_cropping": [
                    2441,
                    2447
                ],
                "width_cropping": [
                    2444,
                    2447
                ],
                "Cropping2D": [
                    2455
                ],
                "interfaces.legacy_cropping2d_support": [
                    2432
                ],
                "dim1_cropping": [
                    2512,
                    2518
                ],
                "dim2_cropping": [
                    2514,
                    2518
                ],
                "dim3_cropping": [
                    2516,
                    2518
                ],
                "Cropping3D": [
                    2528
                ],
                "interfaces.legacy_cropping3d_support": [
                    2500
                ],
                "Convolution1D": [
                    2535
                ],
                "Convolution2D": [
                    2536
                ],
                "Convolution3D": [
                    2537
                ],
                "SeparableConvolution1D": [
                    2538
                ],
                "SeparableConvolution2D": [
                    2539
                ],
                "Convolution2DTranspose": [
                    2540
                ],
                "Deconvolution2D": [
                    2541
                ],
                "Deconv2D": [
                    2541
                ],
                "Deconvolution3D": [
                    2542
                ],
                "Deconv3D": [
                    2542
                ],
                "AtrousConv1D": [
                    2545
                ],
                "AtrousConvolution1D": [
                    2545
                ],
                "AtrousConv2D": [
                    2546
                ],
                "AtrousConvolution2D": [
                    2546
                ]
            },
            "filtered_variables_in_file": {
                "Layer": [
                    2053,
                    1868,
                    2284,
                    1903,
                    1979,
                    31
                ],
                "__init__": [
                    2304,
                    1282,
                    1943,
                    2200,
                    2455,
                    2075,
                    2366,
                    2120,
                    338,
                    597,
                    469,
                    1885,
                    1501,
                    1759,
                    2528,
                    2274,
                    2019,
                    744,
                    105,
                    1642,
                    1007
                ],
                "_Conv": [
                    105,
                    234,
                    363,
                    1161,
                    238,
                    494
                ],
                "self": [
                    2048,
                    2049,
                    2071,
                    2072,
                    2073,
                    2074,
                    2075,
                    2081,
                    2082,
                    2084,
                    2093,
                    2094,
                    2095,
                    2120,
                    2125,
                    2128,
                    105,
                    106,
                    107,
                    108,
                    109,
                    110,
                    111,
                    112,
                    113,
                    114,
                    115,
                    116,
                    117,
                    118,
                    119,
                    120,
                    121,
                    122,
                    125,
                    133,
                    135,
                    136,
                    138,
                    139,
                    140,
                    141,
                    142,
                    144,
                    145,
                    147,
                    149,
                    151,
                    2200,
                    154,
                    157,
                    158,
                    159,
                    160,
                    161,
                    162,
                    2206,
                    2207,
                    165,
                    166,
                    167,
                    168,
                    169,
                    170,
                    173,
                    174,
                    175,
                    176,
                    177,
                    179,
                    182,
                    183,
                    185,
                    186,
                    190,
                    196,
                    197,
                    198,
                    199,
                    201,
                    202,
                    208,
                    209,
                    210,
                    211,
                    213,
                    217,
                    218,
                    219,
                    220,
                    221,
                    222,
                    223,
                    224,
                    225,
                    226,
                    227,
                    228,
                    229,
                    230,
                    231,
                    232,
                    2274,
                    234,
                    2280,
                    2281,
                    2304,
                    2306,
                    2307,
                    2308,
                    2309,
                    2313,
                    2322,
                    2323,
                    2327,
                    2328,
                    2330,
                    2339,
                    2340,
                    2341,
                    2366,
                    2371,
                    338,
                    358,
                    2455,
                    2503,
                    469,
                    2528,
                    489,
                    597,
                    617,
                    744,
                    761,
                    762,
                    763,
                    764,
                    765,
                    767,
                    769,
                    776,
                    784,
                    786,
                    787,
                    789,
                    790,
                    791,
                    792,
                    793,
                    795,
                    796,
                    798,
                    800,
                    801,
                    806,
                    812,
                    813,
                    814,
                    817,
                    822,
                    826,
                    828,
                    829,
                    831,
                    835,
                    837,
                    838,
                    839,
                    841,
                    844,
                    845,
                    847,
                    848,
                    853,
                    858,
                    859,
                    860,
                    863,
                    865,
                    869,
                    874,
                    879,
                    881,
                    1007,
                    1024,
                    1025,
                    1026,
                    1027,
                    1028,
                    1030,
                    1032,
                    1039,
                    1047,
                    1049,
                    1050,
                    1052,
                    1053,
                    1054,
                    1055,
                    1056,
                    1058,
                    1059,
                    1061,
                    1063,
                    1064,
                    1069,
                    1078,
                    1079,
                    1080,
                    1083,
                    1088,
                    1092,
                    1096,
                    1099,
                    1100,
                    1102,
                    1105,
                    1107,
                    1108,
                    1109,
                    1111,
                    1114,
                    1115,
                    1117,
                    1118,
                    1123,
                    1128,
                    1129,
                    1130,
                    1133,
                    1135,
                    1139,
                    1144,
                    1149,
                    1155,
                    1157,
                    1282,
                    1297,
                    1298,
                    1299,
                    1300,
                    1301,
                    1302,
                    1303,
                    1306,
                    1307,
                    1308,
                    1310,
                    1315,
                    1316,
                    1318,
                    1320,
                    1322,
                    1323,
                    1324,
                    1326,
                    1328,
                    1329,
                    1331,
                    1332,
                    1333,
                    1335,
                    1336,
                    1338,
                    1340,
                    1342,
                    1345,
                    1348,
                    1349,
                    1350,
                    1351,
                    1352,
                    1353,
                    1354,
                    1357,
                    1358,
                    1359,
                    1360,
                    1361,
                    1362,
                    1364,
                    1367,
                    1368,
                    1370,
                    1371,
                    1375,
                    1380,
                    1381,
                    1382,
                    1383,
                    1384,
                    1385,
                    1386,
                    1501,
                    1642,
                    1759,
                    1771,
                    1772,
                    1773,
                    1774,
                    1775,
                    1781,
                    1790,
                    1791,
                    1793,
                    1795,
                    1797,
                    1799,
                    1800,
                    1802,
                    1803,
                    1804,
                    1806,
                    1807,
                    1809,
                    1811,
                    1812,
                    1817,
                    1818,
                    1819,
                    1820,
                    1821,
                    1823,
                    1826,
                    1827,
                    1829,
                    1830,
                    1835,
                    1838,
                    1839,
                    1842,
                    1844,
                    1845,
                    1846,
                    1847,
                    1848,
                    1849,
                    1850,
                    1852,
                    1856,
                    1861,
                    1862,
                    1863,
                    1864,
                    1885,
                    1886,
                    1887,
                    1890,
                    1894,
                    1898,
                    1899,
                    1943,
                    1944,
                    1945,
                    1946,
                    1950,
                    1953,
                    1954,
                    1955,
                    1960,
                    1961,
                    1962,
                    1969,
                    1970,
                    1973,
                    1974,
                    1975,
                    2016,
                    2017,
                    2018,
                    2019,
                    2022,
                    2023,
                    2024,
                    2025,
                    2031,
                    2032,
                    2033,
                    2034,
                    2043,
                    2044,
                    2047
                ],
                "kwargs": [
                    2304,
                    1296,
                    1943,
                    2457,
                    2202,
                    2075,
                    2368,
                    2122,
                    1885,
                    2530,
                    355,
                    2019,
                    2276,
                    614,
                    486,
                    105,
                    1770,
                    1522,
                    759,
                    1022,
                    1663
                ],
                "self.rank": [
                    2306,
                    2309,
                    2322,
                    149,
                    2071,
                    2328,
                    2074,
                    154,
                    1306,
                    1307,
                    1308,
                    162,
                    2082,
                    1316,
                    170,
                    1340,
                    1345,
                    1354,
                    217,
                    106,
                    122
                ],
                "rank": [
                    1283,
                    106,
                    108,
                    109,
                    112
                ],
                "self.filters": [
                    865,
                    1316,
                    133,
                    201,
                    107,
                    1100,
                    141,
                    1102,
                    1135,
                    784,
                    1332,
                    213,
                    1047,
                    792,
                    218,
                    1055,
                    829,
                    831
                ],
                "filters": [
                    471,
                    1284,
                    745,
                    107,
                    1644,
                    1008,
                    340,
                    599,
                    1503
                ],
                "self.kernel_size": [
                    1315,
                    196,
                    133,
                    1128,
                    108,
                    812,
                    1847,
                    208,
                    784,
                    1844,
                    1078,
                    1047,
                    858,
                    219,
                    1790,
                    1791
                ],
                "conv_utils.normalize_tuple": [
                    1026,
                    2441,
                    2188,
                    2444,
                    2190,
                    1945,
                    2365,
                    2119,
                    2512,
                    2258,
                    2514,
                    2260,
                    2516,
                    2262,
                    2017,
                    108,
                    109,
                    112,
                    763
                ],
                "conv_utils": [
                    1026,
                    2441,
                    2188,
                    2444,
                    2190,
                    1945,
                    820,
                    1844,
                    1847,
                    824,
                    2365,
                    1086,
                    194,
                    1090,
                    1094,
                    2119,
                    206,
                    2512,
                    2258,
                    2514,
                    2260,
                    2516,
                    2262,
                    2017,
                    866,
                    871,
                    108,
                    109,
                    110,
                    112,
                    1136,
                    1141,
                    1146,
                    763
                ],
                "kernel_size": [
                    1504,
                    1761,
                    1285,
                    746,
                    600,
                    108,
                    1645,
                    1009,
                    341,
                    472
                ],
                "self.strides": [
                    1028,
                    1030,
                    1818,
                    158,
                    166,
                    813,
                    174,
                    1846,
                    1079,
                    1849,
                    837,
                    198,
                    1351,
                    1360,
                    210,
                    1107,
                    859,
                    220,
                    1129,
                    109,
                    765,
                    767
                ],
                "strides": [
                    1505,
                    1762,
                    1286,
                    747,
                    473,
                    109,
                    1646,
                    1010,
                    342,
                    601
                ],
                "self.padding": [
                    2072,
                    1819,
                    2206,
                    159,
                    2081,
                    167,
                    2093,
                    175,
                    1845,
                    822,
                    1848,
                    826,
                    1088,
                    1092,
                    197,
                    838,
                    1096,
                    1352,
                    2125,
                    209,
                    1361,
                    1108,
                    221,
                    869,
                    2280,
                    874,
                    110,
                    1139,
                    1144,
                    1149
                ],
                "conv_utils.normalize_padding": [
                    110
                ],
                "padding": [
                    2182,
                    1287,
                    2183,
                    2184,
                    2185,
                    2187,
                    2188,
                    2190,
                    2071,
                    2072,
                    2199,
                    2119,
                    2252,
                    333,
                    2253,
                    2254,
                    2255,
                    2257,
                    2258,
                    2260,
                    2262,
                    343,
                    602,
                    474,
                    2273,
                    1506,
                    1763,
                    748,
                    110,
                    1647,
                    1011
                ],
                "self.data_format": [
                    2048,
                    2308,
                    776,
                    1039,
                    2323,
                    1944,
                    2073,
                    2330,
                    1821,
                    1310,
                    2207,
                    160,
                    1953,
                    1827,
                    2084,
                    2340,
                    806,
                    168,
                    1960,
                    1835,
                    1069,
                    2094,
                    1839,
                    176,
                    1970,
                    1974,
                    183,
                    1850,
                    828,
                    1852,
                    190,
                    1350,
                    839,
                    2503,
                    202,
                    1099,
                    845,
                    1359,
                    853,
                    1109,
                    1368,
                    1115,
                    222,
                    2016,
                    1123,
                    2022,
                    2281,
                    111,
                    2031,
                    1781,
                    2044,
                    125
                ],
                "K.normalize_data_format": [
                    2016,
                    2308,
                    2503,
                    111,
                    1944,
                    2073
                ],
                "K": [
                    2308,
                    1815,
                    1944,
                    2073,
                    155,
                    2205,
                    1824,
                    163,
                    804,
                    171,
                    1067,
                    1969,
                    180,
                    833,
                    1346,
                    2503,
                    842,
                    1355,
                    2125,
                    1104,
                    1365,
                    1112,
                    2016,
                    1894,
                    2279,
                    111,
                    2042
                ],
                "data_format": [
                    2308,
                    1288,
                    2456,
                    2201,
                    1944,
                    2073,
                    2503,
                    334,
                    344,
                    475,
                    603,
                    2016,
                    2529,
                    1507,
                    1764,
                    2275,
                    749,
                    111,
                    1648,
                    1012
                ],
                "self.dilation_rate": [
                    161,
                    199,
                    169,
                    1353,
                    112,
                    177,
                    1362,
                    211,
                    1820,
                    223
                ],
                "dilation_rate": [
                    1508,
                    1289,
                    112,
                    1649,
                    345,
                    476,
                    604
                ],
                "self.activation": [
                    224,
                    1829,
                    1830,
                    1370,
                    847,
                    848,
                    113,
                    185,
                    186,
                    1371,
                    1117,
                    1118
                ],
                "activations.get": [
                    113
                ],
                "activations": [
                    224,
                    113
                ],
                "activation": [
                    477,
                    1765,
                    1510,
                    1290,
                    750,
                    113,
                    1651,
                    1013,
                    346,
                    605
                ],
                "self.use_bias": [
                    225,
                    841,
                    1802,
                    140,
                    114,
                    179,
                    1331,
                    1364,
                    1111,
                    791,
                    1054,
                    1823
                ],
                "use_bias": [
                    478,
                    1766,
                    1511,
                    1291,
                    751,
                    114,
                    1652,
                    1014,
                    347,
                    606
                ],
                "self.kernel_initializer": [
                    226,
                    136,
                    787,
                    115,
                    1050
                ],
                "initializers.get": [
                    1772,
                    1775,
                    1298,
                    1299,
                    115,
                    116
                ],
                "initializers": [
                    226,
                    227,
                    1381,
                    1382,
                    1862,
                    1772,
                    1775,
                    1298,
                    115,
                    116,
                    1299
                ],
                "kernel_initializer": [
                    479,
                    752,
                    115,
                    1015,
                    348,
                    607
                ],
                "self.bias_initializer": [
                    1056,
                    227,
                    1804,
                    142,
                    1775,
                    116,
                    1333,
                    793
                ],
                "bias_initializer": [
                    480,
                    608,
                    1514,
                    1292,
                    1775,
                    753,
                    116,
                    1655,
                    1016,
                    349
                ],
                "self.kernel_regularizer": [
                    228,
                    138,
                    789,
                    117,
                    1052
                ],
                "regularizers.get": [
                    1773,
                    1300,
                    1301,
                    117,
                    118,
                    119
                ],
                "regularizers": [
                    228,
                    229,
                    230,
                    1383,
                    1384,
                    1863,
                    1773,
                    1300,
                    117,
                    118,
                    119,
                    1301
                ],
                "kernel_regularizer": [
                    481,
                    609,
                    754,
                    117,
                    1017,
                    350
                ],
                "self.bias_regularizer": [
                    1058,
                    229,
                    1806,
                    144,
                    118,
                    1335,
                    795
                ],
                "bias_regularizer": [
                    482,
                    610,
                    1767,
                    1293,
                    1517,
                    755,
                    118,
                    1658,
                    1018,
                    351
                ],
                "self.activity_regularizer": [
                    230,
                    119
                ],
                "activity_regularizer": [
                    352,
                    611,
                    483,
                    1768,
                    1659,
                    1294,
                    1518,
                    756,
                    119,
                    1019
                ],
                "self.kernel_constraint": [
                    231,
                    139,
                    790,
                    120,
                    1053
                ],
                "constraints.get": [
                    1774,
                    1302,
                    1303,
                    120,
                    121
                ],
                "constraints": [
                    231,
                    232,
                    1385,
                    1386,
                    1864,
                    1774,
                    1302,
                    1303,
                    120,
                    121
                ],
                "kernel_constraint": [
                    353,
                    484,
                    612,
                    757,
                    120,
                    1020
                ],
                "self.bias_constraint": [
                    1059,
                    232,
                    1807,
                    145,
                    1336,
                    121,
                    796
                ],
                "bias_constraint": [
                    354,
                    613,
                    485,
                    1769,
                    1295,
                    1521,
                    758,
                    121,
                    1021,
                    1662
                ],
                "self.input_spec": [
                    800,
                    2018,
                    2074,
                    2309,
                    1063,
                    1811,
                    149,
                    122,
                    1340,
                    1946,
                    1887
                ],
                "InputSpec": [
                    800,
                    2018,
                    2074,
                    2309,
                    1063,
                    1811,
                    149,
                    122,
                    1340,
                    1946,
                    1887
                ],
                "channel_axis": [
                    128,
                    129,
                    132,
                    777,
                    779,
                    780,
                    783,
                    1040,
                    1042,
                    1043,
                    1811,
                    150,
                    1046,
                    1310,
                    1311,
                    800,
                    1314,
                    1063,
                    1341,
                    1782,
                    1784,
                    1785,
                    1789,
                    126
                ],
                "input_shape": [
                    2086,
                    129,
                    132,
                    772,
                    775,
                    1035,
                    780,
                    1038,
                    783,
                    1043,
                    1963,
                    1046,
                    1306,
                    2332,
                    1309,
                    1311,
                    1314,
                    1954,
                    804,
                    805,
                    1955,
                    1956,
                    1957,
                    1961,
                    1962,
                    811,
                    1067,
                    1068,
                    1836,
                    1837,
                    1838,
                    1840,
                    1074,
                    1075,
                    1076,
                    1841,
                    1842,
                    1966,
                    1851,
                    1853,
                    191,
                    201,
                    203,
                    852,
                    213,
                    1122,
                    1890,
                    1891,
                    2023,
                    2024,
                    2025,
                    2026,
                    2027,
                    2032,
                    2033,
                    1778,
                    2034,
                    1780,
                    2035,
                    2039,
                    1785,
                    1789
                ],
                "input_dim": [
                    800,
                    1792,
                    1314,
                    1315,
                    132,
                    133,
                    1316,
                    1063,
                    1789,
                    1803,
                    783,
                    784,
                    1811,
                    1047,
                    150,
                    1046,
                    1341
                ],
                "kernel_shape": [
                    133,
                    135,
                    784,
                    786,
                    1047,
                    1049
                ],
                "self.kernel": [
                    835,
                    165,
                    135,
                    173,
                    1105,
                    786,
                    1049,
                    157
                ],
                "self.add_weight": [
                    1795,
                    1318,
                    135,
                    1803,
                    1324,
                    141,
                    786,
                    1332,
                    792,
                    1049,
                    1055
                ],
                "self.bias": [
                    1826,
                    1061,
                    1803,
                    844,
                    141,
                    1338,
                    1809,
                    147,
                    1332,
                    182,
                    1367,
                    792,
                    1114,
                    798,
                    1055
                ],
                "self.built": [
                    801,
                    1064,
                    1812,
                    151,
                    1342
                ],
                "outputs": [
                    1815,
                    155,
                    1824,
                    1825,
                    163,
                    1830,
                    1832,
                    171,
                    180,
                    181,
                    186,
                    187,
                    833,
                    1346,
                    842,
                    843,
                    1355,
                    848,
                    849,
                    1104,
                    1365,
                    1366,
                    1112,
                    1113,
                    1371,
                    1372,
                    1118,
                    1119
                ],
                "K.conv1d": [
                    155
                ],
                "inputs": [
                    834,
                    1347,
                    164,
                    804,
                    1894,
                    2279,
                    1067,
                    172,
                    1356,
                    2125,
                    1104,
                    1969,
                    2324,
                    1816,
                    2042,
                    156,
                    2205
                ],
                "K.conv2d": [
                    163
                ],
                "K.conv3d": [
                    171
                ],
                "K.bias_add": [
                    1824,
                    842,
                    180,
                    1365,
                    1112
                ],
                "space": [
                    193,
                    195,
                    203,
                    205,
                    207,
                    191
                ],
                "new_space": [
                    192,
                    200,
                    201,
                    204,
                    212,
                    213
                ],
                "i": [
                    193,
                    195,
                    196,
                    198,
                    199,
                    205,
                    207,
                    208,
                    210,
                    211
                ],
                "new_dim": [
                    200,
                    194,
                    212,
                    206
                ],
                "conv_utils.conv_output_length": [
                    194,
                    1844,
                    206,
                    1847
                ],
                "new_space.append": [
                    200,
                    212
                ],
                "config": [
                    2050,
                    1155,
                    1156,
                    1157,
                    1158,
                    2339,
                    2342,
                    1382,
                    2093,
                    1383,
                    2096,
                    1384,
                    1973,
                    1976,
                    1385,
                    1386,
                    1856,
                    1857,
                    1858,
                    1859,
                    1860,
                    1861,
                    1862,
                    1863,
                    1864,
                    1865,
                    1898,
                    2128,
                    2129,
                    2130,
                    2131,
                    216,
                    1375,
                    1376,
                    1377,
                    1378,
                    1379,
                    1380,
                    1381,
                    358,
                    359,
                    360,
                    489,
                    490,
                    235,
                    491,
                    617,
                    618,
                    619,
                    879,
                    880,
                    881,
                    882,
                    1387,
                    1900,
                    2047
                ],
                "activations.serialize": [
                    224
                ],
                "initializers.serialize": [
                    226,
                    227,
                    1381,
                    1862,
                    1382
                ],
                "regularizers.serialize": [
                    228,
                    229,
                    230,
                    1383,
                    1384,
                    1863
                ],
                "constraints.serialize": [
                    231,
                    232,
                    1385,
                    1386,
                    1864
                ],
                "base_config": [
                    2049,
                    2050,
                    2371,
                    2372,
                    2341,
                    2342,
                    2373,
                    2374,
                    234,
                    1899,
                    235,
                    1900,
                    2095,
                    2096,
                    1975,
                    1976
                ],
                "get_config": [
                    1856,
                    2049,
                    1155,
                    2371,
                    2341,
                    358,
                    489,
                    234,
                    617,
                    1899,
                    879,
                    2095,
                    2128,
                    1975,
                    1375
                ],
                "base_config.items": [
                    2050,
                    2342,
                    235,
                    1900,
                    2096,
                    1976
                ],
                "config.items": [
                    2050,
                    2342,
                    235,
                    1900,
                    2096,
                    1976
                ],
                "Conv1D": [
                    338,
                    358,
                    2535
                ],
                "interfaces.legacy_conv1d_support": [
                    316
                ],
                "interfaces": [
                    2432,
                    2177,
                    452,
                    580,
                    2500,
                    2250,
                    1621,
                    1941,
                    727,
                    1883,
                    316,
                    2014
                ],
                "config.pop": [
                    1376,
                    1377,
                    1378,
                    1379,
                    1156,
                    1857,
                    1858,
                    359,
                    1859,
                    1860,
                    490,
                    618,
                    880,
                    2130
                ],
                "Conv2D": [
                    1666,
                    2536,
                    489,
                    622,
                    469
                ],
                "interfaces.legacy_conv2d_support": [
                    452
                ],
                "Conv3D": [
                    617,
                    885,
                    2537,
                    597
                ],
                "interfaces.legacy_conv3d_support": [
                    580
                ],
                "Conv2DTranspose": [
                    744,
                    2540,
                    2541,
                    879
                ],
                "self.output_padding": [
                    1024,
                    769,
                    1025,
                    1026,
                    1027,
                    1028,
                    1157,
                    1032,
                    814,
                    817,
                    1080,
                    1083,
                    860,
                    863,
                    1130,
                    1133,
                    881,
                    761,
                    762,
                    763,
                    764,
                    765
                ],
                "output_padding": [
                    1024,
                    761
                ],
                "stride": [
                    1029,
                    1028,
                    765,
                    766
                ],
                "out_pad": [
                    1029,
                    1028,
                    765,
                    766
                ],
                "interfaces.legacy_deconv2d_support": [
                    727
                ],
                "K.shape": [
                    1067,
                    804
                ],
                "batch_size": [
                    805,
                    1100,
                    1068,
                    1102,
                    829,
                    831
                ],
                "h_axis": [
                    866,
                    1124,
                    1126,
                    807,
                    809,
                    811,
                    1070,
                    1072,
                    1075,
                    1141,
                    854,
                    856
                ],
                "w_axis": [
                    1124,
                    1126,
                    807,
                    871,
                    809,
                    811,
                    1070,
                    1072,
                    1076,
                    854,
                    856,
                    1146
                ],
                "height": [
                    1954,
                    1090,
                    1958,
                    1961,
                    811,
                    1964,
                    1075,
                    820
                ],
                "width": [
                    1955,
                    1094,
                    1959,
                    1962,
                    811,
                    1965,
                    1076,
                    824
                ],
                "kernel_h": [
                    1091,
                    868,
                    1128,
                    812,
                    821,
                    1078,
                    1143,
                    858
                ],
                "kernel_w": [
                    1095,
                    1128,
                    873,
                    812,
                    1078,
                    825,
                    858,
                    1148
                ],
                "stride_h": [
                    867,
                    1091,
                    1129,
                    813,
                    821,
                    1142,
                    1079,
                    859
                ],
                "stride_w": [
                    1095,
                    872,
                    1129,
                    1147,
                    813,
                    1079,
                    825,
                    859
                ],
                "out_pad_h": [
                    1145,
                    1093,
                    870,
                    1131,
                    1133,
                    815,
                    817,
                    823,
                    1081,
                    1083,
                    861,
                    863
                ],
                "out_pad_w": [
                    1083,
                    1097,
                    875,
                    1131,
                    1133,
                    815,
                    817,
                    1081,
                    827,
                    861,
                    1150,
                    863
                ],
                "out_height": [
                    1090,
                    1100,
                    1102,
                    820,
                    829,
                    831
                ],
                "conv_utils.deconv_length": [
                    866,
                    1090,
                    1094,
                    871,
                    1136,
                    820,
                    1141,
                    824,
                    1146,
                    1086
                ],
                "out_width": [
                    1094,
                    1100,
                    1102,
                    824,
                    829,
                    831
                ],
                "output_shape": [
                    1152,
                    2332,
                    2333,
                    2334,
                    2335,
                    2336,
                    2086,
                    2087,
                    2088,
                    2089,
                    2090,
                    829,
                    831,
                    836,
                    1100,
                    1102,
                    1106,
                    852,
                    865,
                    866,
                    1122,
                    871,
                    876,
                    1135,
                    1136,
                    1141,
                    1146
                ],
                "K.conv2d_transpose": [
                    833
                ],
                "c_axis": [
                    865,
                    1124,
                    1126,
                    1135,
                    854,
                    856
                ],
                "Conv3DTranspose": [
                    1155,
                    2542,
                    1007
                ],
                "d_axis": [
                    1124,
                    1126,
                    1070,
                    1072,
                    1136,
                    1074
                ],
                "depth": [
                    1074,
                    1086
                ],
                "kernel_d": [
                    1128,
                    1138,
                    1078,
                    1087
                ],
                "stride_d": [
                    1129,
                    1137,
                    1087,
                    1079
                ],
                "out_pad_d": [
                    1089,
                    1131,
                    1133,
                    1140,
                    1081,
                    1083
                ],
                "out_depth": [
                    1102,
                    1100,
                    1086
                ],
                "K.conv3d_transpose": [
                    1104
                ],
                "_SeparableConv": [
                    1282,
                    1525,
                    1390,
                    1375
                ],
                "self.depth_multiplier": [
                    1793,
                    1315,
                    1380,
                    1316,
                    1861,
                    1771,
                    1803,
                    1838,
                    1297,
                    1842
                ],
                "depth_multiplier": [
                    1297,
                    1650,
                    1771,
                    1509
                ],
                "self.depthwise_initializer": [
                    1797,
                    1381,
                    1862,
                    1320,
                    1772,
                    1298
                ],
                "depthwise_initializer": [
                    1512,
                    1298,
                    1772,
                    1653
                ],
                "self.pointwise_initializer": [
                    1382,
                    1299,
                    1326
                ],
                "pointwise_initializer": [
                    1513,
                    1299,
                    1654
                ],
                "self.depthwise_regularizer": [
                    1799,
                    1383,
                    1863,
                    1322,
                    1773,
                    1300
                ],
                "depthwise_regularizer": [
                    1656,
                    1515,
                    1300,
                    1773
                ],
                "self.pointwise_regularizer": [
                    1328,
                    1384,
                    1301
                ],
                "pointwise_regularizer": [
                    1657,
                    1516,
                    1301
                ],
                "self.depthwise_constraint": [
                    1800,
                    1385,
                    1864,
                    1323,
                    1774,
                    1302
                ],
                "depthwise_constraint": [
                    1774,
                    1660,
                    1302,
                    1519
                ],
                "self.pointwise_constraint": [
                    1329,
                    1386,
                    1303
                ],
                "pointwise_constraint": [
                    1520,
                    1661,
                    1303
                ],
                "depthwise_kernel_shape": [
                    1315,
                    1796,
                    1790,
                    1319
                ],
                "pointwise_kernel_shape": [
                    1316,
                    1325
                ],
                "self.depthwise_kernel": [
                    1795,
                    1348,
                    1318,
                    1357,
                    1817
                ],
                "self.pointwise_kernel": [
                    1324,
                    1349,
                    1358
                ],
                "K.separable_conv1d": [
                    1346
                ],
                "K.separable_conv2d": [
                    1355
                ],
                "SeparableConv1D": [
                    2538,
                    1501
                ],
                "SeparableConv2D": [
                    1642,
                    2539
                ],
                "interfaces.legacy_separable_conv2d_support": [
                    1621
                ],
                "DepthwiseConv2D": [
                    1856,
                    1759
                ],
                "K.depthwise_conv2d": [
                    1815
                ],
                "rows": [
                    1836,
                    1840,
                    1844,
                    1851,
                    1853
                ],
                "cols": [
                    1837,
                    1841,
                    1847,
                    1851,
                    1853
                ],
                "out_filters": [
                    1842,
                    1851,
                    1853,
                    1838
                ],
                "UpSampling1D": [
                    1899,
                    1885
                ],
                "self.size": [
                    1945,
                    1954,
                    1955,
                    1961,
                    1962,
                    1969,
                    1973,
                    1886,
                    2017,
                    1890,
                    1894,
                    2023,
                    2024,
                    2025,
                    1898,
                    2032,
                    2033,
                    2034,
                    2043,
                    2047
                ],
                "size": [
                    2017,
                    1890,
                    1891,
                    1945,
                    1886
                ],
                "interfaces.legacy_upsampling1d_support": [
                    1883
                ],
                "output": [
                    1894,
                    1895
                ],
                "K.repeat_elements": [
                    1894
                ],
                "UpSampling2D": [
                    1975,
                    1943
                ],
                "interpolation": [
                    1947,
                    1950
                ],
                "self.interpolation": [
                    1970,
                    1950
                ],
                "interfaces.legacy_upsampling2d_support": [
                    1941
                ],
                "K.resize_images": [
                    1969
                ],
                "UpSampling3D": [
                    2049,
                    2019
                ],
                "interfaces.legacy_upsampling3d_support": [
                    2014
                ],
                "dim1": [
                    2032,
                    2028,
                    2036,
                    2023
                ],
                "dim2": [
                    2024,
                    2033,
                    2029,
                    2037
                ],
                "dim3": [
                    2038,
                    2025,
                    2034,
                    2030
                ],
                "K.resize_volumes": [
                    2042
                ],
                "_ZeroPadding": [
                    2210,
                    2095,
                    2099,
                    2134,
                    2075
                ],
                "padding_all_dims": [
                    2081,
                    2083,
                    2089
                ],
                "spatial_axes": [
                    2082,
                    2085,
                    2322,
                    2323,
                    2328,
                    2331
                ],
                "transpose_shape": [
                    2323,
                    2329,
                    2083
                ],
                "dim": [
                    2087,
                    2088,
                    2089,
                    2333,
                    2334,
                    2335
                ],
                "normalized_padding": [
                    2274,
                    2183,
                    2120,
                    2119,
                    2253,
                    2192,
                    2200,
                    2264
                ],
                "ZeroPadding1D": [
                    2120,
                    2128
                ],
                "K.temporal_padding": [
                    2125
                ],
                "height_padding": [
                    2192,
                    2188
                ],
                "width_padding": [
                    2192,
                    2190
                ],
                "ZeroPadding2D": [
                    2200
                ],
                "interfaces.legacy_zeropadding2d_support": [
                    2177
                ],
                "K.spatial_2d_padding": [
                    2205
                ],
                "dim1_padding": [
                    2264,
                    2258
                ],
                "dim2_padding": [
                    2264,
                    2260
                ],
                "dim3_padding": [
                    2264,
                    2262
                ],
                "ZeroPadding3D": [
                    2274
                ],
                "interfaces.legacy_zeropadding3d_support": [
                    2250
                ],
                "K.spatial_3d_padding": [
                    2279
                ],
                "_Cropping": [
                    2304,
                    2341,
                    2345,
                    2377,
                    2460
                ],
                "cropping": [
                    2306,
                    2307,
                    2436,
                    2435,
                    2437,
                    2438,
                    2440,
                    2442,
                    2445,
                    2454,
                    2365,
                    2504,
                    2505,
                    2506,
                    2507,
                    2508,
                    2509,
                    2511,
                    2512,
                    2514,
                    2516,
                    2527
                ],
                "self.cropping": [
                    2339,
                    2313,
                    2307,
                    2327
                ],
                "slices_dims": [
                    2312,
                    2320,
                    2318
                ],
                "start": [
                    2313,
                    2318
                ],
                "end": [
                    2313,
                    2314,
                    2315,
                    2317,
                    2318
                ],
                "slices_dims.append": [
                    2318
                ],
                "slices": [
                    2320,
                    2321,
                    2323,
                    2324
                ],
                "cropping_all_dims": [
                    2329,
                    2335,
                    2327
                ],
                "normalized_cropping": [
                    2528,
                    2436,
                    2505,
                    2447,
                    2518,
                    2455,
                    2365,
                    2366
                ],
                "Cropping1D": [
                    2371,
                    2366
                ],
                "base_config.pop": [
                    2372
                ],
                "height_cropping": [
                    2441,
                    2447
                ],
                "width_cropping": [
                    2444,
                    2447
                ],
                "Cropping2D": [
                    2455
                ],
                "interfaces.legacy_cropping2d_support": [
                    2432
                ],
                "dim1_cropping": [
                    2512,
                    2518
                ],
                "dim2_cropping": [
                    2514,
                    2518
                ],
                "dim3_cropping": [
                    2516,
                    2518
                ],
                "Cropping3D": [
                    2528
                ],
                "interfaces.legacy_cropping3d_support": [
                    2500
                ],
                "Convolution1D": [
                    2535
                ],
                "Convolution2D": [
                    2536
                ],
                "Convolution3D": [
                    2537
                ],
                "SeparableConvolution1D": [
                    2538
                ],
                "SeparableConvolution2D": [
                    2539
                ],
                "Convolution2DTranspose": [
                    2540
                ],
                "Deconvolution2D": [
                    2541
                ],
                "Deconv2D": [
                    2541
                ],
                "Deconvolution3D": [
                    2542
                ],
                "Deconv3D": [
                    2542
                ],
                "AtrousConv1D": [
                    2545
                ],
                "AtrousConvolution1D": [
                    2545
                ],
                "AtrousConv2D": [
                    2546
                ],
                "AtrousConvolution2D": [
                    2546
                ]
            }
        },
        "/Volumes/SSD2T/bgp_envs_non_pandas/repos/keras_20/keras/utils/conv_utils.py": {
            "buggy_functions": [
                {
                    "function_name": "deconv_length",
                    "function_code": "def deconv_length(dim_size, stride_size, kernel_size, padding, output_padding):\n    \"\"\"Determines output length of a transposed convolution given input length.\n\n    # Arguments\n        dim_size: Integer, the input length.\n        stride_size: Integer, the stride along the dimension of `dim_size`.\n        kernel_size: Integer, the kernel size along the dimension of\n            `dim_size`.\n        padding: One of `\"same\"`, `\"valid\"`, `\"full\"`.\n        output_padding: Integer, amount of padding along the output dimension,\n            Can be set to `None` in which case the output length is inferred.\n\n    # Returns\n        The output length (integer).\n    \"\"\"\n    assert padding in {'same', 'valid', 'full'}\n    if dim_size is None:\n        return None\n\n    # Infer length if output padding is None, else compute the exact length\n    if output_padding is None:\n        if padding == 'valid':\n            dim_size = dim_size * stride_size + max(kernel_size - stride_size, 0)\n        elif padding == 'full':\n            dim_size = dim_size * stride_size - (stride_size + kernel_size - 2)\n        elif padding == 'same':\n            dim_size = dim_size * stride_size\n    else:\n        if padding == 'same':\n            pad = kernel_size // 2\n        elif padding == 'valid':\n            pad = 0\n        elif padding == 'full':\n            pad = kernel_size - 1\n\n        dim_size = ((dim_size - 1) * stride_size + kernel_size - 2 * pad +\n                    output_padding)\n\n    return dim_size\n",
                    "decorators": [],
                    "docstring": "Determines output length of a transposed convolution given input length.\n\n# Arguments\n    dim_size: Integer, the input length.\n    stride_size: Integer, the stride along the dimension of `dim_size`.\n    kernel_size: Integer, the kernel size along the dimension of\n        `dim_size`.\n    padding: One of `\"same\"`, `\"valid\"`, `\"full\"`.\n    output_padding: Integer, amount of padding along the output dimension,\n        Can be set to `None` in which case the output length is inferred.\n\n# Returns\n    The output length (integer).",
                    "start_line": 138,
                    "end_line": 176,
                    "variables": {
                        "padding": [
                            161,
                            163,
                            166,
                            168,
                            170,
                            153,
                            159
                        ],
                        "dim_size": [
                            160,
                            162,
                            164,
                            173,
                            176,
                            154
                        ],
                        "output_padding": [
                            174,
                            158
                        ],
                        "stride_size": [
                            160,
                            162,
                            164,
                            173
                        ],
                        "max": [
                            160
                        ],
                        "kernel_size": [
                            160,
                            162,
                            167,
                            171,
                            173
                        ],
                        "pad": [
                            169,
                            171,
                            173,
                            167
                        ]
                    },
                    "filtered_variables": {
                        "padding": [
                            161,
                            163,
                            166,
                            168,
                            170,
                            153,
                            159
                        ],
                        "dim_size": [
                            160,
                            162,
                            164,
                            173,
                            176,
                            154
                        ],
                        "output_padding": [
                            174,
                            158
                        ],
                        "stride_size": [
                            160,
                            162,
                            164,
                            173
                        ],
                        "kernel_size": [
                            160,
                            162,
                            167,
                            171,
                            173
                        ],
                        "pad": [
                            169,
                            171,
                            173,
                            167
                        ]
                    },
                    "diff_line_number": 138,
                    "class_data": null,
                    "variable_values": [
                        [
                            {
                                "padding": {
                                    "variable_value": "'same'",
                                    "variable_type": "str",
                                    "variable_shape": "4"
                                },
                                "dim_size": {
                                    "variable_value": "5",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "output_padding": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "stride_size": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "kernel_size": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "pad": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                }
                            },
                            {
                                "padding": {
                                    "variable_value": "'same'",
                                    "variable_type": "str",
                                    "variable_shape": "4"
                                },
                                "dim_size": {
                                    "variable_value": "5",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "output_padding": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "stride_size": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "kernel_size": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "pad": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                }
                            }
                        ],
                        [
                            {
                                "padding": {
                                    "variable_value": "'same'",
                                    "variable_type": "str",
                                    "variable_shape": "4"
                                },
                                "dim_size": {
                                    "variable_value": "6",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "output_padding": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "stride_size": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "kernel_size": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "pad": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                }
                            },
                            {
                                "padding": {
                                    "variable_value": "'same'",
                                    "variable_type": "str",
                                    "variable_shape": "4"
                                },
                                "dim_size": {
                                    "variable_value": "6",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "output_padding": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "stride_size": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "kernel_size": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "pad": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                }
                            }
                        ]
                    ],
                    "angelic_variable_values": [
                        [
                            {
                                "padding": {
                                    "variable_value": "'same'",
                                    "variable_type": "str",
                                    "variable_shape": "4"
                                },
                                "dim_size": {
                                    "variable_value": "5",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "kernel_size": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "dilation": {
                                    "variable_value": "2",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "output_padding": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "stride_size": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "pad": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                }
                            },
                            {
                                "padding": {
                                    "variable_value": "'same'",
                                    "variable_type": "str",
                                    "variable_shape": "4"
                                },
                                "dim_size": {
                                    "variable_value": "5",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "kernel_size": {
                                    "variable_value": "5",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "dilation": {
                                    "variable_value": "2",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "output_padding": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "stride_size": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "pad": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                }
                            }
                        ],
                        [
                            {
                                "padding": {
                                    "variable_value": "'same'",
                                    "variable_type": "str",
                                    "variable_shape": "4"
                                },
                                "dim_size": {
                                    "variable_value": "6",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "kernel_size": {
                                    "variable_value": "3",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "dilation": {
                                    "variable_value": "2",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "output_padding": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "stride_size": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "pad": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                }
                            },
                            {
                                "padding": {
                                    "variable_value": "'same'",
                                    "variable_type": "str",
                                    "variable_shape": "4"
                                },
                                "dim_size": {
                                    "variable_value": "6",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "kernel_size": {
                                    "variable_value": "5",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "dilation": {
                                    "variable_value": "2",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "output_padding": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "stride_size": {
                                    "variable_value": "1",
                                    "variable_type": "int",
                                    "variable_shape": null
                                },
                                "pad": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                }
                            }
                        ]
                    ]
                }
            ],
            "inscope_functions": [
                "def normalize_tuple(value, n, name):\n    \"\"\"Transforms a single int or iterable of ints into an int tuple.\n\n    # Arguments\n        value: The value to validate and convert. Could be an int, or any iterable\n          of ints.\n        n: The size of the tuple to be returned.\n        name: The name of the argument being validated, e.g. `strides` or\n          `kernel_size`. This is only used to format error messages.\n\n    # Returns\n        A tuple of n integers.\n\n    # Raises\n        ValueError: If something else than an int/long or iterable thereof was\n        passed.\n    \"\"\"\n    if isinstance(value, int):\n        return (value,) * n\n    else:\n        try:\n            value_tuple = tuple(value)\n        except TypeError:\n            raise ValueError('The `' + name + '` argument must be a tuple of ' +\n                             str(n) + ' integers. Received: ' + str(value))\n        if len(value_tuple) != n:\n            raise ValueError('The `' + name + '` argument must be a tuple of ' +\n                             str(n) + ' integers. Received: ' + str(value))\n        for single_value in value_tuple:\n            try:\n                int(single_value)\n            except ValueError:\n                raise ValueError('The `' + name + '` argument must be a tuple of ' +\n                                 str(n) + ' integers. Received: ' + str(value) + ' '\n                                 'including element ' + str(single_value) + ' of '\n                                 'type ' + str(type(single_value)))\n    return value_tuple",
                "def normalize_padding(value):\n    padding = value.lower()\n    allowed = {'valid', 'same', 'causal'}\n    if K.backend() == 'theano':\n        allowed.add('full')\n    if padding not in allowed:\n        raise ValueError('The `padding` argument must be one of \"valid\", \"same\" '\n                         '(or \"causal\" for Conv1D). Received: ' + str(padding))\n    return padding",
                "def convert_kernel(kernel):\n    \"\"\"Converts a Numpy kernel matrix from Theano format to TensorFlow format.\n\n    Also works reciprocally, since the transformation is its own inverse.\n\n    # Arguments\n        kernel: Numpy array (3D, 4D or 5D).\n\n    # Returns\n        The converted kernel.\n\n    # Raises\n        ValueError: in case of invalid kernel shape or invalid data_format.\n    \"\"\"\n    kernel = np.asarray(kernel)\n    if not 3 <= kernel.ndim <= 5:\n        raise ValueError('Invalid kernel shape:', kernel.shape)\n    slices = [slice(None, None, -1) for _ in range(kernel.ndim)]\n    no_flip = (slice(None, None), slice(None, None))\n    slices[-2:] = no_flip\n    return np.copy(kernel[slices])",
                "def conv_output_length(input_length, filter_size,\n                       padding, stride, dilation=1):\n    \"\"\"Determines output length of a convolution given input length.\n\n    # Arguments\n        input_length: integer.\n        filter_size: integer.\n        padding: one of `\"same\"`, `\"valid\"`, `\"full\"`.\n        stride: integer.\n        dilation: dilation rate, integer.\n\n    # Returns\n        The output length (integer).\n    \"\"\"\n    if input_length is None:\n        return None\n    assert padding in {'same', 'valid', 'full', 'causal'}\n    dilated_filter_size = filter_size + (filter_size - 1) * (dilation - 1)\n    if padding == 'same':\n        output_length = input_length\n    elif padding == 'valid':\n        output_length = input_length - dilated_filter_size + 1\n    elif padding == 'causal':\n        output_length = input_length\n    elif padding == 'full':\n        output_length = input_length + dilated_filter_size - 1\n    return (output_length + stride - 1) // stride",
                "def conv_input_length(output_length, filter_size, padding, stride):\n    \"\"\"Determines input length of a convolution given output length.\n\n    # Arguments\n        output_length: integer.\n        filter_size: integer.\n        padding: one of `\"same\"`, `\"valid\"`, `\"full\"`.\n        stride: integer.\n\n    # Returns\n        The input length (integer).\n    \"\"\"\n    if output_length is None:\n        return None\n    assert padding in {'same', 'valid', 'full'}\n    if padding == 'same':\n        pad = filter_size // 2\n    elif padding == 'valid':\n        pad = 0\n    elif padding == 'full':\n        pad = filter_size - 1\n    return (output_length - 1) * stride - 2 * pad + filter_size",
                "def deconv_length(dim_size, stride_size, kernel_size, padding, output_padding):\n    \"\"\"Determines output length of a transposed convolution given input length.\n\n    # Arguments\n        dim_size: Integer, the input length.\n        stride_size: Integer, the stride along the dimension of `dim_size`.\n        kernel_size: Integer, the kernel size along the dimension of\n            `dim_size`.\n        padding: One of `\"same\"`, `\"valid\"`, `\"full\"`.\n        output_padding: Integer, amount of padding along the output dimension,\n            Can be set to `None` in which case the output length is inferred.\n\n    # Returns\n        The output length (integer).\n    \"\"\"\n    assert padding in {'same', 'valid', 'full'}\n    if dim_size is None:\n        return None\n\n    # Infer length if output padding is None, else compute the exact length\n    if output_padding is None:\n        if padding == 'valid':\n            dim_size = dim_size * stride_size + max(kernel_size - stride_size, 0)\n        elif padding == 'full':\n            dim_size = dim_size * stride_size - (stride_size + kernel_size - 2)\n        elif padding == 'same':\n            dim_size = dim_size * stride_size\n    else:\n        if padding == 'same':\n            pad = kernel_size // 2\n        elif padding == 'valid':\n            pad = 0\n        elif padding == 'full':\n            pad = kernel_size - 1\n\n        dim_size = ((dim_size - 1) * stride_size + kernel_size - 2 * pad +\n                    output_padding)\n\n    return dim_size"
            ],
            "inscope_function_signatures": [
                "normalize_tuple(value, n, name)",
                "normalize_padding(value)",
                "convert_kernel(kernel)",
                "conv_output_length(input_length, filter_size, padding, stride, dilation=1)",
                "conv_input_length(output_length, filter_size, padding, stride)",
                "deconv_length(dim_size, stride_size, kernel_size, padding, output_padding)"
            ],
            "variables_in_file": {
                "isinstance": [
                    29
                ],
                "value": [
                    33,
                    36,
                    39,
                    45,
                    52,
                    29,
                    30
                ],
                "int": [
                    42,
                    29
                ],
                "n": [
                    36,
                    37,
                    39,
                    45,
                    30
                ],
                "value_tuple": [
                    40,
                    33,
                    48,
                    37
                ],
                "tuple": [
                    33
                ],
                "TypeError": [
                    34
                ],
                "ValueError": [
                    35,
                    38,
                    43,
                    44,
                    78,
                    57
                ],
                "name": [
                    35,
                    44,
                    38
                ],
                "str": [
                    36,
                    39,
                    45,
                    46,
                    47,
                    58
                ],
                "len": [
                    37
                ],
                "single_value": [
                    40,
                    42,
                    46,
                    47
                ],
                "type": [
                    47
                ],
                "padding": [
                    128,
                    129,
                    131,
                    133,
                    153,
                    159,
                    161,
                    163,
                    166,
                    168,
                    170,
                    52,
                    56,
                    58,
                    59,
                    101,
                    103,
                    105,
                    107,
                    109
                ],
                "value.lower": [
                    52
                ],
                "allowed": [
                    56,
                    53,
                    55
                ],
                "K.backend": [
                    54
                ],
                "K": [
                    54
                ],
                "allowed.add": [
                    55
                ],
                "kernel": [
                    76,
                    77,
                    78,
                    79,
                    82
                ],
                "np.asarray": [
                    76
                ],
                "np": [
                    82,
                    76
                ],
                "kernel.ndim": [
                    77,
                    79
                ],
                "kernel.shape": [
                    78
                ],
                "slices": [
                    81,
                    82,
                    79
                ],
                "slice": [
                    80,
                    79
                ],
                "_": [
                    79
                ],
                "range": [
                    79
                ],
                "no_flip": [
                    80,
                    81
                ],
                "np.copy": [
                    82
                ],
                "input_length": [
                    99,
                    104,
                    106,
                    108,
                    110
                ],
                "dilated_filter_size": [
                    106,
                    110,
                    102
                ],
                "filter_size": [
                    130,
                    134,
                    102,
                    135
                ],
                "dilation": [
                    102
                ],
                "output_length": [
                    135,
                    104,
                    106,
                    108,
                    110,
                    111,
                    126
                ],
                "stride": [
                    135,
                    111
                ],
                "pad": [
                    130,
                    132,
                    134,
                    167,
                    135,
                    169,
                    171,
                    173
                ],
                "dim_size": [
                    160,
                    162,
                    164,
                    173,
                    176,
                    154
                ],
                "output_padding": [
                    174,
                    158
                ],
                "stride_size": [
                    160,
                    162,
                    164,
                    173
                ],
                "max": [
                    160
                ],
                "kernel_size": [
                    160,
                    162,
                    167,
                    171,
                    173
                ]
            },
            "filtered_variables_in_file": {
                "value": [
                    33,
                    36,
                    39,
                    45,
                    52,
                    29,
                    30
                ],
                "n": [
                    36,
                    37,
                    39,
                    45,
                    30
                ],
                "value_tuple": [
                    40,
                    33,
                    48,
                    37
                ],
                "name": [
                    35,
                    44,
                    38
                ],
                "single_value": [
                    40,
                    42,
                    46,
                    47
                ],
                "padding": [
                    128,
                    129,
                    131,
                    133,
                    153,
                    159,
                    161,
                    163,
                    166,
                    168,
                    170,
                    52,
                    56,
                    58,
                    59,
                    101,
                    103,
                    105,
                    107,
                    109
                ],
                "value.lower": [
                    52
                ],
                "allowed": [
                    56,
                    53,
                    55
                ],
                "K.backend": [
                    54
                ],
                "K": [
                    54
                ],
                "allowed.add": [
                    55
                ],
                "kernel": [
                    76,
                    77,
                    78,
                    79,
                    82
                ],
                "np.asarray": [
                    76
                ],
                "np": [
                    82,
                    76
                ],
                "kernel.ndim": [
                    77,
                    79
                ],
                "kernel.shape": [
                    78
                ],
                "slices": [
                    81,
                    82,
                    79
                ],
                "_": [
                    79
                ],
                "no_flip": [
                    80,
                    81
                ],
                "np.copy": [
                    82
                ],
                "input_length": [
                    99,
                    104,
                    106,
                    108,
                    110
                ],
                "dilated_filter_size": [
                    106,
                    110,
                    102
                ],
                "filter_size": [
                    130,
                    134,
                    102,
                    135
                ],
                "dilation": [
                    102
                ],
                "output_length": [
                    135,
                    104,
                    106,
                    108,
                    110,
                    111,
                    126
                ],
                "stride": [
                    135,
                    111
                ],
                "pad": [
                    130,
                    132,
                    134,
                    167,
                    135,
                    169,
                    171,
                    173
                ],
                "dim_size": [
                    160,
                    162,
                    164,
                    173,
                    176,
                    154
                ],
                "output_padding": [
                    174,
                    158
                ],
                "stride_size": [
                    160,
                    162,
                    164,
                    173
                ],
                "kernel_size": [
                    160,
                    162,
                    167,
                    171,
                    173
                ]
            }
        },
        "test_data": [
            {
                "test_path": "/Volumes/SSD2T/bgp_envs_non_pandas/repos/keras_20/tests/keras/layers/convolutional_test.py",
                "test_function": "test_conv2d_transpose_dilation",
                "test_function_code": "@keras_test\n@pytest.mark.skipif((K.backend() == 'cntk'),\n                    reason='cntk only supports dilated conv transpose on GPU')\ndef test_conv2d_transpose_dilation():\n\n    layer_test(convolutional.Conv2DTranspose,\n               kwargs={'filters': 2,\n                       'kernel_size': 3,\n                       'padding': 'same',\n                       'data_format': 'channels_last',\n                       'dilation_rate': (2, 2)},\n               input_shape=(2, 5, 6, 3))\n\n    # Check dilated conv transpose returns expected output\n    input_data = np.arange(48).reshape((1, 4, 4, 3)).astype(np.float32)\n    expected_output = np.float32([[192, 228, 192, 228],\n                                  [336, 372, 336, 372],\n                                  [192, 228, 192, 228],\n                                  [336, 372, 336, 372]]).reshape((1, 4, 4, 1))\n\n    layer_test(convolutional.Conv2DTranspose,\n               input_data=input_data,\n               kwargs={'filters': 1,\n                       'kernel_size': 3,\n                       'padding': 'same',\n                       'data_format': 'channels_last',\n                       'dilation_rate': (2, 2),\n                       'kernel_initializer': 'ones'},\n               expected_output=expected_output)",
                "test_error": "AssertionError:  Not equal to tolerance rtol=0.001, atol=0  Mismatched elements: 16 / 16 (100%) Max absolute difference: 645. Max relative difference: 3.359375  x: array([[[[102.],          [180.],          [234.],...  y: array([[[[192.],          [228.],          [192.],...",
                "full_test_error": "@keras_test\n    @pytest.mark.skipif((K.backend() == 'cntk'),\n                        reason='cntk only supports dilated conv transpose on GPU')\n    def test_conv2d_transpose_dilation():\n    \n        layer_test(convolutional.Conv2DTranspose,\n                   kwargs={'filters': 2,\n                           'kernel_size': 3,\n                           'padding': 'same',\n                           'data_format': 'channels_last',\n                           'dilation_rate': (2, 2)},\n                   input_shape=(2, 5, 6, 3))\n    \n        # Check dilated conv transpose returns expected output\n        input_data = np.arange(48).reshape((1, 4, 4, 3)).astype(np.float32)\n        expected_output = np.float32([[192, 228, 192, 228],\n                                      [336, 372, 336, 372],\n                                      [192, 228, 192, 228],\n                                      [336, 372, 336, 372]]).reshape((1, 4, 4, 1))\n    \n        layer_test(convolutional.Conv2DTranspose,\n                   input_data=input_data,\n                   kwargs={'filters': 1,\n                           'kernel_size': 3,\n                           'padding': 'same',\n                           'data_format': 'channels_last',\n                           'dilation_rate': (2, 2),\n                           'kernel_initializer': 'ones'},\n>                  expected_output=expected_output)\n\ntests/keras/layers/convolutional_test.py:256: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nkeras/utils/test_utils.py:120: in layer_test\n    _layer_in_model_test(model)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nmodel = <keras.engine.training.Model object at 0x125b11850>\n\n    def _layer_in_model_test(model):\n        actual_output = model.predict(input_data)\n        actual_output_shape = actual_output.shape\n        for expected_dim, actual_dim in zip(expected_output_shape,\n                                            actual_output_shape):\n            if expected_dim is not None:\n                assert expected_dim == actual_dim\n        if expected_output is not None:\n>           assert_allclose(actual_output, expected_output, rtol=1e-3)\nE           AssertionError: \nE           Not equal to tolerance rtol=0.001, atol=0\nE           \nE           Mismatched elements: 16 / 16 (100%)\nE           Max absolute difference: 645.\nE           Max relative difference: 3.359375\nE            x: array([[[[102.],\nE                    [180.],\nE                    [234.],...\nE            y: array([[[[192.],\nE                    [228.],\nE                    [192.],...\n\nkeras/utils/test_utils.py:94: AssertionError",
                "traceback": "keras/utils/test_utils.py:120: in layer_test\n    _layer_in_model_test(model)",
                "test_error_location": "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nmodel = <keras.engine.training.Model object at 0x125b11850>\n\n    def _layer_in_model_test(model):\n        actual_output = model.predict(input_data)\n        actual_output_shape = actual_output.shape\n        for expected_dim, actual_dim in zip(expected_output_shape,\n                                            actual_output_shape):\n            if expected_dim is not None:\n                assert expected_dim == actual_dim\n        if expected_output is not None:\n>           assert_allclose(actual_output, expected_output, rtol=1e-3)\nE           AssertionError: \nE           Not equal to tolerance rtol=0.001, atol=0\nE           \nE           Mismatched elements: 16 / 16 (100%)\nE           Max absolute difference: 645.\nE           Max relative difference: 3.359375\nE            x: array([[[[102.],\nE                    [180.],\nE                    [234.],...\nE            y: array([[[[192.],\nE                    [228.],\nE                    [192.],...\n\nkeras/utils/test_utils.py:94: AssertionError",
                "test_function_decorators": [
                    "keras_test",
                    "pytest.mark.skipif(K.backend() == 'cntk', reason='cntk only supports dilated conv transpose on GPU')"
                ]
            }
        ]
    }
}