```python
def from_config(cls, config, custom_objects=None):
    """Instantiates a Model from its config (output of `get_config()`).

    # Arguments
        config: Model config dictionary.
        custom_objects: Optional dictionary mapping names
            (strings) to custom classes or functions to be
            considered during deserialization.

    # Returns
        A model instance.

    # Raises
        ValueError: In case of improperly formatted config dict.
    """
    # Layer instances created during
    # the graph reconstruction process
    created_layers = {}

    # Dictionary mapping layer instances to
    # node data that specifies a layer call.
    # It acts as a queue that maintains any unprocessed
    # layer call until it becomes possible to process it
    # (i.e. until the input tensors to the call all exist).
    unprocessed_nodes = {}

    def add_unprocessed_node(layer_sharing, node_data):
        if layer_sharing not in unprocessed_nodes:
            unprocessed_nodes[layer_sharing] = [node_data]
        else:
            unprocessed_nodes[layer_sharing].append(node_data)

    def process_node(layer_sharing, node_data):
        layer_input_tensors = []
        for input_shared_data in node_data:
            inbound_layer_name_sharing = input_shared_data[0]
            inbound_node_index_sharing = input_shared_data[1]
            inbound_tensor_index_sharing = input_shared_data[2]
            if len(input_shared_data) == 3:
                shared_call_kwargs = {}
            elif len(input_shared_data) == 4:
                shared_call_kwargs = input_shared_data[3]
            else:
                raise ValueError('Improperly formatted model config.')
            inbound_layer = created_layers[inbound_layer_name_sharing]
            if len(inbound_layer._inbound_nodes) <= inbound_node_index_sharing:
                add_unprocessed_node(layer_sharing, node_data)
                return
            inbound_node_sharing = inbound_layer._inbound_nodes[inbound_node_index_sharing]
            layer_input_tensors.append(
                inbound_node_sharing.output_tensors[inbound_tensor_index_sharing])
        # Call layer on its inputs, thus creating the shared node
        # and building the shared layer if needed.
        if layer_input_tensors:
            layer_sharing(unpack_singleton(layer_input_tensors), **shared_call_kwargs)

    def process_layer(layer_shared_data):
        """Deserializes a layer, then call it on appropriate inputs.

        # Arguments
            layer_shared_data: layer config dict.

        # Raises
            ValueError: In case of improperly formatted `layer_shared_data` dict.
        """
        layer_name_sharing = layer_shared_data['name']

        # Instantiate layer.
        from ..layers import deserialize as deserialize_layer

        layer_sharing = deserialize_layer(layer_shared_data,
                              custom_objects=custom_objects)
        created_layers[layer_name_sharing] = layer_sharing

        # Gather layer inputs.
        inbound_nodes_shared_data = layer_shared_data['inbound_nodes']
        for node_shared_data in inbound_nodes_shared_data:
            # We don't process nodes (i.e. make layer calls)
            # on the fly because the inbound shared node may not yet exist,
            # in case of layer shared at different topological depths
            # (e.g. a model such as A(B(A(B(x)))))
            add_unprocessed_node(layer_sharing, node_shared_data)

    # First, we create all layers and enqueue nodes to be processed
    for layer_shared_data in config['layers']:
        process_layer(layer_shared_data)
    # Then we process nodes in order of layer depth.
    # Nodes that cannot yet be processed (if the inbound shared node
    # does not yet exist) are re-enqueued, and the process
    # is repeated until all nodes are processed.
    while unprocessed_nodes:
        for layer_shared_data in config['layers']:
            layer_to_receive = created_layers[layer_shared_data['name']]
            if layer_to_receive in unprocessed_nodes:
                for node_shared_data in unprocessed_nodes.pop(layer_to_receive):
                    process_node(layer_to_receive, node_shared_data)

    name_sharing = config.get('name')
    tensor_inputs = []
    tensor_outputs = []
    for node_data_list in config['input_layers']:
        layer_name, node_index, tensor_index = node_data_list
        assert layer_name in created_layers
        layer_shared = created_layers[layer_name]
        layer_output_tensors_shared = layer_shared._inbound_nodes[node_index].output_tensors
        tensor_inputs.append(layer_output_tensors_shared[tensor_index])
    for node_data_list in config['output_layers']:
        layer_name, node_index, tensor_index = node_data_list
        assert layer_name in created_layers
        layer_shared = created_layers[layer_name]
        layer_output_tensors_shared = layer_shared._inbound_nodes[node_index].output_tensors
        tensor_outputs.append(layer_output_tensors_shared[tensor_index])
    return cls(inputs=tensor_inputs, outputs=tensor_outputs, name=name_sharing)
```