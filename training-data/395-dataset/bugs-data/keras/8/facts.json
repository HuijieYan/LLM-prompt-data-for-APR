{
    "1.1.1": "@classmethod\ndef from_config(cls, config, custom_objects=None):\n    \n    # Layer instances created during\n    # the graph reconstruction process\n    created_layers = {}\n\n    # Dictionary mapping layer instances to\n    # node data that specifies a layer call.\n    # It acts as a queue that maintains any unprocessed\n    # layer call until it becomes possible to process it\n    # (i.e. until the input tensors to the call all exist).\n    unprocessed_nodes = {}\n\n    def add_unprocessed_node(layer, node_data):\n        if layer not in unprocessed_nodes:\n            unprocessed_nodes[layer] = [node_data]\n        else:\n            unprocessed_nodes[layer].append(node_data)\n\n    def process_node(layer, node_data):\n        input_tensors = []\n        for input_data in node_data:\n            inbound_layer_name = input_data[0]\n            inbound_node_index = input_data[1]\n            inbound_tensor_index = input_data[2]\n            if len(input_data) == 3:\n                kwargs = {}\n            elif len(input_data) == 4:\n                kwargs = input_data[3]\n            else:\n                raise ValueError('Improperly formatted model config.')\n            inbound_layer = created_layers[inbound_layer_name]\n            if len(inbound_layer._inbound_nodes) <= inbound_node_index:\n                add_unprocessed_node(layer, node_data)\n                return\n            inbound_node = inbound_layer._inbound_nodes[inbound_node_index]\n            input_tensors.append(\n                inbound_node.output_tensors[inbound_tensor_index])\n        # Call layer on its inputs, thus creating the node\n        # and building the layer if needed.\n        if input_tensors:\n            layer(unpack_singleton(input_tensors), **kwargs)\n\n    def process_layer(layer_data):\n        \n        layer_name = layer_data['name']\n\n        # Instantiate layer.\n        from ..layers import deserialize as deserialize_layer\n\n        layer = deserialize_layer(layer_data,\n                                  custom_objects=custom_objects)\n        created_layers[layer_name] = layer\n\n        # Gather layer inputs.\n        inbound_nodes_data = layer_data['inbound_nodes']\n        for node_data in inbound_nodes_data:\n            # We don't process nodes (i.e. make layer calls)\n            # on the fly because the inbound node may not yet exist,\n            # in case of layer shared at different topological depths\n            # (e.g. a model such as A(B(A(B(x)))))\n            add_unprocessed_node(layer, node_data)\n\n    # First, we create all layers and enqueue nodes to be processed\n    for layer_data in config['layers']:\n        process_layer(layer_data)\n    # Then we process nodes in order of layer depth.\n    # Nodes that cannot yet be processed (if the inbound node\n    # does not yet exist) are re-enqueued, and the process\n    # is repeated until all nodes are processed.\n    while unprocessed_nodes:\n        for layer_data in config['layers']:\n            layer = created_layers[layer_data['name']]\n            if layer in unprocessed_nodes:\n                for node_data in unprocessed_nodes.pop(layer):\n                    process_node(layer, node_data)\n\n    name = config.get('name')\n    input_tensors = []\n    output_tensors = []\n    for layer_data in config['input_layers']:\n        layer_name, node_index, tensor_index = layer_data\n        assert layer_name in created_layers\n        layer = created_layers[layer_name]\n        layer_output_tensors = layer._inbound_nodes[node_index].output_tensors\n        input_tensors.append(layer_output_tensors[tensor_index])\n    for layer_data in config['output_layers']:\n        layer_name, node_index, tensor_index = layer_data\n        assert layer_name in created_layers\n        layer = created_layers[layer_name]\n        layer_output_tensors = layer._inbound_nodes[node_index].output_tensors\n        output_tensors.append(layer_output_tensors[tensor_index])\n    return cls(inputs=input_tensors, outputs=output_tensors, name=name)\n",
    "1.1.2": "Instantiates a Model from its config (output of `get_config()`).\n\n# Arguments\n    config: Model config dictionary.\n    custom_objects: Optional dictionary mapping names\n        (strings) to custom classes or functions to be\n        considered during deserialization.\n\n# Returns\n    A model instance.\n\n# Raises\n    ValueError: In case of improperly formatted config dict.",
    "1.2.1": "class Network(Layer)",
    "1.2.2": "A Network is a directed acyclic graph of layers.\n\nIt is the topological form of a \"model\". A Model\nis simply a Network with added training routines.\n\n# Properties\n    name\n    inputs\n    outputs\n    layers\n    input_spec (list of class instances)\n        each entry describes one required input:\n            - ndim\n            - dtype\n    trainable (boolean)\n    input_shape\n    output_shape\n    weights (list of variables)\n    trainable_weights (list of variables)\n    non_trainable_weights (list of variables)\n    losses\n    updates\n    state_updates\n    stateful\n\n# Methods\n    __call__\n    summary\n    get_layer\n    get_weights\n    set_weights\n    get_config\n    compute_output_shape\n    save\n    add_loss\n    add_update\n    get_losses_for\n    get_updates_for\n    to_json\n    to_yaml\n    reset_states\n\n# Class Methods\n    from_config\n\n# Raises\n    TypeError: if input tensors are not Keras tensors\n        (tensors returned by `Input`).",
    "1.2.3": [
        "add_unprocessed_node(layer, node_data)",
        "process_node(layer, node_data)",
        "process_layer(layer_data)"
    ],
    "1.3.1": "/Volumes/SSD2T/bgp_envs_non_pandas/repos/keras_8/keras/engine/network.py",
    "1.3.2": [
        "add_unprocessed_node(layer, node_data)",
        "process_node(layer, node_data)",
        "process_layer(layer_data)"
    ],
    "1.4.1": [
        "def test_layer_sharing_at_heterogeneous_depth_order():\n    # This tests for the bug in this issue\n    # https://github.com/keras-team/keras/issues/11159\n    # It occurs with layer sharing at heterogeneous depth when\n    # the layers need to be applied in an order that differs from\n    # the order that occurs in the config.\n\n    input_shape = (1, 12)\n    input_layer = Input(shape=input_shape)\n\n    A = Dense(12, name='layer_a')\n    r1 = layers.Reshape((12,))(input_layer)\n    Aout1 = A(r1)\n\n    r2 = layers.Reshape((12,))(A(input_layer))\n    Aout2 = A(r2)\n\n    # Note: if the order of the layers in the concat is\n    # changed to ([Aout1, Aout2]) the bug doesn't trigger\n    c1 = layers.concatenate([Aout2, Aout1])\n    output = Dense(2, name='layer_b')(c1)\n\n    M = Model(inputs=input_layer, outputs=output)\n\n    x_val = np.random.random((10,) + input_shape)\n    output_val = M.predict(x_val)\n\n    config = M.get_config()\n    weights = M.get_weights()\n\n    M2 = Model.from_config(config)\n    M2.set_weights(weights)\n\n    output_val_2 = M2.predict(x_val)\n    np.testing.assert_allclose(output_val, output_val_2, atol=1e-6)"
    ],
    "1.4.2": [
        "/Volumes/SSD2T/bgp_envs_non_pandas/repos/keras_8/tests/keras/engine/test_topology.py"
    ],
    "2.1.1": [
        [
            "E           ValueError: A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got inputs shapes: [(None, 12), (None, 1, 12)]"
        ]
    ],
    "2.1.2": [
        [
            "def test_layer_sharing_at_heterogeneous_depth_order():\n        # This tests for the bug in this issue\n        # https://github.com/keras-team/keras/issues/11159\n        # It occurs with layer sharing at heterogeneous depth when\n        # the layers need to be applied in an order that differs from\n        # the order that occurs in the config.\n    \n        input_shape = (1, 12)\n        input_layer = Input(shape=input_shape)\n    \n        A = Dense(12, name='layer_a')\n        r1 = layers.Reshape((12,))(input_layer)\n        Aout1 = A(r1)\n    \n        r2 = layers.Reshape((12,))(A(input_layer))\n        Aout2 = A(r2)\n    \n        # Note: if the order of the layers in the concat is\n        # changed to ([Aout1, Aout2]) the bug doesn't trigger\n        c1 = layers.concatenate([Aout2, Aout1])\n        output = Dense(2, name='layer_b')(c1)\n    \n        M = Model(inputs=input_layer, outputs=output)\n    \n        x_val = np.random.random((10,) + input_shape)\n        output_val = M.predict(x_val)\n    \n        config = M.get_config()\n        weights = M.get_weights()\n    \n>       M2 = Model.from_config(config)\n\ntests/keras/engine/test_topology.py:793: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nkeras/engine/network.py:1029: in from_config\n    process_node(layer, node_data)\nkeras/engine/network.py:988: in process_node\n    layer(unpack_singleton(input_tensors), **kwargs)\nkeras/engine/base_layer.py:431: in __call__\n    self.build(unpack_singleton(input_shapes))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <keras.layers.merge.Concatenate object at 0x12374abd0>\ninput_shape = [(None, 12), (None, 1, 12)]\n\n    def build(self, input_shape):\n        # Used purely for shape validation.\n        if not isinstance(input_shape, list) or len(input_shape) < 2:\n            raise ValueError('A `Concatenate` layer should be called '\n                             'on a list of at least 2 inputs')\n        if all([shape is None for shape in input_shape]):\n            return\n        reduced_inputs_shapes = [list(shape) for shape in input_shape]\n        shape_set = set()\n        for i in range(len(reduced_inputs_shapes)):\n            del reduced_inputs_shapes[i][self.axis]\n            shape_set.add(tuple(reduced_inputs_shapes[i]))\n        if len(shape_set) > 1:\n            raise ValueError('A `Concatenate` layer requires '\n                             'inputs with matching shapes '\n                             'except for the concat axis. '\n>                            'Got inputs shapes: %s' % (input_shape))",
            "\nkeras/layers/merge.py:362: ValueError"
        ]
    ],
    "2.1.3": null,
    "2.1.4": null,
    "2.1.5": null,
    "2.1.6": null,
    "3.1.1": [
        "\n"
    ],
    "3.1.2": [
        "\n"
    ]
}