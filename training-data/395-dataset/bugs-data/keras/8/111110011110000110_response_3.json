{
    "keras": [
        {
            "bugID": 8,
            "bitvector": {
                "1.1.1": 1,
                "1.1.2": 1,
                "1.2.1": 1,
                "1.2.2": 1,
                "1.2.3": 1,
                "1.3.1": 0,
                "1.3.2": 0,
                "1.4.1": 1,
                "1.4.2": 1,
                "2.1.1": 1,
                "2.1.2": 1,
                "2.1.3": 0,
                "2.1.4": 0,
                "2.1.5": 0,
                "2.1.6": 0,
                "3.1.1": 1,
                "3.1.2": 1,
                "cot": 0
            },
            "strata": {
                "1": 1,
                "2": 1,
                "3": 0,
                "4": 1,
                "5": 0,
                "6": 1,
                "7": 0
            },
            "available_bitvector": {
                "1.1.1": 1,
                "1.1.2": 1,
                "1.2.1": 1,
                "1.2.2": 1,
                "1.2.3": 1,
                "1.3.1": 0,
                "1.3.2": 0,
                "1.4.1": 1,
                "1.4.2": 1,
                "2.1.1": 1,
                "2.1.2": 1,
                "2.1.3": 0,
                "2.1.4": 0,
                "2.1.5": 0,
                "2.1.6": 0,
                "3.1.1": 1,
                "3.1.2": 1,
                "cot": 0
            },
            "available_strata": {
                "1": 1,
                "2": 1,
                "3": 0,
                "4": 1,
                "5": 0,
                "6": 1,
                "7": 0
            },
            "start_line": 933,
            "file_name": "keras/engine/network.py",
            "replace_code": "def from_config(cls, config, custom_objects=None):\n\n    \"\"\"Instantiates a Model from its config (output of `get_config()`).\n    \n    # Arguments\n        config: Model config dictionary.\n        custom_objects: Optional dictionary mapping names\n            (strings) to custom classes or functions to be\n            considered during deserialization.\n    \n    # Returns\n        A model instance.\n    \n    # Raises\n        ValueError: In case of improperly formatted config dict.\n    \"\"\"\n    # Layer instances created during\n    # the graph reconstruction process\n    created_layers = {}\n    \n    # Dictionary mapping layer instances to\n    # node data that specifies a layer call.\n    # It acts as a queue that maintains any unprocessed\n    # layer call until it becomes possible to process it\n    # (i.e. until the input tensors to the call all exist).\n    unprocessed_nodes = {}\n    \n    # updated add_unprocessed_node method, expected 'cls' argument not used\n    def add_unprocessed_node(node_data):\n        layer = cls.get_layer(node_data['name'])\n        if layer not in unprocessed_nodes:\n            unprocessed_nodes[layer] = [node_data]\n        else:\n            unprocessed_nodes[layer].append(node_data)\n    \n    def process_node(node_data):\n        input_tensors = []\n        for input_data in node_data['inbound_nodes']:\n            inbound_layer = cls.get_layer(input_data[0])\n            inbound_node_index = input_data[1][0]\n            inbound_tensor_index = input_data[1][1]\n            if len(input_data) == 2:\n                kwargs = {}\n            elif len(input_data) == 3:\n                kwargs = input_data[2]\n            else:\n                raise ValueError('Improperly formatted model config.')\n            inbound_node = inbound_layer._inbound_nodes[inbound_node_index]\n            input_tensors.append(\n                inbound_node.output_tensors[inbound_tensor_index])\n    \n        # Process the inputs and add them to the layer\n        inputs = unpack_singleton(input_tensors)\n        layer = cls.get_layer(node_data['name'])\n        layer.original_input = inputs\n        outputs = layer(inputs, **kwargs)\n    \n        # If there are outputs, add them to the layer\n        if outputs:\n            if not isinstance(outputs, list):\n                outputs = [outputs]\n    \n            # Save the output tensors from the layer call\n            for i, output in enumerate(layer._inbound_nodes[-1].output_tensors):\n                cls._save_output(output, node_data['name'], len(unprocessed_nodes))\n    \n            # Process any layers using the generated output\n            cls._process_layers_connected_to(node_data['name'], len(unprocessed_nodes))\n    \n    def process_layer(layer_data):\n        \"\"\"Deserializes a layer, then call it on appropriate inputs.\n    \n        # Arguments\n            layer_data: layer config dict.\n    \n        # Raises\n            ValueError: In case of improperly formatted `layer_data` dict.\n        \"\"\"\n        layer = deserialize_layer(layer_data,\n                                  custom_objects=custom_objects)\n        created_layers[layer_data['name']] = layer\n        inbound_nodes_data = layer_data['inbound_nodes']\n        for node_data in inbound_nodes_data:\n            add_unprocessed_node(node_data)\n    \n    for layer_data in config['layers']:\n        process_layer(layer_data)\n    \n    return created_layers"
        }
    ]
}