# Error stack trace

```json
[
    [
        "def test_model_methods():\n        a = Input(shape=(3,), name='input_a')\n        b = Input(shape=(3,), name='input_b')\n    \n        a_2 = Dense(4, name='dense_1')(a)\n        dp = Dropout(0.5, name='dropout')\n        b_2 = dp(b)\n    \n        model = Model([a, b], [a_2, b_2])\n    \n        optimizer = 'rmsprop'\n        loss = 'mse'\n        loss_weights = [1., 0.5]\n    \n        input_a_np = np.random.random((10, 3))\n        input_b_np = np.random.random((10, 3))\n    \n        output_a_np = np.random.random((10, 4))\n        output_b_np = np.random.random((10, 3))\n    \n        # training/testing doesn't work before compiling.\n        with pytest.raises(RuntimeError):\n            model.train_on_batch([input_a_np, input_b_np],\n                                 [output_a_np, output_b_np])\n    \n        model.compile(optimizer, loss, metrics=[], loss_weights=loss_weights,\n                      sample_weight_mode=None)\n    \n        # test train_on_batch\n        out = model.train_on_batch([input_a_np, input_b_np],\n                                   [output_a_np, output_b_np])\n        out = model.train_on_batch({'input_a': input_a_np, 'input_b': input_b_np},\n                                   [output_a_np, output_b_np])\n        out = model.train_on_batch({'input_a': input_a_np, 'input_b': input_b_np},\n                                   {'dense_1': output_a_np, 'dropout': output_b_np})\n    \n        # test fit\n        out = model.fit([input_a_np, input_b_np],\n                        [output_a_np, output_b_np], epochs=1, batch_size=4)\n        out = model.fit({'input_a': input_a_np, 'input_b': input_b_np},\n                        [output_a_np, output_b_np], epochs=1, batch_size=4)\n        out = model.fit({'input_a': input_a_np, 'input_b': input_b_np},\n                        {'dense_1': output_a_np, 'dropout': output_b_np},\n                        epochs=1, batch_size=4)\n    \n        # test validation_split\n        out = model.fit([input_a_np, input_b_np],\n                        [output_a_np, output_b_np],\n                        epochs=1, batch_size=4, validation_split=0.5)\n        out = model.fit({'input_a': input_a_np, 'input_b': input_b_np},\n                        [output_a_np, output_b_np],\n                        epochs=1, batch_size=4, validation_split=0.5)\n    \n        # test validation data\n        out = model.fit([input_a_np, input_b_np],\n                        [output_a_np, output_b_np],\n                        epochs=1, batch_size=4,\n                        validation_data=([input_a_np, input_b_np],\n                                         [output_a_np, output_b_np]))\n        out = model.fit({'input_a': input_a_np, 'input_b': input_b_np},\n                        [output_a_np, output_b_np],\n                        epochs=1, batch_size=4, validation_split=0.5,\n                        validation_data=({'input_a': input_a_np,\n                                          'input_b': input_b_np},\n                                         [output_a_np, output_b_np]))\n        out = model.fit({'input_a': input_a_np, 'input_b': input_b_np},\n                        {'dense_1': output_a_np, 'dropout': output_b_np},\n                        epochs=1, batch_size=4, validation_split=0.5,\n                        validation_data=(\n                            {'input_a': input_a_np, 'input_b': input_b_np},\n                            {'dense_1': output_a_np, 'dropout': output_b_np}))\n    \n        # test_on_batch\n        out = model.test_on_batch([input_a_np, input_b_np],\n                                  [output_a_np, output_b_np])\n        out = model.test_on_batch({'input_a': input_a_np, 'input_b': input_b_np},\n                                  [output_a_np, output_b_np])\n        out = model.test_on_batch({'input_a': input_a_np, 'input_b': input_b_np},\n                                  {'dense_1': output_a_np, 'dropout': output_b_np})\n    \n        # predict_on_batch\n        out = model.predict_on_batch([input_a_np, input_b_np])\n        out = model.predict_on_batch({'input_a': input_a_np,\n                                      'input_b': input_b_np})\n    \n        # predict, evaluate\n        input_a_np = np.random.random((10, 3))\n        input_b_np = np.random.random((10, 3))\n    \n        output_a_np = np.random.random((10, 4))\n        output_b_np = np.random.random((10, 3))\n    \n        out = model.evaluate([input_a_np, input_b_np],\n                             [output_a_np, output_b_np],\n                             batch_size=4)\n        out = model.predict([input_a_np, input_b_np], batch_size=4)\n    \n        # with sample_weight\n        input_a_np = np.random.random((10, 3))\n        input_b_np = np.random.random((10, 3))\n    \n        output_a_np = np.random.random((10, 4))\n        output_b_np = np.random.random((10, 3))\n    \n        sample_weight = [None, np.random.random((10,))]\n        out = model.train_on_batch([input_a_np, input_b_np],\n                                   [output_a_np, output_b_np],\n                                   sample_weight=sample_weight)\n    \n        out = model.test_on_batch([input_a_np, input_b_np],\n                                  [output_a_np, output_b_np],\n                                  sample_weight=sample_weight)\n    \n        # test accuracy metric\n        model.compile(optimizer, loss, metrics=['acc'],\n                      sample_weight_mode=None)\n    \n        out = model.train_on_batch([input_a_np, input_b_np],\n                                   [output_a_np, output_b_np])\n        assert len(out) == 5\n        out = model.test_on_batch([input_a_np, input_b_np],\n                                  [output_a_np, output_b_np])\n        assert len(out) == 5\n    \n        # this should also work\n        model.compile(optimizer, loss, metrics={'dense_1': 'acc'},\n                      sample_weight_mode=None)\n    \n        out = model.train_on_batch([input_a_np, input_b_np],\n                                   [output_a_np, output_b_np])\n        assert len(out) == 4\n        out = model.test_on_batch([input_a_np, input_b_np],\n                                  [output_a_np, output_b_np])\n        assert len(out) == 4\n    \n        # and this as well\n        model.compile(optimizer, loss, metrics={'dense_1': ['acc']},\n                      sample_weight_mode=None)\n    \n        out = model.train_on_batch([input_a_np, input_b_np],\n                                   [output_a_np, output_b_np])\n        assert len(out) == 4\n        out = model.test_on_batch([input_a_np, input_b_np],\n                                  [output_a_np, output_b_np])\n        assert len(out) == 4\n    \n        # test starting from non-zero initial epoch\n        trained_epochs = []\n        trained_batches = []\n    \n        # define tracer callback\n        def on_epoch_begin(epoch, logs):\n            trained_epochs.append(epoch)\n    \n        def on_batch_begin(batch, logs):\n            trained_batches.append(batch)\n    \n        tracker_cb = LambdaCallback(on_epoch_begin=on_epoch_begin,\n                                    on_batch_begin=on_batch_begin)\n    \n        out = model.fit([input_a_np, input_b_np],\n                        [output_a_np, output_b_np], epochs=5, batch_size=4,\n                        initial_epoch=2, callbacks=[tracker_cb])\n        assert trained_epochs == [2, 3, 4]\n    \n        # test starting from non-zero initial epoch for generator too\n        trained_epochs = []\n    \n        @threadsafe_generator\n        def gen_data(batch_sz):\n            while True:\n                yield ([np.random.random((batch_sz, 3)),\n                        np.random.random((batch_sz, 3))],\n                       [np.random.random((batch_sz, 4)),\n                        np.random.random((batch_sz, 3))])\n    \n        out = model.fit_generator(gen_data(4), steps_per_epoch=3, epochs=5,\n                                  initial_epoch=2, callbacks=[tracker_cb])\n        assert trained_epochs == [2, 3, 4]\n    \n        # test with a custom metric function\n        def mse(y_true, y_pred):\n            return K.mean(K.pow(y_true - y_pred, 2))\n    \n        model.compile(optimizer, loss, metrics=[mse],\n                      sample_weight_mode=None)\n    \n        out = model.train_on_batch([input_a_np, input_b_np],\n                                   [output_a_np, output_b_np])\n        out_len = 1 + 2 * (1 + 1)  # total loss + 2 outputs * (loss + metric)\n        assert len(out) == out_len\n        out = model.test_on_batch([input_a_np, input_b_np],\n                                  [output_a_np, output_b_np])\n        assert len(out) == out_len\n    \n        input_a_np = np.random.random((10, 3))\n        input_b_np = np.random.random((10, 3))\n    \n        output_a_np = np.random.random((10, 4))\n        output_b_np = np.random.random((10, 3))\n    \n        out = model.fit([input_a_np, input_b_np],\n                        [output_a_np, output_b_np],\n                        batch_size=4, epochs=1)\n        out = model.evaluate([input_a_np, input_b_np],\n                             [output_a_np, output_b_np],\n                             batch_size=4)\n        out = model.predict([input_a_np, input_b_np], batch_size=4)\n    \n        # enable verbose for evaluate_generator\n        out = model.evaluate_generator(gen_data(4), steps=3, verbose=1)\n    \n        # empty batch\n        with pytest.raises(ValueError):\n            @threadsafe_generator\n            def gen_data():\n                while True:\n                    yield (np.asarray([]), np.asarray([]))\n    \n            out = model.evaluate_generator(gen_data(), steps=1)\n    \n        # x is not a list of numpy arrays.\n        with pytest.raises(ValueError):\n            out = model.predict([None])\n    \n        # x does not match _feed_input_names.\n        with pytest.raises(ValueError):\n            out = model.predict([input_a_np, None, input_b_np])\n        with pytest.raises(ValueError):\n            out = model.predict([None, input_a_np, input_b_np])\n    \n        # all input/output/weight arrays should have the same number of samples.\n        with pytest.raises(ValueError):\n            out = model.train_on_batch([input_a_np, input_b_np[:2]],\n                                       [output_a_np, output_b_np],\n                                       sample_weight=sample_weight)\n        with pytest.raises(ValueError):\n            out = model.train_on_batch([input_a_np, input_b_np],\n                                       [output_a_np, output_b_np[:2]],\n                                       sample_weight=sample_weight)\n        with pytest.raises(ValueError):\n            out = model.train_on_batch([input_a_np, input_b_np],\n                                       [output_a_np, output_b_np],\n                                       sample_weight=[sample_weight[1],\n                                                      sample_weight[1][:2]])\n    \n        # `sample_weight` is neither a dict nor a list.\n        with pytest.raises(TypeError):\n            out = model.train_on_batch([input_a_np, input_b_np],\n                                       [output_a_np, output_b_np],\n                                       sample_weight=tuple(sample_weight))\n    \n        # `validation_data` is neither a tuple nor a triple.\n        with pytest.raises(ValueError):\n            out = model.fit([input_a_np, input_b_np],\n                            [output_a_np, output_b_np],\n                            epochs=1, batch_size=4,\n                            validation_data=([input_a_np, input_b_np],))\n    \n        # `loss` does not match outputs.\n        with pytest.raises(ValueError):\n            model.compile(optimizer, loss=['mse', 'mae', 'mape'])\n    \n        # `loss_weights` does not match output_names.\n        with pytest.raises(ValueError):\n            model.compile(optimizer, loss='mse', loss_weights={'lstm': 0.5})\n    \n        # `loss_weights` does not match outputs.\n        with pytest.raises(ValueError):\n            model.compile(optimizer, loss='mse', loss_weights=[0.5])\n    \n        # `loss_weights` is invalid type.\n        with pytest.raises(TypeError):\n            model.compile(optimizer, loss='mse', loss_weights=(0.5, 0.5))\n    \n        # `sample_weight_mode` does not match output_names.\n        with pytest.raises(ValueError):\n            model.compile(optimizer, loss='mse',\n                          sample_weight_mode={'lstm': 'temporal'})\n    \n        # `sample_weight_mode` does not match output_names.\n        with pytest.raises(ValueError):\n            model.compile(optimizer, loss='mse', sample_weight_mode=['temporal'])\n    \n        # `sample_weight_mode` matches output_names partially.\n        with pytest.raises(ValueError):\n            model.compile(optimizer, loss='mse',\n                          sample_weight_mode={'dense_1': 'temporal'})\n    \n        # `loss` does not exist.\n        with pytest.raises(ValueError):\n            model.compile(optimizer, loss=[])\n    \n        model.compile(optimizer, loss=['mse', 'mae'])\n        model.compile(optimizer, loss='mse', loss_weights={'dense_1': 0.2,\n                                                           'dropout': 0.8})\n        model.compile(optimizer, loss='mse', loss_weights=[0.2, 0.8])\n    \n        # the rank of weight arrays should be 1.\n        with pytest.raises(ValueError):\n            out = model.train_on_batch(\n                [input_a_np, input_b_np],\n                [output_a_np, output_b_np],\n                sample_weight=[None, np.random.random((10, 20, 30))])\n    \n        model.compile(optimizer, loss='mse',\n                      sample_weight_mode={'dense_1': None, 'dropout': 'temporal'})\n        model.compile(optimizer, loss='mse', sample_weight_mode=[None, 'temporal'])\n    \n        # the rank of output arrays should be at least 3D.\n        with pytest.raises(ValueError):\n            out = model.train_on_batch([input_a_np, input_b_np],\n                                       [output_a_np, output_b_np],\n                                       sample_weight=sample_weight)\n    \n        model.compile(optimizer, loss, metrics=[], loss_weights=loss_weights,\n                      sample_weight_mode=None)\n        trained_epochs = []\n        trained_batches = []\n        val_seq = RandomSequence(4)\n        out = model.fit_generator(generator=RandomSequence(3),\n                                  steps_per_epoch=3,\n                                  epochs=5,\n                                  initial_epoch=0,\n                                  validation_data=val_seq,\n                                  validation_steps=3,\n                                  max_queue_size=1,\n                                  callbacks=[tracker_cb])\n        assert trained_epochs == [0, 1, 2, 3, 4]\n        assert trained_batches == list(range(3)) * 5\n        assert len(val_seq.logs) <= 4 * 5\n    \n        # steps_per_epoch will be equal to len of sequence if it's unspecified\n        trained_epochs = []\n        trained_batches = []\n        val_seq = RandomSequence(4)\n        out = model.fit_generator(generator=RandomSequence(3),\n                                  epochs=5,\n                                  initial_epoch=0,\n                                  validation_data=val_seq,\n                                  callbacks=[tracker_cb])\n        assert trained_epochs == [0, 1, 2, 3, 4]\n        assert trained_batches == list(range(12)) * 5\n        assert len(val_seq.logs) == 12 * 5\n    \n        # test for workers = 0\n        trained_epochs = []\n        trained_batches = []\n        val_seq = RandomSequence(4)\n        out = model.fit_generator(generator=RandomSequence(3),\n                                  epochs=5,\n                                  validation_data=val_seq,\n                                  callbacks=[tracker_cb],\n>                                 workers=0)\n\ntests/keras/engine/test_training.py:479: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nkeras/legacy/interfaces.py:91: in wrapper\n    return func(*args, **kwargs)\nkeras/engine/training.py:1418: in fit_generator\n    initial_epoch=initial_epoch)\nkeras/engine/training_generator.py:233: in fit_generator\n    workers=0)\nkeras/legacy/interfaces.py:91: in wrapper\n    return func(*args, **kwargs)\nkeras/engine/training.py:1472: in evaluate_generator\n    verbose=verbose)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nmodel = <keras.engine.training.Model object at 0x128c14b90>\ngenerator = <generator object iter_sequence_infinite at 0x128b4bcd0>\nsteps = None, max_queue_size = 10, workers = 0, use_multiprocessing = False\nverbose = 0\n\n    def evaluate_generator(model, generator,\n                           steps=None,\n                           max_queue_size=10,\n                           workers=1,\n                           use_multiprocessing=False,\n                           verbose=0):\n        \"\"\"See docstring for `Model.evaluate_generator`.\"\"\"\n        model._make_test_function()\n    \n        if hasattr(model, 'metrics'):\n            for m in model.stateful_metric_functions:\n                m.reset_states()\n            stateful_metric_indices = [\n                i for i, name in enumerate(model.metrics_names)\n                if str(name) in model.stateful_metric_names]\n        else:\n            stateful_metric_indices = []\n    \n        steps_done = 0\n        wait_time = 0.01\n        outs_per_batch = []\n        batch_sizes = []\n        is_sequence = isinstance(generator, Sequence)\n        if not is_sequence and use_multiprocessing and workers > 1:\n            warnings.warn(\n                UserWarning('Using a generator with `use_multiprocessing=True`'\n                            ' and multiple workers may duplicate your data.'\n                            ' Please consider using the`keras.utils.Sequence'\n                            ' class.'))\n        if steps is None:\n            if is_sequence:\n                steps = len(generator)\n            else:\n>               raise ValueError('`steps=None` is only valid for a generator'\n                                 ' based on the `keras.utils.Sequence` class.'\n                                 ' Please specify `steps` or use the'\n                                 ' `keras.utils.Sequence` class.')",
        "\nkeras/engine/training_generator.py:300: ValueError"
    ]
]
```
