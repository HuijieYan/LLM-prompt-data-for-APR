```python
import tensorflow as tf

# File name: /Volumes/SSD2T/bgp_envs/repos/keras_31/keras/backend/tensorflow_backend.py

# Relative function's signature in this file
def transpose(x):
    # ... omitted code ...
    pass

# relative function's signature in this file
def log(x):
    # ... omitted code ...
    pass

# relative function's signature in this file
def expand_dims(x, axis=-1):
    # ... omitted code ...
    pass

# Relative function's signature in this file
def squeeze(x, axis):
    # ... omitted code ...
    pass

# Relative function's signature in this file
def ctc_label_dense_to_sparse(labels, label_lengths):
    # ... omitted code ...
    pass


# Buggy function fixed
def ctc_batch_cost(y_true, y_pred, input_length, label_length):
    """Runs CTC loss algorithm on each batch element.

    # Arguments
        y_true: tensor `(samples, max_string_length)`
            containing the truth labels.
        y_pred: tensor `(samples, time_steps, num_categories)`
            containing the prediction, or output of the softmax.
        input_length: tensor `(samples, 1)` containing the sequence length for
            each batch item in `y_pred`.
        label_length: tensor `(samples, 1)` containing the sequence length for
            each batch item in `y_true`.

    # Returns
        Tensor with shape (samples,1) containing the
            CTC loss of each element.
    """
    epsilon = 1e-8  # Define epsilon value

    label_length = tf.squeeze(tf.to_int32(label_length))  # Convert to int32 and squeeze
    input_length = tf.squeeze(tf.to_int32(input_length))  # Convert to int32 and squeeze
    sparse_labels = tf.sparse.to_dense(tf.to_int32(ctc_label_dense_to_sparse(y_true, label_length)))  # Create sparse labels

    y_pred = tf.log(tf.transpose(y_pred, perm=[1, 0, 2]) + epsilon)  # Apply log and transpose

    return tf.expand_dims(tf.nn.ctc_loss(labels=sparse_labels, logits=y_pred, label_length=label_length, logit_length=input_length), 1)  # Expand dimensions and compute ctc loss
```