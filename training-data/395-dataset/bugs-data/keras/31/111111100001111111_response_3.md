The error occurs in the ctc_batch_cost() function where the input_length and label_length are being squeezed using tf.squeeze(). 

The bug occurs because when using online training with a batch size of 1, the label_length and input_length tensors have a shape of (1,). When these tensors are passed through tf.squeeze(), they are converted to a shape of (), which causes the ctc_label_dense_to_sparse() and ctc_loss() functions to throw an error as they require a minimum shape of (1,).

To fix the bug, we need to remove the tf.squeeze() function calls for label_length and input_length. We should also check if they are scalar values before passing them to ctc_label_dense_to_sparse() and ctc_loss().

Here's the corrected code for the ctc_batch_cost() function:

```python
def ctc_batch_cost(y_true, y_pred, input_length, label_length):
    """Runs CTC loss algorithm on each batch element.

    # Arguments
        y_true: tensor `(samples, max_string_length)`
            containing the truth labels.
        y_pred: tensor `(samples, time_steps, num_categories)`
            containing the prediction, or output of the softmax.
        input_length: tensor `(samples, 1)` containing the sequence length for
            each batch item in `y_pred`.
        label_length: tensor `(samples, 1)` containing the sequence length for
            each batch item in `y_true`.

    # Returns
        Tensor with shape (samples,1) containing the
            CTC loss of each element.
    """
    sparse_labels = tf.to_int32(ctc_label_dense_to_sparse(y_true, label_length))

    y_pred = tf.log(tf.transpose(y_pred, perm=[1, 0, 2]) + epsilon())

    return tf.expand_dims(ctc.ctc_loss(inputs=y_pred,
                                       labels=sparse_labels,
                                       sequence_length=input_length), 1)
```

With these changes, the ctc_batch_cost() function should be able to handle batch sizes of 1 without throwing any errors.