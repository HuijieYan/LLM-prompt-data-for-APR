```python
def get_work(self, host=None, assistant=False, current_tasks=None, worker=None, **kwargs):
    # TODO: remove any expired nodes
    
    if self._config.prune_on_get_work:
        self.prune()

    assert worker is not None
    worker_id = worker
    # Return remaining tasks that have no FAILED descendants
    self.update(worker_id, {'host': host}, get_work=True)
    if assistant:
        self.add_worker(worker_id, [('assistant', assistant)])

    ct_set = set(current_tasks) if current_tasks is not None else set()
    best_task = None
    for task in sorted(self._state.get_running_tasks(), key=self._rank):
        if task.worker_running == worker_id and task.id not in ct_set:
            best_task = task
            break

    if current_tasks is not None:
        # batch running tasks that weren't claimed since the last get_work go back in the pool
        self._reset_orphaned_batch_running_tasks(worker_id)

    locally_pending_tasks = 0
    running_tasks = []
    n_unique_pending = 0

    worker = self._state.get_worker(worker_id)
    if worker.is_trivial_worker(self._state):
        relevant_tasks = worker.get_pending_tasks(self._state)
    else:
        relevant_tasks = self._state.get_pending_tasks()

    retrieved_tasks = []
    for task in relevant_tasks:
        if task.status == PENDING and (assistant or worker_id in task.workers):
            upstream_status = self._upstream_status(task.id)
            if upstream_status != UPSTREAM_DISABLED:
                locally_pending_tasks += 1
                if len(task.workers) == 1 and not assistant:
                    n_unique_pending += 1
            retrieved_tasks.append(task)

    batched_tasks = self._scheduler_resources.retrieve_batchable_tasks(relevant_tasks, len(retrieved_tasks))
    if assistant:
        self._add_to_worker(key=worker_id, value='assistant')

    # rest of the function...
```