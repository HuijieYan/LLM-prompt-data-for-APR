{
    "luigi": [
        {
            "bugID": 11,
            "bitvector": {
                "1.1.1": 1,
                "1.1.2": 1,
                "1.2.1": 0,
                "1.2.2": 0,
                "1.2.3": 0,
                "1.3.1": 1,
                "1.3.2": 1,
                "1.4.1": 1,
                "1.4.2": 1,
                "2.1.1": 1,
                "2.1.2": 1,
                "2.1.3": 0,
                "2.1.4": 0,
                "2.1.5": 0,
                "2.1.6": 0,
                "3.1.1": 0,
                "3.1.2": 0,
                "cot": 0
            },
            "strata": {
                "1": 1,
                "2": 0,
                "3": 1,
                "4": 1,
                "5": 0,
                "6": 0,
                "7": 0
            },
            "available_bitvector": {
                "1.1.1": 1,
                "1.1.2": 0,
                "1.2.1": 0,
                "1.2.2": 0,
                "1.2.3": 0,
                "1.3.1": 1,
                "1.3.2": 1,
                "1.4.1": 1,
                "1.4.2": 1,
                "2.1.1": 1,
                "2.1.2": 1,
                "2.1.3": 0,
                "2.1.4": 0,
                "2.1.5": 0,
                "2.1.6": 0,
                "3.1.1": 0,
                "3.1.2": 0,
                "cot": 0
            },
            "available_strata": {
                "1": 1,
                "2": 0,
                "3": 1,
                "4": 1,
                "5": 0,
                "6": 0,
                "7": 0
            },
            "start_line": 818,
            "file_name": "/luigi/scheduler.py",
            "replace_code": "def get_work(self, host=None, assistant=False, current_tasks=None, worker=None, **kwargs):\n\n    if self._config.prune_on_get_work:\n        self.prune()\n    \n    assert worker is not None\n    worker_id = worker\n    self.update(worker_id, {'host': host}, get_work=True)\n    if assistant:\n        self.add_worker(worker_id, [('assistant', assistant)])\n    \n    best_task = None\n    if current_tasks is not None:\n        ct_set = set(current_tasks)\n        for task in sorted(self.get_running_tasks(), key=self._rank):\n            if task.worker_running == worker_id and task.id not in ct_set:\n                best_task = task\n    \n    if current_tasks is not None:\n        self._reset_orphaned_batch_running_tasks(worker_id)\n    \n    locally_pending_tasks = 0\n    running_tasks = []\n    relevant_tasks = self.get_pending_tasks()\n    activity_limit = time.time() - self._config.worker_disconnect_delay\n    active_workers = self.get_active_workers(last_get_work_gt=activity_limit)\n    greedy_resources = collections.defaultdict(int)\n    n_unique_pending = 0\n    used_resources = self._used_resources()\n    for task in relevant_tasks:\n        in_workers = (assistant and getattr(task, 'runnable', bool(task.workers))) or worker_id in task.workers\n        if in_workers and task.status == PENDING:\n            locally_pending_tasks += 1\n            if len(task.workers) == 1 and not assistant:\n                n_unique_pending += 1\n        if task.status == RUNNING and in_workers:\n            other_worker = self.get_worker(task.worker_running)\n            more_info = {'task_id': task.id, 'worker': str(other_worker)}\n            if other_worker is not None:\n                more_info.update(other_worker.info)\n            running_tasks.append(more_info)\n        if self._schedulable(task) and self._has_resources(task.resources, greedy_resources):\n            if in_workers and self._has_resources(task.resources, used_resources):\n                if not best_task or self._rank(task) < self._rank(best_task):\n                    best_task = task\n            if task.status == RUNNING:\n                if task.worker_running in greedy_resources:\n                    for resource, amount in six.iteritems((task.resources or {})):\n                        greedy_resources[resource] += amount\n    \n    batched_tasks, max_batch_size = [], 1\n    if best_task:\n        self.set_status(best_task, RUNNING, self._config)\n        best_task.worker_running = worker_id\n        best_task.time_running = time.time()\n        self._update_task_history(best_task, RUNNING, host=host)\n    \n    reply = {'n_pending_tasks': locally_pending_tasks,\n             'running_tasks': running_tasks,\n             'task_id': None,\n             'n_unique_pending': n_unique_pending}\n    \n    if len(batched_tasks) > 1:\n        batch_string = '|'.join(task.id for task in batched_tasks)\n        batch_id = hashlib.md5(batch_string.encode('utf-8')).hexdigest()\n        for task in batched_tasks:\n            self.set_batch_running(task, batch_id, worker_id)\n        combined_params = best_task.params.copy()\n        combined_params.update(batched_params)\n        reply['task_id'] = None\n        reply['task_family'] = best_task.family\n        reply['task_module'] = getattr(best_task, 'module', None)\n        reply['task_params'] = combined_params\n        reply['batch_id'] = batch_id\n        reply['batch_task_ids'] = [task.id for task in batched_tasks]\n    elif best_task:\n        reply['task_id'] = best_task.id\n        reply['task_family'] = best_task.family\n        reply['task_module'] = getattr(best_task, 'module', None)\n        reply['task_params'] = best_task.params\n    \n    return reply"
        }
    ]
}