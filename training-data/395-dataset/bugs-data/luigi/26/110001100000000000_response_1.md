```python
def run_job(self, job):
        arglist = []
        if not job.jar() or not os.path.exists(job.jar()):
            logger.error("Can't find jar: %s, full path %s", job.jar(), os.path.abspath(job.jar()))
            raise HadoopJarJobError("job jar does not exist")

        hadoop_arglist = luigi.contrib.hdfs.load_hadoop_cmd() + ['jar', job.jar()]
        if job.main():
            hadoop_arglist.append(job.main())

        jobconfs = job.jobconfs()

        for jc in jobconfs:
            hadoop_arglist += ['-D' + jc]

        (tmp_files, job_args) = fix_paths(job)

        hadoop_arglist += job_args
        arglist.extend(hadoop_arglist)

        luigi.contrib.hadoop.run_and_track_hadoop_job(arglist)

        for a, b in tmp_files:
            a.move(b)
```