Sure! Here's the full corrected code for the `run_job` function:

```python
def run_job(self, job):
    ssh_config = job.ssh()
    if ssh_config:
        # ... omitted code ...

    else:
        arglist = []
        if not job.jar() or not os.path.exists(job.jar()):
            logger.error("Can't find jar: %s, full path %s",
                         job.jar() if job.jar() else "None",  # Handling NoneType
                         os.path.abspath(job.jar()) if job.jar() else "None")  # Handling NoneType
            raise HadoopJarJobError("job jar does not exist")
    
    # TODO(jcrobak): libjars, files, etc. Can refactor out of
    # hadoop.HadoopJobRunner
    hadoop_arglist = luigi.contrib.hdfs.load_hadoop_cmd() + ['jar', job.jar()]
    if job.main():
        hadoop_arglist.append(job.main())

    jobconfs = job.jobconfs()

    for jc in jobconfs:
        hadoop_arglist += ['-D' + jc]

    (tmp_files, job_args) = fix_paths(job)

    hadoop_arglist += job_args
    arglist.extend(hadoop_arglist)

    luigi.contrib.hadoop.run_and_track_hadoop_job(arglist)

    for a, b in tmp_files:
        a.move(b)
```