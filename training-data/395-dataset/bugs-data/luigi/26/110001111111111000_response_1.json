{
    "luigi": [
        {
            "bugID": 26,
            "bitvector": {
                "1.1.1": 1,
                "1.1.2": 1,
                "1.2.1": 0,
                "1.2.2": 0,
                "1.2.3": 0,
                "1.3.1": 1,
                "1.3.2": 1,
                "1.4.1": 1,
                "1.4.2": 1,
                "2.1.1": 1,
                "2.1.2": 1,
                "2.1.3": 1,
                "2.1.4": 1,
                "2.1.5": 1,
                "2.1.6": 1,
                "3.1.1": 0,
                "3.1.2": 0,
                "cot": 0
            },
            "strata": {
                "1": 1,
                "2": 0,
                "3": 1,
                "4": 1,
                "5": 1,
                "6": 0,
                "7": 0
            },
            "available_bitvector": {
                "1.1.1": 1,
                "1.1.2": 0,
                "1.2.1": 0,
                "1.2.2": 0,
                "1.2.3": 0,
                "1.3.1": 1,
                "1.3.2": 1,
                "1.4.1": 1,
                "1.4.2": 1,
                "2.1.1": 1,
                "2.1.2": 1,
                "2.1.3": 0,
                "2.1.4": 0,
                "2.1.5": 0,
                "2.1.6": 0,
                "3.1.1": 0,
                "3.1.2": 0,
                "cot": 0
            },
            "available_strata": {
                "1": 1,
                "2": 0,
                "3": 1,
                "4": 1,
                "5": 0,
                "6": 0,
                "7": 0
            },
            "start_line": 70,
            "file_name": "luigi/contrib/hadoop_jar.py",
            "replace_code": "def run_job(self, job):\n\n    ssh_config = job.ssh() or {}\n    host = ssh_config.get(\"host\", None)\n    key_file = ssh_config.get(\"key_file\", None)\n    username = ssh_config.get(\"username\", None)\n    jar_file = job.jar()\n    \n    if not host or not key_file or not username or not jar_file:\n        raise HadoopJarJobError(\"missing some config for HadoopRemoteJarJobRunner\")\n    \n    arglist = ['ssh', '-i', key_file, '-o', 'BatchMode=yes']  # no password prompts etc\n    \n    if ssh_config.get(\"no_host_key_check\", False):\n        arglist += ['-o', 'UserKnownHostsFile=/dev/null','-o', 'StrictHostKeyChecking=no']\n    \n    arglist.append('{}@{}'.format(username, host))\n    hadoop_arglist = luigi.contrib.hdfs.load_hadoop_cmd() + ['jar', jar_file]\n    \n    main_file = job.main()\n    if main_file:\n        hadoop_arglist.append(main_file)\n    \n    jobconfs = job.jobconfs() or []\n    \n    for jc in jobconfs:\n        hadoop_arglist += ['-D' + jc]\n    \n    (tmp_files, job_args) = fix_paths(job)\n    \n    hadoop_arglist += job_args\n    arglist.extend(hadoop_arglist)\n    \n    luigi.contrib.hadoop.run_and_track_hadoop_job(arglist)\n    \n    for a, b in tmp_files:\n        a.move(b)"
        }
    ]
}