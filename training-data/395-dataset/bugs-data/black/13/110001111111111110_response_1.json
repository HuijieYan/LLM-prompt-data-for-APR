{
    "black": [
        {
            "bugID": 13,
            "bitvector": {
                "1.1.1": 1,
                "1.1.2": 1,
                "1.2.1": 0,
                "1.2.2": 0,
                "1.2.3": 0,
                "1.3.1": 1,
                "1.3.2": 1,
                "1.4.1": 1,
                "1.4.2": 1,
                "2.1.1": 1,
                "2.1.2": 1,
                "2.1.3": 1,
                "2.1.4": 1,
                "2.1.5": 1,
                "2.1.6": 1,
                "3.1.1": 1,
                "3.1.2": 1,
                "cot": 0
            },
            "strata": {
                "1": 1,
                "2": 0,
                "3": 1,
                "4": 1,
                "5": 1,
                "6": 1,
                "7": 0
            },
            "available_bitvector": {
                "1.1.1": 1,
                "1.1.2": 1,
                "1.2.1": 0,
                "1.2.2": 0,
                "1.2.3": 0,
                "1.3.1": 1,
                "1.3.2": 0,
                "1.4.1": 1,
                "1.4.2": 1,
                "2.1.1": 1,
                "2.1.2": 1,
                "2.1.3": 0,
                "2.1.4": 0,
                "2.1.5": 0,
                "2.1.6": 0,
                "3.1.1": 1,
                "3.1.2": 1,
                "cot": 0
            },
            "available_strata": {
                "1": 1,
                "2": 0,
                "3": 1,
                "4": 1,
                "5": 0,
                "6": 1,
                "7": 0
            },
            "start_line": 337,
            "file_name": "mes/SSD2T/bgp_envs/repos/black_13/blib2to3/pgen2/tokenize.py",
            "replace_code": "def generate_tokens(readline):\n\n    lnum = parenlev = continued = 0\n    numchars = '0123456789'\n    contstr, needcont = '', 0\n    contline = None\n    indents = [0]\n    \n    # 'stashed' and 'async_*' are used for async/await parsing\n    stashed = None\n    async_def = False\n    async_def_indent = 0\n    async_def_nl = False\n    \n    while 1:                                   # loop over lines in stream\n        try:\n            line = readline()\n        except StopIteration:\n            line = ''\n        lnum = lnum + 1\n        pos, max = 0, len(line)\n    \n        if contstr:                            # continued string\n            if not line:\n                raise TokenError(\"EOF in multi-line string\", strstart)\n            endmatch = endprog.match(line)\n            if endmatch:\n                pos = end = endmatch.end(0)\n                yield (STRING, contstr + line[:end],\n                       strstart, (lnum, end), contline + line)\n                contstr, needcont = '', 0\n                contline = None\n            elif needcont and line[-2:] != '\\\\\\n' and line[-3:] != '\\\\\\r\\n':\n                yield (ERRORTOKEN, contstr + line,\n                           strstart, (lnum, len(line)), contline)\n                contstr = ''\n                contline = None\n                continue\n            else:\n                contstr = contstr + line\n                contline = contline + line\n                continue\n    \n        elif parenlev == 0 and not continued:  # new statement\n            if not line: break\n            column = 0\n            while pos < max:                   # measure leading whitespace\n                if line[pos] == ' ': column = column + 1\n                elif line[pos] == '\\t': column = (column//tabsize + 1)*tabsize\n                elif line[pos] == '\\f': column = 0\n                else: break\n                pos = pos + 1\n            if pos == max: break\n    \n            if stashed:\n                yield stashed\n                stashed = None\n    \n            if line[pos] in '\\r\\n':            # skip blank lines\n                yield (NL, line[pos:], (lnum, pos), (lnum, len(line)), line)\n                continue\n    \n            if line[pos] == '#':               # skip comments\n                comment_token = line[pos:].rstrip('\\r\\n')\n                nl_pos = pos + len(comment_token)\n                yield (COMMENT, comment_token,\n                        (lnum, pos), (lnum, pos + len(comment_token)), line)\n                yield (NL, line[nl_pos:],\n                        (lnum, nl_pos), (lnum, len(line)), line)\n                continue\n    \n            if column > indents[-1]:           # count indents\n                indents.append(column)\n                yield (INDENT, line[:pos], (lnum, 0), (lnum, pos), line)\n    \n            while column < indents[-1]:        # count dedents\n                if column not in indents:\n                    raise IndentationError(\n                        \"unindent does not match any outer indentation level\",\n                        (\"<tokenize>\", lnum, pos, line))\n                indents = indents[:-1]\n    \n                if async_def and async_def_indent >= indents[-1]:\n                    async_def = False\n                    async_def_nl = False\n                    async_def_indent = 0\n    \n                yield (DEDENT, '', (lnum, pos), (lnum, pos), line)\n    \n            if async_def and async_def_nl and async_def_indent >= indents[-1]:\n                async_def = False\n                async_def_nl = False\n                async_def_indent = 0\n    \n        else:                                  # continued statement\n            if not line:\n                raise TokenError(\"EOF in multi-line statement\", (lnum, 0))\n            continued = 0"
        }
    ]
}