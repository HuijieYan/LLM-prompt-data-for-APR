Please fix the function/method provided below and provide the corrected function/method as the output.


# Buggy function source code
```python
# file name: /Volumes/SSD2T/bgp_envs/repos/scrapy_21/scrapy/downloadermiddlewares/robotstxt.py

# class declaration containing the buggy function
class RobotsTxtMiddleware(object):
    # ... omitted code ...




    # this is the buggy function you need to fix
    def _robots_error(self, failure, netloc):
        self._parsers.pop(netloc).callback(None)
    
```

# Variable runtime value and type inside buggy function
## Buggy case 1
### input parameter runtime value and type for buggy function
self._parsers, value: `{'site.local': <Deferred at 0x105202970>}`, type: `dict`

self, value: `<scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware object at 0x1052027c0>`, type: `RobotsTxtMiddleware`

netloc, value: `'site.local'`, type: `str`

### variable runtime value and type before buggy function return
rp_dfd, value: `<Deferred at 0x105202970 current result: None>`, type: `Deferred`

self._parsers, value: `{'site.local': None}`, type: `dict`

rp_dfd.callback, value: `<bound method Deferred.callback of <Deferred at 0x105202970 current result: None>>`, type: `method`



# Expected variable value and type in tests
## Expected case 1
### Input parameter value and type
self._parsers, value: `{'site.local': <Deferred at 0x108d5b610>}`, type: `dict`

self, value: `<scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware object at 0x108d5b460>`, type: `RobotsTxtMiddleware`

netloc, value: `'site.local'`, type: `str`

### Expected variable value and type before function return
self._parsers, expected value: `{}`, type: `dict`






# A GitHub issue title for this bug
```text
KeyError in robotstxt middleware
```

## The associated detailed issue description
```text
I'm getting these errors in robots.txt middleware:

2016-01-27 16:18:21 [scrapy.core.scraper] ERROR: Error downloading <GET http://yellowpages.co.th>
Traceback (most recent call last):
  File "/Users/kmike/envs/scraping/lib/python2.7/site-packages/twisted/internet/defer.py", line 150, in maybeDeferred
    result = f(*args, **kw)
  File "/Users/kmike/svn/scrapy/scrapy/downloadermiddlewares/robotstxt.py", line 65, in robot_parser
    if isinstance(self._parsers[netloc], Deferred):
KeyError: 'yellowpages.co.th'
It looks like #1473 caused it (I can't get this issue in Scrapy 1.0.4, but it present in Scrapy master). It happens when page failed to download and HTTP cache is enabled. I haven't debugged it further.
```



