{
    "1.1.1": "def quantile(self, q=0.5, interpolation: str = \"linear\"):\n    \n    from pandas import concat\n\n    def pre_processor(vals: np.ndarray) -> Tuple[np.ndarray, Optional[Type]]:\n        if is_object_dtype(vals):\n            raise TypeError(\n                \"'quantile' cannot be performed against 'object' dtypes!\"\n            )\n\n        inference = None\n        if is_integer_dtype(vals):\n            inference = np.int64\n        elif is_datetime64_dtype(vals):\n            inference = \"datetime64[ns]\"\n            vals = vals.astype(np.float)\n\n        return vals, inference\n\n    def post_processor(vals: np.ndarray, inference: Optional[Type]) -> np.ndarray:\n        if inference:\n            # Check for edge case\n            if not (\n                is_integer_dtype(inference)\n                and interpolation in {\"linear\", \"midpoint\"}\n            ):\n                vals = vals.astype(inference)\n\n        return vals\n\n    if is_scalar(q):\n        return self._get_cythonized_result(\n            \"group_quantile\",\n            aggregate=True,\n            needs_values=True,\n            needs_mask=True,\n            cython_dtype=np.dtype(np.float64),\n            pre_processing=pre_processor,\n            post_processing=post_processor,\n            q=q,\n            interpolation=interpolation,\n        )\n    else:\n        results = [\n            self._get_cythonized_result(\n                \"group_quantile\",\n                aggregate=True,\n                needs_values=True,\n                needs_mask=True,\n                cython_dtype=np.dtype(np.float64),\n                pre_processing=pre_processor,\n                post_processing=post_processor,\n                q=qi,\n                interpolation=interpolation,\n            )\n            for qi in q\n        ]\n        result = concat(results, axis=0, keys=q)\n        # fix levels to place quantiles on the inside\n        # TODO(GH-10710): Ideally, we could write this as\n        #  >>> result.stack(0).loc[pd.IndexSlice[:, ..., q], :]\n        #  but this hits https://github.com/pandas-dev/pandas/issues/10710\n        #  which doesn't reorder the list-like `q` on the inner level.\n        order = np.roll(list(range(result.index.nlevels)), -1)\n        result = result.reorder_levels(order)\n        result = result.reindex(q, level=-1)\n\n        # fix order.\n        hi = len(q) * self.ngroups\n        arr = np.arange(0, hi, self.ngroups)\n        arrays = []\n\n        for i in range(self.ngroups):\n            arr2 = arr + i\n            arrays.append(arr2)\n\n        indices = np.concatenate(arrays)\n        assert len(indices) == len(result)\n        return result.take(indices)\n",
    "1.1.2": "Return group values at the given quantile, a la numpy.percentile.\n\nParameters\n----------\nq : float or array-like, default 0.5 (50% quantile)\n    Value(s) between 0 and 1 providing the quantile(s) to compute.\ninterpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}\n    Method to use when the desired quantile falls between two points.\n\nReturns\n-------\nSeries or DataFrame\n    Return type determined by caller of GroupBy object.\n\nSee Also\n--------\nSeries.quantile : Similar method for Series.\nDataFrame.quantile : Similar method for DataFrame.\nnumpy.percentile : NumPy method to compute qth percentile.\n\nExamples\n--------\n>>> df = pd.DataFrame([\n...     ['a', 1], ['a', 2], ['a', 3],\n...     ['b', 1], ['b', 3], ['b', 5]\n... ], columns=['key', 'val'])\n>>> df.groupby('key').quantile()\n    val\nkey\na    2.0\nb    3.0",
    "1.2.1": "class GroupBy(_GroupBy)",
    "1.2.2": "Class for grouping and aggregating relational data.\n\nSee aggregate, transform, and apply functions on this object.\n\nIt's easiest to use obj.groupby(...) to use GroupBy, but you can also do:\n\n::\n\n    grouped = groupby(obj, ...)\n\nParameters\n----------\nobj : pandas object\naxis : int, default 0\nlevel : int, default None\n    Level of MultiIndex\ngroupings : list of Grouping objects\n    Most users should ignore this\nexclusions : array-like, optional\n    List of columns to exclude\nname : str\n    Most users should ignore this\n\nReturns\n-------\n**Attributes**\ngroups : dict\n    {group name -> group labels}\nlen(grouped) : int\n    Number of groups\n\nNotes\n-----\nAfter grouping, see aggregate, apply, and transform functions. Here are\nsome other brief notes about usage. When grouping by multiple groups, the\nresult index will be a MultiIndex (hierarchical) by default.\n\nIteration produces (key, group) tuples, i.e. chunking the data by group. So\nyou can write code like:\n\n::\n\n    grouped = obj.groupby(keys, axis=axis)\n    for key, group in grouped:\n        # do something with the data\n\nFunction calls on GroupBy, if not specially implemented, \"dispatch\" to the\ngrouped data. So if you group a DataFrame and wish to invoke the std()\nmethod on each group, you can simply do:\n\n::\n\n    df.groupby(mapper).std()\n\nrather than\n\n::\n\n    df.groupby(mapper).aggregate(np.std)\n\nYou can pass arguments to these \"wrapped\" functions, too.\n\nSee the online documentation for full exposition on these topics and much\nmore",
    "1.2.3": [
        "_get_cythonized_result(self, how: str, cython_dtype: np.dtype, aggregate: bool=False, needs_values: bool=False, needs_mask: bool=False, needs_ngroups: bool=False, result_is_index: bool=False, pre_processing=None, post_processing=None, **kwargs)",
        "pre_processor(vals: np.ndarray) -> Tuple[np.ndarray, Optional[Type]]",
        "post_processor(vals: np.ndarray, inference: Optional[Type]) -> np.ndarray"
    ],
    "1.2.4": null,
    "1.2.5": null,
    "1.3.1": "pandas/core/groupby/groupby.py",
    "1.3.2": [
        "ngroups(self)",
        "indices(self)",
        "_get_cythonized_result(self, how: str, cython_dtype: np.dtype, aggregate: bool=False, needs_values: bool=False, needs_mask: bool=False, needs_ngroups: bool=False, result_is_index: bool=False, pre_processing=None, post_processing=None, **kwargs)",
        "pre_processor(vals: np.ndarray) -> Tuple[np.ndarray, Optional[Type]]",
        "post_processor(vals: np.ndarray, inference: Optional[Type]) -> np.ndarray"
    ],
    "1.4.1": [
        "@pytest.mark.parametrize(\"frame_size\", [(2, 3), (100, 10)])\n@pytest.mark.parametrize(\"groupby\", [[0], [0, 1]])\n@pytest.mark.parametrize(\"q\", [[0.5, 0.6]])\ndef test_groupby_quantile_with_arraylike_q_and_int_columns(frame_size, groupby, q):\n    # GH30289\n    nrow, ncol = frame_size\n    df = pd.DataFrame(\n        np.array([ncol * [_ % 4] for _ in range(nrow)]), columns=range(ncol)\n    )\n\n    idx_levels = [list(range(min(nrow, 4)))] * len(groupby) + [q]\n    idx_codes = [[x for x in range(min(nrow, 4)) for _ in q]] * len(groupby) + [\n        list(range(len(q))) * min(nrow, 4)\n    ]\n    expected_index = pd.MultiIndex(\n        levels=idx_levels, codes=idx_codes, names=groupby + [None]\n    )\n    expected_values = [\n        [float(x)] * (ncol - len(groupby)) for x in range(min(nrow, 4)) for _ in q\n    ]\n    expected_columns = [x for x in range(ncol) if x not in groupby]\n    expected = pd.DataFrame(\n        expected_values, index=expected_index, columns=expected_columns\n    )\n    result = df.groupby(groupby).quantile(q)\n\n    tm.assert_frame_equal(result, expected)",
        "@pytest.mark.parametrize(\"frame_size\", [(2, 3), (100, 10)])\n@pytest.mark.parametrize(\"groupby\", [[0], [0, 1]])\n@pytest.mark.parametrize(\"q\", [[0.5, 0.6]])\ndef test_groupby_quantile_with_arraylike_q_and_int_columns(frame_size, groupby, q):\n    # GH30289\n    nrow, ncol = frame_size\n    df = pd.DataFrame(\n        np.array([ncol * [_ % 4] for _ in range(nrow)]), columns=range(ncol)\n    )\n\n    idx_levels = [list(range(min(nrow, 4)))] * len(groupby) + [q]\n    idx_codes = [[x for x in range(min(nrow, 4)) for _ in q]] * len(groupby) + [\n        list(range(len(q))) * min(nrow, 4)\n    ]\n    expected_index = pd.MultiIndex(\n        levels=idx_levels, codes=idx_codes, names=groupby + [None]\n    )\n    expected_values = [\n        [float(x)] * (ncol - len(groupby)) for x in range(min(nrow, 4)) for _ in q\n    ]\n    expected_columns = [x for x in range(ncol) if x not in groupby]\n    expected = pd.DataFrame(\n        expected_values, index=expected_index, columns=expected_columns\n    )\n    result = df.groupby(groupby).quantile(q)\n\n    tm.assert_frame_equal(result, expected)",
        "@pytest.mark.parametrize(\"frame_size\", [(2, 3), (100, 10)])\n@pytest.mark.parametrize(\"groupby\", [[0], [0, 1]])\n@pytest.mark.parametrize(\"q\", [[0.5, 0.6]])\ndef test_groupby_quantile_with_arraylike_q_and_int_columns(frame_size, groupby, q):\n    # GH30289\n    nrow, ncol = frame_size\n    df = pd.DataFrame(\n        np.array([ncol * [_ % 4] for _ in range(nrow)]), columns=range(ncol)\n    )\n\n    idx_levels = [list(range(min(nrow, 4)))] * len(groupby) + [q]\n    idx_codes = [[x for x in range(min(nrow, 4)) for _ in q]] * len(groupby) + [\n        list(range(len(q))) * min(nrow, 4)\n    ]\n    expected_index = pd.MultiIndex(\n        levels=idx_levels, codes=idx_codes, names=groupby + [None]\n    )\n    expected_values = [\n        [float(x)] * (ncol - len(groupby)) for x in range(min(nrow, 4)) for _ in q\n    ]\n    expected_columns = [x for x in range(ncol) if x not in groupby]\n    expected = pd.DataFrame(\n        expected_values, index=expected_index, columns=expected_columns\n    )\n    result = df.groupby(groupby).quantile(q)\n\n    tm.assert_frame_equal(result, expected)",
        "@pytest.mark.parametrize(\"frame_size\", [(2, 3), (100, 10)])\n@pytest.mark.parametrize(\"groupby\", [[0], [0, 1]])\n@pytest.mark.parametrize(\"q\", [[0.5, 0.6]])\ndef test_groupby_quantile_with_arraylike_q_and_int_columns(frame_size, groupby, q):\n    # GH30289\n    nrow, ncol = frame_size\n    df = pd.DataFrame(\n        np.array([ncol * [_ % 4] for _ in range(nrow)]), columns=range(ncol)\n    )\n\n    idx_levels = [list(range(min(nrow, 4)))] * len(groupby) + [q]\n    idx_codes = [[x for x in range(min(nrow, 4)) for _ in q]] * len(groupby) + [\n        list(range(len(q))) * min(nrow, 4)\n    ]\n    expected_index = pd.MultiIndex(\n        levels=idx_levels, codes=idx_codes, names=groupby + [None]\n    )\n    expected_values = [\n        [float(x)] * (ncol - len(groupby)) for x in range(min(nrow, 4)) for _ in q\n    ]\n    expected_columns = [x for x in range(ncol) if x not in groupby]\n    expected = pd.DataFrame(\n        expected_values, index=expected_index, columns=expected_columns\n    )\n    result = df.groupby(groupby).quantile(q)\n\n    tm.assert_frame_equal(result, expected)"
    ],
    "1.4.2": [
        "pandas/tests/groupby/test_function.py",
        "pandas/tests/groupby/test_function.py",
        "pandas/tests/groupby/test_function.py",
        "pandas/tests/groupby/test_function.py"
    ],
    "2.1.1": [
        [
            "E           AssertionError"
        ],
        [
            "E           AssertionError"
        ],
        [
            "E           AssertionError"
        ],
        [
            "E           AssertionError"
        ]
    ],
    "2.1.2": [
        [
            "frame_size = (2, 3), groupby = [0], q = [0.5, 0.6]\n\n    @pytest.mark.parametrize(\"frame_size\", [(2, 3), (100, 10)])\n    @pytest.mark.parametrize(\"groupby\", [[0], [0, 1]])\n    @pytest.mark.parametrize(\"q\", [[0.5, 0.6]])\n    def test_groupby_quantile_with_arraylike_q_and_int_columns(frame_size, groupby, q):\n        # GH30289\n        nrow, ncol = frame_size\n        df = pd.DataFrame(\n            np.array([ncol * [_ % 4] for _ in range(nrow)]), columns=range(ncol)\n        )\n    \n        idx_levels = [list(range(min(nrow, 4)))] * len(groupby) + [q]\n        idx_codes = [[x for x in range(min(nrow, 4)) for _ in q]] * len(groupby) + [\n            list(range(len(q))) * min(nrow, 4)\n        ]\n        expected_index = pd.MultiIndex(\n            levels=idx_levels, codes=idx_codes, names=groupby + [None]\n        )\n        expected_values = [\n            [float(x)] * (ncol - len(groupby)) for x in range(min(nrow, 4)) for _ in q\n        ]\n        expected_columns = [x for x in range(ncol) if x not in groupby]\n        expected = pd.DataFrame(\n            expected_values, index=expected_index, columns=expected_columns\n        )\n>       result = df.groupby(groupby).quantile(q)\n\npandas/tests/groupby/test_function.py:1425: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <pandas.core.groupby.generic.DataFrameGroupBy object at 0x12066df40>\nq = [0.5, 0.6], interpolation = 'linear'\n\n    def quantile(self, q=0.5, interpolation: str = \"linear\"):\n        \"\"\"\n        Return group values at the given quantile, a la numpy.percentile.\n    \n        Parameters\n        ----------\n        q : float or array-like, default 0.5 (50% quantile)\n            Value(s) between 0 and 1 providing the quantile(s) to compute.\n        interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}\n            Method to use when the desired quantile falls between two points.\n    \n        Returns\n        -------\n        Series or DataFrame\n            Return type determined by caller of GroupBy object.\n    \n        See Also\n        --------\n        Series.quantile : Similar method for Series.\n        DataFrame.quantile : Similar method for DataFrame.\n        numpy.percentile : NumPy method to compute qth percentile.\n    \n        Examples\n        --------\n        >>> df = pd.DataFrame([\n        ...     ['a', 1], ['a', 2], ['a', 3],\n        ...     ['b', 1], ['b', 3], ['b', 5]\n        ... ], columns=['key', 'val'])\n        >>> df.groupby('key').quantile()\n            val\n        key\n        a    2.0\n        b    3.0\n        \"\"\"\n        from pandas import concat\n    \n        def pre_processor(vals: np.ndarray) -> Tuple[np.ndarray, Optional[Type]]:\n            if is_object_dtype(vals):\n                raise TypeError(\n                    \"'quantile' cannot be performed against 'object' dtypes!\"\n                )\n    \n            inference = None\n            if is_integer_dtype(vals):\n                inference = np.int64\n            elif is_datetime64_dtype(vals):\n                inference = \"datetime64[ns]\"\n                vals = vals.astype(np.float)\n    \n            return vals, inference\n    \n        def post_processor(vals: np.ndarray, inference: Optional[Type]) -> np.ndarray:\n            if inference:\n                # Check for edge case\n                if not (\n                    is_integer_dtype(inference)\n                    and interpolation in {\"linear\", \"midpoint\"}\n                ):\n                    vals = vals.astype(inference)\n    \n            return vals\n    \n        if is_scalar(q):\n            return self._get_cythonized_result(\n                \"group_quantile\",\n                aggregate=True,\n                needs_values=True,\n                needs_mask=True,\n                cython_dtype=np.dtype(np.float64),\n                pre_processing=pre_processor,\n                post_processing=post_processor,\n                q=q,\n                interpolation=interpolation,\n            )\n        else:\n            results = [\n                self._get_cythonized_result(\n                    \"group_quantile\",\n                    aggregate=True,\n                    needs_values=True,\n                    needs_mask=True,\n                    cython_dtype=np.dtype(np.float64),\n                    pre_processing=pre_processor,\n                    post_processing=post_processor,\n                    q=qi,\n                    interpolation=interpolation,\n                )\n                for qi in q\n            ]\n            result = concat(results, axis=0, keys=q)\n            # fix levels to place quantiles on the inside\n            # TODO(GH-10710): Ideally, we could write this as\n            #  >>> result.stack(0).loc[pd.IndexSlice[:, ..., q], :]\n            #  but this hits https://github.com/pandas-dev/pandas/issues/10710\n            #  which doesn't reorder the list-like `q` on the inner level.\n            order = np.roll(list(range(result.index.nlevels)), -1)\n            result = result.reorder_levels(order)\n            result = result.reindex(q, level=-1)\n    \n            # fix order.\n            hi = len(q) * self.ngroups\n            arr = np.arange(0, hi, self.ngroups)\n            arrays = []\n    \n            for i in range(self.ngroups):\n                arr2 = arr + i\n                arrays.append(arr2)\n    \n            indices = np.concatenate(arrays)\n>           assert len(indices) == len(result)",
            "\npandas/core/groupby/groupby.py:1954: AssertionError"
        ],
        [
            "frame_size = (100, 10), groupby = [0], q = [0.5, 0.6]\n\n    @pytest.mark.parametrize(\"frame_size\", [(2, 3), (100, 10)])\n    @pytest.mark.parametrize(\"groupby\", [[0], [0, 1]])\n    @pytest.mark.parametrize(\"q\", [[0.5, 0.6]])\n    def test_groupby_quantile_with_arraylike_q_and_int_columns(frame_size, groupby, q):\n        # GH30289\n        nrow, ncol = frame_size\n        df = pd.DataFrame(\n            np.array([ncol * [_ % 4] for _ in range(nrow)]), columns=range(ncol)\n        )\n    \n        idx_levels = [list(range(min(nrow, 4)))] * len(groupby) + [q]\n        idx_codes = [[x for x in range(min(nrow, 4)) for _ in q]] * len(groupby) + [\n            list(range(len(q))) * min(nrow, 4)\n        ]\n        expected_index = pd.MultiIndex(\n            levels=idx_levels, codes=idx_codes, names=groupby + [None]\n        )\n        expected_values = [\n            [float(x)] * (ncol - len(groupby)) for x in range(min(nrow, 4)) for _ in q\n        ]\n        expected_columns = [x for x in range(ncol) if x not in groupby]\n        expected = pd.DataFrame(\n            expected_values, index=expected_index, columns=expected_columns\n        )\n>       result = df.groupby(groupby).quantile(q)\n\npandas/tests/groupby/test_function.py:1425: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <pandas.core.groupby.generic.DataFrameGroupBy object at 0x12069a370>\nq = [0.5, 0.6], interpolation = 'linear'\n\n    def quantile(self, q=0.5, interpolation: str = \"linear\"):\n        \"\"\"\n        Return group values at the given quantile, a la numpy.percentile.\n    \n        Parameters\n        ----------\n        q : float or array-like, default 0.5 (50% quantile)\n            Value(s) between 0 and 1 providing the quantile(s) to compute.\n        interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}\n            Method to use when the desired quantile falls between two points.\n    \n        Returns\n        -------\n        Series or DataFrame\n            Return type determined by caller of GroupBy object.\n    \n        See Also\n        --------\n        Series.quantile : Similar method for Series.\n        DataFrame.quantile : Similar method for DataFrame.\n        numpy.percentile : NumPy method to compute qth percentile.\n    \n        Examples\n        --------\n        >>> df = pd.DataFrame([\n        ...     ['a', 1], ['a', 2], ['a', 3],\n        ...     ['b', 1], ['b', 3], ['b', 5]\n        ... ], columns=['key', 'val'])\n        >>> df.groupby('key').quantile()\n            val\n        key\n        a    2.0\n        b    3.0\n        \"\"\"\n        from pandas import concat\n    \n        def pre_processor(vals: np.ndarray) -> Tuple[np.ndarray, Optional[Type]]:\n            if is_object_dtype(vals):\n                raise TypeError(\n                    \"'quantile' cannot be performed against 'object' dtypes!\"\n                )\n    \n            inference = None\n            if is_integer_dtype(vals):\n                inference = np.int64\n            elif is_datetime64_dtype(vals):\n                inference = \"datetime64[ns]\"\n                vals = vals.astype(np.float)\n    \n            return vals, inference\n    \n        def post_processor(vals: np.ndarray, inference: Optional[Type]) -> np.ndarray:\n            if inference:\n                # Check for edge case\n                if not (\n                    is_integer_dtype(inference)\n                    and interpolation in {\"linear\", \"midpoint\"}\n                ):\n                    vals = vals.astype(inference)\n    \n            return vals\n    \n        if is_scalar(q):\n            return self._get_cythonized_result(\n                \"group_quantile\",\n                aggregate=True,\n                needs_values=True,\n                needs_mask=True,\n                cython_dtype=np.dtype(np.float64),\n                pre_processing=pre_processor,\n                post_processing=post_processor,\n                q=q,\n                interpolation=interpolation,\n            )\n        else:\n            results = [\n                self._get_cythonized_result(\n                    \"group_quantile\",\n                    aggregate=True,\n                    needs_values=True,\n                    needs_mask=True,\n                    cython_dtype=np.dtype(np.float64),\n                    pre_processing=pre_processor,\n                    post_processing=post_processor,\n                    q=qi,\n                    interpolation=interpolation,\n                )\n                for qi in q\n            ]\n            result = concat(results, axis=0, keys=q)\n            # fix levels to place quantiles on the inside\n            # TODO(GH-10710): Ideally, we could write this as\n            #  >>> result.stack(0).loc[pd.IndexSlice[:, ..., q], :]\n            #  but this hits https://github.com/pandas-dev/pandas/issues/10710\n            #  which doesn't reorder the list-like `q` on the inner level.\n            order = np.roll(list(range(result.index.nlevels)), -1)\n            result = result.reorder_levels(order)\n            result = result.reindex(q, level=-1)\n    \n            # fix order.\n            hi = len(q) * self.ngroups\n            arr = np.arange(0, hi, self.ngroups)\n            arrays = []\n    \n            for i in range(self.ngroups):\n                arr2 = arr + i\n                arrays.append(arr2)\n    \n            indices = np.concatenate(arrays)\n>           assert len(indices) == len(result)",
            "\npandas/core/groupby/groupby.py:1954: AssertionError"
        ],
        [
            "frame_size = (2, 3), groupby = [0, 1], q = [0.5, 0.6]\n\n    @pytest.mark.parametrize(\"frame_size\", [(2, 3), (100, 10)])\n    @pytest.mark.parametrize(\"groupby\", [[0], [0, 1]])\n    @pytest.mark.parametrize(\"q\", [[0.5, 0.6]])\n    def test_groupby_quantile_with_arraylike_q_and_int_columns(frame_size, groupby, q):\n        # GH30289\n        nrow, ncol = frame_size\n        df = pd.DataFrame(\n            np.array([ncol * [_ % 4] for _ in range(nrow)]), columns=range(ncol)\n        )\n    \n        idx_levels = [list(range(min(nrow, 4)))] * len(groupby) + [q]\n        idx_codes = [[x for x in range(min(nrow, 4)) for _ in q]] * len(groupby) + [\n            list(range(len(q))) * min(nrow, 4)\n        ]\n        expected_index = pd.MultiIndex(\n            levels=idx_levels, codes=idx_codes, names=groupby + [None]\n        )\n        expected_values = [\n            [float(x)] * (ncol - len(groupby)) for x in range(min(nrow, 4)) for _ in q\n        ]\n        expected_columns = [x for x in range(ncol) if x not in groupby]\n        expected = pd.DataFrame(\n            expected_values, index=expected_index, columns=expected_columns\n        )\n>       result = df.groupby(groupby).quantile(q)\n\npandas/tests/groupby/test_function.py:1425: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <pandas.core.groupby.generic.DataFrameGroupBy object at 0x120585e80>\nq = [0.5, 0.6], interpolation = 'linear'\n\n    def quantile(self, q=0.5, interpolation: str = \"linear\"):\n        \"\"\"\n        Return group values at the given quantile, a la numpy.percentile.\n    \n        Parameters\n        ----------\n        q : float or array-like, default 0.5 (50% quantile)\n            Value(s) between 0 and 1 providing the quantile(s) to compute.\n        interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}\n            Method to use when the desired quantile falls between two points.\n    \n        Returns\n        -------\n        Series or DataFrame\n            Return type determined by caller of GroupBy object.\n    \n        See Also\n        --------\n        Series.quantile : Similar method for Series.\n        DataFrame.quantile : Similar method for DataFrame.\n        numpy.percentile : NumPy method to compute qth percentile.\n    \n        Examples\n        --------\n        >>> df = pd.DataFrame([\n        ...     ['a', 1], ['a', 2], ['a', 3],\n        ...     ['b', 1], ['b', 3], ['b', 5]\n        ... ], columns=['key', 'val'])\n        >>> df.groupby('key').quantile()\n            val\n        key\n        a    2.0\n        b    3.0\n        \"\"\"\n        from pandas import concat\n    \n        def pre_processor(vals: np.ndarray) -> Tuple[np.ndarray, Optional[Type]]:\n            if is_object_dtype(vals):\n                raise TypeError(\n                    \"'quantile' cannot be performed against 'object' dtypes!\"\n                )\n    \n            inference = None\n            if is_integer_dtype(vals):\n                inference = np.int64\n            elif is_datetime64_dtype(vals):\n                inference = \"datetime64[ns]\"\n                vals = vals.astype(np.float)\n    \n            return vals, inference\n    \n        def post_processor(vals: np.ndarray, inference: Optional[Type]) -> np.ndarray:\n            if inference:\n                # Check for edge case\n                if not (\n                    is_integer_dtype(inference)\n                    and interpolation in {\"linear\", \"midpoint\"}\n                ):\n                    vals = vals.astype(inference)\n    \n            return vals\n    \n        if is_scalar(q):\n            return self._get_cythonized_result(\n                \"group_quantile\",\n                aggregate=True,\n                needs_values=True,\n                needs_mask=True,\n                cython_dtype=np.dtype(np.float64),\n                pre_processing=pre_processor,\n                post_processing=post_processor,\n                q=q,\n                interpolation=interpolation,\n            )\n        else:\n            results = [\n                self._get_cythonized_result(\n                    \"group_quantile\",\n                    aggregate=True,\n                    needs_values=True,\n                    needs_mask=True,\n                    cython_dtype=np.dtype(np.float64),\n                    pre_processing=pre_processor,\n                    post_processing=post_processor,\n                    q=qi,\n                    interpolation=interpolation,\n                )\n                for qi in q\n            ]\n            result = concat(results, axis=0, keys=q)\n            # fix levels to place quantiles on the inside\n            # TODO(GH-10710): Ideally, we could write this as\n            #  >>> result.stack(0).loc[pd.IndexSlice[:, ..., q], :]\n            #  but this hits https://github.com/pandas-dev/pandas/issues/10710\n            #  which doesn't reorder the list-like `q` on the inner level.\n            order = np.roll(list(range(result.index.nlevels)), -1)\n            result = result.reorder_levels(order)\n            result = result.reindex(q, level=-1)\n    \n            # fix order.\n            hi = len(q) * self.ngroups\n            arr = np.arange(0, hi, self.ngroups)\n            arrays = []\n    \n            for i in range(self.ngroups):\n                arr2 = arr + i\n                arrays.append(arr2)\n    \n            indices = np.concatenate(arrays)\n>           assert len(indices) == len(result)",
            "\npandas/core/groupby/groupby.py:1954: AssertionError"
        ],
        [
            "frame_size = (100, 10), groupby = [0, 1], q = [0.5, 0.6]\n\n    @pytest.mark.parametrize(\"frame_size\", [(2, 3), (100, 10)])\n    @pytest.mark.parametrize(\"groupby\", [[0], [0, 1]])\n    @pytest.mark.parametrize(\"q\", [[0.5, 0.6]])\n    def test_groupby_quantile_with_arraylike_q_and_int_columns(frame_size, groupby, q):\n        # GH30289\n        nrow, ncol = frame_size\n        df = pd.DataFrame(\n            np.array([ncol * [_ % 4] for _ in range(nrow)]), columns=range(ncol)\n        )\n    \n        idx_levels = [list(range(min(nrow, 4)))] * len(groupby) + [q]\n        idx_codes = [[x for x in range(min(nrow, 4)) for _ in q]] * len(groupby) + [\n            list(range(len(q))) * min(nrow, 4)\n        ]\n        expected_index = pd.MultiIndex(\n            levels=idx_levels, codes=idx_codes, names=groupby + [None]\n        )\n        expected_values = [\n            [float(x)] * (ncol - len(groupby)) for x in range(min(nrow, 4)) for _ in q\n        ]\n        expected_columns = [x for x in range(ncol) if x not in groupby]\n        expected = pd.DataFrame(\n            expected_values, index=expected_index, columns=expected_columns\n        )\n>       result = df.groupby(groupby).quantile(q)\n\npandas/tests/groupby/test_function.py:1425: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <pandas.core.groupby.generic.DataFrameGroupBy object at 0x12080dac0>\nq = [0.5, 0.6], interpolation = 'linear'\n\n    def quantile(self, q=0.5, interpolation: str = \"linear\"):\n        \"\"\"\n        Return group values at the given quantile, a la numpy.percentile.\n    \n        Parameters\n        ----------\n        q : float or array-like, default 0.5 (50% quantile)\n            Value(s) between 0 and 1 providing the quantile(s) to compute.\n        interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}\n            Method to use when the desired quantile falls between two points.\n    \n        Returns\n        -------\n        Series or DataFrame\n            Return type determined by caller of GroupBy object.\n    \n        See Also\n        --------\n        Series.quantile : Similar method for Series.\n        DataFrame.quantile : Similar method for DataFrame.\n        numpy.percentile : NumPy method to compute qth percentile.\n    \n        Examples\n        --------\n        >>> df = pd.DataFrame([\n        ...     ['a', 1], ['a', 2], ['a', 3],\n        ...     ['b', 1], ['b', 3], ['b', 5]\n        ... ], columns=['key', 'val'])\n        >>> df.groupby('key').quantile()\n            val\n        key\n        a    2.0\n        b    3.0\n        \"\"\"\n        from pandas import concat\n    \n        def pre_processor(vals: np.ndarray) -> Tuple[np.ndarray, Optional[Type]]:\n            if is_object_dtype(vals):\n                raise TypeError(\n                    \"'quantile' cannot be performed against 'object' dtypes!\"\n                )\n    \n            inference = None\n            if is_integer_dtype(vals):\n                inference = np.int64\n            elif is_datetime64_dtype(vals):\n                inference = \"datetime64[ns]\"\n                vals = vals.astype(np.float)\n    \n            return vals, inference\n    \n        def post_processor(vals: np.ndarray, inference: Optional[Type]) -> np.ndarray:\n            if inference:\n                # Check for edge case\n                if not (\n                    is_integer_dtype(inference)\n                    and interpolation in {\"linear\", \"midpoint\"}\n                ):\n                    vals = vals.astype(inference)\n    \n            return vals\n    \n        if is_scalar(q):\n            return self._get_cythonized_result(\n                \"group_quantile\",\n                aggregate=True,\n                needs_values=True,\n                needs_mask=True,\n                cython_dtype=np.dtype(np.float64),\n                pre_processing=pre_processor,\n                post_processing=post_processor,\n                q=q,\n                interpolation=interpolation,\n            )\n        else:\n            results = [\n                self._get_cythonized_result(\n                    \"group_quantile\",\n                    aggregate=True,\n                    needs_values=True,\n                    needs_mask=True,\n                    cython_dtype=np.dtype(np.float64),\n                    pre_processing=pre_processor,\n                    post_processing=post_processor,\n                    q=qi,\n                    interpolation=interpolation,\n                )\n                for qi in q\n            ]\n            result = concat(results, axis=0, keys=q)\n            # fix levels to place quantiles on the inside\n            # TODO(GH-10710): Ideally, we could write this as\n            #  >>> result.stack(0).loc[pd.IndexSlice[:, ..., q], :]\n            #  but this hits https://github.com/pandas-dev/pandas/issues/10710\n            #  which doesn't reorder the list-like `q` on the inner level.\n            order = np.roll(list(range(result.index.nlevels)), -1)\n            result = result.reorder_levels(order)\n            result = result.reindex(q, level=-1)\n    \n            # fix order.\n            hi = len(q) * self.ngroups\n            arr = np.arange(0, hi, self.ngroups)\n            arrays = []\n    \n            for i in range(self.ngroups):\n                arr2 = arr + i\n                arrays.append(arr2)\n    \n            indices = np.concatenate(arrays)\n>           assert len(indices) == len(result)",
            "\npandas/core/groupby/groupby.py:1954: AssertionError"
        ]
    ],
    "2.1.3": [
        [
            {
                "interpolation": {
                    "value": "'linear'",
                    "shape": "6",
                    "omitted": false
                },
                "q": {
                    "value": "[0.5, 0.6]",
                    "shape": "2",
                    "omitted": false
                },
                "self.ngroups": {
                    "value": "2",
                    "shape": null,
                    "omitted": false
                }
            },
            {
                "vals": {
                    "value": "array([0, 1])",
                    "shape": "(2,)",
                    "omitted": false
                }
            }
        ],
        [
            {
                "interpolation": {
                    "value": "'linear'",
                    "shape": "6",
                    "omitted": false
                },
                "q": {
                    "value": "[0.5, 0.6]",
                    "shape": "2",
                    "omitted": false
                },
                "self.ngroups": {
                    "value": "4",
                    "shape": null,
                    "omitted": false
                }
            },
            {
                "vals": {
                    "value": "array([0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1,\n       2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3,\n       0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1,\n       2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3,\n       0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3])",
                    "shape": "(100,)",
                    "omitted": false
                }
            }
        ],
        [
            {
                "interpolation": {
                    "value": "'linear'",
                    "shape": "6",
                    "omitted": false
                },
                "q": {
                    "value": "[0.5, 0.6]",
                    "shape": "2",
                    "omitted": false
                },
                "self.ngroups": {
                    "value": "2",
                    "shape": null,
                    "omitted": false
                }
            },
            {
                "vals": {
                    "value": "array([0, 1])",
                    "shape": "(2,)",
                    "omitted": false
                }
            }
        ],
        [
            {
                "interpolation": {
                    "value": "'linear'",
                    "shape": "6",
                    "omitted": false
                },
                "q": {
                    "value": "[0.5, 0.6]",
                    "shape": "2",
                    "omitted": false
                },
                "self.ngroups": {
                    "value": "4",
                    "shape": null,
                    "omitted": false
                }
            },
            {
                "vals": {
                    "value": "array([0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1,\n       2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3,\n       0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1,\n       2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3,\n       0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3])",
                    "shape": "(100,)",
                    "omitted": false
                }
            }
        ]
    ],
    "2.1.4": [
        [
            {
                "interpolation": "str",
                "q": "list",
                "self.ngroups": "int"
            },
            {
                "vals": "ndarray"
            }
        ],
        [
            {
                "interpolation": "str",
                "q": "list",
                "self.ngroups": "int"
            },
            {
                "vals": "ndarray"
            }
        ],
        [
            {
                "interpolation": "str",
                "q": "list",
                "self.ngroups": "int"
            },
            {
                "vals": "ndarray"
            }
        ],
        [
            {
                "interpolation": "str",
                "q": "list",
                "self.ngroups": "int"
            },
            {
                "vals": "ndarray"
            }
        ]
    ],
    "2.1.5": [
        [
            {
                "interpolation": {
                    "value": "'linear'",
                    "shape": "6",
                    "omitted": false
                },
                "q": {
                    "value": "[0.5, 0.6]",
                    "shape": "2",
                    "omitted": false
                },
                "self.ngroups": {
                    "value": "2",
                    "shape": null,
                    "omitted": false
                }
            },
            {
                "vals": {
                    "value": "array([0, 1])",
                    "shape": "(2,)",
                    "omitted": false
                }
            }
        ],
        [
            {
                "interpolation": {
                    "value": "'linear'",
                    "shape": "6",
                    "omitted": false
                },
                "q": {
                    "value": "[0.5, 0.6]",
                    "shape": "2",
                    "omitted": false
                },
                "self.ngroups": {
                    "value": "4",
                    "shape": null,
                    "omitted": false
                }
            },
            {
                "vals": {
                    "value": "array([0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1,\n       2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3,\n       0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1,\n       2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3,\n       0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3])",
                    "shape": "(100,)",
                    "omitted": false
                }
            }
        ],
        [
            {
                "interpolation": {
                    "value": "'linear'",
                    "shape": "6",
                    "omitted": false
                },
                "q": {
                    "value": "[0.5, 0.6]",
                    "shape": "2",
                    "omitted": false
                },
                "self.ngroups": {
                    "value": "2",
                    "shape": null,
                    "omitted": false
                }
            },
            {
                "vals": {
                    "value": "array([0, 1])",
                    "shape": "(2,)",
                    "omitted": false
                }
            }
        ],
        [
            {
                "interpolation": {
                    "value": "'linear'",
                    "shape": "6",
                    "omitted": false
                },
                "q": {
                    "value": "[0.5, 0.6]",
                    "shape": "2",
                    "omitted": false
                },
                "self.ngroups": {
                    "value": "4",
                    "shape": null,
                    "omitted": false
                }
            },
            {
                "vals": {
                    "value": "array([0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1,\n       2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3,\n       0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1,\n       2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3,\n       0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3])",
                    "shape": "(100,)",
                    "omitted": false
                }
            }
        ]
    ],
    "2.1.6": [
        [
            {
                "interpolation": "str",
                "q": "list",
                "self.ngroups": "int"
            },
            {
                "vals": "ndarray"
            }
        ],
        [
            {
                "interpolation": "str",
                "q": "list",
                "self.ngroups": "int"
            },
            {
                "vals": "ndarray"
            }
        ],
        [
            {
                "interpolation": "str",
                "q": "list",
                "self.ngroups": "int"
            },
            {
                "vals": "ndarray"
            }
        ],
        [
            {
                "interpolation": "str",
                "q": "list",
                "self.ngroups": "int"
            },
            {
                "vals": "ndarray"
            }
        ]
    ],
    "3.1.1": [
        "groupby.quantile(<arraylike>) fails with AssertionError\n"
    ],
    "3.1.2": [
        "Code Sample, a copy-pastable example if possible\n# Your code here\ndf = pd.DataFrame(np.array([10*[_%4] for _ in range(100)]))            \n\ndf.groupby(0).quantile(0.5)                                            \n# Out[19]: \n#     1    2    3    4    5    6    7    8    9\n# 0                                             \n# 0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n# 1  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n# 2  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0\n# 3  3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0\n\ndf.groupby(0).quantile([0.5,0.99])                                     \n---------------------------------------------------------------------------\nAssertionError                            Traceback (most recent call last)\n<ipython-input-20-21c92d2481c9> in <module>\n----> 1 df.groupby(0).quantile([0.5,0.99])\n\n~/PycharmProjects/netsim_stats/venv/lib/python3.7/site-packages/pandas/core/groupby/groupby.py in quantile(self, q, interpolation)\n   1950 \n   1951             indices = np.concatenate(arrays)\n-> 1952             assert len(indices) == len(result)\n   1953             return result.take(indices)\n   1954 \n\nAssertionError: \n\ndf.quantile([0.5,0.99])                                                \n#        0    1    2    3    4    5    6    7    8    9\n# 0.50  1.5  1.5  1.5  1.5  1.5  1.5  1.5  1.5  1.5  1.5\n# 0.99  3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0\n                                                              \ndf.groupby(0)[1].quantile(0.5) \n# 0\n# 0    0.0\n# 1    1.0\n# 2    2.0\n# 3    3.0\n# Name: 1, dtype: float64\n\ndf.groupby(0)[1].quantile([0.5,0.99])\n\n---------------------------------------------------------------------------\nAssertionError                            Traceback (most recent call last)\n<ipython-input-24-ebf6ade716ff> in <module>\n----> 1 df.groupby(0)[1].quantile([0.5,0.99])\n\n~/PycharmProjects/netsim_stats/venv/lib/python3.7/site-packages/pandas/core/groupby/groupby.py in quantile(self, q, interpolation)\n   1950 \n   1951             indices = np.concatenate(arrays)\n-> 1952             assert len(indices) == len(result)\n   1953             return result.take(indices)\n   1954 \n\nAssertionError: \nProblem description\nThe above is a constructed minimal example.\nI am not sure how much I should elaborate on the \"why this is a problem\".\n\ngroupby.quantile() fails with an assertion error for \"larger\" dataframes, smaller dataframes seem to work fine.\n\nExpected Output\n"
    ]
}