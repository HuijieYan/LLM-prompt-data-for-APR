{
    "pandas": [
        {
            "bugID": 52,
            "bitvector": {
                "1.1.1": 1,
                "1.1.2": 1,
                "1.2.1": 0,
                "1.2.2": 0,
                "1.2.3": 0,
                "1.3.1": 0,
                "1.3.2": 0,
                "1.4.1": 0,
                "1.4.2": 0,
                "2.1.1": 0,
                "2.1.2": 0,
                "2.1.3": 0,
                "2.1.4": 0,
                "2.1.5": 0,
                "2.1.6": 0,
                "3.1.1": 0,
                "3.1.2": 0,
                "cot": 0
            },
            "strata": {
                "1": 1,
                "2": 0,
                "3": 0,
                "4": 0,
                "5": 0,
                "6": 0,
                "7": 0
            },
            "available_bitvector": {
                "1.1.1": 1,
                "1.1.2": 1,
                "1.2.1": 0,
                "1.2.2": 0,
                "1.2.3": 0,
                "1.3.1": 0,
                "1.3.2": 0,
                "1.4.1": 0,
                "1.4.2": 0,
                "2.1.1": 0,
                "2.1.2": 0,
                "2.1.3": 0,
                "2.1.4": 0,
                "2.1.5": 0,
                "2.1.6": 0,
                "3.1.1": 0,
                "3.1.2": 0,
                "cot": 0
            },
            "available_strata": {
                "1": 1,
                "2": 0,
                "3": 0,
                "4": 0,
                "5": 0,
                "6": 0,
                "7": 0
            },
            "start_line": 581,
            "file_name": "pandas/core/groupby/generic.py",
            "replace_code": "def nunique(self, dropna: bool = True, method: str = 'hashed') -> Series:\n    \"\"\"\n    Return number of unique elements in the group.\n\n    Returns\n    -------\n    Series\n        Number of unique values within each group.\n    \"\"\"\n    ids, _, _ = self.grouper.group_info\n\n    val = self.obj._internal_get_values()\n\n    # temporary fix while we wait for NumPy bug 12629 to be fixed\n    if isinstance(val.dtype, ('datetime64', 'datetime', 'timedelta64', 'timedelta')):\n        val.replace('NaT', np.datetime64(\"NaT\"), inplace=True)\n\n    try:\n        sorter = np.lexsort((val, ids))\n    except TypeError:  # catches object dtypes\n        msg = f\"val.dtype must be object, got {val.dtype}\"\n        assert val.dtype == object, msg\n        val, _ = algorithms.factorize(val, sort=False)\n        sorter = np.lexsort((val, ids))\n        isna = lambda a: a == -1\n    else:\n        isna = lambda a: pd.isna(a)\n\n    ids, val = ids[sorter], val[sorter]\n\n    # group boundaries are where group ids change\n    # unique observations are where sorted values change\n    idx = np.r_[0, 1 + np.nonzero(ids[1:] != ids[:-1])[0]]\n    inc = np.r_[1, val[1:] != val[:-1]]\n\n    # 1st item of each group is a new unique observation\n    mask = isna(val)\n    if dropna:\n        inc[idx] = 1\n        inc[mask] = 0\n    else:\n        inc[mask & np.r_[False, mask[:-1]]] = 0\n        inc[idx] = 1\n\n    out = np.add.reduceat(inc, idx).astype(\"int64\", copy=False)\n    if len(ids):\n        # NaN/NaT group exists if the head of ids is -1,\n        # so remove it from res and exclude its index from idx\n        if ids[0] == -1:\n            res = out[1:]\n            idx = idx[np.flatnonzero(idx)]\n        else:\n            res = out\n    else:\n        res = out[1:]\n    ri = self.grouper.result_index\n\n    # we might have duplications among the bins\n    if len(res) != len(ri):\n        res, out = np.zeros(len(ri), dtype=out.dtype), res\n        res[ids[idx]] = out\n\n    result = Series(res, index=ri, name=self._selection_name)\n    return self._reindex_output(result, fill_value=0)",
            "import_list": [
                "import numpy as np",
                "from pandas.core.groupby.generic import Series"
            ]
        }
    ]
}