This bug seems to be related to the `Index.get_value` function. The problem is that when a Series is filtered with a mask, the `get_value` method first attempts to create a NumPy array of values using `values_from_object`, which is causing the ExtensionArray to be densified.

The issue seems to be that the `get_value` method is trying to convert the series and key values to NumPy arrays unnecessarily, which can be expensive if the ExtensionArray doesn't store a NumPy array of scalars.

To fix this, one possible approach is to modify the `get_value` method to check for ExtensionArray or Index-like objects and handle them differently without trying to convert them to NumPy arrays. Instead, it can directly access the values in a more efficient manner.

Here's the corrected `get_value` function:

```python
# this is the corrected get_value function
@Appender(_index_shared_docs["get_value"] % _index_doc_kwargs)
def get_value(self, series, key):

    # if we have something that is Index-like, then
    # use this, e.g. DatetimeIndex
    # Things like `Series._get_value` (via .at) pass the EA directly here.
    s = getattr(series, "_values", series)
    if isinstance(s, (ExtensionArray, Index)) and is_scalar(key):
        # GH 20882, 21257
        # Unify Index and ExtensionArray treatment
        # First try to convert the key to a location
        # If that fails, raise a KeyError if an integer
        # index, otherwise, see if key is an integer, and
        # try that
        try:
            iloc = self.get_loc(key)
            return s[iloc]
        except KeyError:
            if len(self) > 0 and (self.holds_integer() or self.is_boolean()):
                raise
            elif is_integer(key):
                return s[key]

    # Handle ExtensionArray or Index-like objects differently
    if isinstance(s, (ExtensionArray, Index)):
        iloc = self.get_loc(key)
        return s[iloc]
    else:
        # For other types, handle as before
        s = com.values_from_object(series)
        k = com.values_from_object(key)

        k = self._convert_scalar_indexer(k, kind="getitem")
        try:
            return self._engine.get_value(s, k, tz=getattr(series.dtype, "tz", None))
        except KeyError as e1:
            if len(self) > 0 and (self.holds_integer() or self.is_boolean()):
                raise

            try:
                return libindex.get_value_at(s, key)
            except IndexError:
                raise
            except TypeError:
                # generator/iterator-like
                if is_iterator(key):
                    raise InvalidIndexError(key)
                else:
                    raise e1
            except Exception:
                raise e1
        except TypeError:
            # e.g. "[False] is an invalid key"
            if is_scalar(key):
                raise IndexError(key)
            raise InvalidIndexError(key)
```

In the corrected function, we've added a check to see if the series is an ExtensionArray or Index-like object. If it is, we handle it separately without trying to convert it to a NumPy array. Otherwise, we handle it as before. This should prevent unnecessary densification of the ExtensionArray and solve the bug.