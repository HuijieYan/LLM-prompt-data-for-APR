Potential error location: The error may occur in the line that tries to open the s3file in 'wb' mode for a path that starts with 's3://' and then pass the opened s3file to the fastparquet internal implementation.

Reasons behind the bug: The error occurs because the function is trying to use 'wb' mode for the s3 file, but it should be using 'ab' mode to append to an existing file if it exists.

Possible approaches for fixing the bug:
1. Use the correct file mode ('ab' for s3 files) when opening the file.
2. Check for the existence of the file and decide whether to write or append based on that.

Corrected code:
```python
def write(
    self, df, path, compression="snappy", index=None, partition_cols=None, **kwargs
):
    self.validate_dataframe(df)
    if "partition_on" in kwargs and partition_cols is not None:
        raise ValueError(
            "Cannot use both partition_on and "
            "partition_cols. Use partition_cols for "
            "partitioning data"
        )
    elif "partition_on" in kwargs:
        partition_cols = kwargs.pop("partition_on")

    if partition_cols is not None:
        kwargs["file_scheme"] = "hive"

    if is_s3_url(path):
        path, _, _, exists = get_filepath_or_buffer(path, mode="ab")
        if exists:
            kwargs["append"] = True
        kwargs["open_with"] = lambda path, mode: s3.open(path, mode)
    else:
        path, _, _, _ = get_filepath_or_buffer(path)

    with catch_warnings(record=True):
        self.api.write(
            path,
            df,
            compression=compression,
            write_index=index,
            partition_on=partition_cols,
            **kwargs
        )
```