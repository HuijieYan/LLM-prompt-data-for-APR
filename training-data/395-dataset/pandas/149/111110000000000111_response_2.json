{
    "pandas": [
        {
            "bugID": 149,
            "bitvector": {
                "1.1.1": 1,
                "1.1.2": 1,
                "1.2.1": 1,
                "1.2.2": 1,
                "1.2.3": 1,
                "1.3.1": 0,
                "1.3.2": 0,
                "1.4.1": 0,
                "1.4.2": 0,
                "2.1.1": 0,
                "2.1.2": 0,
                "2.1.3": 0,
                "2.1.4": 0,
                "2.1.5": 0,
                "2.1.6": 0,
                "3.1.1": 1,
                "3.1.2": 1,
                "cot": 1
            },
            "strata": {
                "1": 1,
                "2": 1,
                "3": 0,
                "4": 0,
                "5": 0,
                "6": 1,
                "7": 1
            },
            "available_bitvector": {
                "1.1.1": 1,
                "1.1.2": 0,
                "1.2.1": 1,
                "1.2.2": 0,
                "1.2.3": 1,
                "1.3.1": 0,
                "1.3.2": 0,
                "1.4.1": 0,
                "1.4.2": 0,
                "2.1.1": 0,
                "2.1.2": 0,
                "2.1.3": 0,
                "2.1.4": 0,
                "2.1.5": 0,
                "2.1.6": 0,
                "3.1.1": 0,
                "3.1.2": 0,
                "cot": 1
            },
            "available_strata": {
                "1": 1,
                "2": 1,
                "3": 0,
                "4": 0,
                "5": 0,
                "6": 0,
                "7": 1
            },
            "start_line": 142,
            "file_name": "pandas/io/parquet.py",
            "replace_code": "def write(self, df, path, compression=\"snappy\", index=None, partition_cols=None, **kwargs):\n        self.validate_dataframe(df)\n        \n        if \"partition_on\" in kwargs and partition_cols is not None:\n            raise ValueError(\n                \"Cannot use both partition_on and \"\n                \"partition_cols. Use partition_cols for \"\n                \"partitioning data\"\n            )\n        elif \"partition_on\" in kwargs:\n            partition_cols = kwargs.pop(\"partition_on\")\n    \n        if partition_cols is not None:\n            kwargs[\"file_scheme\"] = \"hive\"\n    \n        if is_s3_url(path):\n            path, _, _, _ = get_filepath_or_buffer(path, mode=\"wb\")\n            kwargs[\"open_with\"] = lambda path, _: path\n        else:\n            path, _, _, _ = get_filepath_or_buffer(path)\n    \n        with warnings.catch_warnings(record=True) as w:\n            warnings.simplefilter(\"always\")\n            \n            self.api.write(\n                path,\n                df,\n                compression=compression,\n                write_index=index,\n                partition_on=partition_cols,\n                **kwargs\n            )\n            \n            for warning in w:\n                if \"tostring()\" in str(warning.message):\n                    warnings.warn(warning.message.replace(\"tostring()\", \"tobytes()\"), DeprecationWarning)",
            "import_list": [
                "import warnings"
            ]
        }
    ]
}