```python
def write(self, df, path, compression="snappy", index=None, partition_cols=None, **kwargs):
    self.validate_dataframe(df)

    if "partition_on" in kwargs and partition_cols is not None:
        raise ValueError("Cannot use both partition_on and partition_cols. Use partition_cols for partitioning data")
    elif "partition_on" in kwargs:
        partition_cols = kwargs.pop("partition_on")

    if partition_cols is not None:
        kwargs["file_scheme"] = "hive"

    if is_s3_url(path):
        path, _, _, _ = get_filepath_or_buffer(path, mode="wb")
        kwargs["open_with"] = lambda path, _: path
    else:
        path, _, _, _ = get_filepath_or_buffer(path)

    with catch_warnings(record=True):
        self.api.write_to_dataset(
            df,
            root_path=path,
            compression=compression,
            index=index,
            partition_cols=partition_cols,
            **kwargs
        )
```
In the corrected code, I have replaced the `self.api.write` with `self.api.write_to_dataset` and also replaced the parameter names to align with the correct parameter names for the `write_to_dataset` method.