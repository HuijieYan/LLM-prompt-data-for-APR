{
    "pandas": [
        {
            "bugID": 149,
            "bitvector": {
                "1.1.1": 1,
                "1.1.2": 1,
                "1.2.1": 0,
                "1.2.2": 0,
                "1.2.3": 0,
                "1.3.1": 0,
                "1.3.2": 0,
                "1.4.1": 0,
                "1.4.2": 0,
                "2.1.1": 0,
                "2.1.2": 0,
                "2.1.3": 0,
                "2.1.4": 0,
                "2.1.5": 0,
                "2.1.6": 0,
                "3.1.1": 1,
                "3.1.2": 1,
                "cot": 1
            },
            "strata": {
                "1": 1,
                "2": 0,
                "3": 0,
                "4": 0,
                "5": 0,
                "6": 1,
                "7": 1
            },
            "available_bitvector": {
                "1.1.1": 1,
                "1.1.2": 0,
                "1.2.1": 0,
                "1.2.2": 0,
                "1.2.3": 0,
                "1.3.1": 0,
                "1.3.2": 0,
                "1.4.1": 0,
                "1.4.2": 0,
                "2.1.1": 0,
                "2.1.2": 0,
                "2.1.3": 0,
                "2.1.4": 0,
                "2.1.5": 0,
                "2.1.6": 0,
                "3.1.1": 0,
                "3.1.2": 0,
                "cot": 1
            },
            "available_strata": {
                "1": 1,
                "2": 0,
                "3": 0,
                "4": 0,
                "5": 0,
                "6": 0,
                "7": 1
            },
            "start_line": 142,
            "file_name": "pandas/io/parquet.py",
            "replace_code": "def write(self, df, path, compression=\"snappy\", index=None, partition_cols=None, **kwargs):\n    self.validate_dataframe(df)\n\n    partition_on = kwargs.pop(\"partition_on\", None)\n\n    if partition_on and partition_cols:\n        raise ValueError(\"Cannot use both partition_on and partition_cols. Use partition_cols for partitioning data\")\n\n    if partition_on:\n        partition_cols = partition_on\n\n    if partition_cols:\n        kwargs[\"file_scheme\"] = \"hive\"\n\n    if is_s3_url(path):\n        mode = \"wb\"  # Set the default mode to write\n        if \"mode\" in kwargs:\n            mode = kwargs.pop(\"mode\")\n\n        if mode not in [\"wb\", \"ab\"]:\n            raise ValueError(\"Invalid mode for S3 file. Supported modes are 'wb' and 'ab'.\")\n\n        # Open the s3 file\n        path, _, _, _ = get_filepath_or_buffer(path, mode=mode)\n        kwargs[\"open_with\"] = lambda path, _: path\n    else:\n        path, _, _, _ = get_filepath_or_buffer(path)\n\n    with catch_warnings(record=True):\n        self.api.write(\n            path,\n            df,\n            compression=compression,\n            write_index=index,\n            partition_on=partition_cols,\n            **kwargs\n        )",
            "import_list": []
        }
    ]
}