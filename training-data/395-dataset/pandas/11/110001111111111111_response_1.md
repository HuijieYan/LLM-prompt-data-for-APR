The error occurs when trying to concatenate a DataFrame with Series, where the keys contain duplicates. The issue is raised due to an incorrect type being passed to the int() function.

After analyzing the given bug description and test case, it appears that the issue is in the `_make_concat_multiindex` function. The function is trying to handle duplicated keys and is not handling them correctly.

The bug occurs because the function incorrectly stores slice objects in the 'codes_list' variable, which later causes a TypeError when trying to convert them to int. This happens because 'codes_list' is supposed to store integers, not slices.

To fix the bug, we need to ensure that 'codes_list' only stores integer arrays and not slices. We can achieve this by updating the logic in the section where 'codes_list' is being constructed. Instead of storing slices, we need to find the correct integers and store those in 'codes_list'.

Here's the corrected code for the `_make_concat_multiindex` function:

```python
import numpy as np
from pandas.core.indexes.multi import MultiIndex
from pandas import Index, Series, DataFrame, concat
from pandas.core.dtypes.cast import ensure_int8
from pandas.core.arrays.categorical import _coerce_indexer_frozen, coerce_indexer_dtype
from pandas.core.dtypes.common import ensure_int8

def _make_concat_multiindex(indexes, keys, levels=None, names=None) -> MultiIndex:
    if levels is None and isinstance(keys[0], tuple) or (levels is not None and len(levels) > 1):
        zipped = list(zip(*keys))
        if names is None:
            names = [None] * len(zipped)
        if levels is None:
            _, levels = factorize_from_iterables(zipped)
        else:
            levels = [ensure_index(x) for x in levels]
    else:
        zipped = [keys]
        if names is None:
            names = [None]
        if levels is None:
            levels = [ensure_index(keys)]
        else:
            levels = [ensure_index(x) for x in levels]

    if not all_indexes_same(indexes):
        codes_list = []

        for hlevel, level in zip(zipped, levels):
            to_concat = []
            for key, index in zip(hlevel, indexes):
                i = level.get_indexer(key)
                mapped = np.where(i != -1, i, np.nan)
                if np.any(np.isnan(mapped)):
                    raise ValueError(f"Values not found in passed level: {key}")
                to_concat.append(mapped)

            out = np.concatenate(to_concat)
            codes, categories = coerce_indexer_dtype(out, ensure_index(indexes))

            codes_list.append(codes)

        concat_index = _concat_indexes(indexes)

        if isinstance(concat_index, MultiIndex):
            levels.extend(concat_index.levels)
            codes_list.extend(concat_index.codes)
        else:
            codes, categories = factorize_from_iterable(concat_index)
            levels.append(categories)
            codes_list.append(codes)

        if len(names) == len(levels):
            names = list(names)
        else:
            if len({idx.nlevels for idx in indexes}) != 1:
                raise AssertionError("Cannot concat indices that do not have the same number of levels")

            names = names + get_consensus_names(indexes)

        return MultiIndex(levels=levels, codes=[ensure_int8(_coerce_indexer_frozen(c, lev, copy=False)) for c, lev in zip(codes_list, levels)], names=names, verify_integrity=False)

    new_index = indexes[0]
    n = len(new_index)
    kpieces = len(indexes)
    new_names = list(names)
    new_levels = list(levels)
    new_codes = []

    for hlevel, level in zip(zipped, levels):
        hlevel = ensure_index(hlevel)
        mapped = level.get_indexer(hlevel)

        mask = mapped == -1
        if mask.any():
            raise ValueError(f"Values not found in passed level: {hlevel[mask]}")

        new_codes.append(np.repeat(mapped, n))

    if isinstance(new_index, MultiIndex):
        new_levels.extend(new_index.levels)
        new_codes.extend([np.tile(lab, kpieces) for lab in new_index.codes])
    else:
        new_levels.append(new_index)
        new_codes.append(np.tile(np.arange(n), kpieces))

    if len(new_names) < len(new_levels):
        new_names.extend(new_index.names)

    return MultiIndex(levels=new_levels, codes=new_codes, names=new_names, verify_integrity=False)
``` 

In the corrected code, special attention has been given to ensure that 'codes_list' only contains integer arrays, thus avoiding the TypeError when trying to convert slice to int. Furthermore, the code logic for handling duplicated keys has been revised to properly concatenate the indexes.

These changes should address the bug and allow the intended functionality of the `_make_concat_multiindex` function, which should resolve the bug related to the concatenation of DataFrame with Series with duplicate keys.