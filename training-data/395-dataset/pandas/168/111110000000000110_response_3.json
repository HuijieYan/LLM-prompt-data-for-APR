{
    "pandas": [
        {
            "bugID": 168,
            "bitvector": {
                "1.1.1": 1,
                "1.1.2": 1,
                "1.2.1": 1,
                "1.2.2": 1,
                "1.2.3": 1,
                "1.3.1": 0,
                "1.3.2": 0,
                "1.4.1": 0,
                "1.4.2": 0,
                "2.1.1": 0,
                "2.1.2": 0,
                "2.1.3": 0,
                "2.1.4": 0,
                "2.1.5": 0,
                "2.1.6": 0,
                "3.1.1": 1,
                "3.1.2": 1,
                "cot": 0
            },
            "strata": {
                "1": 1,
                "2": 1,
                "3": 0,
                "4": 0,
                "5": 0,
                "6": 1,
                "7": 0
            },
            "available_bitvector": {
                "1.1.1": 1,
                "1.1.2": 1,
                "1.2.1": 0,
                "1.2.2": 0,
                "1.2.3": 0,
                "1.3.1": 0,
                "1.3.2": 0,
                "1.4.1": 0,
                "1.4.2": 0,
                "2.1.1": 0,
                "2.1.2": 0,
                "2.1.3": 0,
                "2.1.4": 0,
                "2.1.5": 0,
                "2.1.6": 0,
                "3.1.1": 1,
                "3.1.2": 1,
                "cot": 0
            },
            "available_strata": {
                "1": 1,
                "2": 0,
                "3": 0,
                "4": 0,
                "5": 0,
                "6": 1,
                "7": 0
            },
            "start_line": 425,
            "file_name": "pandas/core/groupby/grouper.py",
            "replace_code": "def _get_grouper(\n    obj,\n    key=None,\n    axis=0,\n    level=None,\n    sort=True,\n    observed=False,\n    mutated=False,\n    validate=True,\n):\n    def _is_label_like(key):\n        return com.is_scalar(key) or isinstance(key, (tuple, list, np.ndarray))\n\n    group_axis = obj._get_axis(axis)\n\n    if level is not None:\n        if isinstance(group_axis, MultiIndex):\n            if is_list_like(level) and len(level) == 1:\n                level = level[0]\n\n            if key is None and is_scalar(level):\n                key = group_axis.get_level_values(level)\n                level = None\n        else:\n            if is_list_like(level):\n                nlevels = len(level)\n                if nlevels == 1:\n                    level = level[0]\n                elif nlevels == 0:\n                    raise ValueError(\"No group keys passed!\")\n                else:\n                    raise ValueError(\"multiple levels only valid with MultiIndex\")\n\n            if isinstance(level, str):\n                if obj.index.name != level:\n                    raise ValueError(\n                        \"level name {} is not the name of the index\".format(level)\n                    )\n            elif level > 0 or level < -1:\n                raise ValueError(\"level > 0 or level < -1 only valid with MultiIndex\")\n\n            level = None\n            key = group_axis\n\n    if isinstance(key, Grouper):\n        binner, grouper, obj = key._get_grouper(obj, validate=False)\n        if key.key is None:\n            return grouper, [], obj\n        else:\n            return grouper, {key.key}, obj\n    elif isinstance(key, BaseGrouper):\n        return key, [], obj\n\n    # Validation and handling of tuple key\n    is_tuple = isinstance(key, tuple)\n    all_hashable = is_tuple and is_hashable(key)\n\n    if is_tuple:\n        if (all_hashable and key not in obj and set(key).issubset(obj)) or not all_hashable:\n            msg = (\n                \"Interpreting tuple 'by' as a list of keys, rather than \"\n                \"a single key. Use 'by=[...]' instead of 'by=(...)'. In \"\n                \"the future, a tuple will always mean a single key.\"\n            )\n            warnings.warn(msg, FutureWarning, stacklevel=5)\n            key = list(key)\n\n    # Handling keys and creating list of keys\n    if not isinstance(key, list):\n        keys = [key]\n        match_axis_length = False\n    else:\n        keys = key\n        match_axis_length = len(keys) == len(group_axis)\n\n    # Determining the type of keys\n    any_callable = any(callable(g) or isinstance(g, dict) for g in keys)\n    any_groupers = any(isinstance(g, Grouper) for g in keys)\n    any_arraylike = any(\n        isinstance(g, (list, tuple, pd.Series, Index, np.ndarray)) for g in keys\n    )\n\n    if (not any_callable and not any_arraylike and not any_groupers\n            and match_axis_length and level is None):\n        if isinstance(obj, pd.DataFrame):\n            all_in_columns_index = all(\n                g in obj.columns or g in obj.index.names for g in keys\n            )\n        elif isinstance(obj, pd.Series):\n            all_in_columns_index = all(g in obj.index.names for g in keys)\n\n        if not all_in_columns_index:\n            keys = [asarray_tuplesafe(keys)]\n\n    if isinstance(level, (tuple, list)):\n        if key is None:\n            keys = [None] * len(level)\n        levels = level\n    else:\n        levels = [level] * len(keys)\n\n    groupings = []\n    exclusions = []\n\n    for i, (gpr, level) in enumerate(zip(keys, levels)):\n        if not _is_label_like(gpr):\n            try:\n                obj._data.items.get_loc(gpr)\n            except Exception:\n                pass\n            else:\n                in_axis = True\n                name = gpr\n                exclusions.append(name)\n                ping = Grouping(group_axis, gpr, obj=obj, name=name, level=level,\n                                sort=sort, observed=observed, in_axis=in_axis)\n                groupings.append(ping)\n                continue\n        # TODO: handle other cases\n\n        # Categorical data check\n        if is_categorical_dtype(gpr) and len(gpr) != obj.shape[axis]:\n            raise ValueError(\n                (\"Length of grouper ({len_gpr}) and axis ({len_axis})\"\n                \" must be same length\".format(\n                    len_gpr=len(gpr), len_axis=obj.shape[axis]\n                ))\n            )\n        ping = (\n            Grouping(\n                group_axis,\n                gpr,\n                obj=obj,\n                name=name,\n                level=level,\n                sort=sort,\n                observed=observed,\n                in_axis=in_axis,\n            )\n            if not isinstance(gpr, Grouping)\n            else gpr\n        )\n        groupings.append(ping)\n\n    if len(groupings) == 0 and len(obj):\n        raise ValueError(\"No group keys passed!\")\n    elif len(groupings) == 0:\n        groupings.append(Grouping(Index([], dtype=\"int\"), np.array([], dtype=np.intp)))\n\n    grouper = BaseGrouper(group_axis, groupings, sort=sort, mutated=mutated)\n    return grouper, exclusions, obj",
            "imports": [
                "import warnings",
                "import numpy as np",
                "import pandas.core.common as com",
                "from pandas.core.groupby.grouper import Grouper, Grouping, BaseGrouper",
                "from pandas.core.dtypes.common import is_hashable",
                "from pandas.core.dtypes.dtypes import CategoricalDtype, is_categorical_dtype",
                "from pandas.core.indexes.base import Index",
                "from pandas.core.indexes.multi import MultiIndex",
                "from pandas.core.arrays import ExtensionArray",
                "from pandas.core.common import is_list_like, is_scalar",
                "from pandas.core.dtypes.cast import asarray_tuplesafe"
            ]
        }
    ]
}