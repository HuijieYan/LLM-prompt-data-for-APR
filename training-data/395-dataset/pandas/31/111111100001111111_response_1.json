{
    "pandas": [
        {
            "bugID": 31,
            "bitvector": {
                "1.1.1": 1,
                "1.1.2": 1,
                "1.2.1": 1,
                "1.2.2": 1,
                "1.2.3": 1,
                "1.3.1": 1,
                "1.3.2": 1,
                "1.4.1": 0,
                "1.4.2": 0,
                "2.1.1": 0,
                "2.1.2": 0,
                "2.1.3": 1,
                "2.1.4": 1,
                "2.1.5": 1,
                "2.1.6": 1,
                "3.1.1": 1,
                "3.1.2": 1,
                "cot": 1
            },
            "strata": {
                "1": 1,
                "2": 1,
                "3": 1,
                "4": 0,
                "5": 1,
                "6": 1,
                "7": 1
            },
            "available_bitvector": {
                "1.1.1": 1,
                "1.1.2": 1,
                "1.2.1": 1,
                "1.2.2": 1,
                "1.2.3": 1,
                "1.3.1": 1,
                "1.3.2": 1,
                "1.4.1": 0,
                "1.4.2": 0,
                "2.1.1": 0,
                "2.1.2": 0,
                "2.1.3": 1,
                "2.1.4": 1,
                "2.1.5": 1,
                "2.1.6": 1,
                "3.1.1": 1,
                "3.1.2": 1,
                "cot": 1
            },
            "available_strata": {
                "1": 1,
                "2": 1,
                "3": 1,
                "4": 0,
                "5": 1,
                "6": 1,
                "7": 1
            },
            "start_line": 1827,
            "file_name": "pandas/core/groupby/groupby.py",
            "replace_code": "def quantile(self, q=0.5, interpolation: str = \"linear\"):\n    # ... (other code)\n\n    def pre_processor(vals: np.ndarray) -> Tuple[np.ndarray, Optional[Type]]:\n        inference = None\n        if pd.api.types.is_object_dtype(vals):\n            raise TypeError(\"'quantile' cannot be performed against 'object' dtypes!\")\n        elif pd.api.types.is_integer_dtype(vals) and pd.api.types.is_integer_array(vals):\n            inference = pd.Int64Dtype()\n        elif pd.api.types.is_float_dtype(vals):\n            inference = np.float64\n        elif pd.api.types.is_datetime64_any_dtype(vals):\n            inference = \"datetime64[ns]\"\n            vals = np.asarray(vals).astype(np.float)\n\n        return vals, inference\n\n    def post_processor(vals: np.ndarray, inference: Optional[Type]) -> np.ndarray:\n        if inference and pd.api.types.is_integer_array(vals):\n            # Convert to nullable integer if necessary\n            vals = pd.arrays.IntegerArray(vals)\n        elif inference and pd.api.types.is_float_dtype(inference):\n            # Convert back to original dtype\n            vals = vals.astype(inference)\n\n        return vals\n\n    if is_scalar(q):\n        return self._get_cythonized_result(\n            \"group_quantile\",\n            aggregate=True,\n            needs_values=True,\n            needs_mask=True,\n            cython_dtype=np.dtype(np.float64),\n            pre_processing=pre_processor,\n            post_processing=post_processor,\n            q=q,\n            interpolation=interpolation,\n        )\n    else:\n        results = [\n            self._get_cythonized_result(\n                \"group_quantile\",\n                aggregate=True,\n                needs_values=True,\n                needs_mask=True,\n                cython_dtype=np.dtype(np.float64),\n                pre_processing=pre_processor,\n                post_processing=post_processor,\n                q=qi,\n                interpolation=interpolation,\n            )\n            for qi in q\n        ]\n        result = concat(results, axis=0, keys=q)",
            "import_list": []
        }
    ]
}