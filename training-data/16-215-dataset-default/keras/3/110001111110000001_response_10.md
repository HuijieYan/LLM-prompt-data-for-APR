The buggy function `_clone_functional_model` is meant to clone a functional `Model` instance, creating new layers and weights instead of sharing the weights of the existing layers. The failing test `test_clone_functional_model_with_multi_outputs` is trying to clone a model with multiple outputs but encounters an assertion error, indicating that it could not compute the output for a certain tensor.

Upon reviewing the `_clone_functional_model` function and the error message, it seems that the issue is with the cloning process not correctly computing all the model outputs, leading to the assertion error in the failing test.

Potential bug location: The bug seems to be in the section of the code where the model outputs are being computed and then instantiated in a new model.

Approaches for fixing the bug:
1. Ensure that all model outputs are correctly computed and added to the `tensor_map` for instantiation in the new model.
2. Verify that the cloning process includes all the necessary layers and connections for multiple output scenarios.

Here's the corrected code for the `_clone_functional_model` function:

```python
def _clone_functional_model(model, input_tensors=None):
    if not isinstance(model, Model):
        raise ValueError('Expected `model` argument to be a `Model` instance, got ', model)

    layer_map = {}  # Cache for created layers.
    tensor_map = {}  # Map {reference_tensor: (corresponding_tensor, mask)}

    if input_tensors is None:
        input_layers = []
        input_tensors = []

        for layer in model._input_layers:
            input_tensor = Input(batch_shape=layer.input.shape, dtype=layer.dtype, sparse=layer.sparse, name=layer.name)
            input_tensors.append(input_tensor)
            input_layers.append(layer)
            newly_created_input_layer = input_tensor._keras_history[0]
            layer_map[layer] = newly_created_input_layer

        for original, cloned in zip(model._input_layers, input_layers):
            layer_map[original] = cloned
    else:
        input_tensors = to_list(input_tensors)
        _input_tensors = []

        for i, x in enumerate(input_tensors):
            if not K.is_keras_tensor(x):
                name = model._input_layers[i].name
                input_tensor = Input(tensor=x, name='input_wrapper_for_' + name)

                _input_tensors.append(input_tensor)
                original_input_layer = x._keras_history[0]
                newly_created_input_layer = input_tensor._keras_history[0]

                layer_map[original_input_layer] = newly_created_input_layer
            else:
                _input_tensors.append(x)
        input_tensors = _input_tensors

    for x, y in zip(model.inputs, input_tensors):
        tensor_map[x] = (y, None)

    depth_keys = list(model._nodes_by_depth.keys())
    depth_keys.sort(reverse=True)

    for depth in depth_keys:
        nodes = model._nodes_by_depth[depth]

        for node in nodes:
            layer = node.outbound_layer

            if layer not in layer_map:
                new_layer = layer.__class__.from_config(layer.get_config())
                layer_map[layer] = new_layer
            else:
                layer = layer_map[layer]

                if isinstance(layer, InputLayer):
                    continue

            reference_input_tensors = node.input_tensors
            reference_output_tensors = node.output_tensors

            computed_data = []

            for x in reference_input_tensors:
                if x in tensor_map:
                    computed_data.append(tensor_map[x])

            if len(computed_data) == len(reference_input_tensors):
                kwargs = node.arguments if node.arguments else {}

                computed_tensors = [x[0] for x in computed_data]
                computed_masks = [x[1] for x in computed_data]

                output_tensors = to_list(layer(computed_tensors, **kwargs))

                output_masks = to_list(layer.compute_mask(computed_tensors, computed_masks))

                for x, y, mask in zip(reference_output_tensors, output_tensors, output_masks):
                    tensor_map[x] = (y, mask)

    output_tensors = []

    for x in model.outputs:
        assert x in tensor_map, 'Could not compute output ' + str(x)
        tensor, _ = tensor_map[x]
        output_tensors.append(tensor)

    return Model(input_tensors, output_tensors, name=model.name)
```

By making the above corrections to the `_clone_functional_model` function, it should now be able to correctly compute the model outputs and pass the failing test.