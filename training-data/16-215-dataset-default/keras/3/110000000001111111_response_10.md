The potential error location within the problematic function is the computation of output_masks, where it always returns [None] due to the Lambda layer not supporting masks.

The bug's cause is that the function is not handling the case where the layer does not support masks, leading to the error message "Could not compute output Tensor".

To fix the bug, the code needs to check if the layer supports masks before attempting to compute them. If the layer does not support masks, it should skip the computation and set the output_masks to None.

Here's the corrected code for the problematic function:

```python
def _clone_functional_model(model, input_tensors=None):
    # (previous implementation remains unchanged)

    for x, y in zip(model.inputs, input_tensors):
        tensor_map[x] = (y, None)  # tensor, mask

    # Iterated over every node in the reference model, in depth order.
    depth_keys = list(model._nodes_by_depth.keys())
    depth_keys.sort(reverse=True)
    for depth in depth_keys:
        nodes = model._nodes_by_depth[depth]
        for node in nodes:
            # (previous implementation remains unchanged)

            computed_data = []  # List of tuples (input, mask).
            for x in reference_input_tensors:
                if x in tensor_map:
                    computed_data.append(tensor_map[x])

            if len(computed_data) == len(reference_input_tensors):
                # Call layer.
                if node.arguments:
                    kwargs = node.arguments
                else:
                    kwargs = {}
                if len(computed_data) == 1:
                    computed_tensor, computed_mask = computed_data[0]
                    output_tensors = to_list(layer(computed_tensor, **kwargs))
                    output_masks = [None for _ in output_tensors]  # Set output_masks to None
                    # Update tensor_map.
                    for x, y in zip(reference_output_tensors, output_tensors):
                        tensor_map[x] = (y, None)
                else:
                    computed_tensors = [x[0] for x in computed_data]
                    if not layer.supports_masking:  # Check if the layer supports masking
                        output_masks = [None for _ in computed_tensors]  # Set output_masks to None
                    else:
                        output_masks = to_list(layer.compute_mask(computed_tensors, None))
                    output_tensors = to_list(layer(computed_tensors, **kwargs))
                    # Update tensor_map.
                    for x, y, mask in zip(reference_output_tensors, output_tensors, output_masks):
                        tensor_map[x] = (y, mask)

    # Check that we did compute the model outputs,
    # then instantiate a new model from inputs and outputs.
    output_tensors = []
    for x in model.outputs:
        assert x in tensor_map, 'Could not compute output ' + str(x)
        tensor, _ = tensor_map[x]
        output_tensors.append(tensor)
    return Model(input_tensors, output_tensors, name=model.name)
```

The corrected code includes checks for whether the layer supports masking before computing the masks. If the layer does not support masking, the output_masks are set to None. This should resolve the issue posted in the GitHub thread and handle the discrepancy between the expected and actual input/output variable values.