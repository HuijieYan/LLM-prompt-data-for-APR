The issue appears to be related to the handling of output masks in the `clone_model` function. The GitHub issue provides a detailed analysis, indicating that the `output_masks` are always returning `None` when a layer without mask support is used in a functional model with multiple outputs.

The potential error location within the function seems to be around the generation of `output_masks` in the for loop iterating over `reference_output_tensors`.

The cause of the bug seems to be the incorrect handling of output masks when the model contains layers without mask support, leading to the "Could not compute output Tensor" error. This is in line with the observation that `output_masks` always returns `None`, whereas `[None, None]` is expected for a model with multiple outputs.

To fix the bug, the function needs to check if a layer supports masking before calling `layer.compute_mask`, and handle the `output_masks` accordingly.

Here's the corrected code for the problematic function:

```python
def _clone_functional_model(model, input_tensors=None):
    # ... (initial function definition and input parameter handling)

    for x, y in zip(model.inputs, input_tensors):
        tensor_map[x] = (y, None)  # tensor, mask

    # Iterated over every node in the reference model, in depth order.
    depth_keys = list(model._nodes_by_depth.keys())
    depth_keys.sort(reverse=True)
    for depth in depth_keys:
        nodes = model._nodes_by_depth[depth]
        for node in nodes:
            # ... (rest of the code remains unchanged)
            # Call layer.
            if node.arguments:
                kwargs = node.arguments
            else:
                kwargs = {}
            if len(computed_data) == 1:
                computed_tensor, computed_mask = computed_data[0]
                if has_arg(layer.call, 'mask'):
                    if 'mask' not in kwargs and layer.supports_masking:
                        kwargs['mask'] = computed_mask
                output_tensors = to_list(
                    layer(computed_tensor, **kwargs))
                output_masks = to_list(
                    layer.compute_mask(computed_tensor, computed_mask)) if layer.supports_masking else [None] * len(output_tensors)
                computed_tensors = [computed_tensor]
                computed_masks = [computed_mask]
            else:
                computed_tensors = [x[0] for x in computed_data]
                computed_masks = [x[1] for x in computed_data]
                if has_arg(layer.call, 'mask'):
                    if 'mask' not in kwargs and all(layer.supports_masking for layer in computed_data):
                        kwargs['mask'] = computed_masks
                output_tensors = to_list(
                    layer(computed_tensors, **kwargs))
                output_masks = to_list(
                    layer.compute_mask(computed_tensors, computed_masks)) if all(layer.supports_masking for layer in computed_data) else [None] * len(output_tensors)
            # ... (rest of the code remains unchanged)

    # Check that we did compute the model outputs,
    # then instantiate a new model from inputs and outputs.
    output_tensors = []
    for x in model.outputs:
        assert x in tensor_map, 'Could not compute output ' + str(x)
        tensor, _ = tensor_map[x]
        output_tensors.append(tensor)
    return Model(input_tensors, output_tensors, name=model.name)
```

In this corrected version, we added conditions to handle the case where a layer does not support masking, and appropriately set the `output_masks` to `None` for such layers. This should address the issue raised in the GitHub post and correctly handle the output masks based on layer support.