The issue with the _clone_functional_model function seems to be with the creation and mapping of input_tensors. The model was not properly creating and mapping input tensors, leading to the error.

Here's a corrected version of the function:

```python
def _clone_functional_model(model, input_tensors=None):
    """Clone a functional `Model` instance.

    Model cloning is similar to calling a model on new inputs,
    except that it creates new layers (and thus new weights) instead
    of sharing the weights of the existing layers.

    # Arguments
        model: Instance of `Model`.
        input_tensors: optional list of input tensors
            to build the model upon. If not provided,
            placeholders will be created.

    # Returns
        An instance of `Model` reproducing the behavior
        of the original model, on top of new inputs tensors,
        using newly instantiated weights.

    # Raises
        ValueError: in case of invalid `model` argument value.
    """
    if not isinstance(model, Model):
        raise ValueError('Expected `model` argument '
                         'to be a `Model` instance, got ', model)
    if isinstance(model, Sequential):
        raise ValueError('Expected `model` argument '
                         'to be a functional `Model` instance, '
                         'got a `Sequential` instance instead:', model)

    layer_map = {}  # Cache for created layers
    tensor_map = {}  # Map {reference_tensor: (corresponding_tensor, mask)}
    
    if input_tensors is None:
        input_layers = model.inputs
        input_tensors = [Input(batch_shape=layer._keras_shape, dtype=layer.dtype)
                         for layer in input_layers]
        for original, cloned in zip(model.input, input_tensors):
            layer_map[original] = cloned
            tensor_map[original] = (cloned, None)
    else:
        input_tensors = to_list(input_tensors)
        for i, x in enumerate(model.inputs):
            if not K.is_keras_tensor(input_tensors[i]):
                original_input_layer = x._keras_history[0]
                input_tensor = Input(tensor=input_tensors[i],
                                     name='input_wrapper_for_' + original_input_layer.name)
                layer_map[original_input_layer] = input_tensor
                tensor_map[original_input_layer] = (input_tensor, None)
            else:
                tensor_map[x] = (input_tensors[i], None)
    
    layers = model.layers
    for layer in layers:
        if layer not in layer_map:
            new_layer = layer.__class__.from_config(layer.get_config())
            layer_map[layer] = new_layer
    
    for node in model._nodes_by_depth[0]:
        for idx, input_tensor in enumerate(node.input_tensors):
            tensor_map[input_tensor] = (input_tensors[idx], None)

    output_tensors = [tensor_map[out_tensor][0] for out_tensor in model.outputs]
    return Model(inputs=input_tensors, outputs=output_tensors, name=model.name)
```

The corrections include handling the creation and mapping of input_tensors appropriately, as well as using the correct input and output tensors to create the new model. This should resolve the error in the failing test.