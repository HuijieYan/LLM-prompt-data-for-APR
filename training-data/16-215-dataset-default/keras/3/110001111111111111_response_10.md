The bug is located in the `_clone_functional_model` function of the `keras/models.py` file. The error is occurring because the function is not correctly handling the multiple inputs and outputs of the model.

The `_clone_functional_model` function is responsible for cloning a functional Model instance. It iterates over the nodes in the reference model and is supposed to create new layers and new weights.

The failing test is trying to clone a model with multiple inputs and outputs, and the error message indicates that the output tensor cannot be computed. This suggests that the cloning process is not handling the multiple outputs correctly.

The GitHub issue further elaborates on the issue, explaining that the error is related to the use of a functional model with a layer that has more outputs without mask support.

To fix this bug, the `_clone_functional_model` function needs to be updated to properly handle models with multiple inputs and outputs, especially when dealing with layers that do not support masks.

One approach to fixing the bug is to revise the logic in the `_clone_functional_model` function to ensure that it properly handles multiple inputs and outputs, and handles layers that do not support masks.

Here's the corrected version of the `_clone_functional_model` function:

```python
def _clone_functional_model(model, input_tensors=None):
    if not isinstance(model, Model):
        raise ValueError('Expected `model` argument to be a `Model` instance, got ', model)

    layer_map = {}  # Cache for created layers
    tensor_map = {}  # Map {reference_tensor: (corresponding_tensor, mask)}

    if input_tensors is None:
        input_tensors = [Input(batch_shape=layer.input.shape) for layer in model.layers if isinstance(layer, InputLayer)]
    else:
        if not all(K.is_keras_tensor(x) for x in input_tensors):
            raise ValueError('All input tensors must come from a Keras layer.')

    for x, y in zip(model.inputs, input_tensors):
        tensor_map[x] = (y, None)  # tensor, mask

    for layer in model.layers:
        if layer not in layer_map:
            new_layer = layer.__class__.from_config(layer.get_config())
            layer_map[layer] = new_layer

    for layer in model.layers:
        if isinstance(layer, InputLayer):
            continue

        reference_input_tensors = layer.input
        computed_data = [tensor_map[x] for x in reference_input_tensors if x in tensor_map]

        if len(computed_data) == len(reference_input_tensors):
            kwargs = {}  # Additional arguments to layer call
            for x, y, mask in zip(layer.input, *zip(*computed_data)):
                tensor_map[x] = (y, mask)

            if has_arg(layer.call, 'mask'):
                kwargs['mask'] = [m for m in mask if m is not None]

            output_tensors = to_list(layer(y, **kwargs) for y in computed_data[0])

            computed_tensors = [y for y, _ in computed_data]

            for x, y in zip(layer.output, output_tensors):
                tensor_map[x] = (y, None)

    output_tensors = [tensor_map[x][0] for x in model.outputs]
    return Model(input_tensors, output_tensors, name=model.name)
```

This corrected version of the function includes improvements to handle multiple input tensors correctly, account for layers without mask support, and properly compute the output tensors.

With these changes, the function should now successfully clone functional models with multiple inputs and outputs, as well as properly handle layers without mask support. This corrected code should pass the failing test and resolve the issue reported in the GitHub post.