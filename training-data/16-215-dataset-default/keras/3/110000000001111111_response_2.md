The issue appears to be related to the usage of clone_model() on a functional model with a layer that has multiple outputs without mask support. This is causing an assertion error when trying to compute the output tensor.

The potential error location within the problematic function seems to be related to the handling of output masks for layers that do not support masks, such as the Lambda layer.

The discrepancy between the expected and actual input/output variable values in the provided test case indicates that the output_masks are always [None], but [None, None] is expected due to the usage of a layer (such as Lambda) that does not support masks.

To fix this issue, the code should be modified to handle the case of layers without mask support and to correctly compute the output tensors and masks.

One possible approach for fixing the bug is to check for mask support in the layers and handle the computation of output tensors and masks accordingly. If a layer does not support masks, the output_mask should be set to None.

Here's the corrected code for the problematic function:

```python
def _clone_functional_model(model, input_tensors=None):
    # ... (previous implementation)

    # Check if the layer supports masking
    supports_masking = getattr(layer, 'supports_masking', False)

    # Compute the output tensor and mask
    if supports_masking:
        output_tensors = to_list(layer(computed_tensor, **kwargs))
        output_masks = to_list(layer.compute_mask(computed_tensor, computed_mask))
    else:
        output_tensors = to_list(layer(computed_tensor, **kwargs))
        output_masks = [None] * len(output_tensors)

    # Update tensor_map
    for x, y, mask in zip(reference_output_tensors, output_tensors, output_masks):
        tensor_map[x] = (y, mask)

    # ... (remaining implementation)
```

This corrected code should handle the case of layers without mask support and correctly compute the output tensors and masks, resolving the issue reported in the GitHub issue.