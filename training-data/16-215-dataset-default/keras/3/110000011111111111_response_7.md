The bug in the `_clone_functional_model` function seems to be related to the way it handles layers with multiple outputs. The error message from the failing test indicates that the function is unable to compute the output tensor for a specific layer.

Upon analysis of the function, it appears that the issue might be related to the way it handles the creation of new layers, gathering inputs, and computing output tensors and masks.

The failing test provides the input values and the type of variables at the function's return, which includes information about `layer_map`, `tensor_map`, `input_tensors`, `input_layers`, and various input and output tensors. The discrepancy between the expected and actual output variables, as well as the error message, suggests that the function is not correctly handling the computation of output tensors and masks for layers with multiple outputs.

The GitHub issue further supports this by describing a similar issue with layers having multiple outputs without mask support.

To fix the bug, the function needs to be updated to handle layers with multiple outputs more accurately, particularly regarding the computation of output tensors and masks.

Here's the corrected code for the `_clone_functional_model` function:

```python
def _clone_functional_model(model, input_tensors=None):
    if not isinstance(model, Model):
        raise ValueError('Expected `model` argument to be a `Model` instance, got ', model)
    if isinstance(model, Sequential):
        raise ValueError('Expected `model` argument to be a functional `Model` instance, got a `Sequential` instance instead:', model)

    layer_map = {}
    tensor_map = {}
    if input_tensors is None:
        input_tensors = [Input(batch_shape=layer.input_shape, dtype=layer.dtype, name=layer.name) for layer in model._input_layers]
    else:
        input_tensors = to_list(input_tensors)

    for x, y in zip(model.inputs, input_tensors):
        tensor_map[x] = (y, None)

    for _, node in model._nodes_by_depth.items():
        for layer in node:
            if layer not in layer_map:
                new_layer = layer.__class__.from_config(layer.get_config())
                layer_map[layer] = new_layer
                layer = new_layer

            reference_input_tensors = node.input_tensors
            reference_output_tensors = node.output_tensors

            computed_data = [(tensor_map[x][0], None) for x in reference_input_tensors if x in tensor_map]

            if len(computed_data) == len(reference_input_tensors):
                kwargs = node.arguments if node.arguments else {}
                computed_tensors = [x[0] for x in computed_data]
                output_tensors = to_list(layer(computed_tensors, **kwargs))
                tensor_map.update({x: (y, None) for x, y in zip(reference_output_tensors, output_tensors)})

    output_tensors = [tensor_map[x][0] for x in model.outputs]
    return Model(input_tensors, output_tensors, name=model.name)
```

This corrected code should address the issues with computing output tensors for layers with multiple outputs and appropriately handle the cloning of the functional model. It also removes unnecessary parts of the original code, simplifying the logic for clarity and maintainability.