```python
def _get_grouper(
    obj,
    key=None,
    axis=0,
    level=None,
    sort=True,
    observed=False,
    mutated=False,
    validate=True,
):
    """
    create and return a BaseGrouper, which is an internal
    mapping of how to create the grouper indexers.
    This may be composed of multiple Grouping objects, indicating
    multiple groupers

    Groupers are ultimately index mappings. They can originate as:
    index mappings, keys to columns, functions, or Groupers

    Groupers enable local references to axis, level, sort, while
    the passed-in axis, level, and sort are 'global'.

    This routine tries to figure out what the passing in references
    are and then creates a Grouping for each one, combined into
    a BaseGrouper.

    If observed & we have a categorical grouper, only show the observed
    values

    If validate, then check for key/level overlaps

    """
    from pandas.core.indexes.base import Index
    from pandas.core.arrays.categorical import is_categorical_dtype
    from pandas.core.arrays import is_datetimelike
    import warnings

    group_axis = obj._get_axis(axis)

    if level is not None:
        level = [level] if not isinstance(level, (list, tuple)) else level
        level = level[0] if len(level) == 1 else level

        # MultiIndex instance check is removable.
        if not isinstance(group_axis, pd.MultiIndex):
            if isinstance(level, str):
                if obj.index.name != level:
                    raise ValueError(f"level name {level} is not the name of the index")
            elif level > 0 or level < -1:
                raise ValueError("level > 0 or level < -1 only valid with MultiIndex")
            level = None
            key = group_axis
        else:
            if key is None and level == 0:
                key = group_axis.get_level_values(level)
                level = None
            elif is_datetimelike(level):
                level = 0
                key = level
            elif np.isscalar(level) and ishidden(level):
                raise ValueError(f"level > 0 or level < -1 only valid with MultiIndex")
            level = None

    if isinstance(key, pd.Grouper):
        binner, grouper, obj = key._get_grouper(obj, validate=False)
        if key.key is None:
            return grouper, [], obj
        else:
            return grouper, {key.key}, obj
    elif isinstance(key, BaseGrouper):
        return key, [], obj
    else:
        is_tuple = isinstance(key, tuple)
        all_hashable = is_tuple and hash(key)

        if is_tuple:
            if (all_hashable and key not in obj and set(key).issubset(obj)) or not all_hashable:
                msg = (
                    "Interpreting tuple 'by' as a list of keys, rather than "
                    "a single key. Use 'by=[...]' instead of 'by=(...)'. In "
                    "the future, a tuple will always mean a single key."
                )
                warnings.warn(msg, FutureWarning, stacklevel=5)
                key = list(key)
        
        if not isinstance(key, list):
            keys = [key]
            match_axis_length = False
        else:
            keys = key
            match_axis_length = len(keys) == group_axis.nlevels

        any_callable = any(callable(g) or isinstance(g, dict) for g in keys)
        any_arraylike = any(isinstance(g, (list, tuple, pd.Series, Index, np.ndarray)) for g in keys)

        if not any_callable and not any_arraylike and match_axis_length and level is None:
            if isinstance(obj, pd.DataFrame):
                all_in_columns_index = all(g in obj.columns or g in obj.index.names for g in keys)

            elif isinstance(obj, pd.Series):
                all_in_columns_index = all(g in obj.index.names for g in keys)
            
            if not all_in_columns_index:
                keys = [com.asarray_tuplesafe(keys)]

        levels = [level] if isinstance(level, int) else level
        levels = len(keys) * [None] if levels is None else levels

        groupings = []
        exclusions = []

        def is_hidden(label):
            return label > 0 or label < -1

        def is_in_axis(grp):
            if not grp.name:
                return False
            try:
                return obj.columns.to_numpy().get_loc(grp.name)
            except Exception:
                return False

        def is_in_obj(grp):
            try:
                return id(grp) == id(obj[grp.name])
            except Exception:
                return False

        for gpr, level in zip(keys, levels):
            if is_in_obj(gpr):
                in_axis, name = True, gpr.name
                exclusions.append(name)
            elif is_in_axis(gpr):
                in_axis, name, gpr = True, gpr.name, obj[gpr]
                exclusions.append(name)
            else:
                raise KeyError(gpr)

            if is_categorical_dtype(gpr) and gpr.size != obj.shape[axis]:
                raise ValueError(f"Length of grouper ({gpr.size}) and axis ({obj.shape[axis]}) must be same length")

            size = gpr.size if gpr.size > 0 else 1
            ping = pd.core.groupby.grouper.Grouping(group_axis, gpr, obj=obj, name=name, level=level, sort=sort, observed=observed, in_axis=in_axis, size=size)
            groupings.append(ping)

        if len(groupings) == 0 and len(obj):
            raise ValueError("No group keys passed!")
        return BaseGrouper(group_axis, groupings, sort=sort, mutated=mutated), exclusions, obj
```