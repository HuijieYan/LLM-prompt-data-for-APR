{
    "pandas": [
        {
            "bugID": 168,
            "bitvector": {
                "1.1.1": 1,
                "1.1.2": 1,
                "1.2.1": 0,
                "1.2.2": 0,
                "1.2.3": 0,
                "1.3.1": 0,
                "1.3.2": 0,
                "1.4.1": 1,
                "1.4.2": 1,
                "2.1.1": 1,
                "2.1.2": 1,
                "2.1.3": 1,
                "2.1.4": 1,
                "2.1.5": 1,
                "2.1.6": 1,
                "3.1.1": 1,
                "3.1.2": 1,
                "cot": 0
            },
            "strata": {
                "1": 1,
                "2": 0,
                "3": 0,
                "4": 1,
                "5": 1,
                "6": 1,
                "7": 0
            },
            "available_bitvector": {
                "1.1.1": 1,
                "1.1.2": 1,
                "1.2.1": 0,
                "1.2.2": 0,
                "1.2.3": 0,
                "1.3.1": 0,
                "1.3.2": 0,
                "1.4.1": 1,
                "1.4.2": 1,
                "2.1.1": 1,
                "2.1.2": 1,
                "2.1.3": 1,
                "2.1.4": 1,
                "2.1.5": 1,
                "2.1.6": 1,
                "3.1.1": 1,
                "3.1.2": 1,
                "cot": 0
            },
            "available_strata": {
                "1": 1,
                "2": 0,
                "3": 0,
                "4": 1,
                "5": 1,
                "6": 1,
                "7": 0
            },
            "start_line": 425,
            "file_name": "pandas/core/groupby/grouper.py",
            "replace_code": "def _get_grouper(\n    obj,\n    key=None,\n    axis=0,\n    level=None,\n    sort=True,\n    observed=False,\n    mutated=False,\n    validate=True,\n):\n    group_axis = obj._get_axis(axis)\n\n    # validate that the passed single level is compatible with the passed\n    # axis of the object\n    if level is not None:\n        if isinstance(group_axis, pd.MultiIndex):\n            if pd.api.types.is_list_like(level) and len(level) == 1:\n                level = level[0]\n\n            if key is None and pd.api.types.is_scalar(level):\n                # Get the level values from group_axis\n                key = group_axis.get_level_values(level)\n                level = None\n        else:\n            if pd.api.types.is_list_like(level):\n                nlevels = len(level)\n                if nlevels == 1:\n                    level = level[0]\n                elif nlevels == 0:\n                    raise ValueError(\"No group keys passed!\")\n                else:\n                    raise ValueError(\"multiple levels only valid with MultiIndex\")\n\n            if isinstance(level, str):\n                if obj.index.name != level:\n                    raise ValueError(\n                        \"level name {} is not the name of the index\".format(level)\n                    )\n            elif level > 0 or level < -1:\n                raise ValueError(\"level > 0 or level < -1 only valid with MultiIndex\")\n\n            level = None\n            key = group_axis\n\n    # a passed-in Grouper, directly convert\n    if isinstance(key, pd.Grouper):\n        binner, grouper, obj = key._get_grouper(obj, validate=False)\n        if key.key is None:\n            return grouper, [], obj\n        else:\n            return grouper, {key.key}, obj\n\n    # already have a BaseGrouper, just return it\n    elif isinstance(key, pd.BaseGrouper):\n        return key, [], obj\n\n    # In the future, a tuple key will always mean an actual key,\n    # not an iterable of keys. In the meantime, we attempt to provide\n    # a warning. We can assume that the user wanted a list of keys when\n    # the key is not in the index. We just have to be careful with\n    # unhashable elements of `key`. Any unhashable elements implies that\n    # they wanted a list of keys.\n    # https://github.com/pandas-dev/pandas/issues/18314\n    is_tuple = isinstance(key, tuple)\n    all_hashable = is_tuple and pd.api.types.is_hashable(key)\n\n    if is_tuple:\n        if (\n            all_hashable and key not in obj and set(key).issubset(obj)\n        ) or not all_hashable:\n            msg = (\n                \"Interpreting tuple 'by' as a list of keys, rather than \"\n                \"a single key. Use 'by=[...]' instead of 'by=(...)'. In \"\n                \"the future, a tuple will always mean a single key.\"\n            )\n            warnings.warn(msg, FutureWarning, stacklevel=5)\n            key = list(key)\n\n    if not isinstance(key, list):\n        keys = [key]\n        match_axis_length = False\n    else:\n        keys = key\n        match_axis_length = len(keys) == len(group_axis)\n\n    # what are we after, exactly?\n    any_callable = any(callable(g) or isinstance(g, dict) for g in keys)\n    any_groupers = any(isinstance(g, pd.Grouper) for g in keys)\n    any_arraylike = any(\n        isinstance(g, (list, tuple, pd.Series, pd.Index, np.ndarray)) for g in keys\n    )\n\n    # is this an index replacement?\n    if (\n        not any_callable\n        and not any_arraylike\n        and not any_groupers\n        and match_axis_length\n        and level is None\n    ):\n        if isinstance(obj, pd.DataFrame):\n            all_in_columns_index = all(\n                g in obj.columns or g in obj.index.names for g in keys\n            )\n        elif isinstance(obj, pd.Series):\n            all_in_columns_index = all(g in obj.index.names for g in keys)\n\n        if not all_in_columns_index:\n            keys = [pd.compat.asarray_tuplesafe(keys)]\n\n    if isinstance(level, (tuple, list)):\n        if key is None:\n            keys = [None] * len(level)\n        levels = level\n    else:\n        levels = [level] * len(keys)\n\n    groupings = []\n    exclusions = []\n\n    for i, (gpr, lvl) in enumerate(zip(keys, levels)):\n\n        in_axis = not pd.api.types.is_list_like(gpr) and gpr in obj.columns\n        is_index_level = not in_axis and not pd.api.types.is_scalar(gpr)\n        \n        if is_index_level:\n            if gpr not in obj.index.names:\n                raise KeyError(gpr)\n        elif in_axis and validate:\n            obj._check_label_or_level_ambiguity(gpr)\n        elif not in_axis and not is_index_level and validate:\n            raise KeyError(gpr)\n\n        if pd.api.types.is_categorical_dtype(gpr) and pd.api.types.is_scalar(gpr) and len(gpr) != obj.shape[axis]:\n            raise ValueError(\n                f\"Length of grouper ({len(gpr)}) and axis ({obj.shape[axis]}) must be same length\"\n            )\n        elif not pd.api.types.is_categorical_dtype(gpr):\n            pass\n\n        ping = (\n            pd.core.groupby.grouper.Grouping(\n                group_axis,\n                gpr,\n                obj=obj,\n                name=None if in_axis or is_index_level else gpr,\n                level=None if in_axis or is_index_level else lvl,\n                sort=sort,\n                observed=observed,\n                in_axis=in_axis or is_index_level,\n            )\n            if not isinstance(gpr, pd.core.groupby.grouper.Grouping)\n            else gpr\n        )\n\n        groupings.append(ping)\n\n    if len(groupings) == 0 and len(obj):\n        raise ValueError(\"No group keys passed!\")\n    elif len(groupings) == 0:\n        groupings.append(pd.core.groupby.grouper.Grouping(pd.Index([], dtype=\"int\"), np.array([], dtype=np.intp)))\n    else:\n        groupings = [ping for ping in groupings if ping.name is not None]\n\n    grouper = pd.core.groupby.grouper.BaseGrouper(group_axis, groupings, sort=sort, mutated=mutated)\n    return grouper, exclusions, obj",
            "import_list": []
        }
    ]
}