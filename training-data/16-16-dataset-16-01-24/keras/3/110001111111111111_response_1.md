The bug in the `_clone_functional_model` function seems to be related to the handling of input tensors and the creation of new layers. The error message indicates that the output tensor `Tensor("swap_layer_1/Identity:0", shape=(?, 4), dtype=float32)` could not be computed.

The issue seems to be related to the creation of new layers and the mapping of input and output tensors. The function is not handling the case where a layer does not support masks, leading to the error in the failing test.

To fix the bug, the function needs to be modified to properly handle layers that do not support masks. Additionally, the creation of new layers and the mapping of input and output tensors should be reviewed to ensure correctness.

Possible approaches for fixing the bug:
1. Check if the layer supports masks before attempting to compute masks.
2. Ensure that the creation of new layers and the mapping of input and output tensors are done correctly.

Here's the corrected code for the `_clone_functional_model` function:

```python
def _clone_functional_model(model, input_tensors=None):
    # ... (existing code)

    for x, y in zip(model.inputs, input_tensors):
        tensor_map[x] = (y, None)  # tensor, mask

    # Iterated over every node in the reference model, in depth order.
    depth_keys = list(model._nodes_by_depth.keys())
    depth_keys.sort(reverse=True)
    for depth in depth_keys:
        nodes = model._nodes_by_depth[depth]
        for node in nodes:
            # Recover the corresponding layer.
            layer = node.outbound_layer

            # Get or create layer.
            if layer not in layer_map:
                # Clone layer.
                new_layer = layer.__class__.from_config(layer.get_config())
                layer_map[layer] = new_layer
                layer = new_layer
            else:
                # Reuse previously cloned layer.
                layer = layer_map[layer]
                # Don't call InputLayer multiple times.
                if isinstance(layer, InputLayer):
                    continue

            # Gather inputs to call the new layer.
            reference_input_tensors = node.input_tensors
            reference_output_tensors = node.output_tensors

            # If all previous input tensors are available in tensor_map,
            # then call node.inbound_layer on them.
            computed_data = []  # List of tuples (input, mask).
            for x in reference_input_tensors:
                if x in tensor_map:
                    computed_data.append(tensor_map[x])

            if len(computed_data) == len(reference_input_tensors):
                # Call layer.
                kwargs = node.arguments if node.arguments else {}
                computed_tensors = [x[0] for x in computed_data]
                output_tensors = to_list(layer(computed_tensors, **kwargs))
                # Update tensor_map.
                for x, y in zip(reference_output_tensors, output_tensors):
                    tensor_map[x] = (y, None)

    # Check that we did compute the model outputs,
    # then instantiate a new model from inputs and outputs.
    output_tensors = [tensor_map[x][0] for x in model.outputs]
    return Model(input_tensors, output_tensors, name=model.name)
```

This corrected code should address the issues related to the creation of new layers, handling of input tensors, and mapping of input and output tensors. It should pass the failing test and resolve the issue reported in the GitHub post.