The bug in the `_clone_functional_model` function seems to be related to the handling of input tensors and the creation of new layers. The error message indicates that the output tensor `Tensor("swap_layer_1/Identity:0", shape=(?, 4), dtype=float32)` could not be computed, which suggests that there is an issue with the creation of new layers and the mapping of input and output tensors.

The failing test involves creating a model with multiple inputs and outputs, including a custom `Lambda` layer and a `SwapLayer`. The error occurs when trying to clone the model using `keras.models.clone_model`.

The input and output variable information shows that the `layer_map` and `tensor_map` are being populated with the input tensors and newly created layers, but there seems to be an issue with the mapping of input and output tensors, as well as the creation of new layers.

The GitHub issue provides a similar scenario where the error occurs when using a functional model with a layer that has multiple outputs without mask support.

To fix the bug, the `_clone_functional_model` function needs to be modified to correctly handle the creation of new layers and the mapping of input and output tensors. Additionally, the handling of layers with multiple outputs and mask support needs to be addressed.

Here's the corrected code for the `_clone_functional_model` function:

```python
def _clone_functional_model(model, input_tensors=None):
    if not isinstance(model, Model):
        raise ValueError('Expected `model` argument to be a `Model` instance, got ', model)

    layer_map = {}  # Cache for created layers
    tensor_map = {}  # Map {reference_tensor: (corresponding_tensor, mask)}

    if input_tensors is None:
        input_tensors = [Input(batch_shape=layer.batch_input_shape, dtype=layer.dtype, sparse=layer.sparse, name=layer.name) for layer in model._input_layers]
    else:
        input_tensors = to_list(input_tensors)

    for x, y in zip(model.inputs, input_tensors):
        tensor_map[x] = (y, None)  # tensor, mask

    for depth in range(len(model._nodes_by_depth)):
        nodes = model._nodes_by_depth[depth]
        for node in nodes:
            layer = node.outbound_layer

            if layer not in layer_map:
                new_layer = layer.__class__.from_config(layer.get_config())
                layer_map[layer] = new_layer
            else:
                layer = layer_map[layer]

            reference_input_tensors = node.input_tensors
            reference_output_tensors = node.output_tensors

            computed_data = [(tensor_map[x][0], None) for x in reference_input_tensors if x in tensor_map]

            if len(computed_data) == len(reference_input_tensors):
                kwargs = node.arguments if node.arguments else {}
                computed_tensors = [x[0] for x in computed_data]
                output_tensors = to_list(layer(computed_tensors, **kwargs))

                for x, y in zip(reference_output_tensors, output_tensors):
                    tensor_map[x] = (y, None)

    output_tensors = [tensor_map[x][0] for x in model.outputs]
    return Model(input_tensors, output_tensors, name=model.name)
```

This corrected code should address the issues with creating new layers, mapping input and output tensors, and handling layers with multiple outputs and mask support.

With this corrected code, the function should pass the failing test and satisfy the expected input/output variable information. It should also resolve the issue reported in the GitHub post.