Please fix the buggy function provided below and output a corrected version.


# The source code of the buggy function
```python
# The relative path of the buggy file: luigi/contrib/spark.py

# This function from the same file, but not the same class, is called by the buggy function
def name(self):
    # Please ignore the body of this function

# The declaration of the class containing the buggy function
class SparkSubmitTask(luigi.Task):
    """
    Template task for running a Spark job
    
    Supports running jobs on Spark local, standalone, Mesos or Yarn
    
    See http://spark.apache.org/docs/latest/submitting-applications.html
    for more information
    """





    # this is the buggy function you need to fix
    def _dict_arg(self, name, value):
        command = []
        if value and isinstance(value, dict):
            for prop, value in value.items():
                command += [name, '"{0}={1}"'.format(prop, value)]
        return command
    
```

# A failing test function for the buggy function
```python
# The relative path of the failing test file: test/contrib/spark_test.py

    @with_config({'spark': {'spark-submit': ss, 'master': "yarn-client", 'hadoop-conf-dir': 'path'}})
    @patch('luigi.contrib.spark.subprocess.Popen')
    def test_run(self, proc):
        setup_run_process(proc)
        job = TestSparkSubmitTask()
        job.run()

        self.assertEqual(proc.call_args[0][0],
                         ['ss-stub', '--master', 'yarn-client', '--deploy-mode', 'client', '--name', 'AppName',
                          '--class', 'org.test.MyClass', '--jars', 'jars/my.jar', '--py-files', 'file1.py,file2.py',
                          '--files', 'file1,file2', '--archives', 'archive1,archive2', '--conf', 'Prop=Value',
                          '--properties-file', 'conf/spark-defaults.conf', '--driver-memory', '4G', '--driver-java-options', '-Xopt',
                          '--driver-library-path', 'library/path', '--driver-class-path', 'class/path', '--executor-memory', '8G',
                          '--driver-cores', '8', '--supervise', '--total-executor-cores', '150', '--executor-cores', '10',
                          '--queue', 'queue', '--num-executors', '2', 'file', 'arg1', 'arg2'])
```

## The error message from the failing test
```text
self = <contrib.spark_test.SparkSubmitTaskTest testMethod=test_run>
proc = <MagicMock name='Popen' id='4522315984'>

    @with_config({'spark': {'spark-submit': ss, 'master': "yarn-client", 'hadoop-conf-dir': 'path'}})
    @patch('luigi.contrib.spark.subprocess.Popen')
    def test_run(self, proc):
        setup_run_process(proc)
        job = TestSparkSubmitTask()
        job.run()
    
>       self.assertEqual(proc.call_args[0][0],
                         ['ss-stub', '--master', 'yarn-client', '--deploy-mode', 'client', '--name', 'AppName',
                          '--class', 'org.test.MyClass', '--jars', 'jars/my.jar', '--py-files', 'file1.py,file2.py',
                          '--files', 'file1,file2', '--archives', 'archive1,archive2', '--conf', 'Prop=Value',
                          '--properties-file', 'conf/spark-defaults.conf', '--driver-memory', '4G', '--driver-java-options', '-Xopt',
                          '--driver-library-path', 'library/path', '--driver-class-path', 'class/path', '--executor-memory', '8G',
                          '--driver-cores', '8', '--supervise', '--total-executor-cores', '150', '--executor-cores', '10',
                          '--queue', 'queue', '--num-executors', '2', 'file', 'arg1', 'arg2'])
E       AssertionError: Lists differ: ['ss-[240 chars]f', '"Prop=Value"', '--properties-file', 'conf[346 chars]rg2'] != ['ss-[240 chars]f', 'Prop=Value', '--properties-file', 'conf/s[344 chars]rg2']
E       
E       First differing element 18:
E       '"Prop=Value"'
E       'Prop=Value'
E       
E       Diff is 812 characters long. Set self.maxDiff to None to see it.

test/contrib/spark_test.py:149: AssertionError

```
# A failing test function for the buggy function
```python
# The relative path of the failing test file: test/contrib/spark_test.py

    @with_config({'spark': {'spark-submit': ss, 'master': 'spark://host:7077', 'conf': 'prop1=val1', 'jars': 'jar1.jar,jar2.jar',
                            'files': 'file1,file2', 'py-files': 'file1.py,file2.py', 'archives': 'archive1'}})
    @patch('luigi.contrib.spark.subprocess.Popen')
    def test_defaults(self, proc):
        proc.return_value.returncode = 0
        job = TestDefaultSparkSubmitTask()
        job.run()
        self.assertEqual(proc.call_args[0][0],
                         ['ss-stub', '--master', 'spark://host:7077', '--jars', 'jar1.jar,jar2.jar',
                          '--py-files', 'file1.py,file2.py', '--files', 'file1,file2', '--archives', 'archive1',
                          '--conf', 'prop1=val1', 'test.py'])
```

## The error message from the failing test
```text
self = <contrib.spark_test.SparkSubmitTaskTest testMethod=test_defaults>
proc = <MagicMock name='Popen' id='4522656528'>

    @with_config({'spark': {'spark-submit': ss, 'master': 'spark://host:7077', 'conf': 'prop1=val1', 'jars': 'jar1.jar,jar2.jar',
                            'files': 'file1,file2', 'py-files': 'file1.py,file2.py', 'archives': 'archive1'}})
    @patch('luigi.contrib.spark.subprocess.Popen')
    def test_defaults(self, proc):
        proc.return_value.returncode = 0
        job = TestDefaultSparkSubmitTask()
        job.run()
>       self.assertEqual(proc.call_args[0][0],
                         ['ss-stub', '--master', 'spark://host:7077', '--jars', 'jar1.jar,jar2.jar',
                          '--py-files', 'file1.py,file2.py', '--files', 'file1,file2', '--archives', 'archive1',
                          '--conf', 'prop1=val1', 'test.py'])
E       AssertionError: Lists differ: ['ss-[131 chars] '--archives', 'archive1', '--conf', '"prop1=val1"', 'test.py'] != ['ss-[131 chars] '--archives', 'archive1', '--conf', 'prop1=val1', 'test.py']
E       
E       First differing element 12:
E       '"prop1=val1"'
E       'prop1=val1'
E       
E         ['ss-stub',
E          '--master',
E          'spark://host:7077',
E          '--jars',
E          'jar1.jar,jar2.jar',
E          '--py-files',
E          'file1.py,file2.py',
E          '--files',
E          'file1,file2',
E          '--archives',
E          'archive1',
E          '--conf',
E       -  '"prop1=val1"',
E       ?   -          -
E       
E       +  'prop1=val1',
E          'test.py']

test/contrib/spark_test.py:165: AssertionError

```


