The bug in the `_clone_functional_model` function is likely caused by the incorrect handling of input tensors when creating a clone of the model, specifically related to checking whether all previous input tensors are available in tensor_map before calling a node's inbound layer on them.

The failing test is trying to clone a functional model with multiple outputs, however, the function fails to properly compute the output tensors for the new model and raises an assertion error.

To fix this bug, we need to ensure that the output tensors are properly computed and added to the `tensor_map`. Additionally, we need to handle the case where the layer being called is an `InputLayer` to avoid calling it multiple times.

Here's the corrected code for the `_clone_functional_model` function:

```python
def _clone_functional_model(model, input_tensors=None):
    # ... (other parts of the function remain unchanged)
    
    for depth in depth_keys:
        nodes = model._nodes_by_depth[depth]
        for node in nodes:
            # ... (other parts of the loop remain unchanged)
            
            # If all previous input tensors are available in tensor_map,
            # then call node.inbound_layer on them.
            computed_data = []  # List of tuples (input, mask).
            for x in reference_input_tensors:
                if x in tensor_map:
                    computed_data.append(tensor_map[x])
            if len(computed_data) == len(reference_input_tensors):
                # Call layer.
                if node.arguments:
                    kwargs = node.arguments
                else:
                    kwargs = {}
                computed_tensors = [x[0] for x in computed_data]
                computed_masks = [x[1] for x in computed_data]
                # Call the layer if it's not an InputLayer
                if not isinstance(layer, InputLayer):
                    if has_arg(layer.call, 'mask') and 'mask' not in kwargs:
                        kwargs['mask'] = computed_masks
                    # Ensure input_tensors is a list
                    input_tensors = computed_tensors if len(computed_tensors) > 1 else computed_tensors[0]
                    output_tensors = to_list(layer(input_tensors, **kwargs))
                    output_masks = to_list(layer.compute_mask(input_tensors, computed_masks))
                    if isinstance(output_tensors, list) and isinstance(output_masks, list):
                        for x, y, mask in zip(reference_output_tensors, output_tensors, output_masks):
                            tensor_map[x] = (y, mask)
                    else:
                        tensor_map[reference_output_tensors[0]] = (output_tensors, output_masks)
                
    # ... (other parts of the function remain unchanged)
```

With these changes, the function will properly compute the output tensors and add them to the `tensor_map`, ensuring that the new model is created with the correct behavior.

This corrected code should pass the failing test and maintain the expected input/output variable information.