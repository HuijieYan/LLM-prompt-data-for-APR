The bug is occurring in the `_clone_functional_model` function when it tries to compute the output tensors. It is failing to compute the output tensor 'Tensor("swap_layer_1/Identity:0", shape=(?, 4), dtype=float32)'.

The failing test is trying to clone a functional model with multiple outputs, and the bug seems to be related to how the function handles layers with multiple inputs and outputs.

Based on the provided information, it seems that the issue is related to the handling of layers with multiple inputs and outputs, and the computation of masks for the layers.

One possible approach to fixing the bug could be to modify the function to handle layers with multiple inputs and outputs more effectively, and to ensure that the masks are computed correctly for these layers.

Additionally, the function should be updated to address the issue raised in the GitHub post, where layers with multiple outputs and no mask support are causing an error.

Here's the corrected code for the problematic function:

```python
def _clone_functional_model(model, input_tensors=None):
    if not isinstance(model, Model):
        raise ValueError('Expected `model` argument to be a `Model` instance, got ', model)

    if isinstance(model, Sequential):
        raise ValueError('Expected `model` argument to be a functional `Model` instance, got a `Sequential` instance instead:', model)

    layer_map = {}  # Cache for created layers.
    tensor_map = {}  # Map {reference_tensor: (corresponding_tensor, mask)}

    if input_tensors is None:
        input_tensors = [Input(batch_shape=layer.input.shape, dtype=layer.input.dtype, sparse=layer.input.sparse, name=layer.input.name) for layer in model.layers if isinstance(layer, InputLayer)]
    else:
        input_tensors = [Input(tensor=x) if not K.is_keras_tensor(x) else x for x in to_list(input_tensors)]

    for x, y in zip(model.inputs, input_tensors):
        tensor_map[x] = (y, None)  # tensor, mask

    for depth in range(len(model._nodes_by_depth) - 1, -1, -1):
        nodes = model._nodes_by_depth[depth]
        for node in nodes:
            layer = node.outbound_layer

            if layer not in layer_map:
                new_layer = layer.__class__.from_config(layer.get_config())
                layer_map[layer] = new_layer
                layer = new_layer
            else:
                layer = layer_map[layer]
                if isinstance(layer, InputLayer):
                    continue

            reference_input_tensors = node.input_tensors
            reference_output_tensors = node.output_tensors

            computed_data = [(tensor_map[x][0], tensor_map[x][1]) for x in reference_input_tensors if x in tensor_map]

            if len(computed_data) == len(reference_input_tensors):
                kwargs = node.arguments if node.arguments else {}
                computed_tensors, computed_masks = zip(*computed_data)
                output_tensors = to_list(layer(computed_tensors, **kwargs))

                for x, y, mask in zip(reference_output_tensors, output_tensors, [None] * len(output_tensors)):
                    tensor_map[x] = (y, mask)

    output_tensors = [tensor_map[x][0] for x in model.outputs]
    return Model(input_tensors, output_tensors, name=model.name)
```

With this corrected function, the failing test should pass and the issue described in the GitHub post should be resolved.