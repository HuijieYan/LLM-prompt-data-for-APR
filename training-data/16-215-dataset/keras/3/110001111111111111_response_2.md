The bug is caused by the erroneous handling of input tensors and layers during the cloning process, resulting in the failure to compute the model outputs. The error message "Could not compute output Tensor" indicates that the output tensor could not be computed during the model cloning process.

To fix the bug, the function needs to be updated to correctly handle the cloning of input layers and tensors, as well as the computation of output tensors for the cloned model.

Here's the corrected code for the problematic function:

```python
def _clone_functional_model(model, input_tensors=None):
    if not isinstance(model, Model):
        raise ValueError('Expected `model` argument to be a `Model` instance, got ', model)

    layer_map = {}  # Cache for created layers.
    tensor_map = {}  # Map {reference_tensor: (corresponding_tensor, mask)}
    if input_tensors is None:
        # Create placeholders to build the model on top of.
        input_layers = []
        input_tensors = []
        for layer in model._input_layers:
            input_tensor = Input(batch_shape=layer.batch_input_shape,
                                 dtype=layer.dtype,
                                 sparse=layer.sparse,
                                 name=layer.name)
            input_tensors.append(input_tensor)
            # Cache newly created input layer.
            newly_created_input_layer = input_tensor._keras_history[0]
            layer_map[layer] = newly_created_input_layer
    else:
        # Map input tensors to input layers
        for i, x in enumerate(input_tensors):
            if not K.is_keras_tensor(x):
                original_input_layer = model._input_layers[i]
                name = original_input_layer.name
                input_tensor = Input(tensor=x, name='input_wrapper_for_' + name)
                input_tensors[i] = input_tensor
                # Cache newly created input layer.
                newly_created_input_layer = input_tensor._keras_history[0]
                layer_map[original_input_layer] = newly_created_input_layer

    for x, y in zip(model.inputs, input_tensors):
        tensor_map[x] = (y, None)  # tensor, mask

    # Iterated over every node in the reference model, in depth order.
    depth_keys = list(model._nodes_by_depth.keys())
    depth_keys.sort(reverse=True)
    for depth in depth_keys:
        nodes = model._nodes_by_depth[depth]
        for node in nodes:
            # Recover the corresponding layer.
            layer = node.outbound_layer

            # Get or create layer.
            if layer not in layer_map:
                # Clone layer.
                new_layer = layer.__class__.from_config(layer.get_config())
                layer_map[layer] = new_layer

            # Gather inputs to call the new layer.
            reference_input_tensors = node.input_tensors

            # If all previous input tensors are available in tensor_map,
            # then call node.inbound_layer on them.
            computed_data = []  # List of tuples (input, mask).
            for x in reference_input_tensors:
                if x in tensor_map:
                    computed_data.append(tensor_map[x])

            if len(computed_data) == len(reference_input_tensors):
                # Call layer.
                kwargs = node.arguments if node.arguments else {}
                computed_tensors = [x[0] for x in computed_data]
                output_tensors = to_list(layer(computed_tensors, **kwargs))

                # Update tensor_map.
                for x, y in zip(node.output_tensors, output_tensors):
                    tensor_map[x] = (y, None)

    # Check that we did compute the model outputs,
    # then instantiate a new model from inputs and outputs.
    output_tensors = [tensor_map[x][0] for x in model.outputs]
    return Model(input_tensors, output_tensors, name=model.name)
```

The correction involves correctly mapping input tensors to their corresponding input layers, cloning layers, gathering inputs to call the new layer, computing output tensors, and instantiating a new model from inputs and outputs.

With the corrected function, the failing test should pass without any AssertionError. Additionally, the corrected function should also address the issue reported in the GitHub post.

This should resolve the bug and ensure that the function works as expected.