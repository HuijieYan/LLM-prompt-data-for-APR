The issue arises in the `clone_functional_model` function when it tries to compute the output tensors for a layer with multiple output tensors, but some of them do not support using masks. This leads to the `output_masks` being set to `None`, causing the error.

To fix this bug, we need to update the code to handle the case where the layer does not support masking and ensure that the output masks are set correctly.

Here's the corrected code for the `clone_functional_model` function:

```python
def _clone_functional_model(model, input_tensors=None):
    # ... (existing code)

    for x, y in zip(model.inputs, input_tensors):
        tensor_map[x] = (y, None)  # tensor, mask

    # Iterated over every node in the reference model, in depth order.
    depth_keys = list(model._nodes_by_depth.keys())
    depth_keys.sort(reverse=True)
    for depth in depth_keys:
        nodes = model._nodes_by_depth[depth]
        for node in nodes:
            # Recover the corresponding layer.
            layer = node.outbound_layer

            # Get or create layer.
            if layer not in layer_map:
                new_layer = layer.__class__.from_config(layer.get_config())
                layer_map[layer] = new_layer
                layer = new_layer
            else:
                layer = layer_map[layer]

            # Gather inputs to call the new layer.
            reference_input_tensors = node.input_tensors
            reference_output_tensors = node.output_tensors

            # If all previous input tensors are available in tensor_map,
            # then call node.inbound_layer on them.
            computed_data = []  # List of tuples (input, mask).
            for x in reference_input_tensors:
                if x in tensor_map:
                    computed_data.append(tensor_map[x])

            if len(computed_data) == len(reference_input_tensors):
                # Call layer.
                if node.arguments:
                    kwargs = node.arguments
                else:
                    kwargs = {}
                output_tensors = to_list(
                    layer(K.stack([x[0] for x in computed_data]), **kwargs))  # Stack input tensors for multiple input support
                # Update tensor_map.
                for x, y in zip(reference_output_tensors, output_tensors):
                    tensor_map[x] = (y, None)  # Set output masks to None

    # Check that we did compute the model outputs,
    # then instantiate a new model from inputs and outputs.
    output_tensors = []
    for x in model.outputs:
        assert x in tensor_map, 'Could not compute output ' + str(x)
        tensor, _ = tensor_map[x]
        output_tensors.append(tensor)
    return Model(input_tensors, output_tensors, name=model.name)
```

This updated code includes handling for layers with multiple output tensors that do not support using masks. It stacks the input tensors for these layers and sets the output masks to `None`, addressing the issue mentioned in the GitHub post.

With these changes, the function should now work as expected and not raise the error mentioned in the GitHub issue.