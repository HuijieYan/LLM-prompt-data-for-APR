The bug is caused by the `_clone_functional_model` function not correctly handling the creation of new layers and tensors when cloning the model. This results in the error message that the model outputs could not be computed.

One possible approach to fixing the bug is to ensure that all new layers and tensors are properly cached and used when cloning the model.

Here's the corrected code for the `_clone_functional_model` function:

```python
def _clone_functional_model(model, input_tensors=None):
    """Clone a functional `Model` instance.

    Model cloning is similar to calling a model on new inputs,
    except that it creates new layers (and thus new weights) instead
    of sharing the weights of the existing layers.

    # Arguments
        model: Instance of `Model`.
        input_tensors: optional list of input tensors
            to build the model upon. If not provided,
            placeholders will be created.

    # Returns
        An instance of `Model` reproducing the behavior
        of the original model, on top of new inputs tensors,
        using newly instantiated weights.

    # Raises
        ValueError: in case of invalid `model` argument value.
    """
    if not isinstance(model, Model):
        raise ValueError('Expected `model` argument to be a `Model` instance, got ', model)
    if isinstance(model, Sequential):
        raise ValueError('Expected `model` argument to be a functional `Model` instance, got a `Sequential` instance instead:', model)

    layer_map = {}  # Cache for created layers.
    tensor_map = {}  # Map {reference_tensor: (corresponding_tensor, mask)}
    
    if input_tensors is None:
        # Create placeholders to build the model on top of.
        input_tensors = [Input(batch_input_shape=layer.input.shape[1:]) for layer in model.layers if isinstance(layer, InputLayer)]
    else:
        # Make sure that all input tensors come from a Keras layer.
        input_tensors = to_list(input_tensors)

    for original_layer, new_input_tensor in zip(model._input_layers, input_tensors):
        layer_map[original_layer] = new_input_tensor._keras_history[0]
        tensor_map[original_layer.output] = (new_input_tensor, None)

    for layer in model.layers:
        if layer not in layer_map:
            layer_config = layer.get_config()
            recreated_layer = layer.__class__.from_config(layer_config)
            layer_map[layer] = recreated_layer
            layer_output = None
            for node in model._outbound_nodes:
                if layer in node.inbound_layers:
                    layer_output = node.output_tensors[node.inbound_layers.index(layer)]
                    break
            tensor_map[layer_output] = (recreated_layer(layer_input[layer_map[node.input_layers[0]]]), None)

    new_output_tensors = [mapped_tensor[0] for mapped_tensor in tensor_map.values() if mapped_tensor is not None]

    return Model(input_tensors, new_output_tensors, name=model.name)
```

This corrected code should handle the cloning of the functional model properly and ensure that all layers and tensors are correctly cached and used. It should pass the failing test and satisfy the expected input/output variable information.