The buggy function `_clone_functional_model` is failing when trying to clone a functional model with multiple inputs and outputs, as seen in the failing test case `test_clone_functional_model_with_multi_outputs`. 

The error message indicates an issue with the computation of the model output tensors, specifically failing at the assertion `assert x in tensor_map, 'Could not compute output ' + str(x)'`. This assertion checks if the output tensor computed correctly, and it fails for the tensor `"swap_layer_1/Identity:0"`.

The GitHub issue also provides valuable insight into the bug, indicating that the issue arises when a layer with multiple outputs without mask support is used in a functional model. It leads to the `output_masks` being set as `None`, which is not handled correctly.

To fix the bug, the following approaches can be considered:
1. Check for layers with multiple outputs and handle the `output_masks` appropriately to avoid setting them as `None`.
2. Modify the model cloning process to ensure that the cloned model handles layers without mask support correctly.

Here's the corrected code for the `_clone_functional_model` function:

```python
from tensorflow import keras
from keras.engine.training import Model, Input, Layer
from keras.utils.generic_utils import to_list


def _clone_functional_model(model, input_tensors=None):
    if not isinstance(model, Model):
        raise ValueError('Expected `model` argument to be a `Model` instance')

    layer_map = {}  # Cache for created layers.
    tensor_map = {}  # Map {reference_tensor: (corresponding_tensor, mask)}

    if input_tensors is None:
        input_tensors = [Input(batch_shape=tf.shape(input_tensor)[1:]) for input_tensor in to_list(model.inputs)]

    for original_input_layer, cloned_input_layer in zip(model._input_layers, input_tensors):
        layer_map[original_input_layer] = cloned_input_layer

    for layer in model.layers:
        if layer not in layer_map:
            new_layer = layer.__class__.from_config(layer.get_config())
            layer_map[layer] = new_layer

    for node in model._nodes_by_depth:
        reference_input_tensors = node.input_tensors
        reference_output_tensors = node.output_tensors

        computed_data = []
        for x in reference_input_tensors:
            if x in tensor_map:
                computed_data.append(tensor_map[x])

        if len(computed_data) == len(reference_input_tensors):
            kwargs = node.arguments if node.arguments else {}
            computed_tensors = [x[0] for x in computed_data]
            output_tensors = to_list(layer(computed_tensors, **kwargs))
            for output_tensor, reference_output_tensor in zip(output_tensors, reference_output_tensors):
                tensor_map[reference_output_tensor] = output_tensor

    output_tensors = [tensor_map[x] for x in model.outputs]

    return Model(input_tensors, output_tensors, name=model.name)

```

This corrected code handles the multiple inputs and outputs scenario and ensures that the model cloning process propagates the correct input and output tensors. It addresses the issue reported in the failing test and the GitHub issue.