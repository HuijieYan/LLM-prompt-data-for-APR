The buggy function `_clone_functional_model` is supposed to clone a functional `Model` instance by creating new layers and weights instead of sharing the existing ones. The failing test `test_clone_functional_model_with_multi_outputs` is trying to clone a model with multiple inputs and outputs.

The error message indicates an assertion failure in the line `assert x in tensor_map, 'Could not compute output ' + str(x)`. This suggests that the output tensor of the `SwapLayer` is not being computed properly during the cloning process.

The cause of the bug is likely to be related to the handling of multiple input and output tensors in the `_clone_functional_model` function.

To fix the bug, the function needs to be modified to properly handle models with multiple inputs and outputs, ensuring that all input and output tensors are correctly computed and mapped.

Here's the corrected code for the `_clone_functional_model` function:

```python
def _clone_functional_model(model, input_tensors=None):
    
    # ... (existing code)

    # Iterate over every node in the reference model, in depth order.
    depth_keys = list(model._nodes_by_depth.keys())
    depth_keys.sort(reverse=True)
    for depth in depth_keys:
        nodes = model._nodes_by_depth[depth]
        for node in nodes:
            # Recover the corresponding layer.
            layer = node.outbound_layer

            # Get or create layer.
            if layer not in layer_map:
                # Clone layer.
                new_layer = layer.__class__.from_config(layer.get_config())
                layer_map[layer] = new_layer
                layer = new_layer
            else:
                # Reuse previously cloned layer.
                layer = layer_map[layer]
                # Don't call InputLayer multiple times.
                if isinstance(layer, InputLayer):
                    continue

            # Gather inputs to call the new layer.
            reference_input_tensors = node.input_tensors
            reference_output_tensors = node.output_tensors

            # If all previous input tensors are available in tensor_map,
            # then call node.inbound_layer on them.
            computed_data = []  # List of tuples (input, mask).
            for x in reference_input_tensors:
                if x in tensor_map:
                    computed_data.append(tensor_map[x])

            if len(computed_data) == len(reference_input_tensors):
                # Call layer.
                if node.arguments:
                    kwargs = node.arguments
                else:
                    kwargs = {}
                computed_tensors, computed_masks = zip(*computed_data)
                if has_arg(layer.call, 'mask'):
                    kwargs['mask'] = computed_masks
                output_tensors = to_list(layer(computed_tensors, **kwargs))

                # Update tensor_map.
                for x, y in zip(reference_output_tensors, output_tensors):
                    tensor_map[x] = y

    # Check that we did compute the model outputs,
    # then instantiate a new model from inputs and outputs.
    output_tensors = [tensor_map[x] for x in model.outputs]
    return Model([tensor_map[x] for x in model.inputs], output_tensors, name=model.name)
```

With these corrections, the `_clone_functional_model` function should now properly handle models with multiple inputs and outputs and pass the failing test.