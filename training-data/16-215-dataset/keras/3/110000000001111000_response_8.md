To fix the buggy function, we need to make several changes. Below is the updated and corrected version of the function:

```python
def _clone_functional_model(model, input_tensors=None):
    if not isinstance(model, Model):
        raise ValueError('Expected `model` argument to be a `Model` instance, got ', model)
    
    if isinstance(model, Sequential):
        raise ValueError('Expected `model` argument to be a functional `Model` instance, got a `Sequential` instance instead:', model)

    layer_map = {}  
    tensor_map = {} 

    if input_tensors is None:
        input_tensors = [Input(batch_shape=layer.input_shape[1:]) for layer in model.layers if isinstance(layer, InputLayer)]
    else:
        input_tensors = to_list(input_tensors)
        for i, x in enumerate(input_tensors):
            if not K.is_keras_tensor(x):
                name = model.input_names[i]
                input_tensor = Input(tensor=x, name='input_wrapper_for_' + name)
                input_tensors[i] = input_tensor

    for orig_layer, new_layer in zip(model.layers, input_tensors):
        layer_map[orig_layer] = new_layer

    for layer in model.layers:
        if layer not in layer_map:
            new_layer = layer.__class__.from_config(layer.get_config())
            layer_map[layer] = new_layer

    for depth, nodes in model._nodes_by_depth.items():
        for node in nodes:
            layer = node.outbound_layer

            if layer not in layer_map:
                new_layer = layer.__class__.from_config(layer.get_config())
                layer_map[layer] = new_layer
            else:
                layer = layer_map[layer]

            reference_input_tensors = node.input_tensors
            reference_output_tensors = node.output_tensors

            computed_data = []
            for x in reference_input_tensors:
                if x in tensor_map:
                    computed_data.append(tensor_map[x])

            if len(computed_data) == len(reference_input_tensors):
                if node.arguments:
                    kwargs = node.arguments
                else:
                    kwargs = {}

                computed_tensors = [x[0] for x in computed_data]
                computed_masks = [x[1] for x in computed_data]

                if has_arg(layer.call, 'mask'):
                    kwargs['mask'] = computed_masks

                output_tensors = to_list(layer(computed_tensors, **kwargs))

                if has_arg(layer.call, 'mask'):
                    output_masks = to_list(layer.compute_mask(computed_tensors, computed_masks))
                else:
                    output_masks = [None] * len(output_tensors)

                for x, y, mask in zip(reference_output_tensors, output_tensors, output_masks):
                    tensor_map[x] = (y, mask)

    output_tensors = [tensor_map[x][0] for x in model.outputs]
    return Model(input_tensors, output_tensors, name=model.name)
```

In the updated version, we have addressed several issues:

1. Changed the creation of input tensors to handle both cases (when input_tensors is provided and when it is not). Used the input_shape of the layer to create the input tensors.
2. Updated the logic for building the layer_map, ensuring that all layers are properly mapped to their corresponding new layers.
3. Modified the loop over nodes to correctly process the input and output tensors and compute the output of the model based on the input tensors.

This corrected version should resolve the issues observed during the failing tests and provide the expected behavior for the _clone_functional_model function.