# The corrected version of the function

```python
from keras.models import Model
from keras.layers import Input, InputLayer
from keras import backend as K
from keras.utils.generic_utils import has_arg, to_list


def _clone_functional_model(model, input_tensors=None):
    """Clone a functional `Model` instance.

    Model cloning is similar to calling a model on new inputs,
    except that it creates new layers (and thus new weights) instead
    of sharing the weights of the existing layers.

    # Arguments
        model: Instance of `Model`.
        input_tensors: optional list of input tensors
            to build the model upon. If not provided,
            placeholders will be created.

    # Returns
        An instance of `Model` reproducing the behavior
        of the original model, on top of new inputs tensors,
        using newly instantiated weights.

    # Raises
        ValueError: in case of invalid `model` argument value.
    """
    if not isinstance(model, Model):
        raise ValueError('Expected `model` argument to be a `Model` instance, got ', model)
    layer_map = {}  # Cache for created layers.
    tensor_map = {}  # Map {reference_tensor: (corresponding_tensor, mask)}
    if input_tensors is None:
        # Create placeholders to build the model on top of.
        input_layers = []
        input_tensors = []
        for layer in model._input_layers:
            if isinstance(layer, InputLayer):
                input_tensor = Input(batch_shape=layer.batch_input_shape,
                                     dtype=layer.dtype,
                                     sparse=layer.sparse,
                                     name=layer.name)
                input_tensors.append(input_tensor)
                # Cache newly created input layer.
                layer_map[layer] = input_tensor._keras_history[0]
            else:
                input_tensor = Input(shape=layer.output_shape[1:])
                input_tensors.append(input_tensor)
                # Cache newly created input layer.
                layer_map[layer] = input_tensor._keras_history[0]
    else:
        # Make sure that all input tensors come from a Keras layer.
        # If tensor comes from an input layer: cache the input layer.
        input_tensors = to_list(input_tensors)
        for i, x in enumerate(input_tensors):
            if not K.is_keras_tensor(x):
                name = model._input_layers[i].name
                input_tensor = Input(tensor=x,
                                     name='input_wrapper_for_' + name)
                input_tensors[i] = input_tensor
                # Cache newly created input layer.
                layer_map[model._input_layers[i]] = input_tensor._keras_history[0]

    for x, y in zip(model.inputs, input_tensors):
        tensor_map[x] = (y, None)  # tensor, mask

    # Iterated over every node in the reference model, in depth order.
    depth_keys = list(model._nodes_by_depth.keys())
    depth_keys.sort(reverse=True)
    for depth in depth_keys:
        nodes = model._nodes_by_depth[depth]
        for node in nodes:
            # Recover the corresponding layer.
            layer = node.outbound_layer

            # Get or create layer.
            if layer not in layer_map:
                # Clone layer.
                new_layer = layer.__class__.from_config(layer.get_config())
                layer_map[layer] = new_layer
            layer = layer_map[layer]

            # Gather inputs to call the new layer.
            reference_input_tensors = node.input_tensors

            # If all previous input tensors are available in tensor_map,
            # then call node.inbound_layer on them.
            computed_data = []  # List of tuples (input, mask).
            for x in reference_input_tensors:
                if x in tensor_map:
                    computed_data.append(tensor_map[x])

            if len(computed_data) == len(reference_input_tensors):
                # Call layer.
                if node.arguments:
                    kwargs = node.arguments
                else:
                    kwargs = {}
                computed_tensors, computed_masks = ([] for _ in range(2))
                for computed_tensor, computed_mask in computed_data:
                    if has_arg(layer.call, 'mask'):
                        kwargs['mask'] = computed_mask
                    output_tensors = to_list(
                        layer(computed_tensor, **kwargs))
                    output_masks = to_list(
                        layer.compute_mask(computed_tensor,
                                           computed_mask))
                    computed_tensors.extend(to_list(output_tensors))
                    computed_masks.extend(to_list(output_masks))
                # Update tensor_map.
                for x, y, mask in zip(node.output_tensors,
                                      to_list(computed_tensors),
                                      to_list(computed_masks)):
                    tensor_map[x] = (y, mask)

    # Check that we did compute the model outputs,
    # then instantiate a new model from inputs and outputs.
    output_tensors = []
    for x in model.outputs:
        assert x in tensor_map, 'Could not compute output ' + str(x)
        tensor, _ = tensor_map[x]
        output_tensors.append(tensor)
    return Model(input_tensors, output_tensors, name=model.name)

```

The function has been updated to ensure correct cloning of the functional model and to address the issue related to the error "Could not compute output Tensor". The code has been modified to handle the creation of new layers, caching input layers, calling layer functions, and computing output tensors. Additionally, the code now properly checks and handles the presence of masks in the layers.