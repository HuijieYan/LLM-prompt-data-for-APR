The bug in the provided function `_clone_functional_model` is causing the issue reported in the GitHub post. The function is not correctly handling the input and output tensors when cloning a functional model with multiple outputs and when using layers that do not support masks.

The potential error location within the problematic function is the handling of output masks when calling `layer.compute_mask`. This is leading to `None` being assigned to `output_masks` regardless of whether the layer supports masks or not.

The cause of the bug is that the function is not handling the case where the layer does not support masks properly, resulting in incorrect output_masks. This causes the function to fail at a later stage when trying to compute the model outputs.

To fix the bug, the function needs to be modified to properly handle the case where the layer does not support masks and adjust the output masks accordingly.

Here's the corrected code for the problematic function:

```python
def _clone_functional_model(model, input_tensors=None):
    # ... (existing code)

    for x, y in zip(model.inputs, input_tensors):
        tensor_map[x] = (y, None)

    # Iterate over every node in the reference model, in depth order.
    depth_keys = list(model._nodes_by_depth.keys())
    depth_keys.sort(reverse=True)
    for depth in depth_keys:
        nodes = model._nodes_by_depth[depth]
        for node in nodes:
            # Recover the corresponding layer.
            layer = node.outbound_layer

            # Get or create layer.
            if layer not in layer_map:
                # Clone layer.
                new_layer = layer.__class__.from_config(layer.get_config())
                layer_map[layer] = new_layer
                layer = new_layer
            else:
                # Reuse previously cloned layer.
                layer = layer_map[layer]
                # Don't call InputLayer multiple times.
                if isinstance(layer, InputLayer):
                    continue

            # Gather inputs to call the new layer.
            reference_input_tensors = node.input_tensors

            # Call layer.
            computed_tensors = [tensor_map[x][0] for x in reference_input_tensors]
            output_tensors = to_list(layer(computed_tensors))

            # Update tensor_map.
            for x, y in zip(node.output_tensors, output_tensors):
                tensor_map[x] = (y, None)

    # Check that we did compute the model outputs,
    # then instantiate a new model from inputs and outputs.
    output_tensors = []
    for x in model.outputs:
        assert x in tensor_map, 'Could not compute output ' + str(x)
        tensor, _ = tensor_map[x]
        output_tensors.append(tensor)
    return Model(input_tensors, output_tensors, name=model.name)
```

This corrected version of the function should now properly handle the masking issue and reproduce the behavior of the original model on top of new input tensors, using newly instantiated weights.

This should address the issue reported in the GitHub post and ensure that the `clone_model` function works as expected, even with multiple outputs and layers that do not support masks.