{
    "pandas": [
        {
            "bugID": 168,
            "bitvector": {
                "1.1.1": 1,
                "1.1.2": 1,
                "1.2.1": 0,
                "1.2.2": 0,
                "1.2.3": 0,
                "1.3.1": 1,
                "1.3.2": 1,
                "1.4.1": 1,
                "1.4.2": 1,
                "2.1.1": 1,
                "2.1.2": 1,
                "2.1.3": 0,
                "2.1.4": 0,
                "2.1.5": 0,
                "2.1.6": 0,
                "3.1.1": 0,
                "3.1.2": 0,
                "cot": 0
            },
            "strata": {
                "1": 1,
                "2": 0,
                "3": 1,
                "4": 1,
                "5": 0,
                "6": 0,
                "7": 0
            },
            "available_bitvector": {
                "1.1.1": 1,
                "1.1.2": 1,
                "1.2.1": 0,
                "1.2.2": 0,
                "1.2.3": 0,
                "1.3.1": 1,
                "1.3.2": 1,
                "1.4.1": 1,
                "1.4.2": 1,
                "2.1.1": 1,
                "2.1.2": 1,
                "2.1.3": 0,
                "2.1.4": 0,
                "2.1.5": 0,
                "2.1.6": 0,
                "3.1.1": 0,
                "3.1.2": 0,
                "cot": 0
            },
            "available_strata": {
                "1": 1,
                "2": 0,
                "3": 1,
                "4": 1,
                "5": 0,
                "6": 0,
                "7": 0
            },
            "start_line": 425,
            "file_name": "pandas/core/groupby/grouper.py",
            "replace_code": "def _get_grouper(\n    obj,\n    key=None,\n    axis=0,\n    level=None,\n    sort=True,\n    observed=False,\n    mutated=False,\n    validate=True,\n):\n    group_axis = obj._get_axis(axis)\n\n    if level is not None:\n        level_is_multiindex = isinstance(group_axis, MultiIndex)\n\n        if level_is_multiindex:\n            if is_list_like(level) and len(level) == 1:\n                level = level[0]\n\n            if key is None and is_scalar(level):\n                # Get the level values from group_axis\n                key = group_axis.get_level_values(level)\n                level = None\n\n        else:\n            if is_list_like(level):\n                nlevels = len(level)\n                if nlevels == 1:\n                    level = level[0]\n                elif nlevels == 0:\n                    raise ValueError(\"No group keys passed!\")\n                else:\n                    raise ValueError(\"Multiple levels only valid with MultiIndex\")\n\n            if isinstance(level, str):\n                if obj.index.name != level:\n                    raise ValueError(f\"Level name {level} is not the name of the index\")\n            elif level > 0 or level < -1:\n                raise ValueError(\"Level > 0 or level < -1 only valid with MultiIndex\")\n\n            level = None\n            key = group_axis\n\n    if isinstance(key, Grouper):\n        binner, grouper, obj = key._get_grouper(obj, validate=False)\n        return (grouper, {key.key} if key.key else [], obj)\n    elif isinstance(key, BaseGrouper):\n        return (key, [], obj)\n\n    if isinstance(key, tuple):\n        all_hashable = all(map(is_hashable, key))\n        if (all_hashable and key not in obj and set(key).issubset(obj)) or not all_hashable:\n            msg = \"Interpreting tuple 'by' as a list of keys, rather than a single key. Use 'by=[...]' instead of 'by=(...)'. In the future, a tuple will always mean a single key.\"\n            warnings.warn(msg, FutureWarning, stacklevel=3)\n            key = list(key)\n\n    keys = [key] if not isinstance(key, list) else key\n    match_axis_length = len(keys) == len(group_axis)\n\n    any_callable = any(callable(g) or isinstance(g, dict) for g in keys)\n    any_groupers = any(isinstance(g, Grouper) for g in keys)\n    any_arraylike = any(isinstance(g, (list, tuple, Series, Index, np.ndarray)) for g in keys)\n\n    if not any_callable and not any_arraylike and not any_groupers and match_axis_length and level is None:\n        all_in_columns_index = all(g in obj.columns or g in obj.index.names for g in keys) if isinstance(obj, DataFrame) else all(g in obj.index.names for g in keys)\n        if not all_in_columns_index:\n            keys = [com.asarray_tuplesafe(keys)]\n\n    if isinstance(level, (tuple, list)):\n        if key is None:\n            keys = [None] * len(level)\n    levels = level if isinstance(level, (tuple, list)) else [level] * len(keys)\n\n    groupings = []\n    exclusions = []\n\n    for gpr, level in zip(keys, levels):\n        in_axis = isinstance(gpr, str) and gpr in obj\n        name = gpr if in_axis else None\n\n        if is_categorical_dtype(gpr) and len(gpr) != obj.shape[axis]:\n            raise ValueError(f\"Length of grouper ({len(gpr)}) and axis ({obj.shape[axis]}) must be the same length\")\n\n        ping = (\n            Grouping(group_axis, gpr, obj=obj, name=name, level=level, sort=sort, observed=observed, in_axis=in_axis)\n            if not isinstance(gpr, Grouping)\n            else gpr\n        )\n\n        groupings.append(ping)\n\n    if len(groupings) == 0 and len(obj):\n        raise ValueError(\"No group keys passed!\")\n    elif len(groupings) == 0:\n        groupings.append(Grouping(Index([], dtype=\"int\"), np.array([], dtype=np.intp)))\n\n    grouper = BaseGrouper(group_axis, groupings, sort=sort, mutated=mutated)\n    return grouper, exclusions, obj",
            "imports": []
        }
    ]
}