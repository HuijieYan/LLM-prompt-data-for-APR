To fix the buggy function, we need to ensure that the `command` list is constructed correctly to pass the arguments to the SparkSubmitTask. Here's the corrected version of the function with explanations:

```python
class SparkSubmitTask(luigi.Task):

    def _dict_arg(self, name, value):
        command = []
        if value and isinstance(value, dict):
            for prop, val in value.items():  # Changed variable name 'value' to 'val' to avoid conflict
                command += [name, '--{0}={1}'.format(prop, val)]  # Changed the format to '--{0}={1}' as per Spark conventions
        return command
```

Explanation:
1. The original buggy function was not constructing the command list correctly. It was using double quotes around the arguments, and it was not using the proper format for Spark command-line arguments.

2. The bug was caused by the incorrect construction of the command list, which would have led to incorrect arguments being passed to the SparkSubmitTask.

3. The function was intended to construct a command list for passing arguments to a Spark job, but it was not following the correct format for Spark command-line arguments.

4. The strategy for fixing the bug involves correcting the format of the command list by using the proper syntax for Spark command-line arguments and ensuring that the variable names inside the function do not conflict with the function parameters.

5. The corrected version of the function (shown above) fixes the bug by constructing the command list using the proper format for Spark command-line arguments and using non-conflicting variable names.