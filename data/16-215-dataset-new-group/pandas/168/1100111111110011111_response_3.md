```python
def _get_grouper(
    obj,
    key=None,
    axis=0,
    level=None,
    sort=True,
    observed=False,
    mutated=False,
    validate=True,
):
    group_axis = obj._get_axis(axis)
    # Validate level and group_axis for specific functionality
    if level is not None:
        if isinstance(group_axis, MultiIndex):
            if is_list_like(level) and len(level) == 1:
                level = level[0]
            if key is None and is_scalar(level):
                key = group_axis.get_level_values(level)
                level = None
        else:
            if is_list_like(level):
                nlevels = len(level)
                if nlevels == 1:
                    level = level[0]
                elif nlevels == 0:
                    raise ValueError("No group keys passed!")
                else:
                    raise ValueError("multiple levels only valid with MultiIndex")

            if is_scalar(level):
                if obj.index.name != level:
                    raise ValueError("level name {} is not the name of the index".format(level))
            elif level > 0 or level < -1:
                raise ValueError("level > 0 or level < -1 only valid with MultiIndex")

    # a passed-in Grouper, directly convert
    if isinstance(key, Grouper):
        binner, grouper, obj = key._get_grouper(obj, validate=False)
        if key.key is None:
            return grouper, [], obj
        else:
            return grouper, {key.key}, obj

    if isinstance(key, BaseGrouper):
        return key, [], obj

    is_tuple = isinstance(key, tuple)
    all_hashable = is_tuple and all(map(is_hashable, key))

    if is_tuple:
        if (
            all_hashable and key not in obj and set(key).issubset(obj)
        ) or not all_hashable:
            msg = (
                "Interpreting tuple 'by' as a list of keys, rather than "
                "a single key. Use 'by=[...]' instead of 'by=(...)'. In "
                "the future, a tuple will always mean a single key."
            )
            warnings.warn(msg, FutureWarning, stacklevel=5)
            key = list(key)

    if not isinstance(key, list):
        keys = [key]
        match_axis_length = False
    else:
        keys = key
        match_axis_length = len(keys) == len(group_axis)

    any_callable = any(callable(g) or isinstance(g, dict) for g in keys)
    any_groupers = any(isinstance(g, Grouper) for g in keys)
    any_arraylike = any(
        isinstance(g, (list, tuple, Series, Index, np.ndarray)) for g in keys
    )

    if (
        not any_callable
        and not any_arraylike
        and not any_groupers
        and match_axis_length
        and level is None
    ):
        if isinstance(obj, DataFrame):
            all_in_columns_index = all(
                g in obj.columns or g in obj.index.names for g in keys
            )
        elif isinstance(obj, Series):
            all_in_columns_index = all(g in obj.index.names for g in keys)

        if not all_in_columns_index:
            keys = com.asarray_tuplesafe(keys)

    if isinstance(level, (tuple, list)):
        if key is None:
            keys = [None] * len(level)
        levels = level
    else:
        levels = [level] * len(keys)

    groupings = []
    exclusions = []

    def is_in_axis(k):
        if not _is_label_like(k):
            try:
                if axis == 1:
                    obj._data.items.get_loc(k)
                else:
                    obj.columns.get_loc(k)
            except Exception:
                return False
        return True

    def is_in_obj(g):
        try:
            if axis == 1 and isinstance(g, (str, int, Hashable)):
                return id(g) == id(obj[g])
        except Exception:
            return False

    for i, (g, l) in enumerate(zip(keys, levels)):
        if is_in_obj(g):
            in_axis, name = True, g if axis == 1 else obj.columns[g].name
            exclusions.append(name)
        elif is_in_axis(g):
            if g in obj:
                if validate:
                    obj._check_label_or_level_ambiguity(g)
                in_axis, name, g = True, g, obj[g]
                exclusions.append(name)
            else:
                raise KeyError(g)

        # Handle categorical grouper length validation
        if is_categorical_dtype(g) and not obj.empty:
            if len(g) != len(obj):
                raise ValueError(
                    (
                        "Length of grouper ({len_gpr}) and axis ({len_axis})"
                        " must be same length".format(
                            len_gpr=len(g), len_axis=obj.shape[axis]
                        )
                    )
                )

        # Handle creation of Grouping
        if not isinstance(g, Grouping):
            ping = Grouping(
                group_axis,
                g,
                obj=obj,
                name=name,
                level=l,
                sort=sort,
                observed=observed,
                in_axis=in_axis,
            )
        else:
            ping = g
        groupings.append(ping)

    if len(groupings) == 0 and len(obj):
        raise ValueError("No group keys passed!")
    elif len(groupings) == 0:
        groupings.append(
            Grouping(Index([], dtype="int"), np.array([], dtype=np.intp))
        )

    # create the internals grouper
    grouper = BaseGrouper(group_axis, groupings, sort=sort, mutated=mutated)
    return grouper, exclusions, obj
```