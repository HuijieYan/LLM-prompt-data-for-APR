```python
def _get_grouper(
    obj,
    key=None,
    axis=0,
    level=None,
    sort=True,
    observed=False,
    mutated=False,
    validate=True,
):
    """
    create and return a BaseGrouper, which is an internal
    mapping of how to create the grouper indexers.
    This may be composed of multiple Grouping objects, indicating
    multiple groupers

    Groupers are ultimately index mappings. They can originate as:
    index mappings, keys to columns, functions, or Groupers

    Groupers enable local references to axis,level,sort, while
    the passed in axis, level, and sort are 'global'.

    This routine tries to figure out what the passing in references
    are and then creates a Grouping for each one, combined into
    a BaseGrouper.

    If observed & we have a categorical grouper, only show the observed
    values

    If validate, then check for key/level overlaps

    """
    group_axis = obj._get_axis(axis)

    if level is not None and isinstance(group_axis, MultiIndex):
        if is_list_like(level) and len(level) == 1:
            level = level[0]

        if key is None and is_scalar(level):
            # Get the level values from group_axis
            key = group_axis.get_level_values(level)
            level = None

    else:
        if is_list_like(level):
            nlevels = len(level)
            if nlevels == 1:
                level = level[0]
            elif nlevels == 0:
                raise ValueError("No group keys passed!")
            else:
                raise ValueError("multiple levels only valid with MultiIndex")

        if isinstance(level, str):
            if obj.index.name != level:
                raise ValueError(
                    "level name {} is not the name of the index".format(level)
                )
        elif level > 0 or level < -1:
            raise ValueError("level > 0 or level < -1 only valid with MultiIndex")

        level = None
        key = group_axis

    if isinstance(key, Grouper):
        binner, grouper, obj = key._get_grouper(obj, validate=False)
        if key.key is None:
            return grouper, [], obj
        else:
            return grouper, {key.key}, obj

    elif isinstance(key, BaseGrouper):
        return key, [], obj

    elif isinstance(key, tuple):
        if (
            (all(is_hashable(element) for element in key) and set(key).issubset(obj))
            or not all(is_hashable(element) for element in key)
        ):
            msg = (
                "Interpreting tuple 'by' as a list of keys, rather than "
                "a single key. Use 'by=[...]' instead of 'by=(...)'. In "
                "the future, a tuple will always mean a single key."
            )
            warnings.warn(msg, FutureWarning, stacklevel=5)
            key = list(key)

    if not isinstance(key, list):
        keys = [key]
        match_axis_length = False
    else:
        keys = key
        match_axis_length = len(keys) == len(group_axis)

    obj_is_dataframe = isinstance(obj, DataFrame)
    obj_is_series = isinstance(obj, Series)

    if (
        not any(callable(g) or isinstance(g, dict) for g in keys)
        and not any(isinstance(g, (list, tuple, Series, Index, np.ndarray)) for g in keys)
        and all(hashable(g) for g in keys)
        and match_axis_length
        and level is None
        and obj_is_dataframe
    ):
        all_in_columns_index = all(
            g in obj.columns or g in obj.index.names for g in keys
        ) if obj_is_dataframe else all(g in obj.index.names for g in keys)

        if not all_in_columns_index:
            keys = [com.asarray_tuplesafe(keys)]

    levels = [level] * len(keys)

    groupings = []
    exclusions = []

    for i, (gpr, level) in enumerate(zip(keys, levels):
        if pd.api.types.is_scalar(gpr):
            if not _is_label_like(gpr):
                try:
                    obj._data.items.get_loc(gpr)
                except Exception:
                    raise KeyError(gpr)

            if obj_is_dataframe:
                all_in_columns_index = all(
                    g in obj.columns or g in obj.index.names for g in [gpr]
                )
            elif obj_is_series:
                all_in_columns_index = gpr in obj.index.names

            if not all_in_columns_index:
                raise ValueError(f"{gpr} not in columns or index names")

            in_axis, name, gpr = True, gpr, obj[gpr]
            exclusions.append(name)

        if len(gpr) != obj.shape[axis]:
            raise ValueError(
                (
                    "Length of grouper ({len_gpr}) and axis ({len_axis})"
                    " must be same length".format(
                        len_gpr=len(gpr), len_axis=obj.shape[axis]
                    )
                )
            )

        if all(hashable(g) for g in gpr):
            category_axis = gpr if match_axis_length else group_axis
            ping = (
                Grouping(
                    category_axis,
                    gpr,
                    obj=obj,
                    name=gpr,
                    level=None,
                    sort=sort,
                    observed=observed,
                    in_axis=True,
                )
                if not isinstance(gpr, Grouping)
                else gpr
            )

        groupings.append(ping)

    if len(groupings) == 0 and len(obj):
        raise ValueError("No group keys passed!")
    elif len(groupings) == 0:
        groupings.append(Grouping(Index([], dtype="int"), np.array([], dtype=np.intp)))

    grouper = BaseGrouper(group_axis, groupings, sort=sort, mutated=mutated)
    return grouper, exclusions, obj
```