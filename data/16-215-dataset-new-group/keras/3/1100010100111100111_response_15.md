The bug in the `_clone_functional_model` function is causing an assertion error about not being able to compute the output tensor. The specific issue was reported on GitHub, mentioning a problem with `clone_model` and `multi_gpu_model` when using `cpu_relocation=True`, resulting in an AssertionError while trying to compute the output tensor.

The issue seems to be due to the lack of support for masks in the layers used, which results in `output_masks` always being `None` instead of `[None, None]` as expected.

The strategy to fix this bug is to identify the layers that are causing the issue due to the lack of mask support and check if masks are expected. This can help resolve the error when attempting to compute output tensors.

Here's the corrected version of the function:

```python
def _clone_functional_model(model, input_tensors=None):
    if not isinstance(model, Model):
        raise ValueError('Expected `model` argument to be a `Model` instance, got ', model)
    if isinstance(model, Sequential):
        raise ValueError('Expected `model` argument to be a functional `Model` instance, got a `Sequential` instance instead:', model)

    input_layers = []
    layer_map = {}
    tensor_map = {}

    if input_tensors is None:
        # Create placeholders to build the model on top of.
        for layer in model._input_layers:
            input_tensor = Input(batch_shape=layer.batch_input_shape,
                                 dtype=layer.dtype,
                                 sparse=layer.sparse,
                                 name=layer.name)
            input_layers.append(input_tensor)
            # Cache newly created input layer.
            newly_created_input_layer = input_tensor._keras_history[0]
            layer_map[layer] = newly_created_input_layer
        input_tensors = input_layers

    for x, y in zip(model.inputs, input_tensors):
        tensor_map[x] = (y, None)  # tensor, mask

    depth_keys = list(model._nodes_by_depth.keys())
    depth_keys.sort(reverse=True)
    for depth in depth_keys:
        nodes = model._nodes_by_depth[depth]
        for node in nodes:
            reference_input_tensors = node.input_tensors
            reference_output_tensors = node.output_tensors
            computed_data = []
            for x in reference_input_tensors:
                if x in tensor_map:
                    computed_data.append(tensor_map[x])

            if len(computed_data) == len(reference_input_tensors):
                layer = node.outbound_layer
                if layer not in layer_map:
                    new_layer = layer.__class__.from_config(layer.get_config())
                    layer_map[layer] = new_layer
                    layer = new_layer
                else:
                    layer = layer_map[layer]

                if len(computed_data) == 1:
                    computed_tensor, _ = computed_data[0]
                    output_tensors = to_list(layer(computed_tensor))
                else:
                    computed_tensors = [x[0] for x in computed_data]
                    output_tensors = to_list(layer(computed_tensors))

                for x, y in zip(reference_output_tensors, output_tensors):
                    tensor_map[x] = (y, None)

    output_tensors = []
    for x in model.outputs:
        assert x in tensor_map, 'Could not compute output ' + str(x)
        tensor, _ = tensor_map[x]
        output_tensors.append(tensor)
    return Model(input_tensors, output_tensors, name=model.name)
```

In the corrected version, unnecessary computations regarding masks have been removed. This should resolve the issue when computing output tensors, as observed in the GitHub issue.