The bug in the function `_clone_functional_model` is causing the `ValueError: Could not compute output...` issue. The function is trying to clone a functional `Model` instance, but it incorrectly handles the layers and input tensors in the model. Specifically, it fails to ensure input tensors from non-Keras layers are properly cached during the cloning process, leading to a mismatch between the input and output tensors.

To fix this bug, the function should be modified to iterate over the layers and input tensors more carefully, ensuring that all input tensors come from a Keras layer and that the cloning process is done correctly.

Here's the corrected version of the function:

```python
def _clone_functional_model(model, input_tensors=None):
    if not isinstance(model, Model):
        raise ValueError('Expected `model` argument to be a `Model` instance, got ', model)

    layer_map = {}  # Cache for created layers.
    tensor_map = {}  # Map {reference_tensor: (corresponding_tensor, mask)}
    input_layers = model._input_layers

    if input_tensors is None:
        input_tensors = [Input(tensor=x) for x in input_layers]
        for original_input, new_input in zip(input_layers, input_tensors):
            layer_map[original_input] = new_input
    else:
        input_tensors = to_list(input_tensors)

    for x, y in zip(model.inputs, input_tensors):
        tensor_map[x] = (y, None)  # tensor, mask

    for depth in range(len(model._nodes_by_depth)):
        nodes = model._nodes_by_depth[depth]
        for node in nodes:
            layer = node.outbound_layer
            if layer not in layer_map:
                new_layer = layer.__class__.from_config(layer.get_config())
                layer_map[layer] = new_layer
            else:
                layer = layer_map[layer]
                if isinstance(layer, InputLayer):
                    continue

            reference_input_tensors = node.input_tensors
            reference_output_tensors = node.output_tensors

            computed_data = []
            for x in reference_input_tensors:
                if x in tensor_map:
                    computed_data.append(tensor_map[x])

            if len(computed_data) == len(reference_input_tensors):
                kwargs = node.arguments if node.arguments else {}

                if len(computed_data) == 1:
                    computed_tensor, _ = computed_data[0]
                    output_tensors = to_list(layer(computed_tensor, **kwargs))
                else:
                    computed_tensors, _ = zip(*computed_data)
                    output_tensors = to_list(layer(computed_tensors, **kwargs))

                for x, y in zip(reference_output_tensors, output_tensors):
                    tensor_map[x] = (y, None)

    output_tensors = [tensor_map[x][0] for x in model.outputs]
    return Model(input_tensors, output_tensors, name=model.name)
```

This correction should address the issues with the previous implementation and resolve the failing test and the GitHub issue related to cloning a functional `Model` instance. The new version of the function handles input tensors and layer cloning more carefully, ensuring that the model outputs are correctly computed.