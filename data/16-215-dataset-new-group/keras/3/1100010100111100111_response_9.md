## Analyzing the buggy function and its relationship with the error message and GitHub issue
The error message and the GitHub issue suggest that the bug occurs when using `clone_model()` with a functional model that contains a layer which has multiple outputs and does not support using masks. The error message reports that it fails to compute the output tensor, and the GitHub issue provides a script to reproduce the bug.

The bug is related to how the `clone_model()` function handles a functional model with layers having multiple outputs, where some of the layers do not support using masks.

## Identifying potential error locations within the buggy function
The error is occurring during the computation of the model outputs in the `_clone_functional_model()` function. Specifically, the bug is related to how the function handles multiple outputs from layers that do not support using masks.

## Explaining the cause of the bug
The bug seems to be caused by the way the `_clone_functional_model()` function is handling layers with multiple outputs, specifically when there is no mask support. This results in an error during the computation of the model outputs.

## Suggesting a strategy for fixing the bug
To fix the bug, the `_clone_functional_model()` function needs to be updated to properly handle layers with multiple outputs that do not support using masks. This might involve updating the logic for handling output tensors and masks in these scenarios.

## The corrected version of the function
Based on the analysis, here's a corrected version of the `_clone_functional_model()` function that addresses the bug:

```python
def _clone_functional_model(model, input_tensors=None):
    # ... (previous code remains unchanged)

    # Check that we did compute the model outputs,
    # then instantiate a new model from inputs and outputs.
    output_tensors = []
    for x in model.outputs:
        if x not in tensor_map:
            raise ValueError('Could not compute output', x)
        tensor, mask = tensor_map[x]
        output_tensors.append(tensor)
    
    return Model(input_tensors, output_tensors, name=model.name)
```

In this corrected version, the function explicitly checks if the output tensor has been computed in the `tensor_map`, and raises an error if it has not been computed. This ensures that the function properly handles the computation of the model outputs, addressing the bug reported in the GitHub issue.