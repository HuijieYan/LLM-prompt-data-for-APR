The bug in the `_clone_functional_model` function arises from the incorrect handling of the input tensors and the layer mapping for the model nodes. The error message "Could not compute output Tensor" in the failing test indicates that the function is unable to compute the output tensors for the cloned model.

The cause of the bug is that the function fails to properly handle the input tensors and create the required layer mapping for the model nodes. This results in the output tensors not being computed correctly, leading to the assertion error in the failing test.

To fix the bug, the function should be modified to correctly handle the input tensors, create the necessary layer mapping, and ensure that the output tensors are computed accurately. It should also handle the case where a layer does not support masks, as indicated in the GitHub issue.

Here's the corrected version of the `_clone_functional_model` function:

```python
def _clone_functional_model(model, input_tensors=None):
    """Clone a functional `Model` instance.

    Model cloning is similar to calling a model on new inputs,
    except that it creates new layers (and thus new weights) instead
    of sharing the weights of the existing layers.

    # Arguments
        model: Instance of `Model`.
        input_tensors: optional list of input tensors
            to build the model upon. If not provided,
            placeholders will be created.

    # Returns
        An instance of `Model` reproducing the behavior
        of the original model, on top of new input tensors,
        using newly instantiated weights.

    # Raises
        ValueError: in case of invalid `model` argument value.
    """
    if not isinstance(model, Model):
        raise ValueError('Expected `model` argument '
                         'to be a `Model` instance, got ', model)
    if isinstance(model, Sequential):
        raise ValueError('Expected `model` argument '
                         'to be a functional `Model` instance, '
                         'got a `Sequential` instance instead:', model)

    # Create placeholders to build the model on top of.
    if input_tensors is None:
        input_tensors = [Input(shape=inp.shape[1:]) for inp in model.inputs]

    layer_map = {original_layer: layer for original_layer, layer in zip(model.inputs, input_tensors)}

    def clone_layer(layer):
        cloned_layer = layer.__class__.from_config(layer.get_config())
        return cloned_layer

    for node in model._nodes_by_depth:
        cloned_layers = {}
        for in_node, out_node in zip(node.inbound_layers, node.outbound_layer):
            if in_node not in cloned_layers:
                cloned_layers[in_node] = clone_layer(in_node)
            if out_node not in cloned_layers:
                cloned_layers[out_node] = clone_layer(out_node)

            # Connect cloned layers
            cloned_layers[in_node]._outbound_nodes.append(out_node)
            cloned_layers[out_node]._inbound_nodes.append(in_node)

    output_tensors = [cloned_layers[out] for out in model.outputs]
    return Model(input_tensors, output_tensors, name=model.name)
```

By implementing the changes suggested in the corrected version, the function should now be able to handle the input tensors, create the required layer mapping, and accurately compute the output tensors for the cloned model. This should resolve the issue reported on GitHub and allow the failing test to pass.