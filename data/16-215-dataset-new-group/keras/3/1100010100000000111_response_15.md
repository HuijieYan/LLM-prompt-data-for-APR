The bug in the `clone_model` function is causing an assertion error when using `multi_gpu_model` with `cpu_relocation=True`. The issue arises from the fact that the `clone_model` function is not properly computing the model outputs in some cases, leading to the error.

The cause of the bug is that the `clone_model` function is not handling the case where the cloned model contains a layer with multiple outputs and no mask support. This leads to the `output_masks` being set as `None`, when it should be a list of `None`, resulting in the assertion error.

To fix the bug, we need to modify the `clone_model` function to correctly handle the case where a layer has multiple outputs and no mask support, ensuring that the `output_masks` is a list of `None`.

Here's the corrected version of the `clone_model` function:

```python
def _clone_functional_model(model, input_tensors=None):
    # ... (other code remains unchanged)

    for x, y in zip(model.inputs, input_tensors):
        tensor_map[x] = (y, None)  # tensor, mask

    # ... (other code remains unchanged)

    for x, y, mask in zip(reference_output_tensors, output_tensors, output_masks):
        if mask is None:
            mask = [None] * len(output_tensors)  # Ensure output_masks is a list of None
        tensor_map[x] = (y, mask)

    # ... (other code remains unchanged)

    return Model(input_tensors, output_tensors, name=model.name)
```

By modifying the assignment of `output_masks` within the loop to ensure it is always a list of `None`, we can fix the bug and prevent the assertion error when using `clone_model` with `multi_gpu_model` and `cpu_relocation=True`.