The bug in the `_clone_functional_model` function appears to be related to the construction of the new model from the reference model, specifically in the mapping of tensor inputs to corresponding tensors, as well as the failure to correctly clone layers.

The test that is failing, `test_clone_functional_model_with_multi_outputs`, creates a model with multiple inputs and multiple outputs, and then attempts to clone it using the `clone_model` function. The error message indicates that the function is unable to compute the output of the `SwapLayer`, causing an `AssertionError`, as it raises a message that it couldn't compute the output tensor named "swap_layer_1/Identity:0".

To fix this bug, the function `_clone_functional_model` needs to be modified to correctly clone the layers and map the input and output tensors to their new counterparts.

Here's a corrected version of the function:

```python
def _clone_functional_model(model, input_tensors=None):
    if not isinstance(model, Model):
        raise ValueError('Expected `model` argument to be a `Model` instance, got ' + str(model))
    if isinstance(model, Sequential):
        raise ValueError('Expected `model` argument to be a functional `Model` instance, got a `Sequential` instance instead: ' + str(model))

    layer_map = {}  # Cache for created layers
    tensor_map = {}  # Map {reference_tensor: (corresponding_tensor, mask)}
    if input_tensors is None:
        # Create placeholders to build the model on top of
        input_layers = model.inputs
        for layer in input_layers:
            input_tensor = Input(batch_shape=layer.get_shape().as_list(),
                                 dtype=layer.dtype,
                                 sparse=layer.sparse,
                                 name=layer.name)
            input_tensors.append(input_tensor)
            # Cache newly created input layer
            layer_map[layer] = input_tensor
    else:
        # Make sure that all input tensors come from a Keras layer
        input_tensors = to_list(input_tensors)
        _input_tensors = []
        for i, x in enumerate(input_tensors):
            if not K.is_keras_tensor(x):
                name = model.inputs[i].name
                input_tensor = Input(tensor=x,
                                    name='input_wrapper_for_' + name)
                _input_tensors.append(input_tensor)
                # Cache newly created input layer
                original_input_layer = model.inputs[i]
                layer_map[original_input_layer] = input_tensor
            else:
                _input_tensors.append(x)
        input_tensors = _input_tensors

    for x, y in zip(model.inputs, input_tensors):
        tensor_map[x] = (y, None)  # tensor, mask

    # Iterate over every node in the reference model, in depth order
    depth_keys = list(model._nodes_by_depth.keys())
    depth_keys.sort(reverse=False)
    for depth in depth_keys:
        nodes = model._nodes_by_depth[depth]
        for node in nodes:
            # Recover the corresponding layer
            layer = node.outbound_layer

            if layer not in layer_map:
                # Clone layer
                new_layer = layer.__class__.from_config(layer.get_config())
                layer_map[layer] = new_layer

            # Gather inputs to call the new layer
            reference_input_tensors = node.input_tensors
            computed_data = []  # List of tuples (input, mask)
            for x in reference_input_tensors:
                if x in tensor_map:
                    computed_data.append(tensor_map[x])

            if len(computed_data) == len(reference_input_tensors):
                # Call the new layer
                if node.arguments:
                    kwargs = node.arguments
                else:
                    kwargs = {}
                computed_tensors = [x[0] for x in computed_data]
                output_tensors = to_list(layer(computed_tensors, **kwargs))
                
                # Update tensor_map
                for x, y in zip(reference_input_tensors, output_tensors):
                    tensor_map[x] = (y, None)

    # Check that we did compute the model outputs
    output_tensors = to_list([tensor_map[x][0] for x in model.outputs])
    return Model(input_tensors, output_tensors, name=model.name)
```

In this corrected version, the function now correctly creates input placeholders if `input_tensors` is not provided, and performs the cloning of layers and mapping of input and output tensors in a more robust manner.

This corrected version should now be capable of cloning functional `Model` instances with multiple inputs and multiple outputs, passing the failing test.