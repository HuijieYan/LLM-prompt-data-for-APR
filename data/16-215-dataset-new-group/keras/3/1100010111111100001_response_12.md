The bug in the _clone_functional_model function seems to be related to the creation and caching of layers and input tensors. The error message from the failing test indicates that the model outputs could not be computed.

Upon analyzing the execution of the failing test case 1, it appears that the issue lies in the creation and caching of input tensors and input layers. The input_tensors list is not properly handled, leading to input tensors not being correctly mapped to their corresponding newly instantiated input layer.

To fix the bug, we need to ensure that the input tensors are properly handled and cached, and that the layers are correctly cloned and mapped.

Here's the corrected version of the _clone_functional_model function:

```python
def _clone_functional_model(model, input_tensors=None):
    if not isinstance(model, Model):
        raise ValueError('Expected `model` argument to be a `Model` instance, got ', model)
    
    layer_map = {}  # Cache for created layers
    tensor_map = {}  # Map {reference_tensor: (corresponding_tensor, mask)}
    
    if input_tensors is None:
        input_tensors = [None] * len(model.inputs)  # Create placeholders
    else:
        # Create placeholders if input_tensors is not a list
        input_tensors = to_list(input_tensors)
        if len(input_tensors) != len(model.inputs):
            input_tensors = [None] * len(model.inputs)
    
    for original_layer, input_tensor in zip(model._input_layers, input_tensors):
        # Cache newly created input layer
        if input_tensor is None:
            new_input_tensor = Input(batch_shape=original_layer.batch_input_shape,
                                     dtype=original_layer.dtype,
                                     sparse=original_layer.sparse,
                                     name=original_layer.name)
            input_tensor = new_input_tensor
        else:
            if not K.is_keras_tensor(input_tensor):
                input_tensor = Input(tensor=input_tensor,
                                     name='input_wrapper_for_' + input_tensor.name)
        
        newly_created_input_layer = input_tensor._keras_history[0]
        layer_map[original_layer] = newly_created_input_layer
        tensor_map[original_layer] = (input_tensor, None)  # Map the input tensor
    
    for depth in sorted(model._nodes_by_depth.keys(), reverse=True):
        nodes = model._nodes_by_depth[depth]
        for node in nodes:
            # Recover the corresponding layer
            layer = node.outbound_layer
            
            # Get or create layer
            if layer not in layer_map:
                # Clone layer
                new_layer = layer.__class__.from_config(layer.get_config())
                layer_map[layer] = new_layer
            else:
                # Reuse previously cloned layer
                new_layer = layer_map[layer]
            
            # Gather inputs to call the new layer
            reference_input_tensors = node.input_tensors
            reference_output_tensors = node.output_tensors
            
            # Map input tensors to their corresponding ones
            computed_data = []
            for tensor in reference_input_tensors:
                if tensor in tensor_map:
                    computed_data.append(tensor_map[tensor])
            
            # Call the layer using the computed input tensors
            if len(computed_data) == len(reference_input_tensors):
                # Call layer
                output_tensors = to_list(
                    new_layer(computed_data[0][0])  # Assuming only one tensor
                )
                for ref_tensor, out_tensor in zip(reference_output_tensors, output_tensors):
                    tensor_map[ref_tensor] = (out_tensor, None)  # Map the output tensor
    
    # Collect the output tensors for the new model
    output_tensors = [tensor_map[tensor][0] for tensor in model.outputs]
    
    return Model(input_tensors, output_tensors, name=model.name)
```

In this corrected version, we ensure that the input tensors are correctly mapped to their corresponding layers and that the newly created layers are appropriately cached. This should resolve the issues seen in the failing test case.

With this corrected function, the failing test case should pass, and the error message should no longer occur.