The bug occurs in the `_clone_functional_model` function of keras/models.py. The error message indicates an `AssertionError` because the output tensor `"swap_layer_1/Identity:0"` was not found in the `tensor_map`.

The cause of the bug seems to be related to the incorrect handling of input tensors and the mapping of tensor relationships within the functional model. Some variables are not being properly updated during the iteration over the model's nodes, leading to missing mappings in the `tensor_map`.

To fix the bug, we need to ensure that all input tensors and their dependencies are correctly mapped and used to create the new model. The loop iterating over the model nodes should be carefully reviewed to capture any missing or incorrect mappings.

Here's the corrected version of the `_clone_functional_model` function:

```python
def _clone_functional_model(model, input_tensors=None):
    if not isinstance(model, Model):
        raise ValueError('Expected `model` argument to be a `Model` instance, got ', model)
        
    layer_map = {}  # Cache for created layers.
    initial_input_layers = model._get_all_node_layers(model.inputs)
    if input_tensors is None:
        # Create placeholders to build the model on top of.
        input_tensors = [Input(batch_shape=layer.batch_input_shape,
                               dtype=layer.dtype,
                               sparse=layer.sparse,
                               name=layer.name) for layer in initial_input_layers]
    new_input_layers = [layer.__class__.from_config(layer.get_config()) for layer in input_tensors]
    layer_map = {init: new for init, new in zip(initial_input_layers, new_input_layers)}

    tensor_map = {x: y for x, y in zip(model.inputs, input_tensors)}
    
    nodes = model._nodes_by_depth
    for depth in sorted(nodes.keys(), reverse=True):
        depth_nodes = nodes[depth]
        for node in depth_nodes:
            outbound_layer = node.outbound_layer

            if outbound_layer not in layer_map:
                new_layer = outbound_layer.__class__.from_config(outbound_layer.get_config())
                layer_map[outbound_layer] = new_layer

            inbound_tensors = node.input_tensors
            output_tensors = node.output_tensors

            computed_data = []
            for x in inbound_tensors:
                if x in tensor_map:
                    computed_data.append(tensor_map[x])

            if len(computed_data) == len(inbound_tensors):
                kwargs = node.arguments if node.arguments is not None else {}
                output_tensors = []
                masks = []
                for i, x in enumerate(computed_data):
                    tensor, mask = x
                    if has_arg(outbound_layer.call, 'mask'):
                        kwargs['mask'] = mask
                    out = outbound_layer(tensor, **kwargs)
                    output_tensors = to_list(out) if i == 0 else output_tensors + to_list(out)
                    masks = to_list(outbound_layer.compute_mask(tensor, mask))

                for i, y in enumerate(output_tensors):
                    tensor_map[output_tensors[i]] = (y, masks[i])
                    
    output_tensors = [tensor_map[x][0] for x in model.outputs]

    return Model(input_tensors, output_tensors, name=model.name)
```

In the corrected version, we properly handle the creation of placeholder input tensors, mapping of input tensors, correct iteration over the model's nodes, and updating the tensor_map. This should resolve the issue with the failing test case.