The cause of the bug is that the `_clone_functional_model` function is not handling the case of a model with multiple outputs correctly, causing it to fail the test.

To fix the bug, we need to update the `_clone_functional_model` function to handle models with multiple outputs properly. Specifically, the function should correctly handle cases where a layer has multiple output tensors and manage the cloning of the layer to ensure the new model is able to reproduce the behavior of the original model accurately.

Here's the corrected version of the `_clone_functional_model` function:

```python
def _clone_functional_model(model, input_tensors=None):
    # ... (previous code)

    # Check that we did compute the model output tensors.
    output_tensors = []
    for x in model.outputs:
        assert x in tensor_map, 'Could not compute output ' + str(x)
        tensor, mask = tensor_map[x]
        output_tensors.append(tensor)

    new_model = Model(input_tensors, output_tensors, name=model.name)

    return new_model
```

In this corrected version, we iterate over the model's output tensors and retrieve the tensors generated by the cloning process using `tensor_map`. We then create a new `Model` instance based on the input tensors and output tensors, and return the new model.

This updated version ensures that the cloning process handles models with multiple outputs correctly, and it should pass the failing test provided.