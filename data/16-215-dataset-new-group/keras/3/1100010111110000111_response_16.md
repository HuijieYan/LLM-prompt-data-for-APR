The bug in the `_clone_functional_model` function seems to be related to the creation and mapping of input and output tensors. The failing test specifically involves a model with multiple outputs, and the error message indicates that the model outputs cannot be computed.

The cause of the bug appears to be related to the handling of input and output tensors, especially when dealing with multiple outputs and potentially missing mask support for certain layers.

To fix the bug, we need to ensure that the input and output tensors are correctly mapped and computed, especially in cases where multiple outputs are involved, and there may be issues with mask support for certain layers.

Here's the corrected version of the `_clone_functional_model` function:

```python
def _clone_functional_model(model, input_tensors=None):
    if not isinstance(model, Model):
        raise ValueError('Expected `model` argument to be a `Model` instance, got ', model)

    layer_map = {}  # Cache for created layers.
    tensor_map = {}  # Map {reference_tensor: (corresponding_tensor, mask)}

    # Handle input tensors
    if input_tensors is None:
        input_layers = []
        input_tensors = []
        for layer in model._input_layers:
            input_tensor = Input(batch_shape=layer.batch_input_shape,
                                dtype=layer.dtype,
                                sparse=layer.sparse,
                                name=layer.name)
            input_tensors.append(input_tensor)
            layer_map[layer] = input_tensor
        for original, cloned in zip(model._input_layers, input_tensors):
            layer_map[original] = cloned
    else:
        input_tensors = to_list(input_tensors)
        _input_tensors = []
        for i, x in enumerate(input_tensors):
            if not K.is_keras_tensor(x):
                name = model._input_layers[i].name
                input_tensor = Input(tensor=x,
                                    name='input_wrapper_for_' + name)
                _input_tensors.append(input_tensor)
                original_input_layer = x._keras_history[0]
                newly_created_input_layer = input_tensor._keras_history[0]
                layer_map[original_input_layer] = newly_created_input_layer
            else:
                _input_tensors.append(x)
        input_tensors = _input_tensors

    for x, y in zip(model.inputs, input_tensors):
        tensor_map[x] = (y, None)

    # Iterate over every node in the reference model, in reverse depth order.
    depth_keys = list(model._outbound_nodes.keys())
    depth_keys.sort(reverse=True)
    for depth in depth_keys:
        nodes = model._outbound_nodes[depth]
        for node in nodes:
            layer = node.inbound_layers[0]

            # Get or create layer
            if layer not in layer_map:
                new_layer = layer.__class__.from_config(layer.get_config())
                layer_map[layer] = new_layer
            else:
                layer = layer_map[layer]

            reference_input_tensors = node.input_tensors
            reference_output_tensors = node.output_tensors

            computed_data = []  # List of tuples (input, mask).
            for x in reference_input_tensors:
                if x in tensor_map:
                    computed_data.append(tensor_map[x])

            if len(computed_data) == len(reference_input_tensors):
                # Call layer
                if node.arguments:
                    kwargs = node.arguments
                else:
                    kwargs = {}
                computed_tensors = [x[0] for x in computed_data]
                computed_masks = [x[1] for x in computed_data]
                if 'mask' in kwargs:  # Remove 'mask' from kwargs if it exists
                    del kwargs['mask']
                if has_arg(layer.call, 'mask'):
                    output_tensors = to_list(layer(computed_tensors, **kwargs))
                else:
                    output_tensors = to_list(layer(computed_tensors))
                for x, y in zip(reference_output_tensors, output_tensors):
                    tensor_map[x] = (y, None)

    # Check that we did compute the model outputs, then instantiate a new model from inputs and outputs
    output_tensors = [tensor_map[x][0] for x in model.outputs]
    return Model(input_tensors, output_tensors, name=model.name)
```

The corrected version of the function should address the issues related to the mapping and computation of input and output tensors, especially when dealing with multiple outputs and potential lack of mask support for certain layers.

This correction should resolve the failing test and the issue posted on GitHub.