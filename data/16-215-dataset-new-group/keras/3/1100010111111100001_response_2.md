The bug in the `_clone_functional_model` function seems to be caused by incorrect handling of the `layer_map` and `tensor_map`, leading to an AssertionError at the end of the function. The variables `layer_map` and `tensor_map` are being used to cache created layers and map input/output tensors, but they are not being populated correctly.

The potential error locations within the function are:
1. Incorrect creation and mapping of `input_tensors` when `input_tensors` is not provided
2. Improper consistency check for filled `tensor_map` at the end of the function

The cause of the bug is that the function is not properly mapping input and output tensors and layers. This is leading to an incomplete mapping in `tensor_map`, causing the AssertionError when trying to compute the model outputs.

To fix the bug:
1. Fix the creation and mapping of `input_tensors` when `input_tensors` is not provided to ensure proper caching in `layer_map` and `tensor_map`.
2. Ensure that all necessary tensors and layers are correctly mapped in `tensor_map` before attempting to compute the model outputs.

Below is the corrected version of the `_clone_functional_model` function:

```python
def _clone_functional_model(model, input_tensors=None):
    # ... (same function signature and comments)

    layer_map = {}  # Cache for created layers.
    tensor_map = {}  # Map {reference_tensor: (corresponding_tensor, mask)}

    if input_tensors is None:
        # Create placeholders to build the model on top of.
        input_tensors = [Input(batch_shape=layer.batch_input_shape,
                               dtype=layer.dtype,
                               sparse=layer.sparse,
                               name=layer.name) for layer in model._input_layers]
        layer_map = {layer: input_tensor for layer, input_tensor in zip(model._input_layers, input_tensors)}
    else:
        # ... (same as original implementation)

    # Iterate over every node in the reference model, in depth order.
    # ... (same as original implementation)

    # Instantiate a new model from inputs and outputs.
    output_tensors = []
    for x in model.outputs:
        if x not in tensor_map:
            raise ValueError('Could not compute output ' + str(x))
        tensor, _ = tensor_map[x]
        output_tensors.append(tensor)
    
    return Model(input_tensors, output_tensors, name=model.name)
```

The corrected version ensures that input tensors are appropriately mapped and that all necessary tensors are correctly computed and mapped in `tensor_map`.

With the provided fix, the `_clone_functional_model` function should pass the failing test case.