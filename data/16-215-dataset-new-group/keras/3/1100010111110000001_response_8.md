The error message indicates that the `_clone_functional_model` function is unable to compute the output tensor for the `swap_layer_1` layer. This is likely due to an issue in the logic that creates new layers during the cloning process.

Upon analyzing the function, the issue seems to be with how the new layers are cloned and mapped in the `layer_map`. During the model cloning process, the function is attempting to create and map newly instantiated layers, but the logic for mapping and creating the layers seems to be flawed.

To fix the bug, the logic for creating and mapping the new layers should be revised to ensure that the input tensors are properly connected to the layers and that the output tensors are correctly computed and mapped. Additionally, it is essential to validate the code for potential edge cases.

Here's the corrected version of the `_clone_functional_model` function:

```python
def _clone_functional_model(model, input_tensors=None):
    if not isinstance(model, Model):
        raise ValueError('Expected `model` argument to be a `Model` instance, got ', model)
    if isinstance(model, Sequential):
        raise ValueError('Expected `model` argument to be a functional `Model` instance, got a `Sequential` instance instead:', model)

    layer_map = {}  # Cache for created layers.
    tensor_map = {}  # Map {reference_tensor: (corresponding_tensor, mask)}
    if input_tensors is None:
        # Create placeholders to build the model on top of.
        input_layers = [Input(batch_shape=layer.batch_input_shape, dtype=layer.dtype, sparse=layer.sparse, name=layer.name) for layer in model._input_layers]
        input_tensors = input_layers
        for original, cloned in zip(model._input_layers, input_layers):
            layer_map[original] = cloned
    else:
        # Make sure that all input tensors come from a Keras layer.
        # If tensor comes from an input layer: cache the input layer.
        input_tensors = to_list(input_tensors)
        _input_tensors = []
        for i, x in enumerate(input_tensors):
            if not K.is_keras_tensor(x):
                name = model._input_layers[i].name
                input_tensor = Input(tensor=x, name='input_wrapper_for_' + name)
                _input_tensors.append(input_tensor)
                original_input_layer = x._keras_history[0]
                newly_created_input_layer = input_tensor._keras_history[0]
                layer_map[original_input_layer] = newly_created_input_layer
            else:
                _input_tensors.append(x)
        input_tensors = _input_tensors

    for x, y in zip(model.inputs, input_tensors):
        tensor_map[x] = (y, None)  # tensor, mask

    for layer in model.layers:
        if layer not in layer_map:
            # Clone layer.
            new_layer = layer.__class__.from_config(layer.get_config())
            layer_map[layer] = new_layer

    for layer in model.layers:
        if not isinstance(layer, InputLayer):
            if layer not in tensor_map:
                inbound_tensors = []
                for inbound_node in layer._inbound_nodes:
                    for inbound_tensor in inbound_node.input_tensors:
                        if inbound_tensor not in tensor_map:
                            break
                        inbound_tensors.append(tensor_map[inbound_tensor][0])
                    else:
                        continue
                    break
                else:
                    output_tensors = to_list(layer(inbound_tensors))
                    for input_tensor, output_tensor in zip(layer.inbound, output_tensors):
                        tensor_map[input_tensor] = output_tensor

    output_tensors = [tensor_map[x][0] for x in model.outputs]
    return Model(input_tensors, output_tensors, name=model.name)
```

This corrected version should address the issues that caused the failing test and ensure that the function properly maps and creates the new layers during the cloning process.