### Analysis
The `clone_model` function is calling the `_clone_functional_model` function, which is responsible for cloning a functional model instance. The error message indicates that the model fails to compute the output Tensor during the cloning process.

### Potential Error Locations
1. InputLayer creation when `input_tensors` is `None`.
2. Cloning or reusing layers within the model.
3. Handling of input tensors and their associated layers.

### Cause of the Bug
The bug is likely caused by the mishandling of input tensors, incorrect layer cloning, or issues related to the processing of multi-output layers. This can be seen from the error message which indicates a failure in computing the output Tensor during the model cloning.

### Strategy for Fixing the Bug
1. Ensure that input layers are properly created when `input_tensors` is `None`.
2. Check the cloning mechanism to ensure that new layers are instantiated properly.
3. Verify the handling of input tensors and their associated layers to prevent issues related to multi-output layers.

### Bug Fix
```python
from keras.engine.saving import model_from_config
import copy

def _clone_functional_model(model, input_tensors=None):
    if not isinstance(model, Model):
        raise ValueError('Expected `model` argument to be a `Model` instance, got ', model)
    if isinstance(model, Sequential):
        raise ValueError('Expected `model` argument to be a functional `Model` instance, '
                         'got a `Sequential` instance instead:', model)

    # Create a deep copy of the model configuration to avoid modifying the original model
    model_config = copy.deepcopy(model.get_config())
    
    if input_tensors is None:
        # Create input_layers if input_tensors is None
        input_tensors = []
        for layer_config in model_config['input_layers']:
            input_tensors.append(InputLayer.from_config(layer_config, custom_objects=K._COLLECTIONS))

    model = model_from_config(model_config, custom_objects=K._COLLECTIONS)

    return model
```
This fix ensures that the model configuration is deep-copied and used to recreate the model. It creates input layers if `None` is provided as input_tensors.

This fix should address the issue and allow the test to pass successfully.