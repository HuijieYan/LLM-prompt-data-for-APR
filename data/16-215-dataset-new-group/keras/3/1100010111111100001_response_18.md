The buggy function `_clone_functional_model` is supposed to clone a functional `Model` instance, creating new layers and weights instead of sharing the weights of the existing layers. However, there are several issues with the current implementation:

1. The function does not properly handle the case where input_tensors are provided. It fails to create new input layers based on the provided input_tensors.
2. It does not properly update the tensor_map with the computed output tensors, leading to an AssertionError when checking whether all outputs have been computed.

To fix the bug, we need to modify the function to correctly handle the input_tensors and update the tensor_map with the computed output tensors.

Here's the corrected version of the `_clone_functional_model` function:

```python
def _clone_functional_model(model, input_tensors=None):
    if not isinstance(model, Model):
        raise ValueError('Expected `model` argument to be a `Model` instance, got {}'.format(model))

    if isinstance(model, Sequential):
        raise ValueError('Expected `model` argument to be a functional `Model` instance, got a `Sequential` instance instead: {}'.format(model))

    layer_map = {}  # Cache for created layers
    tensor_map = {}  # Map {reference_tensor: (corresponding_tensor, mask)}
    
    if input_tensors is None:
        input_tensors = [Input(batch_shape=layer.input.shape) for layer in model._input_layers]
    else:
        input_tensors = to_list(input_tensors)
        for i, x in enumerate(input_tensors):
            if not K.is_keras_tensor(x):
                input_tensor = Input(tensor=x, name='input_wrapper_for_' + model._input_layers[i].name)
                input_tensors[i] = input_tensor
                layer_map[model._input_layers[i]] = input_tensor

    for x, y in zip(model.inputs, input_tensors):
        tensor_map[x] = (y, None)  # tensor, mask

    for depth, nodes in model._nodes_by_depth.items():
        for node in nodes:
            layer = node.outbound_layer
            if layer not in layer_map:
                new_layer = layer.__class__.from_config(layer.get_config())
                layer_map[layer] = new_layer

            reference_output_tensors = node.output_tensors
            computed_data = [(tensor_map[x][0], tensor_map[x][1]) for x in node.input_tensors if x in tensor_map]
            
            if len(computed_data) == len(node.input_tensors):
                kwargs = node.arguments if node.arguments else {}
                if isinstance(layer, InputLayer):
                    continue
                if len(computed_data) == 1:
                    computed_tensor, computed_mask = computed_data[0]
                    if has_arg(layer.call, 'mask') and 'mask' not in kwargs:
                        kwargs['mask'] = computed_mask
                    output_tensors = to_list(layer(computed_tensor, **kwargs))
                    output_masks = to_list(layer.compute_mask(computed_tensor, computed_mask))
                else:
                    computed_tensors = [x[0] for x in computed_data]
                    computed_masks = [x[1] for x in computed_data]
                    if has_arg(layer.call, 'mask') and 'mask' not in kwargs:
                        kwargs['mask'] = computed_masks
                    output_tensors = to_list(layer(computed_tensors, **kwargs))
                    output_masks = to_list(layer.compute_mask(computed_tensors, computed_masks))

                for x, y, mask in zip(reference_output_tensors, output_tensors, output_masks):
                    tensor_map[x] = (y, mask)

    output_tensors = [tensor_map[x][0] for x in model.outputs]
    return Model(input_tensors, output_tensors, name=model.name)
```

In the corrected version, we properly handle the input_tensors by creating new Input layers based on them, and we update the tensor_map with the computed output tensors. This should address the issues and make the function work as intended. This corrected version should pass the failing test.