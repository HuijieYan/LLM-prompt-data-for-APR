The bug in the `_clone_functional_model` originates from the creation of input placeholders. The input_layers are created but then not used to initialize input_tensors, resulting in an empty list being used as the model's inputs. This leads to the inconsistency in the compiled model, causing the "Could not compute output Tensor" error. 

To fix the bug, the input_layers should be used to initialize input_tensors, ensuring that the new clone is properly constructed with the expected inputs.

Here's the corrected version of `_clone_functional_model`:

```python
def _clone_functional_model(model, input_tensors=None):
    # ... (existing code)

    if input_tensors is None:
        # Use input_layers to create input_tensors
        input_tensors = [layer.input for layer in model._input_layers]

    # ... (remaining code)

    return Model(input_tensors, output_tensors, name=model.name)
```

By using the input_layers to initialize the input_tensors in the case where input_tensors is None, the function ensures that the new clone will have consistent inputs, preventing the error identified in the GitHub issue.