The buggy function `_clone_functional_model` is failing to correctly clone a functional `Model` instance when it has multiple inputs and outputs. The function uses a map to track the relationship between the original and cloned layers and input tensors, but it has issues in correctly tracking these relationships and computing the new output tensors.

The error message indicates that the function fails to compute the output tensor for the layer named "swap_layer_1". This means that the function is not correctly handling the computation of the new output tensors for layers with multiple inputs and outputs.

To fix this bug, it's necessary to revise the part of the code that handles the computation of the output tensors and the update of the `tensor_map`. Specifically, the logic for calling the new layer with the computed input tensors and handling the output tensors and masks needs to be carefully reviewed.

Here's a corrected version of the `_clone_functional_model` function:

```python
def _clone_functional_model(model, input_tensors=None):
    # ... (existing code)

    # Check that we did compute the model outputs,
    # then instantiate a new model from inputs and outputs.
    cloned_input_tensors = []
    for x in model.inputs:
        if x not in tensor_map:
            new_placeholder = Input(shape=x.shape[1:])
            tensor_map[x] = (new_placeholder, None)  # tensor, mask
            cloned_input_tensors.append(new_placeholder)
        else:
            tensor, _ = tensor_map[x]
            cloned_input_tensors.append(tensor)

    depth_keys = list(model._nodes_by_depth.keys())
    depth_keys.sort()

    output_tensors = []
    for depth in depth_keys:
        nodes = model._nodes_by_depth[depth]
        for node in nodes:
            reference_input_tensors = node.input_tensors
            reference_output_tensors = node.output_tensors

            # Gather inputs to call the new layer.
            input_data = []
            for x in reference_input_tensors:
                if x in tensor_map:
                    input_data.append(tensor_map[x])

            if len(input_data) == len(reference_input_tensors):
                layer = node.outbound_layer
                kwargs = node.arguments if node.arguments else {}

                computed_tensors = [x[0] for x in input_data]
                computed_masks = [x[1] for x in input_data]

                if has_arg(layer.call, 'mask'):
                    if 'mask' not in kwargs:
                        kwargs['mask'] = computed_masks

                output = layer(computed_tensors, **kwargs)

                if isinstance(output, list):
                    output_tensors.extend(output)
                    for out, ref_out in zip(output, reference_output_tensors):
                        tensor_map[ref_out] = (out, None)  # tensor, mask
                else:
                    output_tensors.append(output)
                    tensor_map[reference_output_tensors[0]] = (output, None)  # tensor, mask

    return Model(cloned_input_tensors, output_tensors, name=model.name)
```

In this corrected version, I've refactored the logic for computing the output tensors to ensure that the function properly handles layers with multiple inputs and outputs and updates the `tensor_map` accordingly. With this revised logic, the function should correctly clone the functional model and pass the failing test.