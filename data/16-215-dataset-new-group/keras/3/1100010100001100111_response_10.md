The issue seems to be related to the `clone_model` function, particularly around the handling of layers with multiple outputs and the use of masks. The error occurs when using multi_gpu_model with the `cpu_relocation=True` parameter, although the issue is reproducible when using `clone_model` directly, which indicates a problem in the `_clone_functional_model` function. 

A key observation is that the output_masks will always be [None] instead of [None, None] as expected. This is due to the fact that Lambda layer doesn't support using masks, and `layer.compute_mask` will always return None when applied to Lambda layer.

The bug does not properly handle layers with multiple outputs and the absence of mask support, leading to the error when trying to compute the model outputs.

To fix this bug, we need to update the `_clone_functional_model` function to properly handle layers with multiple outputs and the absence of mask support, specifically for the Lambda layer.

Based on the provided information and the observed behavior, a corrected version of the `_clone_functional_model` function that addresses the bug can be provided as follows:

```python
def _clone_functional_model(model, input_tensors=None):
    # Existing code before the bug
    # ... (same as the original function)

    # New implementation to handle Lambda layer and multiple outputs
    for x, y in zip(model.inputs, input_tensors):
        tensor_map[x] = (y, None)  # Initialize tensor_map

    # Iterate over every node in the reference model, in depth order.
    depth_keys = list(model._nodes_by_depth.keys())
    depth_keys.sort(reverse=True)
    for depth in depth_keys:
        nodes = model._nodes_by_depth[depth]
        for node in nodes:
            # Handle Lambda layer with multiple outputs
            if isinstance(node.outbound_layer, Lambda) and len(node.output_tensors) > 1:
                computed_data = [(tensor_map[t], None) for t in node.input_tensors]
                output_tensors = [computed_data[i][0] for i in range(len(computed_data))]
                mask = None
                # Update tensor_map
                for x, y in zip(node.output_tensors, output_tensors):
                    tensor_map[x] = (y, mask)
            else:
                # Existing code to handle other layers
                # ...

    # Check that we did compute the model outputs, then instantiate a new model from inputs and outputs
    output_tensors = []
    for x in model.outputs:
        assert x in tensor_map, 'Could not compute output ' + str(x)
        tensor, _ = tensor_map[x]
        output_tensors.append(tensor)
    return Model(input_tensors, output_tensors, name=model.name)
```

This corrected version of the `_clone_functional_model` function adds a specific conditional check to handle Lambda layers with multiple outputs. It addresses the issue raised in the GitHub report related to the error when computing the model outputs.

With this correction, the function should now properly handle the Lambda layer and its multiple outputs, ensuring the correct computation of the model outputs even when some layers do not support masks.