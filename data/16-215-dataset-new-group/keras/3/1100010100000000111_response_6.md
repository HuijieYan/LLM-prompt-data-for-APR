### Analysis:
The buggy function `_clone_functional_model` is causing an issue for the user when using the `clone_model` function. The user encountered the error "Could not compute output Tensor" when using `clone_model` and `multi_gpu_model` with `cpu_relocation=True`. The user has identified the bug as being caused by the `clone_model` function and has provided a script to reproduce the issue. The error originates from the cloning process and the handling of output masks for layers that do not support masks, specifically the Lambda layer.

### Error Locations:
1. Line 153: The output_masks are set to `[None]` even when multiple outputs are expected, causing the issue for layers that do not support masks.

### Cause of the Bug:
The bug arises from the handling of output masks for layers that do not support masks, resulting in an incorrect assertion error when using `clone_model`.

### Strategy for Fixing the Bug:
Adjust the handling of output masks when encountering layers that do not support masks, such as the Lambda layer. This may involve modifying the logic for computing output masks and handling multiple output tensors.

### Corrected Version:
```python
# The corrected version of the buggy function
def _clone_functional_model(model, input_tensors=None):
    # ... (same as original function)
    
    # Check that we did compute the model outputs,
    # then instantiate a new model from inputs and outputs.
    output_tensors = []
    for x in model.outputs:
        assert x in tensor_map, 'Could not compute output ' + str(x)
        tensor, _ = tensor_map[x]
        output_tensors.append(tensor)
    
    # Fix output_masks when it's None for layers that don't support masks
    computed_output_masks = []
    for output_tensor in model.outputs:
        if output_tensor in tensor_map and tensor_map[output_tensor][1] is not None:
            computed_output_masks.append(tensor_map[output_tensor][1])
        else:
            computed_output_masks.append(None)
    
    return Model(input_tensors, output_tensors, name=model.name, output_mask=computed_output_masks)
```

In the corrected version, we fixed the handling of `output_masks` by explicitly determining the masks for each output tensor, especially for layers that do not support masks. We create a list `computed_output_masks` to store the computed masks for the output tensors. This ensures that the correct masks are associated with each output tensor, addressing the issue raised by the user.