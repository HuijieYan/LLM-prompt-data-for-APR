### Explanation
The bug in the `_clone_functional_model` function leads to the failure of the `test_clone_functional_model_with_multi_outputs` test. The issue arises when a layer with multiple outputs is used without mask support, causing the error "Could not compute output Tensor" when cloning the model. This is consistent with the GitHub issue where it is reported that output_masks will always be [None] when using a layer without mask support.

The issue occurs because the `computed_mask` is always set to None when it should be set to the actual mask value of the layer's output. This leads to the model failing to compute the output tensor and results in the error. The bug is specifically related to the handling of masks for layers with multiple outputs, and it causes the cloned model to not reproduce the behavior of the original model correctly for such layers.

### Fix Strategy
To fix this bug, the `_clone_functional_model` function needs to be updated to correctly handle the masks for layers with multiple outputs. Specifically, the `computed_mask` should be set to the actual mask value when calling the layer.

### The corrected version of the function

```python
def _clone_functional_model(model, input_tensors=None):
    """
    Clone a functional `Model` instance.

    ... (Same documentation as before)

    # Returns
        An instance of `Model` reproducing the behavior
        of the original model, on top of new inputs tensors,
        using newly instantiated weights.

    ... (Same error handling as before)
    """
    if not isinstance(model, Model):
        raise ValueError('Expected `model` argument '
                         'to be a `Model` instance, got ', model)
    if isinstance(model, Sequential):
        raise ValueError('Expected `model` argument '
                         'to be a functional `Model` instance, '
                         'got a `Sequential` instance instead:', model)

    layer_map = {}  # Cache for created layers.
    tensor_map = {}  # Map {reference_tensor: (corresponding_tensor, mask)}
    if input_tensors is None:
        # Create placeholders to build the model on top of.
        input_layers = []
        input_tensors = []
        for layer in model._input_layers:
            input_tensor = Input(batch_shape=layer.batch_input_shape,
                                 dtype=layer.dtype,
                                 sparse=layer.sparse,
                                 name=layer.name)
            input_tensors.append(input_tensor)
            # Cache newly created input layer.
            newly_created_input_layer = input_tensor._keras_history[0]
            layer_map[layer] = newly_created_input_layer
        for _original, _cloned in zip(model._input_layers, input_layers):
            layer_map[_original] = _cloned
    else:
        # Make sure that all input tensors come from a Keras layer.
        # If tensor comes from an input layer: cache the input layer.
        input_tensors = to_list(input_tensors)
        _input_tensors = []
        for i, x in enumerate(input_tensors):
            if not K.is_keras_tensor(x):
                name = model._input_layers[i].name
                input_tensor = Input(tensor=x,
                                     name='input_wrapper_for_' + name)
                _input_tensors.append(input_tensor)
                # Cache newly created input layer.
                original_input_layer = x._keras_history[0]
                newly_created_input_layer = input_tensor._keras_history[0]
                layer_map[original_input_layer] = newly_created_input_layer
            else:
                _input_tensors.append(x)
        input_tensors = _input_tensors

    for x, y in zip(model.inputs, input_tensors):
        tensor_map[x] = (y, None)  # tensor, mask (initialized to None)

    # Iterated over every node in the reference model, in depth order.
    depth_keys = list(model._nodes_by_depth.keys())
    depth_keys.sort(reverse=True)
    for depth in depth_keys:
        nodes = model._nodes_by_depth[depth]
        for node in nodes:
            # Recover the corresponding layer.
            layer = node.outbound_layer
            ...
            # Call layer.
            if node.outbound_layer.supports_masking:
                computed_tensor, computed_mask = layer.compute_mask(computed_tensors, computed_masks)
                if computed_mask is not None and has_arg(layer.call, 'mask'):
                    if 'mask' not in kwargs:
                        kwargs['mask'] = computed_mask
            else:
                computed_mask = None

            output_tensors = to_list(
                layer(computed_tensors, **kwargs))
            ...
            # Update tensor_map with mask info.
            for x, y, mask in zip(reference_output_tensors,
                                  output_tensors,
                                  computed_mask):
                tensor_map[x] = (y, mask)

    # Check that we did compute the model outputs,
    # then instantiate a new model from inputs and outputsmode.
    output_tensors = []
    for x in model.outputs:
        assert x in tensor_map, 'Could not compute output ' + str(x)
        tensor, mask = tensor_map[x]
        output_tensors.append(tensor)
    return Model(input_tensors, output_tensors, name=model.name)
```

The corrected version of the function includes additional logic to handle the computation and assignment of masks for layers with multiple outputs. In particular, the `computed_mask` is set appropriately based on the support for masking in the outbound layer, and is updated in the `tensor_map` along with the output tensor. This ensures that the cloned model can correctly reproduce the behavior of the original model for layers with multiple outputs and without mask support.