The buggy function is raising an assertion error because it is unable to compute the output tensor "Tensor('swap_layer_1/Identity:0', shape=(?, 4), dtype=float32)" in the reference model. This issue is likely caused by a problem with the logic for computing the output tensors in the function.

The strategy for fixing the bug is to carefully review the logic for computing the output tensors in the function and ensure that all necessary steps are being taken to correctly map the input and output tensors of the model and its layers.

Here's the corrected version of the function:

```python
def _clone_functional_model(model, input_tensors=None):
    if not isinstance(model, Model):
        raise ValueError('Expected `model` argument to be a `Model` instance, got {}'.format(type(model)))

    if isinstance(model, Sequential):
        raise ValueError('Expected `model` argument to be a functional `Model` instance, got a `Sequential` instance instead: {}'.format(type(model)))

    layer_map = {}  # Cache for created layers.
    tensor_map = {}  # Map {reference_tensor: (corresponding_tensor, mask)}
    
    if input_tensors is None:
        # Create placeholders to build the model on top of.
        input_layers = []
        input_tensors = []
        for layer in model._input_layers:
            input_tensor = Input(batch_shape=layer.batch_input_shape,
                                 dtype=layer.dtype,
                                 sparse=layer.sparse,
                                 name=layer.name)
            input_tensors.append(input_tensor)
            # Cache newly created input layer.
            layer_map[layer] = input_tensor._keras_history[0]
    else:
        # Make sure that all input tensors come from a Keras layer.
        # If tensor comes from an input layer: cache the input layer.
        input_tensors = to_list(input_tensors)
        for i, x in enumerate(input_tensors):
            if not K.is_keras_tensor(x):
                name = model._input_layers[i].name
                input_tensor = Input(tensor=x, name='input_wrapper_for_' + name)
                # Cache newly created input layer.
                layer_map[model._input_layers[i]] = input_tensor._keras_history[0]
                input_tensors[i] = input_tensor

    for x, y in zip(model.inputs, input_tensors):
        tensor_map[x] = (y, None)  # tensor, mask

    # Iterated over every node in the reference model, in depth order.
    for layer in model.layers:
        layer_config = layer.get_config()
        new_layer = layer.__class__.from_config(layer_config)
        layer_map[layer] = new_layer
        
        # Gather inputs to call the new layer.
        inbound_tensors = []
        for node in layer.inbound_nodes:
            for inbound_layer, node_index, tensor_index, _ in node.iterate_inbound():
                inbound_tensors.append(tensor_map[inbound_layer.output][0])

        # Call the new layer on the inputs
        out_tensors = new_layer(inbound_tensors)
        for dst_tensor, out_tensor in zip(layer.output, out_tensors):
            tensor_map[dst_tensor] = (out_tensor, None)

    # Check that we did compute the model outputs,
    output_tensors = [tensor_map[x][0] for x in model.outputs]

    return Model(input_tensors, output_tensors, name=model.name)
```

The corrected function now properly handles the input tensors and the computation of output tensors during the cloning process. It should pass the failing test for cloning a functional model with multiple outputs.