The cause of the bug is in the `_clone_functional_model` function in the line where it generates the model outputs. It is failing to ensure that it has computed all the model outputs and that the tensor map contains all the output tensors. This is causing the failing test, as it fails to produce the correct outputs when the model is cloned.

To fix the bug, we should modify the `_clone_functional_model` function to properly track the tensor map, ensure it has computed all the model outputs, and instantiate a new model from the inputs and outputs.

Here's the corrected version of the `_clone_functional_model` function:

```python
def _clone_functional_model(model, input_tensors=None):
    # ... (previous implementation)

    # Check that we did compute the model outputs,
    # then instantiate a new model from inputs and outputs.
    output_tensors = []
    for x in model.outputs:
        assert x in tensor_map, 'Could not compute output ' + str(x)
        tensor, mask = tensor_map[x]
        # Use tensor and mask to instantiate new outputs
        if mask is not None:
            output_tensor = Output(tensor, mask=mask)
        else:
            output_tensor = Output(tensor)
        output_tensors.append(output_tensor)

    # Ensure that new_model is a functional model instance
    new_model = Model(input_tensors, output_tensors, name=model.name)

    return new_model
```

With these changes, the `_clone_functional_model` function should now pass the failing test and produce correct outputs when the model is cloned.