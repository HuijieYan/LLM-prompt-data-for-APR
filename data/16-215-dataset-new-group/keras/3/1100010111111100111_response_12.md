The bug in the `_clone_functional_model` function is causing the failing test. The bug leads to an `AssertionError` where the output tensor cannot be computed. The bug is present in the `for x in model.outputs` loop around line 166, where `assert x in tensor_map` is failing, indicating that the output tensor cannot be computed.

The issue is caused by the fact that `tensor_map` is not properly populated with the output tensors. When iterating through the model's nodes and layers, the function does not update the `tensor_map` correctly, leading to not all node output tensors being present in the `tensor_map` at the time of the assertion.

To fix the bug, the function should properly populate the `tensor_map` as the function iterates through the model's nodes and layers, ensuring that all output tensors are correctly added to the map.

Here's the corrected version of the function:

```python
def _clone_functional_model(model, input_tensors=None):
    # existing code...

    for depth in depth_keys:
        nodes = model._nodes_by_depth[depth]
        for node in nodes:
            # existing code...

            output_tensors = to_list(
                layer(computed_tensors, **kwargs))
            for original_output_tensor, computed_output_tensor in zip(reference_output_tensors, output_tensors):
                tensor_map[original_output_tensor] = (computed_output_tensor, None)

    # existing code...

    return Model(input_tensors, output_tensors, name=model.name)
```

By ensuring that the `tensor_map` is updated with the computed output tensors, the corrected function should resolve the issue and pass the failing test.