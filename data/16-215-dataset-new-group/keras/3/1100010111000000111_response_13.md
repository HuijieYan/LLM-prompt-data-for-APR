The bug in the `_clone_functional_model` function is related to the incorrect handling of multiple outputs when cloning a functional model. The issue reported on GitHub confirms that the `clone_model` function fails when the original model has layers with multiple outputs and no mask support.

The GitHub issue also provides an example that reproduces the bug, where the `clone_model` function raises an assertion error.

To fix the bug, the `_clone_functional_model` function needs to be updated to properly handle layers with multiple outputs and no mask support.

Here's the corrected version of the `_clone_functional_model` function:

```python
def _clone_functional_model(model, input_tensors=None):
    # Previous code...

    for x, y in zip(model.inputs, input_tensors):
        tensor_map[x] = (y, None)  # tensor, mask

    # Iterated over every node in the reference model, in depth order.
    depth_keys = list(model._nodes_by_depth.keys())
    depth_keys.sort(reverse=True)
    for depth in depth_keys:
        nodes = model._nodes_by_depth[depth]
        for node in nodes:
            # Previous code...

            # If all previous input tensors are available in tensor_map,
            # then call node.inbound_layer on them.
            computed_data = []  # List of tuples (input, mask).
            all_inputs_available = True
            for x in reference_input_tensors:
                if x in tensor_map:
                    computed_data.append(tensor_map[x])
                else:
                    all_inputs_available = False
                    break
            
            if all_inputs_available:
                # Call layer.
                if node.arguments:
                    kwargs = node.arguments
                else:
                    kwargs = {}
                computed_tensors = [x[0] for x in computed_data]
                if len(computed_data) == 1:
                    computed_masks = [computed_data[0][1]]
                else:
                    computed_masks = [x[1] for x in computed_data]

                output_tensors = to_list(layer(computed_tensors, **kwargs))

                for x, y, mask in zip(reference_output_tensors, output_tensors, computed_masks):
                    tensor_map[x] = (y, mask)
    return Model(input_tensors, [tensor_map[x][0] for x in model.outputs], name=model.name)
```

This updated version of the function properly handles the case when a layer has multiple outputs and no mask support. It checks if all the input tensors are available in the `tensor_map` before calling the layer, and then properly updates the `tensor_map` for each output tensor.

With this corrected function, the provided failing test `test_clone_functional_model_with_multi_outputs` should pass, and the reported GitHub issue should be resolved.