The bug in the `_clone_functional_model` function is related to the handling of multiple inputs and outputs in the model. The function is failing to properly handle the case where a layer has multiple inputs and outputs, which results in the "Could not compute output Tensor" error in the GitHub issue.

The bug is caused by the following:
1. The function does not properly handle layers with multiple inputs and outputs, specifically when there is no mask support for the layer.
2. The computation of `output_masks` is not correctly handled when the `layer.compute_mask` function returns `None` due to lack of mask support.

To fix the bug, the function needs to be modified to correctly handle layers with multiple inputs and outputs, and to properly handle cases where the layer does not support masks.

Below is the corrected version of the `_clone_functional_model` function:

```python
def _clone_functional_model(model, input_tensors=None):
    if not isinstance(model, Model):
        raise ValueError('Expected `model` argument to be a `Model` instance, got ', model)
    if isinstance(model, Sequential):
        raise ValueError('Expected `model` argument to be a functional `Model` instance, got a `Sequential` instance instead:', model)

    layer_map = {}  
    tensor_map = {}  
    if input_tensors is None:
        input_tensors = []
        for layer in model._input_layers:
            input_tensor = Input(batch_shape=layer.batch_input_shape,
                                 dtype=layer.dtype,
                                 sparse=layer.sparse,
                                 name=layer.name)
            input_tensors.append(input_tensor)
            layer_map[layer] = input_tensor._keras_history[0]
    else:
        input_tensors = to_list(input_tensors)
        for i, x in enumerate(input_tensors):
            if not K.is_keras_tensor(x):
                name = model._input_layers[i].name
                input_tensor = Input(tensor=x,
                                     name='input_wrapper_for_' + name)
                input_tensors[i] = input_tensor
                layer_map[x._keras_history[0]] = input_tensor._keras_history[0]

    for x, y in zip(model.inputs, input_tensors):
        tensor_map[x] = (y, None)  

    depth_keys = list(model._nodes_by_depth.keys())
    depth_keys.sort(reverse=True)
    for depth in depth_keys:
        nodes = model._nodes_by_depth[depth]
        for node in nodes:
            layer = node.outbound_layer
            if layer not in layer_map:
                new_layer = layer.__class__.from_config(layer.get_config())
                layer_map[layer] = new_layer
            else:
                layer = layer_map[layer]
                if isinstance(layer, InputLayer):
                    continue
                    
            reference_input_tensors = node.input_tensors
            reference_output_tensors = node.output_tensors
            computed_data = []  
            for x in reference_input_tensors:
                if x in tensor_map:
                    computed_data.append(tensor_map[x])

            if len(computed_data) == len(reference_input_tensors):
                kwargs = node.arguments
                computed_tensors = [x[0] for x in computed_data]
                if has_arg(layer.call, 'mask') and not all(mask is None for _, mask in computed_data):
                    kwargs['mask'] = [mask for _, mask in computed_data]

                output_tensors = to_list(layer(computed_tensors, **kwargs))
                output_tensors = [x if x is not None else K.identity(x) for x in to_list(output_tensors)]

                if has_arg(layer.call, 'mask'):
                    computed_masks = [mask for _, mask in computed_data if mask is not None]
                    output_masks = to_list(layer.compute_mask(computed_tensors, computed_masks))
                else:
                    output_masks = [None] * len(output_tensors)

                for x, y, mask in zip(reference_output_tensors, output_tensors, output_masks):
                    tensor_map[x] = (y, mask)

    output_tensors = [tensor_map[x][0] for x in model.outputs]
    assert all(x in tensor_map for x in model.outputs)
    return Model(input_tensors, output_tensors, name=model.name)
```

In this corrected version, the function properly handles layers with multiple inputs and outputs and correctly deals with cases where the layer does not support masks.

After applying this fix, the `test_clone_functional_model_with_multi_outputs` test should pass, and the issue reported in the GitHub post should be resolved.