The buggy function `_clone_functional_model` is supposed to clone a functional `Model` instance by creating new layers and new weights instead of sharing the weights of the existing layers. However, the function is not able to compute the model outputs properly and fails with the assertion error `Could not compute output`.

The potential error locations within the function are:
1. Incorrect handling of the input tensors when `input_tensors` is not None.
2. Improper updating of the `tensor_map` when computing the new layer outputs.

The cause of the bug is that the function is not correctly handling the input tensors and the computation of the model outputs. This leads to the assertion error when trying to compute the model outputs.

To fix the bug, we need to ensure that the input tensors are properly handled and the `tensor_map` is updated correctly when computing the output tensors for the new model.

Here's the corrected version of the function:

```python
def _clone_functional_model(model, input_tensors=None):
    # ... (other code remains the same) ...

    if input_tensors is None:
        input_tensors = [Input(batch_shape=layer.batch_input_shape, dtype=layer.dtype, sparse=layer.sparse, name=layer.name) for layer in model._input_layers]
    else:
        input_tensors = to_list(input_tensors)
        tensor_map = {orig: inp for orig, inp in zip(model.inputs, input_tensors)}

    # ... (remaining code remains the same) ...
    
    return Model(input_tensors, output_tensors, name=model.name)
```

In the corrected version, the `input_tensors` are properly handled in both cases (when None and when not None), and the `tensor_map` is correctly initialized when `input_tensors` are provided. This should address the bug and make the function compute the model outputs correctly.