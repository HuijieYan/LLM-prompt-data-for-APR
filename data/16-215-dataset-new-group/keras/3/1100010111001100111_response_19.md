The bug in the `_clone_functional_model` function seems to be related to the loop iterations in the function. The issue in GitHub describes a similar problem, and the user suspects that the error occurs when using a functional model with a layer that has multiple outputs without mask support.

The problem seems to arise when the function is unable to compute the output Tensor due to the lack of mask support in certain layers. This results in the `output_masks` being `None`, when it's expected to be `[None, None]`. The GitHub issue also mentions that the `Layer.compute_mask` returns None since the Lambda layer doesn't support masks. This aligns with the failing test involving Lambda layers and multi-outputs.

To fix the bug, it would be necessary to handle the scenario where a layer doesn't support masks, providing a workaround to compute the output_tensors and output_masks appropriately.

Here's the corrected version of the function:

```python
def _clone_functional_model(model, input_tensors=None):
    # ... (existing code)

    if not isinstance(model, Model):
        raise ValueError('Expected `model` argument to be a `Model` instance, got ', model)
    if isinstance(model, Sequential):
        raise ValueError('Expected `model` argument to be a functional `Model` instance, got a `Sequential` instance instead:', model)

    layer_map = {}  # Cache for created layers.
    tensor_map = {}  # Map {reference_tensor: (corresponding_tensor, mask)}
    if input_tensors is None:
        # Create placeholders to build the model on top of.
        input_layers = []
        input_tensors = []
        for layer in model._input_layers:
            input_tensor = Input(batch_shape=layer.batch_input_shape,
                                 dtype=layer.dtype,
                                 sparse=layer.sparse,
                                 name=layer.name)
            input_tensors.append(input_tensor)
            # Cache newly created input layer.
            newly_created_input_layer = input_tensor._keras_history[0]
            layer_map[layer] = newly_created_input_layer
    # ... (remaining code)

    for x, y in zip(model.inputs, input_tensors):
        tensor_map[x] = (y, None)  # tensor, mask

    # Iterate over every node in the reference model, in depth order.
    depth_keys = list(model._nodes_by_depth.keys())
    depth_keys.sort(reverse=True)
    for depth in depth_keys:
        nodes = model._nodes_by_depth[depth]
        for node in nodes:
            # Recover the corresponding layer.
            layer = node.outbound_layer

            # Get or create layer.
            if layer not in layer_map:
                # Clone layer.
                new_layer = layer.__class__.from_config(layer.get_config())
                layer_map[layer] = new_layer
                layer = new_layer
            else:
                # Reuse previously cloned layer.
                layer = layer_map[layer]
                # Don't call InputLayer multiple times.
                if isinstance(layer, InputLayer):
                    continue

            # Gather inputs to call the new layer.
            reference_input_tensors = node.input_tensors
            reference_output_tensors = node.output_tensors

            # If all previous input tensors are available in tensor_map,
            # then call node.inbound_layer on them.
            computed_data = []  # List of tuples (input, mask).
            
            computed_tensors = []
            computed_masks = []
            for x in reference_input_tensors:
                if x in tensor_map:
                    computed_tensor, computed_mask = tensor_map[x]
                    computed_tensors.append(computed_tensor)
                    computed_masks.append(computed_mask)

            # Call layer.
            if node.arguments:
                kwargs = node.arguments
            else:
                kwargs = {}

            if len(computed_tensors) == 1:
                computed_tensor, computed_mask = computed_tensors[0], computed_masks[0]
                output_tensors = to_list(
                    layer(computed_tensor, **kwargs))
                output_masks = to_list(
                    layer.compute_mask(computed_tensor,
                                       computed_mask)) if has_arg(layer.call, 'mask') else [None]
            else:
                output_tensors = to_list(
                    layer(computed_tensors, **kwargs))
                output_masks = to_list(
                    layer.compute_mask(computed_tensors,
                                       computed_masks)) if has_arg(layer.call, 'mask') else [None]

            # Update tensor_map.
            for x, y, mask in zip(reference_output_tensors,
                                  output_tensors,
                                  output_masks):
                tensor_map[x] = (y, mask)

    # ... (remaining code)
```

In this corrected version, we handle the scenario of a layer not supporting masks by checking for the existence of masks before computing them. This should address the specific issue described in the failing test and the GitHub report.