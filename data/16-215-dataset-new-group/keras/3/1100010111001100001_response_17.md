The issue with the current implementation of the `_clone_functional_model` function seems to be related to the creation and maintenance of the input tensors and layers. The issue is also reflected in the failing test case `test_clone_functional_model_with_multi_outputs`.

The expected input for the function `_clone_functional_model` is an instance of a `Model`. The function then processes the model's input layers, nodes, outputs, and name to create a new instance of `Model` with new inputs and outputs.

In the failing test case, the input layers are being passed appropriately, but the new model's outputs are not being computed correctly, resulting in a failed assertion for `pred_new_a` and `pred_new_b` when compared to `pred_a` and `pred_b`.

To fix this bug, the function `_clone_functional_model` needs to ensure the correct mapping and computation of the output tensors from the input model to the new cloned model.

```python
def _clone_functional_model(model, input_tensors=None):
    # ... (existing code)

    # Check that we did compute the model outputs,
    # then instantiate a new model from inputs and outputs.
    output_tensors = []
    for x in model.outputs:
        assert x in tensor_map, 'Could not compute output ' + str(x)
        tensor, _ = tensor_map[x]
        output_tensors.append(tensor)
    
    # Create a new model with the input tensors and output tensors
    # obtained from the tensor map
    new_model = Model(input_tensors, output_tensors, name=model.name)
    return new_model
```

In this fixed code, we create a new list `output_tensors` to store the output tensors computed using the `tensor_map`. Then, we instantiate a new model `new_model` using the input tensors and output tensors obtained from the `tensor_map`. This ensures that the new model is rightfully computed and will produce the expected outputs.

With these changes, the fixed `_clone_functional_model` function should correctly compute the new model outputs and pass the failing test case.