The bug is caused by the incorrect handling of multiple outputs in the _clone_functional_model function, which leads to an assertion error when trying to compute the output tensors.

The erroneous part of the function is in the for loop over the nodes, where the computed_data list is being filled using the tensor_map dictionary, and the subsequent check on whether all previous input tensors are available in the tensor_map.

To fix the bug, we need to refactor the logic for computing the output tensors to correctly handle multiple outputs.

Here's the corrected version of the _clone_functional_model function:

```python
def _clone_functional_model(model, input_tensors=None):
    if not isinstance(model, Model):
        raise ValueError('Expected `model` argument to be a `Model` instance, got ', model)

    layer_map = {}
    tensor_map = {}
    if input_tensors is None:
        input_tensors = [Input(batch_shape=layer.batch_input_shape,
                               dtype=layer.dtype,
                               sparse=layer.sparse,
                               name=layer.name) for layer in model._input_layers]
    else:
        input_tensors = to_list(input_tensors)

    for orig, tensor in zip(model.inputs, input_tensors):
        tensor_map[orig] = (tensor, None)

    depth_keys = list(model._nodes_by_depth.keys())
    depth_keys.sort(reverse=True)
    for depth in depth_keys:
        nodes = model._nodes_by_depth[depth]
        for node in nodes:
            for tensor in node.output_tensors:
                if tensor not in tensor_map:
                    # create new layer and update the map
                    layer = node.outbound_layer.__class__.from_config(node.outbound_layer.get_config())
                    layer_map[node.outbound_layer] = layer
                    tensor_map[tensor] = (layer(tensor_map[r][0] for r in node.input_tensors), None)

    output_tensors = [tensor_map[t][0] for t in model.outputs]
    return Model(input_tensors, output_tensors, name=model.name)
```

This corrected function ensures that the output tensors are properly computed and the model is instantiated correctly. This should address the assertion error when running the failing test.