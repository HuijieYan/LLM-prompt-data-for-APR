In the `_clone_functional_model` function, the bug is likely caused by the incorrect handling of the computational graph, especially when dealing with layers that do not support masks, and when manually handling input tensors. This can lead to mismatched references in the `tensor_map` variable, as observed in the failing test's runtime values.

To fix the bug, the computation of masks and tensors inside the `for x, y in zip(model.inputs, input_tensors)` loop is crucial. The code should ensure that each input tensor corresponds to the correct reference tensor, as the current implementation can lead to incorrect mapping in the `tensor_map`, causing the `Could not compute output Tensor` error.

Another potential improvement is to refactor the code to handle the computation of output tensors and masks in a more robust way, specifically for cases where the layers do not support masks. Lastly, the model's outputs should be validated within the `output_tensors` loop and an appropriate action should be taken if any discrepancy is found.

Here's the corrected version of the `_clone_functional_model` function:

```python
def _clone_functional_model(model, input_tensors=None):
    # ... (code for argument validation)

    # ... (code for creating placeholders if input_tensors is None)

    # ... (code for handling non-Keras input tensors)

    for x, y in zip(model.inputs, input_tensors):
        tensor_map[x] = (y, None)  # tensor, mask

    for depth in reversed(range(len(model._nodes_by_depth))):
        for node in model._nodes_by_depth[depth]:
            layer = node.outbound_layer

            if layer not in layer_map:
                new_layer = layer.__class__.from_config(layer.get_config())
                layer_map[layer] = new_layer
                layer = new_layer
            else:
                layer = layer_map[layer]

            reference_input_tensors = node.input_tensors
            reference_output_tensors = node.output_tensors

            computed_data = []
            for x in reference_input_tensors:
                if x in tensor_map:
                    computed_data.append(tensor_map[x])

            if len(computed_data) == len(reference_input_tensors):
                kwargs = node.arguments if node.arguments else {}
                computed_tensors = [x[0] for x in computed_data]
                computed_masks = [x[1] for x in computed_data]
                if has_arg(layer.call, 'mask') and computed_masks and not any(computed_masks):
                    computed_masks = None  # Set masks to None if the layer does not support masks
                output_tensors = to_list(layer(computed_tensors, **kwargs))
                output_masks = to_list(layer.compute_mask(computed_tensors, computed_masks))

                for x, y, mask in zip(reference_output_tensors, output_tensors, output_masks):
                    tensor_map[x] = (y, mask)

    output_tensors = [tensor_map[x][0] for x in model.outputs]
    return Model(input_tensors, output_tensors, name=model.name)
```

In this fixed version, the `output_tensors` are correctly computed and added to the `tensor_map`, with special consideration for layers that do not support masks. This revised approach should address the underlying issues identified in the failing test and the related GitHub issue.