{
    "pandas": [
        {
            "bitvector": {
                "1.1.1": 1,
                "1.1.2": 1,
                "1.2.1": 1,
                "1.2.2": 1,
                "1.2.3": 0,
                "1.3.1": 1,
                "1.3.2": 0,
                "1.3.3": 1,
                "1.4.1": 0,
                "1.4.2": 0,
                "2.1.1": 0,
                "2.1.2": 0,
                "2.1.5": 1,
                "2.1.6": 1,
                "2.1.3": 0,
                "2.1.4": 0,
                "3.1.1": 0,
                "3.1.2": 0,
                "cot": 1
            },
            "strata": {
                "1": 1,
                "2": 1,
                "3": 0,
                "4": 0,
                "5": 0,
                "6": 1,
                "7": 0,
                "8": 0,
                "9": 1
            },
            "available_bitvector": {
                "1.1.1": 1,
                "1.1.2": 0,
                "1.2.1": 1,
                "1.2.2": 0,
                "1.2.3": 0,
                "1.3.1": 1,
                "1.3.2": 0,
                "1.3.3": 1,
                "1.4.1": 0,
                "1.4.2": 0,
                "2.1.1": 0,
                "2.1.2": 0,
                "2.1.5": 1,
                "2.1.6": 1,
                "2.1.3": 0,
                "2.1.4": 0,
                "3.1.1": 0,
                "3.1.2": 0,
                "cot": 1
            },
            "available_strata": {
                "1": 1,
                "2": 1,
                "3": 0,
                "4": 0,
                "5": 0,
                "6": 1,
                "7": 0,
                "8": 0,
                "9": 1
            },
            "bugID": 48,
            "start_line": 999,
            "file_name": "pandas/core/groupby/generic.py",
            "replace_code": "def _cython_agg_blocks(\n        self, how: str, alt=None, numeric_only: bool = True, min_count: int = -1\n    ) -> \"Tuple[List[Block], Index]\":\n        data: BlockManager = self._get_data_to_aggregate()\n    \n        if numeric_only:\n            data = data.get_numeric_data(copy=False)\n    \n        agg_blocks: List[Block] = []\n        new_items: List[np.ndarray] = []\n    \n        for block in data.blocks:\n            locs = block.mgr_locs.as_array\n            # Assess whether block is an extension\n            if block.is_extension:\n                # handle result calculations and processing differently\n                values = block.extension.aggregate(how, axis=self.axis, min_count=min_count)\n            else:\n                try:\n                    values, _ = self.grouper.aggregate(\n                        block.values, how, axis=self.axis, min_count=min_count\n                    )\n                except NotImplementedError:\n                    # alternate way of performing the operation in case of an error\n                    if alt is not None:\n                        obj = self.obj[data.items[locs]]\n                        s = get_groupby(obj, self.grouper)\n                        result = s.aggregate(lambda x: alt(x, axis=self.axis))\n                        values = result.values\n                    else:\n                        print(f\"Cannot perform the operation in alternate way for block: {locs}\")\n                        continue\n                    \n            new_items.append(locs)\n            agg_blocks.append(block.make_block(values))\n    \n        if not agg_blocks:\n            raise DataError(\"No types to aggregate\")\n            \n        # extract the corresponding items from data and reset the locs in the blocks\n        indexer = np.concatenate(new_items)\n        agg_items = data.items.take(np.sort(indexer))\n        offset = 0\n        for blk in agg_blocks:\n            loc = len(blk.mgr_locs)\n            blk.mgr_locs = indexer[offset: (offset + loc)]\n            offset += loc\n    \n        return agg_blocks, agg_items",
            "import_list": []
        }
    ]
}