{
    "pandas": [
        {
            "bitvector": {
                "1.1.1": 1,
                "1.1.2": 1,
                "1.3.1": 0,
                "1.3.2": 0,
                "1.4.1": 1,
                "1.2.1": 1,
                "1.4.2": 1,
                "1.2.2": 1,
                "1.5.1": 1,
                "1.5.2": 1,
                "2.1.1": 0,
                "2.1.2": 0,
                "2.2.1": 0,
                "2.2.2": 0,
                "2.3.1": 0,
                "2.3.2": 0,
                "3.1.1": 0,
                "3.1.2": 0,
                "cot": 1
            },
            "strata": {
                "1": 1,
                "2": 0,
                "3": 1,
                "4": 1,
                "5": 0,
                "6": 0,
                "7": 0,
                "8": 0,
                "9": 1
            },
            "available_bitvector": {
                "1.1.1": 1,
                "1.1.2": 1,
                "1.3.1": 0,
                "1.3.2": 0,
                "1.4.1": 0,
                "1.2.1": 1,
                "1.4.2": 1,
                "1.2.2": 1,
                "1.5.1": 1,
                "1.5.2": 1,
                "2.1.1": 0,
                "2.1.2": 0,
                "2.2.1": 0,
                "2.2.2": 0,
                "2.3.1": 0,
                "2.3.2": 0,
                "3.1.1": 0,
                "3.1.2": 0,
                "cot": 1
            },
            "available_strata": {
                "1": 1,
                "2": 0,
                "3": 1,
                "4": 1,
                "5": 0,
                "6": 0,
                "7": 0,
                "8": 0,
                "9": 1
            },
            "bugID": 101,
            "start_line": 792,
            "file_name": "pandas/core/dtypes/cast.py",
            "replace_code": "def astype_nansafe(arr, dtype, copy: bool = True, skipna: bool = False):\n    if is_extension_array_dtype(dtype):\n        return dtype.construct_array_type()._from_sequence(arr, dtype=dtype, copy=copy)\n    \n    if not isinstance(dtype, np.dtype):\n        dtype = pandas_dtype(dtype)\n    \n    if np.issubdtype(arr.dtype, np.datetime64) and np.datetime_data(arr.dtype).unit is None:\n        msg = f\"The '{arr.dtype.name}' dtype has no unit. Please pass in '{arr.dtype.name}[ns]' instead.\"\n        raise ValueError(msg)\n    \n    if np.issubdtype(arr.dtype, np.timedelta64) and np.timedelta_data(arr.dtype).unit is None:\n        msg = f\"The '{arr.dtype.name}' dtype has no unit. Please pass in '{arr.dtype.name}[ns]' instead.\"\n        raise ValueError(msg)\n    \n    is_object_arr = is_object_dtype(arr.dtype)\n    is_object_typ = is_object_dtype(dtype)\n    \n    if is_datetime64_dtype(arr) and is_object_typ:\n        return tslib.ints_to_pydatetime(arr.view(np.int64))\n    \n    if is_timedelta64_dtype(arr) and is_object_typ:\n        return tslibs.ints_to_pytimedelta(arr.view(np.int64))\n    \n    if np.issubdtype(arr.dtype, np.floating) and np.issubdtype(dtype, np.integer):\n        # Filter out the NaT values before conversion\n        mask = notna(arr)\n        arr_filtered = arr[mask]\n        \n        if not np.isfinite(arr_filtered).all():\n            raise ValueError(\"Cannot convert non-finite values (NA or inf) to integer\")\n    \n    if is_object_arr:\n        if np.issubdtype(dtype.type, np.integer):\n            return lib.astype_intsafe(arr.ravel(), dtype).reshape(arr.shape)\n        \n        elif is_datetime64_dtype(dtype):\n            from pandas import to_datetime\n            return astype_nansafe(to_datetime(arr).values, dtype, copy=copy)\n        \n        elif is_timedelta64_dtype(dtype):\n            from pandas import to_timedelta\n            return astype_nansafe(to_timedelta(arr).values, dtype, copy=copy)\n    \n    if copy or is_object_arr or is_object_typ:\n        return arr.astype(dtype, copy=True)\n    \n    return arr.view(dtype)",
            "import_list": [
                "from pandas import to_datetime",
                "from pandas import to_timedelta"
            ]
        }
    ]
}