### Analysis:
1. The bug is located in the `_dict_arg` function of the `SparkSubmitTask` class in the `luigi.contrib.spark` module.
2. The error message indicates a difference between the expected command list and the actual command list generated by the `_dict_arg` function.
3. The cause of the bug seems to be related to the handling of dictionary values. The function is converting dictionary values into strings with quotes, which leads to a mismatch with the expected command structure.
4. To fix the bug, we need to modify the `_dict_arg` function to handle dictionary values appropriately without adding unnecessary quotes.

### Bug Fix Strategy:
1. Check if the argument value is a dictionary and iterate over its items.
2. Create command strings without additional quotes for dictionary key-value pairs.
3. Append the generated command strings to the `command` list.
4. Return the `command` list once all dictionary items have been processed.

### Corrected Version:
```python
class SparkSubmitTask(luigi.Task):
    """
    Template task for running a Spark job
    
    Supports running jobs on Spark local, standalone, Mesos or Yarn
    
    See http://spark.apache.org/docs/latest/submitting-applications.html
    for more information
    """

    def _dict_arg(self, name, value):
        command = []
        if value and isinstance(value, dict):
            for prop, prop_value in value.items():
                command += [name, '{0}={1}'.format(prop, prop_value)]
        return command
```

By updating the `_dict_arg` function with the corrected version provided above, the function will generate the command list without unnecessary quotes, which should resolve the issues in the failing tests.