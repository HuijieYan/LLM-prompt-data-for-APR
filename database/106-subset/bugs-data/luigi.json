{
  "project": "luigi",
  "bugs": [
    {
      "id": 4,
      "buggy_code_blocks": [
        {
          "filename": "luigi/contrib/redshift.py",
          "source_code": "    def copy(self, cursor, f):\n        \"\"\"\n        Defines copying from s3 into redshift.\n\n        If both key-based and role-based credentials are provided, role-based will be used.\n        \"\"\"\n        logger.info(\"Inserting file: %s\", f)\n        colnames = ''\n        if len(self.columns) > 0:\n            colnames = \",\".join([x[0] for x in self.columns])\n            colnames = '({})'.format(colnames)\n\n        cursor.execute(\"\"\"\n         COPY {table} {colnames} from '{source}'\n         CREDENTIALS '{creds}'\n         {options}\n         ;\"\"\".format(\n            table=self.table,\n            colnames=colnames,\n            source=f,\n            creds=self._credentials(),\n            options=self.copy_options)\n        )"
        }
      ],
      "features": {
        "class_definition": null,
        "variable_definitions": null,
        "error_message": "============================= test session starts =============================\nplatform linux -- Python 3.8.10, pytest-7.4.2, pluggy-1.3.0\nrootdir: /home/huijieyan/Desktop/PyRepair/benchmarks/BugsInPy_Cloned_Repos/luigi:4\nplugins: cov-4.1.0, mock-3.11.1, timeout-2.1.0\ntimeout: 60.0s\ntimeout method: signal\ntimeout func_only: False\ncollected 1 item                                                              \n\ntest/contrib/redshift_test.py F                                         [100%]\n\n================================== FAILURES ===================================\n____________ TestS3CopyToTable.test_s3_copy_with_nonetype_columns _____________\n\nself = <contrib.redshift_test.TestS3CopyToTable testMethod=test_s3_copy_with_nonetype_columns>\nmock_redshift_target = <MagicMock name='RedshiftTarget' id='139768575303008'>\n\n    @mock.patch(\"luigi.contrib.redshift.RedshiftTarget\")\n    def test_s3_copy_with_nonetype_columns(self, mock_redshift_target):\n        task = DummyS3CopyToTableKey(columns=None)\n>       task.run()\n\ntest/contrib/redshift_test.py:337: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nluigi/contrib/redshift.py:338: in run\n    self.copy(cursor, path)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = DummyS3CopyToTableKey(table=dummy_table, columns=null)\ncursor = <MagicMock name='RedshiftTarget().connect().cursor()' id='139768574974560'>\nf = 's3://bucket/key'\n\n    def copy(self, cursor, f):\n        \"\"\"\n        Defines copying from s3 into redshift.\n    \n        If both key-based and role-based credentials are provided, role-based will be used.\n        \"\"\"\n        logger.info(\"Inserting file: %s\", f)\n        colnames = ''\n>       if len(self.columns) > 0:\nE       TypeError: object of type 'NoneType' has no len()\n\nluigi/contrib/redshift.py:356: TypeError\n============================== warnings summary ===============================\nluigi/parameter.py:28\n  /home/huijieyan/Desktop/PyRepair/benchmarks/BugsInPy_Cloned_Repos/luigi:4/luigi/parameter.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import OrderedDict, Mapping\n\nluigi/scheduler.py:208\n  /home/huijieyan/Desktop/PyRepair/benchmarks/BugsInPy_Cloned_Repos/luigi:4/luigi/scheduler.py:208: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    class OrderedSet(collections.MutableSet):\n\nluigi/scheduler.py:98: 29 warnings\n  /home/huijieyan/Desktop/PyRepair/benchmarks/BugsInPy_Cloned_Repos/luigi:4/luigi/scheduler.py:98: DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n    fn_args = inspect.getargspec(fn)\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n=========================== short test summary info ===========================\nFAILED test/contrib/redshift_test.py::TestS3CopyToTable::test_s3_copy_with_nonetype_columns - TypeError: object of type 'NoneType' has no len()\n======================= 1 failed, 31 warnings in 0.12s ========================\n",
        "stack_trace": null,
        "test_code_blocks": [
          {
            "filename": "test/contrib/redshift_test.py",
            "test_code": "    @mock.patch(\"luigi.contrib.redshift.RedshiftTarget\")\n    def test_s3_copy_with_nonetype_columns(self, mock_redshift_target):\n        task = DummyS3CopyToTableKey(columns=None)\n        task.run()\n\n        # The mocked connection cursor passed to\n        # S3CopyToTable.copy(self, cursor, f).\n        mock_cursor = (mock_redshift_target.return_value\n                                           .connect\n                                           .return_value\n                                           .cursor\n                                           .return_value)\n\n        # `mock_redshift_target` is the mocked `RedshiftTarget` object\n        # returned by S3CopyToTable.output(self).\n        mock_redshift_target.assert_called_once_with(\n            database=task.database,\n            host=task.host,\n            update_id=task.task_id,\n            user=task.user,\n            table=task.table,\n            password=task.password,\n        )\n\n        # To get the proper intendation in the multiline `COPY` statement the\n        # SQL string was copied from redshift.py.\n        mock_cursor.execute.assert_called_with(\"\"\"\n         COPY {table} {colnames} from '{source}'\n         CREDENTIALS '{creds}'\n         {options}\n         ;\"\"\".format(\n            table='dummy_table',\n            colnames='',\n            source='s3://bucket/key',\n            creds='aws_access_key_id=key;aws_secret_access_key=secret',\n            options='')\n        )"
          }
        ],
        "raised_issue_descriptions": [
          {
            "title": "Redshift COPY fails in luigi 2.7.1 when columns are not provided",
            "content": "Running Redshift COPY jobs with columns = None to prohibit table creation fails in luigi 2.7.1 with\n\nTypeError: object of type 'NoneType' has no len()\nThe root cause seems to be https://github.com/spotify/luigi/pull/2245/files#diff-778ea3db4cccaf4de6564889c5eb670fR338\n\nA possible solution would be to change the line to\n\nif self.columns and len(self.columns) > 0:\nunless I am missing some reason to explicitly ask only for len(self.columns)."
          }
        ]
      }
    },
    {
      "id": 25,
      "buggy_code_blocks": [
        {
          "filename": "luigi/contrib/redshift.py",
          "source_code": "    def run(self):\n        \"\"\"\n        If the target table doesn't exist, self.create_table\n        will be called to attempt to create the table.\n        \"\"\"\n        if not (self.table):\n            raise Exception(\"table need to be specified\")\n\n        path = self.s3_load_path()\n        connection = self.output().connect()\n        if not self.does_table_exist(connection):\n            # try creating table\n            logger.info(\"Creating table %s\", self.table)\n            connection.reset()\n            self.create_table(connection)\n        elif self.do_truncate_table():\n            logger.info(\"Truncating table %s\", self.table)\n            self.truncate_table(connection)\n\n        logger.info(\"Inserting file: %s\", path)\n        cursor = connection.cursor()\n        self.init_copy(connection)\n        self.copy(cursor, path)\n        self.output().touch(connection)\n        connection.commit()\n\n        # commit and clean up\n        connection.close()"
        }
      ],
      "features": {
        "class_definition": null,
        "variable_definitions": null,
        "error_message": "=================================== FAILURES ===================================\n___________________ TestS3CopyToTable.test_s3_copy_to_table ____________________\n\nself = <contrib.redshift_test.TestS3CopyToTable testMethod=test_s3_copy_to_table>\nmock_redshift_target = <MagicMock name='RedshiftTarget' id='139901530488544'>\nmock_copy = <MagicMock name='copy' id='139901530230352'>\n\n    @mock.patch(\"luigi.contrib.redshift.S3CopyToTable.copy\")\n    @mock.patch(\"luigi.contrib.redshift.RedshiftTarget\")\n    def test_s3_copy_to_table(self, mock_redshift_target, mock_copy):\n        task = DummyS3CopyToTable()\n>       task.run()\n\ntest/contrib/redshift_test.py:55: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = DummyS3CopyToTable()\n\n    def run(self):\n        \"\"\"\n        If the target table doesn't exist, self.create_table\n        will be called to attempt to create the table.\n        \"\"\"\n        if not (self.table):\n            raise Exception(\"table need to be specified\")\n    \n>       path = self.s3_load_path()\nE       TypeError: 'str' object is not callable\n\nenv/lib/python3.8/site-packages/luigi/contrib/redshift.py:166: TypeError\n",
        "stack_trace": null,
        "test_code_blocks": [
          {
            "filename": "test/contrib/redshift_test.py",
            "test_code": "    @mock.patch(\"luigi.contrib.redshift.S3CopyToTable.copy\")\n    @mock.patch(\"luigi.contrib.redshift.RedshiftTarget\")\n    def test_s3_copy_to_table(self, mock_redshift_target, mock_copy):\n        task = DummyS3CopyToTable()\n        task.run()\n\n        # The mocked connection cursor passed to\n        # S3CopyToTable.copy(self, cursor, f).\n        mock_cursor = (mock_redshift_target.return_value\n                                           .connect\n                                           .return_value\n                                           .cursor\n                                           .return_value)\n\n        # `mock_redshift_target` is the mocked `RedshiftTarget` object\n        # returned by S3CopyToTable.output(self).\n        mock_redshift_target.assert_called_with(database=task.database,\n                                                host=task.host,\n                                                update_id='DummyS3CopyToTable()',\n                                                user=task.user,\n                                                table=task.table,\n                                                password=task.password)\n\n        # Check if the `S3CopyToTable.s3_load_path` class attribute was\n        # successfully referenced in the `S3CopyToTable.run` method, which is\n        # in-turn passed to `S3CopyToTable.copy` and other functions in `run`\n        # (see issue #995).\n        mock_copy.assert_called_with(mock_cursor, task.s3_load_path)\n\n        # Check the SQL query in `S3CopyToTable.does_table_exist`.\n        mock_cursor.execute.assert_called_with(\"select 1 as table_exists \"\n                                               \"from pg_table_def \"\n                                               \"where tablename = %s limit 1\",\n                                               (task.table,))\n\n        return"
          }
        ],
        "raised_issue_descriptions": [
          {
            "title": "S3CopyToTable.s3_load_path TypeError",
            "content": "I encountered this TypeError when subclassing S3CopyToTable:\n...\nTraceback (most recent call last):\n  File \"/home/kian/workspaces/contrib/luigi/luigi/worker.py\", line 137, in run\n    new_deps = self._run_get_new_deps()\n  File \"/home/kian/workspaces/contrib/luigi/luigi/worker.py\", line 88, in _run_get_new_deps\n    task_gen = self.task.run()\n  File \"/home/kian/workspaces/contrib/luigi/luigi/contrib/redshift.py\", line 166, in run\n    path = self.s3_load_path()\nTypeError: 'str' object is not callable\nINFO: Skipping error email. Set `error-email` in the `core` section of the luigi config file to receive error emails.\nDEBUG: 1 running tasks, waiting for next task to finish\nDEBUG: Asking scheduler for work...\nINFO: Done\nINFO: There are no more tasks to run at this time\nINFO: Worker Worker(salt=532581476, workers=1, host=..., username=kian, pid=23435) was stopped. Shutting down Keep-Alive thread\n\nwhich was fixed by changing https://github.com/spotify/luigi/blob/master/luigi/contrib/redshift.py#L166 from:\npath = self.s3_load_path()\n\nto\npath = self.s3_load_path\n\n(I submitted this fix as PR #996)\n\nas per the other class properties, which as far as i can tell, aren't explicitly referenced as methods either (otherwise they too would raise the above exception?).\n\nThe snippet I used to generate the above error:\nimport luigi\n\nfrom luigi.s3 import S3Target, S3Client                                                                          \nfrom luigi.contrib.redshift import S3CopyToTable                                                                 \n\n\nclass MyS3Task(luigi.Task): \n    local_tsv = luigi.Parameter()\n    s3_load_path = luigi.Parameter()                                                                             \n    client = luigi.Parameter()\n\n    def output(self):\n        return S3Target(self.s3_load_path, client=self.client)\n\n    def run(self):\n        self.client.put(self.local_tsv, self.output().path)\n        return\n\n\nclass MyRedshiftTask(S3CopyToTable):\n    host = luigi.Parameter()\n    database = luigi.Parameter()\n    user = luigi.Parameter()\n    password = luigi.Parameter()\n    table = luigi.Parameter()\n    local_tsv = luigi.Parameter()\n\n    aws_access_key_id = luigi.Parameter()\n    aws_secret_access_key = luigi.Parameter()\n\n    columns = [(\"x\", \"INT\"),\n               (\"y\", \"INT\")]\n\n    s3_load_path = luigi.Parameter()\n    copy_options = \"IGNOREHEADER 1\"\n\n    def requires(self):\n        client = S3Client(self.aws_access_key_id, self.aws_secret_access_key)\n        return MyS3Task(s3_load_path=self.s3_load_path,\n                        local_tsv=self.local_tsv, client=client)\n\n\nif __name__ == '__main__':\n    luigi.run()\n\nwhich was run from the command line using:\npython ./luigi_example.py --local-scheduler MyRedshiftTask \\\n    --host \"<REDSHIFT ENDPOINT>:5439\" \\\n    --database \"dev\" \\\n    --user \"<USERNAME>\" \\\n    --password \"<HIDDEN>\" \\\n    --table \"test_redshift_table_5439\" \\\n    --aws-access-key-id \"<HIDDEN>\" \\\n    --aws-secret-access-key \"<HIDDEN>\" \\\n    --s3-load-path \"s3://bucket-5439/test.tsv\" \\\n    --local-tsv \"./test.tsv\" \\\n\nwhere test.tsv (tab-separated values) contained:\nx   y\n1   2\n10  20\n100 200"
          }
        ]
      }
    },
    {
      "id": 28,
      "buggy_code_blocks": [
        {
          "filename": "luigi/contrib/hive.py",
          "source_code": "    def table_exists(self, table, database='default', partition=None):\n        if partition is None:\n            stdout = run_hive_cmd('use {0}; show tables like \"{1}\";'.format(database, table))\n\n            return stdout and table in stdout\n        else:\n            stdout = run_hive_cmd(\"\"\"use %s; show partitions %s partition\n                                (%s)\"\"\" % (database, table, self.partition_spec(partition)))\n\n            if stdout:\n                return True\n            else:\n                return False"
        }
      ],
      "features": {
        "class_definition": null,
        "variable_definitions": null,
        "error_message": "",
        "stack_trace": null,
        "test_code_blocks": [
          {
            "filename": "test/contrib/redshift_test.py",
            "test_code": "    @mock.patch(\"luigi.contrib.redshift.S3CopyToTable.copy\")\n    @mock.patch(\"luigi.contrib.redshift.RedshiftTarget\")\n    def test_s3_copy_to_table(self, mock_redshift_target, mock_copy):\n        task = DummyS3CopyToTable()\n        task.run()\n\n        # The mocked connection cursor passed to\n        # S3CopyToTable.copy(self, cursor, f).\n        mock_cursor = (mock_redshift_target.return_value\n                                           .connect\n                                           .return_value\n                                           .cursor\n                                           .return_value)\n\n        # `mock_redshift_target` is the mocked `RedshiftTarget` object\n        # returned by S3CopyToTable.output(self).\n        mock_redshift_target.assert_called_with(database=task.database,\n                                                host=task.host,\n                                                update_id='DummyS3CopyToTable()',\n                                                user=task.user,\n                                                table=task.table,\n                                                password=task.password)\n\n        # Check if the `S3CopyToTable.s3_load_path` class attribute was\n        # successfully referenced in the `S3CopyToTable.run` method, which is\n        # in-turn passed to `S3CopyToTable.copy` and other functions in `run`\n        # (see issue #995).\n        mock_copy.assert_called_with(mock_cursor, task.s3_load_path)\n\n        # Check the SQL query in `S3CopyToTable.does_table_exist`.\n        mock_cursor.execute.assert_called_with(\"select 1 as table_exists \"\n                                               \"from pg_table_def \"\n                                               \"where tablename = %s limit 1\",\n                                               (task.table,))\n\n        return"
          }
        ],
        "raised_issue_descriptions": [
          {
            "title": "hive table_exists should be case insensitive?",
            "content": "Any thoughts on this one?\\n\\nIn https://github.com/spotify/luigi/blob/master/luigi/contrib/hive.py#L141\\n(possibly here too, but we're not on CDH: https://github.com/spotify/luigi/blob/master/luigi/contrib/hive.py#L192)\\n\\nSometimes we have tables that are defined as capitalized, rather than lower case underscored names. These are easier to read in code if left capitalized, though hive is case insensitive, and will return them as lower case.\\n\\nE.g. when checking for an existing table table = 'FooBar', stdout will return with foobar and the test will fail\\n\\nThis wasn't an issue in older versions, which just checked for string \\\"does not exist\\\" or \\\"Table not found\\\" in stdout.\\n\\nWould be easy to fix using return stdout and table.lower() in stdout or return stdout and table.lower() in stdout.lower()\\n\\nLet me know your thoughts on this. I can supply a pull request if necessary.\\n\\nThanks,\\nLin."
          },
          {
            "title": "Fix #896: make table_exists case insensitive",
            "content": "Check stdout against table.lower() to avoid case issues"
          }
        ]
      }
    }
  ]
}