{
  "project": "keras",
  "bugs": [
    {
      "id": 9,
      "buggy_code_blocks": [
        {
          "filename": "docs/autogen.py",
          "source_code": "def process_list_block(docstring, starting_point, section_end,\n                       leading_spaces, marker):\n    ending_point = docstring.find('\\n\\n', starting_point)\n    block = docstring[starting_point:(None if ending_point == -1 else\n                                      ending_point - 1)]\n    # Place marker for later reinjection.\n    docstring_slice = docstring[starting_point:section_end].replace(block, marker)\n    docstring = (docstring[:starting_point]\n                 + docstring_slice\n                 + docstring[section_end:])\n    lines = block.split('\\n')\n    # Remove the computed number of leading white spaces from each line.\n    lines = [re.sub('^' + ' ' * leading_spaces, '', line) for line in lines]\n    # Usually lines have at least 4 additional leading spaces.\n    # These have to be removed, but first the list roots have to be detected.\n    top_level_regex = r'^    ([^\\s\\\\\\(]+):(.*)'\n    top_level_replacement = r'- __\\1__:\\2'\n    lines = [re.sub(top_level_regex, top_level_replacement, line) for line in lines]\n    # All the other lines get simply the 4 leading space (if present) removed\n    lines = [re.sub(r'^    ', '', line) for line in lines]\n    # Fix text lines after lists\n    indent = 0\n    text_block = False\n    for i in range(len(lines)):\n        line = lines[i]\n        spaces = re.search(r'\\S', line)\n        if spaces:\n            # If it is a list element\n            if line[spaces.start()] == '-':\n                indent = spaces.start() + 1\n                if text_block:\n                    text_block = False\n                    lines[i] = '\\n' + line\n            elif spaces.start() < indent:\n                text_block = True\n                indent = spaces.start()\n                lines[i] = '\\n' + line\n        else:\n            text_block = False\n            indent = 0\n    block = '\\n'.join(lines)\n    return docstring, block"
        }
      ],
      "features": {
        "class_definition": null,
        "variable_definitions": null,
        "error_message": "=================================================== test session starts ===================================================\nplatform darwin -- Python 3.7.9, pytest-5.4.3, py-1.8.1, pluggy-0.13.1 -- /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:9/venv/bin/python3.7\ncachedir: .pytest_cache\nrootdir: /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:9, inifile: pytest.ini\nplugins: timeout-2.1.0, cov-4.1.0, mock-3.11.1, flaky-3.6.1, forked-1.1.3, xdist-1.32.0\ntimeout: 60.0s\ntimeout method: signal\ntimeout func_only: False\n[gw0] darwin Python 3.7.9 cwd: /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:9\n[gw1] darwin Python 3.7.9 cwd: /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:9\n[gw0] Python 3.7.9 (v3.7.9:13c94747c7, Aug 15 2020, 01:31:08)  -- [Clang 6.0 (clang-600.0.57)]\n[gw1] Python 3.7.9 (v3.7.9:13c94747c7, Aug 15 2020, 01:31:08)  -- [Clang 6.0 (clang-600.0.57)]\ngw0 [1] / gw1 [1]\nscheduling tests via LoadScheduling\n\ntests/test_doc_auto_generation.py::test_doc_lists[docs_descriptor1] \n[gw0] [100%] FAILED tests/test_doc_auto_generation.py::test_doc_lists[docs_descriptor1] \n\n======================================================== FAILURES =========================================================\n____________________________________________ test_doc_lists[docs_descriptor1] _____________________________________________\n[gw0] darwin -- Python 3.7.9 /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:9/venv/bin/python3.7\n\ndocs_descriptor = {'doc': 'Base class for recurrent layers.\\n\\n    # Arguments\\n        return_sequences: Boolean. Whether to return the...r the full sequence.\\n- __return_state__: Boolean. Whether to return the last state\\n    in addition to the output.\\n'}\n\n    @pytest.mark.parametrize('docs_descriptor', [\n        test_doc1,\n        test_doc_with_arguments_as_last_block,\n    ])\n    def test_doc_lists(docs_descriptor):\n        docstring = autogen.process_docstring(docs_descriptor['doc'])\n>       assert markdown(docstring) == markdown(docs_descriptor['result'])\nE       AssertionError: assert '<p>Base clas...e output.</p>' == '<p>Base clas....</li>\\n</ul>'\nE           <p>Base class for recurrent layers.</p>\nE           <p><strong>Arguments</strong></p>\nE         - <ul>\nE         - <li><strong>return_sequences</strong>: Boolean. Whether to return the last output\nE         ?  ^^^^^^^^^^                 ---------\nE         + <p>return_sequences: Boolean. Whether to return the last output\nE         ?  ^...\nE         \nE         ...Full output truncated (12 lines hidden), use '-vv' to show\n\ntests/test_doc_auto_generation.py:355: AssertionError\n------------------------------------------------ Captured stderr teardown -------------------------------------------------\nWARNING:tensorflow:From /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:9/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n\nWARNING:tensorflow:From /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:9/keras/backend/tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n\nWARNING:tensorflow:From /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:9/keras/backend/tensorflow_backend.py:102: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n\n-------------------------------------------------- Captured log teardown --------------------------------------------------\nWARNING  tensorflow:module_wrapper.py:139 From /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:9/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n\nWARNING  tensorflow:module_wrapper.py:139 From /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:9/keras/backend/tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n\nWARNING  tensorflow:module_wrapper.py:139 From /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:9/keras/backend/tensorflow_backend.py:102: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n==================================================== warnings summary =====================================================\nvenv/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/learn_io/generator_io.py:26\n  /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:9/venv/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/learn_io/generator_io.py:26: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n    from collections import Container\n\n-- Docs: https://docs.pytest.org/en/latest/warnings.html\n================================================ slowest 20 test durations ================================================\n0.01s call     tests/test_doc_auto_generation.py::test_doc_lists[docs_descriptor1]\n\n(0.00 durations hidden.  Use -vv to show these durations.)\n================================================= short test summary info =================================================\nFAILED tests/test_doc_auto_generation.py::test_doc_lists[docs_descriptor1] - AssertionError: assert '<p>Base clas...e ou...\n============================================== 1 failed, 1 warning in 6.29s ===============================================\nUsing TensorFlow backend.",
        "test_code_blocks": [
          {
            "filename": "tests/test_doc_auto_generation.py",
            "test_code": "\ntest_doc_with_arguments_as_last_block = {\n    'doc': \"\"\"Base class for recurrent layers.\n    # Arguments\n        return_sequences: Boolean. Whether to return the last output\n            in the output sequence, or the full sequence.\n        return_state: Boolean. Whether to return the last state\n            in addition to the output.\n    \"\"\",\n    'result': '''Base class for recurrent layers.\n__Arguments__\n- __return_sequences__: Boolean. Whether to return the last output\n    in the output sequence, or the full sequence.\n- __return_state__: Boolean. Whether to return the last state\n    in addition to the output.\n'''}\n\n\n@pytest.mark.parametrize('docs_descriptor', [\n    test_doc1,\n    test_doc_with_arguments_as_last_block,\n])\ndef test_doc_lists(docs_descriptor):\n    docstring = autogen.process_docstring(docs_descriptor['doc'])\n    assert markdown(docstring) == markdown(docs_descriptor['result'])"
          }
        ],
        "raised_issue_descriptions": [
          {
            "title": "Callbacks documentation not showing bullet points correctly",
            "content": "The current documentation on callbacks isn't showing bullet points correctly under the \"Arguments\" section of a few models. Here's the example for ModelCheckpoint:\n\nfilepath: string, path to save the model file. monitor: quantity to monitor. verbose: verbosity mode, 0 or 1. save_best_only: if save_best_only=True, the latest best model according to the quantity monitored will not be overwritten. mode: one of {auto, min, max}. If save_best_only=True, the decision to overwrite the current save file is made based on either the maximization or the minimization of the monitored quantity. For val_acc, this should be max, for val_loss this should be min, etc. In auto mode, the direction is automatically inferred from the name of the monitored quantity. save_weights_only: if True, then only the model's weights will be saved (model.save_weights(filepath)), else the full model is saved (model.save(filepath)). period: Interval (number of epochs) between checkpoints.\n\nLooking at the source code, the docstring seems to be organized correctly:\nkeras/keras/callbacks.py\n\nLines 371 to 390 in dc9e510\n\n     # Arguments \n         filepath: string, path to save the model file. \n         monitor: quantity to monitor. \n         verbose: verbosity mode, 0 or 1. \n         save_best_only: if `save_best_only=True`, \n             the latest best model according to \n             the quantity monitored will not be overwritten. \n         mode: one of {auto, min, max}. \n             If `save_best_only=True`, the decision \n             to overwrite the current save file is made \n             based on either the maximization or the \n             minimization of the monitored quantity. For `val_acc`, \n             this should be `max`, for `val_loss` this should \n             be `min`, etc. In `auto` mode, the direction is \n             automatically inferred from the name of the monitored quantity. \n         save_weights_only: if True, then only the model's weights will be \n             saved (`model.save_weights(filepath)`), else the full model \n             is saved (`model.save(filepath)`). \n         period: Interval (number of epochs) between checkpoints. \n     \"\"\" \nIt is however showing up correctly for other models, e.g. ProgbarLogger:\n\nArguments\ncount_mode: One of \"steps\" or \"samples\". Whether the progress bar should count samples seen or steps (batches) seen.\nstateful_metrics: Iterable of string names of metrics that should not be averaged over an epoch. Metrics in this list will be logged as-is. All others will be averaged over time (e.g. loss, etc)."
          },
          {
            "title": "EarlyStopping documentation with wrong format",
            "content": "EarlyStopping documentation has the wrong format. See here:\nhttps://keras.io/callbacks/#earlystopping\n\nThe Arguments section is bugged."
          }
        ]
      }
    },
    {
      "id": 14,
      "buggy_code_blocks": [
        {
          "filename": "keras/metrics.py",
          "source_code": "def sparse_top_k_categorical_accuracy(y_true, y_pred, k=5):\n    return K.mean(K.in_top_k(y_pred, K.cast(K.max(y_true, axis=-1), 'int32'), k),\n                  axis=-1)"
        }
      ],
      "features": {
        "class_definition": null,
        "variable_definitions": null,
        "error_message": "=================================================== test session starts ===================================================\nplatform darwin -- Python 3.7.9, pytest-5.4.3, py-1.8.1, pluggy-0.13.1 -- /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:14/venv/bin/python3.7\ncachedir: .pytest_cache\nrootdir: /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:14, inifile: pytest.ini\nplugins: timeout-2.1.0, cov-4.1.0, mock-3.11.1, flaky-3.6.1, forked-1.1.3, xdist-1.32.0\ntimeout: 60.0s\ntimeout method: signal\ntimeout func_only: False\n[gw0] darwin Python 3.7.9 cwd: /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:14\n[gw1] darwin Python 3.7.9 cwd: /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:14\n[gw0] Python 3.7.9 (v3.7.9:13c94747c7, Aug 15 2020, 01:31:08)  -- [Clang 6.0 (clang-600.0.57)]\n[gw1] Python 3.7.9 (v3.7.9:13c94747c7, Aug 15 2020, 01:31:08)  -- [Clang 6.0 (clang-600.0.57)]\ngw0 [1] / gw1 [1]\nscheduling tests via LoadScheduling\n\ntests/keras/metrics_test.py::test_sparse_top_k_categorical_accuracy[y_pred1-y_true1] \n[gw0] [100%] FAILED tests/keras/metrics_test.py::test_sparse_top_k_categorical_accuracy[y_pred1-y_true1] \n\n======================================================== FAILURES =========================================================\n_________________________________ test_sparse_top_k_categorical_accuracy[y_pred1-y_true1] _________________________________\n[gw0] darwin -- Python 3.7.9 /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:14/venv/bin/python3.7\n\ngraph = <tensorflow.python.framework.ops.Graph object at 0x7fc42f2b1650>\nnode_def = name: \"in_top_k/InTopKV2\"\nop: \"InTopKV2\"\nattr {\n  key: \"T\"\n  value {\n    type: DT_INT32\n  }\n}\n\ninputs = [<tf.Tensor 'Variable/read:0' shape=(2, 3) dtype=float32>, <tf.Tensor 'Cast:0' shape=() dtype=int32>, <tf.Tensor 'in_top_k/InTopKV2/k:0' shape=() dtype=int32>]\ncontrol_inputs = []\n\n    def _create_c_op(graph, node_def, inputs, control_inputs):\n      \"\"\"Creates a TF_Operation.\n    \n      Args:\n        graph: a `Graph`.\n        node_def: `node_def_pb2.NodeDef` for the operation to create.\n        inputs: A list of `Tensor`s (corresponding to scalar inputs) and lists of\n          `Tensor`s (corresponding to sequence inputs, e.g. \"int64 * N\",\n          \"list(int64)\"). The length of the list should be equal to the number of\n          inputs specified by this operation's op def.\n        control_inputs: A list of `Operation`s to set as control dependencies.\n    \n      Returns:\n        A wrapped TF_Operation*.\n      \"\"\"\n      # pylint: disable=protected-access\n      op_desc = c_api.TF_NewOperation(graph._c_graph, compat.as_str(node_def.op),\n                                      compat.as_str(node_def.name))\n      if node_def.device:\n        c_api.TF_SetDevice(op_desc, compat.as_str(node_def.device))\n      # Add inputs\n      for op_input in inputs:\n        if isinstance(op_input, (list, tuple)):\n          c_api.TF_AddInputList(op_desc, [t._as_tf_output() for t in op_input])\n        else:\n          c_api.TF_AddInput(op_desc, op_input._as_tf_output())\n    \n      # Add control inputs\n      for control_input in control_inputs:\n        c_api.TF_AddControlInput(op_desc, control_input._c_op)\n      # pylint: enable=protected-access\n    \n      # Add attrs\n      for name, attr_value in node_def.attr.items():\n        serialized = attr_value.SerializeToString()\n        # TODO(skyewm): this creates and deletes a new TF_Status for every attr.\n        # It might be worth creating a convenient way to re-use the same status.\n        c_api.TF_SetAttrValueProto(op_desc, compat.as_str(name), serialized)\n    \n      try:\n>       c_op = c_api.TF_FinishOperation(op_desc)\nE       tensorflow.python.framework.errors_impl.InvalidArgumentError: Shape must be rank 1 but is rank 0 for 'in_top_k/InTopKV2' (op: 'InTopKV2') with input shapes: [2,3], [], [].\n\nvenv/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1607: InvalidArgumentError\n\nDuring handling of the above exception, another exception occurred:\n\ny_pred = <tf.Variable 'Variable:0' shape=(2, 3) dtype=float32_ref>\ny_true = <tf.Variable 'Variable_1:0' shape=(2,) dtype=float32_ref>\n\n    @pytest.mark.skipif((K.backend() == 'cntk'),\n                        reason='CNTK backend does not support top_k yet')\n    @pytest.mark.parametrize('y_pred, y_true', [\n        # Test correctness if the shape of y_true is (num_samples, 1)\n        (np.array([[0.3, 0.2, 0.1], [0.1, 0.2, 0.7]]), np.array([[1], [0]])),\n        # Test correctness if the shape of y_true is (num_samples,)\n        (np.array([[0.3, 0.2, 0.1], [0.1, 0.2, 0.7]]), np.array([1, 0])),\n    ])\n    def test_sparse_top_k_categorical_accuracy(y_pred, y_true):\n        y_pred = K.variable(y_pred)\n        y_true = K.variable(y_true)\n        success_result = K.eval(\n>           metrics.sparse_top_k_categorical_accuracy(y_true, y_pred, k=3))\n\ntests/keras/metrics_test.py:109: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nkeras/metrics.py:48: in sparse_top_k_categorical_accuracy\n    return K.mean(K.in_top_k(y_pred, K.cast(K.max(y_true, axis=-1), 'int32'), k),\nkeras/backend/tensorflow_backend.py:3446: in in_top_k\n    return tf.nn.in_top_k(predictions, targets, k)\nvenv/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_ops.py:4843: in in_top_k\n    return gen_nn_ops.in_top_kv2(predictions, targets, k, name=name)\nvenv/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_nn_ops.py:5042: in in_top_kv2\n    \"InTopKV2\", predictions=predictions, targets=targets, k=k, name=name)\nvenv/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py:794: in _apply_op_helper\n    op_def=op_def)\nvenv/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py:507: in new_func\n    return func(*args, **kwargs)\nvenv/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:3357: in create_op\n    attrs, op_def, compute_device)\nvenv/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:3426: in _create_op_internal\n    op_def=op_def)\nvenv/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1770: in __init__\n    control_input_ops)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ngraph = <tensorflow.python.framework.ops.Graph object at 0x7fc42f2b1650>\nnode_def = name: \"in_top_k/InTopKV2\"\nop: \"InTopKV2\"\nattr {\n  key: \"T\"\n  value {\n    type: DT_INT32\n  }\n}\n\ninputs = [<tf.Tensor 'Variable/read:0' shape=(2, 3) dtype=float32>, <tf.Tensor 'Cast:0' shape=() dtype=int32>, <tf.Tensor 'in_top_k/InTopKV2/k:0' shape=() dtype=int32>]\ncontrol_inputs = []\n\n    def _create_c_op(graph, node_def, inputs, control_inputs):\n      \"\"\"Creates a TF_Operation.\n    \n      Args:\n        graph: a `Graph`.\n        node_def: `node_def_pb2.NodeDef` for the operation to create.\n        inputs: A list of `Tensor`s (corresponding to scalar inputs) and lists of\n          `Tensor`s (corresponding to sequence inputs, e.g. \"int64 * N\",\n          \"list(int64)\"). The length of the list should be equal to the number of\n          inputs specified by this operation's op def.\n        control_inputs: A list of `Operation`s to set as control dependencies.\n    \n      Returns:\n        A wrapped TF_Operation*.\n      \"\"\"\n      # pylint: disable=protected-access\n      op_desc = c_api.TF_NewOperation(graph._c_graph, compat.as_str(node_def.op),\n                                      compat.as_str(node_def.name))\n      if node_def.device:\n        c_api.TF_SetDevice(op_desc, compat.as_str(node_def.device))\n      # Add inputs\n      for op_input in inputs:\n        if isinstance(op_input, (list, tuple)):\n          c_api.TF_AddInputList(op_desc, [t._as_tf_output() for t in op_input])\n        else:\n          c_api.TF_AddInput(op_desc, op_input._as_tf_output())\n    \n      # Add control inputs\n      for control_input in control_inputs:\n        c_api.TF_AddControlInput(op_desc, control_input._c_op)\n      # pylint: enable=protected-access\n    \n      # Add attrs\n      for name, attr_value in node_def.attr.items():\n        serialized = attr_value.SerializeToString()\n        # TODO(skyewm): this creates and deletes a new TF_Status for every attr.\n        # It might be worth creating a convenient way to re-use the same status.\n        c_api.TF_SetAttrValueProto(op_desc, compat.as_str(name), serialized)\n    \n      try:\n        c_op = c_api.TF_FinishOperation(op_desc)\n      except errors.InvalidArgumentError as e:\n        # Convert to ValueError for backwards compatibility.\n>       raise ValueError(str(e))\nE       ValueError: Shape must be rank 1 but is rank 0 for 'in_top_k/InTopKV2' (op: 'InTopKV2') with input shapes: [2,3], [], [].\n\nvenv/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1610: ValueError\n------------------------------------------------ Captured stderr teardown -------------------------------------------------\nWARNING:tensorflow:From /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:14/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n\nWARNING:tensorflow:From /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:14/keras/backend/tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n\nWARNING:tensorflow:From /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:14/keras/backend/tensorflow_backend.py:102: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n\n-------------------------------------------------- Captured log teardown --------------------------------------------------\nWARNING  tensorflow:module_wrapper.py:139 From /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:14/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n\nWARNING  tensorflow:module_wrapper.py:139 From /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:14/keras/backend/tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n\nWARNING  tensorflow:module_wrapper.py:139 From /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:14/keras/backend/tensorflow_backend.py:102: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n==================================================== warnings summary =====================================================\nvenv/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_util.py:521\nvenv/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_util.py:521\n  /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:14/venv/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_util.py:521: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n    tensor_proto.tensor_content = nparray.tostring()\n\nvenv/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/learn_io/generator_io.py:26\n  /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:14/venv/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/learn_io/generator_io.py:26: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n    from collections import Container\n\n-- Docs: https://docs.pytest.org/en/latest/warnings.html\n================================================ slowest 20 test durations ================================================\n0.01s call     tests/keras/metrics_test.py::test_sparse_top_k_categorical_accuracy[y_pred1-y_true1]\n\n(0.00 durations hidden.  Use -vv to show these durations.)\n================================================= short test summary info =================================================\nFAILED tests/keras/metrics_test.py::test_sparse_top_k_categorical_accuracy[y_pred1-y_true1] - ValueError: Shape must be ...\n============================================== 1 failed, 3 warnings in 6.56s ==============================================\nUsing TensorFlow backend.",
        "test_code_blocks": [
          {
            "filename": "tests/keras/metrics_test.py",
            "test_code": "@pytest.mark.skipif((K.backend() == 'cntk'),\n                    reason='CNTK backend does not support top_k yet')\n@pytest.mark.parametrize('y_pred, y_true', [\n    # Test correctness if the shape of y_true is (num_samples, 1)\n    (np.array([[0.3, 0.2, 0.1], [0.1, 0.2, 0.7]]), np.array([[1], [0]])),\n    # Test correctness if the shape of y_true is (num_samples,)\n    (np.array([[0.3, 0.2, 0.1], [0.1, 0.2, 0.7]]), np.array([1, 0])),\n])\ndef test_sparse_top_k_categorical_accuracy(y_pred, y_true):\n    y_pred = K.variable(y_pred)\n    y_true = K.variable(y_true)\n    success_result = K.eval(\n        metrics.sparse_top_k_categorical_accuracy(y_true, y_pred, k=3))\n\n    assert success_result == 1\n    partial_result = K.eval(\n        metrics.sparse_top_k_categorical_accuracy(y_true, y_pred, k=2))\n    assert partial_result == 0.5\n    failure_result = K.eval(\n        metrics.sparse_top_k_categorical_accuracy(y_true, y_pred, k=1))\n    assert failure_result == 0"
          }
        ],
        "raised_issue_descriptions": [
          {
            "title": "fix sparse categorical acc",
            "content": "Summary\nsparse categorical acc should have the same result as categorical acc.\nFor example, with 3 classes, given sparse_true_label = [0, 1, 1], it's equivalent in categorical labels is dense_true_label = [[1, 0, 0], [0, 1, 0], [0, 1, 0]]. With the same predictions\n\npred = [[0.7, 0.2, 0.1], \n[0.1, 0.1, 0.8], \n[0.2, 0.6, 0.2]]\nThey should produce the same acc which is [1, 0 ,1]\n\nNot sure why max is used, but it should directly compare with y_true\nAdded unit test to test correctness\nRelated Issues\nPR Overview\n This PR requires new unit tests [y] (make sure tests are included)\n This PR requires to update the documentation [n] (make sure the docs are up-to-date)\n This PR is backwards compatible [y]\n This PR changes the current API [n] (all API changes need to be approved by fchollet)"
          },
          {
            "title": "metrics=['accuracy'] seems to be calculated differently if one uses tf.data inputs instead of numpy arrays for keras model",
            "content": "Please go to Stack Overflow for help and support:\n\nhttps://stackoverflow.com/questions/tagged/tensorflow\n\nIf you open a GitHub issue, here is our policy:\n\nIt must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\nThe form below must be filled out.\nIt shouldn't be a TensorBoard issue. Those go here.\nHere's why we have that policy: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\n\nSystem information\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): YES\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\nMobile device:na\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below):1.11.0-dev20180907\nPython version:3.6.3\nBazel version (if compiling from source):na\nGCC/Compiler version (if compiling from source):na\nCUDA/cuDNN version:na\nGPU model and memory:na\nExact command to reproduce:na\nYou can collect some of this information using our environment capture script:\n\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\n\nYou can obtain the TensorFlow version with\n\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\n\nDescribe the problem\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\n\nGiven the same piece of code for loading mnist data and training a keras model in tensorflow, the metric \"accuracy\" given as argument to keras_model.compile(metrics=[...]) generates very different values (order of 0.10 versus order of 0.90) depending on if you use numpy arrays or tf.data datasets as training inputs. Note that the values of the loss in each case are very close. I suspect that \"accuracy\" is being calculated differently depending on the type of input (numpy or tf.data), or that it is being calculated wrong in one of the cases.\nIn particular, as an example, using numpy arrays as input, one can get the pair loss: 0.2086 - acc: 0.9389 in one of the steps, while the same loss in with tf.data gives the pair loss: 0.2086 - acc: 0.1024.\n\nSource code / logs\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\n\nThe code below as it is can be run and training with tf.data datasets will be performed. If you comment the block between #Train with tf.data datasets and ######################## and uncomment the block between #Train with numpy arrays and ########################, training with numpy arrays as inputs will be performed.\n\nimport tensorflow as tf\nimport numpy as np\n\nnp.random.seed(1)\ntf.set_random_seed(1)\nBATCH_SIZE = 32\n\n#Import mnist dataset as numpy arrays\n(x_train, y_train), (_, _) = tf.keras.datasets.mnist.load_data()#Import\nx_train = x_train / 255.0 #normalizing\ny_train = y_train.astype(dtype='float32')\nx_train = x_train.astype(dtype='float32')\n\nx_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1]*x_train.shape[2]))#Reshaping the 2D picture\n\n##############################################################################################\n#THIS BLOCK CREATES A DATASET FROM THE NUMPY ARRAYS. IT WILL BE USED FOR THE CASE OF TF.DATA DATASET INPUTS\ntfdata_dataset_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\ntfdata_dataset_train = tfdata_dataset_train.batch(BATCH_SIZE).repeat()\n##############################################################################################\n\n#Create model\nkeras_model = tf.keras.models.Sequential([\n    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n    tf.keras.layers.Dropout(0.2, seed=1),\n    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n])\n\n#Compile the model\nkeras_model.compile(optimizer=tf.keras.optimizers.Adam(),\n                    loss=tf.keras.losses.sparse_categorical_crossentropy,\n                    metrics=['accuracy'])\n\n#Train with numpy arrays\n#keras_training_history = keras_model.fit(x_train,\n#                y_train,\n#                epochs=1\n#                )\n########################\n\n#Train with tf.data datasets\nkeras_training_history = keras_model.fit(tfdata_dataset_train,\n                epochs=1,\n                steps_per_epoch=60000//BATCH_SIZE\n                )\n########################"
          },
          {
            "title": "Fix bug in tf.keras.metrics.sparse_categorical_accuracy",
            "content": "Fix #22190\n\nFor the input of tf.keras.metrics.sparse_categorical_accuracy, the shape of y_true can be (num_samples, 1) or (num_samples,), see #22190 for detail. The existing code assume the shape of y_true is (num_samples, 1), always reduce in the last dimension which leads the incorrect output. Actually we should check the shape of y_true and squeeze if applicable.\nMeanwhile, I also fix sparse_top_k_categorical_accuracy which has the same issue."
          }
        ]
      }
    },
    {
      "id": 25,
      "buggy_code_blocks": [
        {
          "filename": "keras/applications/imagenet_utils.py",
          "source_code": "def _preprocess_numpy_input(x, data_format, mode):\n    \"\"\"Preprocesses a Numpy array encoding a batch of images.\n    # Arguments\n        x: Input array, 3D or 4D.\n        data_format: Data format of the image array.\n        mode: One of \"caffe\", \"tf\" or \"torch\".\n            - caffe: will convert the images from RGB to BGR,\n                then will zero-center each color channel with\n                respect to the ImageNet dataset,\n                without scaling.\n            - tf: will scale pixels between -1 and 1,\n                sample-wise.\n            - torch: will scale pixels between 0 and 1 and then\n                will normalize each channel with respect to the\n                ImageNet dataset.\n    # Returns\n        Preprocessed Numpy array.\n    \"\"\"\n    if mode == 'tf':\n        x /= 127.5\n        x -= 1.\n        return x\n    if mode == 'torch':\n        x /= 255.\n        mean = [0.485, 0.456, 0.406]\n        std = [0.229, 0.224, 0.225]\n    else:\n        if data_format == 'channels_first':\n            # 'RGB'->'BGR'\n            if x.ndim == 3:\n                x = x[::-1, ...]\n            else:\n                x = x[:, ::-1, ...]\n        else:\n            # 'RGB'->'BGR'\n            x = x[..., ::-1]\n        mean = [103.939, 116.779, 123.68]\n        std = None\n    # Zero-center by mean pixel\n    if data_format == 'channels_first':\n        if x.ndim == 3:\n            x[0, :, :] -= mean[0]\n            x[1, :, :] -= mean[1]\n            x[2, :, :] -= mean[2]\n            if std is not None:\n                x[0, :, :] /= std[0]\n                x[1, :, :] /= std[1]\n                x[2, :, :] /= std[2]\n        else:\n            x[:, 0, :, :] -= mean[0]\n            x[:, 1, :, :] -= mean[1]\n            x[:, 2, :, :] -= mean[2]\n            if std is not None:\n                x[:, 0, :, :] /= std[0]\n                x[:, 1, :, :] /= std[1]\n                x[:, 2, :, :] /= std[2]\n    else:\n        x[..., 0] -= mean[0]\n        x[..., 1] -= mean[1]\n        x[..., 2] -= mean[2]\n        if std is not None:\n            x[..., 0] /= std[0]\n            x[..., 1] /= std[1]\n            x[..., 2] /= std[2]\n    return x"
        }
      ],
      "features": {
        "class_definition": null,
        "variable_definitions": null,
        "error_message": "=================================================== test session starts ===================================================\nplatform darwin -- Python 3.7.9, pytest-5.4.3, py-1.8.1, pluggy-0.13.1 -- /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:25/venv/bin/python3.7\ncachedir: .pytest_cache\nrootdir: /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:25, inifile: pytest.ini\nplugins: httpbin-1.0.0, timeout-2.1.0, cov-4.1.0, mock-3.11.1, flaky-3.6.1, forked-1.1.3, xdist-1.32.0\ntimeout: 60.0s\ntimeout method: signal\ntimeout func_only: False\n[gw0] darwin Python 3.7.9 cwd: /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:25\n[gw1] darwin Python 3.7.9 cwd: /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:25\n[gw0] Python 3.7.9 (v3.7.9:13c94747c7, Aug 15 2020, 01:31:08)  -- [Clang 6.0 (clang-600.0.57)]\n[gw1] Python 3.7.9 (v3.7.9:13c94747c7, Aug 15 2020, 01:31:08)  -- [Clang 6.0 (clang-600.0.57)]\ngw0 [1] / gw1 [1]\nscheduling tests via LoadScheduling\n\ntests/keras/applications/imagenet_utils_test.py::test_preprocess_input \n[gw0] [100%] FAILED tests/keras/applications/imagenet_utils_test.py::test_preprocess_input \n\n======================================================== FAILURES =========================================================\n__________________________________________________ test_preprocess_input __________________________________________________\n[gw0] darwin -- Python 3.7.9 /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:25/venv/bin/python3.7\n\n    def test_preprocess_input():\n        # Test image batch with float and int image input\n        x = np.random.uniform(0, 255, (2, 10, 10, 3))\n        xint = x.astype('int32')\n        assert utils.preprocess_input(x).shape == x.shape\n>       assert utils.preprocess_input(xint).shape == xint.shape\n\ntests/keras/applications/imagenet_utils_test.py:15: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nkeras/applications/imagenet_utils.py:178: in preprocess_input\n    return _preprocess_numpy_input(x, data_format=data_format, mode=mode)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nx = array([[[[143, 234, 166],\n         [ 67, 166, 122],\n         [182,  81, 169],\n         [164,  36, 180],\n         [133,...         [242, 192, 133],\n         [100, 122,  30],\n         [172, 242, 181],\n         [188, 223,  39]]]], dtype=int32)\ndata_format = 'channels_last', mode = 'caffe'\n\n    def _preprocess_numpy_input(x, data_format, mode):\n        \"\"\"Preprocesses a Numpy array encoding a batch of images.\n    \n        # Arguments\n            x: Input array, 3D or 4D.\n            data_format: Data format of the image array.\n            mode: One of \"caffe\", \"tf\" or \"torch\".\n                - caffe: will convert the images from RGB to BGR,\n                    then will zero-center each color channel with\n                    respect to the ImageNet dataset,\n                    without scaling.\n                - tf: will scale pixels between -1 and 1,\n                    sample-wise.\n                - torch: will scale pixels between 0 and 1 and then\n                    will normalize each channel with respect to the\n                    ImageNet dataset.\n    \n        # Returns\n            Preprocessed Numpy array.\n        \"\"\"\n        if mode == 'tf':\n            x /= 127.5\n            x -= 1.\n            return x\n    \n        if mode == 'torch':\n            x /= 255.\n            mean = [0.485, 0.456, 0.406]\n            std = [0.229, 0.224, 0.225]\n        else:\n            if data_format == 'channels_first':\n                # 'RGB'->'BGR'\n                if x.ndim == 3:\n                    x = x[::-1, ...]\n                else:\n                    x = x[:, ::-1, ...]\n            else:\n                # 'RGB'->'BGR'\n                x = x[..., ::-1]\n            mean = [103.939, 116.779, 123.68]\n            std = None\n    \n        # Zero-center by mean pixel\n        if data_format == 'channels_first':\n            if x.ndim == 3:\n                x[0, :, :] -= mean[0]\n                x[1, :, :] -= mean[1]\n                x[2, :, :] -= mean[2]\n                if std is not None:\n                    x[0, :, :] /= std[0]\n                    x[1, :, :] /= std[1]\n                    x[2, :, :] /= std[2]\n            else:\n                x[:, 0, :, :] -= mean[0]\n                x[:, 1, :, :] -= mean[1]\n                x[:, 2, :, :] -= mean[2]\n                if std is not None:\n                    x[:, 0, :, :] /= std[0]\n                    x[:, 1, :, :] /= std[1]\n                    x[:, 2, :, :] /= std[2]\n        else:\n>           x[..., 0] -= mean[0]\nE           numpy.core._exceptions.UFuncTypeError: Cannot cast ufunc 'subtract' output from dtype('float64') to dtype('int32') with casting rule 'same_kind'\n\nkeras/applications/imagenet_utils.py:82: UFuncTypeError\n==================================================== warnings summary =====================================================\nvenv/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py:15\nvenv/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py:15\n  /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:25/venv/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py:15: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n    import imp\n\nvenv/lib/python3.7/site-packages/tensorflow/python/util/nest.py:1286\nvenv/lib/python3.7/site-packages/tensorflow/python/util/nest.py:1286\n  /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:25/venv/lib/python3.7/site-packages/tensorflow/python/util/nest.py:1286: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n    _pywrap_tensorflow.RegisterType(\"Mapping\", _collections.Mapping)\n\nvenv/lib/python3.7/site-packages/tensorflow/python/util/nest.py:1287\nvenv/lib/python3.7/site-packages/tensorflow/python/util/nest.py:1287\n  /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:25/venv/lib/python3.7/site-packages/tensorflow/python/util/nest.py:1287: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n    _pywrap_tensorflow.RegisterType(\"Sequence\", _collections.Sequence)\n\nvenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516\nvenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516\n  /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:25/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n    _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n\nvenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517\nvenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517\n  /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:25/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n    _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n\nvenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518\nvenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518\n  /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:25/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n    _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n\nvenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519\nvenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519\n  /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:25/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n    _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n\nvenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520\nvenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520\n  /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:25/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n    _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n\nvenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525\nvenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525\n  /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:25/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n    np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n\nvenv/lib/python3.7/site-packages/tensorflow/python/training/tracking/object_identity.py:61\nvenv/lib/python3.7/site-packages/tensorflow/python/training/tracking/object_identity.py:61\n  /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:25/venv/lib/python3.7/site-packages/tensorflow/python/training/tracking/object_identity.py:61: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n    class ObjectIdentityDictionary(collections.MutableMapping):\n\nvenv/lib/python3.7/site-packages/tensorflow/python/training/tracking/object_identity.py:112\nvenv/lib/python3.7/site-packages/tensorflow/python/training/tracking/object_identity.py:112\n  /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:25/venv/lib/python3.7/site-packages/tensorflow/python/training/tracking/object_identity.py:112: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n    class ObjectIdentitySet(collections.MutableSet):\n\nvenv/lib/python3.7/site-packages/tensorflow/python/training/tracking/data_structures.py:374\nvenv/lib/python3.7/site-packages/tensorflow/python/training/tracking/data_structures.py:374\n  /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:25/venv/lib/python3.7/site-packages/tensorflow/python/training/tracking/data_structures.py:374: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n    class _ListWrapper(List, collections.MutableSequence,\n\nvenv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541\nvenv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541\n  /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:25/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n    _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n\nvenv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542\nvenv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542\n  /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:25/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n    _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n\nvenv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543\nvenv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543\n  /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:25/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n    _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n\nvenv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544\nvenv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544\n  /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:25/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n    _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n\nvenv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545\nvenv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545\n  /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:25/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n    _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n\nvenv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550\nvenv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550\n  /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:25/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n    np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n\nkeras/callbacks.py:18\nkeras/callbacks.py:18\n  /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:25/keras/callbacks.py:18: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n    from collections import Iterable\n\n-- Docs: https://docs.pytest.org/en/latest/warnings.html\n================================================ slowest 20 test durations ================================================\n\n(0.00 durations hidden.  Use -vv to show these durations.)\n================================================= short test summary info =================================================\nFAILED tests/keras/applications/imagenet_utils_test.py::test_preprocess_input - numpy.core._exceptions.UFuncTypeError: C...\n============================================= 1 failed, 38 warnings in 3.67s ==============================================",
        "test_code_blocks": [
          {
            "filename": "tests/keras/applications/imagenet_utils_test.py",
            "test_code": "def test_preprocess_input():\n    # Test image batch with float and int image input\n    x = np.random.uniform(0, 255, (2, 10, 10, 3))\n    xint = x.astype('int32')\n    assert utils.preprocess_input(x).shape == x.shape\n    assert utils.preprocess_input(xint).shape == xint.shape\n\n    out1 = utils.preprocess_input(x, 'channels_last')\n    out1int = utils.preprocess_input(xint, 'channels_last')\n    out2 = utils.preprocess_input(np.transpose(x, (0, 3, 1, 2)),\n                                  'channels_first')\n    out2int = utils.preprocess_input(np.transpose(xint, (0, 3, 1, 2)),\n                                     'channels_first')\n    assert_allclose(out1, out2.transpose(0, 2, 3, 1))\n    assert_allclose(out1int, out2int.transpose(0, 2, 3, 1))\n\n    # Test single image\n    x = np.random.uniform(0, 255, (10, 10, 3))\n    xint = x.astype('int32')\n    assert utils.preprocess_input(x).shape == x.shape\n    assert utils.preprocess_input(xint).shape == xint.shape\n\n    out1 = utils.preprocess_input(x, 'channels_last')\n    out1int = utils.preprocess_input(xint, 'channels_last')\n    out2 = utils.preprocess_input(np.transpose(x, (2, 0, 1)),\n                                  'channels_first')\n    out2int = utils.preprocess_input(np.transpose(xint, (2, 0, 1)),\n                                     'channels_first')\n    assert_allclose(out1, out2.transpose(1, 2, 0))\n    assert_allclose(out1int, out2int.transpose(1, 2, 0))"
          }
        ],
        "raised_issue_descriptions": null
      }
    },
    {
      "id": 38,
      "buggy_code_blocks": [
        {
          "filename": "keras/layers/recurrent.py",
          "source_code": "    def build(self, input_shape):\n        for cell in self.cells:\n            if isinstance(cell, Layer):\n                cell.build(input_shape)\n            if hasattr(cell.state_size, '__len__'):\n                output_dim = cell.state_size[0]\n            else:\n                output_dim = cell.state_size\n            input_shape = (input_shape[0], input_shape[1], output_dim)\n        self.built = True"
        }
      ],
      "features": {
        "class_definition": null,
        "variable_definitions": null,
        "error_message": "=================================================== test session starts ===================================================\nplatform darwin -- Python 3.7.9, pytest-5.4.3, py-1.8.1, pluggy-0.13.1 -- /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:38/venv/bin/python3.7\ncachedir: .pytest_cache\nrootdir: /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:38, inifile: pytest.ini\nplugins: httpbin-1.0.0, timeout-2.1.0, cov-4.1.0, mock-3.11.1, flaky-3.6.1, forked-1.1.3, xdist-1.32.0\ntimeout: 60.0s\ntimeout method: signal\ntimeout func_only: False\n[gw0] darwin Python 3.7.9 cwd: /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:38\n[gw1] darwin Python 3.7.9 cwd: /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:38\n[gw0] Python 3.7.9 (v3.7.9:13c94747c7, Aug 15 2020, 01:31:08)  -- [Clang 6.0 (clang-600.0.57)]\n[gw1] Python 3.7.9 (v3.7.9:13c94747c7, Aug 15 2020, 01:31:08)  -- [Clang 6.0 (clang-600.0.57)]\ngw0 [1] / gw1 [1]\nscheduling tests via LoadScheduling\n\ntests/keras/layers/recurrent_test.py::test_minimal_rnn_cell_layer \n[gw0] [100%] FAILED tests/keras/layers/recurrent_test.py::test_minimal_rnn_cell_layer \n\n======================================================== FAILURES =========================================================\n_______________________________________________ test_minimal_rnn_cell_layer _______________________________________________\n[gw0] darwin -- Python 3.7.9 /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:38/venv/bin/python3.7\n\n    @keras_test\n    def test_minimal_rnn_cell_layer():\n    \n        class MinimalRNNCell(keras.layers.Layer):\n    \n            def __init__(self, units, **kwargs):\n                self.units = units\n                self.state_size = units\n                super(MinimalRNNCell, self).__init__(**kwargs)\n    \n            def build(self, input_shape):\n                # no time axis in the input shape passed to RNN cells\n                assert len(input_shape) == 2\n    \n                self.kernel = self.add_weight(shape=(input_shape[-1], self.units),\n                                              initializer='uniform',\n                                              name='kernel')\n                self.recurrent_kernel = self.add_weight(\n                    shape=(self.units, self.units),\n                    initializer='uniform',\n                    name='recurrent_kernel')\n                self.built = True\n    \n            def call(self, inputs, states):\n                prev_output = states[0]\n                h = keras.backend.dot(inputs, self.kernel)\n                output = h + keras.backend.dot(prev_output, self.recurrent_kernel)\n                return output, [output]\n    \n            def get_config(self):\n                config = {'units': self.units}\n                base_config = super(MinimalRNNCell, self).get_config()\n                return dict(list(base_config.items()) + list(config.items()))\n    \n        # Test basic case.\n        x = keras.Input((None, 5))\n        cell = MinimalRNNCell(32)\n        layer = recurrent.RNN(cell)\n        y = layer(x)\n        model = keras.models.Model(x, y)\n        model.compile(optimizer='rmsprop', loss='mse')\n        model.train_on_batch(np.zeros((6, 5, 5)), np.zeros((6, 32)))\n    \n        # Test basic case serialization.\n        x_np = np.random.random((6, 5, 5))\n        y_np = model.predict(x_np)\n        weights = model.get_weights()\n        config = layer.get_config()\n        with keras.utils.CustomObjectScope({'MinimalRNNCell': MinimalRNNCell}):\n            layer = recurrent.RNN.from_config(config)\n        y = layer(x)\n        model = keras.models.Model(x, y)\n        model.set_weights(weights)\n        y_np_2 = model.predict(x_np)\n        assert_allclose(y_np, y_np_2, atol=1e-4)\n    \n        # Test stacking.\n        cells = [MinimalRNNCell(8),\n                 MinimalRNNCell(12),\n                 MinimalRNNCell(32)]\n        layer = recurrent.RNN(cells)\n>       y = layer(x)\n\ntests/keras/layers/recurrent_test.py:570: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nkeras/layers/recurrent.py:488: in __call__\n    return super(RNN, self).__call__(inputs, **kwargs)\nkeras/engine/topology.py:590: in __call__\n    self.build(input_shapes[0])\nkeras/layers/recurrent.py:450: in build\n    self.cell.build(step_input_shape)\nkeras/layers/recurrent.py:104: in build\n    cell.build(input_shape)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <recurrent_test.test_minimal_rnn_cell_layer.<locals>.MinimalRNNCell object at 0x7fdc5c79d950>\ninput_shape = (None, 5, 8)\n\n    def build(self, input_shape):\n        # no time axis in the input shape passed to RNN cells\n>       assert len(input_shape) == 2\nE       assert 3 == 2\nE         +3\nE         -2\n\ntests/keras/layers/recurrent_test.py:521: AssertionError\n-------------------------------------------------- Captured stderr call ---------------------------------------------------\nWARNING:tensorflow:From /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:38/keras/backend/tensorflow_backend.py:504: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n\nWARNING:tensorflow:From /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:38/keras/backend/tensorflow_backend.py:3828: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n\nWARNING:tensorflow:From /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:38/keras/optimizers.py:744: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n\nWARNING:tensorflow:From /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:38/keras/backend/tensorflow_backend.py:973: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n\nWARNING:tensorflow:From /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:38/keras/backend/tensorflow_backend.py:960: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n\nWARNING:tensorflow:From /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:38/keras/backend/tensorflow_backend.py:2496: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n\nWARNING:tensorflow:From /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:38/keras/backend/tensorflow_backend.py:166: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n\nWARNING:tensorflow:From /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:38/keras/backend/tensorflow_backend.py:171: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n\n2023-09-29 17:04:04.802278: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n2023-09-29 17:04:04.814654: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdc5bf5beb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n2023-09-29 17:04:04.814695: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\nWARNING:tensorflow:From /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:38/keras/backend/tensorflow_backend.py:180: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n\nWARNING:tensorflow:From /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:38/keras/backend/tensorflow_backend.py:189: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n\nWARNING:tensorflow:From /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:38/keras/backend/tensorflow_backend.py:196: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n\n---------------------------------------------------- Captured log call ----------------------------------------------------\nWARNING  tensorflow:module_wrapper.py:139 From /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:38/keras/backend/tensorflow_backend.py:504: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n\nWARNING  tensorflow:module_wrapper.py:139 From /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:38/keras/backend/tensorflow_backend.py:3828: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n\nWARNING  tensorflow:module_wrapper.py:139 From /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:38/keras/optimizers.py:744: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n\nWARNING  tensorflow:module_wrapper.py:139 From /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:38/keras/backend/tensorflow_backend.py:973: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n\nWARNING  tensorflow:module_wrapper.py:139 From /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:38/keras/backend/tensorflow_backend.py:960: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n\nWARNING  tensorflow:module_wrapper.py:139 From /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:38/keras/backend/tensorflow_backend.py:2496: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n\nWARNING  tensorflow:module_wrapper.py:139 From /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:38/keras/backend/tensorflow_backend.py:166: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n\nWARNING  tensorflow:module_wrapper.py:139 From /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:38/keras/backend/tensorflow_backend.py:171: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n\nWARNING  tensorflow:module_wrapper.py:139 From /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:38/keras/backend/tensorflow_backend.py:180: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n\nWARNING  tensorflow:module_wrapper.py:139 From /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:38/keras/backend/tensorflow_backend.py:189: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n\nWARNING  tensorflow:module_wrapper.py:139 From /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:38/keras/backend/tensorflow_backend.py:196: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n==================================================== warnings summary =====================================================\nvenv/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py:15\nvenv/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py:15\n  /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:38/venv/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py:15: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n    import imp\n\nkeras/callbacks.py:18\nkeras/callbacks.py:18\n  /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:38/keras/callbacks.py:18: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n    from collections import Iterable\n\nvenv/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_util.py:521: 15 tests with warnings\n  /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:38/venv/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_util.py:521: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n    tensor_proto.tensor_content = nparray.tostring()\n\nvenv/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:339\n  /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:38/venv/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:339: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n    if not isinstance(values, collections.Sequence):\n\nvenv/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/learn_io/generator_io.py:26\n  /Users/jerry/Documents/GitHub/PyRepair/benchmarks/BugsInPy_Cloned_Repos/keras:38/venv/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/learn_io/generator_io.py:26: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n    from collections import Container\n\n-- Docs: https://docs.pytest.org/en/latest/warnings.html\n================================================ slowest 10 test durations ================================================\n0.46s call     tests/keras/layers/recurrent_test.py::test_minimal_rnn_cell_layer\n\n(0.00 durations hidden.  Use -vv to show these durations.)\n================================================= short test summary info =================================================\nFAILED tests/keras/layers/recurrent_test.py::test_minimal_rnn_cell_layer - assert 3 == 2\n============================================= 1 failed, 21 warnings in 7.23s ==============================================",
        "test_code_blocks": [
          {
            "filename": "tests/keras/layers/recurrent_test.py",
            "test_code": "        def build(self, input_shape):\n            # no time axis in the input shape passed to RNN cells\n            assert len(input_shape) == 2\n\n            self.kernel = self.add_weight(shape=(input_shape[-1], self.units),\n                                          initializer='uniform',\n                                          name='kernel')\n            self.recurrent_kernel = self.add_weight(\n                shape=(self.units, self.units),\n                initializer='uniform',\n                name='recurrent_kernel')\n            self.built = True"
          }
        ],
        "raised_issue_descriptions": null
      }
    }
  ]
}