{
    "keras:31": {
        "/Volumes/SSD2T/bgp_envs/repos/keras_31/keras/backend/tensorflow_backend.py": {
            "buggy_functions": [
                {
                    "function_name": "ctc_batch_cost",
                    "function_code": "def ctc_batch_cost(y_true, y_pred, input_length, label_length):\n    \"\"\"Runs CTC loss algorithm on each batch element.\n\n    # Arguments\n        y_true: tensor `(samples, max_string_length)`\n            containing the truth labels.\n        y_pred: tensor `(samples, time_steps, num_categories)`\n            containing the prediction, or output of the softmax.\n        input_length: tensor `(samples, 1)` containing the sequence length for\n            each batch item in `y_pred`.\n        label_length: tensor `(samples, 1)` containing the sequence length for\n            each batch item in `y_true`.\n\n    # Returns\n        Tensor with shape (samples,1) containing the\n            CTC loss of each element.\n    \"\"\"\n    label_length = tf.to_int32(tf.squeeze(label_length))\n    input_length = tf.to_int32(tf.squeeze(input_length))\n    sparse_labels = tf.to_int32(ctc_label_dense_to_sparse(y_true, label_length))\n\n    y_pred = tf.log(tf.transpose(y_pred, perm=[1, 0, 2]) + epsilon())\n\n    return tf.expand_dims(ctc.ctc_loss(inputs=y_pred,\n                                       labels=sparse_labels,\n                                       sequence_length=input_length), 1)\n",
                    "decorators": [],
                    "docstring": "Runs CTC loss algorithm on each batch element.\n\n# Arguments\n    y_true: tensor `(samples, max_string_length)`\n        containing the truth labels.\n    y_pred: tensor `(samples, time_steps, num_categories)`\n        containing the prediction, or output of the softmax.\n    input_length: tensor `(samples, 1)` containing the sequence length for\n        each batch item in `y_pred`.\n    label_length: tensor `(samples, 1)` containing the sequence length for\n        each batch item in `y_true`.\n\n# Returns\n    Tensor with shape (samples,1) containing the\n        CTC loss of each element.",
                    "start_line": 3928,
                    "end_line": 3953,
                    "variables": {
                        "label_length": [
                            3945,
                            3947
                        ],
                        "tf.to_int32": [
                            3945,
                            3946,
                            3947
                        ],
                        "tf": [
                            3945,
                            3946,
                            3947,
                            3949,
                            3951
                        ],
                        "tf.squeeze": [
                            3945,
                            3946
                        ],
                        "input_length": [
                            3953,
                            3946
                        ],
                        "sparse_labels": [
                            3952,
                            3947
                        ],
                        "ctc_label_dense_to_sparse": [
                            3947
                        ],
                        "y_true": [
                            3947
                        ],
                        "y_pred": [
                            3949,
                            3951
                        ],
                        "tf.log": [
                            3949
                        ],
                        "tf.transpose": [
                            3949
                        ],
                        "epsilon": [
                            3949
                        ],
                        "tf.expand_dims": [
                            3951
                        ],
                        "ctc.ctc_loss": [
                            3951
                        ],
                        "ctc": [
                            3951
                        ]
                    },
                    "filtered_variables": {
                        "label_length": [
                            3945,
                            3947
                        ],
                        "tf.to_int32": [
                            3945,
                            3946,
                            3947
                        ],
                        "tf": [
                            3945,
                            3946,
                            3947,
                            3949,
                            3951
                        ],
                        "tf.squeeze": [
                            3945,
                            3946
                        ],
                        "input_length": [
                            3953,
                            3946
                        ],
                        "sparse_labels": [
                            3952,
                            3947
                        ],
                        "ctc_label_dense_to_sparse": [
                            3947
                        ],
                        "y_true": [
                            3947
                        ],
                        "y_pred": [
                            3949,
                            3951
                        ],
                        "tf.log": [
                            3949
                        ],
                        "tf.transpose": [
                            3949
                        ],
                        "epsilon": [
                            3949
                        ],
                        "tf.expand_dims": [
                            3951
                        ],
                        "ctc.ctc_loss": [
                            3951
                        ],
                        "ctc": [
                            3951
                        ]
                    },
                    "diff_line_number": 3945,
                    "class_data": null,
                    "variable_values": [
                        [
                            {
                                "label_length": {
                                    "variable_value": "<tf.Variable 'Variable_3:0' shape=(2, 1) dtype=int32_ref>",
                                    "variable_type": "RefVariable",
                                    "variable_shape": "TensorShape([Dimension(2), Dimension(1)])"
                                },
                                "tf.to_int32": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "tf": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "tf.squeeze": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "input_length": {
                                    "variable_value": "<tf.Variable 'Variable_2:0' shape=(2, 1) dtype=int32_ref>",
                                    "variable_type": "RefVariable",
                                    "variable_shape": "TensorShape([Dimension(2), Dimension(1)])"
                                },
                                "sparse_labels": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "ctc_label_dense_to_sparse": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "y_true": {
                                    "variable_value": "<tf.Variable 'Variable:0' shape=(2, 5) dtype=int32_ref>",
                                    "variable_type": "RefVariable",
                                    "variable_shape": "TensorShape([Dimension(2), Dimension(5)])"
                                },
                                "y_pred": {
                                    "variable_value": "<tf.Variable 'Variable_1:0' shape=(2, 5, 6) dtype=float32_ref>",
                                    "variable_type": "RefVariable",
                                    "variable_shape": "TensorShape([Dimension(2), Dimension(5), Dimension(6)])"
                                },
                                "tf.log": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "tf.transpose": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "epsilon": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "tf.expand_dims": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "ctc.ctc_loss": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "ctc": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                }
                            },
                            {
                                "label_length": {
                                    "variable_value": "<tf.Tensor 'Squeeze:0' shape=(2,) dtype=int32>",
                                    "variable_type": "Tensor",
                                    "variable_shape": "TensorShape([Dimension(2)])"
                                },
                                "tf.to_int32": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "tf": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "tf.squeeze": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "input_length": {
                                    "variable_value": "<tf.Tensor 'Squeeze_1:0' shape=(2,) dtype=int32>",
                                    "variable_type": "Tensor",
                                    "variable_shape": "TensorShape([Dimension(2)])"
                                },
                                "sparse_labels": {
                                    "variable_value": "<tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x129198cd0>",
                                    "variable_type": "SparseTensor",
                                    "variable_shape": "TensorShape([Dimension(2), Dimension(5)])"
                                },
                                "ctc_label_dense_to_sparse": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "y_true": {
                                    "variable_value": "<tf.Variable 'Variable:0' shape=(2, 5) dtype=int32_ref>",
                                    "variable_type": "RefVariable",
                                    "variable_shape": "TensorShape([Dimension(2), Dimension(5)])"
                                },
                                "y_pred": {
                                    "variable_value": "<tf.Tensor 'Log:0' shape=(5, 2, 6) dtype=float32>",
                                    "variable_type": "Tensor",
                                    "variable_shape": "TensorShape([Dimension(5), Dimension(2), Dimension(6)])"
                                },
                                "tf.log": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "tf.transpose": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "epsilon": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "tf.expand_dims": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "ctc.ctc_loss": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "ctc": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                }
                            }
                        ]
                    ],
                    "angelic_variable_values": [
                        [
                            {
                                "label_length": {
                                    "variable_value": "<tf.Variable 'Variable_3:0' shape=(2, 1) dtype=int32_ref>",
                                    "variable_type": "RefVariable",
                                    "variable_shape": "TensorShape([Dimension(2), Dimension(1)])"
                                },
                                "tf.to_int32": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "tf": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "tf.squeeze": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "input_length": {
                                    "variable_value": "<tf.Variable 'Variable_2:0' shape=(2, 1) dtype=int32_ref>",
                                    "variable_type": "RefVariable",
                                    "variable_shape": "TensorShape([Dimension(2), Dimension(1)])"
                                },
                                "sparse_labels": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "ctc_label_dense_to_sparse": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "y_true": {
                                    "variable_value": "<tf.Variable 'Variable:0' shape=(2, 5) dtype=int32_ref>",
                                    "variable_type": "RefVariable",
                                    "variable_shape": "TensorShape([Dimension(2), Dimension(5)])"
                                },
                                "y_pred": {
                                    "variable_value": "<tf.Variable 'Variable_1:0' shape=(2, 5, 6) dtype=float32_ref>",
                                    "variable_type": "RefVariable",
                                    "variable_shape": "TensorShape([Dimension(2), Dimension(5), Dimension(6)])"
                                },
                                "tf.log": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "tf.transpose": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "epsilon": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "tf.expand_dims": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "ctc.ctc_loss": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "ctc": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                }
                            },
                            {
                                "label_length": {
                                    "variable_value": "<tf.Tensor 'Squeeze:0' shape=(2,) dtype=int32>",
                                    "variable_type": "Tensor",
                                    "variable_shape": "TensorShape([Dimension(2)])"
                                },
                                "tf.to_int32": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "tf": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "tf.squeeze": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "input_length": {
                                    "variable_value": "<tf.Tensor 'Squeeze_1:0' shape=(2,) dtype=int32>",
                                    "variable_type": "Tensor",
                                    "variable_shape": "TensorShape([Dimension(2)])"
                                },
                                "sparse_labels": {
                                    "variable_value": "<tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x123847690>",
                                    "variable_type": "SparseTensor",
                                    "variable_shape": "TensorShape([Dimension(2), Dimension(5)])"
                                },
                                "ctc_label_dense_to_sparse": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "y_true": {
                                    "variable_value": "<tf.Variable 'Variable:0' shape=(2, 5) dtype=int32_ref>",
                                    "variable_type": "RefVariable",
                                    "variable_shape": "TensorShape([Dimension(2), Dimension(5)])"
                                },
                                "y_pred": {
                                    "variable_value": "<tf.Tensor 'Log:0' shape=(5, 2, 6) dtype=float32>",
                                    "variable_type": "Tensor",
                                    "variable_shape": "TensorShape([Dimension(5), Dimension(2), Dimension(6)])"
                                },
                                "tf.log": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "tf.transpose": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "epsilon": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "tf.expand_dims": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "ctc.ctc_loss": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "ctc": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                }
                            }
                        ],
                        [
                            {
                                "label_length": {
                                    "variable_value": "<tf.Variable 'Variable_7:0' shape=(1, 1) dtype=int32_ref>",
                                    "variable_type": "RefVariable",
                                    "variable_shape": "TensorShape([Dimension(1), Dimension(1)])"
                                },
                                "tf.to_int32": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "tf": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "tf.squeeze": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "input_length": {
                                    "variable_value": "<tf.Variable 'Variable_6:0' shape=(1, 1) dtype=int32_ref>",
                                    "variable_type": "RefVariable",
                                    "variable_shape": "TensorShape([Dimension(1), Dimension(1)])"
                                },
                                "sparse_labels": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "ctc_label_dense_to_sparse": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "y_true": {
                                    "variable_value": "<tf.Variable 'Variable_4:0' shape=(1, 5) dtype=int32_ref>",
                                    "variable_type": "RefVariable",
                                    "variable_shape": "TensorShape([Dimension(1), Dimension(5)])"
                                },
                                "y_pred": {
                                    "variable_value": "<tf.Variable 'Variable_5:0' shape=(1, 5, 6) dtype=float32_ref>",
                                    "variable_type": "RefVariable",
                                    "variable_shape": "TensorShape([Dimension(1), Dimension(5), Dimension(6)])"
                                },
                                "tf.log": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "tf.transpose": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "epsilon": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "tf.expand_dims": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "ctc.ctc_loss": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "ctc": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                }
                            },
                            {
                                "label_length": {
                                    "variable_value": "<tf.Tensor 'Squeeze_2:0' shape=(1,) dtype=int32>",
                                    "variable_type": "Tensor",
                                    "variable_shape": "TensorShape([Dimension(1)])"
                                },
                                "tf.to_int32": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "tf": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "tf.squeeze": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "input_length": {
                                    "variable_value": "<tf.Tensor 'Squeeze_3:0' shape=(1,) dtype=int32>",
                                    "variable_type": "Tensor",
                                    "variable_shape": "TensorShape([Dimension(1)])"
                                },
                                "sparse_labels": {
                                    "variable_value": "<tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x123a60590>",
                                    "variable_type": "SparseTensor",
                                    "variable_shape": "TensorShape([Dimension(1), Dimension(5)])"
                                },
                                "ctc_label_dense_to_sparse": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "y_true": {
                                    "variable_value": "<tf.Variable 'Variable_4:0' shape=(1, 5) dtype=int32_ref>",
                                    "variable_type": "RefVariable",
                                    "variable_shape": "TensorShape([Dimension(1), Dimension(5)])"
                                },
                                "y_pred": {
                                    "variable_value": "<tf.Tensor 'Log_1:0' shape=(5, 1, 6) dtype=float32>",
                                    "variable_type": "Tensor",
                                    "variable_shape": "TensorShape([Dimension(5), Dimension(1), Dimension(6)])"
                                },
                                "tf.log": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "tf.transpose": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "epsilon": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "tf.expand_dims": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "ctc.ctc_loss": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "ctc": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                }
                            }
                        ]
                    ]
                }
            ],
            "inscope_functions": [
                "def get_uid(prefix=''):\n    \"\"\"Get the uid for the default graph.\n\n    # Arguments\n        prefix: An optional prefix of the graph.\n\n    # Returns\n        A unique identifier for the graph.\n    \"\"\"\n    global _GRAPH_UID_DICTS\n    graph = tf.get_default_graph()\n    if graph not in _GRAPH_UID_DICTS:\n        _GRAPH_UID_DICTS[graph] = defaultdict(int)\n    _GRAPH_UID_DICTS[graph][prefix] += 1\n    return _GRAPH_UID_DICTS[graph][prefix]",
                "def reset_uids():\n    \"\"\"Resets graph identifiers.\n    \"\"\"\n    global _GRAPH_UID_DICTS\n    _GRAPH_UID_DICTS = {}",
                "def clear_session():\n    \"\"\"Destroys the current TF graph and creates a new one.\n\n    Useful to avoid clutter from old models / layers.\n    \"\"\"\n    global _SESSION\n    global _GRAPH_LEARNING_PHASES\n    tf.reset_default_graph()\n    reset_uids()\n    _SESSION = None\n    phase = tf.placeholder_with_default(False,\n                                        shape=(),\n                                        name='keras_learning_phase')\n    _GRAPH_LEARNING_PHASES = {}\n    _GRAPH_LEARNING_PHASES[tf.get_default_graph()] = phase",
                "def manual_variable_initialization(value):\n    \"\"\"Sets the manual variable initialization flag.\n\n    This boolean flag determines whether\n    variables should be initialized\n    as they are instantiated (default), or if\n    the user should handle the initialization\n    (e.g. via `tf.initialize_all_variables()`).\n\n    # Arguments\n        value: Python boolean.\n    \"\"\"\n    global _MANUAL_VAR_INIT\n    _MANUAL_VAR_INIT = value",
                "def learning_phase():\n    \"\"\"Returns the learning phase flag.\n\n    The learning phase flag is a bool tensor (0 = test, 1 = train)\n    to be passed as input to any Keras function\n    that uses a different behavior at train time and test time.\n\n    # Returns\n        Learning phase (scalar integer tensor or Python integer).\n    \"\"\"\n    graph = tf.get_default_graph()\n    if graph not in _GRAPH_LEARNING_PHASES:\n        phase = tf.placeholder_with_default(False,\n                                            shape=(),\n                                            name='keras_learning_phase')\n        _GRAPH_LEARNING_PHASES[graph] = phase\n    return _GRAPH_LEARNING_PHASES[graph]",
                "def set_learning_phase(value):\n    \"\"\"Sets the learning phase to a fixed value.\n\n    # Arguments\n        value: Learning phase value, either 0 or 1 (integers).\n\n    # Raises\n        ValueError: if `value` is neither `0` nor `1`.\n    \"\"\"\n    global _GRAPH_LEARNING_PHASES\n    if value not in {0, 1}:\n        raise ValueError('Expected learning phase to be '\n                         '0 or 1.')\n    _GRAPH_LEARNING_PHASES[tf.get_default_graph()] = value",
                "def get_session():\n    \"\"\"Returns the TF session to be used by the backend.\n\n    If a default TensorFlow session is available, we will return it.\n\n    Else, we will return the global Keras session.\n\n    If no global Keras session exists at this point:\n    we will create a new global session.\n\n    Note that you can manually set the global session\n    via `K.set_session(sess)`.\n\n    # Returns\n        A TensorFlow session.\n    \"\"\"\n    global _SESSION\n\n    default_session = tf.get_default_session()\n\n    if default_session is not None:\n        session = default_session\n    else:\n        if _SESSION is None:\n            if not os.environ.get('OMP_NUM_THREADS'):\n                config = tf.ConfigProto(allow_soft_placement=True)\n            else:\n                num_thread = int(os.environ.get('OMP_NUM_THREADS'))\n                config = tf.ConfigProto(intra_op_parallelism_threads=num_thread,\n                                        allow_soft_placement=True)\n            _SESSION = tf.Session(config=config)\n        session = _SESSION\n    if not _MANUAL_VAR_INIT:\n        with session.graph.as_default():\n            variables = tf.global_variables()\n            candidate_vars = []\n            for v in variables:\n                if not getattr(v, '_keras_initialized', False):\n                    candidate_vars.append(v)\n            if candidate_vars:\n                # This step is expensive, so we only run it on variables\n                # not already marked as initialized.\n                is_initialized = session.run(\n                    [tf.is_variable_initialized(v) for v in candidate_vars])\n                uninitialized_vars = []\n                for flag, v in zip(is_initialized, candidate_vars):\n                    if not flag:\n                        uninitialized_vars.append(v)\n                    v._keras_initialized = True\n                if uninitialized_vars:\n                    session.run(tf.variables_initializer(uninitialized_vars))\n    # hack for list_devices() function.\n    # list_devices() function is not available under tensorflow r1.3.\n    if not hasattr(session, 'list_devices'):\n        session.list_devices = lambda: device_lib.list_local_devices()\n    return session",
                "def set_session(session):\n    \"\"\"Sets the global TensorFlow session.\n\n    # Arguments\n        session: A TF Session.\n    \"\"\"\n    global _SESSION\n    _SESSION = session",
                "def _get_current_tf_device():\n    \"\"\"Return explicit device of current context, otherwise returns `None`.\n\n    # Returns\n        If the current device scope is explicitly set, it returns a string with\n        the device (`CPU` or `GPU`). If the scope is not explicitly set, it will\n        return `None`.\n    \"\"\"\n    g = tf.get_default_graph()\n    op = _TfDeviceCaptureOp()\n    g._apply_device_functions(op)\n    return op.device",
                "def _is_current_explicit_device(device_type):\n    \"\"\"Check if the current device is explicitly set on the device type specified.\n\n    # Arguments\n        device_type: A string containing `GPU` or `CPU` (case-insensitive).\n\n    # Returns\n        A boolean indicating if the current device scope is explicitly set on the device type.\n\n    # Raises\n        ValueError: If the `device_type` string indicates an unsupported device.\n    \"\"\"\n    device_type = device_type.upper()\n    if device_type not in ['CPU', 'GPU']:\n        raise ValueError('`device_type` should be either \"CPU\" or \"GPU\".')\n    device = _get_current_tf_device()\n    return (device is not None and device.device_type == device_type.upper())",
                "def _get_available_gpus():\n    \"\"\"Get a list of available gpu devices (formatted as strings).\n\n    # Returns\n        A list of available GPU devices.\n    \"\"\"\n    global _LOCAL_DEVICES\n    if _LOCAL_DEVICES is None:\n        _LOCAL_DEVICES = get_session().list_devices()\n    return [x.name for x in _LOCAL_DEVICES if x.device_type == 'GPU']",
                "def _has_nchw_support():\n    \"\"\"Check whether the current scope supports NCHW ops.\n\n    TensorFlow does not support NCHW on CPU. Therefore we check if we are not explicitly put on\n    CPU, and have GPUs available. In this case there will be soft-placing on the GPU device.\n\n    # Returns\n        bool: if the current scope device placement would support nchw\n    \"\"\"\n    explicitly_on_cpu = _is_current_explicit_device('CPU')\n    gpus_available = len(_get_available_gpus()) > 0\n    return (not explicitly_on_cpu and gpus_available)",
                "def _to_tensor(x, dtype):\n    \"\"\"Convert the input `x` to a tensor of type `dtype`.\n\n    # Arguments\n        x: An object to be converted (numpy array, list, tensors).\n        dtype: The destination type.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.convert_to_tensor(x, dtype=dtype)",
                "def is_sparse(tensor):\n    \"\"\"Returns whether a tensor is a sparse tensor.\n\n    # Arguments\n        tensor: A tensor instance.\n\n    # Returns\n        A boolean.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> a = K.placeholder((2, 2), sparse=False)\n        >>> print(K.is_sparse(a))\n        False\n        >>> b = K.placeholder((2, 2), sparse=True)\n        >>> print(K.is_sparse(b))\n        True\n    ```\n    \"\"\"\n    return isinstance(tensor, tf.SparseTensor)",
                "def to_dense(tensor):\n    \"\"\"Converts a sparse tensor into a dense tensor and returns it.\n\n    # Arguments\n        tensor: A tensor instance (potentially sparse).\n\n    # Returns\n        A dense tensor.\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> b = K.placeholder((2, 2), sparse=True)\n        >>> print(K.is_sparse(b))\n        True\n        >>> c = K.to_dense(b)\n        >>> print(K.is_sparse(c))\n        False\n    ```\n    \"\"\"\n    if is_sparse(tensor):\n        return tf.sparse_tensor_to_dense(tensor)\n    else:\n        return tensor",
                "def variable(value, dtype=None, name=None, constraint=None):\n    \"\"\"Instantiates a variable and returns it.\n\n    # Arguments\n        value: Numpy array, initial value of the tensor.\n        dtype: Tensor type.\n        name: Optional name string for the tensor.\n        constraint: Optional projection function to be\n            applied to the variable after an optimizer update.\n\n    # Returns\n        A variable instance (with Keras metadata included).\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> val = np.array([[1, 2], [3, 4]])\n        >>> kvar = K.variable(value=val, dtype='float64', name='example_var')\n        >>> K.dtype(kvar)\n        'float64'\n        >>> print(kvar)\n        example_var\n        >>> K.eval(kvar)\n        array([[ 1.,  2.],\n               [ 3.,  4.]])\n    ```\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    if hasattr(value, 'tocoo'):\n        sparse_coo = value.tocoo()\n        indices = np.concatenate((np.expand_dims(sparse_coo.row, 1),\n                                  np.expand_dims(sparse_coo.col, 1)), 1)\n        v = tf.SparseTensor(indices=indices,\n                            values=sparse_coo.data,\n                            dense_shape=sparse_coo.shape)\n        v._keras_shape = sparse_coo.shape\n        v._uses_learning_phase = False\n        return v\n    v = tf.Variable(value, dtype=tf.as_dtype(dtype), name=name)\n    if isinstance(value, np.ndarray):\n        v._keras_shape = value.shape\n    elif hasattr(value, 'get_shape'):\n        v._keras_shape = int_shape(value)\n    v._uses_learning_phase = False\n    # TODO: move to Variable constructor when supported in public release.\n    try:\n        v.constraint = constraint\n    except AttributeError:\n        v._constraint = constraint\n    return v",
                "def constant(value, dtype=None, shape=None, name=None):\n    \"\"\"Creates a constant tensor.\n\n    # Arguments\n        value: A constant value (or list)\n        dtype: The type of the elements of the resulting tensor.\n        shape: Optional dimensions of resulting tensor.\n        name: Optional name for the tensor.\n\n    # Returns\n        A Constant Tensor.\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    return tf.constant(value, dtype=dtype, shape=shape, name=name)",
                "def is_keras_tensor(x):\n    \"\"\"Returns whether `x` is a Keras tensor.\n\n    A \"Keras tensor\" is a tensor that was returned by a Keras layer,\n    (`Layer` class) or by `Input`.\n\n    # Arguments\n        x: A candidate tensor.\n\n    # Returns\n        A boolean: Whether the argument is a Keras tensor.\n\n    # Raises\n        ValueError: In case `x` is not a symbolic tensor.\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> from keras.layers import Input, Dense\n        >>> np_var = numpy.array([1, 2])\n        >>> K.is_keras_tensor(np_var) # A numpy array is not a symbolic tensor.\n        ValueError\n        >>> k_var = tf.placeholder('float32', shape=(1,1))\n        >>> K.is_keras_tensor(k_var) # A variable indirectly created outside of keras is not a Keras tensor.\n        False\n        >>> keras_var = K.variable(np_var)\n        >>> K.is_keras_tensor(keras_var)  # A variable created with the keras backend is not a Keras tensor.\n        False\n        >>> keras_placeholder = K.placeholder(shape=(2, 4, 5))\n        >>> K.is_keras_tensor(keras_placeholder)  # A placeholder is not a Keras tensor.\n        False\n        >>> keras_input = Input([10])\n        >>> K.is_keras_tensor(keras_input) # An Input is a Keras tensor.\n        True\n        >>> keras_layer_output = Dense(10)(keras_input)\n        >>> K.is_keras_tensor(keras_layer_output) # Any Keras layer output is a Keras tensor.\n        True\n    ```\n    \"\"\"\n    if not isinstance(x, (tf.Tensor,\n                          tf_variables.Variable,\n                          tf.SparseTensor)):\n        raise ValueError('Unexpectedly found an instance of type `' + str(type(x)) + '`. '\n                         'Expected a symbolic tensor instance.')\n    return hasattr(x, '_keras_history')",
                "def placeholder(shape=None, ndim=None, dtype=None, sparse=False, name=None):\n    \"\"\"Instantiates a placeholder tensor and returns it.\n\n    # Arguments\n        shape: Shape of the placeholder\n            (integer tuple, may include `None` entries).\n        ndim: Number of axes of the tensor.\n            At least one of {`shape`, `ndim`} must be specified.\n            If both are specified, `shape` is used.\n        dtype: Placeholder type.\n        sparse: Boolean, whether the placeholder should have a sparse type.\n        name: Optional name string for the placeholder.\n\n    # Returns\n        Tensor instance (with Keras metadata included).\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> input_ph = K.placeholder(shape=(2, 4, 5))\n        >>> input_ph._keras_shape\n        (2, 4, 5)\n        >>> input_ph\n        <tf.Tensor 'Placeholder_4:0' shape=(2, 4, 5) dtype=float32>\n    ```\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    if not shape:\n        if ndim:\n            shape = tuple([None for _ in range(ndim)])\n    if sparse:\n        x = tf.sparse_placeholder(dtype, shape=shape, name=name)\n    else:\n        x = tf.placeholder(dtype, shape=shape, name=name)\n    x._keras_shape = shape\n    x._uses_learning_phase = False\n    return x",
                "def is_placeholder(x):\n    \"\"\"Returns whether `x` is a placeholder.\n\n    # Arguments\n        x: A candidate placeholder.\n\n    # Returns\n        Boolean.\n    \"\"\"\n    try:\n        return x.op.type == 'Placeholder'\n    except AttributeError:\n        return False",
                "def shape(x):\n    \"\"\"Returns the symbolic shape of a tensor or variable.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A symbolic shape (which is itself a tensor).\n\n    # Examples\n    ```python\n        # TensorFlow example\n        >>> from keras import backend as K\n        >>> tf_session = K.get_session()\n        >>> val = np.array([[1, 2], [3, 4]])\n        >>> kvar = K.variable(value=val)\n        >>> inputs = keras.backend.placeholder(shape=(2, 4, 5))\n        >>> K.shape(kvar)\n        <tf.Tensor 'Shape_8:0' shape=(2,) dtype=int32>\n        >>> K.shape(inputs)\n        <tf.Tensor 'Shape_9:0' shape=(3,) dtype=int32>\n        # To get integer shape (Instead, you can use K.int_shape(x))\n        >>> K.shape(kvar).eval(session=tf_session)\n        array([2, 2], dtype=int32)\n        >>> K.shape(inputs).eval(session=tf_session)\n        array([2, 4, 5], dtype=int32)\n    ```\n    \"\"\"\n    return tf.shape(x)",
                "def int_shape(x):\n    \"\"\"Returns the shape of tensor or variable as a tuple of int or None entries.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tuple of integers (or None entries).\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> inputs = K.placeholder(shape=(2, 4, 5))\n        >>> K.int_shape(inputs)\n        (2, 4, 5)\n        >>> val = np.array([[1, 2], [3, 4]])\n        >>> kvar = K.variable(value=val)\n        >>> K.int_shape(kvar)\n        (2, 2)\n    ```\n    \"\"\"\n    if hasattr(x, '_keras_shape'):\n        return x._keras_shape\n    try:\n        return tuple(x.get_shape().as_list())\n    except ValueError:\n        return None",
                "def ndim(x):\n    \"\"\"Returns the number of axes in a tensor, as an integer.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        Integer (scalar), number of axes.\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> inputs = K.placeholder(shape=(2, 4, 5))\n        >>> val = np.array([[1, 2], [3, 4]])\n        >>> kvar = K.variable(value=val)\n        >>> K.ndim(inputs)\n        3\n        >>> K.ndim(kvar)\n        2\n    ```\n    \"\"\"\n    dims = x.get_shape()._dims\n    if dims is not None:\n        return len(dims)\n    return None",
                "def dtype(x):\n    \"\"\"Returns the dtype of a Keras tensor or variable, as a string.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        String, dtype of `x`.\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> K.dtype(K.placeholder(shape=(2,4,5)))\n        'float32'\n        >>> K.dtype(K.placeholder(shape=(2,4,5), dtype='float32'))\n        'float32'\n        >>> K.dtype(K.placeholder(shape=(2,4,5), dtype='float64'))\n        'float64'\n        # Keras variable\n        >>> kvar = K.variable(np.array([[1, 2], [3, 4]]))\n        >>> K.dtype(kvar)\n        'float32_ref'\n        >>> kvar = K.variable(np.array([[1, 2], [3, 4]]), dtype='float32')\n        >>> K.dtype(kvar)\n        'float32_ref'\n    ```\n    \"\"\"\n    return x.dtype.base_dtype.name",
                "def eval(x):\n    \"\"\"Evaluates the value of a variable.\n\n    # Arguments\n        x: A variable.\n\n    # Returns\n        A Numpy array.\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> kvar = K.variable(np.array([[1, 2], [3, 4]]), dtype='float32')\n        >>> K.eval(kvar)\n        array([[ 1.,  2.],\n               [ 3.,  4.]], dtype=float32)\n    ```\n    \"\"\"\n    return to_dense(x).eval(session=get_session())",
                "def zeros(shape, dtype=None, name=None):\n    \"\"\"Instantiates an all-zeros variable and returns it.\n\n    # Arguments\n        shape: Tuple of integers, shape of returned Keras variable\n        dtype: String, data type of returned Keras variable\n        name: String, name of returned Keras variable\n\n    # Returns\n        A variable (including Keras metadata), filled with `0.0`.\n        Note that if `shape` was symbolic, we cannot return a variable,\n        and will return a dynamically-shaped tensor instead.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> kvar = K.zeros((3,4))\n        >>> K.eval(kvar)\n        array([[ 0.,  0.,  0.,  0.],\n               [ 0.,  0.,  0.,  0.],\n               [ 0.,  0.,  0.,  0.]], dtype=float32)\n    ```\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    tf_dtype = tf.as_dtype(dtype)\n    v = tf.zeros(shape=shape, dtype=tf_dtype, name=name)\n    if py_all(v.get_shape().as_list()):\n        return variable(v, dtype=dtype, name=name)\n    return v",
                "def ones(shape, dtype=None, name=None):\n    \"\"\"Instantiates an all-ones variable and returns it.\n\n    # Arguments\n        shape: Tuple of integers, shape of returned Keras variable.\n        dtype: String, data type of returned Keras variable.\n        name: String, name of returned Keras variable.\n\n    # Returns\n        A Keras variable, filled with `1.0`.\n        Note that if `shape` was symbolic, we cannot return a variable,\n        and will return a dynamically-shaped tensor instead.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> kvar = K.ones((3,4))\n        >>> K.eval(kvar)\n        array([[ 1.,  1.,  1.,  1.],\n               [ 1.,  1.,  1.,  1.],\n               [ 1.,  1.,  1.,  1.]], dtype=float32)\n    ```\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    tf_dtype = tf.as_dtype(dtype)\n    v = tf.ones(shape=shape, dtype=tf_dtype, name=name)\n    if py_all(v.get_shape().as_list()):\n        return variable(v, dtype=dtype, name=name)\n    return v",
                "def eye(size, dtype=None, name=None):\n    \"\"\"Instantiate an identity matrix and returns it.\n\n    # Arguments\n        size: Integer, number of rows/columns.\n        dtype: String, data type of returned Keras variable.\n        name: String, name of returned Keras variable.\n\n    # Returns\n        A Keras variable, an identity matrix.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> kvar = K.eye(3)\n        >>> K.eval(kvar)\n        array([[ 1.,  0.,  0.],\n               [ 0.,  1.,  0.],\n               [ 0.,  0.,  1.]], dtype=float32)\n    ```\n\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    tf_dtype = tf.as_dtype(dtype)\n    return variable(tf.eye(size, dtype=tf_dtype), dtype, name)",
                "def zeros_like(x, dtype=None, name=None):\n    \"\"\"Instantiates an all-zeros variable of the same shape as another tensor.\n\n    # Arguments\n        x: Keras variable or Keras tensor.\n        dtype: String, dtype of returned Keras variable.\n             None uses the dtype of x.\n        name: String, name for the variable to create.\n\n    # Returns\n        A Keras variable with the shape of x filled with zeros.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> kvar = K.variable(np.random.random((2,3)))\n        >>> kvar_zeros = K.zeros_like(kvar)\n        >>> K.eval(kvar_zeros)\n        array([[ 0.,  0.,  0.],\n               [ 0.,  0.,  0.]], dtype=float32)\n    ```\n    \"\"\"\n    return tf.zeros_like(x, dtype=dtype, name=name)",
                "def ones_like(x, dtype=None, name=None):\n    \"\"\"Instantiates an all-ones variable of the same shape as another tensor.\n\n    # Arguments\n        x: Keras variable or tensor.\n        dtype: String, dtype of returned Keras variable.\n             None uses the dtype of x.\n        name: String, name for the variable to create.\n\n    # Returns\n        A Keras variable with the shape of x filled with ones.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> kvar = K.variable(np.random.random((2,3)))\n        >>> kvar_ones = K.ones_like(kvar)\n        >>> K.eval(kvar_ones)\n        array([[ 1.,  1.,  1.],\n               [ 1.,  1.,  1.]], dtype=float32)\n    ```\n    \"\"\"\n    return tf.ones_like(x, dtype=dtype, name=name)",
                "def identity(x, name=None):\n    \"\"\"Returns a tensor with the same content as the input tensor.\n\n    # Arguments\n        x: The input tensor.\n        name: String, name for the variable to create.\n\n    # Returns\n        A tensor of the same shape, type and content.\n    \"\"\"\n    return tf.identity(x, name)",
                "def random_uniform_variable(shape, low, high, dtype=None,\n                            name=None, seed=None):\n    \"\"\"Instantiates a variable with values drawn from a uniform distribution.\n\n    # Arguments\n        shape: Tuple of integers, shape of returned Keras variable.\n        low: Float, lower boundary of the output interval.\n        high: Float, upper boundary of the output interval.\n        dtype: String, dtype of returned Keras variable.\n        name: String, name of returned Keras variable.\n        seed: Integer, random seed.\n\n    # Returns\n        A Keras variable, filled with drawn samples.\n\n    # Example\n    ```python\n        # TensorFlow example\n        >>> kvar = K.random_uniform_variable((2,3), 0, 1)\n        >>> kvar\n        <tensorflow.python.ops.variables.Variable object at 0x10ab40b10>\n        >>> K.eval(kvar)\n        array([[ 0.10940075,  0.10047495,  0.476143  ],\n               [ 0.66137183,  0.00869417,  0.89220798]], dtype=float32)\n    ```\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    tf_dtype = tf.as_dtype(dtype)\n    if seed is None:\n        # ensure that randomness is conditioned by the Numpy RNG\n        seed = np.random.randint(10e8)\n    value = tf.random_uniform_initializer(\n        low, high, dtype=tf_dtype, seed=seed)(shape)\n    return variable(value, dtype=dtype, name=name)",
                "def random_normal_variable(shape, mean, scale, dtype=None,\n                           name=None, seed=None):\n    \"\"\"Instantiates a variable with values drawn from a normal distribution.\n\n    # Arguments\n        shape: Tuple of integers, shape of returned Keras variable.\n        mean: Float, mean of the normal distribution.\n        scale: Float, standard deviation of the normal distribution.\n        dtype: String, dtype of returned Keras variable.\n        name: String, name of returned Keras variable.\n        seed: Integer, random seed.\n\n    # Returns\n        A Keras variable, filled with drawn samples.\n\n    # Example\n    ```python\n        # TensorFlow example\n        >>> kvar = K.random_normal_variable((2,3), 0, 1)\n        >>> kvar\n        <tensorflow.python.ops.variables.Variable object at 0x10ab12dd0>\n        >>> K.eval(kvar)\n        array([[ 1.19591331,  0.68685907, -0.63814116],\n               [ 0.92629528,  0.28055015,  1.70484698]], dtype=float32)\n    ```\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    tf_dtype = tf.as_dtype(dtype)\n    if seed is None:\n        # ensure that randomness is conditioned by the Numpy RNG\n        seed = np.random.randint(10e8)\n    value = tf.random_normal_initializer(\n        mean, scale, dtype=tf_dtype, seed=seed)(shape)\n    return variable(value, dtype=dtype, name=name)",
                "def count_params(x):\n    \"\"\"Returns the static number of elements in a Keras variable or tensor.\n\n    # Arguments\n        x: Keras variable or tensor.\n\n    # Returns\n        Integer, the number of elements in `x`, i.e., the product of the\n        array's static dimensions.\n\n    # Example\n    ```python\n        >>> kvar = K.zeros((2,3))\n        >>> K.count_params(kvar)\n        6\n        >>> K.eval(kvar)\n        array([[ 0.,  0.,  0.],\n               [ 0.,  0.,  0.]], dtype=float32)\n    ```\n    \"\"\"\n    return np.prod(int_shape(x))",
                "def cast(x, dtype):\n    \"\"\"Casts a tensor to a different dtype and returns it.\n\n    You can cast a Keras variable but it still returns a Keras tensor.\n\n    # Arguments\n        x: Keras tensor (or variable).\n        dtype: String, either (`'float16'`, `'float32'`, or `'float64'`).\n\n    # Returns\n        Keras tensor with dtype `dtype`.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> input = K.placeholder((2, 3), dtype='float32')\n        >>> input\n        <tf.Tensor 'Placeholder_2:0' shape=(2, 3) dtype=float32>\n        # It doesn't work in-place as below.\n        >>> K.cast(input, dtype='float16')\n        <tf.Tensor 'Cast_1:0' shape=(2, 3) dtype=float16>\n        >>> input\n        <tf.Tensor 'Placeholder_2:0' shape=(2, 3) dtype=float32>\n        # you need to assign it.\n        >>> input = K.cast(input, dtype='float16')\n        >>> input\n        <tf.Tensor 'Cast_2:0' shape=(2, 3) dtype=float16>\n    ```\n    \"\"\"\n    return tf.cast(x, dtype)",
                "def update(x, new_x):\n    \"\"\"Update the value of `x` to `new_x`.\n\n    # Arguments\n        x: A `Variable`.\n        new_x: A tensor of same shape as `x`.\n\n    # Returns\n        The variable `x` updated.\n    \"\"\"\n    return tf.assign(x, new_x)",
                "def update_add(x, increment):\n    \"\"\"Update the value of `x` by adding `increment`.\n\n    # Arguments\n        x: A `Variable`.\n        increment: A tensor of same shape as `x`.\n\n    # Returns\n        The variable `x` updated.\n    \"\"\"\n    return tf.assign_add(x, increment)",
                "def update_sub(x, decrement):\n    \"\"\"Update the value of `x` by subtracting `decrement`.\n\n    # Arguments\n        x: A `Variable`.\n        decrement: A tensor of same shape as `x`.\n\n    # Returns\n        The variable `x` updated.\n    \"\"\"\n    return tf.assign_sub(x, decrement)",
                "def moving_average_update(x, value, momentum):\n    \"\"\"Compute the moving average of a variable.\n\n    # Arguments\n        x: A `Variable`.\n        value: A tensor with the same shape as `x`.\n        momentum: The moving average momentum.\n\n    # Returns\n        An operation to update the variable.\n    \"\"\"\n    return moving_averages.assign_moving_average(\n        x, value, momentum, zero_debias=True)",
                "def dot(x, y):\n    \"\"\"Multiplies 2 tensors (and/or variables) and returns a *tensor*.\n\n    When attempting to multiply a nD tensor\n    with a nD tensor, it reproduces the Theano behavior.\n    (e.g. `(2, 3) * (4, 3, 5) -> (2, 4, 5)`)\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A tensor, dot product of `x` and `y`.\n\n    # Examples\n    ```python\n        # dot product between tensors\n        >>> x = K.placeholder(shape=(2, 3))\n        >>> y = K.placeholder(shape=(3, 4))\n        >>> xy = K.dot(x, y)\n        >>> xy\n        <tf.Tensor 'MatMul_9:0' shape=(2, 4) dtype=float32>\n    ```\n\n    ```python\n        # dot product between tensors\n        >>> x = K.placeholder(shape=(32, 28, 3))\n        >>> y = K.placeholder(shape=(3, 4))\n        >>> xy = K.dot(x, y)\n        >>> xy\n        <tf.Tensor 'MatMul_9:0' shape=(32, 28, 4) dtype=float32>\n    ```\n\n    ```python\n        # Theano-like behavior example\n        >>> x = K.random_uniform_variable(shape=(2, 3), low=0, high=1)\n        >>> y = K.ones((4, 3, 5))\n        >>> xy = K.dot(x, y)\n        >>> K.int_shape(xy)\n        (2, 4, 5)\n    ```\n    \"\"\"\n    if ndim(x) is not None and (ndim(x) > 2 or ndim(y) > 2):\n        x_shape = []\n        for i, s in zip(int_shape(x), tf.unstack(tf.shape(x))):\n            if i is not None:\n                x_shape.append(i)\n            else:\n                x_shape.append(s)\n        x_shape = tuple(x_shape)\n        y_shape = []\n        for i, s in zip(int_shape(y), tf.unstack(tf.shape(y))):\n            if i is not None:\n                y_shape.append(i)\n            else:\n                y_shape.append(s)\n        y_shape = tuple(y_shape)\n        y_permute_dim = list(range(ndim(y)))\n        y_permute_dim = [y_permute_dim.pop(-2)] + y_permute_dim\n        xt = tf.reshape(x, [-1, x_shape[-1]])\n        yt = tf.reshape(tf.transpose(y, perm=y_permute_dim), [y_shape[-2], -1])\n        return tf.reshape(tf.matmul(xt, yt),\n                          x_shape[:-1] + y_shape[:-2] + y_shape[-1:])\n    if is_sparse(x):\n        out = tf.sparse_tensor_dense_matmul(x, y)\n    else:\n        out = tf.matmul(x, y)\n    return out",
                "def batch_dot(x, y, axes=None):\n    \"\"\"Batchwise dot product.\n\n    `batch_dot` is used to compute dot product of `x` and `y` when\n    `x` and `y` are data in batch, i.e. in a shape of\n    `(batch_size, :)`.\n    `batch_dot` results in a tensor or variable with less dimensions\n    than the input. If the number of dimensions is reduced to 1,\n    we use `expand_dims` to make sure that ndim is at least 2.\n\n    # Arguments\n        x: Keras tensor or variable with `ndim >= 2`.\n        y: Keras tensor or variable with `ndim >= 2`.\n        axes: list of (or single) int with target dimensions.\n            The lengths of `axes[0]` and `axes[1]` should be the same.\n\n    # Returns\n        A tensor with shape equal to the concatenation of `x`'s shape\n        (less the dimension that was summed over) and `y`'s shape\n        (less the batch dimension and the dimension that was summed over).\n        If the final rank is 1, we reshape it to `(batch_size, 1)`.\n\n    # Examples\n        Assume `x = [[1, 2], [3, 4]]` and `y = [[5, 6], [7, 8]]`\n        `batch_dot(x, y, axes=1) = [[17], [53]]` which is the main diagonal\n        of `x.dot(y.T)`, although we never have to calculate the off-diagonal\n        elements.\n\n        Shape inference:\n        Let `x`'s shape be `(100, 20)` and `y`'s shape be `(100, 30, 20)`.\n        If `axes` is (1, 2), to find the output shape of resultant tensor,\n            loop through each dimension in `x`'s shape and `y`'s shape:\n\n        * `x.shape[0]` : 100 : append to output shape\n        * `x.shape[1]` : 20 : do not append to output shape,\n            dimension 1 of `x` has been summed over. (`dot_axes[0]` = 1)\n        * `y.shape[0]` : 100 : do not append to output shape,\n            always ignore first dimension of `y`\n        * `y.shape[1]` : 30 : append to output shape\n        * `y.shape[2]` : 20 : do not append to output shape,\n            dimension 2 of `y` has been summed over. (`dot_axes[1]` = 2)\n        `output_shape` = `(100, 30)`\n\n    ```python\n        >>> x_batch = K.ones(shape=(32, 20, 1))\n        >>> y_batch = K.ones(shape=(32, 30, 20))\n        >>> xy_batch_dot = K.batch_dot(x_batch, y_batch, axes=[1, 2])\n        >>> K.int_shape(xy_batch_dot)\n        (32, 1, 30)\n    ```\n    \"\"\"\n    if isinstance(axes, int):\n        axes = (axes, axes)\n    x_ndim = ndim(x)\n    y_ndim = ndim(y)\n    if x_ndim > y_ndim:\n        diff = x_ndim - y_ndim\n        y = tf.reshape(y, tf.concat([tf.shape(y), [1] * (diff)], axis=0))\n    elif y_ndim > x_ndim:\n        diff = y_ndim - x_ndim\n        x = tf.reshape(x, tf.concat([tf.shape(x), [1] * (diff)], axis=0))\n    else:\n        diff = 0\n    if ndim(x) == 2 and ndim(y) == 2:\n        if axes[0] == axes[1]:\n            out = tf.reduce_sum(tf.multiply(x, y), axes[0])\n        else:\n            out = tf.reduce_sum(tf.multiply(tf.transpose(x, [1, 0]), y), axes[1])\n    else:\n        if axes is not None:\n            adj_x = None if axes[0] == ndim(x) - 1 else True\n            adj_y = True if axes[1] == ndim(y) - 1 else None\n        else:\n            adj_x = None\n            adj_y = None\n        out = tf.matmul(x, y, adjoint_a=adj_x, adjoint_b=adj_y)\n    if diff:\n        if x_ndim > y_ndim:\n            idx = x_ndim + y_ndim - 3\n        else:\n            idx = x_ndim - 1\n        out = tf.squeeze(out, list(range(idx, idx + diff)))\n    if ndim(out) == 1:\n        out = expand_dims(out, 1)\n    return out",
                "def transpose(x):\n    \"\"\"Transposes a tensor and returns it.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n\n    # Examples\n    ```python\n        >>> var = K.variable([[1, 2, 3], [4, 5, 6]])\n        >>> K.eval(var)\n        array([[ 1.,  2.,  3.],\n               [ 4.,  5.,  6.]], dtype=float32)\n        >>> var_transposed = K.transpose(var)\n        >>> K.eval(var_transposed)\n        array([[ 1.,  4.],\n               [ 2.,  5.],\n               [ 3.,  6.]], dtype=float32)\n    ```\n\n    ```python\n        >>> inputs = K.placeholder((2, 3))\n        >>> inputs\n        <tf.Tensor 'Placeholder_11:0' shape=(2, 3) dtype=float32>\n        >>> input_transposed = K.transpose(inputs)\n        >>> input_transposed\n        <tf.Tensor 'transpose_4:0' shape=(3, 2) dtype=float32>\n\n    ```\n    \"\"\"\n    return tf.transpose(x)",
                "def gather(reference, indices):\n    \"\"\"Retrieves the elements of indices `indices` in the tensor `reference`.\n\n    # Arguments\n        reference: A tensor.\n        indices: An integer tensor of indices.\n\n    # Returns\n        A tensor of same type as `reference`.\n    \"\"\"\n    return tf.gather(reference, indices)",
                "def max(x, axis=None, keepdims=False):\n    \"\"\"Maximum value in a tensor.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer, the axis to find maximum values.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1. If `keepdims` is `True`,\n            the reduced dimension is retained with length 1.\n\n    # Returns\n        A tensor with maximum values of `x`.\n    \"\"\"\n    return tf.reduce_max(x, axis, keepdims)",
                "def min(x, axis=None, keepdims=False):\n    \"\"\"Minimum value in a tensor.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer, the axis to find minimum values.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1. If `keepdims` is `True`,\n            the reduced dimension is retained with length 1.\n\n    # Returns\n        A tensor with miminum values of `x`.\n    \"\"\"\n    return tf.reduce_min(x, axis, keepdims)",
                "def sum(x, axis=None, keepdims=False):\n    \"\"\"Sum of the values in a tensor, alongside the specified axis.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer, the axis to sum over.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1. If `keepdims` is `True`,\n            the reduced dimension is retained with length 1.\n\n    # Returns\n        A tensor with sum of `x`.\n    \"\"\"\n    return tf.reduce_sum(x, axis, keepdims)",
                "def prod(x, axis=None, keepdims=False):\n    \"\"\"Multiplies the values in a tensor, alongside the specified axis.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer, the axis to compute the product.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1. If `keepdims` is `True`,\n            the reduced dimension is retained with length 1.\n\n    # Returns\n        A tensor with the product of elements of `x`.\n    \"\"\"\n    return tf.reduce_prod(x, axis, keepdims)",
                "def cumsum(x, axis=0):\n    \"\"\"Cumulative sum of the values in a tensor, alongside the specified axis.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer, the axis to compute the sum.\n\n    # Returns\n        A tensor of the cumulative sum of values of `x` along `axis`.\n    \"\"\"\n    return tf.cumsum(x, axis=axis)",
                "def cumprod(x, axis=0):\n    \"\"\"Cumulative product of the values in a tensor, alongside the specified axis.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer, the axis to compute the product.\n\n    # Returns\n        A tensor of the cumulative product of values of `x` along `axis`.\n    \"\"\"\n    return tf.cumprod(x, axis=axis)",
                "def var(x, axis=None, keepdims=False):\n    \"\"\"Variance of a tensor, alongside the specified axis.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer, the axis to compute the variance.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1. If `keepdims` is `True`,\n            the reduced dimension is retained with length 1.\n\n    # Returns\n        A tensor with the variance of elements of `x`.\n    \"\"\"\n    if x.dtype.base_dtype == tf.bool:\n        x = tf.cast(x, floatx())\n    m = tf.reduce_mean(x, axis, True)\n    devs_squared = tf.square(x - m)\n    return tf.reduce_mean(devs_squared,\n                          axis,\n                          keepdims)",
                "def std(x, axis=None, keepdims=False):\n    \"\"\"Standard deviation of a tensor, alongside the specified axis.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer, the axis to compute the standard deviation.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1. If `keepdims` is `True`,\n            the reduced dimension is retained with length 1.\n\n    # Returns\n        A tensor with the standard deviation of elements of `x`.\n    \"\"\"\n    return tf.sqrt(var(x, axis=axis, keepdims=keepdims))",
                "def mean(x, axis=None, keepdims=False):\n    \"\"\"Mean of a tensor, alongside the specified axis.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: A list of integer. Axes to compute the mean.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1 for each entry in `axis`. If `keepdims` is `True`,\n            the reduced dimensions are retained with length 1.\n\n    # Returns\n        A tensor with the mean of elements of `x`.\n    \"\"\"\n    if x.dtype.base_dtype == tf.bool:\n        x = tf.cast(x, floatx())\n    return tf.reduce_mean(x, axis, keepdims)",
                "def any(x, axis=None, keepdims=False):\n    \"\"\"Bitwise reduction (logical OR).\n\n    # Arguments\n        x: Tensor or variable.\n        axis: axis along which to perform the reduction.\n        keepdims: whether the drop or broadcast the reduction axes.\n\n    # Returns\n        A uint8 tensor (0s and 1s).\n    \"\"\"\n    x = tf.cast(x, tf.bool)\n    return tf.reduce_any(x, axis, keepdims)",
                "def all(x, axis=None, keepdims=False):\n    \"\"\"Bitwise reduction (logical AND).\n\n    # Arguments\n        x: Tensor or variable.\n        axis: axis along which to perform the reduction.\n        keepdims: whether the drop or broadcast the reduction axes.\n\n    # Returns\n        A uint8 tensor (0s and 1s).\n    \"\"\"\n    x = tf.cast(x, tf.bool)\n    return tf.reduce_all(x, axis, keepdims)",
                "def argmax(x, axis=-1):\n    \"\"\"Returns the index of the maximum value along an axis.\n\n    # Arguments\n        x: Tensor or variable.\n        axis: axis along which to perform the reduction.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.argmax(x, axis)",
                "def argmin(x, axis=-1):\n    \"\"\"Returns the index of the minimum value along an axis.\n\n    # Arguments\n        x: Tensor or variable.\n        axis: axis along which to perform the reduction.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.argmin(x, axis)",
                "def square(x):\n    \"\"\"Element-wise square.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.square(x)",
                "def abs(x):\n    \"\"\"Element-wise absolute value.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.abs(x)",
                "def sqrt(x):\n    \"\"\"Element-wise square root.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    zero = _to_tensor(0., x.dtype.base_dtype)\n    inf = _to_tensor(np.inf, x.dtype.base_dtype)\n    x = tf.clip_by_value(x, zero, inf)\n    return tf.sqrt(x)",
                "def exp(x):\n    \"\"\"Element-wise exponential.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.exp(x)",
                "def log(x):\n    \"\"\"Element-wise log.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.log(x)",
                "def logsumexp(x, axis=None, keepdims=False):\n    \"\"\"Computes log(sum(exp(elements across dimensions of a tensor))).\n\n    This function is more numerically stable than log(sum(exp(x))).\n    It avoids overflows caused by taking the exp of large inputs and\n    underflows caused by taking the log of small inputs.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer, the axis to reduce over.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1. If `keepdims` is `True`, the reduced dimension is\n            retained with length 1.\n\n    # Returns\n        The reduced tensor.\n    \"\"\"\n    return tf.reduce_logsumexp(x, axis, keepdims)",
                "def round(x):\n    \"\"\"Element-wise rounding to the closest integer.\n\n    In case of tie, the rounding mode used is \"half to even\".\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.round(x)",
                "def sign(x):\n    \"\"\"Element-wise sign.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.sign(x)",
                "def pow(x, a):\n    \"\"\"Element-wise exponentiation.\n\n    # Arguments\n        x: Tensor or variable.\n        a: Python integer.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.pow(x, a)",
                "def clip(x, min_value, max_value):\n    \"\"\"Element-wise value clipping.\n\n    # Arguments\n        x: Tensor or variable.\n        min_value: Python float or integer.\n        max_value: Python float or integer.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if max_value is not None and max_value < min_value:\n        max_value = min_value\n    if max_value is None:\n        max_value = np.inf\n    min_value = _to_tensor(min_value, x.dtype.base_dtype)\n    max_value = _to_tensor(max_value, x.dtype.base_dtype)\n    return tf.clip_by_value(x, min_value, max_value)",
                "def equal(x, y):\n    \"\"\"Element-wise equality between two tensors.\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A bool tensor.\n    \"\"\"\n    return tf.equal(x, y)",
                "def not_equal(x, y):\n    \"\"\"Element-wise inequality between two tensors.\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A bool tensor.\n    \"\"\"\n    return tf.not_equal(x, y)",
                "def greater(x, y):\n    \"\"\"Element-wise truth value of (x > y).\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A bool tensor.\n    \"\"\"\n    return tf.greater(x, y)",
                "def greater_equal(x, y):\n    \"\"\"Element-wise truth value of (x >= y).\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A bool tensor.\n    \"\"\"\n    return tf.greater_equal(x, y)",
                "def less(x, y):\n    \"\"\"Element-wise truth value of (x < y).\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A bool tensor.\n    \"\"\"\n    return tf.less(x, y)",
                "def less_equal(x, y):\n    \"\"\"Element-wise truth value of (x <= y).\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A bool tensor.\n    \"\"\"\n    return tf.less_equal(x, y)",
                "def maximum(x, y):\n    \"\"\"Element-wise maximum of two tensors.\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.maximum(x, y)",
                "def minimum(x, y):\n    \"\"\"Element-wise minimum of two tensors.\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.minimum(x, y)",
                "def sin(x):\n    \"\"\"Computes sin of x element-wise.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.sin(x)",
                "def cos(x):\n    \"\"\"Computes cos of x element-wise.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.cos(x)",
                "def _regular_normalize_batch_in_training(x, gamma, beta,\n                                         reduction_axes, epsilon=1e-3):\n    \"\"\"Non-fused version of `normalize_batch_in_training`.\n\n    # Arguments\n        x: Input tensor or variable.\n        gamma: Tensor by which to scale the input.\n        beta: Tensor with which to center the input.\n        reduction_axes: iterable of integers,\n            axes over which to normalize.\n        epsilon: Fuzz factor.\n\n    # Returns\n        A tuple length of 3, `(normalized_tensor, mean, variance)`.\n    \"\"\"\n    mean, var = tf.nn.moments(x, reduction_axes,\n                              None, None, False)\n    normed = tf.nn.batch_normalization(x, mean, var,\n                                       beta, gamma,\n                                       epsilon)\n    return normed, mean, var",
                "def _broadcast_normalize_batch_in_training(x, gamma, beta,\n                                           reduction_axes, epsilon=1e-3):\n    \"\"\"Non-fused, broadcast version of `normalize_batch_in_training`.\n\n    # Arguments\n        x: Input tensor or variable.\n        gamma: Tensor by which to scale the input.\n        beta: Tensor with which to center the input.\n        reduction_axes: iterable of integers,\n            axes over which to normalize.\n        epsilon: Fuzz factor.\n\n    # Returns\n        A tuple length of 3, `(normalized_tensor, mean, variance)`.\n    \"\"\"\n    mean, var = tf.nn.moments(x, reduction_axes,\n                              None, None, False)\n    target_shape = []\n    for axis in range(ndim(x)):\n        if axis in reduction_axes:\n            target_shape.append(1)\n        else:\n            target_shape.append(tf.shape(x)[axis])\n    target_shape = tf.stack(target_shape)\n\n    broadcast_mean = tf.reshape(mean, target_shape)\n    broadcast_var = tf.reshape(var, target_shape)\n    if gamma is None:\n        broadcast_gamma = None\n    else:\n        broadcast_gamma = tf.reshape(gamma, target_shape)\n    if beta is None:\n        broadcast_beta = None\n    else:\n        broadcast_beta = tf.reshape(beta, target_shape)\n\n    normed = tf.nn.batch_normalization(\n        x,\n        broadcast_mean,\n        broadcast_var,\n        broadcast_beta,\n        broadcast_gamma,\n        epsilon)\n    return normed, mean, var",
                "def _fused_normalize_batch_in_training(x, gamma, beta, reduction_axes,\n                                       epsilon=1e-3):\n    \"\"\"Fused version of `normalize_batch_in_training`.\n\n    # Arguments\n        x: Input tensor or variable.\n        gamma: Tensor by which to scale the input.\n        beta: Tensor with which to center the input.\n        reduction_axes: iterable of integers,\n            axes over which to normalize.\n        epsilon: Fuzz factor.\n\n    # Returns\n        A tuple length of 3, `(normalized_tensor, mean, variance)`.\n    \"\"\"\n    if list(reduction_axes) == [0, 1, 2]:\n        normalization_axis = 3\n        tf_data_format = 'NHWC'\n    else:\n        normalization_axis = 1\n        tf_data_format = 'NCHW'\n\n    if gamma is None:\n        gamma = tf.constant(1.0,\n                            dtype=x.dtype,\n                            shape=[x.get_shape()[normalization_axis]])\n    if beta is None:\n        beta = tf.constant(0.0,\n                           dtype=x.dtype,\n                           shape=[x.get_shape()[normalization_axis]])\n\n    return tf.nn.fused_batch_norm(\n        x,\n        gamma,\n        beta,\n        epsilon=epsilon,\n        data_format=tf_data_format)",
                "def normalize_batch_in_training(x, gamma, beta,\n                                reduction_axes, epsilon=1e-3):\n    \"\"\"Computes mean and std for batch then apply batch_normalization on batch.\n\n    # Arguments\n        x: Input tensor or variable.\n        gamma: Tensor by which to scale the input.\n        beta: Tensor with which to center the input.\n        reduction_axes: iterable of integers,\n            axes over which to normalize.\n        epsilon: Fuzz factor.\n\n    # Returns\n        A tuple length of 3, `(normalized_tensor, mean, variance)`.\n    \"\"\"\n    if ndim(x) == 4 and list(reduction_axes) in [[0, 1, 2], [0, 2, 3]]:\n        if not _has_nchw_support() and list(reduction_axes) == [0, 2, 3]:\n            return _broadcast_normalize_batch_in_training(x, gamma, beta,\n                                                          reduction_axes,\n                                                          epsilon=epsilon)\n        return _fused_normalize_batch_in_training(\n            x, gamma, beta, reduction_axes,\n            epsilon=epsilon)\n    else:\n        if sorted(reduction_axes) == list(range(ndim(x)))[:-1]:\n            return _regular_normalize_batch_in_training(x, gamma, beta,\n                                                        reduction_axes,\n                                                        epsilon=epsilon)\n        else:\n            return _broadcast_normalize_batch_in_training(x, gamma, beta,\n                                                          reduction_axes,\n                                                          epsilon=epsilon)",
                "def batch_normalization(x, mean, var, beta, gamma, epsilon=1e-3):\n    \"\"\"Applies batch normalization on x given mean, var, beta and gamma.\n\n    I.e. returns:\n    `output = (x - mean) / (sqrt(var) + epsilon) * gamma + beta`\n\n    # Arguments\n        x: Input tensor or variable.\n        mean: Mean of batch.\n        var: Variance of batch.\n        beta: Tensor with which to center the input.\n        gamma: Tensor by which to scale the input.\n        epsilon: Fuzz factor.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.nn.batch_normalization(x, mean, var, beta, gamma, epsilon)",
                "def concatenate(tensors, axis=-1):\n    \"\"\"Concatenates a list of tensors alongside the specified axis.\n\n    # Arguments\n        tensors: list of tensors to concatenate.\n        axis: concatenation axis.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if axis < 0:\n        rank = ndim(tensors[0])\n        if rank:\n            axis %= rank\n        else:\n            axis = 0\n\n    if py_all([is_sparse(x) for x in tensors]):\n        return tf.sparse_concat(axis, tensors)\n    else:\n        return tf.concat([to_dense(x) for x in tensors], axis)",
                "def reshape(x, shape):\n    \"\"\"Reshapes a tensor to the specified shape.\n\n    # Arguments\n        x: Tensor or variable.\n        shape: Target shape tuple.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.reshape(x, shape)",
                "def permute_dimensions(x, pattern):\n    \"\"\"Permutes axes in a tensor.\n\n    # Arguments\n        x: Tensor or variable.\n        pattern: A tuple of\n            dimension indices, e.g. `(0, 2, 1)`.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.transpose(x, perm=pattern)",
                "def resize_images(x, height_factor, width_factor, data_format):\n    \"\"\"Resizes the images contained in a 4D tensor.\n\n    # Arguments\n        x: Tensor or variable to resize.\n        height_factor: Positive integer.\n        width_factor: Positive integer.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n\n    # Returns\n        A tensor.\n\n    # Raises\n        ValueError: if `data_format` is neither `\"channels_last\"` or `\"channels_first\"`.\n    \"\"\"\n    if data_format == 'channels_first':\n        original_shape = int_shape(x)\n        new_shape = tf.shape(x)[2:]\n        new_shape *= tf.constant(np.array([height_factor, width_factor]).astype('int32'))\n        x = permute_dimensions(x, [0, 2, 3, 1])\n        x = tf.image.resize_nearest_neighbor(x, new_shape)\n        x = permute_dimensions(x, [0, 3, 1, 2])\n        x.set_shape((None, None, original_shape[2] * height_factor if original_shape[2] is not None else None,\n                     original_shape[3] * width_factor if original_shape[3] is not None else None))\n        return x\n    elif data_format == 'channels_last':\n        original_shape = int_shape(x)\n        new_shape = tf.shape(x)[1:3]\n        new_shape *= tf.constant(np.array([height_factor, width_factor]).astype('int32'))\n        x = tf.image.resize_nearest_neighbor(x, new_shape)\n        x.set_shape((None, original_shape[1] * height_factor if original_shape[1] is not None else None,\n                     original_shape[2] * width_factor if original_shape[2] is not None else None, None))\n        return x\n    else:\n        raise ValueError('Unknown data_format: ' + str(data_format))",
                "def resize_volumes(x, depth_factor, height_factor, width_factor, data_format):\n    \"\"\"Resizes the volume contained in a 5D tensor.\n\n    # Arguments\n        x: Tensor or variable to resize.\n        depth_factor: Positive integer.\n        height_factor: Positive integer.\n        width_factor: Positive integer.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n\n    # Returns\n        A tensor.\n\n    # Raises\n        ValueError: if `data_format` is neither `\"channels_last\"` or `\"channels_first\"`.\n    \"\"\"\n    if data_format == 'channels_first':\n        output = repeat_elements(x, depth_factor, axis=2)\n        output = repeat_elements(output, height_factor, axis=3)\n        output = repeat_elements(output, width_factor, axis=4)\n        return output\n    elif data_format == 'channels_last':\n        output = repeat_elements(x, depth_factor, axis=1)\n        output = repeat_elements(output, height_factor, axis=2)\n        output = repeat_elements(output, width_factor, axis=3)\n        return output\n    else:\n        raise ValueError('Unknown data_format: ' + str(data_format))",
                "def repeat_elements(x, rep, axis):\n    \"\"\"Repeats the elements of a tensor along an axis, like `np.repeat`.\n\n    If `x` has shape `(s1, s2, s3)` and `axis` is `1`, the output\n    will have shape `(s1, s2 * rep, s3)`.\n\n    # Arguments\n        x: Tensor or variable.\n        rep: Python integer, number of times to repeat.\n        axis: Axis along which to repeat.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    x_shape = x.get_shape().as_list()\n    # For static axis\n    if x_shape[axis] is not None:\n        # slices along the repeat axis\n        splits = tf.split(value=x, num_or_size_splits=x_shape[axis], axis=axis)\n        # repeat each slice the given number of reps\n        x_rep = [s for s in splits for _ in range(rep)]\n        return concatenate(x_rep, axis)\n\n    # Here we use tf.tile to mimic behavior of np.repeat so that\n    # we can handle dynamic shapes (that include None).\n    # To do that, we need an auxiliary axis to repeat elements along\n    # it and then merge them along the desired axis.\n\n    # Repeating\n    auxiliary_axis = axis + 1\n    x_shape = tf.shape(x)\n    x_rep = tf.expand_dims(x, axis=auxiliary_axis)\n    reps = np.ones(len(x.get_shape()) + 1)\n    reps[auxiliary_axis] = rep\n    x_rep = tf.tile(x_rep, reps)\n\n    # Merging\n    reps = np.delete(reps, auxiliary_axis)\n    reps[axis] = rep\n    reps = tf.constant(reps, dtype='int32')\n    x_shape = x_shape * reps\n    x_rep = tf.reshape(x_rep, x_shape)\n\n    # Fix shape representation\n    x_shape = x.get_shape().as_list()\n    x_rep.set_shape(x_shape)\n    x_rep._keras_shape = tuple(x_shape)\n    return x_rep",
                "def repeat(x, n):\n    \"\"\"Repeats a 2D tensor.\n\n    if `x` has shape (samples, dim) and `n` is `2`,\n    the output will have shape `(samples, 2, dim)`.\n\n    # Arguments\n        x: Tensor or variable.\n        n: Python integer, number of times to repeat.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    assert ndim(x) == 2\n    x = tf.expand_dims(x, 1)\n    pattern = tf.stack([1, n, 1])\n    return tf.tile(x, pattern)",
                "def arange(start, stop=None, step=1, dtype='int32'):\n    \"\"\"Creates a 1D tensor containing a sequence of integers.\n\n    The function arguments use the same convention as\n    Theano's arange: if only one argument is provided,\n    it is in fact the \"stop\" argument and \"start\" is 0.\n\n    The default type of the returned tensor is `'int32'` to\n    match TensorFlow's default.\n\n    # Arguments\n        start: Start value.\n        stop: Stop value.\n        step: Difference between two successive values.\n        dtype: Integer dtype to use.\n\n    # Returns\n        An integer tensor.\n\n    \"\"\"\n    # Match the behavior of numpy and Theano by returning an empty sequence.\n    if stop is None:\n        try:\n            if start < 0:\n                start = 0\n        except TypeError:\n            # Handle case where start is a tensor\n            start = tf.cond(start < 0,\n                            true_fn=lambda: tf.constant(0, dtype=start.dtype),\n                            false_fn=lambda: start)\n\n    result = tf.range(start, limit=stop, delta=step, name='arange')\n    if dtype != 'int32':\n        result = cast(result, dtype)\n    return result",
                "def tile(x, n):\n    \"\"\"Creates a tensor by tiling `x` by `n`.\n\n    # Arguments\n        x: A tensor or variable\n        n: A list of integer. The length must be the same as the number of\n            dimensions in `x`.\n\n    # Returns\n        A tiled tensor.\n    \"\"\"\n    if isinstance(n, int):\n        n = [n]\n    return tf.tile(x, n)",
                "def flatten(x):\n    \"\"\"Flatten a tensor.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A tensor, reshaped into 1-D\n    \"\"\"\n    return tf.reshape(x, [-1])",
                "def batch_flatten(x):\n    \"\"\"Turn a nD tensor into a 2D tensor with same 0th dimension.\n\n    In other words, it flattens each data samples of a batch.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    x = tf.reshape(x, tf.stack([-1, prod(shape(x)[1:])]))\n    return x",
                "def expand_dims(x, axis=-1):\n    \"\"\"Adds a 1-sized dimension at index \"axis\".\n\n    # Arguments\n        x: A tensor or variable.\n        axis: Position where to add a new axis.\n\n    # Returns\n        A tensor with expanded dimensions.\n    \"\"\"\n    return tf.expand_dims(x, axis)",
                "def squeeze(x, axis):\n    \"\"\"Removes a 1-dimension from the tensor at index \"axis\".\n\n    # Arguments\n        x: A tensor or variable.\n        axis: Axis to drop.\n\n    # Returns\n        A tensor with the same data as `x` but reduced dimensions.\n    \"\"\"\n    return tf.squeeze(x, [axis])",
                "def temporal_padding(x, padding=(1, 1)):\n    \"\"\"Pads the middle dimension of a 3D tensor.\n\n    # Arguments\n        x: Tensor or variable.\n        padding: Tuple of 2 integers, how many zeros to\n            add at the start and end of dim 1.\n\n    # Returns\n        A padded 3D tensor.\n    \"\"\"\n    assert len(padding) == 2\n    pattern = [[0, 0], [padding[0], padding[1]], [0, 0]]\n    return tf.pad(x, pattern)",
                "def spatial_2d_padding(x, padding=((1, 1), (1, 1)), data_format=None):\n    \"\"\"Pads the 2nd and 3rd dimensions of a 4D tensor.\n\n    # Arguments\n        x: Tensor or variable.\n        padding: Tuple of 2 tuples, padding pattern.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n\n    # Returns\n        A padded 4D tensor.\n\n    # Raises\n        ValueError: if `data_format` is neither `\"channels_last\"` or `\"channels_first\"`.\n    \"\"\"\n    assert len(padding) == 2\n    assert len(padding[0]) == 2\n    assert len(padding[1]) == 2\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format: ' + str(data_format))\n\n    if data_format == 'channels_first':\n        pattern = [[0, 0],\n                   [0, 0],\n                   list(padding[0]),\n                   list(padding[1])]\n    else:\n        pattern = [[0, 0],\n                   list(padding[0]), list(padding[1]),\n                   [0, 0]]\n    return tf.pad(x, pattern)",
                "def spatial_3d_padding(x, padding=((1, 1), (1, 1), (1, 1)), data_format=None):\n    \"\"\"Pads 5D tensor with zeros along the depth, height, width dimensions.\n\n    Pads these dimensions with respectively\n    \"padding[0]\", \"padding[1]\" and \"padding[2]\" zeros left and right.\n\n    For 'channels_last' data_format,\n    the 2nd, 3rd and 4th dimension will be padded.\n    For 'channels_first' data_format,\n    the 3rd, 4th and 5th dimension will be padded.\n\n    # Arguments\n        x: Tensor or variable.\n        padding: Tuple of 3 tuples, padding pattern.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n\n    # Returns\n        A padded 5D tensor.\n\n    # Raises\n        ValueError: if `data_format` is neither `\"channels_last\"` or `\"channels_first\"`.\n\n    \"\"\"\n    assert len(padding) == 3\n    assert len(padding[0]) == 2\n    assert len(padding[1]) == 2\n    assert len(padding[2]) == 2\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format: ' + str(data_format))\n\n    if data_format == 'channels_first':\n        pattern = [\n            [0, 0],\n            [0, 0],\n            [padding[0][0], padding[0][1]],\n            [padding[1][0], padding[1][1]],\n            [padding[2][0], padding[2][1]]\n        ]\n    else:\n        pattern = [\n            [0, 0],\n            [padding[0][0], padding[0][1]],\n            [padding[1][0], padding[1][1]],\n            [padding[2][0], padding[2][1]],\n            [0, 0]\n        ]\n    return tf.pad(x, pattern)",
                "def stack(x, axis=0):\n    \"\"\"Stacks a list of rank `R` tensors into a rank `R+1` tensor.\n\n    # Arguments\n        x: List of tensors.\n        axis: Axis along which to perform stacking.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.stack(x, axis=axis)",
                "def one_hot(indices, num_classes):\n    \"\"\"Computes the one-hot representation of an integer tensor.\n\n    # Arguments\n        indices: nD integer tensor of shape\n            `(batch_size, dim1, dim2, ... dim(n-1))`\n        num_classes: Integer, number of classes to consider.\n\n    # Returns\n        (n + 1)D one hot representation of the input\n        with shape `(batch_size, dim1, dim2, ... dim(n-1), num_classes)`\n    \"\"\"\n    return tf.one_hot(indices, depth=num_classes, axis=-1)",
                "def reverse(x, axes):\n    \"\"\"Reverse a tensor along the specified axes.\n\n    # Arguments\n        x: Tensor to reverse.\n        axes: Integer or iterable of integers.\n            Axes to reverse.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if isinstance(axes, int):\n        axes = [axes]\n    return tf.reverse(x, axes)",
                "def get_value(x):\n    \"\"\"Returns the value of a variable.\n\n    # Arguments\n        x: input variable.\n\n    # Returns\n        A Numpy array.\n    \"\"\"\n    return x.eval(session=get_session())",
                "def batch_get_value(ops):\n    \"\"\"Returns the value of more than one tensor variable.\n\n    # Arguments\n        ops: list of ops to run.\n\n    # Returns\n        A list of Numpy arrays.\n    \"\"\"\n    if ops:\n        return get_session().run(ops)\n    else:\n        return []",
                "def set_value(x, value):\n    \"\"\"Sets the value of a variable, from a Numpy array.\n\n    # Arguments\n        x: Tensor to set to a new value.\n        value: Value to set the tensor to, as a Numpy array\n            (of the same shape).\n    \"\"\"\n    value = np.asarray(value, dtype=dtype(x))\n    tf_dtype = tf.as_dtype(x.dtype.name.split('_')[0])\n    if hasattr(x, '_assign_placeholder'):\n        assign_placeholder = x._assign_placeholder\n        assign_op = x._assign_op\n    else:\n        assign_placeholder = tf.placeholder(tf_dtype, shape=value.shape)\n        assign_op = x.assign(assign_placeholder)\n        x._assign_placeholder = assign_placeholder\n        x._assign_op = assign_op\n    get_session().run(assign_op, feed_dict={assign_placeholder: value})",
                "def batch_set_value(tuples):\n    \"\"\"Sets the values of many tensor variables at once.\n\n    # Arguments\n        tuples: a list of tuples `(tensor, value)`.\n            `value` should be a Numpy array.\n    \"\"\"\n    if tuples:\n        assign_ops = []\n        feed_dict = {}\n        for x, value in tuples:\n            value = np.asarray(value, dtype=dtype(x))\n            tf_dtype = tf.as_dtype(x.dtype.name.split('_')[0])\n            if hasattr(x, '_assign_placeholder'):\n                assign_placeholder = x._assign_placeholder\n                assign_op = x._assign_op\n            else:\n                assign_placeholder = tf.placeholder(tf_dtype,\n                                                    shape=value.shape)\n                assign_op = x.assign(assign_placeholder)\n                x._assign_placeholder = assign_placeholder\n                x._assign_op = assign_op\n            assign_ops.append(assign_op)\n            feed_dict[assign_placeholder] = value\n        get_session().run(assign_ops, feed_dict=feed_dict)",
                "def get_variable_shape(x):\n    \"\"\"Returns the shape of a variable.\n\n    # Arguments\n        x: A variable.\n\n    # Returns\n        A tuple of integers.\n    \"\"\"\n    return int_shape(x)",
                "def print_tensor(x, message=''):\n    \"\"\"Prints `message` and the tensor value when evaluated.\n\n     Note that `print_tensor` returns a new tensor identical to `x`\n     which should be used in the following code. Otherwise the\n     print operation is not taken into account during evaluation.\n\n     # Example\n     ```python\n         >>> x = K.print_tensor(x, message=\"x is: \")\n     ```\n\n    # Arguments\n        x: Tensor to print.\n        message: Message to print jointly with the tensor.\n\n    # Returns\n        The same tensor `x`, unchanged.\n    \"\"\"\n    return tf.Print(x, [x], message)",
                "def function(inputs, outputs, updates=None, **kwargs):\n    \"\"\"Instantiates a Keras function.\n\n    # Arguments\n        inputs: List of placeholder tensors.\n        outputs: List of output tensors.\n        updates: List of update ops.\n        **kwargs: Passed to `tf.Session.run`.\n\n    # Returns\n        Output values as Numpy arrays.\n\n    # Raises\n        ValueError: if invalid kwargs are passed in.\n    \"\"\"\n    if kwargs:\n        for key in kwargs:\n            if not (has_arg(tf.Session.run, key, True) or has_arg(Function.__init__, key, True)):\n                msg = 'Invalid argument \"%s\" passed to K.function with TensorFlow backend' % key\n                raise ValueError(msg)\n    return Function(inputs, outputs, updates=updates, **kwargs)",
                "def gradients(loss, variables):\n    \"\"\"Returns the gradients of `variables` w.r.t. `loss`.\n\n    # Arguments\n        loss: Scalar tensor to minimize.\n        variables: List of variables.\n\n    # Returns\n        A gradients tensor.\n    \"\"\"\n    return tf.gradients(loss, variables, colocate_gradients_with_ops=True)",
                "def stop_gradient(variables):\n    \"\"\"Returns `variables` but with zero gradient w.r.t. every other variable.\n\n    # Arguments\n        variables: tensor or list of tensors to consider constant with respect\n            to any other variable.\n\n    # Returns\n        A single tensor or a list of tensors (depending on the passed argument)\n            that has constant gradient with respect to any other variable.\n    \"\"\"\n    if isinstance(variables, (list, tuple)):\n        return map(tf.stop_gradient, variables)\n    else:\n        return tf.stop_gradient(variables)",
                "def rnn(step_function, inputs, initial_states,\n        go_backwards=False, mask=None, constants=None,\n        unroll=False, input_length=None):\n    \"\"\"Iterates over the time dimension of a tensor.\n\n    # Arguments\n        step_function: RNN step function.\n            Parameters:\n                inputs: tensor with shape `(samples, ...)` (no time dimension),\n                    representing input for the batch of samples at a certain\n                    time step.\n                states: list of tensors.\n            Returns:\n                outputs: tensor with shape `(samples, output_dim)`\n                    (no time dimension).\n                new_states: list of tensors, same length and shapes\n                    as 'states'. The first state in the list must be the\n                    output tensor at the previous timestep.\n        inputs: tensor of temporal data of shape `(samples, time, ...)`\n            (at least 3D).\n        initial_states: tensor with shape (samples, output_dim)\n            (no time dimension),\n            containing the initial values for the states used in\n            the step function.\n        go_backwards: boolean. If True, do the iteration over the time\n            dimension in reverse order and return the reversed sequence.\n        mask: binary tensor with shape `(samples, time, 1)`,\n            with a zero for every element that is masked.\n        constants: a list of constant values passed at each step.\n        unroll: whether to unroll the RNN or to use a symbolic loop (`while_loop` or `scan` depending on backend).\n        input_length: not relevant in the TensorFlow implementation.\n            Must be specified if using unrolling with Theano.\n\n    # Returns\n        A tuple, `(last_output, outputs, new_states)`.\n\n            last_output: the latest output of the rnn, of shape `(samples, ...)`\n            outputs: tensor with shape `(samples, time, ...)` where each\n                entry `outputs[s, t]` is the output of the step function\n                at time `t` for sample `s`.\n            new_states: list of tensors, latest states returned by\n                the step function, of shape `(samples, ...)`.\n\n    # Raises\n        ValueError: if input dimension is less than 3.\n        ValueError: if `unroll` is `True` but input timestep is not a fixed number.\n        ValueError: if `mask` is provided (not `None`) but states is not provided\n            (`len(states)` == 0).\n    \"\"\"\n    ndim = len(inputs.get_shape())\n    if ndim < 3:\n        raise ValueError('Input should be at least 3D.')\n\n    # Transpose to time-major, i.e.\n    # from (batch, time, ...) to (time, batch, ...)\n    axes = [1, 0] + list(range(2, ndim))\n    inputs = tf.transpose(inputs, (axes))\n\n    if mask is not None:\n        if mask.dtype != tf.bool:\n            mask = tf.cast(mask, tf.bool)\n        if len(mask.get_shape()) == ndim - 1:\n            mask = expand_dims(mask)\n        mask = tf.transpose(mask, axes)\n\n    if constants is None:\n        constants = []\n\n    global uses_learning_phase\n    uses_learning_phase = False\n\n    if unroll:\n        if not inputs.get_shape()[0]:\n            raise ValueError('Unrolling requires a '\n                             'fixed number of timesteps.')\n        states = initial_states\n        successive_states = []\n        successive_outputs = []\n\n        input_list = tf.unstack(inputs)\n        if go_backwards:\n            input_list.reverse()\n\n        if mask is not None:\n            mask_list = tf.unstack(mask)\n            if go_backwards:\n                mask_list.reverse()\n\n            for inp, mask_t in zip(input_list, mask_list):\n                output, new_states = step_function(inp, states + constants)\n                if getattr(output, '_uses_learning_phase', False):\n                    uses_learning_phase = True\n\n                # tf.where needs its condition tensor\n                # to be the same shape as its two\n                # result tensors, but in our case\n                # the condition (mask) tensor is\n                # (nsamples, 1), and A and B are (nsamples, ndimensions).\n                # So we need to\n                # broadcast the mask to match the shape of A and B.\n                # That's what the tile call does,\n                # it just repeats the mask along its second dimension\n                # n times.\n                tiled_mask_t = tf.tile(mask_t,\n                                       tf.stack([1, tf.shape(output)[1]]))\n\n                if not successive_outputs:\n                    prev_output = zeros_like(output)\n                else:\n                    prev_output = successive_outputs[-1]\n\n                output = tf.where(tiled_mask_t, output, prev_output)\n\n                return_states = []\n                for state, new_state in zip(states, new_states):\n                    # (see earlier comment for tile explanation)\n                    tiled_mask_t = tf.tile(mask_t,\n                                           tf.stack([1, tf.shape(new_state)[1]]))\n                    return_states.append(tf.where(tiled_mask_t,\n                                                  new_state,\n                                                  state))\n                states = return_states\n                successive_outputs.append(output)\n                successive_states.append(states)\n            last_output = successive_outputs[-1]\n            new_states = successive_states[-1]\n            outputs = tf.stack(successive_outputs)\n        else:\n            for inp in input_list:\n                output, states = step_function(inp, states + constants)\n                if getattr(output, '_uses_learning_phase', False):\n                    uses_learning_phase = True\n                successive_outputs.append(output)\n                successive_states.append(states)\n            last_output = successive_outputs[-1]\n            new_states = successive_states[-1]\n            outputs = tf.stack(successive_outputs)\n\n    else:\n        if go_backwards:\n            inputs = reverse(inputs, 0)\n\n        states = tuple(initial_states)\n\n        time_steps = tf.shape(inputs)[0]\n        outputs, _ = step_function(inputs[0], initial_states + constants)\n        output_ta = tensor_array_ops.TensorArray(\n            dtype=outputs.dtype,\n            size=time_steps,\n            tensor_array_name='output_ta')\n        input_ta = tensor_array_ops.TensorArray(\n            dtype=inputs.dtype,\n            size=time_steps,\n            tensor_array_name='input_ta')\n        input_ta = input_ta.unstack(inputs)\n        time = tf.constant(0, dtype='int32', name='time')\n\n        if mask is not None:\n            if not states:\n                raise ValueError('No initial states provided! '\n                                 'When using masking in an RNN, you should '\n                                 'provide initial states '\n                                 '(and your step function should return '\n                                 'as its first state at time `t` '\n                                 'the output at time `t-1`).')\n            if go_backwards:\n                mask = reverse(mask, 0)\n\n            mask_ta = tensor_array_ops.TensorArray(\n                dtype=tf.bool,\n                size=time_steps,\n                tensor_array_name='mask_ta')\n            mask_ta = mask_ta.unstack(mask)\n\n            def _step(time, output_ta_t, *states):\n                \"\"\"RNN step function.\n\n                # Arguments\n                    time: Current timestep value.\n                    output_ta_t: TensorArray.\n                    *states: List of states.\n\n                # Returns\n                    Tuple: `(time + 1,output_ta_t) + tuple(new_states)`\n                \"\"\"\n                current_input = input_ta.read(time)\n                mask_t = mask_ta.read(time)\n                output, new_states = step_function(current_input,\n                                                   tuple(states) +\n                                                   tuple(constants))\n                if getattr(output, '_uses_learning_phase', False):\n                    global uses_learning_phase\n                    uses_learning_phase = True\n                for state, new_state in zip(states, new_states):\n                    new_state.set_shape(state.get_shape())\n                tiled_mask_t = tf.tile(mask_t,\n                                       tf.stack([1, tf.shape(output)[1]]))\n                output = tf.where(tiled_mask_t, output, states[0])\n                new_states = [tf.where(tiled_mask_t, new_states[i], states[i]) for i in range(len(states))]\n                output_ta_t = output_ta_t.write(time, output)\n                return (time + 1, output_ta_t) + tuple(new_states)\n        else:\n            def _step(time, output_ta_t, *states):\n                \"\"\"RNN step function.\n\n                # Arguments\n                    time: Current timestep value.\n                    output_ta_t: TensorArray.\n                    *states: List of states.\n\n                # Returns\n                    Tuple: `(time + 1,output_ta_t) + tuple(new_states)`\n                \"\"\"\n                current_input = input_ta.read(time)\n                output, new_states = step_function(current_input,\n                                                   tuple(states) +\n                                                   tuple(constants))\n                if getattr(output, '_uses_learning_phase', False):\n                    global uses_learning_phase\n                    uses_learning_phase = True\n                for state, new_state in zip(states, new_states):\n                    new_state.set_shape(state.get_shape())\n                output_ta_t = output_ta_t.write(time, output)\n                return (time + 1, output_ta_t) + tuple(new_states)\n\n        final_outputs = control_flow_ops.while_loop(\n            cond=lambda time, *_: time < time_steps,\n            body=_step,\n            loop_vars=(time, output_ta) + states,\n            parallel_iterations=32,\n            swap_memory=True)\n        last_time = final_outputs[0]\n        output_ta = final_outputs[1]\n        new_states = final_outputs[2:]\n\n        outputs = output_ta.stack()\n        last_output = output_ta.read(last_time - 1)\n\n    axes = [1, 0] + list(range(2, len(outputs.get_shape())))\n    outputs = tf.transpose(outputs, axes)\n    last_output._uses_learning_phase = uses_learning_phase\n    return last_output, outputs, new_states",
                "def switch(condition, then_expression, else_expression):\n    \"\"\"Switches between two operations depending on a scalar value.\n\n    Note that both `then_expression` and `else_expression`\n    should be symbolic tensors of the *same shape*.\n\n    # Arguments\n        condition: tensor (`int` or `bool`).\n        then_expression: either a tensor, or a callable that returns a tensor.\n        else_expression: either a tensor, or a callable that returns a tensor.\n\n    # Returns\n        The selected tensor.\n\n    # Raises\n        ValueError: If rank of `condition` is greater than rank of expressions.\n    \"\"\"\n    if condition.dtype != tf.bool:\n        condition = tf.cast(condition, 'bool')\n    cond_ndim = ndim(condition)\n    if not cond_ndim:\n        if not callable(then_expression):\n            def then_expression_fn():\n                return then_expression\n        else:\n            then_expression_fn = then_expression\n        if not callable(else_expression):\n            def else_expression_fn():\n                return else_expression\n        else:\n            else_expression_fn = else_expression\n        x = tf.cond(condition,\n                    then_expression_fn,\n                    else_expression_fn)\n    else:\n        # tf.where needs its condition tensor\n        # to be the same shape as its two\n        # result tensors\n        if callable(then_expression):\n            then_expression = then_expression()\n        if callable(else_expression):\n            else_expression = else_expression()\n        expr_ndim = ndim(then_expression)\n        if cond_ndim > expr_ndim:\n            raise ValueError('Rank of `condition` should be less than or'\n                             ' equal to rank of `then_expression` and '\n                             '`else_expression`. ndim(condition)=' +\n                             str(cond_ndim) + ', ndim(then_expression)'\n                             '=' + str(expr_ndim))\n        if cond_ndim > 1:\n            ndim_diff = expr_ndim - cond_ndim\n            cond_shape = tf.concat([tf.shape(condition), [1] * ndim_diff], axis=0)\n            condition = tf.reshape(condition, cond_shape)\n            expr_shape = tf.shape(then_expression)\n            shape_diff = expr_shape - cond_shape\n            tile_shape = tf.where(shape_diff > 0, expr_shape, tf.ones_like(expr_shape))\n            condition = tf.tile(condition, tile_shape)\n        x = tf.where(condition, then_expression, else_expression)\n    return x",
                "def in_train_phase(x, alt, training=None):\n    \"\"\"Selects `x` in train phase, and `alt` otherwise.\n\n    Note that `alt` should have the *same shape* as `x`.\n\n    # Arguments\n        x: What to return in train phase\n            (tensor or callable that returns a tensor).\n        alt: What to return otherwise\n            (tensor or callable that returns a tensor).\n        training: Optional scalar tensor\n            (or Python boolean, or Python integer)\n            specifying the learning phase.\n\n    # Returns\n        Either `x` or `alt` based on the `training` flag.\n        the `training` flag defaults to `K.learning_phase()`.\n    \"\"\"\n    if training is None:\n        training = learning_phase()\n        uses_learning_phase = True\n    else:\n        uses_learning_phase = False\n\n    if training is 1 or training is True:\n        if callable(x):\n            return x()\n        else:\n            return x\n\n    elif training is 0 or training is False:\n        if callable(alt):\n            return alt()\n        else:\n            return alt\n\n    # else: assume learning phase is a placeholder tensor.\n    x = switch(training, x, alt)\n    if uses_learning_phase:\n        x._uses_learning_phase = True\n    return x",
                "def in_test_phase(x, alt, training=None):\n    \"\"\"Selects `x` in test phase, and `alt` otherwise.\n\n    Note that `alt` should have the *same shape* as `x`.\n\n    # Arguments\n        x: What to return in test phase\n            (tensor or callable that returns a tensor).\n        alt: What to return otherwise\n            (tensor or callable that returns a tensor).\n        training: Optional scalar tensor\n            (or Python boolean, or Python integer)\n            specifying the learning phase.\n\n    # Returns\n        Either `x` or `alt` based on `K.learning_phase`.\n    \"\"\"\n    return in_train_phase(alt, x, training=training)",
                "def relu(x, alpha=0., max_value=None):\n    \"\"\"Rectified linear unit.\n\n    With default values, it returns element-wise `max(x, 0)`.\n\n    # Arguments\n        x: A tensor or variable.\n        alpha: A scalar, slope of negative section (default=`0.`).\n        max_value: Saturation threshold.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if alpha != 0.:\n        x = tf.nn.leaky_relu(x, alpha)\n    else:\n        x = tf.nn.relu(x)\n\n    if max_value is not None:\n        max_value = _to_tensor(max_value, x.dtype.base_dtype)\n        x = tf.minimum(x, max_value)\n    return x",
                "def elu(x, alpha=1.):\n    \"\"\"Exponential linear unit.\n\n    # Arguments\n        x: A tensor or variable to compute the activation function for.\n        alpha: A scalar, slope of negative section.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    res = tf.nn.elu(x)\n    if alpha == 1:\n        return res\n    else:\n        return tf.where(x > 0, res, alpha * res)",
                "def softmax(x, axis=-1):\n    \"\"\"Softmax of a tensor.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: The dimension softmax would be performed on.\n            The default is -1 which indicates the last dimension.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.nn.softmax(x, axis=axis)",
                "def softplus(x):\n    \"\"\"Softplus of a tensor.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.nn.softplus(x)",
                "def softsign(x):\n    \"\"\"Softsign of a tensor.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.nn.softsign(x)",
                "def categorical_crossentropy(target, output, from_logits=False):\n    \"\"\"Categorical crossentropy between an output tensor and a target tensor.\n\n    # Arguments\n        target: A tensor of the same shape as `output`.\n        output: A tensor resulting from a softmax\n            (unless `from_logits` is True, in which\n            case `output` is expected to be the logits).\n        from_logits: Boolean, whether `output` is the\n            result of a softmax, or is a tensor of logits.\n\n    # Returns\n        Output tensor.\n    \"\"\"\n    # Note: tf.nn.softmax_cross_entropy_with_logits\n    # expects logits, Keras expects probabilities.\n    if not from_logits:\n        # scale preds so that the class probas of each sample sum to 1\n        output /= tf.reduce_sum(output,\n                                len(output.get_shape()) - 1,\n                                True)\n        # manual computation of crossentropy\n        _epsilon = _to_tensor(epsilon(), output.dtype.base_dtype)\n        output = tf.clip_by_value(output, _epsilon, 1. - _epsilon)\n        return - tf.reduce_sum(target * tf.log(output),\n                               len(output.get_shape()) - 1)\n    else:\n        return tf.nn.softmax_cross_entropy_with_logits(labels=target,\n                                                       logits=output)",
                "def sparse_categorical_crossentropy(target, output, from_logits=False):\n    \"\"\"Categorical crossentropy with integer targets.\n\n    # Arguments\n        target: An integer tensor.\n        output: A tensor resulting from a softmax\n            (unless `from_logits` is True, in which\n            case `output` is expected to be the logits).\n        from_logits: Boolean, whether `output` is the\n            result of a softmax, or is a tensor of logits.\n\n    # Returns\n        Output tensor.\n    \"\"\"\n    # Note: tf.nn.sparse_softmax_cross_entropy_with_logits\n    # expects logits, Keras expects probabilities.\n    if not from_logits:\n        _epsilon = _to_tensor(epsilon(), output.dtype.base_dtype)\n        output = tf.clip_by_value(output, _epsilon, 1 - _epsilon)\n        output = tf.log(output)\n\n    output_shape = output.get_shape()\n    targets = cast(flatten(target), 'int64')\n    logits = tf.reshape(output, [-1, int(output_shape[-1])])\n    res = tf.nn.sparse_softmax_cross_entropy_with_logits(\n        labels=targets,\n        logits=logits)\n    if len(output_shape) >= 3:\n        # if our output includes timestep dimension\n        # or spatial dimensions we need to reshape\n        return tf.reshape(res, tf.shape(output)[:-1])\n    else:\n        return res",
                "def binary_crossentropy(target, output, from_logits=False):\n    \"\"\"Binary crossentropy between an output tensor and a target tensor.\n\n    # Arguments\n        target: A tensor with the same shape as `output`.\n        output: A tensor.\n        from_logits: Whether `output` is expected to be a logits tensor.\n            By default, we consider that `output`\n            encodes a probability distribution.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    # Note: tf.nn.sigmoid_cross_entropy_with_logits\n    # expects logits, Keras expects probabilities.\n    if not from_logits:\n        # transform back to logits\n        _epsilon = _to_tensor(epsilon(), output.dtype.base_dtype)\n        output = tf.clip_by_value(output, _epsilon, 1 - _epsilon)\n        output = tf.log(output / (1 - output))\n\n    return tf.nn.sigmoid_cross_entropy_with_logits(labels=target,\n                                                   logits=output)",
                "def sigmoid(x):\n    \"\"\"Element-wise sigmoid.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.nn.sigmoid(x)",
                "def hard_sigmoid(x):\n    \"\"\"Segment-wise linear approximation of sigmoid.\n\n    Faster than sigmoid.\n    Returns `0.` if `x < -2.5`, `1.` if `x > 2.5`.\n    In `-2.5 <= x <= 2.5`, returns `0.2 * x + 0.5`.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    x = (0.2 * x) + 0.5\n    zero = _to_tensor(0., x.dtype.base_dtype)\n    one = _to_tensor(1., x.dtype.base_dtype)\n    x = tf.clip_by_value(x, zero, one)\n    return x",
                "def tanh(x):\n    \"\"\"Element-wise tanh.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.nn.tanh(x)",
                "def dropout(x, level, noise_shape=None, seed=None):\n    \"\"\"Sets entries in `x` to zero at random, while scaling the entire tensor.\n\n    # Arguments\n        x: tensor\n        level: fraction of the entries in the tensor\n            that will be set to 0.\n        noise_shape: shape for randomly generated keep/drop flags,\n            must be broadcastable to the shape of `x`\n        seed: random seed to ensure determinism.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    retain_prob = 1. - level\n    if seed is None:\n        seed = np.random.randint(10e6)\n    # the dummy 1. works around a TF bug\n    # (float32_ref vs. float32 incompatibility)\n    return tf.nn.dropout(x * 1., retain_prob, noise_shape, seed=seed)",
                "def l2_normalize(x, axis=None):\n    \"\"\"Normalizes a tensor wrt the L2 norm alongside the specified axis.\n\n    # Arguments\n        x: Tensor or variable.\n        axis: axis along which to perform normalization.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.nn.l2_normalize(x, axis=axis)",
                "def in_top_k(predictions, targets, k):\n    \"\"\"Returns whether the `targets` are in the top `k` `predictions`.\n\n    # Arguments\n        predictions: A tensor of shape `(batch_size, classes)` and type `float32`.\n        targets: A 1D tensor of length `batch_size` and type `int32` or `int64`.\n        k: An `int`, number of top elements to consider.\n\n    # Returns\n        A 1D tensor of length `batch_size` and type `bool`.\n        `output[i]` is `True` if `predictions[i, targets[i]]` is within top-`k`\n        values of `predictions[i]`.\n    \"\"\"\n    return tf.nn.in_top_k(predictions, targets, k)",
                "def _preprocess_conv1d_input(x, data_format):\n    \"\"\"Transpose and cast the input before the conv1d.\n\n    # Arguments\n        x: input tensor.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if dtype(x) == 'float64':\n        x = tf.cast(x, 'float32')\n    tf_data_format = 'NHWC'  # to pass TF Conv2dNative operations\n    if data_format == 'channels_first':\n        if not _has_nchw_support():\n            x = tf.transpose(x, (0, 2, 1))  # NCW -> NWC\n        else:\n            tf_data_format = 'NCHW'\n    return x, tf_data_format",
                "def _preprocess_conv2d_input(x, data_format):\n    \"\"\"Transpose and cast the input before the conv2d.\n\n    # Arguments\n        x: input tensor.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if dtype(x) == 'float64':\n        x = tf.cast(x, 'float32')\n    tf_data_format = 'NHWC'\n    if data_format == 'channels_first':\n        if not _has_nchw_support():\n            x = tf.transpose(x, (0, 2, 3, 1))  # NCHW -> NHWC\n        else:\n            tf_data_format = 'NCHW'\n    return x, tf_data_format",
                "def _preprocess_conv3d_input(x, data_format):\n    \"\"\"Transpose and cast the input before the conv3d.\n\n    # Arguments\n        x: input tensor.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if dtype(x) == 'float64':\n        x = tf.cast(x, 'float32')\n    tf_data_format = 'NDHWC'\n    if data_format == 'channels_first':\n        if not _has_nchw_support():\n            x = tf.transpose(x, (0, 2, 3, 4, 1))\n        else:\n            tf_data_format = 'NCDHW'\n    return x, tf_data_format",
                "def _preprocess_padding(padding):\n    \"\"\"Convert keras' padding to tensorflow's padding.\n\n    # Arguments\n        padding: string, `\"same\"` or `\"valid\"`.\n\n    # Returns\n        a string, `\"SAME\"` or `\"VALID\"`.\n\n    # Raises\n        ValueError: if `padding` is invalid.\n    \"\"\"\n    if padding == 'same':\n        padding = 'SAME'\n    elif padding == 'valid':\n        padding = 'VALID'\n    else:\n        raise ValueError('Invalid padding: ' + str(padding))\n    return padding",
                "def conv1d(x, kernel, strides=1, padding='valid',\n           data_format=None, dilation_rate=1):\n    \"\"\"1D convolution.\n\n    # Arguments\n        x: Tensor or variable.\n        kernel: kernel tensor.\n        strides: stride integer.\n        padding: string, `\"same\"`, `\"causal\"` or `\"valid\"`.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n        dilation_rate: integer dilate rate.\n\n    # Returns\n        A tensor, result of 1D convolution.\n\n    # Raises\n        ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format: ' + str(data_format))\n\n    kernel_shape = kernel.get_shape().as_list()\n    if padding == 'causal':\n        # causal (dilated) convolution:\n        left_pad = dilation_rate * (kernel_shape[0] - 1)\n        x = temporal_padding(x, (left_pad, 0))\n        padding = 'valid'\n    padding = _preprocess_padding(padding)\n    if data_format == 'channels_last':\n        tf_data_format = 'NWC'\n    else:\n        tf_data_format = 'NCW'\n    x = tf.nn.convolution(\n        input=x,\n        filter=kernel,\n        dilation_rate=(dilation_rate,),\n        strides=(strides,),\n        padding=padding,\n        data_format=tf_data_format)\n    return x",
                "def conv2d(x, kernel, strides=(1, 1), padding='valid',\n           data_format=None, dilation_rate=(1, 1)):\n    \"\"\"2D convolution.\n\n    # Arguments\n        x: Tensor or variable.\n        kernel: kernel tensor.\n        strides: strides tuple.\n        padding: string, `\"same\"` or `\"valid\"`.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n            Whether to use Theano or TensorFlow/CNTK data format\n            for inputs/kernels/outputs.\n        dilation_rate: tuple of 2 integers.\n\n    # Returns\n        A tensor, result of 2D convolution.\n\n    # Raises\n        ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format: ' + str(data_format))\n\n    x, tf_data_format = _preprocess_conv2d_input(x, data_format)\n\n    padding = _preprocess_padding(padding)\n    x = tf.nn.convolution(\n        input=x,\n        filter=kernel,\n        dilation_rate=dilation_rate,\n        strides=strides,\n        padding=padding,\n        data_format=tf_data_format)\n\n    if data_format == 'channels_first' and tf_data_format == 'NHWC':\n        x = tf.transpose(x, (0, 3, 1, 2))  # NHWC -> NCHW\n    return x",
                "def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),\n                     padding='valid', data_format=None):\n    \"\"\"2D deconvolution (i.e. transposed convolution).\n\n    # Arguments\n        x: Tensor or variable.\n        kernel: kernel tensor.\n        output_shape: 1D int tensor for the output shape.\n        strides: strides tuple.\n        padding: string, `\"same\"` or `\"valid\"`.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n            Whether to use Theano or TensorFlow/CNTK data format\n            for inputs/kernels/outputs.\n\n    # Returns\n        A tensor, result of transposed 2D convolution.\n\n    # Raises\n        ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format: ' + str(data_format))\n    if isinstance(output_shape, (tuple, list)):\n        output_shape = tf.stack(output_shape)\n\n    x, tf_data_format = _preprocess_conv2d_input(x, data_format)\n\n    if data_format == 'channels_first' and tf_data_format == 'NHWC':\n        output_shape = (output_shape[0],\n                        output_shape[2],\n                        output_shape[3],\n                        output_shape[1])\n    if output_shape[0] is None:\n        output_shape = (tf.shape(x)[0],) + tuple(output_shape[1:])\n        output_shape = tf.stack(list(output_shape))\n\n    padding = _preprocess_padding(padding)\n    if tf_data_format == 'NHWC':\n        strides = (1,) + strides + (1,)\n    else:\n        strides = (1, 1) + strides\n\n    x = tf.nn.conv2d_transpose(x, kernel, output_shape, strides,\n                               padding=padding,\n                               data_format=tf_data_format)\n    if data_format == 'channels_first' and tf_data_format == 'NHWC':\n        x = tf.transpose(x, (0, 3, 1, 2))  # NHWC -> NCHW\n    return x",
                "def separable_conv1d(x, depthwise_kernel, pointwise_kernel, strides=1,\n                     padding='valid', data_format=None, dilation_rate=1):\n    \"\"\"1D convolution with separable filters.\n\n    # Arguments\n        x: input tensor\n        depthwise_kernel: convolution kernel for the depthwise convolution.\n        pointwise_kernel: kernel for the 1x1 convolution.\n        strides: stride integer.\n        padding: string, `\"same\"` or `\"valid\"`.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n        dilation_rate: integer dilation rate.\n\n    # Returns\n        Output tensor.\n\n    # Raises\n        ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format: ' + str(data_format))\n\n    x, tf_data_format = _preprocess_conv1d_input(x, data_format)\n    padding = _preprocess_padding(padding)\n    if tf_data_format == 'NHWC':\n        spatial_start_dim = 1\n        strides = (1,) + strides * 2 + (1,)\n    else:\n        spatial_start_dim = 2\n        strides = (1, 1) + strides * 2\n    x = tf.expand_dims(x, spatial_start_dim)\n    depthwise_kernel = tf.expand_dims(depthwise_kernel, 0)\n    pointwise_kernel = tf.expand_dims(pointwise_kernel, 0)\n    dilation_rate = (1,) + dilation_rate\n\n    x = tf.nn.separable_conv2d(x, depthwise_kernel, pointwise_kernel,\n                               strides=strides,\n                               padding=padding,\n                               rate=dilation_rate,\n                               data_format=tf_data_format)\n\n    x = tf.squeeze(x, [spatial_start_dim])\n\n    if data_format == 'channels_first' and tf_data_format == 'NHWC':\n        x = tf.transpose(x, (0, 2, 1))  # NWC -> NCW\n\n    return x",
                "def separable_conv2d(x, depthwise_kernel, pointwise_kernel, strides=(1, 1),\n                     padding='valid', data_format=None, dilation_rate=(1, 1)):\n    \"\"\"2D convolution with separable filters.\n\n    # Arguments\n        x: input tensor\n        depthwise_kernel: convolution kernel for the depthwise convolution.\n        pointwise_kernel: kernel for the 1x1 convolution.\n        strides: strides tuple (length 2).\n        padding: string, `\"same\"` or `\"valid\"`.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n        dilation_rate: tuple of integers,\n            dilation rates for the separable convolution.\n\n    # Returns\n        Output tensor.\n\n    # Raises\n        ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format: ' + str(data_format))\n\n    x, tf_data_format = _preprocess_conv2d_input(x, data_format)\n    padding = _preprocess_padding(padding)\n    if tf_data_format == 'NHWC':\n        strides = (1,) + strides + (1,)\n    else:\n        strides = (1, 1) + strides\n\n    x = tf.nn.separable_conv2d(x, depthwise_kernel, pointwise_kernel,\n                               strides=strides,\n                               padding=padding,\n                               rate=dilation_rate,\n                               data_format=tf_data_format)\n    if data_format == 'channels_first' and tf_data_format == 'NHWC':\n        x = tf.transpose(x, (0, 3, 1, 2))  # NHWC -> NCHW\n    return x",
                "def depthwise_conv2d(x, depthwise_kernel, strides=(1, 1), padding='valid',\n                     data_format=None, dilation_rate=(1, 1)):\n    \"\"\"2D convolution with separable filters.\n\n    # Arguments\n        x: input tensor\n        depthwise_kernel: convolution kernel for the depthwise convolution.\n        strides: strides tuple (length 2).\n        padding: string, `\"same\"` or `\"valid\"`.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n        dilation_rate: tuple of integers,\n            dilation rates for the separable convolution.\n\n    # Returns\n        Output tensor.\n\n    # Raises\n        ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format: ' + str(data_format))\n\n    x, tf_data_format = _preprocess_conv2d_input(x, data_format)\n    padding = _preprocess_padding(padding)\n    if tf_data_format == 'NHWC':\n        strides = (1,) + strides + (1,)\n    else:\n        strides = (1, 1) + strides\n\n    x = tf.nn.depthwise_conv2d(x, depthwise_kernel,\n                               strides=strides,\n                               padding=padding,\n                               rate=dilation_rate,\n                               data_format=tf_data_format)\n    if data_format == 'channels_first' and tf_data_format == 'NHWC':\n        x = tf.transpose(x, (0, 3, 1, 2))  # NHWC -> NCHW\n    return x",
                "def conv3d(x, kernel, strides=(1, 1, 1), padding='valid',\n           data_format=None, dilation_rate=(1, 1, 1)):\n    \"\"\"3D convolution.\n\n    # Arguments\n        x: Tensor or variable.\n        kernel: kernel tensor.\n        strides: strides tuple.\n        padding: string, `\"same\"` or `\"valid\"`.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n            Whether to use Theano or TensorFlow/CNTK data format\n            for inputs/kernels/outputs.\n        dilation_rate: tuple of 3 integers.\n\n    # Returns\n        A tensor, result of 3D convolution.\n\n    # Raises\n        ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format: ' + str(data_format))\n\n    x, tf_data_format = _preprocess_conv3d_input(x, data_format)\n    padding = _preprocess_padding(padding)\n    x = tf.nn.convolution(\n        input=x,\n        filter=kernel,\n        dilation_rate=dilation_rate,\n        strides=strides,\n        padding=padding,\n        data_format=tf_data_format)\n    if data_format == 'channels_first' and tf_data_format == 'NDHWC':\n        x = tf.transpose(x, (0, 4, 1, 2, 3))\n    return x",
                "def conv3d_transpose(x, kernel, output_shape, strides=(1, 1, 1),\n                     padding='valid', data_format=None):\n    \"\"\"3D deconvolution (i.e. transposed convolution).\n\n    # Arguments\n        x: input tensor.\n        kernel: kernel tensor.\n        output_shape: 1D int tensor for the output shape.\n        strides: strides tuple.\n        padding: string, \"same\" or \"valid\".\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n            Whether to use Theano or TensorFlow/CNTK data format\n            for inputs/kernels/outputs.\n\n    # Returns\n        A tensor, result of transposed 3D convolution.\n\n    # Raises\n        ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format: ' + str(data_format))\n    if isinstance(output_shape, (tuple, list)):\n        output_shape = tf.stack(output_shape)\n\n    x, tf_data_format = _preprocess_conv3d_input(x, data_format)\n\n    if data_format == 'channels_first' and tf_data_format == 'NDHWC':\n        output_shape = (output_shape[0],\n                        output_shape[2],\n                        output_shape[3],\n                        output_shape[4],\n                        output_shape[1])\n    if output_shape[0] is None:\n        output_shape = (tf.shape(x)[0],) + tuple(output_shape[1:])\n        output_shape = tf.stack(list(output_shape))\n\n    padding = _preprocess_padding(padding)\n    if tf_data_format == 'NDHWC':\n        strides = (1,) + strides + (1,)\n    else:\n        strides = (1, 1) + strides\n\n    x = tf.nn.conv3d_transpose(x, kernel, output_shape, strides,\n                               padding=padding,\n                               data_format=tf_data_format)\n    if data_format == 'channels_first' and tf_data_format == 'NDHWC':\n        x = tf.transpose(x, (0, 4, 1, 2, 3))\n    return x",
                "def pool2d(x, pool_size, strides=(1, 1),\n           padding='valid', data_format=None,\n           pool_mode='max'):\n    \"\"\"2D Pooling.\n\n    # Arguments\n        x: Tensor or variable.\n        pool_size: tuple of 2 integers.\n        strides: tuple of 2 integers.\n        padding: string, `\"same\"` or `\"valid\"`.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n        pool_mode: string, `\"max\"` or `\"avg\"`.\n\n    # Returns\n        A tensor, result of 2D pooling.\n\n    # Raises\n        ValueError: if `data_format` is neither `\"channels_last\"` or `\"channels_first\"`.\n        ValueError: if `pool_mode` is neither `\"max\"` or `\"avg\"`.\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format: ' + str(data_format))\n\n    x, tf_data_format = _preprocess_conv2d_input(x, data_format)\n    padding = _preprocess_padding(padding)\n    if tf_data_format == 'NHWC':\n        strides = (1,) + strides + (1,)\n        pool_size = (1,) + pool_size + (1,)\n    else:\n        strides = (1, 1) + strides\n        pool_size = (1, 1) + pool_size\n\n    if pool_mode == 'max':\n        x = tf.nn.max_pool(x, pool_size, strides,\n                           padding=padding,\n                           data_format=tf_data_format)\n    elif pool_mode == 'avg':\n        x = tf.nn.avg_pool(x, pool_size, strides,\n                           padding=padding,\n                           data_format=tf_data_format)\n    else:\n        raise ValueError('Invalid pool_mode: ' + str(pool_mode))\n\n    if data_format == 'channels_first' and tf_data_format == 'NHWC':\n        x = tf.transpose(x, (0, 3, 1, 2))  # NHWC -> NCHW\n    return x",
                "def pool3d(x, pool_size, strides=(1, 1, 1), padding='valid',\n           data_format=None, pool_mode='max'):\n    \"\"\"3D Pooling.\n\n    # Arguments\n        x: Tensor or variable.\n        pool_size: tuple of 3 integers.\n        strides: tuple of 3 integers.\n        padding: string, `\"same\"` or `\"valid\"`.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n        pool_mode: string, `\"max\"` or `\"avg\"`.\n\n    # Returns\n        A tensor, result of 3D pooling.\n\n    # Raises\n        ValueError: if `data_format` is neither `\"channels_last\"` or `\"channels_first\"`.\n        ValueError: if `pool_mode` is neither `\"max\"` or `\"avg\"`.\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format: ' + str(data_format))\n\n    x, tf_data_format = _preprocess_conv3d_input(x, data_format)\n    padding = _preprocess_padding(padding)\n    if tf_data_format == 'NDHWC':\n        strides = (1,) + strides + (1,)\n        pool_size = (1,) + pool_size + (1,)\n    else:\n        strides = (1, 1) + strides\n        pool_size = (1, 1) + pool_size\n\n    if pool_mode == 'max':\n        x = tf.nn.max_pool3d(x, pool_size, strides,\n                             padding=padding,\n                             data_format=tf_data_format)\n    elif pool_mode == 'avg':\n        x = tf.nn.avg_pool3d(x, pool_size, strides,\n                             padding=padding,\n                             data_format=tf_data_format)\n    else:\n        raise ValueError('Invalid pool_mode: ' + str(pool_mode))\n\n    if data_format == 'channels_first' and tf_data_format == 'NDHWC':\n        x = tf.transpose(x, (0, 4, 1, 2, 3))\n    return x",
                "def bias_add(x, bias, data_format=None):\n    \"\"\"Adds a bias vector to a tensor.\n\n    # Arguments\n        x: Tensor or variable.\n        bias: Bias tensor to add.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n\n    # Returns\n        Output tensor.\n\n    # Raises\n        ValueError: In one of the two cases below:\n                    1. invalid `data_format` argument.\n                    2. invalid bias shape.\n                       the bias should be either a vector or\n                       a tensor with ndim(x) - 1 dimension\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format: ' + str(data_format))\n    bias_shape = int_shape(bias)\n    if len(bias_shape) != 1 and len(bias_shape) != ndim(x) - 1:\n        raise ValueError('Unexpected bias dimensions %d, expect to be 1 or %d dimensions'\n                         % (len(bias_shape), ndim(x)))\n    if ndim(x) == 5:\n        if data_format == 'channels_first':\n            if len(bias_shape) == 1:\n                x += reshape(bias, (1, bias_shape[0], 1, 1, 1))\n            else:\n                x += reshape(bias, (1, bias_shape[3]) + bias_shape[:3])\n        elif data_format == 'channels_last':\n            if len(bias_shape) == 1:\n                x += reshape(bias, (1, 1, 1, bias_shape[0]))\n            else:\n                x += reshape(bias, (1,) + bias_shape)\n    elif ndim(x) == 4:\n        if data_format == 'channels_first':\n            if len(bias_shape) == 1:\n                if _has_nchw_support():\n                    x = tf.nn.bias_add(x, bias,\n                                       data_format='NCHW')\n                else:\n                    x += reshape(bias, (1, bias_shape[0], 1, 1))\n            else:\n                x += reshape(bias, (1, bias_shape[2]) + bias_shape[:2])\n        elif data_format == 'channels_last':\n            if len(bias_shape) == 1:\n                x = tf.nn.bias_add(x, bias,\n                                   data_format='NHWC')\n            else:\n                x += reshape(bias, (1,) + bias_shape)\n    elif ndim(x) == 3:\n        if data_format == 'channels_first':\n            if len(bias_shape) == 1:\n                x += reshape(bias, (1, bias_shape[0], 1))\n            else:\n                x += reshape(bias, (1, bias_shape[1], bias_shape[0]))\n        elif data_format == 'channels_last':\n            if len(bias_shape) == 1:\n                x += reshape(bias, (1, 1, bias_shape[0]))\n            else:\n                x += reshape(bias, (1, ) + bias_shape)\n    else:\n        x = tf.nn.bias_add(x, bias)\n    return x",
                "def random_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n    \"\"\"Returns a tensor with normal distribution of values.\n\n    # Arguments\n        shape: A tuple of integers, the shape of tensor to create.\n        mean: A float, mean of the normal distribution to draw samples.\n        stddev: A float, standard deviation of the normal distribution\n            to draw samples.\n        dtype: String, dtype of returned tensor.\n        seed: Integer, random seed.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    if seed is None:\n        seed = np.random.randint(10e6)\n    return tf.random_normal(shape, mean=mean, stddev=stddev,\n                            dtype=dtype, seed=seed)",
                "def random_uniform(shape, minval=0.0, maxval=1.0, dtype=None, seed=None):\n    \"\"\"Returns a tensor with uniform distribution of values.\n\n    # Arguments\n        shape: A tuple of integers, the shape of tensor to create.\n        minval: A float, lower boundary of the uniform distribution\n            to draw samples.\n        maxval: A float, upper boundary of the uniform distribution\n            to draw samples.\n        dtype: String, dtype of returned tensor.\n        seed: Integer, random seed.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    if seed is None:\n        seed = np.random.randint(10e6)\n    return tf.random_uniform(shape, minval=minval, maxval=maxval,\n                             dtype=dtype, seed=seed)",
                "def random_binomial(shape, p=0.0, dtype=None, seed=None):\n    \"\"\"Returns a tensor with random binomial distribution of values.\n\n    # Arguments\n        shape: A tuple of integers, the shape of tensor to create.\n        p: A float, `0. <= p <= 1`, probability of binomial distribution.\n        dtype: String, dtype of returned tensor.\n        seed: Integer, random seed.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    if seed is None:\n        seed = np.random.randint(10e6)\n    return tf.where(tf.random_uniform(shape, dtype=dtype, seed=seed) <= p,\n                    tf.ones(shape, dtype=dtype),\n                    tf.zeros(shape, dtype=dtype))",
                "def truncated_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n    \"\"\"Returns a tensor with truncated random normal distribution of values.\n\n    The generated values follow a normal distribution\n    with specified mean and standard deviation,\n    except that values whose magnitude is more than\n    two standard deviations from the mean are dropped and re-picked.\n\n    # Arguments\n        shape: A tuple of integers, the shape of tensor to create.\n        mean: Mean of the values.\n        stddev: Standard deviation of the values.\n        dtype: String, dtype of returned tensor.\n        seed: Integer, random seed.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    if seed is None:\n        seed = np.random.randint(10e6)\n    return tf.truncated_normal(shape, mean, stddev, dtype=dtype, seed=seed)",
                "def ctc_label_dense_to_sparse(labels, label_lengths):\n    \"\"\"Converts CTC labels from dense to sparse.\n\n    # Arguments\n        labels: dense CTC labels.\n        label_lengths: length of the labels.\n\n    # Returns\n        A sparse tensor representation of the labels.\n    \"\"\"\n    label_shape = tf.shape(labels)\n    num_batches_tns = tf.stack([label_shape[0]])\n    max_num_labels_tns = tf.stack([label_shape[1]])\n\n    def range_less_than(_, current_input):\n        return tf.expand_dims(tf.range(label_shape[1]), 0) < tf.fill(\n            max_num_labels_tns, current_input)\n\n    init = tf.cast(tf.fill([1, label_shape[1]], 0), tf.bool)\n    dense_mask = functional_ops.scan(range_less_than, label_lengths,\n                                     initializer=init, parallel_iterations=1)\n    dense_mask = dense_mask[:, 0, :]\n\n    label_array = tf.reshape(tf.tile(tf.range(label_shape[1]), num_batches_tns),\n                             label_shape)\n    label_ind = tf.boolean_mask(label_array, dense_mask)\n\n    batch_array = tf.transpose(tf.reshape(tf.tile(tf.range(label_shape[0]),\n                                                  max_num_labels_tns), reverse(label_shape, 0)))\n    batch_ind = tf.boolean_mask(batch_array, dense_mask)\n    indices = tf.transpose(tf.reshape(concatenate([batch_ind, label_ind], axis=0), [2, -1]))\n\n    vals_sparse = tf.gather_nd(labels, indices)\n\n    return tf.SparseTensor(tf.to_int64(indices), vals_sparse, tf.to_int64(label_shape))",
                "def ctc_batch_cost(y_true, y_pred, input_length, label_length):\n    \"\"\"Runs CTC loss algorithm on each batch element.\n\n    # Arguments\n        y_true: tensor `(samples, max_string_length)`\n            containing the truth labels.\n        y_pred: tensor `(samples, time_steps, num_categories)`\n            containing the prediction, or output of the softmax.\n        input_length: tensor `(samples, 1)` containing the sequence length for\n            each batch item in `y_pred`.\n        label_length: tensor `(samples, 1)` containing the sequence length for\n            each batch item in `y_true`.\n\n    # Returns\n        Tensor with shape (samples,1) containing the\n            CTC loss of each element.\n    \"\"\"\n    label_length = tf.to_int32(tf.squeeze(label_length))\n    input_length = tf.to_int32(tf.squeeze(input_length))\n    sparse_labels = tf.to_int32(ctc_label_dense_to_sparse(y_true, label_length))\n\n    y_pred = tf.log(tf.transpose(y_pred, perm=[1, 0, 2]) + epsilon())\n\n    return tf.expand_dims(ctc.ctc_loss(inputs=y_pred,\n                                       labels=sparse_labels,\n                                       sequence_length=input_length), 1)",
                "def ctc_decode(y_pred, input_length, greedy=True, beam_width=100,\n               top_paths=1):\n    \"\"\"Decodes the output of a softmax.\n\n    Can use either greedy search (also known as best path)\n    or a constrained dictionary search.\n\n    # Arguments\n        y_pred: tensor `(samples, time_steps, num_categories)`\n            containing the prediction, or output of the softmax.\n        input_length: tensor `(samples, )` containing the sequence length for\n            each batch item in `y_pred`.\n        greedy: perform much faster best-path search if `true`.\n            This does not use a dictionary.\n        beam_width: if `greedy` is `false`: a beam search decoder will be used\n            with a beam of this width.\n        top_paths: if `greedy` is `false`,\n            how many of the most probable paths will be returned.\n\n    # Returns\n        Tuple:\n            List: if `greedy` is `true`, returns a list of one element that\n                contains the decoded sequence.\n                If `false`, returns the `top_paths` most probable\n                decoded sequences.\n                Important: blank labels are returned as `-1`.\n            Tensor `(top_paths, )` that contains\n                the log probability of each decoded sequence.\n    \"\"\"\n    y_pred = tf.log(tf.transpose(y_pred, perm=[1, 0, 2]) + epsilon())\n    input_length = tf.to_int32(input_length)\n\n    if greedy:\n        (decoded, log_prob) = ctc.ctc_greedy_decoder(\n            inputs=y_pred,\n            sequence_length=input_length)\n    else:\n        (decoded, log_prob) = ctc.ctc_beam_search_decoder(\n            inputs=y_pred,\n            sequence_length=input_length, beam_width=beam_width,\n            top_paths=top_paths)\n\n    decoded_dense = [tf.sparse_to_dense(st.indices, st.dense_shape, st.values, default_value=-1)\n                     for st in decoded]\n    return (decoded_dense, log_prob)",
                "def map_fn(fn, elems, name=None, dtype=None):\n    \"\"\"Map the function fn over the elements elems and return the outputs.\n\n    # Arguments\n        fn: Callable that will be called upon each element in elems\n        elems: tensor\n        name: A string name for the map node in the graph\n        dtype: Output data type.\n\n    # Returns\n        Tensor with dtype `dtype`.\n    \"\"\"\n    return tf.map_fn(fn, elems, name=name, dtype=dtype)",
                "def foldl(fn, elems, initializer=None, name=None):\n    \"\"\"Reduce elems using fn to combine them from left to right.\n\n    # Arguments\n        fn: Callable that will be called upon each element in elems and an\n            accumulator, for instance `lambda acc, x: acc + x`\n        elems: tensor\n        initializer: The first value used (`elems[0]` in case of None)\n        name: A string name for the foldl node in the graph\n\n    # Returns\n        Tensor with same type and shape as `initializer`.\n    \"\"\"\n    return tf.foldl(fn, elems, initializer=initializer, name=name)",
                "def foldr(fn, elems, initializer=None, name=None):\n    \"\"\"Reduce elems using fn to combine them from right to left.\n\n    # Arguments\n        fn: Callable that will be called upon each element in elems and an\n            accumulator, for instance `lambda acc, x: acc + x`\n        elems: tensor\n        initializer: The first value used (`elems[-1]` in case of None)\n        name: A string name for the foldr node in the graph\n\n    # Returns\n        Tensor with same type and shape as `initializer`.\n    \"\"\"\n    return tf.foldr(fn, elems, initializer=initializer, name=name)",
                "def local_conv1d(inputs, kernel, kernel_size, strides, data_format=None):\n    \"\"\"Apply 1D conv with un-shared weights.\n\n    # Arguments\n        inputs: 3D tensor with shape: (batch_size, steps, input_dim)\n        kernel: the unshared weight for convolution,\n                with shape (output_length, feature_dim, filters)\n        kernel_size: a tuple of a single integer,\n                     specifying the length of the 1D convolution window\n        strides: a tuple of a single integer,\n                 specifying the stride length of the convolution\n        data_format: the data format, channels_first or channels_last\n\n    # Returns\n        the tensor after 1d conv with un-shared weights, with shape (batch_size, output_length, filters)\n\n    # Raises\n        ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format: ' + str(data_format))\n\n    stride = strides[0]\n    kernel_shape = int_shape(kernel)\n    output_length, feature_dim, filters = kernel_shape\n\n    xs = []\n    for i in range(output_length):\n        slice_length = slice(i * stride,\n                             i * stride + kernel_size[0])\n        xs.append(reshape(inputs[:, slice_length, :],\n                          (1, -1, feature_dim)))\n    x_aggregate = concatenate(xs, axis=0)\n    # Shape: `(output_length, batch_size, filters)`.\n    output = batch_dot(x_aggregate, kernel)\n    return permute_dimensions(output, (1, 0, 2))",
                "def local_conv2d(inputs, kernel, kernel_size, strides, output_shape, data_format=None):\n    \"\"\"Apply 2D conv with un-shared weights.\n\n    # Arguments\n        inputs: 4D tensor with shape:\n                (batch_size, filters, new_rows, new_cols)\n                if data_format='channels_first'\n                or 4D tensor with shape:\n                (batch_size, new_rows, new_cols, filters)\n                if data_format='channels_last'.\n        kernel: the unshared weight for convolution,\n                with shape (output_items, feature_dim, filters)\n        kernel_size: a tuple of 2 integers, specifying the\n                     width and height of the 2D convolution window.\n        strides: a tuple of 2 integers, specifying the strides\n                 of the convolution along the width and height.\n        output_shape: a tuple with (output_row, output_col)\n        data_format: the data format, channels_first or channels_last\n\n    # Returns\n        A 4d tensor with shape:\n        (batch_size, filters, new_rows, new_cols)\n        if data_format='channels_first'\n        or 4D tensor with shape:\n        (batch_size, new_rows, new_cols, filters)\n        if data_format='channels_last'.\n\n    # Raises\n        ValueError: if `data_format` is neither\n                    `channels_last` or `channels_first`.\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format: ' + str(data_format))\n\n    stride_row, stride_col = strides\n    output_row, output_col = output_shape\n    kernel_shape = int_shape(kernel)\n    _, feature_dim, filters = kernel_shape\n\n    xs = []\n    for i in range(output_row):\n        for j in range(output_col):\n            slice_row = slice(i * stride_row,\n                              i * stride_row + kernel_size[0])\n            slice_col = slice(j * stride_col,\n                              j * stride_col + kernel_size[1])\n            if data_format == 'channels_first':\n                xs.append(reshape(inputs[:, :, slice_row, slice_col],\n                                  (1, -1, feature_dim)))\n            else:\n                xs.append(reshape(inputs[:, slice_row, slice_col, :],\n                                  (1, -1, feature_dim)))\n\n    x_aggregate = concatenate(xs, axis=0)\n    output = batch_dot(x_aggregate, kernel)\n    output = reshape(output,\n                     (output_row, output_col, -1, filters))\n\n    if data_format == 'channels_first':\n        output = permute_dimensions(output, (2, 3, 0, 1))\n    else:\n        output = permute_dimensions(output, (2, 0, 1, 3))\n    return output",
                "def __init__(self):\n    self.device = None",
                "def _set_device(self, device):\n    \"\"\"This method captures TF's explicit device scope setting.\"\"\"\n    self.device = device",
                "def __init__(self, inputs, outputs, updates=None, name=None, **session_kwargs):\n    updates = updates or []\n    if not isinstance(inputs, (list, tuple)):\n        raise TypeError('`inputs` to a TensorFlow backend function '\n                        'should be a list or tuple.')\n    if not isinstance(outputs, (list, tuple)):\n        raise TypeError('`outputs` of a TensorFlow backend function '\n                        'should be a list or tuple.')\n    if not isinstance(updates, (list, tuple)):\n        raise TypeError('`updates` in a TensorFlow backend function '\n                        'should be a list or tuple.')\n    self.inputs = list(inputs)\n    self.outputs = list(outputs)\n    with tf.control_dependencies(self.outputs):\n        updates_ops = []\n        for update in updates:\n            if isinstance(update, tuple):\n                p, new_p = update\n                updates_ops.append(tf.assign(p, new_p))\n            else:\n                # assumed already an op\n                updates_ops.append(update)\n        self.updates_op = tf.group(*updates_ops)\n    self.name = name\n    # additional tensor substitutions\n    self.feed_dict = session_kwargs.pop('feed_dict', {})\n    # additional operations\n    self.fetches = session_kwargs.pop('fetches', [])\n    if not isinstance(self.fetches, list):\n        self.fetches = [self.fetches]\n    self.session_kwargs = session_kwargs",
                "def __call__(self, inputs):\n    if not isinstance(inputs, (list, tuple)):\n        raise TypeError('`inputs` should be a list or tuple.')\n    feed_dict = self.feed_dict.copy()\n    for tensor, value in zip(self.inputs, inputs):\n        if is_sparse(tensor):\n            sparse_coo = value.tocoo()\n            indices = np.concatenate((np.expand_dims(sparse_coo.row, 1),\n                                      np.expand_dims(sparse_coo.col, 1)), 1)\n            value = (indices, sparse_coo.data, sparse_coo.shape)\n        feed_dict[tensor] = value\n    fetches = self.outputs + [self.updates_op] + self.fetches\n    session = get_session()\n    updated = session.run(fetches=fetches, feed_dict=feed_dict,\n                          **self.session_kwargs)\n    return updated[:len(self.outputs)]",
                "def range_less_than(_, current_input):\n    return tf.expand_dims(tf.range(label_shape[1]), 0) < tf.fill(\n        max_num_labels_tns, current_input)",
                "def _step(time, output_ta_t, *states):\n    \"\"\"RNN step function.\n\n    # Arguments\n        time: Current timestep value.\n        output_ta_t: TensorArray.\n        *states: List of states.\n\n    # Returns\n        Tuple: `(time + 1,output_ta_t) + tuple(new_states)`\n    \"\"\"\n    current_input = input_ta.read(time)\n    mask_t = mask_ta.read(time)\n    output, new_states = step_function(current_input,\n                                       tuple(states) +\n                                       tuple(constants))\n    if getattr(output, '_uses_learning_phase', False):\n        global uses_learning_phase\n        uses_learning_phase = True\n    for state, new_state in zip(states, new_states):\n        new_state.set_shape(state.get_shape())\n    tiled_mask_t = tf.tile(mask_t,\n                           tf.stack([1, tf.shape(output)[1]]))\n    output = tf.where(tiled_mask_t, output, states[0])\n    new_states = [tf.where(tiled_mask_t, new_states[i], states[i]) for i in range(len(states))]\n    output_ta_t = output_ta_t.write(time, output)\n    return (time + 1, output_ta_t) + tuple(new_states)",
                "def _step(time, output_ta_t, *states):\n    \"\"\"RNN step function.\n\n    # Arguments\n        time: Current timestep value.\n        output_ta_t: TensorArray.\n        *states: List of states.\n\n    # Returns\n        Tuple: `(time + 1,output_ta_t) + tuple(new_states)`\n    \"\"\"\n    current_input = input_ta.read(time)\n    output, new_states = step_function(current_input,\n                                       tuple(states) +\n                                       tuple(constants))\n    if getattr(output, '_uses_learning_phase', False):\n        global uses_learning_phase\n        uses_learning_phase = True\n    for state, new_state in zip(states, new_states):\n        new_state.set_shape(state.get_shape())\n    output_ta_t = output_ta_t.write(time, output)\n    return (time + 1, output_ta_t) + tuple(new_states)",
                "def then_expression_fn():\n    return then_expression",
                "def else_expression_fn():\n    return else_expression"
            ],
            "inscope_function_signatures": [
                "get_uid(prefix='')",
                "reset_uids()",
                "clear_session()",
                "manual_variable_initialization(value)",
                "learning_phase()",
                "set_learning_phase(value)",
                "get_session()",
                "set_session(session)",
                "_get_current_tf_device()",
                "_is_current_explicit_device(device_type)",
                "_get_available_gpus()",
                "_has_nchw_support()",
                "_to_tensor(x, dtype)",
                "is_sparse(tensor)",
                "to_dense(tensor)",
                "variable(value, dtype=None, name=None, constraint=None)",
                "constant(value, dtype=None, shape=None, name=None)",
                "is_keras_tensor(x)",
                "placeholder(shape=None, ndim=None, dtype=None, sparse=False, name=None)",
                "is_placeholder(x)",
                "shape(x)",
                "int_shape(x)",
                "ndim(x)",
                "dtype(x)",
                "eval(x)",
                "zeros(shape, dtype=None, name=None)",
                "ones(shape, dtype=None, name=None)",
                "eye(size, dtype=None, name=None)",
                "zeros_like(x, dtype=None, name=None)",
                "ones_like(x, dtype=None, name=None)",
                "identity(x, name=None)",
                "random_uniform_variable(shape, low, high, dtype=None, name=None, seed=None)",
                "random_normal_variable(shape, mean, scale, dtype=None, name=None, seed=None)",
                "count_params(x)",
                "cast(x, dtype)",
                "update(x, new_x)",
                "update_add(x, increment)",
                "update_sub(x, decrement)",
                "moving_average_update(x, value, momentum)",
                "dot(x, y)",
                "batch_dot(x, y, axes=None)",
                "transpose(x)",
                "gather(reference, indices)",
                "max(x, axis=None, keepdims=False)",
                "min(x, axis=None, keepdims=False)",
                "sum(x, axis=None, keepdims=False)",
                "prod(x, axis=None, keepdims=False)",
                "cumsum(x, axis=0)",
                "cumprod(x, axis=0)",
                "var(x, axis=None, keepdims=False)",
                "std(x, axis=None, keepdims=False)",
                "mean(x, axis=None, keepdims=False)",
                "any(x, axis=None, keepdims=False)",
                "all(x, axis=None, keepdims=False)",
                "argmax(x, axis=-1)",
                "argmin(x, axis=-1)",
                "square(x)",
                "abs(x)",
                "sqrt(x)",
                "exp(x)",
                "log(x)",
                "logsumexp(x, axis=None, keepdims=False)",
                "round(x)",
                "sign(x)",
                "pow(x, a)",
                "clip(x, min_value, max_value)",
                "equal(x, y)",
                "not_equal(x, y)",
                "greater(x, y)",
                "greater_equal(x, y)",
                "less(x, y)",
                "less_equal(x, y)",
                "maximum(x, y)",
                "minimum(x, y)",
                "sin(x)",
                "cos(x)",
                "_regular_normalize_batch_in_training(x, gamma, beta, reduction_axes, epsilon=0.001)",
                "_broadcast_normalize_batch_in_training(x, gamma, beta, reduction_axes, epsilon=0.001)",
                "_fused_normalize_batch_in_training(x, gamma, beta, reduction_axes, epsilon=0.001)",
                "normalize_batch_in_training(x, gamma, beta, reduction_axes, epsilon=0.001)",
                "batch_normalization(x, mean, var, beta, gamma, epsilon=0.001)",
                "concatenate(tensors, axis=-1)",
                "reshape(x, shape)",
                "permute_dimensions(x, pattern)",
                "resize_images(x, height_factor, width_factor, data_format)",
                "resize_volumes(x, depth_factor, height_factor, width_factor, data_format)",
                "repeat_elements(x, rep, axis)",
                "repeat(x, n)",
                "arange(start, stop=None, step=1, dtype='int32')",
                "tile(x, n)",
                "flatten(x)",
                "batch_flatten(x)",
                "expand_dims(x, axis=-1)",
                "squeeze(x, axis)",
                "temporal_padding(x, padding=(1, 1))",
                "spatial_2d_padding(x, padding=((1, 1), (1, 1)), data_format=None)",
                "spatial_3d_padding(x, padding=((1, 1), (1, 1), (1, 1)), data_format=None)",
                "stack(x, axis=0)",
                "one_hot(indices, num_classes)",
                "reverse(x, axes)",
                "get_value(x)",
                "batch_get_value(ops)",
                "set_value(x, value)",
                "batch_set_value(tuples)",
                "get_variable_shape(x)",
                "print_tensor(x, message='')",
                "function(inputs, outputs, updates=None, **kwargs)",
                "gradients(loss, variables)",
                "stop_gradient(variables)",
                "rnn(step_function, inputs, initial_states, go_backwards=False, mask=None, constants=None, unroll=False, input_length=None)",
                "switch(condition, then_expression, else_expression)",
                "in_train_phase(x, alt, training=None)",
                "in_test_phase(x, alt, training=None)",
                "relu(x, alpha=0.0, max_value=None)",
                "elu(x, alpha=1.0)",
                "softmax(x, axis=-1)",
                "softplus(x)",
                "softsign(x)",
                "categorical_crossentropy(target, output, from_logits=False)",
                "sparse_categorical_crossentropy(target, output, from_logits=False)",
                "binary_crossentropy(target, output, from_logits=False)",
                "sigmoid(x)",
                "hard_sigmoid(x)",
                "tanh(x)",
                "dropout(x, level, noise_shape=None, seed=None)",
                "l2_normalize(x, axis=None)",
                "in_top_k(predictions, targets, k)",
                "_preprocess_conv1d_input(x, data_format)",
                "_preprocess_conv2d_input(x, data_format)",
                "_preprocess_conv3d_input(x, data_format)",
                "_preprocess_padding(padding)",
                "conv1d(x, kernel, strides=1, padding='valid', data_format=None, dilation_rate=1)",
                "conv2d(x, kernel, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1))",
                "conv2d_transpose(x, kernel, output_shape, strides=(1, 1), padding='valid', data_format=None)",
                "separable_conv1d(x, depthwise_kernel, pointwise_kernel, strides=1, padding='valid', data_format=None, dilation_rate=1)",
                "separable_conv2d(x, depthwise_kernel, pointwise_kernel, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1))",
                "depthwise_conv2d(x, depthwise_kernel, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1))",
                "conv3d(x, kernel, strides=(1, 1, 1), padding='valid', data_format=None, dilation_rate=(1, 1, 1))",
                "conv3d_transpose(x, kernel, output_shape, strides=(1, 1, 1), padding='valid', data_format=None)",
                "pool2d(x, pool_size, strides=(1, 1), padding='valid', data_format=None, pool_mode='max')",
                "pool3d(x, pool_size, strides=(1, 1, 1), padding='valid', data_format=None, pool_mode='max')",
                "bias_add(x, bias, data_format=None)",
                "random_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None)",
                "random_uniform(shape, minval=0.0, maxval=1.0, dtype=None, seed=None)",
                "random_binomial(shape, p=0.0, dtype=None, seed=None)",
                "truncated_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None)",
                "ctc_label_dense_to_sparse(labels, label_lengths)",
                "ctc_batch_cost(y_true, y_pred, input_length, label_length)",
                "ctc_decode(y_pred, input_length, greedy=True, beam_width=100, top_paths=1)",
                "map_fn(fn, elems, name=None, dtype=None)",
                "foldl(fn, elems, initializer=None, name=None)",
                "foldr(fn, elems, initializer=None, name=None)",
                "local_conv1d(inputs, kernel, kernel_size, strides, data_format=None)",
                "local_conv2d(inputs, kernel, kernel_size, strides, output_shape, data_format=None)",
                "__init__(self)",
                "_set_device(self, device)",
                "__init__(self, inputs, outputs, updates=None, name=None, **session_kwargs)",
                "__call__(self, inputs)",
                "range_less_than(_, current_input)",
                "_step(time, output_ta_t, *states)",
                "_step(time, output_ta_t, *states)",
                "then_expression_fn()",
                "else_expression_fn()"
            ],
            "variables_in_file": {
                "py_all": [
                    27,
                    726,
                    694,
                    1879
                ],
                "all": [
                    27
                ],
                "py_sum": [
                    28
                ],
                "sum": [
                    28
                ],
                "_SESSION": [
                    34,
                    173,
                    180,
                    181,
                    215,
                    91
                ],
                "_GRAPH_LEARNING_PHASES": [
                    96,
                    130,
                    131,
                    39,
                    147,
                    126,
                    95
                ],
                "_GRAPH_UID_DICTS": [
                    69,
                    70,
                    71,
                    72,
                    45,
                    79
                ],
                "_MANUAL_VAR_INIT": [
                    112,
                    50,
                    182
                ],
                "_LOCAL_DEVICES": [
                    272,
                    273,
                    271,
                    55
                ],
                "graph": [
                    130,
                    131,
                    68,
                    69,
                    70,
                    71,
                    72,
                    125,
                    126
                ],
                "tf.get_default_graph": [
                    96,
                    68,
                    239,
                    147,
                    125
                ],
                "tf": [
                    3072,
                    3074,
                    1547,
                    3595,
                    3087,
                    3606,
                    3607,
                    2075,
                    2076,
                    1054,
                    1567,
                    2079,
                    3615,
                    2594,
                    3106,
                    3619,
                    1061,
                    2597,
                    2598,
                    2601,
                    1580,
                    557,
                    1069,
                    1071,
                    1070,
                    2044,
                    1074,
                    2098,
                    1076,
                    3119,
                    1593,
                    2617,
                    2110,
                    2622,
                    68,
                    3141,
                    1606,
                    3658,
                    2124,
                    3662,
                    2641,
                    2642,
                    1619,
                    3154,
                    3669,
                    89,
                    2138,
                    2649,
                    92,
                    2654,
                    2655,
                    96,
                    1632,
                    2656,
                    3170,
                    2151,
                    2664,
                    1645,
                    1137,
                    2674,
                    3187,
                    1140,
                    2167,
                    3191,
                    1145,
                    1658,
                    1147,
                    2682,
                    125,
                    3707,
                    127,
                    3711,
                    1155,
                    2693,
                    3718,
                    1671,
                    3208,
                    1161,
                    3212,
                    147,
                    1683,
                    2707,
                    2201,
                    3229,
                    1695,
                    3233,
                    168,
                    2733,
                    2734,
                    1199,
                    175,
                    1713,
                    178,
                    1715,
                    180,
                    692,
                    693,
                    2735,
                    184,
                    2736,
                    3763,
                    3771,
                    1212,
                    193,
                    200,
                    1736,
                    3787,
                    2252,
                    1743,
                    1232,
                    1744,
                    1746,
                    1747,
                    724,
                    725,
                    1751,
                    2265,
                    2777,
                    1755,
                    1757,
                    3294,
                    1249,
                    3811,
                    2280,
                    239,
                    2799,
                    2800,
                    1266,
                    755,
                    756,
                    2296,
                    3834,
                    2813,
                    1790,
                    1794,
                    1283,
                    3332,
                    1798,
                    781,
                    3341,
                    3854,
                    1296,
                    2833,
                    2834,
                    2835,
                    3855,
                    2837,
                    2838,
                    2839,
                    3856,
                    1309,
                    2338,
                    806,
                    2343,
                    3881,
                    3370,
                    1326,
                    1327,
                    1328,
                    1329,
                    302,
                    819,
                    1330,
                    3380,
                    3381,
                    2362,
                    3389,
                    3901,
                    2367,
                    3902,
                    1857,
                    3393,
                    3903,
                    3906,
                    325,
                    1349,
                    3909,
                    3914,
                    3916,
                    3918,
                    3920,
                    3921,
                    850,
                    3923,
                    3925,
                    854,
                    1366,
                    1367,
                    1368,
                    1880,
                    1882,
                    349,
                    354,
                    3429,
                    1382,
                    1383,
                    1895,
                    2408,
                    2922,
                    3430,
                    2924,
                    3431,
                    3434,
                    3945,
                    2928,
                    3440,
                    3946,
                    3443,
                    3947,
                    1397,
                    1398,
                    887,
                    1909,
                    891,
                    2942,
                    2946,
                    1411,
                    390,
                    1929,
                    1930,
                    396,
                    1932,
                    2446,
                    1424,
                    2960,
                    3985,
                    1939,
                    1940,
                    1941,
                    2451,
                    2455,
                    3480,
                    3986,
                    1436,
                    2972,
                    3486,
                    3949,
                    3998,
                    3951,
                    424,
                    1448,
                    2984,
                    4017,
                    948,
                    1462,
                    1463,
                    3005,
                    3521,
                    3010,
                    1475,
                    964,
                    2500,
                    3011,
                    3014,
                    3527,
                    4033,
                    1997,
                    1487,
                    977,
                    466,
                    4049,
                    468,
                    2516,
                    2009,
                    2010,
                    3036,
                    2013,
                    990,
                    3037,
                    3041,
                    2018,
                    2531,
                    1508,
                    2020,
                    2533,
                    3042,
                    3048,
                    3558,
                    3566,
                    1522,
                    506,
                    2043,
                    508,
                    2045,
                    1534,
                    3071
                ],
                "defaultdict": [
                    70
                ],
                "int": [
                    3041,
                    70,
                    1131,
                    2096,
                    177,
                    2294
                ],
                "prefix": [
                    72,
                    71
                ],
                "tf.reset_default_graph": [
                    89
                ],
                "reset_uids": [
                    90
                ],
                "phase": [
                    96,
                    130,
                    92,
                    127
                ],
                "tf.placeholder_with_default": [
                    92,
                    127
                ],
                "value": [
                    386,
                    387,
                    396,
                    397,
                    398,
                    399,
                    144,
                    400,
                    147,
                    2337,
                    2469,
                    2343,
                    424,
                    2471,
                    2474,
                    2347,
                    2475,
                    2360,
                    2361,
                    2368,
                    2373,
                    854,
                    856,
                    1005,
                    112,
                    891,
                    893
                ],
                "ValueError": [
                    259,
                    3715,
                    2697,
                    2826,
                    3593,
                    2190,
                    3471,
                    145,
                    1946,
                    2589,
                    4126,
                    3743,
                    3746,
                    3368,
                    2611,
                    1976,
                    3256,
                    2234,
                    3512,
                    3646,
                    2502,
                    585,
                    3281,
                    3666,
                    469,
                    3419,
                    3554,
                    4074,
                    3695,
                    3327
                ],
                "default_session": [
                    168,
                    170,
                    171
                ],
                "tf.get_default_session": [
                    168
                ],
                "session": [
                    192,
                    200,
                    171,
                    203,
                    204,
                    205,
                    2477,
                    2478,
                    181,
                    183,
                    215
                ],
                "os.environ.get": [
                    177,
                    174
                ],
                "os.environ": [
                    177,
                    174
                ],
                "os": [
                    177,
                    174
                ],
                "config": [
                    178,
                    180,
                    175
                ],
                "tf.ConfigProto": [
                    178,
                    175
                ],
                "num_thread": [
                    177,
                    178
                ],
                "tf.Session": [
                    2500,
                    180
                ],
                "session.graph.as_default": [
                    183
                ],
                "session.graph": [
                    183
                ],
                "variables": [
                    2530,
                    2531,
                    2533,
                    2516,
                    184,
                    186
                ],
                "tf.global_variables": [
                    184
                ],
                "candidate_vars": [
                    193,
                    195,
                    185,
                    188,
                    189
                ],
                "v": [
                    390,
                    393,
                    394,
                    395,
                    396,
                    398,
                    400,
                    401,
                    404,
                    406,
                    407,
                    693,
                    694,
                    695,
                    696,
                    186,
                    187,
                    188,
                    193,
                    195,
                    197,
                    198,
                    725,
                    726,
                    727,
                    728
                ],
                "getattr": [
                    2755,
                    2628,
                    2728,
                    2668,
                    187
                ],
                "candidate_vars.append": [
                    188
                ],
                "is_initialized": [
                    192,
                    195
                ],
                "session.run": [
                    192,
                    2478,
                    200
                ],
                "tf.is_variable_initialized": [
                    193
                ],
                "uninitialized_vars": [
                    200,
                    194,
                    197,
                    199
                ],
                "flag": [
                    195,
                    196
                ],
                "zip": [
                    2626,
                    195,
                    1061,
                    2469,
                    2758,
                    2731,
                    2652,
                    1054
                ],
                "uninitialized_vars.append": [
                    197
                ],
                "v._keras_initialized": [
                    198
                ],
                "tf.variables_initializer": [
                    200
                ],
                "hasattr": [
                    386,
                    2339,
                    581,
                    203,
                    399,
                    471,
                    2363
                ],
                "session.list_devices": [
                    204
                ],
                "device_lib.list_local_devices": [
                    204
                ],
                "device_lib": [
                    204
                ],
                "object": [
                    220,
                    2413
                ],
                "self.device": [
                    224,
                    228
                ],
                "self": [
                    224,
                    228,
                    2468,
                    2469,
                    2444,
                    2445,
                    2446,
                    2476,
                    2479,
                    2480,
                    2455,
                    2456,
                    2458,
                    2460,
                    2461,
                    2462,
                    2463
                ],
                "device": [
                    261,
                    228,
                    260
                ],
                "g": [
                    241,
                    239
                ],
                "op": [
                    240,
                    241,
                    242
                ],
                "_TfDeviceCaptureOp": [
                    240
                ],
                "g._apply_device_functions": [
                    241
                ],
                "op.device": [
                    242
                ],
                "device_type": [
                    257,
                    258,
                    261
                ],
                "device_type.upper": [
                    257,
                    261
                ],
                "_get_current_tf_device": [
                    260
                ],
                "device.device_type": [
                    261
                ],
                "list_devices": [
                    272
                ],
                "get_session": [
                    2374,
                    2311,
                    2347,
                    2477,
                    272,
                    2324,
                    664
                ],
                "x.name": [
                    273
                ],
                "x": [
                    510,
                    1547,
                    524,
                    3597,
                    3087,
                    3606,
                    1052,
                    1565,
                    1054,
                    1566,
                    1567,
                    3103,
                    2042,
                    3104,
                    3105,
                    3106,
                    3107,
                    3615,
                    3619,
                    3620,
                    1580,
                    557,
                    1069,
                    3119,
                    1073,
                    1074,
                    2045,
                    1076,
                    2098,
                    1593,
                    2110,
                    3648,
                    581,
                    582,
                    1606,
                    584,
                    3141,
                    3372,
                    3658,
                    2124,
                    2125,
                    3662,
                    3154,
                    1619,
                    3669,
                    3670,
                    2138,
                    1632,
                    610,
                    2151,
                    1133,
                    1645,
                    3697,
                    3186,
                    3187,
                    1140,
                    1143,
                    2167,
                    1145,
                    1658,
                    1147,
                    3191,
                    3194,
                    1150,
                    3707,
                    3711,
                    643,
                    1155,
                    3718,
                    1671,
                    3207,
                    3208,
                    3719,
                    3212,
                    3215,
                    1683,
                    664,
                    2201,
                    3228,
                    3229,
                    1695,
                    3233,
                    3745,
                    3747,
                    3236,
                    3748,
                    3751,
                    3753,
                    3756,
                    3758,
                    1199,
                    3759,
                    1713,
                    1715,
                    3763,
                    3766,
                    3768,
                    3771,
                    3774,
                    3775,
                    3778,
                    3780,
                    3783,
                    1736,
                    3785,
                    1739,
                    2252,
                    3787,
                    3788,
                    1743,
                    1232,
                    3287,
                    2265,
                    1758,
                    3294,
                    3295,
                    1249,
                    3301,
                    1266,
                    2296,
                    2813,
                    1791,
                    1792,
                    3329,
                    1283,
                    1795,
                    1796,
                    3332,
                    1799,
                    2311,
                    3333,
                    781,
                    3341,
                    3342,
                    1296,
                    273,
                    2839,
                    2840,
                    1309,
                    1821,
                    1823,
                    2337,
                    2338,
                    1827,
                    2339,
                    2340,
                    806,
                    1830,
                    1831,
                    2341,
                    2344,
                    1835,
                    2345,
                    2346,
                    302,
                    1326,
                    1327,
                    1328,
                    1329,
                    819,
                    2868,
                    2869,
                    3380,
                    2871,
                    2360,
                    2361,
                    2362,
                    2363,
                    2364,
                    2365,
                    3389,
                    2880,
                    1857,
                    2369,
                    2370,
                    2371,
                    1349,
                    2882,
                    2883,
                    3393,
                    3394,
                    2386,
                    1366,
                    1367,
                    1368,
                    1879,
                    1882,
                    2903,
                    3421,
                    3429,
                    1382,
                    1383,
                    1895,
                    2408,
                    2922,
                    3434,
                    2924,
                    2927,
                    2928,
                    2929,
                    3440,
                    3443,
                    1397,
                    1398,
                    1909,
                    3445,
                    2942,
                    2946,
                    1411,
                    1928,
                    1929,
                    1931,
                    1932,
                    1933,
                    1934,
                    1424,
                    1936,
                    1938,
                    1939,
                    916,
                    1941,
                    1942,
                    2960,
                    1944,
                    3473,
                    3480,
                    1436,
                    2972,
                    3486,
                    3487,
                    1448,
                    2984,
                    1966,
                    1971,
                    948,
                    1460,
                    1461,
                    1462,
                    1463,
                    3514,
                    3521,
                    1475,
                    964,
                    3527,
                    3528,
                    1993,
                    1997,
                    1487,
                    977,
                    466,
                    469,
                    471,
                    2009,
                    2010,
                    2011,
                    990,
                    1508,
                    3556,
                    3558,
                    2023,
                    3559,
                    1005,
                    3566,
                    3567,
                    1522,
                    506,
                    2043,
                    508,
                    509,
                    1534,
                    511
                ],
                "x.device_type": [
                    273
                ],
                "explicitly_on_cpu": [
                    285,
                    287
                ],
                "_is_current_explicit_device": [
                    285
                ],
                "gpus_available": [
                    286,
                    287
                ],
                "len": [
                    2184,
                    2185,
                    2186,
                    2587,
                    286,
                    3745,
                    3747,
                    3750,
                    2599,
                    3755,
                    2480,
                    2736,
                    3761,
                    2227,
                    2228,
                    2229,
                    2230,
                    3770,
                    3006,
                    3777,
                    3012,
                    3782,
                    2776,
                    2011,
                    612,
                    3045,
                    2165
                ],
                "_get_available_gpus": [
                    286
                ],
                "tf.convert_to_tensor": [
                    302
                ],
                "dtype": [
                    384,
                    385,
                    3207,
                    3850,
                    3851,
                    396,
                    781,
                    3854,
                    3855,
                    3856,
                    3228,
                    2080,
                    2081,
                    2337,
                    3877,
                    422,
                    423,
                    424,
                    806,
                    3878,
                    3881,
                    302,
                    4017,
                    690,
                    691,
                    692,
                    948,
                    695,
                    2361,
                    3831,
                    848,
                    849,
                    722,
                    723,
                    724,
                    850,
                    727,
                    856,
                    3807,
                    3808,
                    3835,
                    3812,
                    887,
                    753,
                    754,
                    755,
                    500,
                    501,
                    756,
                    885,
                    886,
                    3186,
                    506,
                    3830,
                    508,
                    893
                ],
                "isinstance": [
                    2466,
                    2435,
                    2530,
                    325,
                    2438,
                    2441,
                    3369,
                    1131,
                    3594,
                    397,
                    2096,
                    2449,
                    466,
                    2294,
                    2461
                ],
                "tensor": [
                    325,
                    2469,
                    2470,
                    2475,
                    348,
                    349,
                    351
                ],
                "tf.SparseTensor": [
                    3925,
                    468,
                    325,
                    390
                ],
                "is_sparse": [
                    1073,
                    348,
                    2470,
                    1879
                ],
                "tf.sparse_tensor_to_dense": [
                    349
                ],
                "name_scope": [
                    354
                ],
                "tf.name_scope": [
                    354
                ],
                "floatx": [
                    3808,
                    385,
                    3878,
                    423,
                    3831,
                    3851,
                    1327,
                    849,
                    754,
                    691,
                    723,
                    501,
                    886,
                    1367
                ],
                "sparse_coo": [
                    387,
                    388,
                    389,
                    391,
                    392,
                    393,
                    2471,
                    2472,
                    2473,
                    2474
                ],
                "value.tocoo": [
                    387,
                    2471
                ],
                "indices": [
                    388,
                    390,
                    2280,
                    2472,
                    2474,
                    3921,
                    3923,
                    3925,
                    1212
                ],
                "np.concatenate": [
                    2472,
                    388
                ],
                "np": [
                    388,
                    389,
                    1930,
                    397,
                    3853,
                    916,
                    1940,
                    1564,
                    2337,
                    2472,
                    2473,
                    3880,
                    1461,
                    2361,
                    3138,
                    853,
                    2011,
                    2016,
                    3810,
                    3833,
                    890
                ],
                "np.expand_dims": [
                    2472,
                    2473,
                    388,
                    389
                ],
                "sparse_coo.row": [
                    2472,
                    388
                ],
                "sparse_coo.col": [
                    2473,
                    389
                ],
                "sparse_coo.data": [
                    2474,
                    391
                ],
                "sparse_coo.shape": [
                    392,
                    393,
                    2474
                ],
                "v._keras_shape": [
                    400,
                    393,
                    398
                ],
                "v._uses_learning_phase": [
                    401,
                    394
                ],
                "tf.Variable": [
                    396
                ],
                "tf.as_dtype": [
                    2338,
                    396,
                    850,
                    755,
                    692,
                    724,
                    887,
                    2362
                ],
                "name": [
                    4033,
                    2456,
                    806,
                    424,
                    727,
                    396,
                    781,
                    4017,
                    4049,
                    819,
                    756,
                    693,
                    725,
                    695,
                    856,
                    506,
                    508,
                    893
                ],
                "np.ndarray": [
                    397
                ],
                "value.shape": [
                    2368,
                    398,
                    2343
                ],
                "int_shape": [
                    3744,
                    4130,
                    1061,
                    1928,
                    4077,
                    400,
                    1938,
                    2386,
                    916,
                    1054
                ],
                "v.constraint": [
                    404
                ],
                "constraint": [
                    404,
                    406
                ],
                "AttributeError": [
                    525,
                    405
                ],
                "v._constraint": [
                    406
                ],
                "tf.constant": [
                    1794,
                    2018,
                    2693,
                    424,
                    1930,
                    1940,
                    2076,
                    1790
                ],
                "shape": [
                    3811,
                    3834,
                    1895,
                    424,
                    892,
                    3881,
                    2124,
                    855,
                    3854,
                    3855,
                    3856,
                    693,
                    502,
                    725,
                    504,
                    506,
                    508,
                    509
                ],
                "tf.Tensor": [
                    466
                ],
                "tf_variables.Variable": [
                    467
                ],
                "tf_variables": [
                    467
                ],
                "str": [
                    3715,
                    3593,
                    2829,
                    2190,
                    2830,
                    3471,
                    1946,
                    4126,
                    3743,
                    3368,
                    3512,
                    1976,
                    2234,
                    3256,
                    3646,
                    3281,
                    3666,
                    469,
                    3419,
                    3554,
                    4074,
                    3695,
                    3327
                ],
                "type": [
                    469
                ],
                "ndim": [
                    2824,
                    1162,
                    2587,
                    2588,
                    1052,
                    1821,
                    2593,
                    3745,
                    3747,
                    3748,
                    1830,
                    2599,
                    1067,
                    3759,
                    3775,
                    1739,
                    1873,
                    503,
                    1133,
                    1134,
                    2801,
                    1143,
                    504,
                    2042,
                    1150,
                    1151
                ],
                "tuple": [
                    2435,
                    2438,
                    2441,
                    3594,
                    2449,
                    3606,
                    2466,
                    1059,
                    2726,
                    2727,
                    3369,
                    1066,
                    2738,
                    3380,
                    2753,
                    2754,
                    584,
                    2761,
                    2530,
                    504,
                    2025,
                    2680
                ],
                "_": [
                    504,
                    4131,
                    2683,
                    1999
                ],
                "range": [
                    2593,
                    1830,
                    4134,
                    4135,
                    1161,
                    1067,
                    1739,
                    1999,
                    2736,
                    2776,
                    4081,
                    504
                ],
                "sparse": [
                    505
                ],
                "tf.sparse_placeholder": [
                    506
                ],
                "tf.placeholder": [
                    508,
                    2367,
                    2343
                ],
                "x._keras_shape": [
                    509,
                    582
                ],
                "x._uses_learning_phase": [
                    2882,
                    510
                ],
                "x.op.type": [
                    524
                ],
                "x.op": [
                    524
                ],
                "tf.shape": [
                    1929,
                    2833,
                    1939,
                    2835,
                    3606,
                    1054,
                    1061,
                    557,
                    2734,
                    3380,
                    3901,
                    1743,
                    2642,
                    2009,
                    2655,
                    3048,
                    1137,
                    1140,
                    2682
                ],
                "as_list": [
                    2023,
                    584,
                    1993,
                    3283,
                    726,
                    694
                ],
                "x.get_shape": [
                    1792,
                    610,
                    1796,
                    2023,
                    584,
                    1993,
                    2011
                ],
                "dims": [
                    610,
                    611,
                    612
                ],
                "_dims": [
                    610
                ],
                "x.dtype.base_dtype.name": [
                    643
                ],
                "x.dtype.base_dtype": [
                    3104,
                    3105,
                    643,
                    1326,
                    2927,
                    1460,
                    1461,
                    1366,
                    1565,
                    1566
                ],
                "x.dtype": [
                    3104,
                    3105,
                    2338,
                    643,
                    1795,
                    1326,
                    2927,
                    1460,
                    1461,
                    1366,
                    2362,
                    1565,
                    1566,
                    1791
                ],
                "eval": [
                    664
                ],
                "to_dense": [
                    664,
                    1882
                ],
                "tf_dtype": [
                    2338,
                    2343,
                    855,
                    887,
                    850,
                    755,
                    724,
                    725,
                    692,
                    693,
                    756,
                    2362,
                    892,
                    2367
                ],
                "tf.zeros": [
                    3856,
                    693
                ],
                "v.get_shape": [
                    726,
                    694
                ],
                "variable": [
                    695,
                    756,
                    727,
                    856,
                    893
                ],
                "tf.ones": [
                    725,
                    3855
                ],
                "tf.eye": [
                    756
                ],
                "size": [
                    756
                ],
                "tf.zeros_like": [
                    781
                ],
                "tf.ones_like": [
                    2837,
                    806
                ],
                "tf.identity": [
                    819
                ],
                "seed": [
                    3852,
                    3853,
                    3854,
                    3879,
                    3880,
                    3881,
                    3137,
                    3138,
                    3141,
                    851,
                    853,
                    855,
                    3809,
                    3810,
                    3812,
                    888,
                    3832,
                    3833,
                    890,
                    3835,
                    892
                ],
                "np.random.randint": [
                    3138,
                    3810,
                    3880,
                    3853,
                    853,
                    3833,
                    890
                ],
                "np.random": [
                    3138,
                    3810,
                    3880,
                    3853,
                    853,
                    3833,
                    890
                ],
                "tf.random_uniform_initializer": [
                    854
                ],
                "low": [
                    855
                ],
                "high": [
                    855
                ],
                "tf.random_normal_initializer": [
                    891
                ],
                "mean": [
                    1857,
                    3811,
                    1764,
                    1736,
                    3881,
                    1713,
                    1746,
                    1715,
                    1718,
                    892
                ],
                "scale": [
                    892
                ],
                "np.prod": [
                    916
                ],
                "tf.cast": [
                    3909,
                    1382,
                    2598,
                    3208,
                    1327,
                    2800,
                    3187,
                    948,
                    1397,
                    1367,
                    3229
                ],
                "tf.assign": [
                    2451,
                    964
                ],
                "new_x": [
                    964
                ],
                "tf.assign_add": [
                    977
                ],
                "increment": [
                    977
                ],
                "tf.assign_sub": [
                    990
                ],
                "decrement": [
                    990
                ],
                "moving_averages.assign_moving_average": [
                    1004
                ],
                "moving_averages": [
                    1004
                ],
                "momentum": [
                    1005
                ],
                "y": [
                    1155,
                    1671,
                    1052,
                    1061,
                    1067,
                    1580,
                    1070,
                    1074,
                    1076,
                    1593,
                    1606,
                    1619,
                    1632,
                    1645,
                    1134,
                    1137,
                    1143,
                    1145,
                    1658,
                    1147,
                    1151
                ],
                "x_shape": [
                    1056,
                    1058,
                    1059,
                    2019,
                    2020,
                    2023,
                    2024,
                    1993,
                    2025,
                    1995,
                    1069,
                    1997,
                    1072,
                    2009,
                    1053
                ],
                "i": [
                    1056,
                    1061,
                    1062,
                    1063,
                    4134,
                    4136,
                    4137,
                    2736,
                    4081,
                    4082,
                    4083,
                    1054,
                    1055
                ],
                "s": [
                    1058,
                    1061,
                    1065,
                    1999,
                    1054
                ],
                "tf.unstack": [
                    2622,
                    2617,
                    1061,
                    1054
                ],
                "x_shape.append": [
                    1056,
                    1058
                ],
                "y_shape": [
                    1060,
                    1063,
                    1065,
                    1066,
                    1070,
                    1072
                ],
                "y_shape.append": [
                    1065,
                    1063
                ],
                "y_permute_dim": [
                    1067,
                    1068,
                    1070
                ],
                "list": [
                    2435,
                    2438,
                    1161,
                    2441,
                    3594,
                    2444,
                    2445,
                    2195,
                    2196,
                    2199,
                    3607,
                    2461,
                    1821,
                    1822,
                    2593,
                    2466,
                    1830,
                    3369,
                    1067,
                    3381,
                    2776,
                    2530,
                    1782
                ],
                "y_permute_dim.pop": [
                    1068
                ],
                "xt": [
                    1069,
                    1071
                ],
                "tf.reshape": [
                    2834,
                    1069,
                    1070,
                    1071,
                    2110,
                    3914,
                    2124,
                    3918,
                    3921,
                    1746,
                    1747,
                    1751,
                    1755,
                    3041,
                    2020,
                    1895,
                    3048,
                    1137,
                    1140
                ],
                "yt": [
                    1070,
                    1071
                ],
                "tf.transpose": [
                    3718,
                    3212,
                    3341,
                    3985,
                    3486,
                    3233,
                    2594,
                    3619,
                    2601,
                    1070,
                    1199,
                    3393,
                    3527,
                    3918,
                    3921,
                    3669,
                    2777,
                    3949,
                    3566,
                    3443,
                    1909,
                    3191,
                    1147
                ],
                "tf.matmul": [
                    1155,
                    1076,
                    1071
                ],
                "out": [
                    1155,
                    1161,
                    1162,
                    1163,
                    1164,
                    1074,
                    1076,
                    1077,
                    1145,
                    1147
                ],
                "tf.sparse_tensor_dense_matmul": [
                    1074
                ],
                "axes": [
                    2296,
                    2593,
                    2594,
                    2601,
                    1131,
                    1132,
                    2776,
                    2777,
                    2294,
                    2295,
                    1144,
                    1145,
                    1147,
                    1149,
                    1150,
                    1151
                ],
                "x_ndim": [
                    1157,
                    1158,
                    1160,
                    1133,
                    1135,
                    1136,
                    1138,
                    1139
                ],
                "y_ndim": [
                    1157,
                    1158,
                    1134,
                    1135,
                    1136,
                    1138,
                    1139
                ],
                "diff": [
                    1156,
                    1161,
                    1136,
                    1137,
                    1139,
                    1140,
                    1142
                ],
                "tf.concat": [
                    1137,
                    1882,
                    1140,
                    2833
                ],
                "tf.reduce_sum": [
                    3011,
                    1266,
                    1145,
                    1147,
                    3005
                ],
                "tf.multiply": [
                    1145,
                    1147
                ],
                "adj_x": [
                    1153,
                    1155,
                    1150
                ],
                "adj_y": [
                    1154,
                    1155,
                    1151
                ],
                "idx": [
                    1160,
                    1161,
                    1158
                ],
                "tf.squeeze": [
                    2151,
                    1161,
                    3946,
                    3945,
                    3440
                ],
                "expand_dims": [
                    2600,
                    1163
                ],
                "tf.gather": [
                    1212
                ],
                "reference": [
                    1212
                ],
                "tf.reduce_max": [
                    1232
                ],
                "axis": [
                    1283,
                    1411,
                    1296,
                    1424,
                    2960,
                    1309,
                    1328,
                    1331,
                    1349,
                    1739,
                    1740,
                    1995,
                    1997,
                    1743,
                    1232,
                    1872,
                    2000,
                    1875,
                    3154,
                    1877,
                    1368,
                    1880,
                    1882,
                    2008,
                    2138,
                    2265,
                    1249,
                    2017,
                    1508,
                    1383,
                    2151,
                    1266,
                    1398
                ],
                "keepdims": [
                    1249,
                    1283,
                    1508,
                    1349,
                    1383,
                    1232,
                    1266,
                    1332,
                    1398,
                    1368
                ],
                "tf.reduce_min": [
                    1249
                ],
                "tf.reduce_prod": [
                    1283
                ],
                "tf.cumsum": [
                    1296
                ],
                "tf.cumprod": [
                    1309
                ],
                "tf.bool": [
                    2597,
                    1382,
                    2598,
                    3909,
                    1326,
                    2799,
                    2707,
                    1397,
                    1366
                ],
                "m": [
                    1328,
                    1329
                ],
                "tf.reduce_mean": [
                    1328,
                    1330,
                    1368
                ],
                "devs_squared": [
                    1329,
                    1330
                ],
                "tf.square": [
                    1329,
                    1436
                ],
                "tf.sqrt": [
                    1349,
                    1463
                ],
                "var": [
                    1857,
                    1764,
                    1349,
                    1736,
                    1713,
                    1715,
                    1747,
                    1718
                ],
                "tf.reduce_any": [
                    1383
                ],
                "tf.reduce_all": [
                    1398
                ],
                "tf.argmax": [
                    1411
                ],
                "tf.argmin": [
                    1424
                ],
                "tf.abs": [
                    1448
                ],
                "zero": [
                    3104,
                    3106,
                    1460,
                    1462
                ],
                "_to_tensor": [
                    3104,
                    3009,
                    3105,
                    2927,
                    1460,
                    1461,
                    3070,
                    3035,
                    1565,
                    1566
                ],
                "inf": [
                    1461,
                    1462
                ],
                "np.inf": [
                    1564,
                    1461
                ],
                "tf.clip_by_value": [
                    3010,
                    3106,
                    1567,
                    1462,
                    3036,
                    3071
                ],
                "tf.exp": [
                    1475
                ],
                "tf.log": [
                    3072,
                    3011,
                    3949,
                    1487,
                    3985,
                    3037
                ],
                "tf.reduce_logsumexp": [
                    1508
                ],
                "tf.round": [
                    1522
                ],
                "tf.sign": [
                    1534
                ],
                "tf.pow": [
                    1547
                ],
                "a": [
                    1547
                ],
                "max_value": [
                    2926,
                    2927,
                    2928,
                    1561,
                    1562,
                    1563,
                    1564,
                    1566,
                    1567
                ],
                "min_value": [
                    1561,
                    1562,
                    1565,
                    1567
                ],
                "tf.equal": [
                    1580
                ],
                "tf.not_equal": [
                    1593
                ],
                "tf.greater": [
                    1606
                ],
                "tf.greater_equal": [
                    1619
                ],
                "tf.less": [
                    1632
                ],
                "tf.less_equal": [
                    1645
                ],
                "tf.maximum": [
                    1658
                ],
                "tf.minimum": [
                    2928,
                    1671
                ],
                "tf.sin": [
                    1683
                ],
                "tf.cos": [
                    1695
                ],
                "tf.nn.moments": [
                    1736,
                    1713
                ],
                "tf.nn": [
                    3074,
                    3332,
                    1798,
                    3087,
                    2960,
                    3480,
                    2972,
                    3615,
                    2984,
                    3119,
                    1713,
                    1715,
                    3763,
                    3771,
                    3389,
                    1857,
                    3521,
                    3141,
                    3014,
                    1736,
                    3658,
                    3787,
                    3662,
                    3154,
                    1757,
                    3294,
                    3042,
                    3170,
                    3558,
                    2922,
                    3434,
                    2924,
                    3707,
                    2942,
                    3711
                ],
                "reduction_axes": [
                    1824,
                    1827,
                    1830,
                    1736,
                    1832,
                    1740,
                    1836,
                    1713,
                    1782,
                    1821,
                    1822
                ],
                "normed": [
                    1715,
                    1764,
                    1757,
                    1718
                ],
                "tf.nn.batch_normalization": [
                    1857,
                    1715,
                    1757
                ],
                "beta": [
                    1793,
                    1794,
                    1827,
                    1857,
                    1831,
                    1801,
                    1835,
                    1716,
                    1752,
                    1755,
                    1823
                ],
                "gamma": [
                    1857,
                    1827,
                    1831,
                    1800,
                    1835,
                    1748,
                    1716,
                    1751,
                    1789,
                    1790,
                    1823
                ],
                "epsilon": [
                    1825,
                    1857,
                    1763,
                    1828,
                    3009,
                    1833,
                    1802,
                    1837,
                    3949,
                    3985,
                    1717,
                    3035,
                    3070
                ],
                "target_shape": [
                    1738,
                    1741,
                    1743,
                    1744,
                    1746,
                    1747,
                    1751,
                    1755
                ],
                "target_shape.append": [
                    1741,
                    1743
                ],
                "tf.stack": [
                    2664,
                    3370,
                    3595,
                    2124,
                    2734,
                    1744,
                    2642,
                    2674,
                    3381,
                    3903,
                    3607,
                    2265,
                    2044,
                    3902,
                    2655
                ],
                "broadcast_mean": [
                    1746,
                    1759
                ],
                "broadcast_var": [
                    1760,
                    1747
                ],
                "broadcast_gamma": [
                    1762,
                    1749,
                    1751
                ],
                "broadcast_beta": [
                    1753,
                    1755,
                    1761
                ],
                "normalization_axis": [
                    1792,
                    1786,
                    1796,
                    1783
                ],
                "tf_data_format": [
                    3329,
                    3713,
                    3717,
                    3209,
                    3338,
                    1803,
                    3340,
                    3597,
                    3214,
                    3215,
                    3599,
                    3473,
                    3475,
                    3610,
                    3484,
                    3485,
                    3230,
                    3617,
                    3618,
                    3235,
                    3236,
                    3372,
                    3374,
                    3384,
                    3514,
                    3516,
                    3391,
                    3392,
                    3648,
                    3650,
                    3525,
                    3526,
                    3660,
                    3664,
                    3668,
                    3291,
                    3293,
                    3421,
                    3423,
                    3300,
                    3556,
                    3564,
                    3565,
                    3438,
                    3697,
                    3442,
                    3699,
                    3188,
                    1784,
                    3193,
                    3194,
                    1787,
                    3709
                ],
                "tf.nn.fused_batch_norm": [
                    1798
                ],
                "_has_nchw_support": [
                    3232,
                    3211,
                    3762,
                    3190,
                    1822
                ],
                "_broadcast_normalize_batch_in_training": [
                    1835,
                    1823
                ],
                "_fused_normalize_batch_in_training": [
                    1826
                ],
                "sorted": [
                    1830
                ],
                "_regular_normalize_batch_in_training": [
                    1831
                ],
                "rank": [
                    1873,
                    1874,
                    1875
                ],
                "tensors": [
                    1880,
                    1873,
                    1882,
                    1879
                ],
                "tf.sparse_concat": [
                    1880
                ],
                "pattern": [
                    2245,
                    2252,
                    2193,
                    1909,
                    2166,
                    2167,
                    2198,
                    2201,
                    2237,
                    2044,
                    2045
                ],
                "data_format": [
                    3590,
                    3591,
                    3592,
                    3593,
                    3597,
                    3599,
                    4123,
                    4124,
                    4125,
                    4126,
                    3618,
                    4140,
                    4152,
                    3643,
                    3644,
                    3645,
                    3646,
                    3648,
                    3668,
                    3692,
                    3693,
                    3694,
                    3695,
                    3697,
                    3189,
                    3717,
                    3210,
                    2187,
                    2188,
                    2189,
                    2190,
                    2192,
                    3740,
                    3741,
                    3742,
                    3231,
                    3743,
                    3749,
                    3754,
                    3760,
                    2231,
                    2232,
                    2233,
                    2234,
                    3769,
                    2236,
                    3776,
                    3781,
                    3278,
                    3279,
                    3280,
                    3281,
                    3290,
                    3324,
                    3325,
                    3326,
                    3327,
                    3329,
                    3340,
                    3365,
                    3366,
                    3367,
                    3368,
                    3372,
                    3374,
                    3392,
                    3416,
                    3417,
                    3418,
                    3419,
                    3421,
                    3442,
                    1927,
                    3468,
                    3469,
                    3470,
                    3471,
                    1937,
                    3473,
                    1946,
                    3485,
                    1965,
                    1970,
                    3509,
                    3510,
                    3511,
                    1976,
                    3512,
                    3514,
                    3526,
                    3551,
                    3552,
                    3553,
                    3554,
                    3556,
                    4071,
                    4072,
                    4073,
                    4074,
                    3565
                ],
                "original_shape": [
                    1928,
                    1934,
                    1935,
                    1938,
                    1942,
                    1943
                ],
                "new_shape": [
                    1929,
                    1930,
                    1932,
                    1939,
                    1940,
                    1941
                ],
                "astype": [
                    1930,
                    1940
                ],
                "np.array": [
                    1930,
                    1940
                ],
                "height_factor": [
                    1930,
                    1934,
                    1967,
                    1940,
                    1972,
                    1942
                ],
                "width_factor": [
                    1930,
                    1935,
                    1968,
                    1940,
                    1973,
                    1943
                ],
                "permute_dimensions": [
                    1931,
                    1933,
                    4089,
                    4155,
                    4153
                ],
                "tf.image.resize_nearest_neighbor": [
                    1932,
                    1941
                ],
                "tf.image": [
                    1932,
                    1941
                ],
                "x.set_shape": [
                    1942,
                    1934
                ],
                "output": [
                    3072,
                    3075,
                    2725,
                    2728,
                    1966,
                    1967,
                    1968,
                    1969,
                    2734,
                    1971,
                    1972,
                    1973,
                    1974,
                    2735,
                    2737,
                    4148,
                    4149,
                    4153,
                    4155,
                    3005,
                    3006,
                    4156,
                    2752,
                    3009,
                    3010,
                    2627,
                    2628,
                    2755,
                    3011,
                    3012,
                    2760,
                    3015,
                    2642,
                    2645,
                    2649,
                    3035,
                    3036,
                    3037,
                    3039,
                    3041,
                    2660,
                    3048,
                    2667,
                    2668,
                    2670,
                    4088,
                    4089,
                    3070,
                    3071
                ],
                "repeat_elements": [
                    1966,
                    1967,
                    1968,
                    1971,
                    1972,
                    1973
                ],
                "depth_factor": [
                    1971,
                    1966
                ],
                "splits": [
                    1997,
                    1999
                ],
                "tf.split": [
                    1997
                ],
                "x_rep": [
                    2020,
                    2024,
                    2025,
                    2026,
                    1999,
                    2000,
                    2010,
                    2013
                ],
                "rep": [
                    2017,
                    2012,
                    1999
                ],
                "concatenate": [
                    2000,
                    3921,
                    4147,
                    4086
                ],
                "auxiliary_axis": [
                    2008,
                    2010,
                    2016,
                    2012
                ],
                "tf.expand_dims": [
                    3906,
                    3429,
                    2138,
                    3430,
                    3431,
                    3951,
                    2010,
                    2043
                ],
                "reps": [
                    2016,
                    2017,
                    2018,
                    2019,
                    2011,
                    2012,
                    2013
                ],
                "np.ones": [
                    2011
                ],
                "tf.tile": [
                    3914,
                    2733,
                    3918,
                    2013,
                    2641,
                    2098,
                    2838,
                    2045,
                    2654
                ],
                "np.delete": [
                    2016
                ],
                "x_rep.set_shape": [
                    2024
                ],
                "x_rep._keras_shape": [
                    2025
                ],
                "n": [
                    2096,
                    2097,
                    2098,
                    2044
                ],
                "stop": [
                    2069,
                    2079
                ],
                "start": [
                    2071,
                    2072,
                    2075,
                    2076,
                    2077,
                    2079
                ],
                "TypeError": [
                    2467,
                    2436,
                    2439,
                    2442,
                    2073
                ],
                "tf.cond": [
                    2075,
                    2813
                ],
                "start.dtype": [
                    2076
                ],
                "result": [
                    2081,
                    2082,
                    2079
                ],
                "tf.range": [
                    3906,
                    3914,
                    3918,
                    2079
                ],
                "step": [
                    2079
                ],
                "cast": [
                    3040,
                    2081
                ],
                "prod": [
                    2124
                ],
                "padding": [
                    3712,
                    3331,
                    2184,
                    2185,
                    2186,
                    3337,
                    3474,
                    2195,
                    2196,
                    2199,
                    3609,
                    3482,
                    3616,
                    2227,
                    2228,
                    2229,
                    2230,
                    3251,
                    3252,
                    3253,
                    3254,
                    3256,
                    3257,
                    3383,
                    3390,
                    3515,
                    2240,
                    2241,
                    2242,
                    3523,
                    3649,
                    2247,
                    2248,
                    2249,
                    3659,
                    3663,
                    3284,
                    3288,
                    3289,
                    3422,
                    3299,
                    3557,
                    3563,
                    3436,
                    3698,
                    2165,
                    2166,
                    3708
                ],
                "tf.pad": [
                    2201,
                    2252,
                    2167
                ],
                "image_data_format": [
                    3552,
                    3366,
                    3591,
                    3741,
                    4072,
                    2188,
                    3469,
                    3693,
                    3279,
                    4124,
                    3510,
                    2232,
                    3417,
                    3644,
                    3325
                ],
                "tf.one_hot": [
                    2280
                ],
                "num_classes": [
                    2280
                ],
                "tf.reverse": [
                    2296
                ],
                "x.eval": [
                    2311
                ],
                "ops": [
                    2323,
                    2324
                ],
                "run": [
                    2347,
                    2324,
                    2374
                ],
                "np.asarray": [
                    2337,
                    2361
                ],
                "x.dtype.name.split": [
                    2338,
                    2362
                ],
                "x.dtype.name": [
                    2338,
                    2362
                ],
                "assign_placeholder": [
                    2369,
                    2370,
                    2340,
                    2373,
                    2343,
                    2344,
                    2345,
                    2347,
                    2364,
                    2367
                ],
                "x._assign_placeholder": [
                    2345,
                    2370,
                    2340,
                    2364
                ],
                "assign_op": [
                    2369,
                    2371,
                    2372,
                    2341,
                    2344,
                    2346,
                    2347,
                    2365
                ],
                "x._assign_op": [
                    2371,
                    2346,
                    2365,
                    2341
                ],
                "x.assign": [
                    2344,
                    2369
                ],
                "tuples": [
                    2360,
                    2357
                ],
                "assign_ops": [
                    2374,
                    2372,
                    2358
                ],
                "feed_dict": [
                    2468,
                    2373,
                    2374,
                    2475,
                    2478,
                    2359
                ],
                "assign_ops.append": [
                    2372
                ],
                "tf.Print": [
                    2408
                ],
                "message": [
                    2408
                ],
                "updates": [
                    2448,
                    2441,
                    2434,
                    2503
                ],
                "inputs": [
                    2689,
                    2466,
                    2435,
                    2594,
                    2469,
                    2692,
                    2503,
                    2683,
                    2444,
                    4141,
                    4144,
                    2610,
                    4084,
                    2678,
                    2617,
                    2682,
                    2587
                ],
                "outputs": [
                    2438,
                    2503,
                    2664,
                    2445,
                    2674,
                    2773,
                    2776,
                    2777,
                    2683,
                    2685,
                    2779
                ],
                "self.inputs": [
                    2444,
                    2469
                ],
                "self.outputs": [
                    2480,
                    2476,
                    2445,
                    2446
                ],
                "tf.control_dependencies": [
                    2446
                ],
                "updates_ops": [
                    2455,
                    2451,
                    2454,
                    2447
                ],
                "update": [
                    2448,
                    2449,
                    2450,
                    2454
                ],
                "p": [
                    2450,
                    2451,
                    3854
                ],
                "new_p": [
                    2450,
                    2451
                ],
                "updates_ops.append": [
                    2451,
                    2454
                ],
                "self.updates_op": [
                    2476,
                    2455
                ],
                "tf.group": [
                    2455
                ],
                "self.name": [
                    2456
                ],
                "self.feed_dict": [
                    2458,
                    2468
                ],
                "session_kwargs.pop": [
                    2458,
                    2460
                ],
                "session_kwargs": [
                    2458,
                    2460,
                    2463
                ],
                "self.fetches": [
                    2476,
                    2460,
                    2461,
                    2462
                ],
                "self.session_kwargs": [
                    2479,
                    2463
                ],
                "self.feed_dict.copy": [
                    2468
                ],
                "fetches": [
                    2476,
                    2478
                ],
                "updated": [
                    2480,
                    2478
                ],
                "kwargs": [
                    2498,
                    2499,
                    2503
                ],
                "key": [
                    2499,
                    2500,
                    2501
                ],
                "has_arg": [
                    2500
                ],
                "tf.Session.run": [
                    2500
                ],
                "Function.__init__": [
                    2500
                ],
                "Function": [
                    2500,
                    2503
                ],
                "msg": [
                    2501,
                    2502
                ],
                "tf.gradients": [
                    2516
                ],
                "loss": [
                    2516
                ],
                "map": [
                    2531
                ],
                "tf.stop_gradient": [
                    2531,
                    2533
                ],
                "inputs.get_shape": [
                    2610,
                    2587
                ],
                "mask": [
                    2596,
                    2597,
                    2598,
                    2599,
                    2600,
                    2601,
                    2695,
                    2704,
                    2710,
                    2621,
                    2622
                ],
                "mask.dtype": [
                    2597
                ],
                "mask.get_shape": [
                    2599
                ],
                "constants": [
                    2754,
                    2627,
                    2727,
                    2667,
                    2603,
                    2604,
                    2683
                ],
                "uses_learning_phase": [
                    2881,
                    2757,
                    2629,
                    2730,
                    2669,
                    2607,
                    2863,
                    2865,
                    2778
                ],
                "unroll": [
                    2609
                ],
                "states": [
                    2753,
                    2659,
                    2627,
                    2661,
                    2726,
                    2758,
                    2696,
                    2667,
                    2731,
                    2766,
                    2671,
                    2735,
                    2736,
                    2613,
                    2680,
                    2652
                ],
                "initial_states": [
                    2680,
                    2683,
                    2613
                ],
                "successive_states": [
                    2661,
                    2663,
                    2671,
                    2673,
                    2614
                ],
                "successive_outputs": [
                    2660,
                    2615,
                    2662,
                    2664,
                    2670,
                    2672,
                    2674,
                    2644,
                    2647
                ],
                "input_list": [
                    2617,
                    2626,
                    2619,
                    2666
                ],
                "go_backwards": [
                    2703,
                    2618,
                    2677,
                    2623
                ],
                "input_list.reverse": [
                    2619
                ],
                "mask_list": [
                    2624,
                    2626,
                    2622
                ],
                "mask_list.reverse": [
                    2624
                ],
                "inp": [
                    2667,
                    2626,
                    2627,
                    2666
                ],
                "mask_t": [
                    2626,
                    2724,
                    2733,
                    2641,
                    2654
                ],
                "new_states": [
                    2752,
                    2627,
                    2725,
                    2758,
                    2663,
                    2761,
                    2731,
                    2736,
                    2673,
                    2738,
                    2771,
                    2779,
                    2652
                ],
                "step_function": [
                    2752,
                    2627,
                    2725,
                    2667,
                    2683
                ],
                "tiled_mask_t": [
                    2656,
                    2733,
                    2735,
                    2736,
                    2641,
                    2649,
                    2654
                ],
                "prev_output": [
                    2649,
                    2645,
                    2647
                ],
                "zeros_like": [
                    2645
                ],
                "tf.where": [
                    2656,
                    2946,
                    3854,
                    2735,
                    2736,
                    2837,
                    2839,
                    2649
                ],
                "return_states": [
                    2656,
                    2659,
                    2651
                ],
                "state": [
                    2658,
                    2758,
                    2759,
                    2731,
                    2732,
                    2652
                ],
                "new_state": [
                    2657,
                    2758,
                    2759,
                    2731,
                    2732,
                    2652,
                    2655
                ],
                "return_states.append": [
                    2656
                ],
                "successive_outputs.append": [
                    2660,
                    2670
                ],
                "successive_states.append": [
                    2661,
                    2671
                ],
                "last_output": [
                    2662,
                    2672,
                    2774,
                    2778,
                    2779
                ],
                "reverse": [
                    2704,
                    2678,
                    3919
                ],
                "time_steps": [
                    2690,
                    2764,
                    2708,
                    2682,
                    2686
                ],
                "output_ta": [
                    2766,
                    2770,
                    2773,
                    2774,
                    2684
                ],
                "tensor_array_ops.TensorArray": [
                    2688,
                    2706,
                    2684
                ],
                "tensor_array_ops": [
                    2688,
                    2706,
                    2684
                ],
                "outputs.dtype": [
                    2685
                ],
                "input_ta": [
                    2688,
                    2723,
                    2692,
                    2751
                ],
                "inputs.dtype": [
                    2689
                ],
                "input_ta.unstack": [
                    2692
                ],
                "time": [
                    2723,
                    2724,
                    2693,
                    2760,
                    2761,
                    2764,
                    2766,
                    2737,
                    2738,
                    2751
                ],
                "mask_ta": [
                    2706,
                    2724,
                    2710
                ],
                "mask_ta.unstack": [
                    2710
                ],
                "current_input": [
                    2752,
                    3907,
                    2723,
                    2725,
                    2751
                ],
                "input_ta.read": [
                    2723,
                    2751
                ],
                "mask_ta.read": [
                    2724
                ],
                "new_state.set_shape": [
                    2732,
                    2759
                ],
                "state.get_shape": [
                    2732,
                    2759
                ],
                "output_ta_t": [
                    2760,
                    2737,
                    2738,
                    2761
                ],
                "output_ta_t.write": [
                    2760,
                    2737
                ],
                "final_outputs": [
                    2769,
                    2770,
                    2763,
                    2771
                ],
                "control_flow_ops.while_loop": [
                    2763
                ],
                "control_flow_ops": [
                    2763
                ],
                "_step": [
                    2765
                ],
                "last_time": [
                    2769,
                    2774
                ],
                "output_ta.stack": [
                    2773
                ],
                "output_ta.read": [
                    2774
                ],
                "outputs.get_shape": [
                    2776
                ],
                "last_output._uses_learning_phase": [
                    2778
                ],
                "condition.dtype": [
                    2799
                ],
                "condition": [
                    2799,
                    2800,
                    2801,
                    2833,
                    2834,
                    2838,
                    2839,
                    2813
                ],
                "cond_ndim": [
                    2825,
                    2829,
                    2831,
                    2832,
                    2801,
                    2802
                ],
                "callable": [
                    2820,
                    2822,
                    2803,
                    2868,
                    2808,
                    2874
                ],
                "then_expression": [
                    2820,
                    2821,
                    2824,
                    2839,
                    2803,
                    2835,
                    2805,
                    2807
                ],
                "then_expression_fn": [
                    2814,
                    2807
                ],
                "else_expression": [
                    2822,
                    2823,
                    2839,
                    2808,
                    2810,
                    2812
                ],
                "else_expression_fn": [
                    2812,
                    2815
                ],
                "expr_ndim": [
                    2824,
                    2825,
                    2830,
                    2832
                ],
                "ndim_diff": [
                    2832,
                    2833
                ],
                "cond_shape": [
                    2833,
                    2834,
                    2836
                ],
                "expr_shape": [
                    2835,
                    2836,
                    2837
                ],
                "shape_diff": [
                    2836,
                    2837
                ],
                "tile_shape": [
                    2837,
                    2838
                ],
                "training": [
                    2880,
                    2861,
                    2862,
                    2867,
                    2903,
                    2873
                ],
                "learning_phase": [
                    2862
                ],
                "alt": [
                    2880,
                    2903,
                    2874,
                    2875,
                    2877
                ],
                "switch": [
                    2880
                ],
                "in_train_phase": [
                    2903
                ],
                "alpha": [
                    2921,
                    2922,
                    2946,
                    2943
                ],
                "tf.nn.leaky_relu": [
                    2922
                ],
                "tf.nn.relu": [
                    2924
                ],
                "res": [
                    2944,
                    2946,
                    3042,
                    3048,
                    3050,
                    2942
                ],
                "tf.nn.elu": [
                    2942
                ],
                "tf.nn.softmax": [
                    2960
                ],
                "tf.nn.softplus": [
                    2972
                ],
                "tf.nn.softsign": [
                    2984
                ],
                "from_logits": [
                    3034,
                    3003,
                    3068
                ],
                "output.get_shape": [
                    3012,
                    3006,
                    3039
                ],
                "_epsilon": [
                    3009,
                    3010,
                    3035,
                    3036,
                    3070,
                    3071
                ],
                "output.dtype.base_dtype": [
                    3009,
                    3035,
                    3070
                ],
                "output.dtype": [
                    3009,
                    3035,
                    3070
                ],
                "target": [
                    3040,
                    3074,
                    3011,
                    3014
                ],
                "tf.nn.softmax_cross_entropy_with_logits": [
                    3014
                ],
                "output_shape": [
                    3594,
                    3595,
                    3600,
                    3601,
                    3602,
                    3603,
                    3604,
                    3605,
                    3606,
                    3607,
                    3615,
                    4129,
                    3369,
                    3370,
                    3375,
                    3376,
                    3377,
                    3378,
                    3379,
                    3380,
                    3381,
                    3389,
                    3039,
                    3041,
                    3045
                ],
                "targets": [
                    3040,
                    3170,
                    3043
                ],
                "flatten": [
                    3040
                ],
                "logits": [
                    3041,
                    3044
                ],
                "tf.nn.sparse_softmax_cross_entropy_with_logits": [
                    3042
                ],
                "tf.nn.sigmoid_cross_entropy_with_logits": [
                    3074
                ],
                "tf.nn.sigmoid": [
                    3087
                ],
                "one": [
                    3105,
                    3106
                ],
                "tf.nn.tanh": [
                    3119
                ],
                "retain_prob": [
                    3136,
                    3141
                ],
                "level": [
                    3136
                ],
                "tf.nn.dropout": [
                    3141
                ],
                "noise_shape": [
                    3141
                ],
                "tf.nn.l2_normalize": [
                    3154
                ],
                "tf.nn.in_top_k": [
                    3170
                ],
                "predictions": [
                    3170
                ],
                "k": [
                    3170
                ],
                "kernel_shape": [
                    4130,
                    4131,
                    4077,
                    4078,
                    3283,
                    3286
                ],
                "kernel.get_shape": [
                    3283
                ],
                "kernel": [
                    3296,
                    4130,
                    3334,
                    3560,
                    4077,
                    3283,
                    4148,
                    4088,
                    3389,
                    3615
                ],
                "left_pad": [
                    3286,
                    3287
                ],
                "dilation_rate": [
                    3297,
                    3524,
                    3335,
                    3432,
                    3561,
                    3437,
                    3286,
                    3483
                ],
                "temporal_padding": [
                    3287
                ],
                "_preprocess_padding": [
                    3649,
                    3331,
                    3557,
                    3609,
                    3474,
                    3698,
                    3383,
                    3289,
                    3515,
                    3422
                ],
                "tf.nn.convolution": [
                    3558,
                    3332,
                    3294
                ],
                "strides": [
                    3336,
                    3476,
                    3478,
                    3481,
                    3611,
                    3613,
                    3615,
                    4128,
                    3385,
                    3387,
                    3389,
                    3517,
                    3519,
                    3522,
                    3651,
                    3654,
                    3658,
                    3662,
                    3425,
                    3298,
                    3428,
                    3562,
                    3435,
                    4076,
                    3700,
                    3703,
                    3707,
                    3711
                ],
                "_preprocess_conv2d_input": [
                    3648,
                    3329,
                    3372,
                    3473,
                    3514
                ],
                "tf.nn.conv2d_transpose": [
                    3389
                ],
                "_preprocess_conv1d_input": [
                    3421
                ],
                "spatial_start_dim": [
                    3424,
                    3427,
                    3440,
                    3429
                ],
                "depthwise_kernel": [
                    3480,
                    3521,
                    3434,
                    3430
                ],
                "pointwise_kernel": [
                    3480,
                    3434,
                    3431
                ],
                "tf.nn.separable_conv2d": [
                    3480,
                    3434
                ],
                "tf.nn.depthwise_conv2d": [
                    3521
                ],
                "_preprocess_conv3d_input": [
                    3697,
                    3556,
                    3597
                ],
                "tf.nn.conv3d_transpose": [
                    3615
                ],
                "pool_size": [
                    3652,
                    3655,
                    3658,
                    3662,
                    3701,
                    3704,
                    3707,
                    3711
                ],
                "pool_mode": [
                    3715,
                    3657,
                    3661,
                    3666,
                    3706,
                    3710
                ],
                "tf.nn.max_pool": [
                    3658
                ],
                "tf.nn.avg_pool": [
                    3662
                ],
                "tf.nn.max_pool3d": [
                    3707
                ],
                "tf.nn.avg_pool3d": [
                    3711
                ],
                "bias_shape": [
                    3744,
                    3745,
                    3747,
                    3750,
                    3751,
                    3753,
                    3755,
                    3756,
                    3758,
                    3761,
                    3766,
                    3768,
                    3770,
                    3774,
                    3777,
                    3778,
                    3780,
                    3782,
                    3783,
                    3785
                ],
                "bias": [
                    3744,
                    3778,
                    3780,
                    3751,
                    3783,
                    3753,
                    3785,
                    3787,
                    3756,
                    3758,
                    3763,
                    3766,
                    3768,
                    3771,
                    3774
                ],
                "reshape": [
                    3778,
                    3780,
                    3751,
                    3783,
                    3753,
                    3785,
                    3756,
                    4141,
                    3758,
                    4144,
                    4084,
                    4149,
                    3766,
                    3768,
                    3774
                ],
                "tf.nn.bias_add": [
                    3763,
                    3771,
                    3787
                ],
                "tf.random_normal": [
                    3811
                ],
                "stddev": [
                    3881,
                    3811
                ],
                "tf.random_uniform": [
                    3834,
                    3854
                ],
                "minval": [
                    3834
                ],
                "maxval": [
                    3834
                ],
                "tf.truncated_normal": [
                    3881
                ],
                "label_shape": [
                    3906,
                    3909,
                    3914,
                    3915,
                    3918,
                    3919,
                    3925,
                    3901,
                    3902,
                    3903
                ],
                "labels": [
                    3923,
                    3901
                ],
                "num_batches_tns": [
                    3914,
                    3902
                ],
                "max_num_labels_tns": [
                    3907,
                    3919,
                    3903
                ],
                "tf.fill": [
                    3906,
                    3909
                ],
                "init": [
                    3909,
                    3911
                ],
                "dense_mask": [
                    3912,
                    3920,
                    3916,
                    3910
                ],
                "functional_ops.scan": [
                    3910
                ],
                "functional_ops": [
                    3910
                ],
                "range_less_than": [
                    3910
                ],
                "label_lengths": [
                    3910
                ],
                "label_array": [
                    3914,
                    3916
                ],
                "label_ind": [
                    3921,
                    3916
                ],
                "tf.boolean_mask": [
                    3920,
                    3916
                ],
                "batch_array": [
                    3920,
                    3918
                ],
                "batch_ind": [
                    3920,
                    3921
                ],
                "vals_sparse": [
                    3923,
                    3925
                ],
                "tf.gather_nd": [
                    3923
                ],
                "tf.to_int64": [
                    3925
                ],
                "label_length": [
                    3945,
                    3947
                ],
                "tf.to_int32": [
                    3945,
                    3946,
                    3947,
                    3986
                ],
                "input_length": [
                    3946,
                    3953,
                    3986,
                    3991,
                    3995
                ],
                "sparse_labels": [
                    3952,
                    3947
                ],
                "ctc_label_dense_to_sparse": [
                    3947
                ],
                "y_true": [
                    3947
                ],
                "y_pred": [
                    3949,
                    3951,
                    3985,
                    3990,
                    3994
                ],
                "ctc.ctc_loss": [
                    3951
                ],
                "ctc": [
                    3993,
                    3989,
                    3951
                ],
                "greedy": [
                    3988
                ],
                "decoded": [
                    3993,
                    3989,
                    3999
                ],
                "log_prob": [
                    4000,
                    3993,
                    3989
                ],
                "ctc.ctc_greedy_decoder": [
                    3989
                ],
                "ctc.ctc_beam_search_decoder": [
                    3993
                ],
                "beam_width": [
                    3995
                ],
                "top_paths": [
                    3996
                ],
                "decoded_dense": [
                    4000,
                    3998
                ],
                "tf.sparse_to_dense": [
                    3998
                ],
                "st.indices": [
                    3998
                ],
                "st": [
                    3998,
                    3999
                ],
                "st.dense_shape": [
                    3998
                ],
                "st.values": [
                    3998
                ],
                "tf.map_fn": [
                    4017
                ],
                "fn": [
                    4049,
                    4017,
                    4033
                ],
                "elems": [
                    4049,
                    4017,
                    4033
                ],
                "tf.foldl": [
                    4033
                ],
                "initializer": [
                    4033,
                    4049
                ],
                "tf.foldr": [
                    4049
                ],
                "stride": [
                    4082,
                    4083,
                    4076
                ],
                "output_length": [
                    4081,
                    4078
                ],
                "feature_dim": [
                    4131,
                    4142,
                    4078,
                    4145,
                    4085
                ],
                "filters": [
                    4150,
                    4131,
                    4078
                ],
                "xs": [
                    4133,
                    4141,
                    4080,
                    4144,
                    4147,
                    4084,
                    4086
                ],
                "slice_length": [
                    4082,
                    4084
                ],
                "slice": [
                    4136,
                    4082,
                    4138
                ],
                "kernel_size": [
                    4137,
                    4139,
                    4083
                ],
                "xs.append": [
                    4144,
                    4084,
                    4141
                ],
                "x_aggregate": [
                    4088,
                    4147,
                    4148,
                    4086
                ],
                "batch_dot": [
                    4088,
                    4148
                ],
                "stride_row": [
                    4128,
                    4137,
                    4136
                ],
                "stride_col": [
                    4128,
                    4138,
                    4139
                ],
                "output_row": [
                    4150,
                    4129,
                    4134
                ],
                "output_col": [
                    4129,
                    4150,
                    4135
                ],
                "j": [
                    4138,
                    4139,
                    4135
                ],
                "slice_row": [
                    4136,
                    4144,
                    4141
                ],
                "slice_col": [
                    4144,
                    4138,
                    4141
                ]
            },
            "filtered_variables_in_file": {
                "py_all": [
                    27,
                    726,
                    694,
                    1879
                ],
                "py_sum": [
                    28
                ],
                "_SESSION": [
                    34,
                    173,
                    180,
                    181,
                    215,
                    91
                ],
                "_GRAPH_LEARNING_PHASES": [
                    96,
                    130,
                    131,
                    39,
                    147,
                    126,
                    95
                ],
                "_GRAPH_UID_DICTS": [
                    69,
                    70,
                    71,
                    72,
                    45,
                    79
                ],
                "_MANUAL_VAR_INIT": [
                    112,
                    50,
                    182
                ],
                "_LOCAL_DEVICES": [
                    272,
                    273,
                    271,
                    55
                ],
                "graph": [
                    130,
                    131,
                    68,
                    69,
                    70,
                    71,
                    72,
                    125,
                    126
                ],
                "tf.get_default_graph": [
                    96,
                    68,
                    239,
                    147,
                    125
                ],
                "tf": [
                    3072,
                    3074,
                    1547,
                    3595,
                    3087,
                    3606,
                    3607,
                    2075,
                    2076,
                    1054,
                    1567,
                    2079,
                    3615,
                    2594,
                    3106,
                    3619,
                    1061,
                    2597,
                    2598,
                    2601,
                    1580,
                    557,
                    1069,
                    1071,
                    1070,
                    2044,
                    1074,
                    2098,
                    1076,
                    3119,
                    1593,
                    2617,
                    2110,
                    2622,
                    68,
                    3141,
                    1606,
                    3658,
                    2124,
                    3662,
                    2641,
                    2642,
                    1619,
                    3154,
                    3669,
                    89,
                    2138,
                    2649,
                    92,
                    2654,
                    2655,
                    96,
                    1632,
                    2656,
                    3170,
                    2151,
                    2664,
                    1645,
                    1137,
                    2674,
                    3187,
                    1140,
                    2167,
                    3191,
                    1145,
                    1658,
                    1147,
                    2682,
                    125,
                    3707,
                    127,
                    3711,
                    1155,
                    2693,
                    3718,
                    1671,
                    3208,
                    1161,
                    3212,
                    147,
                    1683,
                    2707,
                    2201,
                    3229,
                    1695,
                    3233,
                    168,
                    2733,
                    2734,
                    1199,
                    175,
                    1713,
                    178,
                    1715,
                    180,
                    692,
                    693,
                    2735,
                    184,
                    2736,
                    3763,
                    3771,
                    1212,
                    193,
                    200,
                    1736,
                    3787,
                    2252,
                    1743,
                    1232,
                    1744,
                    1746,
                    1747,
                    724,
                    725,
                    1751,
                    2265,
                    2777,
                    1755,
                    1757,
                    3294,
                    1249,
                    3811,
                    2280,
                    239,
                    2799,
                    2800,
                    1266,
                    755,
                    756,
                    2296,
                    3834,
                    2813,
                    1790,
                    1794,
                    1283,
                    3332,
                    1798,
                    781,
                    3341,
                    3854,
                    1296,
                    2833,
                    2834,
                    2835,
                    3855,
                    2837,
                    2838,
                    2839,
                    3856,
                    1309,
                    2338,
                    806,
                    2343,
                    3881,
                    3370,
                    1326,
                    1327,
                    1328,
                    1329,
                    302,
                    819,
                    1330,
                    3380,
                    3381,
                    2362,
                    3389,
                    3901,
                    2367,
                    3902,
                    1857,
                    3393,
                    3903,
                    3906,
                    325,
                    1349,
                    3909,
                    3914,
                    3916,
                    3918,
                    3920,
                    3921,
                    850,
                    3923,
                    3925,
                    854,
                    1366,
                    1367,
                    1368,
                    1880,
                    1882,
                    349,
                    354,
                    3429,
                    1382,
                    1383,
                    1895,
                    2408,
                    2922,
                    3430,
                    2924,
                    3431,
                    3434,
                    3945,
                    2928,
                    3440,
                    3946,
                    3443,
                    3947,
                    1397,
                    1398,
                    887,
                    1909,
                    891,
                    2942,
                    2946,
                    1411,
                    390,
                    1929,
                    1930,
                    396,
                    1932,
                    2446,
                    1424,
                    2960,
                    3985,
                    1939,
                    1940,
                    1941,
                    2451,
                    2455,
                    3480,
                    3986,
                    1436,
                    2972,
                    3486,
                    3949,
                    3998,
                    3951,
                    424,
                    1448,
                    2984,
                    4017,
                    948,
                    1462,
                    1463,
                    3005,
                    3521,
                    3010,
                    1475,
                    964,
                    2500,
                    3011,
                    3014,
                    3527,
                    4033,
                    1997,
                    1487,
                    977,
                    466,
                    4049,
                    468,
                    2516,
                    2009,
                    2010,
                    3036,
                    2013,
                    990,
                    3037,
                    3041,
                    2018,
                    2531,
                    1508,
                    2020,
                    2533,
                    3042,
                    3048,
                    3558,
                    3566,
                    1522,
                    506,
                    2043,
                    508,
                    2045,
                    1534,
                    3071
                ],
                "defaultdict": [
                    70
                ],
                "prefix": [
                    72,
                    71
                ],
                "tf.reset_default_graph": [
                    89
                ],
                "reset_uids": [
                    90
                ],
                "phase": [
                    96,
                    130,
                    92,
                    127
                ],
                "tf.placeholder_with_default": [
                    92,
                    127
                ],
                "value": [
                    386,
                    387,
                    396,
                    397,
                    398,
                    399,
                    144,
                    400,
                    147,
                    2337,
                    2469,
                    2343,
                    424,
                    2471,
                    2474,
                    2347,
                    2475,
                    2360,
                    2361,
                    2368,
                    2373,
                    854,
                    856,
                    1005,
                    112,
                    891,
                    893
                ],
                "default_session": [
                    168,
                    170,
                    171
                ],
                "tf.get_default_session": [
                    168
                ],
                "session": [
                    192,
                    200,
                    171,
                    203,
                    204,
                    205,
                    2477,
                    2478,
                    181,
                    183,
                    215
                ],
                "os.environ.get": [
                    177,
                    174
                ],
                "os.environ": [
                    177,
                    174
                ],
                "os": [
                    177,
                    174
                ],
                "config": [
                    178,
                    180,
                    175
                ],
                "tf.ConfigProto": [
                    178,
                    175
                ],
                "num_thread": [
                    177,
                    178
                ],
                "tf.Session": [
                    2500,
                    180
                ],
                "session.graph.as_default": [
                    183
                ],
                "session.graph": [
                    183
                ],
                "variables": [
                    2530,
                    2531,
                    2533,
                    2516,
                    184,
                    186
                ],
                "tf.global_variables": [
                    184
                ],
                "candidate_vars": [
                    193,
                    195,
                    185,
                    188,
                    189
                ],
                "v": [
                    390,
                    393,
                    394,
                    395,
                    396,
                    398,
                    400,
                    401,
                    404,
                    406,
                    407,
                    693,
                    694,
                    695,
                    696,
                    186,
                    187,
                    188,
                    193,
                    195,
                    197,
                    198,
                    725,
                    726,
                    727,
                    728
                ],
                "candidate_vars.append": [
                    188
                ],
                "is_initialized": [
                    192,
                    195
                ],
                "session.run": [
                    192,
                    2478,
                    200
                ],
                "tf.is_variable_initialized": [
                    193
                ],
                "uninitialized_vars": [
                    200,
                    194,
                    197,
                    199
                ],
                "flag": [
                    195,
                    196
                ],
                "uninitialized_vars.append": [
                    197
                ],
                "v._keras_initialized": [
                    198
                ],
                "tf.variables_initializer": [
                    200
                ],
                "session.list_devices": [
                    204
                ],
                "device_lib.list_local_devices": [
                    204
                ],
                "device_lib": [
                    204
                ],
                "self.device": [
                    224,
                    228
                ],
                "self": [
                    224,
                    228,
                    2468,
                    2469,
                    2444,
                    2445,
                    2446,
                    2476,
                    2479,
                    2480,
                    2455,
                    2456,
                    2458,
                    2460,
                    2461,
                    2462,
                    2463
                ],
                "device": [
                    261,
                    228,
                    260
                ],
                "g": [
                    241,
                    239
                ],
                "op": [
                    240,
                    241,
                    242
                ],
                "_TfDeviceCaptureOp": [
                    240
                ],
                "g._apply_device_functions": [
                    241
                ],
                "op.device": [
                    242
                ],
                "device_type": [
                    257,
                    258,
                    261
                ],
                "device_type.upper": [
                    257,
                    261
                ],
                "_get_current_tf_device": [
                    260
                ],
                "device.device_type": [
                    261
                ],
                "list_devices": [
                    272
                ],
                "get_session": [
                    2374,
                    2311,
                    2347,
                    2477,
                    272,
                    2324,
                    664
                ],
                "x.name": [
                    273
                ],
                "x": [
                    510,
                    1547,
                    524,
                    3597,
                    3087,
                    3606,
                    1052,
                    1565,
                    1054,
                    1566,
                    1567,
                    3103,
                    2042,
                    3104,
                    3105,
                    3106,
                    3107,
                    3615,
                    3619,
                    3620,
                    1580,
                    557,
                    1069,
                    3119,
                    1073,
                    1074,
                    2045,
                    1076,
                    2098,
                    1593,
                    2110,
                    3648,
                    581,
                    582,
                    1606,
                    584,
                    3141,
                    3372,
                    3658,
                    2124,
                    2125,
                    3662,
                    3154,
                    1619,
                    3669,
                    3670,
                    2138,
                    1632,
                    610,
                    2151,
                    1133,
                    1645,
                    3697,
                    3186,
                    3187,
                    1140,
                    1143,
                    2167,
                    1145,
                    1658,
                    1147,
                    3191,
                    3194,
                    1150,
                    3707,
                    3711,
                    643,
                    1155,
                    3718,
                    1671,
                    3207,
                    3208,
                    3719,
                    3212,
                    3215,
                    1683,
                    664,
                    2201,
                    3228,
                    3229,
                    1695,
                    3233,
                    3745,
                    3747,
                    3236,
                    3748,
                    3751,
                    3753,
                    3756,
                    3758,
                    1199,
                    3759,
                    1713,
                    1715,
                    3763,
                    3766,
                    3768,
                    3771,
                    3774,
                    3775,
                    3778,
                    3780,
                    3783,
                    1736,
                    3785,
                    1739,
                    2252,
                    3787,
                    3788,
                    1743,
                    1232,
                    3287,
                    2265,
                    1758,
                    3294,
                    3295,
                    1249,
                    3301,
                    1266,
                    2296,
                    2813,
                    1791,
                    1792,
                    3329,
                    1283,
                    1795,
                    1796,
                    3332,
                    1799,
                    2311,
                    3333,
                    781,
                    3341,
                    3342,
                    1296,
                    273,
                    2839,
                    2840,
                    1309,
                    1821,
                    1823,
                    2337,
                    2338,
                    1827,
                    2339,
                    2340,
                    806,
                    1830,
                    1831,
                    2341,
                    2344,
                    1835,
                    2345,
                    2346,
                    302,
                    1326,
                    1327,
                    1328,
                    1329,
                    819,
                    2868,
                    2869,
                    3380,
                    2871,
                    2360,
                    2361,
                    2362,
                    2363,
                    2364,
                    2365,
                    3389,
                    2880,
                    1857,
                    2369,
                    2370,
                    2371,
                    1349,
                    2882,
                    2883,
                    3393,
                    3394,
                    2386,
                    1366,
                    1367,
                    1368,
                    1879,
                    1882,
                    2903,
                    3421,
                    3429,
                    1382,
                    1383,
                    1895,
                    2408,
                    2922,
                    3434,
                    2924,
                    2927,
                    2928,
                    2929,
                    3440,
                    3443,
                    1397,
                    1398,
                    1909,
                    3445,
                    2942,
                    2946,
                    1411,
                    1928,
                    1929,
                    1931,
                    1932,
                    1933,
                    1934,
                    1424,
                    1936,
                    1938,
                    1939,
                    916,
                    1941,
                    1942,
                    2960,
                    1944,
                    3473,
                    3480,
                    1436,
                    2972,
                    3486,
                    3487,
                    1448,
                    2984,
                    1966,
                    1971,
                    948,
                    1460,
                    1461,
                    1462,
                    1463,
                    3514,
                    3521,
                    1475,
                    964,
                    3527,
                    3528,
                    1993,
                    1997,
                    1487,
                    977,
                    466,
                    469,
                    471,
                    2009,
                    2010,
                    2011,
                    990,
                    1508,
                    3556,
                    3558,
                    2023,
                    3559,
                    1005,
                    3566,
                    3567,
                    1522,
                    506,
                    2043,
                    508,
                    509,
                    1534,
                    511
                ],
                "x.device_type": [
                    273
                ],
                "explicitly_on_cpu": [
                    285,
                    287
                ],
                "_is_current_explicit_device": [
                    285
                ],
                "gpus_available": [
                    286,
                    287
                ],
                "_get_available_gpus": [
                    286
                ],
                "tf.convert_to_tensor": [
                    302
                ],
                "dtype": [
                    384,
                    385,
                    3207,
                    3850,
                    3851,
                    396,
                    781,
                    3854,
                    3855,
                    3856,
                    3228,
                    2080,
                    2081,
                    2337,
                    3877,
                    422,
                    423,
                    424,
                    806,
                    3878,
                    3881,
                    302,
                    4017,
                    690,
                    691,
                    692,
                    948,
                    695,
                    2361,
                    3831,
                    848,
                    849,
                    722,
                    723,
                    724,
                    850,
                    727,
                    856,
                    3807,
                    3808,
                    3835,
                    3812,
                    887,
                    753,
                    754,
                    755,
                    500,
                    501,
                    756,
                    885,
                    886,
                    3186,
                    506,
                    3830,
                    508,
                    893
                ],
                "tensor": [
                    325,
                    2469,
                    2470,
                    2475,
                    348,
                    349,
                    351
                ],
                "tf.SparseTensor": [
                    3925,
                    468,
                    325,
                    390
                ],
                "is_sparse": [
                    1073,
                    348,
                    2470,
                    1879
                ],
                "tf.sparse_tensor_to_dense": [
                    349
                ],
                "name_scope": [
                    354
                ],
                "tf.name_scope": [
                    354
                ],
                "floatx": [
                    3808,
                    385,
                    3878,
                    423,
                    3831,
                    3851,
                    1327,
                    849,
                    754,
                    691,
                    723,
                    501,
                    886,
                    1367
                ],
                "sparse_coo": [
                    387,
                    388,
                    389,
                    391,
                    392,
                    393,
                    2471,
                    2472,
                    2473,
                    2474
                ],
                "value.tocoo": [
                    387,
                    2471
                ],
                "indices": [
                    388,
                    390,
                    2280,
                    2472,
                    2474,
                    3921,
                    3923,
                    3925,
                    1212
                ],
                "np.concatenate": [
                    2472,
                    388
                ],
                "np": [
                    388,
                    389,
                    1930,
                    397,
                    3853,
                    916,
                    1940,
                    1564,
                    2337,
                    2472,
                    2473,
                    3880,
                    1461,
                    2361,
                    3138,
                    853,
                    2011,
                    2016,
                    3810,
                    3833,
                    890
                ],
                "np.expand_dims": [
                    2472,
                    2473,
                    388,
                    389
                ],
                "sparse_coo.row": [
                    2472,
                    388
                ],
                "sparse_coo.col": [
                    2473,
                    389
                ],
                "sparse_coo.data": [
                    2474,
                    391
                ],
                "sparse_coo.shape": [
                    392,
                    393,
                    2474
                ],
                "v._keras_shape": [
                    400,
                    393,
                    398
                ],
                "v._uses_learning_phase": [
                    401,
                    394
                ],
                "tf.Variable": [
                    396
                ],
                "tf.as_dtype": [
                    2338,
                    396,
                    850,
                    755,
                    692,
                    724,
                    887,
                    2362
                ],
                "name": [
                    4033,
                    2456,
                    806,
                    424,
                    727,
                    396,
                    781,
                    4017,
                    4049,
                    819,
                    756,
                    693,
                    725,
                    695,
                    856,
                    506,
                    508,
                    893
                ],
                "np.ndarray": [
                    397
                ],
                "value.shape": [
                    2368,
                    398,
                    2343
                ],
                "int_shape": [
                    3744,
                    4130,
                    1061,
                    1928,
                    4077,
                    400,
                    1938,
                    2386,
                    916,
                    1054
                ],
                "v.constraint": [
                    404
                ],
                "constraint": [
                    404,
                    406
                ],
                "v._constraint": [
                    406
                ],
                "tf.constant": [
                    1794,
                    2018,
                    2693,
                    424,
                    1930,
                    1940,
                    2076,
                    1790
                ],
                "shape": [
                    3811,
                    3834,
                    1895,
                    424,
                    892,
                    3881,
                    2124,
                    855,
                    3854,
                    3855,
                    3856,
                    693,
                    502,
                    725,
                    504,
                    506,
                    508,
                    509
                ],
                "tf.Tensor": [
                    466
                ],
                "tf_variables.Variable": [
                    467
                ],
                "tf_variables": [
                    467
                ],
                "ndim": [
                    2824,
                    1162,
                    2587,
                    2588,
                    1052,
                    1821,
                    2593,
                    3745,
                    3747,
                    3748,
                    1830,
                    2599,
                    1067,
                    3759,
                    3775,
                    1739,
                    1873,
                    503,
                    1133,
                    1134,
                    2801,
                    1143,
                    504,
                    2042,
                    1150,
                    1151
                ],
                "_": [
                    504,
                    4131,
                    2683,
                    1999
                ],
                "sparse": [
                    505
                ],
                "tf.sparse_placeholder": [
                    506
                ],
                "tf.placeholder": [
                    508,
                    2367,
                    2343
                ],
                "x._keras_shape": [
                    509,
                    582
                ],
                "x._uses_learning_phase": [
                    2882,
                    510
                ],
                "x.op.type": [
                    524
                ],
                "x.op": [
                    524
                ],
                "tf.shape": [
                    1929,
                    2833,
                    1939,
                    2835,
                    3606,
                    1054,
                    1061,
                    557,
                    2734,
                    3380,
                    3901,
                    1743,
                    2642,
                    2009,
                    2655,
                    3048,
                    1137,
                    1140,
                    2682
                ],
                "as_list": [
                    2023,
                    584,
                    1993,
                    3283,
                    726,
                    694
                ],
                "x.get_shape": [
                    1792,
                    610,
                    1796,
                    2023,
                    584,
                    1993,
                    2011
                ],
                "dims": [
                    610,
                    611,
                    612
                ],
                "_dims": [
                    610
                ],
                "x.dtype.base_dtype.name": [
                    643
                ],
                "x.dtype.base_dtype": [
                    3104,
                    3105,
                    643,
                    1326,
                    2927,
                    1460,
                    1461,
                    1366,
                    1565,
                    1566
                ],
                "x.dtype": [
                    3104,
                    3105,
                    2338,
                    643,
                    1795,
                    1326,
                    2927,
                    1460,
                    1461,
                    1366,
                    2362,
                    1565,
                    1566,
                    1791
                ],
                "to_dense": [
                    664,
                    1882
                ],
                "tf_dtype": [
                    2338,
                    2343,
                    855,
                    887,
                    850,
                    755,
                    724,
                    725,
                    692,
                    693,
                    756,
                    2362,
                    892,
                    2367
                ],
                "tf.zeros": [
                    3856,
                    693
                ],
                "v.get_shape": [
                    726,
                    694
                ],
                "variable": [
                    695,
                    756,
                    727,
                    856,
                    893
                ],
                "tf.ones": [
                    725,
                    3855
                ],
                "tf.eye": [
                    756
                ],
                "size": [
                    756
                ],
                "tf.zeros_like": [
                    781
                ],
                "tf.ones_like": [
                    2837,
                    806
                ],
                "tf.identity": [
                    819
                ],
                "seed": [
                    3852,
                    3853,
                    3854,
                    3879,
                    3880,
                    3881,
                    3137,
                    3138,
                    3141,
                    851,
                    853,
                    855,
                    3809,
                    3810,
                    3812,
                    888,
                    3832,
                    3833,
                    890,
                    3835,
                    892
                ],
                "np.random.randint": [
                    3138,
                    3810,
                    3880,
                    3853,
                    853,
                    3833,
                    890
                ],
                "np.random": [
                    3138,
                    3810,
                    3880,
                    3853,
                    853,
                    3833,
                    890
                ],
                "tf.random_uniform_initializer": [
                    854
                ],
                "low": [
                    855
                ],
                "high": [
                    855
                ],
                "tf.random_normal_initializer": [
                    891
                ],
                "mean": [
                    1857,
                    3811,
                    1764,
                    1736,
                    3881,
                    1713,
                    1746,
                    1715,
                    1718,
                    892
                ],
                "scale": [
                    892
                ],
                "np.prod": [
                    916
                ],
                "tf.cast": [
                    3909,
                    1382,
                    2598,
                    3208,
                    1327,
                    2800,
                    3187,
                    948,
                    1397,
                    1367,
                    3229
                ],
                "tf.assign": [
                    2451,
                    964
                ],
                "new_x": [
                    964
                ],
                "tf.assign_add": [
                    977
                ],
                "increment": [
                    977
                ],
                "tf.assign_sub": [
                    990
                ],
                "decrement": [
                    990
                ],
                "moving_averages.assign_moving_average": [
                    1004
                ],
                "moving_averages": [
                    1004
                ],
                "momentum": [
                    1005
                ],
                "y": [
                    1155,
                    1671,
                    1052,
                    1061,
                    1067,
                    1580,
                    1070,
                    1074,
                    1076,
                    1593,
                    1606,
                    1619,
                    1632,
                    1645,
                    1134,
                    1137,
                    1143,
                    1145,
                    1658,
                    1147,
                    1151
                ],
                "x_shape": [
                    1056,
                    1058,
                    1059,
                    2019,
                    2020,
                    2023,
                    2024,
                    1993,
                    2025,
                    1995,
                    1069,
                    1997,
                    1072,
                    2009,
                    1053
                ],
                "i": [
                    1056,
                    1061,
                    1062,
                    1063,
                    4134,
                    4136,
                    4137,
                    2736,
                    4081,
                    4082,
                    4083,
                    1054,
                    1055
                ],
                "s": [
                    1058,
                    1061,
                    1065,
                    1999,
                    1054
                ],
                "tf.unstack": [
                    2622,
                    2617,
                    1061,
                    1054
                ],
                "x_shape.append": [
                    1056,
                    1058
                ],
                "y_shape": [
                    1060,
                    1063,
                    1065,
                    1066,
                    1070,
                    1072
                ],
                "y_shape.append": [
                    1065,
                    1063
                ],
                "y_permute_dim": [
                    1067,
                    1068,
                    1070
                ],
                "y_permute_dim.pop": [
                    1068
                ],
                "xt": [
                    1069,
                    1071
                ],
                "tf.reshape": [
                    2834,
                    1069,
                    1070,
                    1071,
                    2110,
                    3914,
                    2124,
                    3918,
                    3921,
                    1746,
                    1747,
                    1751,
                    1755,
                    3041,
                    2020,
                    1895,
                    3048,
                    1137,
                    1140
                ],
                "yt": [
                    1070,
                    1071
                ],
                "tf.transpose": [
                    3718,
                    3212,
                    3341,
                    3985,
                    3486,
                    3233,
                    2594,
                    3619,
                    2601,
                    1070,
                    1199,
                    3393,
                    3527,
                    3918,
                    3921,
                    3669,
                    2777,
                    3949,
                    3566,
                    3443,
                    1909,
                    3191,
                    1147
                ],
                "tf.matmul": [
                    1155,
                    1076,
                    1071
                ],
                "out": [
                    1155,
                    1161,
                    1162,
                    1163,
                    1164,
                    1074,
                    1076,
                    1077,
                    1145,
                    1147
                ],
                "tf.sparse_tensor_dense_matmul": [
                    1074
                ],
                "axes": [
                    2296,
                    2593,
                    2594,
                    2601,
                    1131,
                    1132,
                    2776,
                    2777,
                    2294,
                    2295,
                    1144,
                    1145,
                    1147,
                    1149,
                    1150,
                    1151
                ],
                "x_ndim": [
                    1157,
                    1158,
                    1160,
                    1133,
                    1135,
                    1136,
                    1138,
                    1139
                ],
                "y_ndim": [
                    1157,
                    1158,
                    1134,
                    1135,
                    1136,
                    1138,
                    1139
                ],
                "diff": [
                    1156,
                    1161,
                    1136,
                    1137,
                    1139,
                    1140,
                    1142
                ],
                "tf.concat": [
                    1137,
                    1882,
                    1140,
                    2833
                ],
                "tf.reduce_sum": [
                    3011,
                    1266,
                    1145,
                    1147,
                    3005
                ],
                "tf.multiply": [
                    1145,
                    1147
                ],
                "adj_x": [
                    1153,
                    1155,
                    1150
                ],
                "adj_y": [
                    1154,
                    1155,
                    1151
                ],
                "idx": [
                    1160,
                    1161,
                    1158
                ],
                "tf.squeeze": [
                    2151,
                    1161,
                    3946,
                    3945,
                    3440
                ],
                "expand_dims": [
                    2600,
                    1163
                ],
                "tf.gather": [
                    1212
                ],
                "reference": [
                    1212
                ],
                "tf.reduce_max": [
                    1232
                ],
                "axis": [
                    1283,
                    1411,
                    1296,
                    1424,
                    2960,
                    1309,
                    1328,
                    1331,
                    1349,
                    1739,
                    1740,
                    1995,
                    1997,
                    1743,
                    1232,
                    1872,
                    2000,
                    1875,
                    3154,
                    1877,
                    1368,
                    1880,
                    1882,
                    2008,
                    2138,
                    2265,
                    1249,
                    2017,
                    1508,
                    1383,
                    2151,
                    1266,
                    1398
                ],
                "keepdims": [
                    1249,
                    1283,
                    1508,
                    1349,
                    1383,
                    1232,
                    1266,
                    1332,
                    1398,
                    1368
                ],
                "tf.reduce_min": [
                    1249
                ],
                "tf.reduce_prod": [
                    1283
                ],
                "tf.cumsum": [
                    1296
                ],
                "tf.cumprod": [
                    1309
                ],
                "tf.bool": [
                    2597,
                    1382,
                    2598,
                    3909,
                    1326,
                    2799,
                    2707,
                    1397,
                    1366
                ],
                "m": [
                    1328,
                    1329
                ],
                "tf.reduce_mean": [
                    1328,
                    1330,
                    1368
                ],
                "devs_squared": [
                    1329,
                    1330
                ],
                "tf.square": [
                    1329,
                    1436
                ],
                "tf.sqrt": [
                    1349,
                    1463
                ],
                "var": [
                    1857,
                    1764,
                    1349,
                    1736,
                    1713,
                    1715,
                    1747,
                    1718
                ],
                "tf.reduce_any": [
                    1383
                ],
                "tf.reduce_all": [
                    1398
                ],
                "tf.argmax": [
                    1411
                ],
                "tf.argmin": [
                    1424
                ],
                "tf.abs": [
                    1448
                ],
                "zero": [
                    3104,
                    3106,
                    1460,
                    1462
                ],
                "_to_tensor": [
                    3104,
                    3009,
                    3105,
                    2927,
                    1460,
                    1461,
                    3070,
                    3035,
                    1565,
                    1566
                ],
                "inf": [
                    1461,
                    1462
                ],
                "np.inf": [
                    1564,
                    1461
                ],
                "tf.clip_by_value": [
                    3010,
                    3106,
                    1567,
                    1462,
                    3036,
                    3071
                ],
                "tf.exp": [
                    1475
                ],
                "tf.log": [
                    3072,
                    3011,
                    3949,
                    1487,
                    3985,
                    3037
                ],
                "tf.reduce_logsumexp": [
                    1508
                ],
                "tf.round": [
                    1522
                ],
                "tf.sign": [
                    1534
                ],
                "tf.pow": [
                    1547
                ],
                "a": [
                    1547
                ],
                "max_value": [
                    2926,
                    2927,
                    2928,
                    1561,
                    1562,
                    1563,
                    1564,
                    1566,
                    1567
                ],
                "min_value": [
                    1561,
                    1562,
                    1565,
                    1567
                ],
                "tf.equal": [
                    1580
                ],
                "tf.not_equal": [
                    1593
                ],
                "tf.greater": [
                    1606
                ],
                "tf.greater_equal": [
                    1619
                ],
                "tf.less": [
                    1632
                ],
                "tf.less_equal": [
                    1645
                ],
                "tf.maximum": [
                    1658
                ],
                "tf.minimum": [
                    2928,
                    1671
                ],
                "tf.sin": [
                    1683
                ],
                "tf.cos": [
                    1695
                ],
                "tf.nn.moments": [
                    1736,
                    1713
                ],
                "tf.nn": [
                    3074,
                    3332,
                    1798,
                    3087,
                    2960,
                    3480,
                    2972,
                    3615,
                    2984,
                    3119,
                    1713,
                    1715,
                    3763,
                    3771,
                    3389,
                    1857,
                    3521,
                    3141,
                    3014,
                    1736,
                    3658,
                    3787,
                    3662,
                    3154,
                    1757,
                    3294,
                    3042,
                    3170,
                    3558,
                    2922,
                    3434,
                    2924,
                    3707,
                    2942,
                    3711
                ],
                "reduction_axes": [
                    1824,
                    1827,
                    1830,
                    1736,
                    1832,
                    1740,
                    1836,
                    1713,
                    1782,
                    1821,
                    1822
                ],
                "normed": [
                    1715,
                    1764,
                    1757,
                    1718
                ],
                "tf.nn.batch_normalization": [
                    1857,
                    1715,
                    1757
                ],
                "beta": [
                    1793,
                    1794,
                    1827,
                    1857,
                    1831,
                    1801,
                    1835,
                    1716,
                    1752,
                    1755,
                    1823
                ],
                "gamma": [
                    1857,
                    1827,
                    1831,
                    1800,
                    1835,
                    1748,
                    1716,
                    1751,
                    1789,
                    1790,
                    1823
                ],
                "epsilon": [
                    1825,
                    1857,
                    1763,
                    1828,
                    3009,
                    1833,
                    1802,
                    1837,
                    3949,
                    3985,
                    1717,
                    3035,
                    3070
                ],
                "target_shape": [
                    1738,
                    1741,
                    1743,
                    1744,
                    1746,
                    1747,
                    1751,
                    1755
                ],
                "target_shape.append": [
                    1741,
                    1743
                ],
                "tf.stack": [
                    2664,
                    3370,
                    3595,
                    2124,
                    2734,
                    1744,
                    2642,
                    2674,
                    3381,
                    3903,
                    3607,
                    2265,
                    2044,
                    3902,
                    2655
                ],
                "broadcast_mean": [
                    1746,
                    1759
                ],
                "broadcast_var": [
                    1760,
                    1747
                ],
                "broadcast_gamma": [
                    1762,
                    1749,
                    1751
                ],
                "broadcast_beta": [
                    1753,
                    1755,
                    1761
                ],
                "normalization_axis": [
                    1792,
                    1786,
                    1796,
                    1783
                ],
                "tf_data_format": [
                    3329,
                    3713,
                    3717,
                    3209,
                    3338,
                    1803,
                    3340,
                    3597,
                    3214,
                    3215,
                    3599,
                    3473,
                    3475,
                    3610,
                    3484,
                    3485,
                    3230,
                    3617,
                    3618,
                    3235,
                    3236,
                    3372,
                    3374,
                    3384,
                    3514,
                    3516,
                    3391,
                    3392,
                    3648,
                    3650,
                    3525,
                    3526,
                    3660,
                    3664,
                    3668,
                    3291,
                    3293,
                    3421,
                    3423,
                    3300,
                    3556,
                    3564,
                    3565,
                    3438,
                    3697,
                    3442,
                    3699,
                    3188,
                    1784,
                    3193,
                    3194,
                    1787,
                    3709
                ],
                "tf.nn.fused_batch_norm": [
                    1798
                ],
                "_has_nchw_support": [
                    3232,
                    3211,
                    3762,
                    3190,
                    1822
                ],
                "_broadcast_normalize_batch_in_training": [
                    1835,
                    1823
                ],
                "_fused_normalize_batch_in_training": [
                    1826
                ],
                "_regular_normalize_batch_in_training": [
                    1831
                ],
                "rank": [
                    1873,
                    1874,
                    1875
                ],
                "tensors": [
                    1880,
                    1873,
                    1882,
                    1879
                ],
                "tf.sparse_concat": [
                    1880
                ],
                "pattern": [
                    2245,
                    2252,
                    2193,
                    1909,
                    2166,
                    2167,
                    2198,
                    2201,
                    2237,
                    2044,
                    2045
                ],
                "data_format": [
                    3590,
                    3591,
                    3592,
                    3593,
                    3597,
                    3599,
                    4123,
                    4124,
                    4125,
                    4126,
                    3618,
                    4140,
                    4152,
                    3643,
                    3644,
                    3645,
                    3646,
                    3648,
                    3668,
                    3692,
                    3693,
                    3694,
                    3695,
                    3697,
                    3189,
                    3717,
                    3210,
                    2187,
                    2188,
                    2189,
                    2190,
                    2192,
                    3740,
                    3741,
                    3742,
                    3231,
                    3743,
                    3749,
                    3754,
                    3760,
                    2231,
                    2232,
                    2233,
                    2234,
                    3769,
                    2236,
                    3776,
                    3781,
                    3278,
                    3279,
                    3280,
                    3281,
                    3290,
                    3324,
                    3325,
                    3326,
                    3327,
                    3329,
                    3340,
                    3365,
                    3366,
                    3367,
                    3368,
                    3372,
                    3374,
                    3392,
                    3416,
                    3417,
                    3418,
                    3419,
                    3421,
                    3442,
                    1927,
                    3468,
                    3469,
                    3470,
                    3471,
                    1937,
                    3473,
                    1946,
                    3485,
                    1965,
                    1970,
                    3509,
                    3510,
                    3511,
                    1976,
                    3512,
                    3514,
                    3526,
                    3551,
                    3552,
                    3553,
                    3554,
                    3556,
                    4071,
                    4072,
                    4073,
                    4074,
                    3565
                ],
                "original_shape": [
                    1928,
                    1934,
                    1935,
                    1938,
                    1942,
                    1943
                ],
                "new_shape": [
                    1929,
                    1930,
                    1932,
                    1939,
                    1940,
                    1941
                ],
                "astype": [
                    1930,
                    1940
                ],
                "np.array": [
                    1930,
                    1940
                ],
                "height_factor": [
                    1930,
                    1934,
                    1967,
                    1940,
                    1972,
                    1942
                ],
                "width_factor": [
                    1930,
                    1935,
                    1968,
                    1940,
                    1973,
                    1943
                ],
                "permute_dimensions": [
                    1931,
                    1933,
                    4089,
                    4155,
                    4153
                ],
                "tf.image.resize_nearest_neighbor": [
                    1932,
                    1941
                ],
                "tf.image": [
                    1932,
                    1941
                ],
                "x.set_shape": [
                    1942,
                    1934
                ],
                "output": [
                    3072,
                    3075,
                    2725,
                    2728,
                    1966,
                    1967,
                    1968,
                    1969,
                    2734,
                    1971,
                    1972,
                    1973,
                    1974,
                    2735,
                    2737,
                    4148,
                    4149,
                    4153,
                    4155,
                    3005,
                    3006,
                    4156,
                    2752,
                    3009,
                    3010,
                    2627,
                    2628,
                    2755,
                    3011,
                    3012,
                    2760,
                    3015,
                    2642,
                    2645,
                    2649,
                    3035,
                    3036,
                    3037,
                    3039,
                    3041,
                    2660,
                    3048,
                    2667,
                    2668,
                    2670,
                    4088,
                    4089,
                    3070,
                    3071
                ],
                "repeat_elements": [
                    1966,
                    1967,
                    1968,
                    1971,
                    1972,
                    1973
                ],
                "depth_factor": [
                    1971,
                    1966
                ],
                "splits": [
                    1997,
                    1999
                ],
                "tf.split": [
                    1997
                ],
                "x_rep": [
                    2020,
                    2024,
                    2025,
                    2026,
                    1999,
                    2000,
                    2010,
                    2013
                ],
                "rep": [
                    2017,
                    2012,
                    1999
                ],
                "concatenate": [
                    2000,
                    3921,
                    4147,
                    4086
                ],
                "auxiliary_axis": [
                    2008,
                    2010,
                    2016,
                    2012
                ],
                "tf.expand_dims": [
                    3906,
                    3429,
                    2138,
                    3430,
                    3431,
                    3951,
                    2010,
                    2043
                ],
                "reps": [
                    2016,
                    2017,
                    2018,
                    2019,
                    2011,
                    2012,
                    2013
                ],
                "np.ones": [
                    2011
                ],
                "tf.tile": [
                    3914,
                    2733,
                    3918,
                    2013,
                    2641,
                    2098,
                    2838,
                    2045,
                    2654
                ],
                "np.delete": [
                    2016
                ],
                "x_rep.set_shape": [
                    2024
                ],
                "x_rep._keras_shape": [
                    2025
                ],
                "n": [
                    2096,
                    2097,
                    2098,
                    2044
                ],
                "stop": [
                    2069,
                    2079
                ],
                "start": [
                    2071,
                    2072,
                    2075,
                    2076,
                    2077,
                    2079
                ],
                "tf.cond": [
                    2075,
                    2813
                ],
                "start.dtype": [
                    2076
                ],
                "result": [
                    2081,
                    2082,
                    2079
                ],
                "tf.range": [
                    3906,
                    3914,
                    3918,
                    2079
                ],
                "step": [
                    2079
                ],
                "cast": [
                    3040,
                    2081
                ],
                "prod": [
                    2124
                ],
                "padding": [
                    3712,
                    3331,
                    2184,
                    2185,
                    2186,
                    3337,
                    3474,
                    2195,
                    2196,
                    2199,
                    3609,
                    3482,
                    3616,
                    2227,
                    2228,
                    2229,
                    2230,
                    3251,
                    3252,
                    3253,
                    3254,
                    3256,
                    3257,
                    3383,
                    3390,
                    3515,
                    2240,
                    2241,
                    2242,
                    3523,
                    3649,
                    2247,
                    2248,
                    2249,
                    3659,
                    3663,
                    3284,
                    3288,
                    3289,
                    3422,
                    3299,
                    3557,
                    3563,
                    3436,
                    3698,
                    2165,
                    2166,
                    3708
                ],
                "tf.pad": [
                    2201,
                    2252,
                    2167
                ],
                "image_data_format": [
                    3552,
                    3366,
                    3591,
                    3741,
                    4072,
                    2188,
                    3469,
                    3693,
                    3279,
                    4124,
                    3510,
                    2232,
                    3417,
                    3644,
                    3325
                ],
                "tf.one_hot": [
                    2280
                ],
                "num_classes": [
                    2280
                ],
                "tf.reverse": [
                    2296
                ],
                "x.eval": [
                    2311
                ],
                "ops": [
                    2323,
                    2324
                ],
                "run": [
                    2347,
                    2324,
                    2374
                ],
                "np.asarray": [
                    2337,
                    2361
                ],
                "x.dtype.name.split": [
                    2338,
                    2362
                ],
                "x.dtype.name": [
                    2338,
                    2362
                ],
                "assign_placeholder": [
                    2369,
                    2370,
                    2340,
                    2373,
                    2343,
                    2344,
                    2345,
                    2347,
                    2364,
                    2367
                ],
                "x._assign_placeholder": [
                    2345,
                    2370,
                    2340,
                    2364
                ],
                "assign_op": [
                    2369,
                    2371,
                    2372,
                    2341,
                    2344,
                    2346,
                    2347,
                    2365
                ],
                "x._assign_op": [
                    2371,
                    2346,
                    2365,
                    2341
                ],
                "x.assign": [
                    2344,
                    2369
                ],
                "tuples": [
                    2360,
                    2357
                ],
                "assign_ops": [
                    2374,
                    2372,
                    2358
                ],
                "feed_dict": [
                    2468,
                    2373,
                    2374,
                    2475,
                    2478,
                    2359
                ],
                "assign_ops.append": [
                    2372
                ],
                "tf.Print": [
                    2408
                ],
                "message": [
                    2408
                ],
                "updates": [
                    2448,
                    2441,
                    2434,
                    2503
                ],
                "inputs": [
                    2689,
                    2466,
                    2435,
                    2594,
                    2469,
                    2692,
                    2503,
                    2683,
                    2444,
                    4141,
                    4144,
                    2610,
                    4084,
                    2678,
                    2617,
                    2682,
                    2587
                ],
                "outputs": [
                    2438,
                    2503,
                    2664,
                    2445,
                    2674,
                    2773,
                    2776,
                    2777,
                    2683,
                    2685,
                    2779
                ],
                "self.inputs": [
                    2444,
                    2469
                ],
                "self.outputs": [
                    2480,
                    2476,
                    2445,
                    2446
                ],
                "tf.control_dependencies": [
                    2446
                ],
                "updates_ops": [
                    2455,
                    2451,
                    2454,
                    2447
                ],
                "update": [
                    2448,
                    2449,
                    2450,
                    2454
                ],
                "p": [
                    2450,
                    2451,
                    3854
                ],
                "new_p": [
                    2450,
                    2451
                ],
                "updates_ops.append": [
                    2451,
                    2454
                ],
                "self.updates_op": [
                    2476,
                    2455
                ],
                "tf.group": [
                    2455
                ],
                "self.name": [
                    2456
                ],
                "self.feed_dict": [
                    2458,
                    2468
                ],
                "session_kwargs.pop": [
                    2458,
                    2460
                ],
                "session_kwargs": [
                    2458,
                    2460,
                    2463
                ],
                "self.fetches": [
                    2476,
                    2460,
                    2461,
                    2462
                ],
                "self.session_kwargs": [
                    2479,
                    2463
                ],
                "self.feed_dict.copy": [
                    2468
                ],
                "fetches": [
                    2476,
                    2478
                ],
                "updated": [
                    2480,
                    2478
                ],
                "kwargs": [
                    2498,
                    2499,
                    2503
                ],
                "key": [
                    2499,
                    2500,
                    2501
                ],
                "has_arg": [
                    2500
                ],
                "tf.Session.run": [
                    2500
                ],
                "Function.__init__": [
                    2500
                ],
                "Function": [
                    2500,
                    2503
                ],
                "msg": [
                    2501,
                    2502
                ],
                "tf.gradients": [
                    2516
                ],
                "loss": [
                    2516
                ],
                "tf.stop_gradient": [
                    2531,
                    2533
                ],
                "inputs.get_shape": [
                    2610,
                    2587
                ],
                "mask": [
                    2596,
                    2597,
                    2598,
                    2599,
                    2600,
                    2601,
                    2695,
                    2704,
                    2710,
                    2621,
                    2622
                ],
                "mask.dtype": [
                    2597
                ],
                "mask.get_shape": [
                    2599
                ],
                "constants": [
                    2754,
                    2627,
                    2727,
                    2667,
                    2603,
                    2604,
                    2683
                ],
                "uses_learning_phase": [
                    2881,
                    2757,
                    2629,
                    2730,
                    2669,
                    2607,
                    2863,
                    2865,
                    2778
                ],
                "unroll": [
                    2609
                ],
                "states": [
                    2753,
                    2659,
                    2627,
                    2661,
                    2726,
                    2758,
                    2696,
                    2667,
                    2731,
                    2766,
                    2671,
                    2735,
                    2736,
                    2613,
                    2680,
                    2652
                ],
                "initial_states": [
                    2680,
                    2683,
                    2613
                ],
                "successive_states": [
                    2661,
                    2663,
                    2671,
                    2673,
                    2614
                ],
                "successive_outputs": [
                    2660,
                    2615,
                    2662,
                    2664,
                    2670,
                    2672,
                    2674,
                    2644,
                    2647
                ],
                "input_list": [
                    2617,
                    2626,
                    2619,
                    2666
                ],
                "go_backwards": [
                    2703,
                    2618,
                    2677,
                    2623
                ],
                "input_list.reverse": [
                    2619
                ],
                "mask_list": [
                    2624,
                    2626,
                    2622
                ],
                "mask_list.reverse": [
                    2624
                ],
                "inp": [
                    2667,
                    2626,
                    2627,
                    2666
                ],
                "mask_t": [
                    2626,
                    2724,
                    2733,
                    2641,
                    2654
                ],
                "new_states": [
                    2752,
                    2627,
                    2725,
                    2758,
                    2663,
                    2761,
                    2731,
                    2736,
                    2673,
                    2738,
                    2771,
                    2779,
                    2652
                ],
                "step_function": [
                    2752,
                    2627,
                    2725,
                    2667,
                    2683
                ],
                "tiled_mask_t": [
                    2656,
                    2733,
                    2735,
                    2736,
                    2641,
                    2649,
                    2654
                ],
                "prev_output": [
                    2649,
                    2645,
                    2647
                ],
                "zeros_like": [
                    2645
                ],
                "tf.where": [
                    2656,
                    2946,
                    3854,
                    2735,
                    2736,
                    2837,
                    2839,
                    2649
                ],
                "return_states": [
                    2656,
                    2659,
                    2651
                ],
                "state": [
                    2658,
                    2758,
                    2759,
                    2731,
                    2732,
                    2652
                ],
                "new_state": [
                    2657,
                    2758,
                    2759,
                    2731,
                    2732,
                    2652,
                    2655
                ],
                "return_states.append": [
                    2656
                ],
                "successive_outputs.append": [
                    2660,
                    2670
                ],
                "successive_states.append": [
                    2661,
                    2671
                ],
                "last_output": [
                    2662,
                    2672,
                    2774,
                    2778,
                    2779
                ],
                "reverse": [
                    2704,
                    2678,
                    3919
                ],
                "time_steps": [
                    2690,
                    2764,
                    2708,
                    2682,
                    2686
                ],
                "output_ta": [
                    2766,
                    2770,
                    2773,
                    2774,
                    2684
                ],
                "tensor_array_ops.TensorArray": [
                    2688,
                    2706,
                    2684
                ],
                "tensor_array_ops": [
                    2688,
                    2706,
                    2684
                ],
                "outputs.dtype": [
                    2685
                ],
                "input_ta": [
                    2688,
                    2723,
                    2692,
                    2751
                ],
                "inputs.dtype": [
                    2689
                ],
                "input_ta.unstack": [
                    2692
                ],
                "time": [
                    2723,
                    2724,
                    2693,
                    2760,
                    2761,
                    2764,
                    2766,
                    2737,
                    2738,
                    2751
                ],
                "mask_ta": [
                    2706,
                    2724,
                    2710
                ],
                "mask_ta.unstack": [
                    2710
                ],
                "current_input": [
                    2752,
                    3907,
                    2723,
                    2725,
                    2751
                ],
                "input_ta.read": [
                    2723,
                    2751
                ],
                "mask_ta.read": [
                    2724
                ],
                "new_state.set_shape": [
                    2732,
                    2759
                ],
                "state.get_shape": [
                    2732,
                    2759
                ],
                "output_ta_t": [
                    2760,
                    2737,
                    2738,
                    2761
                ],
                "output_ta_t.write": [
                    2760,
                    2737
                ],
                "final_outputs": [
                    2769,
                    2770,
                    2763,
                    2771
                ],
                "control_flow_ops.while_loop": [
                    2763
                ],
                "control_flow_ops": [
                    2763
                ],
                "_step": [
                    2765
                ],
                "last_time": [
                    2769,
                    2774
                ],
                "output_ta.stack": [
                    2773
                ],
                "output_ta.read": [
                    2774
                ],
                "outputs.get_shape": [
                    2776
                ],
                "last_output._uses_learning_phase": [
                    2778
                ],
                "condition.dtype": [
                    2799
                ],
                "condition": [
                    2799,
                    2800,
                    2801,
                    2833,
                    2834,
                    2838,
                    2839,
                    2813
                ],
                "cond_ndim": [
                    2825,
                    2829,
                    2831,
                    2832,
                    2801,
                    2802
                ],
                "then_expression": [
                    2820,
                    2821,
                    2824,
                    2839,
                    2803,
                    2835,
                    2805,
                    2807
                ],
                "then_expression_fn": [
                    2814,
                    2807
                ],
                "else_expression": [
                    2822,
                    2823,
                    2839,
                    2808,
                    2810,
                    2812
                ],
                "else_expression_fn": [
                    2812,
                    2815
                ],
                "expr_ndim": [
                    2824,
                    2825,
                    2830,
                    2832
                ],
                "ndim_diff": [
                    2832,
                    2833
                ],
                "cond_shape": [
                    2833,
                    2834,
                    2836
                ],
                "expr_shape": [
                    2835,
                    2836,
                    2837
                ],
                "shape_diff": [
                    2836,
                    2837
                ],
                "tile_shape": [
                    2837,
                    2838
                ],
                "training": [
                    2880,
                    2861,
                    2862,
                    2867,
                    2903,
                    2873
                ],
                "learning_phase": [
                    2862
                ],
                "alt": [
                    2880,
                    2903,
                    2874,
                    2875,
                    2877
                ],
                "switch": [
                    2880
                ],
                "in_train_phase": [
                    2903
                ],
                "alpha": [
                    2921,
                    2922,
                    2946,
                    2943
                ],
                "tf.nn.leaky_relu": [
                    2922
                ],
                "tf.nn.relu": [
                    2924
                ],
                "res": [
                    2944,
                    2946,
                    3042,
                    3048,
                    3050,
                    2942
                ],
                "tf.nn.elu": [
                    2942
                ],
                "tf.nn.softmax": [
                    2960
                ],
                "tf.nn.softplus": [
                    2972
                ],
                "tf.nn.softsign": [
                    2984
                ],
                "from_logits": [
                    3034,
                    3003,
                    3068
                ],
                "output.get_shape": [
                    3012,
                    3006,
                    3039
                ],
                "_epsilon": [
                    3009,
                    3010,
                    3035,
                    3036,
                    3070,
                    3071
                ],
                "output.dtype.base_dtype": [
                    3009,
                    3035,
                    3070
                ],
                "output.dtype": [
                    3009,
                    3035,
                    3070
                ],
                "target": [
                    3040,
                    3074,
                    3011,
                    3014
                ],
                "tf.nn.softmax_cross_entropy_with_logits": [
                    3014
                ],
                "output_shape": [
                    3594,
                    3595,
                    3600,
                    3601,
                    3602,
                    3603,
                    3604,
                    3605,
                    3606,
                    3607,
                    3615,
                    4129,
                    3369,
                    3370,
                    3375,
                    3376,
                    3377,
                    3378,
                    3379,
                    3380,
                    3381,
                    3389,
                    3039,
                    3041,
                    3045
                ],
                "targets": [
                    3040,
                    3170,
                    3043
                ],
                "flatten": [
                    3040
                ],
                "logits": [
                    3041,
                    3044
                ],
                "tf.nn.sparse_softmax_cross_entropy_with_logits": [
                    3042
                ],
                "tf.nn.sigmoid_cross_entropy_with_logits": [
                    3074
                ],
                "tf.nn.sigmoid": [
                    3087
                ],
                "one": [
                    3105,
                    3106
                ],
                "tf.nn.tanh": [
                    3119
                ],
                "retain_prob": [
                    3136,
                    3141
                ],
                "level": [
                    3136
                ],
                "tf.nn.dropout": [
                    3141
                ],
                "noise_shape": [
                    3141
                ],
                "tf.nn.l2_normalize": [
                    3154
                ],
                "tf.nn.in_top_k": [
                    3170
                ],
                "predictions": [
                    3170
                ],
                "k": [
                    3170
                ],
                "kernel_shape": [
                    4130,
                    4131,
                    4077,
                    4078,
                    3283,
                    3286
                ],
                "kernel.get_shape": [
                    3283
                ],
                "kernel": [
                    3296,
                    4130,
                    3334,
                    3560,
                    4077,
                    3283,
                    4148,
                    4088,
                    3389,
                    3615
                ],
                "left_pad": [
                    3286,
                    3287
                ],
                "dilation_rate": [
                    3297,
                    3524,
                    3335,
                    3432,
                    3561,
                    3437,
                    3286,
                    3483
                ],
                "temporal_padding": [
                    3287
                ],
                "_preprocess_padding": [
                    3649,
                    3331,
                    3557,
                    3609,
                    3474,
                    3698,
                    3383,
                    3289,
                    3515,
                    3422
                ],
                "tf.nn.convolution": [
                    3558,
                    3332,
                    3294
                ],
                "strides": [
                    3336,
                    3476,
                    3478,
                    3481,
                    3611,
                    3613,
                    3615,
                    4128,
                    3385,
                    3387,
                    3389,
                    3517,
                    3519,
                    3522,
                    3651,
                    3654,
                    3658,
                    3662,
                    3425,
                    3298,
                    3428,
                    3562,
                    3435,
                    4076,
                    3700,
                    3703,
                    3707,
                    3711
                ],
                "_preprocess_conv2d_input": [
                    3648,
                    3329,
                    3372,
                    3473,
                    3514
                ],
                "tf.nn.conv2d_transpose": [
                    3389
                ],
                "_preprocess_conv1d_input": [
                    3421
                ],
                "spatial_start_dim": [
                    3424,
                    3427,
                    3440,
                    3429
                ],
                "depthwise_kernel": [
                    3480,
                    3521,
                    3434,
                    3430
                ],
                "pointwise_kernel": [
                    3480,
                    3434,
                    3431
                ],
                "tf.nn.separable_conv2d": [
                    3480,
                    3434
                ],
                "tf.nn.depthwise_conv2d": [
                    3521
                ],
                "_preprocess_conv3d_input": [
                    3697,
                    3556,
                    3597
                ],
                "tf.nn.conv3d_transpose": [
                    3615
                ],
                "pool_size": [
                    3652,
                    3655,
                    3658,
                    3662,
                    3701,
                    3704,
                    3707,
                    3711
                ],
                "pool_mode": [
                    3715,
                    3657,
                    3661,
                    3666,
                    3706,
                    3710
                ],
                "tf.nn.max_pool": [
                    3658
                ],
                "tf.nn.avg_pool": [
                    3662
                ],
                "tf.nn.max_pool3d": [
                    3707
                ],
                "tf.nn.avg_pool3d": [
                    3711
                ],
                "bias_shape": [
                    3744,
                    3745,
                    3747,
                    3750,
                    3751,
                    3753,
                    3755,
                    3756,
                    3758,
                    3761,
                    3766,
                    3768,
                    3770,
                    3774,
                    3777,
                    3778,
                    3780,
                    3782,
                    3783,
                    3785
                ],
                "bias": [
                    3744,
                    3778,
                    3780,
                    3751,
                    3783,
                    3753,
                    3785,
                    3787,
                    3756,
                    3758,
                    3763,
                    3766,
                    3768,
                    3771,
                    3774
                ],
                "reshape": [
                    3778,
                    3780,
                    3751,
                    3783,
                    3753,
                    3785,
                    3756,
                    4141,
                    3758,
                    4144,
                    4084,
                    4149,
                    3766,
                    3768,
                    3774
                ],
                "tf.nn.bias_add": [
                    3763,
                    3771,
                    3787
                ],
                "tf.random_normal": [
                    3811
                ],
                "stddev": [
                    3881,
                    3811
                ],
                "tf.random_uniform": [
                    3834,
                    3854
                ],
                "minval": [
                    3834
                ],
                "maxval": [
                    3834
                ],
                "tf.truncated_normal": [
                    3881
                ],
                "label_shape": [
                    3906,
                    3909,
                    3914,
                    3915,
                    3918,
                    3919,
                    3925,
                    3901,
                    3902,
                    3903
                ],
                "labels": [
                    3923,
                    3901
                ],
                "num_batches_tns": [
                    3914,
                    3902
                ],
                "max_num_labels_tns": [
                    3907,
                    3919,
                    3903
                ],
                "tf.fill": [
                    3906,
                    3909
                ],
                "init": [
                    3909,
                    3911
                ],
                "dense_mask": [
                    3912,
                    3920,
                    3916,
                    3910
                ],
                "functional_ops.scan": [
                    3910
                ],
                "functional_ops": [
                    3910
                ],
                "range_less_than": [
                    3910
                ],
                "label_lengths": [
                    3910
                ],
                "label_array": [
                    3914,
                    3916
                ],
                "label_ind": [
                    3921,
                    3916
                ],
                "tf.boolean_mask": [
                    3920,
                    3916
                ],
                "batch_array": [
                    3920,
                    3918
                ],
                "batch_ind": [
                    3920,
                    3921
                ],
                "vals_sparse": [
                    3923,
                    3925
                ],
                "tf.gather_nd": [
                    3923
                ],
                "tf.to_int64": [
                    3925
                ],
                "label_length": [
                    3945,
                    3947
                ],
                "tf.to_int32": [
                    3945,
                    3946,
                    3947,
                    3986
                ],
                "input_length": [
                    3946,
                    3953,
                    3986,
                    3991,
                    3995
                ],
                "sparse_labels": [
                    3952,
                    3947
                ],
                "ctc_label_dense_to_sparse": [
                    3947
                ],
                "y_true": [
                    3947
                ],
                "y_pred": [
                    3949,
                    3951,
                    3985,
                    3990,
                    3994
                ],
                "ctc.ctc_loss": [
                    3951
                ],
                "ctc": [
                    3993,
                    3989,
                    3951
                ],
                "greedy": [
                    3988
                ],
                "decoded": [
                    3993,
                    3989,
                    3999
                ],
                "log_prob": [
                    4000,
                    3993,
                    3989
                ],
                "ctc.ctc_greedy_decoder": [
                    3989
                ],
                "ctc.ctc_beam_search_decoder": [
                    3993
                ],
                "beam_width": [
                    3995
                ],
                "top_paths": [
                    3996
                ],
                "decoded_dense": [
                    4000,
                    3998
                ],
                "tf.sparse_to_dense": [
                    3998
                ],
                "st.indices": [
                    3998
                ],
                "st": [
                    3998,
                    3999
                ],
                "st.dense_shape": [
                    3998
                ],
                "st.values": [
                    3998
                ],
                "tf.map_fn": [
                    4017
                ],
                "fn": [
                    4049,
                    4017,
                    4033
                ],
                "elems": [
                    4049,
                    4017,
                    4033
                ],
                "tf.foldl": [
                    4033
                ],
                "initializer": [
                    4033,
                    4049
                ],
                "tf.foldr": [
                    4049
                ],
                "stride": [
                    4082,
                    4083,
                    4076
                ],
                "output_length": [
                    4081,
                    4078
                ],
                "feature_dim": [
                    4131,
                    4142,
                    4078,
                    4145,
                    4085
                ],
                "filters": [
                    4150,
                    4131,
                    4078
                ],
                "xs": [
                    4133,
                    4141,
                    4080,
                    4144,
                    4147,
                    4084,
                    4086
                ],
                "slice_length": [
                    4082,
                    4084
                ],
                "kernel_size": [
                    4137,
                    4139,
                    4083
                ],
                "xs.append": [
                    4144,
                    4084,
                    4141
                ],
                "x_aggregate": [
                    4088,
                    4147,
                    4148,
                    4086
                ],
                "batch_dot": [
                    4088,
                    4148
                ],
                "stride_row": [
                    4128,
                    4137,
                    4136
                ],
                "stride_col": [
                    4128,
                    4138,
                    4139
                ],
                "output_row": [
                    4150,
                    4129,
                    4134
                ],
                "output_col": [
                    4129,
                    4150,
                    4135
                ],
                "j": [
                    4138,
                    4139,
                    4135
                ],
                "slice_row": [
                    4136,
                    4144,
                    4141
                ],
                "slice_col": [
                    4144,
                    4138,
                    4141
                ]
            }
        },
        "test_data": [
            {
                "test_path": "/Volumes/SSD2T/bgp_envs/repos/keras_31/tests/keras/backend/backend_test.py",
                "test_function": "test_ctc",
                "test_function_code": "    @pytest.mark.skipif(K.backend() == 'cntk', reason='Not supported.')\n    def test_ctc(self):\n        if K.backend() == 'theano':\n            ref = [1.73308, 3.81351]\n        else:\n            ref = [3.34211, 5.42262]\n        # simplified version of TensorFlow's test\n\n        label_lens = np.expand_dims(np.asarray([5, 4]), 1)\n        input_lens = np.expand_dims(np.asarray([5, 5]), 1)  # number of timesteps\n\n        # dimensions are batch x time x categories\n        labels = np.asarray([[0, 1, 2, 1, 0], [0, 1, 1, 0, -1]])\n        inputs = np.asarray(\n            [[[0.633766, 0.221185, 0.0917319, 0.0129757, 0.0142857, 0.0260553],\n              [0.111121, 0.588392, 0.278779, 0.0055756, 0.00569609, 0.010436],\n              [0.0357786, 0.633813, 0.321418, 0.00249248, 0.00272882, 0.0037688],\n              [0.0663296, 0.643849, 0.280111, 0.00283995, 0.0035545, 0.00331533],\n              [0.458235, 0.396634, 0.123377, 0.00648837, 0.00903441, 0.00623107]],\n             [[0.30176, 0.28562, 0.0831517, 0.0862751, 0.0816851, 0.161508],\n              [0.24082, 0.397533, 0.0557226, 0.0546814, 0.0557528, 0.19549],\n              [0.230246, 0.450868, 0.0389607, 0.038309, 0.0391602, 0.202456],\n              [0.280884, 0.429522, 0.0326593, 0.0339046, 0.0326856, 0.190345],\n              [0.423286, 0.315517, 0.0338439, 0.0393744, 0.0339315, 0.154046]]],\n            dtype=np.float32)\n\n        k_labels = K.variable(labels, dtype=\"int32\")\n        k_inputs = K.variable(inputs, dtype=\"float32\")\n        k_input_lens = K.variable(input_lens, dtype=\"int32\")\n        k_label_lens = K.variable(label_lens, dtype=\"int32\")\n        res = K.eval(K.ctc_batch_cost(k_labels, k_inputs, k_input_lens, k_label_lens))\n        assert_allclose(res[0, :] if K.backend() == 'theano' else res[:, 0], ref, atol=1e-05)\n\n        # test when batch_size = 1, that is, one sample only\n        # get only first sample from above test case\n        if K.backend() == 'theano':\n            ref = [1.73308]\n        else:\n            ref = [3.34211]\n\n        input_lens = np.expand_dims(np.asarray([5]), 1)\n        label_lens = np.expand_dims(np.asarray([5]), 1)\n\n        labels = np.asarray([[0, 1, 2, 1, 0]])\n        inputs = np.asarray(\n            [[[0.633766, 0.221185, 0.0917319, 0.0129757, 0.0142857, 0.0260553],\n              [0.111121, 0.588392, 0.278779, 0.0055756, 0.00569609, 0.010436],\n              [0.0357786, 0.633813, 0.321418, 0.00249248, 0.00272882, 0.0037688],\n              [0.0663296, 0.643849, 0.280111, 0.00283995, 0.0035545, 0.00331533],\n              [0.458235, 0.396634, 0.123377, 0.00648837, 0.00903441, 0.00623107]]],\n            dtype=np.float32)\n\n        k_labels = K.variable(labels, dtype=\"int32\")\n        k_inputs = K.variable(inputs, dtype=\"float32\")\n        k_input_lens = K.variable(input_lens, dtype=\"int32\")\n        k_label_lens = K.variable(label_lens, dtype=\"int32\")\n        res = K.eval(K.ctc_batch_cost(k_labels, k_inputs, k_input_lens, k_label_lens))\n        assert_allclose(res[0, :] if K.backend() == 'theano' else res[:, 0], ref, atol=1e-05)",
                "test_error": "IndexError: list index out of range",
                "full_test_error": "self = <backend_test.TestBackend object at 0x12dcac110>\n\n    @pytest.mark.skipif(K.backend() == 'cntk', reason='Not supported.')\n    def test_ctc(self):\n        if K.backend() == 'theano':\n            ref = [1.73308, 3.81351]\n        else:\n            ref = [3.34211, 5.42262]\n        # simplified version of TensorFlow's test\n    \n        label_lens = np.expand_dims(np.asarray([5, 4]), 1)\n        input_lens = np.expand_dims(np.asarray([5, 5]), 1)  # number of timesteps\n    \n        # dimensions are batch x time x categories\n        labels = np.asarray([[0, 1, 2, 1, 0], [0, 1, 1, 0, -1]])\n        inputs = np.asarray(\n            [[[0.633766, 0.221185, 0.0917319, 0.0129757, 0.0142857, 0.0260553],\n              [0.111121, 0.588392, 0.278779, 0.0055756, 0.00569609, 0.010436],\n              [0.0357786, 0.633813, 0.321418, 0.00249248, 0.00272882, 0.0037688],\n              [0.0663296, 0.643849, 0.280111, 0.00283995, 0.0035545, 0.00331533],\n              [0.458235, 0.396634, 0.123377, 0.00648837, 0.00903441, 0.00623107]],\n             [[0.30176, 0.28562, 0.0831517, 0.0862751, 0.0816851, 0.161508],\n              [0.24082, 0.397533, 0.0557226, 0.0546814, 0.0557528, 0.19549],\n              [0.230246, 0.450868, 0.0389607, 0.038309, 0.0391602, 0.202456],\n              [0.280884, 0.429522, 0.0326593, 0.0339046, 0.0326856, 0.190345],\n              [0.423286, 0.315517, 0.0338439, 0.0393744, 0.0339315, 0.154046]]],\n            dtype=np.float32)\n    \n        k_labels = K.variable(labels, dtype=\"int32\")\n        k_inputs = K.variable(inputs, dtype=\"float32\")\n        k_input_lens = K.variable(input_lens, dtype=\"int32\")\n        k_label_lens = K.variable(label_lens, dtype=\"int32\")\n        res = K.eval(K.ctc_batch_cost(k_labels, k_inputs, k_input_lens, k_label_lens))\n        assert_allclose(res[0, :] if K.backend() == 'theano' else res[:, 0], ref, atol=1e-05)\n    \n        # test when batch_size = 1, that is, one sample only\n        # get only first sample from above test case\n        if K.backend() == 'theano':\n            ref = [1.73308]\n        else:\n            ref = [3.34211]\n    \n        input_lens = np.expand_dims(np.asarray([5]), 1)\n        label_lens = np.expand_dims(np.asarray([5]), 1)\n    \n        labels = np.asarray([[0, 1, 2, 1, 0]])\n        inputs = np.asarray(\n            [[[0.633766, 0.221185, 0.0917319, 0.0129757, 0.0142857, 0.0260553],\n              [0.111121, 0.588392, 0.278779, 0.0055756, 0.00569609, 0.010436],\n              [0.0357786, 0.633813, 0.321418, 0.00249248, 0.00272882, 0.0037688],\n              [0.0663296, 0.643849, 0.280111, 0.00283995, 0.0035545, 0.00331533],\n              [0.458235, 0.396634, 0.123377, 0.00648837, 0.00903441, 0.00623107]]],\n            dtype=np.float32)\n    \n        k_labels = K.variable(labels, dtype=\"int32\")\n        k_inputs = K.variable(inputs, dtype=\"float32\")\n        k_input_lens = K.variable(input_lens, dtype=\"int32\")\n        k_label_lens = K.variable(label_lens, dtype=\"int32\")\n>       res = K.eval(K.ctc_batch_cost(k_labels, k_inputs, k_input_lens, k_label_lens))\n\ntests/keras/backend/backend_test.py:1501: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nkeras/backend/tensorflow_backend.py:3947: in ctc_batch_cost\n    sparse_labels = tf.to_int32(ctc_label_dense_to_sparse(y_true, label_length))\nkeras/backend/tensorflow_backend.py:3911: in ctc_label_dense_to_sparse\n    initializer=init, parallel_iterations=1)\n../../envs/keras_31/lib/python3.7/site-packages/tensorflow/python/ops/functional_ops.py:651: in scan\n    n = (tensor_shape.dimension_value(elems_flat[0].shape[0])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = TensorShape([]), key = 0\n\n    def __getitem__(self, key):\n      \"\"\"Returns the value of a dimension or a shape, depending on the key.\n    \n      Args:\n        key: If `key` is an integer, returns the dimension at that index;\n          otherwise if `key` is a slice, returns a TensorShape whose\n          dimensions are those selected by the slice from `self`.\n    \n      Returns:\n        An integer if `key` is an integer, or a `TensorShape` if `key` is a\n        slice.\n    \n      Raises:\n        ValueError: If `key` is a slice and `self` is completely unknown and\n          the step is set.\n      \"\"\"\n      if self._dims is not None:\n        if isinstance(key, slice):\n          return TensorShape(self._dims[key])\n        else:\n          if self._v2_behavior:\n            return self._dims[key].value\n          else:\n>           return self._dims[key]\nE           IndexError: list index out of range\n\n../../envs/keras_31/lib/python3.7/site-packages/tensorflow/python/framework/tensor_shape.py:788: IndexError",
                "traceback": "keras/backend/tensorflow_backend.py:3947: in ctc_batch_cost\n    sparse_labels = tf.to_int32(ctc_label_dense_to_sparse(y_true, label_length))\nkeras/backend/tensorflow_backend.py:3911: in ctc_label_dense_to_sparse\n    initializer=init, parallel_iterations=1)\n../../envs/keras_31/lib/python3.7/site-packages/tensorflow/python/ops/functional_ops.py:651: in scan\n    n = (tensor_shape.dimension_value(elems_flat[0].shape[0])",
                "test_error_location": "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = TensorShape([]), key = 0\n\n    def __getitem__(self, key):\n      \"\"\"Returns the value of a dimension or a shape, depending on the key.\n    \n      Args:\n        key: If `key` is an integer, returns the dimension at that index;\n          otherwise if `key` is a slice, returns a TensorShape whose\n          dimensions are those selected by the slice from `self`.\n    \n      Returns:\n        An integer if `key` is an integer, or a `TensorShape` if `key` is a\n        slice.\n    \n      Raises:\n        ValueError: If `key` is a slice and `self` is completely unknown and\n          the step is set.\n      \"\"\"\n      if self._dims is not None:\n        if isinstance(key, slice):\n          return TensorShape(self._dims[key])\n        else:\n          if self._v2_behavior:\n            return self._dims[key].value\n          else:\n>           return self._dims[key]\nE           IndexError: list index out of range\n\n../../envs/keras_31/lib/python3.7/site-packages/tensorflow/python/framework/tensor_shape.py:788: IndexError",
                "test_function_decorators": [
                    "pytest.mark.skipif(K.backend() == 'cntk', reason='Not supported.')"
                ]
            }
        ]
    }
}