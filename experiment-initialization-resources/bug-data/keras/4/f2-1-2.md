# Error stack trace

```json
[
    [
        "@pytest.mark.skipif((K.backend() != 'tensorflow'),\n                        reason='Requires TensorFlow backend')\n    def test_tfoptimizer_pass_correct_named_params_to_native_tensorflow_optimizer():\n        from keras import constraints\n        from tensorflow import train\n    \n        class MyTfOptimizer(train.Optimizer):\n            wrapping_optimizer = train.AdamOptimizer()\n    \n            def compute_gradients(self, loss, **kwargs):\n                return super(MyTfOptimizer, self).compute_gradients(loss, **kwargs)\n    \n            def apply_gradients(self, grads_and_vars, **kwargs):\n                return self.wrapping_optimizer.apply_gradients(grads_and_vars,\n                                                               **kwargs)\n        my_tf_optimizer = MyTfOptimizer(use_locking=False, name='MyTfOptimizer')\n        optimizer = optimizers.TFOptimizer(my_tf_optimizer)\n        model = Sequential()\n        model.add(Dense(num_classes, input_shape=(3,),\n                        kernel_constraint=constraints.MaxNorm(1)))\n        model.compile(loss='mean_squared_error', optimizer=optimizer)\n        model.fit(np.random.random((5, 3)), np.random.random((5, num_classes)),\n>                 epochs=1, batch_size=5, verbose=0)\n\ntests/keras/optimizers_test.py:173: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nkeras/engine/training.py:1026: in fit\n    self._make_train_function()\nkeras/engine/training.py:509: in _make_train_function\n    loss=self.total_loss)\nkeras/legacy/interfaces.py:91: in wrapper\n    return func(*args, **kwargs)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <keras.optimizers.TFOptimizer object at 0x7f9b97de0690>\nloss = <tf.Tensor 'loss/mul:0' shape=() dtype=float32>\nparams = [<tf.Variable 'dense_1/kernel:0' shape=(3, 2) dtype=float32_ref>, <tf.Variable 'dense_1/bias:0' shape=(2,) dtype=float32_ref>]\n\n    @interfaces.legacy_get_updates_support\n    def get_updates(self, loss, params):\n>       grads = self.optimizer.compute_gradients(loss, params)",
        "\nkeras/optimizers.py:706: TypeError"
    ]
]
```
