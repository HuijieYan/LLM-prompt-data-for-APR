{
    "1": "Assume that the following list of imports are available in the current environment, so you don't need to import them when generating a fix.\n```python\nfrom . import backend as K\n```\n\n## The source code of the buggy function\n```python\n# The relative path of the buggy file: keras/metrics.py\n\n# this is the buggy function you need to fix\ndef sparse_top_k_categorical_accuracy(y_true, y_pred, k=5):\n    return K.mean(K.in_top_k(y_pred, K.cast(K.max(y_true, axis=-1), 'int32'), k),\n                  axis=-1)\n\n```",
    "2": "",
    "3": "",
    "4": "## A failing test function for the buggy function\n```python\n# The relative path of the failing test file: tests/keras/metrics_test.py\n\n@pytest.mark.skipif((K.backend() == 'cntk'),\n                    reason='CNTK backend does not support top_k yet')\n@pytest.mark.parametrize('y_pred, y_true', [\n    # Test correctness if the shape of y_true is (num_samples, 1)\n    (np.array([[0.3, 0.2, 0.1], [0.1, 0.2, 0.7]]), np.array([[1], [0]])),\n    # Test correctness if the shape of y_true is (num_samples,)\n    (np.array([[0.3, 0.2, 0.1], [0.1, 0.2, 0.7]]), np.array([1, 0])),\n])\ndef test_sparse_top_k_categorical_accuracy(y_pred, y_true):\n    y_pred = K.variable(y_pred)\n    y_true = K.variable(y_true)\n    success_result = K.eval(\n        metrics.sparse_top_k_categorical_accuracy(y_true, y_pred, k=3))\n\n    assert success_result == 1\n    partial_result = K.eval(\n        metrics.sparse_top_k_categorical_accuracy(y_true, y_pred, k=2))\n\n    assert partial_result == 0.5\n    failure_result = K.eval(\n        metrics.sparse_top_k_categorical_accuracy(y_true, y_pred, k=1))\n\n    assert failure_result == 0\n```\n\n\n",
    "5": "### The error message from the failing test\n```text\ngraph = <tensorflow.python.framework.ops.Graph object at 0x7f02cac67850>\nnode_def = name: \"in_top_k/InTopKV2\"\nop: \"InTopKV2\"\nattr {\n  key: \"T\"\n  value {\n    type: DT_INT32\n  }\n}\n\ninputs = [<tf.Tensor 'Variable/read:0' shape=(2, 3) dtype=float32>, <tf.Tensor 'Cast:0' shape=() dtype=int32>, <tf.Tensor 'in_top_k/InTopKV2/k:0' shape=() dtype=int32>]\ncontrol_inputs = []\n\n    def _create_c_op(graph, node_def, inputs, control_inputs):\n      \"\"\"Creates a TF_Operation.\n    \n      Args:\n        graph: a `Graph`.\n        node_def: `node_def_pb2.NodeDef` for the operation to create.\n        inputs: A list of `Tensor`s (corresponding to scalar inputs) and lists of\n          `Tensor`s (corresponding to sequence inputs, e.g. \"int64 * N\",\n          \"list(int64)\"). The length of the list should be equal to the number of\n          inputs specified by this operation's op def.\n        control_inputs: A list of `Operation`s to set as control dependencies.\n    \n      Returns:\n        A wrapped TF_Operation*.\n      \"\"\"\n      # pylint: disable=protected-access\n      op_desc = c_api.TF_NewOperation(graph._c_graph, compat.as_str(node_def.op),\n                                      compat.as_str(node_def.name))\n      if node_def.device:\n        c_api.TF_SetDevice(op_desc, compat.as_str(node_def.device))\n      # Add inputs\n      for op_input in inputs:\n        if isinstance(op_input, (list, tuple)):\n          c_api.TF_AddInputList(op_desc, [t._as_tf_output() for t in op_input])\n        else:\n          c_api.TF_AddInput(op_desc, op_input._as_tf_output())\n    \n      # Add control inputs\n      for control_input in control_inputs:\n        c_api.TF_AddControlInput(op_desc, control_input._c_op)\n      # pylint: enable=protected-access\n    \n      # Add attrs\n      for name, attr_value in node_def.attr.items():\n        serialized = attr_value.SerializeToString()\n        # TODO(skyewm): this creates and deletes a new TF_Status for every attr.\n        # It might be worth creating a convenient way to re-use the same status.\n        c_api.TF_SetAttrValueProto(op_desc, compat.as_str(name), serialized)\n    \n      try:\n>       c_op = c_api.TF_FinishOperation(op_desc)\nE       tensorflow.python.framework.errors_impl.InvalidArgumentError: Shape must be rank 1 but is rank 0 for 'in_top_k/InTopKV2' (op: 'InTopKV2') with input shapes: [2,3], [], [].\n\n../../envs/keras_14/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1607: InvalidArgumentError\n\nDuring handling of the above exception, another exception occurred:\n\ny_pred = <tf.Variable 'Variable:0' shape=(2, 3) dtype=float32_ref>\ny_true = <tf.Variable 'Variable_1:0' shape=(2,) dtype=float32_ref>\n\n    @pytest.mark.skipif((K.backend() == 'cntk'),\n                        reason='CNTK backend does not support top_k yet')\n    @pytest.mark.parametrize('y_pred, y_true', [\n        # Test correctness if the shape of y_true is (num_samples, 1)\n        (np.array([[0.3, 0.2, 0.1], [0.1, 0.2, 0.7]]), np.array([[1], [0]])),\n        # Test correctness if the shape of y_true is (num_samples,)\n        (np.array([[0.3, 0.2, 0.1], [0.1, 0.2, 0.7]]), np.array([1, 0])),\n    ])\n    def test_sparse_top_k_categorical_accuracy(y_pred, y_true):\n        y_pred = K.variable(y_pred)\n        y_true = K.variable(y_true)\n        success_result = K.eval(\n>           metrics.sparse_top_k_categorical_accuracy(y_true, y_pred, k=3))\n\ntests/keras/metrics_test.py:109: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nkeras/metrics.py:48: in sparse_top_k_categorical_accuracy\n    return K.mean(K.in_top_k(y_pred, K.cast(K.max(y_true, axis=-1), 'int32'), k),\nkeras/backend/tensorflow_backend.py:3446: in in_top_k\n    return tf.nn.in_top_k(predictions, targets, k)\n../../envs/keras_14/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_ops.py:4843: in in_top_k\n    return gen_nn_ops.in_top_kv2(predictions, targets, k, name=name)\n../../envs/keras_14/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_nn_ops.py:5042: in in_top_kv2\n    \"InTopKV2\", predictions=predictions, targets=targets, k=k, name=name)\n../../envs/keras_14/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py:794: in _apply_op_helper\n    op_def=op_def)\n../../envs/keras_14/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py:507: in new_func\n    return func(*args, **kwargs)\n../../envs/keras_14/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:3357: in create_op\n    attrs, op_def, compute_device)\n../../envs/keras_14/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:3426: in _create_op_internal\n    op_def=op_def)\n../../envs/keras_14/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1770: in __init__\n    control_input_ops)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ngraph = <tensorflow.python.framework.ops.Graph object at 0x7f02cac67850>\nnode_def = name: \"in_top_k/InTopKV2\"\nop: \"InTopKV2\"\nattr {\n  key: \"T\"\n  value {\n    type: DT_INT32\n  }\n}\n\ninputs = [<tf.Tensor 'Variable/read:0' shape=(2, 3) dtype=float32>, <tf.Tensor 'Cast:0' shape=() dtype=int32>, <tf.Tensor 'in_top_k/InTopKV2/k:0' shape=() dtype=int32>]\ncontrol_inputs = []\n\n    def _create_c_op(graph, node_def, inputs, control_inputs):\n      \"\"\"Creates a TF_Operation.\n    \n      Args:\n        graph: a `Graph`.\n        node_def: `node_def_pb2.NodeDef` for the operation to create.\n        inputs: A list of `Tensor`s (corresponding to scalar inputs) and lists of\n          `Tensor`s (corresponding to sequence inputs, e.g. \"int64 * N\",\n          \"list(int64)\"). The length of the list should be equal to the number of\n          inputs specified by this operation's op def.\n        control_inputs: A list of `Operation`s to set as control dependencies.\n    \n      Returns:\n        A wrapped TF_Operation*.\n      \"\"\"\n      # pylint: disable=protected-access\n      op_desc = c_api.TF_NewOperation(graph._c_graph, compat.as_str(node_def.op),\n                                      compat.as_str(node_def.name))\n      if node_def.device:\n        c_api.TF_SetDevice(op_desc, compat.as_str(node_def.device))\n      # Add inputs\n      for op_input in inputs:\n        if isinstance(op_input, (list, tuple)):\n          c_api.TF_AddInputList(op_desc, [t._as_tf_output() for t in op_input])\n        else:\n          c_api.TF_AddInput(op_desc, op_input._as_tf_output())\n    \n      # Add control inputs\n      for control_input in control_inputs:\n        c_api.TF_AddControlInput(op_desc, control_input._c_op)\n      # pylint: enable=protected-access\n    \n      # Add attrs\n      for name, attr_value in node_def.attr.items():\n        serialized = attr_value.SerializeToString()\n        # TODO(skyewm): this creates and deletes a new TF_Status for every attr.\n        # It might be worth creating a convenient way to re-use the same status.\n        c_api.TF_SetAttrValueProto(op_desc, compat.as_str(name), serialized)\n    \n      try:\n        c_op = c_api.TF_FinishOperation(op_desc)\n      except errors.InvalidArgumentError as e:\n        # Convert to ValueError for backwards compatibility.\n>       raise ValueError(str(e))\nE       ValueError: Shape must be rank 1 but is rank 0 for 'in_top_k/InTopKV2' (op: 'InTopKV2') with input shapes: [2,3], [], [].\n\n../../envs/keras_14/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1610: ValueError\n\n```\n",
    "6": "## Runtime values and types of variables inside the buggy function\nEach case below includes input parameter values and types, and the values and types of relevant variables at the function's return, derived from executing failing tests. If an input parameter is not reflected in the output, it is assumed to remain unchanged. Note that some of these values at the function's return might be incorrect. Analyze these cases to identify why the tests are failing to effectively fix the bug.\n\n### Case 1\n#### Runtime values and types of the input parameters of the buggy function\ny_pred, value: `<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32_ref>`, type: `RefVariable`\n\ny_true, value: `<tf.Variable 'Variable_1:0' shape=(2,) dtype=float32_ref>`, type: `RefVariable`\n\nk, value: `3`, type: `int`\n\n### Case 2\n#### Runtime values and types of the input parameters of the buggy function\ny_pred, value: `<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32_ref>`, type: `RefVariable`\n\ny_true, value: `<tf.Variable 'Variable_1:0' shape=(2,) dtype=float32_ref>`, type: `RefVariable`\n\nk, value: `2`, type: `int`\n\n### Case 3\n#### Runtime values and types of the input parameters of the buggy function\ny_pred, value: `<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32_ref>`, type: `RefVariable`\n\ny_true, value: `<tf.Variable 'Variable_1:0' shape=(2,) dtype=float32_ref>`, type: `RefVariable`\n\nk, value: `1`, type: `int`\n\n",
    "7": "## Expected values and types of variables during the failing test execution\nEach case below includes input parameter values and types, and the expected values and types of relevant variables at the function's return. If an input parameter is not reflected in the output, it is assumed to remain unchanged. A corrected function must satisfy all these cases.\n\n### Expected case 1\n#### The values and types of buggy function's parameters\ny_pred, value: `<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32_ref>`, type: `RefVariable`\n\ny_true, value: `<tf.Variable 'Variable_1:0' shape=(2,) dtype=float32_ref>`, type: `RefVariable`\n\nk, value: `3`, type: `int`\n\n",
    "8": "## A GitHub issue for this bug\n\nThe issue's title:\n```text\nfix sparse categorical acc\n```\n\nThe issue's detailed description:\n```text\nSummary\nsparse categorical acc should have the same result as categorical acc.\nFor example, with 3 classes, given sparse_true_label = [0, 1, 1], it's equivalent in categorical labels is dense_true_label = [[1, 0, 0], [0, 1, 0], [0, 1, 0]]. With the same predictions\n\npred = [[0.7, 0.2, 0.1], \n[0.1, 0.1, 0.8], \n[0.2, 0.6, 0.2]]\nThey should produce the same acc which is [1, 0 ,1]\n\nNot sure why max is used, but it should directly compare with y_true\nAdded unit test to test correctness\nRelated Issues\nPR Overview\n This PR requires new unit tests [y] (make sure tests are included)\n This PR requires to update the documentation [n] (make sure the docs are up-to-date)\n This PR is backwards compatible [y]\n This PR changes the current API [n] (all API changes need to be approved by fchollet)\n```\n\n## A GitHub issue for this bug\n\nThe issue's title:\n```text\nmetrics=['accuracy'] seems to be calculated differently if one uses tf.data inputs instead of numpy arrays for keras model\n```\n\nThe issue's detailed description:\n```text\nPlease go to Stack Overflow for help and support:\n\nhttps://stackoverflow.com/questions/tagged/tensorflow\n\nIf you open a GitHub issue, here is our policy:\n\nIt must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\nThe form below must be filled out.\nIt shouldn't be a TensorBoard issue. Those go here.\nHere's why we have that policy: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\n\nSystem information\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): YES\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\nMobile device:na\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below):1.11.0-dev20180907\nPython version:3.6.3\nBazel version (if compiling from source):na\nGCC/Compiler version (if compiling from source):na\nCUDA/cuDNN version:na\nGPU model and memory:na\nExact command to reproduce:na\nYou can collect some of this information using our environment capture script:\n\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\n\nYou can obtain the TensorFlow version with\n\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\n\nDescribe the problem\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\n\nGiven the same piece of code for loading mnist data and training a keras model in tensorflow, the metric \"accuracy\" given as argument to keras_model.compile(metrics=[...]) generates very different values (order of 0.10 versus order of 0.90) depending on if you use numpy arrays or tf.data datasets as training inputs. Note that the values of the loss in each case are very close. I suspect that \"accuracy\" is being calculated differently depending on the type of input (numpy or tf.data), or that it is being calculated wrong in one of the cases.\nIn particular, as an example, using numpy arrays as input, one can get the pair loss: 0.2086 - acc: 0.9389 in one of the steps, while the same loss in with tf.data gives the pair loss: 0.2086 - acc: 0.1024.\n\nSource code / logs\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\n\nThe code below as it is can be run and training with tf.data datasets will be performed. If you comment the block between #Train with tf.data datasets and ######################## and uncomment the block between #Train with numpy arrays and ########################, training with numpy arrays as inputs will be performed.\n\nimport tensorflow as tf\nimport numpy as np\n\nnp.random.seed(1)\ntf.set_random_seed(1)\nBATCH_SIZE = 32\n\n#Import mnist dataset as numpy arrays\n(x_train, y_train), (_, _) = tf.keras.datasets.mnist.load_data()#Import\nx_train = x_train / 255.0 #normalizing\ny_train = y_train.astype(dtype='float32')\nx_train = x_train.astype(dtype='float32')\n\nx_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1]*x_train.shape[2]))#Reshaping the 2D picture\n\n##############################################################################################\n#THIS BLOCK CREATES A DATASET FROM THE NUMPY ARRAYS. IT WILL BE USED FOR THE CASE OF TF.DATA DATASET INPUTS\ntfdata_dataset_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\ntfdata_dataset_train = tfdata_dataset_train.batch(BATCH_SIZE).repeat()\n##############################################################################################\n\n#Create model\nkeras_model = tf.keras.models.Sequential([\n    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n    tf.keras.layers.Dropout(0.2, seed=1),\n    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n])\n\n#Compile the model\nkeras_model.compile(optimizer=tf.keras.optimizers.Adam(),\n                    loss=tf.keras.losses.sparse_categorical_crossentropy,\n                    metrics=['accuracy'])\n\n#Train with numpy arrays\n#keras_training_history = keras_model.fit(x_train,\n#                y_train,\n#                epochs=1\n#                )\n########################\n\n#Train with tf.data datasets\nkeras_training_history = keras_model.fit(tfdata_dataset_train,\n                epochs=1,\n                steps_per_epoch=60000//BATCH_SIZE\n                )\n########################\n```\n\n## A GitHub issue for this bug\n\nThe issue's title:\n```text\nFix bug in tf.keras.metrics.sparse_categorical_accuracy\n```\n\nThe issue's detailed description:\n```text\nFix #22190\n\nFor the input of tf.keras.metrics.sparse_categorical_accuracy, the shape of y_true can be (num_samples, 1) or (num_samples,), see #22190 for detail. The existing code assume the shape of y_true is (num_samples, 1), always reduce in the last dimension which leads the incorrect output. Actually we should check the shape of y_true and squeeze if applicable.\nMeanwhile, I also fix sparse_top_k_categorical_accuracy which has the same issue.\n```\n\n",
    "9": "Your output should follow these steps:\n1. Analyze the buggy function and its relationship with the test code, corresponding error message, the actual input/output variable information, the expected input/output variable information, the github issue.\n2. Identify a potential error location within the buggy function.\n3. Elucidate the bug's cause using:\n   (a) The buggy function, \n   (b) The failing test, \n   (c) The corresponding error message, \n   (d) The actual input/output variable values, \n   (e) The expected input/output variable values, \n   (f) The GitHub Issue information\n\n4. Suggest approaches for fixing the bug.\n5. Present the corrected code for the buggy function such that it satisfied the following:\n   (a) the program passes the failing test, \n   (b) the function satisfies the expected input/output variable information provided, \n   (c) successfully resolves the issue posted in GitHub\n\n",
    "1.3.3": "Assume that the following list of imports are available in the current environment, so you don't need to import them when generating a fix.\n```python\nfrom . import backend as K\n```\n\n",
    "source_code_body": "# this is the buggy function you need to fix\ndef sparse_top_k_categorical_accuracy(y_true, y_pred, k=5):\n    return K.mean(K.in_top_k(y_pred, K.cast(K.max(y_true, axis=-1), 'int32'), k),\n                  axis=-1)\n\n"
}