{
    "keras:14": {
        "github_issue_title": [
            "fix sparse categorical acc\n",
            "metrics=['accuracy'] seems to be calculated differently if one uses tf.data inputs instead of numpy arrays for keras model\n",
            "Fix bug in tf.keras.metrics.sparse_categorical_accuracy\n"
        ],
        "github_issue_description": [
            "Summary\nsparse categorical acc should have the same result as categorical acc.\nFor example, with 3 classes, given sparse_true_label = [0, 1, 1], it's equivalent in categorical labels is dense_true_label = [[1, 0, 0], [0, 1, 0], [0, 1, 0]]. With the same predictions\n\npred = [[0.7, 0.2, 0.1], \n[0.1, 0.1, 0.8], \n[0.2, 0.6, 0.2]]\nThey should produce the same acc which is [1, 0 ,1]\n\nNot sure why max is used, but it should directly compare with y_true\nAdded unit test to test correctness\nRelated Issues\nPR Overview\n This PR requires new unit tests [y] (make sure tests are included)\n This PR requires to update the documentation [n] (make sure the docs are up-to-date)\n This PR is backwards compatible [y]\n This PR changes the current API [n] (all API changes need to be approved by fchollet)\n",
            "Please go to Stack Overflow for help and support:\n\nhttps://stackoverflow.com/questions/tagged/tensorflow\n\nIf you open a GitHub issue, here is our policy:\n\nIt must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\nThe form below must be filled out.\nIt shouldn't be a TensorBoard issue. Those go here.\nHere's why we have that policy: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\n\nSystem information\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): YES\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\nMobile device:na\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below):1.11.0-dev20180907\nPython version:3.6.3\nBazel version (if compiling from source):na\nGCC/Compiler version (if compiling from source):na\nCUDA/cuDNN version:na\nGPU model and memory:na\nExact command to reproduce:na\nYou can collect some of this information using our environment capture script:\n\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\n\nYou can obtain the TensorFlow version with\n\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\n\nDescribe the problem\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\n\nGiven the same piece of code for loading mnist data and training a keras model in tensorflow, the metric \"accuracy\" given as argument to keras_model.compile(metrics=[...]) generates very different values (order of 0.10 versus order of 0.90) depending on if you use numpy arrays or tf.data datasets as training inputs. Note that the values of the loss in each case are very close. I suspect that \"accuracy\" is being calculated differently depending on the type of input (numpy or tf.data), or that it is being calculated wrong in one of the cases.\nIn particular, as an example, using numpy arrays as input, one can get the pair loss: 0.2086 - acc: 0.9389 in one of the steps, while the same loss in with tf.data gives the pair loss: 0.2086 - acc: 0.1024.\n\nSource code / logs\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\n\nThe code below as it is can be run and training with tf.data datasets will be performed. If you comment the block between #Train with tf.data datasets and ######################## and uncomment the block between #Train with numpy arrays and ########################, training with numpy arrays as inputs will be performed.\n\nimport tensorflow as tf\nimport numpy as np\n\nnp.random.seed(1)\ntf.set_random_seed(1)\nBATCH_SIZE = 32\n\n#Import mnist dataset as numpy arrays\n(x_train, y_train), (_, _) = tf.keras.datasets.mnist.load_data()#Import\nx_train = x_train / 255.0 #normalizing\ny_train = y_train.astype(dtype='float32')\nx_train = x_train.astype(dtype='float32')\n\nx_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1]*x_train.shape[2]))#Reshaping the 2D picture\n\n##############################################################################################\n#THIS BLOCK CREATES A DATASET FROM THE NUMPY ARRAYS. IT WILL BE USED FOR THE CASE OF TF.DATA DATASET INPUTS\ntfdata_dataset_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\ntfdata_dataset_train = tfdata_dataset_train.batch(BATCH_SIZE).repeat()\n##############################################################################################\n\n#Create model\nkeras_model = tf.keras.models.Sequential([\n    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n    tf.keras.layers.Dropout(0.2, seed=1),\n    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n])\n\n#Compile the model\nkeras_model.compile(optimizer=tf.keras.optimizers.Adam(),\n                    loss=tf.keras.losses.sparse_categorical_crossentropy,\n                    metrics=['accuracy'])\n\n#Train with numpy arrays\n#keras_training_history = keras_model.fit(x_train,\n#                y_train,\n#                epochs=1\n#                )\n########################\n\n#Train with tf.data datasets\nkeras_training_history = keras_model.fit(tfdata_dataset_train,\n                epochs=1,\n                steps_per_epoch=60000//BATCH_SIZE\n                )\n########################\n",
            "Fix #22190\n\nFor the input of tf.keras.metrics.sparse_categorical_accuracy, the shape of y_true can be (num_samples, 1) or (num_samples,), see #22190 for detail. The existing code assume the shape of y_true is (num_samples, 1), always reduce in the last dimension which leads the incorrect output. Actually we should check the shape of y_true and squeeze if applicable.\nMeanwhile, I also fix sparse_top_k_categorical_accuracy which has the same issue.\n"
        ]
    }
}