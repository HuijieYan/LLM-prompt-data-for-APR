{
    "1": "    def get_file(fname,\n                 origin,\n                 untar=False,\n                 md5_hash=None,\n                 file_hash=None,\n                 cache_subdir='datasets',\n                 hash_algorithm='auto',\n                 extract=False,\n                 archive_format='auto',\n                 cache_dir=None):\n        \"\"\"Downloads a file from a URL if it not already in the cache.\n    \n        By default the file at the url `origin` is downloaded to the\n        cache_dir `~/.keras`, placed in the cache_subdir `datasets`,\n        and given the filename `fname`. The final location of a file\n        `example.txt` would therefore be `~/.keras/datasets/example.txt`.\n    \n        Files in tar, tar.gz, tar.bz, and zip formats can also be extracted.\n        Passing a hash will verify the file after download. The command line\n        programs `shasum` and `sha256sum` can compute the hash.\n    \n        # Arguments\n            fname: Name of the file. If an absolute path `/path/to/file.txt` is\n                specified the file will be saved at that location.\n            origin: Original URL of the file.\n            untar: Deprecated in favor of 'extract'.\n                boolean, whether the file should be decompressed\n            md5_hash: Deprecated in favor of 'file_hash'.\n                md5 hash of the file for verification\n            file_hash: The expected hash string of the file after download.\n                The sha256 and md5 hash algorithms are both supported.\n            cache_subdir: Subdirectory under the Keras cache dir where the file is\n                saved. If an absolute path `/path/to/folder` is\n                specified the file will be saved at that location.\n            hash_algorithm: Select the hash algorithm to verify the file.\n                options are 'md5', 'sha256', and 'auto'.\n                The default 'auto' detects the hash algorithm in use.\n            extract: True tries extracting the file as an Archive, like tar or zip.\n            archive_format: Archive format to try for extracting the file.\n                Options are 'auto', 'tar', 'zip', and None.\n                'tar' includes tar, tar.gz, and tar.bz files.\n                The default 'auto' is ['tar', 'zip'].\n                None or an empty list will return no matches found.\n            cache_dir: Location to store cached files, when None it\n                defaults to the [Keras Directory](/faq/#where-is-the-keras-configuration-filed-stored).\n    \n        # Returns\n            Path to the downloaded file\n        \"\"\"  # noqa\n        if cache_dir is None:\n            cache_dir = os.path.join(os.path.expanduser('~'), '.keras')\n        if md5_hash is not None and file_hash is None:\n            file_hash = md5_hash\n            hash_algorithm = 'md5'\n        datadir_base = os.path.expanduser(cache_dir)\n        if not os.access(datadir_base, os.W_OK):\n            datadir_base = os.path.join('/tmp', '.keras')\n        datadir = os.path.join(datadir_base, cache_subdir)\n        if not os.path.exists(datadir):\n            os.makedirs(datadir)\n    \n        if untar:\n            untar_fpath = os.path.join(datadir, fname)\n            fpath = untar_fpath + '.tar.gz'\n        else:\n            fpath = os.path.join(datadir, fname)\n    \n        download = False\n        if os.path.exists(fpath):\n            # File found; verify integrity if a hash was provided.\n            if file_hash is not None:\n                if not validate_file(fpath, file_hash, algorithm=hash_algorithm):\n                    print('A local file was found, but it seems to be '\n                          'incomplete or outdated because the ' + hash_algorithm +\n                          ' file hash does not match the original value of ' +\n                          file_hash + ' so we will re-download the data.')\n                    download = True\n        else:\n            download = True\n    \n        if download:\n            print('Downloading data from', origin)\n    \n            class ProgressTracker(object):\n                # Maintain progbar for the lifetime of download.\n                # This design was chosen for Python 2.7 compatibility.\n                progbar = None\n    \n            def dl_progress(count, block_size, total_size):\n                if ProgressTracker.progbar is None:\n                    if total_size == -1:\n                        total_size = None\n                    ProgressTracker.progbar = Progbar(total_size)\n                else:\n                    ProgressTracker.progbar.update(count * block_size)\n    \n            error_msg = 'URL fetch failure on {} : {} -- {}'\n            try:\n                try:\n                    urlretrieve(origin, fpath, dl_progress)\n                except HTTPError as e:\n                    raise Exception(error_msg.format(origin, e.code, e.msg))\n                except URLError as e:\n                    raise Exception(error_msg.format(origin, e.errno, e.reason))\n            except (Exception, KeyboardInterrupt):\n                if os.path.exists(fpath):\n                    os.remove(fpath)\n                raise\n            ProgressTracker.progbar = None\n    \n        if untar:\n            if not os.path.exists(untar_fpath):\n                _extract_archive(fpath, datadir, archive_format='tar')\n            return untar_fpath\n    \n        if extract:\n            _extract_archive(fpath, datadir, archive_format)\n    \n        return fpath\n    \n",
    "2": "",
    "3": "# file name: /Volumes/SSD2T/bgp_envs/repos/keras_5/keras/utils/data_utils.py\n\n# relative function's signature in this file\ndef _extract_archive(file_path, path='.', archive_format='auto'):\n    # ... omitted code ...\n    pass\n\n# relative function's signature in this file\ndef validate_file(fpath, file_hash, algorithm='auto', chunk_size=65535):\n    # ... omitted code ...\n    pass\n\n# relative function's signature in this file\ndef urlretrieve(url, filename, reporthook=None, data=None):\n    # ... omitted code ...\n    pass\n\n# relative function's signature in this file\ndef dl_progress(count, block_size, total_size):\n    # ... omitted code ...\n    pass\n\n",
    "4": "# A test function for the buggy function\n```python\n# file name: /Volumes/SSD2T/bgp_envs/repos/keras_5/tests/keras/utils/data_utils_test.py\n\ndef test_data_utils(in_tmpdir):\n    \"\"\"Tests get_file from a url, plus extraction and validation.\n    \"\"\"\n    dirname = 'data_utils'\n\n    with open('test.txt', 'w') as text_file:\n        text_file.write('Float like a butterfly, sting like a bee.')\n\n    with tarfile.open('test.tar.gz', 'w:gz') as tar_file:\n        tar_file.add('test.txt')\n\n    with zipfile.ZipFile('test.zip', 'w') as zip_file:\n        zip_file.write('test.txt')\n\n    origin = urljoin('file://', pathname2url(os.path.abspath('test.tar.gz')))\n\n    path = get_file(dirname, origin, untar=True)\n    filepath = path + '.tar.gz'\n    data_keras_home = os.path.dirname(os.path.dirname(os.path.abspath(filepath)))\n    assert data_keras_home == os.path.dirname(K._config_path)\n    os.remove(filepath)\n\n    _keras_home = os.path.join(os.path.abspath('.'), '.keras')\n    if not os.path.exists(_keras_home):\n        os.makedirs(_keras_home)\n    os.environ['KERAS_HOME'] = _keras_home\n    reload_module(K)\n    path = get_file(dirname, origin, untar=True)\n    filepath = path + '.tar.gz'\n    data_keras_home = os.path.dirname(os.path.dirname(os.path.abspath(filepath)))\n    assert data_keras_home == os.path.dirname(K._config_path)\n    os.environ.pop('KERAS_HOME')\n    shutil.rmtree(_keras_home)\n    reload_module(K)\n\n    path = get_file(dirname, origin, untar=True)\n    filepath = path + '.tar.gz'\n    hashval_sha256 = _hash_file(filepath)\n    hashval_md5 = _hash_file(filepath, algorithm='md5')\n    path = get_file(dirname, origin, md5_hash=hashval_md5, untar=True)\n    path = get_file(filepath, origin, file_hash=hashval_sha256, extract=True)\n    assert os.path.exists(filepath)\n    assert validate_file(filepath, hashval_sha256)\n    assert validate_file(filepath, hashval_md5)\n    os.remove(filepath)\n    os.remove('test.tar.gz')\n\n    origin = urljoin('file://', pathname2url(os.path.abspath('test.zip')))\n\n    hashval_sha256 = _hash_file('test.zip')\n    hashval_md5 = _hash_file('test.zip', algorithm='md5')\n    path = get_file(dirname, origin, md5_hash=hashval_md5, extract=True)\n    path = get_file(dirname, origin, file_hash=hashval_sha256, extract=True)\n    assert os.path.exists(path)\n    assert validate_file(path, hashval_sha256)\n    assert validate_file(path, hashval_md5)\n\n    os.remove(path)\n    os.remove(os.path.join(os.path.dirname(path), 'test.txt'))\n    os.remove('test.txt')\n    os.remove('test.zip')\n```\n\n## Error message from test function\n```text\nin_tmpdir = None\n\n    def test_data_utils(in_tmpdir):\n        \"\"\"Tests get_file from a url, plus extraction and validation.\n        \"\"\"\n        dirname = 'data_utils'\n    \n        with open('test.txt', 'w') as text_file:\n            text_file.write('Float like a butterfly, sting like a bee.')\n    \n        with tarfile.open('test.tar.gz', 'w:gz') as tar_file:\n            tar_file.add('test.txt')\n    \n        with zipfile.ZipFile('test.zip', 'w') as zip_file:\n            zip_file.write('test.txt')\n    \n        origin = urljoin('file://', pathname2url(os.path.abspath('test.tar.gz')))\n    \n        path = get_file(dirname, origin, untar=True)\n        filepath = path + '.tar.gz'\n        data_keras_home = os.path.dirname(os.path.dirname(os.path.abspath(filepath)))\n        assert data_keras_home == os.path.dirname(K._config_path)\n        os.remove(filepath)\n    \n        _keras_home = os.path.join(os.path.abspath('.'), '.keras')\n        if not os.path.exists(_keras_home):\n            os.makedirs(_keras_home)\n        os.environ['KERAS_HOME'] = _keras_home\n        reload_module(K)\n        path = get_file(dirname, origin, untar=True)\n        filepath = path + '.tar.gz'\n        data_keras_home = os.path.dirname(os.path.dirname(os.path.abspath(filepath)))\n>       assert data_keras_home == os.path.dirname(K._config_path)\nE       AssertionError: assert '/Users/jerry/.keras' == '/private/var/folders/ng/72llsm517x12c2p18htksyjc0000gn/T/pytest-of-jerry/pytest-1422/popen-gw0/test_data_utils0/.keras'\nE         - /private/var/folders/ng/72llsm517x12c2p18htksyjc0000gn/T/pytest-of-jerry/pytest-1422/popen-gw0/test_data_utils0/.keras\nE         + /Users/jerry/.keras\n\n/Volumes/SSD2T/bgp_envs/repos/keras_5/tests/keras/utils/data_utils_test.py:102: AssertionError\n\n```\n",
    "5": "# Variable runtime value and type inside buggy function\n## Buggy case 1\n### input parameter runtime value and type for buggy function\nhash_algorithm, value: `'auto'`, type: `str`\n\ncache_subdir, value: `'datasets'`, type: `str`\n\nuntar, value: `True`, type: `bool`\n\nfname, value: `'data_utils'`, type: `str`\n\norigin, value: `'file:///private/var/folders/ng/72llsm517x12c2p18htksyjc0000gn/T/pytest-of-jerry/pytest-1424/popen-gw0/test_data_utils0/test.tar.gz'`, type: `str`\n\nextract, value: `False`, type: `bool`\n\narchive_format, value: `'auto'`, type: `str`\n\n### variable runtime value and type before buggy function return\ncache_dir, value: `'/Users/jerry/.keras'`, type: `str`\n\ndatadir_base, value: `'/Users/jerry/.keras'`, type: `str`\n\ndatadir, value: `'/Users/jerry/.keras/datasets'`, type: `str`\n\nuntar_fpath, value: `'/Users/jerry/.keras/datasets/data_utils'`, type: `str`\n\nfpath, value: `'/Users/jerry/.keras/datasets/data_utils.tar.gz'`, type: `str`\n\ndownload, value: `False`, type: `bool`\n\n## Buggy case 2\n### input parameter runtime value and type for buggy function\nmd5_hash, value: `'4272ea8e1c38a68b93051b59d92be571'`, type: `str`\n\nhash_algorithm, value: `'auto'`, type: `str`\n\ncache_subdir, value: `'datasets'`, type: `str`\n\nuntar, value: `True`, type: `bool`\n\nfname, value: `'data_utils'`, type: `str`\n\norigin, value: `'file:///private/var/folders/ng/72llsm517x12c2p18htksyjc0000gn/T/pytest-of-jerry/pytest-1424/popen-gw0/test_data_utils0/test.tar.gz'`, type: `str`\n\nextract, value: `False`, type: `bool`\n\narchive_format, value: `'auto'`, type: `str`\n\n### variable runtime value and type before buggy function return\ncache_dir, value: `'/Users/jerry/.keras'`, type: `str`\n\nfile_hash, value: `'4272ea8e1c38a68b93051b59d92be571'`, type: `str`\n\nhash_algorithm, value: `'md5'`, type: `str`\n\ndatadir_base, value: `'/Users/jerry/.keras'`, type: `str`\n\ndatadir, value: `'/Users/jerry/.keras/datasets'`, type: `str`\n\nuntar_fpath, value: `'/Users/jerry/.keras/datasets/data_utils'`, type: `str`\n\nfpath, value: `'/Users/jerry/.keras/datasets/data_utils.tar.gz'`, type: `str`\n\ndownload, value: `False`, type: `bool`\n\n## Buggy case 3\n### input parameter runtime value and type for buggy function\nfile_hash, value: `'471b82c33ef8a11d2ad1d0f3250ccb2112d29a18469d3adef30e244717b69e82'`, type: `str`\n\nhash_algorithm, value: `'auto'`, type: `str`\n\ncache_subdir, value: `'datasets'`, type: `str`\n\nuntar, value: `False`, type: `bool`\n\nfname, value: `'/Users/jerry/.keras/datasets/data_utils.tar.gz'`, type: `str`\n\norigin, value: `'file:///private/var/folders/ng/72llsm517x12c2p18htksyjc0000gn/T/pytest-of-jerry/pytest-1424/popen-gw0/test_data_utils0/test.tar.gz'`, type: `str`\n\nextract, value: `True`, type: `bool`\n\narchive_format, value: `'auto'`, type: `str`\n\n### variable runtime value and type before buggy function return\ncache_dir, value: `'/Users/jerry/.keras'`, type: `str`\n\ndatadir_base, value: `'/Users/jerry/.keras'`, type: `str`\n\ndatadir, value: `'/Users/jerry/.keras/datasets'`, type: `str`\n\nfpath, value: `'/Users/jerry/.keras/datasets/data_utils.tar.gz'`, type: `str`\n\ndownload, value: `False`, type: `bool`\n\n## Buggy case 4\n### input parameter runtime value and type for buggy function\nmd5_hash, value: `'7de27c3002a0645eb2c28f586747807a'`, type: `str`\n\nhash_algorithm, value: `'auto'`, type: `str`\n\ncache_subdir, value: `'datasets'`, type: `str`\n\nuntar, value: `False`, type: `bool`\n\nfname, value: `'data_utils'`, type: `str`\n\norigin, value: `'file:///private/var/folders/ng/72llsm517x12c2p18htksyjc0000gn/T/pytest-of-jerry/pytest-1424/popen-gw0/test_data_utils0/test.zip'`, type: `str`\n\nextract, value: `True`, type: `bool`\n\narchive_format, value: `'auto'`, type: `str`\n\n### variable runtime value and type before buggy function return\ncache_dir, value: `'/Users/jerry/.keras'`, type: `str`\n\nfile_hash, value: `'7de27c3002a0645eb2c28f586747807a'`, type: `str`\n\nhash_algorithm, value: `'md5'`, type: `str`\n\ndatadir_base, value: `'/Users/jerry/.keras'`, type: `str`\n\ndatadir, value: `'/Users/jerry/.keras/datasets'`, type: `str`\n\nfpath, value: `'/Users/jerry/.keras/datasets/data_utils'`, type: `str`\n\ndownload, value: `True`, type: `bool`\n\nProgressTracker, value: `<class 'keras.utils.data_utils.get_file.<locals>.ProgressTracker'>`, type: `type`\n\nerror_msg, value: `'URL fetch failure on {} : {} -- {}'`, type: `str`\n\ndl_progress, value: `<function get_file.<locals>.dl_progress at 0x124f95a70>`, type: `function`\n\n## Buggy case 5\n### input parameter runtime value and type for buggy function\nfile_hash, value: `'c5eecca412bf9f91c74ac68a2187a9b1ce5b4c6a355752857c52afa12c7284e4'`, type: `str`\n\nhash_algorithm, value: `'auto'`, type: `str`\n\ncache_subdir, value: `'datasets'`, type: `str`\n\nuntar, value: `False`, type: `bool`\n\nfname, value: `'data_utils'`, type: `str`\n\norigin, value: `'file:///private/var/folders/ng/72llsm517x12c2p18htksyjc0000gn/T/pytest-of-jerry/pytest-1424/popen-gw0/test_data_utils0/test.zip'`, type: `str`\n\nextract, value: `True`, type: `bool`\n\narchive_format, value: `'auto'`, type: `str`\n\n### variable runtime value and type before buggy function return\ncache_dir, value: `'/Users/jerry/.keras'`, type: `str`\n\ndatadir_base, value: `'/Users/jerry/.keras'`, type: `str`\n\ndatadir, value: `'/Users/jerry/.keras/datasets'`, type: `str`\n\nfpath, value: `'/Users/jerry/.keras/datasets/data_utils'`, type: `str`\n\ndownload, value: `False`, type: `bool`\n\n\n\n# Expected variable value and type in tests\n## Expected case 1\n### Input parameter value and type\nhash_algorithm, value: `'auto'`, type: `str`\n\ncache_subdir, value: `'datasets'`, type: `str`\n\nuntar, value: `True`, type: `bool`\n\nfname, value: `'data_utils'`, type: `str`\n\norigin, value: `'file:///private/var/folders/ng/72llsm517x12c2p18htksyjc0000gn/T/pytest-of-jerry/pytest-1423/popen-gw0/test_data_utils0/test.tar.gz'`, type: `str`\n\nextract, value: `False`, type: `bool`\n\narchive_format, value: `'auto'`, type: `str`\n\n### Expected variable value and type before function return\ncache_dir, expected value: `'/Users/jerry/.keras'`, type: `str`\n\ndatadir_base, expected value: `'/Users/jerry/.keras'`, type: `str`\n\ndatadir, expected value: `'/Users/jerry/.keras/datasets'`, type: `str`\n\nuntar_fpath, expected value: `'/Users/jerry/.keras/datasets/data_utils'`, type: `str`\n\nfpath, expected value: `'/Users/jerry/.keras/datasets/data_utils.tar.gz'`, type: `str`\n\ndownload, expected value: `False`, type: `bool`\n\n\n\n",
    "6": "# A GitHub issue title for this bug\n```text\nFix function 'get_file()' is inconsistent with keras backend when 'KERAS_HOME' is not ~/.keras\n```\n\n## The associated detailed issue description\n```text\nSummary\nthe default value(None) for param cache_dir in function get_file() is inconsistent with keras backend when 'KERAS_HOME' is not ~/.keras.\nwhen we set KERAS_HOME and KERAS_HOME is not ~/.keras, models and datasets will still be in ~/.keras(when the cache_dir is default value) while the config file keras.json in KERAS_HOME.\nThe config file keras.json, models and datasets should be in the same folder by default\n\nbug fix the unit test test_data_utils () in tests/keras/utils/data_utils_test.py where the cache_dir remain extracted-file test.txt(which should be removed at last) when untar is True\n\nRelated Issues\nThis applies the fix in issue #11923\n\nPR Overview\n[n] This PR requires new unit tests [y/n] (make sure tests are included)\n[n] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)\n[y] This PR is backwards compatible [y/n]\n[n] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)\n```\n\n",
    "7": "# Instructions\n\n1. Analyze the test case and its relationship with the error message, if applicable.\n2. Identify the potential error location within the problematic function.\n3. Explain the reasons behind the occurrence of the bug.\n4. Suggest possible approaches for fixing the bug.\n5. Present the corrected code for the problematic function."
}