{
    "1": "Assume that the following list of imports are available in the current environment, so you don't need to import them when generating a fix.\n```python\nimport os\nfrom six.moves.urllib.error import HTTPError\nfrom six.moves.urllib.error import URLError\nfrom ..utils.generic_utils import Progbar\nfrom six.moves.urllib.request import urlretrieve\n```\n\n# The source code of the buggy function\n```python\n# The relative path of the buggy file: keras/utils/data_utils.py\n\n# this is the buggy function you need to fix\ndef get_file(fname,\n             origin,\n             untar=False,\n             md5_hash=None,\n             file_hash=None,\n             cache_subdir='datasets',\n             hash_algorithm='auto',\n             extract=False,\n             archive_format='auto',\n             cache_dir=None):\n    \"\"\"Downloads a file from a URL if it not already in the cache.\n\n    By default the file at the url `origin` is downloaded to the\n    cache_dir `~/.keras`, placed in the cache_subdir `datasets`,\n    and given the filename `fname`. The final location of a file\n    `example.txt` would therefore be `~/.keras/datasets/example.txt`.\n\n    Files in tar, tar.gz, tar.bz, and zip formats can also be extracted.\n    Passing a hash will verify the file after download. The command line\n    programs `shasum` and `sha256sum` can compute the hash.\n\n    # Arguments\n        fname: Name of the file. If an absolute path `/path/to/file.txt` is\n            specified the file will be saved at that location.\n        origin: Original URL of the file.\n        untar: Deprecated in favor of 'extract'.\n            boolean, whether the file should be decompressed\n        md5_hash: Deprecated in favor of 'file_hash'.\n            md5 hash of the file for verification\n        file_hash: The expected hash string of the file after download.\n            The sha256 and md5 hash algorithms are both supported.\n        cache_subdir: Subdirectory under the Keras cache dir where the file is\n            saved. If an absolute path `/path/to/folder` is\n            specified the file will be saved at that location.\n        hash_algorithm: Select the hash algorithm to verify the file.\n            options are 'md5', 'sha256', and 'auto'.\n            The default 'auto' detects the hash algorithm in use.\n        extract: True tries extracting the file as an Archive, like tar or zip.\n        archive_format: Archive format to try for extracting the file.\n            Options are 'auto', 'tar', 'zip', and None.\n            'tar' includes tar, tar.gz, and tar.bz files.\n            The default 'auto' is ['tar', 'zip'].\n            None or an empty list will return no matches found.\n        cache_dir: Location to store cached files, when None it\n            defaults to the [Keras Directory](/faq/#where-is-the-keras-configuration-filed-stored).\n\n    # Returns\n        Path to the downloaded file\n    \"\"\"  # noqa\n    if cache_dir is None:\n        cache_dir = os.path.join(os.path.expanduser('~'), '.keras')\n    if md5_hash is not None and file_hash is None:\n        file_hash = md5_hash\n        hash_algorithm = 'md5'\n    datadir_base = os.path.expanduser(cache_dir)\n    if not os.access(datadir_base, os.W_OK):\n        datadir_base = os.path.join('/tmp', '.keras')\n    datadir = os.path.join(datadir_base, cache_subdir)\n    if not os.path.exists(datadir):\n        os.makedirs(datadir)\n\n    if untar:\n        untar_fpath = os.path.join(datadir, fname)\n        fpath = untar_fpath + '.tar.gz'\n    else:\n        fpath = os.path.join(datadir, fname)\n\n    download = False\n    if os.path.exists(fpath):\n        # File found; verify integrity if a hash was provided.\n        if file_hash is not None:\n            if not validate_file(fpath, file_hash, algorithm=hash_algorithm):\n                print('A local file was found, but it seems to be '\n                      'incomplete or outdated because the ' + hash_algorithm +\n                      ' file hash does not match the original value of ' +\n                      file_hash + ' so we will re-download the data.')\n                download = True\n    else:\n        download = True\n\n    if download:\n        print('Downloading data from', origin)\n\n        class ProgressTracker(object):\n            # Maintain progbar for the lifetime of download.\n            # This design was chosen for Python 2.7 compatibility.\n            progbar = None\n\n        def dl_progress(count, block_size, total_size):\n            if ProgressTracker.progbar is None:\n                if total_size == -1:\n                    total_size = None\n                ProgressTracker.progbar = Progbar(total_size)\n            else:\n                ProgressTracker.progbar.update(count * block_size)\n\n        error_msg = 'URL fetch failure on {} : {} -- {}'\n        try:\n            try:\n                urlretrieve(origin, fpath, dl_progress)\n            except HTTPError as e:\n                raise Exception(error_msg.format(origin, e.code, e.msg))\n            except URLError as e:\n                raise Exception(error_msg.format(origin, e.errno, e.reason))\n        except (Exception, KeyboardInterrupt):\n            if os.path.exists(fpath):\n                os.remove(fpath)\n            raise\n        ProgressTracker.progbar = None\n\n    if untar:\n        if not os.path.exists(untar_fpath):\n            _extract_archive(fpath, datadir, archive_format='tar')\n        return untar_fpath\n\n    if extract:\n        _extract_archive(fpath, datadir, archive_format)\n\n    return fpath\n\n```",
    "2": "",
    "3": "# This function from the same file, but not the same class, is called by the buggy function\ndef _extract_archive(file_path, path='.', archive_format='auto'):\n    # Please ignore the body of this function\n\n# This function from the same file, but not the same class, is called by the buggy function\ndef validate_file(fpath, file_hash, algorithm='auto', chunk_size=65535):\n    # Please ignore the body of this function\n\n# This function from the same file, but not the same class, is called by the buggy function\ndef urlretrieve(url, filename, reporthook=None, data=None):\n    # Please ignore the body of this function\n\n# This function from the same file, but not the same class, is called by the buggy function\ndef dl_progress(count, block_size, total_size):\n    # Please ignore the body of this function\n\n",
    "4": "# A failing test function for the buggy function\n```python\n# The relative path of the failing test file: tests/keras/utils/data_utils_test.py\n\ndef test_data_utils(in_tmpdir):\n    \"\"\"Tests get_file from a url, plus extraction and validation.\n    \"\"\"\n    dirname = 'data_utils'\n\n    with open('test.txt', 'w') as text_file:\n        text_file.write('Float like a butterfly, sting like a bee.')\n\n    with tarfile.open('test.tar.gz', 'w:gz') as tar_file:\n        tar_file.add('test.txt')\n\n    with zipfile.ZipFile('test.zip', 'w') as zip_file:\n        zip_file.write('test.txt')\n\n    origin = urljoin('file://', pathname2url(os.path.abspath('test.tar.gz')))\n\n    path = get_file(dirname, origin, untar=True)\n    filepath = path + '.tar.gz'\n    data_keras_home = os.path.dirname(os.path.dirname(os.path.abspath(filepath)))\n    assert data_keras_home == os.path.dirname(K._config_path)\n    os.remove(filepath)\n\n    _keras_home = os.path.join(os.path.abspath('.'), '.keras')\n    if not os.path.exists(_keras_home):\n        os.makedirs(_keras_home)\n    os.environ['KERAS_HOME'] = _keras_home\n    reload_module(K)\n    path = get_file(dirname, origin, untar=True)\n    filepath = path + '.tar.gz'\n    data_keras_home = os.path.dirname(os.path.dirname(os.path.abspath(filepath)))\n    assert data_keras_home == os.path.dirname(K._config_path)\n    os.environ.pop('KERAS_HOME')\n    shutil.rmtree(_keras_home)\n    reload_module(K)\n\n    path = get_file(dirname, origin, untar=True)\n    filepath = path + '.tar.gz'\n    hashval_sha256 = _hash_file(filepath)\n    hashval_md5 = _hash_file(filepath, algorithm='md5')\n    path = get_file(dirname, origin, md5_hash=hashval_md5, untar=True)\n    path = get_file(filepath, origin, file_hash=hashval_sha256, extract=True)\n    assert os.path.exists(filepath)\n    assert validate_file(filepath, hashval_sha256)\n    assert validate_file(filepath, hashval_md5)\n    os.remove(filepath)\n    os.remove('test.tar.gz')\n\n    origin = urljoin('file://', pathname2url(os.path.abspath('test.zip')))\n\n    hashval_sha256 = _hash_file('test.zip')\n    hashval_md5 = _hash_file('test.zip', algorithm='md5')\n    path = get_file(dirname, origin, md5_hash=hashval_md5, extract=True)\n    path = get_file(dirname, origin, file_hash=hashval_sha256, extract=True)\n    assert os.path.exists(path)\n    assert validate_file(path, hashval_sha256)\n    assert validate_file(path, hashval_md5)\n\n    os.remove(path)\n    os.remove(os.path.join(os.path.dirname(path), 'test.txt'))\n    os.remove('test.txt')\n    os.remove('test.zip')\n```\n\n\n",
    "5": "## The error message from the failing test\n```text\nin_tmpdir = None\n\n    def test_data_utils(in_tmpdir):\n        \"\"\"Tests get_file from a url, plus extraction and validation.\n        \"\"\"\n        dirname = 'data_utils'\n    \n        with open('test.txt', 'w') as text_file:\n            text_file.write('Float like a butterfly, sting like a bee.')\n    \n        with tarfile.open('test.tar.gz', 'w:gz') as tar_file:\n            tar_file.add('test.txt')\n    \n        with zipfile.ZipFile('test.zip', 'w') as zip_file:\n            zip_file.write('test.txt')\n    \n        origin = urljoin('file://', pathname2url(os.path.abspath('test.tar.gz')))\n    \n        path = get_file(dirname, origin, untar=True)\n        filepath = path + '.tar.gz'\n        data_keras_home = os.path.dirname(os.path.dirname(os.path.abspath(filepath)))\n        assert data_keras_home == os.path.dirname(K._config_path)\n        os.remove(filepath)\n    \n        _keras_home = os.path.join(os.path.abspath('.'), '.keras')\n        if not os.path.exists(_keras_home):\n            os.makedirs(_keras_home)\n        os.environ['KERAS_HOME'] = _keras_home\n        reload_module(K)\n        path = get_file(dirname, origin, untar=True)\n        filepath = path + '.tar.gz'\n        data_keras_home = os.path.dirname(os.path.dirname(os.path.abspath(filepath)))\n>       assert data_keras_home == os.path.dirname(K._config_path)\nE       AssertionError: assert '/home/ubuntu/.keras' == '/tmp/pytest-of-ubuntu/pytest-70720/popen-gw0/test_data_utils0/.keras'\nE         - /tmp/pytest-of-ubuntu/pytest-70720/popen-gw0/test_data_utils0/.keras\nE         + /home/ubuntu/.keras\n\n/home/ubuntu/Desktop/bgp_envs_local/repos/keras_5/tests/keras/utils/data_utils_test.py:102: AssertionError\n\n```\n",
    "6": "# Runtime values and types of variables inside the buggy function\nEach case below includes input parameter values and types, and the values and types of relevant variables at the function's return, derived from executing failing tests. If an input parameter is not reflected in the output, it is assumed to remain unchanged. Note that some of these values at the function's return might be incorrect. Analyze these cases to identify why the tests are failing to effectively fix the bug.\n\n## Case 1\n### Runtime values and types of the input parameters of the buggy function\nhash_algorithm, value: `'auto'`, type: `str`\n\ncache_subdir, value: `'datasets'`, type: `str`\n\nuntar, value: `True`, type: `bool`\n\nfname, value: `'data_utils'`, type: `str`\n\norigin, value: `'file:///tmp/pytest-of-ubuntu/pytest-70722/popen-gw0/test_data_utils0/test.tar.gz'`, type: `str`\n\nextract, value: `False`, type: `bool`\n\narchive_format, value: `'auto'`, type: `str`\n\n### Runtime values and types of variables right before the buggy function's return\ncache_dir, value: `'/home/ubuntu/.keras'`, type: `str`\n\ndatadir_base, value: `'/home/ubuntu/.keras'`, type: `str`\n\ndatadir, value: `'/home/ubuntu/.keras/datasets'`, type: `str`\n\nuntar_fpath, value: `'/home/ubuntu/.keras/datasets/data_utils'`, type: `str`\n\nfpath, value: `'/home/ubuntu/.keras/datasets/data_utils.tar.gz'`, type: `str`\n\ndownload, value: `False`, type: `bool`\n\n## Case 2\n### Runtime values and types of the input parameters of the buggy function\nmd5_hash, value: `'69ac4d834c9357bf5f42ef48deacdcdf'`, type: `str`\n\nhash_algorithm, value: `'auto'`, type: `str`\n\ncache_subdir, value: `'datasets'`, type: `str`\n\nuntar, value: `True`, type: `bool`\n\nfname, value: `'data_utils'`, type: `str`\n\norigin, value: `'file:///tmp/pytest-of-ubuntu/pytest-70722/popen-gw0/test_data_utils0/test.tar.gz'`, type: `str`\n\nextract, value: `False`, type: `bool`\n\narchive_format, value: `'auto'`, type: `str`\n\n### Runtime values and types of variables right before the buggy function's return\ncache_dir, value: `'/home/ubuntu/.keras'`, type: `str`\n\nfile_hash, value: `'69ac4d834c9357bf5f42ef48deacdcdf'`, type: `str`\n\nhash_algorithm, value: `'md5'`, type: `str`\n\ndatadir_base, value: `'/home/ubuntu/.keras'`, type: `str`\n\ndatadir, value: `'/home/ubuntu/.keras/datasets'`, type: `str`\n\nuntar_fpath, value: `'/home/ubuntu/.keras/datasets/data_utils'`, type: `str`\n\nfpath, value: `'/home/ubuntu/.keras/datasets/data_utils.tar.gz'`, type: `str`\n\ndownload, value: `False`, type: `bool`\n\n## Case 3\n### Runtime values and types of the input parameters of the buggy function\nfile_hash, value: `'cc17b8a9736d9cc5e0ead7364e60cbbd30dbd0b79d2a175168984a65424c89a2'`, type: `str`\n\nhash_algorithm, value: `'auto'`, type: `str`\n\ncache_subdir, value: `'datasets'`, type: `str`\n\nuntar, value: `False`, type: `bool`\n\nfname, value: `'/home/ubuntu/.keras/datasets/data_utils.tar.gz'`, type: `str`\n\norigin, value: `'file:///tmp/pytest-of-ubuntu/pytest-70722/popen-gw0/test_data_utils0/test.tar.gz'`, type: `str`\n\nextract, value: `True`, type: `bool`\n\narchive_format, value: `'auto'`, type: `str`\n\n### Runtime values and types of variables right before the buggy function's return\ncache_dir, value: `'/home/ubuntu/.keras'`, type: `str`\n\ndatadir_base, value: `'/home/ubuntu/.keras'`, type: `str`\n\ndatadir, value: `'/home/ubuntu/.keras/datasets'`, type: `str`\n\nfpath, value: `'/home/ubuntu/.keras/datasets/data_utils.tar.gz'`, type: `str`\n\ndownload, value: `False`, type: `bool`\n\n## Case 4\n### Runtime values and types of the input parameters of the buggy function\nmd5_hash, value: `'86cad1dbdee229e3adcd30aa3c10c42c'`, type: `str`\n\nhash_algorithm, value: `'auto'`, type: `str`\n\ncache_subdir, value: `'datasets'`, type: `str`\n\nuntar, value: `False`, type: `bool`\n\nfname, value: `'data_utils'`, type: `str`\n\norigin, value: `'file:///tmp/pytest-of-ubuntu/pytest-70722/popen-gw0/test_data_utils0/test.zip'`, type: `str`\n\nextract, value: `True`, type: `bool`\n\narchive_format, value: `'auto'`, type: `str`\n\n### Runtime values and types of variables right before the buggy function's return\ncache_dir, value: `'/home/ubuntu/.keras'`, type: `str`\n\nfile_hash, value: `'86cad1dbdee229e3adcd30aa3c10c42c'`, type: `str`\n\nhash_algorithm, value: `'md5'`, type: `str`\n\ndatadir_base, value: `'/home/ubuntu/.keras'`, type: `str`\n\ndatadir, value: `'/home/ubuntu/.keras/datasets'`, type: `str`\n\nfpath, value: `'/home/ubuntu/.keras/datasets/data_utils'`, type: `str`\n\ndownload, value: `True`, type: `bool`\n\nerror_msg, value: `'URL fetch failure on {} : {} -- {}'`, type: `str`\n\n## Case 5\n### Runtime values and types of the input parameters of the buggy function\nfile_hash, value: `'5f4e590b71cc314c37e63b1b9ccc4f98f3a904df4199f970f2b830ba14ae5916'`, type: `str`\n\nhash_algorithm, value: `'auto'`, type: `str`\n\ncache_subdir, value: `'datasets'`, type: `str`\n\nuntar, value: `False`, type: `bool`\n\nfname, value: `'data_utils'`, type: `str`\n\norigin, value: `'file:///tmp/pytest-of-ubuntu/pytest-70722/popen-gw0/test_data_utils0/test.zip'`, type: `str`\n\nextract, value: `True`, type: `bool`\n\narchive_format, value: `'auto'`, type: `str`\n\n### Runtime values and types of variables right before the buggy function's return\ncache_dir, value: `'/home/ubuntu/.keras'`, type: `str`\n\ndatadir_base, value: `'/home/ubuntu/.keras'`, type: `str`\n\ndatadir, value: `'/home/ubuntu/.keras/datasets'`, type: `str`\n\nfpath, value: `'/home/ubuntu/.keras/datasets/data_utils'`, type: `str`\n\ndownload, value: `False`, type: `bool`\n\n",
    "7": "# Expected values and types of variables during the failing test execution\nEach case below includes input parameter values and types, and the expected values and types of relevant variables at the function's return. If an input parameter is not reflected in the output, it is assumed to remain unchanged. A corrected function must satisfy all these cases.\n\n## Expected case 1\n### Input parameter values and types\n### The values and types of buggy function's parameters\nhash_algorithm, value: `'auto'`, type: `str`\n\ncache_subdir, value: `'datasets'`, type: `str`\n\nuntar, value: `True`, type: `bool`\n\nfname, value: `'data_utils'`, type: `str`\n\norigin, value: `'file:///tmp/pytest-of-ubuntu/pytest-70721/popen-gw0/test_data_utils0/test.tar.gz'`, type: `str`\n\nextract, value: `False`, type: `bool`\n\narchive_format, value: `'auto'`, type: `str`\n\n### Expected values and types of variables right before the buggy function's return\ncache_dir, expected value: `'/home/ubuntu/.keras'`, type: `str`\n\ndatadir_base, expected value: `'/home/ubuntu/.keras'`, type: `str`\n\ndatadir, expected value: `'/home/ubuntu/.keras/datasets'`, type: `str`\n\nuntar_fpath, expected value: `'/home/ubuntu/.keras/datasets/data_utils'`, type: `str`\n\nfpath, expected value: `'/home/ubuntu/.keras/datasets/data_utils.tar.gz'`, type: `str`\n\ndownload, expected value: `False`, type: `bool`\n\n",
    "8": "# A GitHub issue for this bug\n\nThe issue's title:\n```text\nFix function 'get_file()' is inconsistent with keras backend when 'KERAS_HOME' is not ~/.keras\n```\n\nThe issue's detailed description:\n```text\nSummary\nthe default value(None) for param cache_dir in function get_file() is inconsistent with keras backend when 'KERAS_HOME' is not ~/.keras.\nwhen we set KERAS_HOME and KERAS_HOME is not ~/.keras, models and datasets will still be in ~/.keras(when the cache_dir is default value) while the config file keras.json in KERAS_HOME.\nThe config file keras.json, models and datasets should be in the same folder by default\n\nbug fix the unit test test_data_utils () in tests/keras/utils/data_utils_test.py where the cache_dir remain extracted-file test.txt(which should be removed at last) when untar is True\n\nRelated Issues\nThis applies the fix in issue #11923\n\nPR Overview\n[n] This PR requires new unit tests [y/n] (make sure tests are included)\n[n] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)\n[y] This PR is backwards compatible [y/n]\n[n] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)\n```\n\n",
    "9": "1. Analyze the buggy function and its relationship with the related functions, test code, corresponding error message, the actual input/output variable information, the expected input/output variable information, the github issue.\n2. Identify a potential error location within the buggy function.\n3. Elucidate the bug's cause using:\n   (a) The buggy function, \n   (b) The related functions, \n   (c) The failing test, \n   (d) The corresponding error message, \n   (e) The actual input/output variable values, \n   (f) The expected input/output variable values, \n   (g) The GitHub Issue information\n\n4. Suggest approaches for fixing the bug.\n5. Present the corrected code for the buggy function such that it satisfied the following:\n   (a) the program passes the failing test, \n   (b) the function satisfies the expected input/output variable information provided, \n   (c) successfully resolves the issue posted in GitHub\n\n",
    "1.3.3": "Assume that the following list of imports are available in the current environment, so you don't need to import them when generating a fix.\n```python\nimport os\nfrom six.moves.urllib.error import HTTPError\nfrom six.moves.urllib.error import URLError\nfrom ..utils.generic_utils import Progbar\nfrom six.moves.urllib.request import urlretrieve\n```\n\n",
    "source_code_section": "# The source code of the buggy function\n```python\n# The relative path of the buggy file: keras/utils/data_utils.py\n\n# this is the buggy function you need to fix\ndef get_file(fname,\n             origin,\n             untar=False,\n             md5_hash=None,\n             file_hash=None,\n             cache_subdir='datasets',\n             hash_algorithm='auto',\n             extract=False,\n             archive_format='auto',\n             cache_dir=None):\n    \"\"\"Downloads a file from a URL if it not already in the cache.\n\n    By default the file at the url `origin` is downloaded to the\n    cache_dir `~/.keras`, placed in the cache_subdir `datasets`,\n    and given the filename `fname`. The final location of a file\n    `example.txt` would therefore be `~/.keras/datasets/example.txt`.\n\n    Files in tar, tar.gz, tar.bz, and zip formats can also be extracted.\n    Passing a hash will verify the file after download. The command line\n    programs `shasum` and `sha256sum` can compute the hash.\n\n    # Arguments\n        fname: Name of the file. If an absolute path `/path/to/file.txt` is\n            specified the file will be saved at that location.\n        origin: Original URL of the file.\n        untar: Deprecated in favor of 'extract'.\n            boolean, whether the file should be decompressed\n        md5_hash: Deprecated in favor of 'file_hash'.\n            md5 hash of the file for verification\n        file_hash: The expected hash string of the file after download.\n            The sha256 and md5 hash algorithms are both supported.\n        cache_subdir: Subdirectory under the Keras cache dir where the file is\n            saved. If an absolute path `/path/to/folder` is\n            specified the file will be saved at that location.\n        hash_algorithm: Select the hash algorithm to verify the file.\n            options are 'md5', 'sha256', and 'auto'.\n            The default 'auto' detects the hash algorithm in use.\n        extract: True tries extracting the file as an Archive, like tar or zip.\n        archive_format: Archive format to try for extracting the file.\n            Options are 'auto', 'tar', 'zip', and None.\n            'tar' includes tar, tar.gz, and tar.bz files.\n            The default 'auto' is ['tar', 'zip'].\n            None or an empty list will return no matches found.\n        cache_dir: Location to store cached files, when None it\n            defaults to the [Keras Directory](/faq/#where-is-the-keras-configuration-filed-stored).\n\n    # Returns\n        Path to the downloaded file\n    \"\"\"  # noqa\n    if cache_dir is None:\n        cache_dir = os.path.join(os.path.expanduser('~'), '.keras')\n    if md5_hash is not None and file_hash is None:\n        file_hash = md5_hash\n        hash_algorithm = 'md5'\n    datadir_base = os.path.expanduser(cache_dir)\n    if not os.access(datadir_base, os.W_OK):\n        datadir_base = os.path.join('/tmp', '.keras')\n    datadir = os.path.join(datadir_base, cache_subdir)\n    if not os.path.exists(datadir):\n        os.makedirs(datadir)\n\n    if untar:\n        untar_fpath = os.path.join(datadir, fname)\n        fpath = untar_fpath + '.tar.gz'\n    else:\n        fpath = os.path.join(datadir, fname)\n\n    download = False\n    if os.path.exists(fpath):\n        # File found; verify integrity if a hash was provided.\n        if file_hash is not None:\n            if not validate_file(fpath, file_hash, algorithm=hash_algorithm):\n                print('A local file was found, but it seems to be '\n                      'incomplete or outdated because the ' + hash_algorithm +\n                      ' file hash does not match the original value of ' +\n                      file_hash + ' so we will re-download the data.')\n                download = True\n    else:\n        download = True\n\n    if download:\n        print('Downloading data from', origin)\n\n        class ProgressTracker(object):\n            # Maintain progbar for the lifetime of download.\n            # This design was chosen for Python 2.7 compatibility.\n            progbar = None\n\n        def dl_progress(count, block_size, total_size):\n            if ProgressTracker.progbar is None:\n                if total_size == -1:\n                    total_size = None\n                ProgressTracker.progbar = Progbar(total_size)\n            else:\n                ProgressTracker.progbar.update(count * block_size)\n\n        error_msg = 'URL fetch failure on {} : {} -- {}'\n        try:\n            try:\n                urlretrieve(origin, fpath, dl_progress)\n            except HTTPError as e:\n                raise Exception(error_msg.format(origin, e.code, e.msg))\n            except URLError as e:\n                raise Exception(error_msg.format(origin, e.errno, e.reason))\n        except (Exception, KeyboardInterrupt):\n            if os.path.exists(fpath):\n                os.remove(fpath)\n            raise\n        ProgressTracker.progbar = None\n\n    if untar:\n        if not os.path.exists(untar_fpath):\n            _extract_archive(fpath, datadir, archive_format='tar')\n        return untar_fpath\n\n    if extract:\n        _extract_archive(fpath, datadir, archive_format)\n\n    return fpath\n\n```"
}