{
    "1": "Assume that the following list of imports are available in the current environment, so you don't need to import them when generating a fix.\n```python\nfrom . import backend as K\nfrom .utils.generic_utils import has_arg\nfrom .utils.generic_utils import to_list\nfrom .engine.input_layer import Input\nfrom .engine.input_layer import InputLayer\nfrom .engine.training import Model\nfrom .engine.sequential import Sequential\n```\n\n# The source code of the buggy function\n```python\n# The relative path of the buggy file: keras/models.py\n\n# this is the buggy function you need to fix\ndef _clone_functional_model(model, input_tensors=None):\n    \"\"\"Clone a functional `Model` instance.\n\n    Model cloning is similar to calling a model on new inputs,\n    except that it creates new layers (and thus new weights) instead\n    of sharing the weights of the existing layers.\n\n    # Arguments\n        model: Instance of `Model`.\n        input_tensors: optional list of input tensors\n            to build the model upon. If not provided,\n            placeholders will be created.\n\n    # Returns\n        An instance of `Model` reproducing the behavior\n        of the original model, on top of new inputs tensors,\n        using newly instantiated weights.\n\n    # Raises\n        ValueError: in case of invalid `model` argument value.\n    \"\"\"\n    if not isinstance(model, Model):\n        raise ValueError('Expected `model` argument '\n                         'to be a `Model` instance, got ', model)\n    if isinstance(model, Sequential):\n        raise ValueError('Expected `model` argument '\n                         'to be a functional `Model` instance, '\n                         'got a `Sequential` instance instead:', model)\n\n    layer_map = {}  # Cache for created layers.\n    tensor_map = {}  # Map {reference_tensor: (corresponding_tensor, mask)}\n    if input_tensors is None:\n        # Create placeholders to build the model on top of.\n        input_layers = []\n        input_tensors = []\n        for layer in model._input_layers:\n            input_tensor = Input(batch_shape=layer.batch_input_shape,\n                                 dtype=layer.dtype,\n                                 sparse=layer.sparse,\n                                 name=layer.name)\n            input_tensors.append(input_tensor)\n            # Cache newly created input layer.\n            newly_created_input_layer = input_tensor._keras_history[0]\n            layer_map[layer] = newly_created_input_layer\n        for _original, _cloned in zip(model._input_layers, input_layers):\n            layer_map[_original] = _cloned\n    else:\n        # Make sure that all input tensors come from a Keras layer.\n        # If tensor comes from an input layer: cache the input layer.\n        input_tensors = to_list(input_tensors)\n        _input_tensors = []\n        for i, x in enumerate(input_tensors):\n            if not K.is_keras_tensor(x):\n                name = model._input_layers[i].name\n                input_tensor = Input(tensor=x,\n                                     name='input_wrapper_for_' + name)\n                _input_tensors.append(input_tensor)\n                # Cache newly created input layer.\n                original_input_layer = x._keras_history[0]\n                newly_created_input_layer = input_tensor._keras_history[0]\n                layer_map[original_input_layer] = newly_created_input_layer\n            else:\n                _input_tensors.append(x)\n        input_tensors = _input_tensors\n\n    for x, y in zip(model.inputs, input_tensors):\n        tensor_map[x] = (y, None)  # tensor, mask\n\n    # Iterated over every node in the reference model, in depth order.\n    depth_keys = list(model._nodes_by_depth.keys())\n    depth_keys.sort(reverse=True)\n    for depth in depth_keys:\n        nodes = model._nodes_by_depth[depth]\n        for node in nodes:\n            # Recover the corresponding layer.\n            layer = node.outbound_layer\n\n            # Get or create layer.\n            if layer not in layer_map:\n                # Clone layer.\n                new_layer = layer.__class__.from_config(layer.get_config())\n                layer_map[layer] = new_layer\n                layer = new_layer\n            else:\n                # Reuse previously cloned layer.\n                layer = layer_map[layer]\n                # Don't call InputLayer multiple times.\n                if isinstance(layer, InputLayer):\n                    continue\n\n            # Gather inputs to call the new layer.\n            reference_input_tensors = node.input_tensors\n            reference_output_tensors = node.output_tensors\n\n            # If all previous input tensors are available in tensor_map,\n            # then call node.inbound_layer on them.\n            computed_data = []  # List of tuples (input, mask).\n            for x in reference_input_tensors:\n                if x in tensor_map:\n                    computed_data.append(tensor_map[x])\n\n            if len(computed_data) == len(reference_input_tensors):\n                # Call layer.\n                if node.arguments:\n                    kwargs = node.arguments\n                else:\n                    kwargs = {}\n                if len(computed_data) == 1:\n                    computed_tensor, computed_mask = computed_data[0]\n                    if has_arg(layer.call, 'mask'):\n                        if 'mask' not in kwargs:\n                            kwargs['mask'] = computed_mask\n                    output_tensors = to_list(\n                        layer(computed_tensor, **kwargs))\n                    output_masks = to_list(\n                        layer.compute_mask(computed_tensor,\n                                           computed_mask))\n                    computed_tensors = [computed_tensor]\n                    computed_masks = [computed_mask]\n                else:\n                    computed_tensors = [x[0] for x in computed_data]\n                    computed_masks = [x[1] for x in computed_data]\n                    if has_arg(layer.call, 'mask'):\n                        if 'mask' not in kwargs:\n                            kwargs['mask'] = computed_masks\n                    output_tensors = to_list(\n                        layer(computed_tensors, **kwargs))\n                    output_masks = to_list(\n                        layer.compute_mask(computed_tensors,\n                                           computed_masks))\n                # Update tensor_map.\n                for x, y, mask in zip(reference_output_tensors,\n                                      output_tensors,\n                                      output_masks):\n                    tensor_map[x] = (y, mask)\n\n    # Check that we did compute the model outputs,\n    # then instantiate a new model from inputs and outputs.\n    output_tensors = []\n    for x in model.outputs:\n        assert x in tensor_map, 'Could not compute output ' + str(x)\n        tensor, _ = tensor_map[x]\n        output_tensors.append(tensor)\n    return Model(input_tensors, output_tensors, name=model.name)\n\n```",
    "2": "",
    "3": "",
    "4": "# A failing test function for the buggy function\n```python\n# The relative path of the failing test file: tests/keras/test_sequential_model.py\n\ndef test_clone_functional_model_with_multi_outputs():\n    input_layer = keras.Input(shape=(4,))\n\n    # Layer with single input and multiple outputs\n    layer1 = keras.layers.Lambda(lambda x: [x + 1, x],\n                                 lambda shapes: [shapes, shapes])\n    x_a, x_b = layer1(input_layer)\n\n    class SwapLayer(keras.layers.Layer):\n        def call(self, inputs, **kwargs):\n            return [inputs[1], inputs[0]]\n\n        def compute_output_shape(self, input_shape):\n            return [input_shape[1], input_shape[0]]\n\n    # Layer with multiple inputs and outputs\n    x_a, x_b = SwapLayer()([x_a, x_b])\n    model = keras.Model(inputs=[input_layer], outputs=[x_a, x_b])\n    new_model = keras.models.clone_model(model)\n\n    x_test = np.random.random((10, 4))\n    pred_a, pred_b = model.predict(x_test)\n    pred_new_a, pred_new_b = new_model.predict(x_test)\n    assert(pred_a.all() == pred_new_a.all())\n    assert(pred_b.all() == pred_new_b.all())\n```\n\n\n",
    "5": "## The error message from the failing test\n```text\ndef test_clone_functional_model_with_multi_outputs():\n        input_layer = keras.Input(shape=(4,))\n    \n        # Layer with single input and multiple outputs\n        layer1 = keras.layers.Lambda(lambda x: [x + 1, x],\n                                     lambda shapes: [shapes, shapes])\n        x_a, x_b = layer1(input_layer)\n    \n        class SwapLayer(keras.layers.Layer):\n            def call(self, inputs, **kwargs):\n                return [inputs[1], inputs[0]]\n    \n            def compute_output_shape(self, input_shape):\n                return [input_shape[1], input_shape[0]]\n    \n        # Layer with multiple inputs and outputs\n        x_a, x_b = SwapLayer()([x_a, x_b])\n        model = keras.Model(inputs=[input_layer], outputs=[x_a, x_b])\n>       new_model = keras.models.clone_model(model)\n\ntests/keras/test_sequential_model.py:360: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nkeras/models.py:251: in clone_model\n    return _clone_functional_model(model, input_tensors=input_tensors)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nmodel = <keras.engine.training.Model object at 0x7f1e4ca7bd90>\ninput_tensors = [<tf.Tensor 'input_1_1:0' shape=(?, 4) dtype=float32>]\n\n    def _clone_functional_model(model, input_tensors=None):\n        \"\"\"Clone a functional `Model` instance.\n    \n        Model cloning is similar to calling a model on new inputs,\n        except that it creates new layers (and thus new weights) instead\n        of sharing the weights of the existing layers.\n    \n        # Arguments\n            model: Instance of `Model`.\n            input_tensors: optional list of input tensors\n                to build the model upon. If not provided,\n                placeholders will be created.\n    \n        # Returns\n            An instance of `Model` reproducing the behavior\n            of the original model, on top of new inputs tensors,\n            using newly instantiated weights.\n    \n        # Raises\n            ValueError: in case of invalid `model` argument value.\n        \"\"\"\n        if not isinstance(model, Model):\n            raise ValueError('Expected `model` argument '\n                             'to be a `Model` instance, got ', model)\n        if isinstance(model, Sequential):\n            raise ValueError('Expected `model` argument '\n                             'to be a functional `Model` instance, '\n                             'got a `Sequential` instance instead:', model)\n    \n        layer_map = {}  # Cache for created layers.\n        tensor_map = {}  # Map {reference_tensor: (corresponding_tensor, mask)}\n        if input_tensors is None:\n            # Create placeholders to build the model on top of.\n            input_layers = []\n            input_tensors = []\n            for layer in model._input_layers:\n                input_tensor = Input(batch_shape=layer.batch_input_shape,\n                                     dtype=layer.dtype,\n                                     sparse=layer.sparse,\n                                     name=layer.name)\n                input_tensors.append(input_tensor)\n                # Cache newly created input layer.\n                newly_created_input_layer = input_tensor._keras_history[0]\n                layer_map[layer] = newly_created_input_layer\n            for _original, _cloned in zip(model._input_layers, input_layers):\n                layer_map[_original] = _cloned\n        else:\n            # Make sure that all input tensors come from a Keras layer.\n            # If tensor comes from an input layer: cache the input layer.\n            input_tensors = to_list(input_tensors)\n            _input_tensors = []\n            for i, x in enumerate(input_tensors):\n                if not K.is_keras_tensor(x):\n                    name = model._input_layers[i].name\n                    input_tensor = Input(tensor=x,\n                                         name='input_wrapper_for_' + name)\n                    _input_tensors.append(input_tensor)\n                    # Cache newly created input layer.\n                    original_input_layer = x._keras_history[0]\n                    newly_created_input_layer = input_tensor._keras_history[0]\n                    layer_map[original_input_layer] = newly_created_input_layer\n                else:\n                    _input_tensors.append(x)\n            input_tensors = _input_tensors\n    \n        for x, y in zip(model.inputs, input_tensors):\n            tensor_map[x] = (y, None)  # tensor, mask\n    \n        # Iterated over every node in the reference model, in depth order.\n        depth_keys = list(model._nodes_by_depth.keys())\n        depth_keys.sort(reverse=True)\n        for depth in depth_keys:\n            nodes = model._nodes_by_depth[depth]\n            for node in nodes:\n                # Recover the corresponding layer.\n                layer = node.outbound_layer\n    \n                # Get or create layer.\n                if layer not in layer_map:\n                    # Clone layer.\n                    new_layer = layer.__class__.from_config(layer.get_config())\n                    layer_map[layer] = new_layer\n                    layer = new_layer\n                else:\n                    # Reuse previously cloned layer.\n                    layer = layer_map[layer]\n                    # Don't call InputLayer multiple times.\n                    if isinstance(layer, InputLayer):\n                        continue\n    \n                # Gather inputs to call the new layer.\n                reference_input_tensors = node.input_tensors\n                reference_output_tensors = node.output_tensors\n    \n                # If all previous input tensors are available in tensor_map,\n                # then call node.inbound_layer on them.\n                computed_data = []  # List of tuples (input, mask).\n                for x in reference_input_tensors:\n                    if x in tensor_map:\n                        computed_data.append(tensor_map[x])\n    \n                if len(computed_data) == len(reference_input_tensors):\n                    # Call layer.\n                    if node.arguments:\n                        kwargs = node.arguments\n                    else:\n                        kwargs = {}\n                    if len(computed_data) == 1:\n                        computed_tensor, computed_mask = computed_data[0]\n                        if has_arg(layer.call, 'mask'):\n                            if 'mask' not in kwargs:\n                                kwargs['mask'] = computed_mask\n                        output_tensors = to_list(\n                            layer(computed_tensor, **kwargs))\n                        output_masks = to_list(\n                            layer.compute_mask(computed_tensor,\n                                               computed_mask))\n                        computed_tensors = [computed_tensor]\n                        computed_masks = [computed_mask]\n                    else:\n                        computed_tensors = [x[0] for x in computed_data]\n                        computed_masks = [x[1] for x in computed_data]\n                        if has_arg(layer.call, 'mask'):\n                            if 'mask' not in kwargs:\n                                kwargs['mask'] = computed_masks\n                        output_tensors = to_list(\n                            layer(computed_tensors, **kwargs))\n                        output_masks = to_list(\n                            layer.compute_mask(computed_tensors,\n                                               computed_masks))\n                    # Update tensor_map.\n                    for x, y, mask in zip(reference_output_tensors,\n                                          output_tensors,\n                                          output_masks):\n                        tensor_map[x] = (y, mask)\n    \n        # Check that we did compute the model outputs,\n        # then instantiate a new model from inputs and outputs.\n        output_tensors = []\n        for x in model.outputs:\n>           assert x in tensor_map, 'Could not compute output ' + str(x)\nE           AssertionError: Could not compute output Tensor(\"swap_layer_1/Identity:0\", shape=(?, 4), dtype=float32)\n\nkeras/models.py:166: AssertionError\n\n```\n",
    "6": "# Runtime value and type of variables inside the buggy function\nEach case below includes input parameter value and type, and the value and type of relevant variables at the function's return, derived from executing failing tests. If an input parameter is not reflected in the output, it is assumed to remain unchanged. Note that some of these values at the function's return might be incorrect. Analyze these cases to identify why the tests are failing to effectively fix the bug.\n\n## Case 1\n### Runtime value and type of the input parameters of the buggy function\nmodel._input_layers, value: `[<keras.engine.input_layer.InputLayer object at 0x7f21169baa10>]`, type: `list`\n\nmodel.inputs, value: `[<tf.Tensor 'input_1:0' shape=(?, 4) dtype=float32>]`, type: `list`\n\nmodel._nodes_by_depth, value: `{0: [<keras.engine.base_layer.Node object at 0x7f211717eed0>], 1: [<keras.engine.base_layer.Node object at 0x7f211717ead0>], 2: [<keras.engine.base_layer.Node object at 0x7f211717e910>]}`, type: `dict`\n\nmodel.outputs, value: `[<tf.Tensor 'swap_layer_1/Identity:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'swap_layer_1/Identity_1:0' shape=(?, 4) dtype=float32>]`, type: `list`\n\nmodel.name, value: `'model_1'`, type: `str`\n\n### Runtime value and type of variables right before the buggy function's return\nlayer_map, value: `{<keras.engine.input_layer.InputLayer object at 0x7f21169baa10>: <keras.engine.input_layer.InputLayer object at 0x7f21169bf0d0>, <keras.layers.core.Lambda object at 0x7f211717ef10>: <keras.layers.core.Lambda object at 0x7f21169bf310>, <test_sequential_model.test_clone_functional_model_with_multi_outputs.<locals>.SwapLayer object at 0x7f211717ea90>: <test_sequential_model.test_clone_functional_model_with_multi_outputs.<locals>.SwapLayer object at 0x7f21169bac90>}`, type: `dict`\n\ntensor_map, value: `{<tf.Tensor 'input_1:0' shape=(?, 4) ... (<tf.Tensor 'swap_layer_1_1/Identity_1:0' shape=(?, 4) dtype=float32>, None)}`, shape: `5`, type: `dict`\n\ninput_tensors, value: `[<tf.Tensor 'input_1_1:0' shape=(?, 4) dtype=float32>]`, type: `list`\n\ninput_layers, value: `[]`, type: `list`\n\ninput_tensor, value: `<tf.Tensor 'input_1_1:0' shape=(?, 4) dtype=float32>`, type: `Tensor`\n\nlayer.name, value: `'swap_layer_1'`, type: `str`\n\ninput_tensor._keras_history, value: `(<keras.engine.input_layer.InputLayer object at 0x7f21169bf0d0>, 0, 0)`, type: `tuple`\n\nx, value: `<tf.Tensor 'swap_layer_1/Identity_1:0' shape=(?, 4) dtype=float32>`, type: `Tensor`\n\nx._keras_history, value: `(<test_sequential_model.test_clone_functional_model_with_multi_outputs.<locals>.SwapLayer object at 0x7f211717ea90>, 0, 1)`, type: `tuple`\n\ny, value: `<tf.Tensor 'swap_layer_1_1/Identity_1:0' shape=(?, 4) dtype=float32>`, type: `Tensor`\n\ndepth_keys, value: `[2, 1, 0]`, type: `list`\n\ndepth, value: `0`, type: `int`\n\nnodes, value: `[<keras.engine.base_layer.Node object at 0x7f211717eed0>]`, type: `list`\n\nreference_input_tensors, value: `[<tf.Tensor 'lambda_1/add:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'lambda_1/Identity:0' shape=(?, 4) dtype=float32>]`, type: `list`\n\nnode.input_tensors, value: `[<tf.Tensor 'lambda_1/add:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'lambda_1/Identity:0' shape=(?, 4) dtype=float32>]`, type: `list`\n\nreference_output_tensors, value: `[<tf.Tensor 'swap_layer_1/Identity:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'swap_layer_1/Identity_1:0' shape=(?, 4) dtype=float32>]`, type: `list`\n\nnode.output_tensors, value: `[<tf.Tensor 'swap_layer_1/Identity:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'swap_layer_1/Identity_1:0' shape=(?, 4) dtype=float32>]`, type: `list`\n\ncomputed_data, value: `[(<tf.Tensor 'lambda_1_1/add:0' shape=(?, 4) dtype=float32>, None), (<tf.Tensor 'lambda_1_1/Identity:0' shape=(?, 4) dtype=float32>, None)]`, type: `list`\n\nnode.arguments, value: `{}`, type: `dict`\n\nkwargs, value: `{}`, type: `dict`\n\ncomputed_tensor, value: `<tf.Tensor 'input_1_1:0' shape=(?, 4) dtype=float32>`, type: `Tensor`\n\noutput_tensors, value: `[<tf.Tensor 'swap_layer_1_1/Identity:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'swap_layer_1_1/Identity_1:0' shape=(?, 4) dtype=float32>]`, type: `list`\n\nlayer.supports_masking, value: `False`, type: `bool`\n\noutput_masks, value: `[None, None]`, type: `list`\n\ncomputed_tensors, value: `[<tf.Tensor 'lambda_1_1/add:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'lambda_1_1/Identity:0' shape=(?, 4) dtype=float32>]`, type: `list`\n\ncomputed_masks, value: `[None, None]`, type: `list`\n\ntensor, value: `<tf.Tensor 'swap_layer_1_1/Identity_1:0' shape=(?, 4) dtype=float32>`, type: `Tensor`\n\n",
    "7": "",
    "8": "# A GitHub issue title for this bug\n```text\n'Could not compute output Tensor' error when I\u2018m using clone_model()\n```\n\n## The GitHub issue's detailed description\n```text\nHi guys, I think I just met a bug.\nThere was something wrong when I was using multi_gpu_model with cpu_relocation=True. After analyzing the traceback I think it is a bug inside keras.models.clone_model\nThe script below can reproduce it\n\nfrom keras.models import Model, clone_model\nfrom keras.layers import Input, Add, Lambda\nfrom keras.utils import multi_gpu_model\n\n\ndef build_model():\n    input_layer = Input(shape=(1,))\n    test1, test2 = Lambda(lambda x: [x, x])(input_layer)\n    add = Add()([test1, test2])\n    model = Model(inputs=[input_layer], outputs=[add])\n    return model\n\n\nif __name__ == '__main__':\n    model = build_model()\n    model = clone_model(model)\n    # model = multi_gpu_model(model, cpu_relocation=True)  # it uses clone_model when set cpu_relocation=True\nIf I didn't make any mistake, the script will raise AssertionError: Could not compute output Tensor(\"add_1/add:0\", shape=(?, 1), dtype=float32)\n\nMy environment:\n\nKeras 2.2.4\ntensorflow 1.12.0\nI met the error on both 4 GTX1080tis and my own laptop with a GTX1060MQ\n\nI noticed that output_masks here will always be [None](but [None, None] is expected)\nkeras/keras/models.py\n\nLine 157 in a139716\n\n for x, y, mask in zip(reference_output_tensors, \nand that's because layer.compute_mask(...) will always return None since Lambda doesn't support using masks\nkeras/keras/models.py\n\nLine 153 in a139716\n\n output_masks = to_list( \nSo if I'm using a functional model with a layer which has more outputs without a mask support, I think the error can appear.\n\nP.S. thanks a lot for your brilliant works :)\nFrom my perspective, Keras is an amazing gift to everyone. Thank you all!\n```\n\n",
    "9": "1. Analyze the buggy function and it's relationship with the test code, corresponding error message, the actual input/output variable information, the github issue.\n2. Identify the potential error location within the problematic function.\n3. Elucidate the bug's cause using:\n   (a). The buggy function\n   (b). The failing test\n   (c). The corresponding error message\n   (d). Discrepancies between actual input/output variable value\n   (e). The GitHub Issue information\n\n4. Suggest possible approaches for fixing the bug.\n5. Present the corrected code for the problematic function such that it satisfied the following:\n   (a). Passes the failing test\n   (b). Successfully resolves the issue posted in GitHub\n\n",
    "1.3.3": "Assume that the following list of imports are available in the current environment, so you don't need to import them when generating a fix.\n```python\nfrom . import backend as K\nfrom .utils.generic_utils import has_arg\nfrom .utils.generic_utils import to_list\nfrom .engine.input_layer import Input\nfrom .engine.input_layer import InputLayer\nfrom .engine.training import Model\nfrom .engine.sequential import Sequential\n```\n\n",
    "source_code_section": "# The source code of the buggy function\n```python\n# The relative path of the buggy file: keras/models.py\n\n# this is the buggy function you need to fix\ndef _clone_functional_model(model, input_tensors=None):\n    \"\"\"Clone a functional `Model` instance.\n\n    Model cloning is similar to calling a model on new inputs,\n    except that it creates new layers (and thus new weights) instead\n    of sharing the weights of the existing layers.\n\n    # Arguments\n        model: Instance of `Model`.\n        input_tensors: optional list of input tensors\n            to build the model upon. If not provided,\n            placeholders will be created.\n\n    # Returns\n        An instance of `Model` reproducing the behavior\n        of the original model, on top of new inputs tensors,\n        using newly instantiated weights.\n\n    # Raises\n        ValueError: in case of invalid `model` argument value.\n    \"\"\"\n    if not isinstance(model, Model):\n        raise ValueError('Expected `model` argument '\n                         'to be a `Model` instance, got ', model)\n    if isinstance(model, Sequential):\n        raise ValueError('Expected `model` argument '\n                         'to be a functional `Model` instance, '\n                         'got a `Sequential` instance instead:', model)\n\n    layer_map = {}  # Cache for created layers.\n    tensor_map = {}  # Map {reference_tensor: (corresponding_tensor, mask)}\n    if input_tensors is None:\n        # Create placeholders to build the model on top of.\n        input_layers = []\n        input_tensors = []\n        for layer in model._input_layers:\n            input_tensor = Input(batch_shape=layer.batch_input_shape,\n                                 dtype=layer.dtype,\n                                 sparse=layer.sparse,\n                                 name=layer.name)\n            input_tensors.append(input_tensor)\n            # Cache newly created input layer.\n            newly_created_input_layer = input_tensor._keras_history[0]\n            layer_map[layer] = newly_created_input_layer\n        for _original, _cloned in zip(model._input_layers, input_layers):\n            layer_map[_original] = _cloned\n    else:\n        # Make sure that all input tensors come from a Keras layer.\n        # If tensor comes from an input layer: cache the input layer.\n        input_tensors = to_list(input_tensors)\n        _input_tensors = []\n        for i, x in enumerate(input_tensors):\n            if not K.is_keras_tensor(x):\n                name = model._input_layers[i].name\n                input_tensor = Input(tensor=x,\n                                     name='input_wrapper_for_' + name)\n                _input_tensors.append(input_tensor)\n                # Cache newly created input layer.\n                original_input_layer = x._keras_history[0]\n                newly_created_input_layer = input_tensor._keras_history[0]\n                layer_map[original_input_layer] = newly_created_input_layer\n            else:\n                _input_tensors.append(x)\n        input_tensors = _input_tensors\n\n    for x, y in zip(model.inputs, input_tensors):\n        tensor_map[x] = (y, None)  # tensor, mask\n\n    # Iterated over every node in the reference model, in depth order.\n    depth_keys = list(model._nodes_by_depth.keys())\n    depth_keys.sort(reverse=True)\n    for depth in depth_keys:\n        nodes = model._nodes_by_depth[depth]\n        for node in nodes:\n            # Recover the corresponding layer.\n            layer = node.outbound_layer\n\n            # Get or create layer.\n            if layer not in layer_map:\n                # Clone layer.\n                new_layer = layer.__class__.from_config(layer.get_config())\n                layer_map[layer] = new_layer\n                layer = new_layer\n            else:\n                # Reuse previously cloned layer.\n                layer = layer_map[layer]\n                # Don't call InputLayer multiple times.\n                if isinstance(layer, InputLayer):\n                    continue\n\n            # Gather inputs to call the new layer.\n            reference_input_tensors = node.input_tensors\n            reference_output_tensors = node.output_tensors\n\n            # If all previous input tensors are available in tensor_map,\n            # then call node.inbound_layer on them.\n            computed_data = []  # List of tuples (input, mask).\n            for x in reference_input_tensors:\n                if x in tensor_map:\n                    computed_data.append(tensor_map[x])\n\n            if len(computed_data) == len(reference_input_tensors):\n                # Call layer.\n                if node.arguments:\n                    kwargs = node.arguments\n                else:\n                    kwargs = {}\n                if len(computed_data) == 1:\n                    computed_tensor, computed_mask = computed_data[0]\n                    if has_arg(layer.call, 'mask'):\n                        if 'mask' not in kwargs:\n                            kwargs['mask'] = computed_mask\n                    output_tensors = to_list(\n                        layer(computed_tensor, **kwargs))\n                    output_masks = to_list(\n                        layer.compute_mask(computed_tensor,\n                                           computed_mask))\n                    computed_tensors = [computed_tensor]\n                    computed_masks = [computed_mask]\n                else:\n                    computed_tensors = [x[0] for x in computed_data]\n                    computed_masks = [x[1] for x in computed_data]\n                    if has_arg(layer.call, 'mask'):\n                        if 'mask' not in kwargs:\n                            kwargs['mask'] = computed_masks\n                    output_tensors = to_list(\n                        layer(computed_tensors, **kwargs))\n                    output_masks = to_list(\n                        layer.compute_mask(computed_tensors,\n                                           computed_masks))\n                # Update tensor_map.\n                for x, y, mask in zip(reference_output_tensors,\n                                      output_tensors,\n                                      output_masks):\n                    tensor_map[x] = (y, mask)\n\n    # Check that we did compute the model outputs,\n    # then instantiate a new model from inputs and outputs.\n    output_tensors = []\n    for x in model.outputs:\n        assert x in tensor_map, 'Could not compute output ' + str(x)\n        tensor, _ = tensor_map[x]\n        output_tensors.append(tensor)\n    return Model(input_tensors, output_tensors, name=model.name)\n\n```"
}