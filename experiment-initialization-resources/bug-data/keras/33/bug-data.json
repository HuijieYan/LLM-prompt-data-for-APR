{
    "keras:33": {
        "/Volumes/SSD2T/bgp_envs/repos/keras_33/keras/preprocessing/text.py": {
            "buggy_functions": [
                {
                    "function_name": "text_to_word_sequence",
                    "function_code": "def text_to_word_sequence(text,\n                          filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n                          lower=True, split=\" \"):\n    \"\"\"Converts a text to a sequence of words (or tokens).\n\n    # Arguments\n        text: Input text (string).\n        filters: Sequence of characters to filter out.\n        lower: Whether to convert the input to lowercase.\n        split: Sentence split marker (string).\n\n    # Returns\n        A list of words (or tokens).\n    \"\"\"\n    if lower:\n        text = text.lower()\n\n    if sys.version_info < (3,) and isinstance(text, unicode):\n        translate_map = dict((ord(c), unicode(split)) for c in filters)\n    else:\n        translate_map = maketrans(filters, split * len(filters))\n\n    text = text.translate(translate_map)\n    seq = text.split(split)\n    return [i for i in seq if i]\n",
                    "decorators": [],
                    "docstring": "Converts a text to a sequence of words (or tokens).\n\n# Arguments\n    text: Input text (string).\n    filters: Sequence of characters to filter out.\n    lower: Whether to convert the input to lowercase.\n    split: Sentence split marker (string).\n\n# Returns\n    A list of words (or tokens).",
                    "start_line": 24,
                    "end_line": 48,
                    "variables": {
                        "lower": [
                            38
                        ],
                        "text": [
                            41,
                            47,
                            46,
                            39
                        ],
                        "text.lower": [
                            39
                        ],
                        "sys.version_info": [
                            41
                        ],
                        "sys": [
                            41
                        ],
                        "isinstance": [
                            41
                        ],
                        "unicode": [
                            41,
                            42
                        ],
                        "translate_map": [
                            42,
                            44,
                            46
                        ],
                        "dict": [
                            42
                        ],
                        "ord": [
                            42
                        ],
                        "c": [
                            42
                        ],
                        "split": [
                            42,
                            44,
                            47
                        ],
                        "filters": [
                            42,
                            44
                        ],
                        "maketrans": [
                            44
                        ],
                        "len": [
                            44
                        ],
                        "text.translate": [
                            46
                        ],
                        "seq": [
                            48,
                            47
                        ],
                        "text.split": [
                            47
                        ],
                        "i": [
                            48
                        ]
                    },
                    "filtered_variables": {
                        "lower": [
                            38
                        ],
                        "text": [
                            41,
                            47,
                            46,
                            39
                        ],
                        "text.lower": [
                            39
                        ],
                        "sys.version_info": [
                            41
                        ],
                        "sys": [
                            41
                        ],
                        "unicode": [
                            41,
                            42
                        ],
                        "translate_map": [
                            42,
                            44,
                            46
                        ],
                        "c": [
                            42
                        ],
                        "split": [
                            42,
                            44,
                            47
                        ],
                        "filters": [
                            42,
                            44
                        ],
                        "maketrans": [
                            44
                        ],
                        "text.translate": [
                            46
                        ],
                        "seq": [
                            48,
                            47
                        ],
                        "text.split": [
                            47
                        ],
                        "i": [
                            48
                        ]
                    },
                    "diff_line_number": 41,
                    "class_data": null,
                    "variable_values": [
                        [
                            {
                                "lower": {
                                    "variable_value": "True",
                                    "variable_type": "bool",
                                    "variable_shape": null
                                },
                                "text": {
                                    "variable_value": "'ali!stopveli?stopk\u0131rkstopdokuzstopelli'",
                                    "variable_type": "str",
                                    "variable_shape": "38"
                                },
                                "text.lower": {
                                    "variable_value": "<built-in method lower of str object at 0x110ac4850>",
                                    "variable_type": "builtin_function_or_method",
                                    "variable_shape": null
                                },
                                "sys.version_info": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "sys": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "unicode": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "translate_map": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "c": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "split": {
                                    "variable_value": "'stop'",
                                    "variable_type": "str",
                                    "variable_shape": "4"
                                },
                                "filters": {
                                    "variable_value": "'!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{",
                                    "variable_type": "str",
                                    "variable_shape": "}~\\t\\n'"
                                },
                                "maketrans": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "text.translate": {
                                    "variable_value": "<built-in method translate of str object at 0x110ac4850>",
                                    "variable_type": "builtin_function_or_method",
                                    "variable_shape": null
                                },
                                "seq": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "text.split": {
                                    "variable_value": "<built-in method split of str object at 0x110ac4850>",
                                    "variable_type": "builtin_function_or_method",
                                    "variable_shape": null
                                },
                                "i": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                }
                            },
                            {}
                        ]
                    ],
                    "angelic_variable_values": [
                        [
                            {
                                "lower": {
                                    "variable_value": "True",
                                    "variable_type": "bool",
                                    "variable_shape": null
                                },
                                "text": {
                                    "variable_value": "'hello!stop?world!'",
                                    "variable_type": "str",
                                    "variable_shape": "17"
                                },
                                "text.lower": {
                                    "variable_value": "<built-in method lower of str object at 0x110c968f0>",
                                    "variable_type": "builtin_function_or_method",
                                    "variable_shape": null
                                },
                                "sys.version_info": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "sys": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "unicode": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "translate_map": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "c": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "split": {
                                    "variable_value": "'stop'",
                                    "variable_type": "str",
                                    "variable_shape": "4"
                                },
                                "filters": {
                                    "variable_value": "'!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{",
                                    "variable_type": "str",
                                    "variable_shape": "}~\\t\\n'"
                                },
                                "text.translate": {
                                    "variable_value": "<built-in method translate of str object at 0x110c968f0>",
                                    "variable_type": "builtin_function_or_method",
                                    "variable_shape": null
                                },
                                "maketrans": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "text.replace": {
                                    "variable_value": "<built-in method replace of str object at 0x110c968f0>",
                                    "variable_type": "builtin_function_or_method",
                                    "variable_shape": null
                                },
                                "translate_dict": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "seq": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "text.split": {
                                    "variable_value": "<built-in method split of str object at 0x110c968f0>",
                                    "variable_type": "builtin_function_or_method",
                                    "variable_shape": null
                                },
                                "i": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                }
                            },
                            {
                                "lower": {
                                    "variable_value": "True",
                                    "variable_type": "bool",
                                    "variable_shape": null
                                },
                                "text": {
                                    "variable_value": "'hellostopstopstopworldstop'",
                                    "variable_type": "str",
                                    "variable_shape": "26"
                                },
                                "text.lower": {
                                    "variable_value": "<built-in method lower of str object at 0x138cae300>",
                                    "variable_type": "builtin_function_or_method",
                                    "variable_shape": null
                                },
                                "sys.version_info": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "sys": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "unicode": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "translate_map": {
                                    "variable_value": "{33: 'stop', 34: 'stop', 35: 'stop', 36: 'stop', 37: 'stop', 38: 'stop', 40: 'stop', 41: 'stop', 42: 'stop', 43: 'stop', 44: 'stop', 45: 'stop', 46: 'stop', 47: 'stop', 58: 'stop', 59: 'stop', 60: 'stop', 61: 'stop', 62: 'stop', 63: 'stop', 64: 'stop', 91: 'stop', 92: 'stop', 93: 'stop', 94: 'stop', 95: 'stop', 96: 'stop', 123: 'stop', 124: 'stop', 125: 'stop', 126: 'stop', 9: 'stop', 10: 'stop'}",
                                    "variable_type": "dict",
                                    "variable_shape": "33"
                                },
                                "c": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "split": {
                                    "variable_value": "'stop'",
                                    "variable_type": "str",
                                    "variable_shape": "4"
                                },
                                "filters": {
                                    "variable_value": "'!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{",
                                    "variable_type": "str",
                                    "variable_shape": "}~\\t\\n'"
                                },
                                "text.translate": {
                                    "variable_value": "<built-in method translate of str object at 0x138cae300>",
                                    "variable_type": "builtin_function_or_method",
                                    "variable_shape": null
                                },
                                "maketrans": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "text.replace": {
                                    "variable_value": "<built-in method replace of str object at 0x138cae300>",
                                    "variable_type": "builtin_function_or_method",
                                    "variable_shape": null
                                },
                                "translate_dict": {
                                    "variable_value": "{'!': 'stop', '\"': 'stop', '#': 'stop', '$': 'stop', '%': 'stop', '&': 'stop', '(': 'stop', ')': 'stop', '*': 'stop', '+': 'stop', ',': 'stop', '-': 'stop', '.': 'stop', '/': 'stop', ':': 'stop', ';': 'stop', '<': 'stop', '=': 'stop', '>': 'stop', '?': 'stop', '@': 'stop', '[': 'stop', '\\\\': 'stop', ']': 'stop', '^': 'stop', '_': 'stop', '`': 'stop', '{': 'stop', '",
                                    "variable_type": "dict",
                                    "variable_shape": "': 'stop', '}': 'stop', '~': 'stop', '\\t': 'stop', '\\n': 'stop'}"
                                },
                                "seq": {
                                    "variable_value": "['hello', '', '', 'world', '']",
                                    "variable_type": "list",
                                    "variable_shape": "5"
                                },
                                "text.split": {
                                    "variable_value": "<built-in method split of str object at 0x138cae300>",
                                    "variable_type": "builtin_function_or_method",
                                    "variable_shape": null
                                },
                                "i": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                }
                            }
                        ],
                        [
                            {
                                "lower": {
                                    "variable_value": "True",
                                    "variable_type": "bool",
                                    "variable_shape": null
                                },
                                "text": {
                                    "variable_value": "'ali!stopveli?stopk\u0131rkstopdokuzstopelli'",
                                    "variable_type": "str",
                                    "variable_shape": "38"
                                },
                                "text.lower": {
                                    "variable_value": "<built-in method lower of str object at 0x104004850>",
                                    "variable_type": "builtin_function_or_method",
                                    "variable_shape": null
                                },
                                "sys.version_info": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "sys": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "unicode": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "translate_map": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "c": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "split": {
                                    "variable_value": "'stop'",
                                    "variable_type": "str",
                                    "variable_shape": "4"
                                },
                                "filters": {
                                    "variable_value": "'!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{",
                                    "variable_type": "str",
                                    "variable_shape": "}~\\t\\n'"
                                },
                                "text.translate": {
                                    "variable_value": "<built-in method translate of str object at 0x104004850>",
                                    "variable_type": "builtin_function_or_method",
                                    "variable_shape": null
                                },
                                "maketrans": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "text.replace": {
                                    "variable_value": "<built-in method replace of str object at 0x104004850>",
                                    "variable_type": "builtin_function_or_method",
                                    "variable_shape": null
                                },
                                "translate_dict": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "seq": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "text.split": {
                                    "variable_value": "<built-in method split of str object at 0x104004850>",
                                    "variable_type": "builtin_function_or_method",
                                    "variable_shape": null
                                },
                                "i": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                }
                            },
                            {
                                "lower": {
                                    "variable_value": "True",
                                    "variable_type": "bool",
                                    "variable_shape": null
                                },
                                "text": {
                                    "variable_value": "'alistopstopvelistopstopk\u0131rkstopdokuzstopelli'",
                                    "variable_type": "str",
                                    "variable_shape": "44"
                                },
                                "text.lower": {
                                    "variable_value": "<built-in method lower of str object at 0x12c0747c0>",
                                    "variable_type": "builtin_function_or_method",
                                    "variable_shape": null
                                },
                                "sys.version_info": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "sys": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "unicode": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "translate_map": {
                                    "variable_value": "{33: 'stop', 34: 'stop', 35: 'stop', 36: 'stop', 37: 'stop', 38: 'stop', 40: 'stop', 41: 'stop', 42: 'stop', 43: 'stop', 44: 'stop', 45: 'stop', 46: 'stop', 47: 'stop', 58: 'stop', 59: 'stop', 60: 'stop', 61: 'stop', 62: 'stop', 63: 'stop', 64: 'stop', 91: 'stop', 92: 'stop', 93: 'stop', 94: 'stop', 95: 'stop', 96: 'stop', 123: 'stop', 124: 'stop', 125: 'stop', 126: 'stop', 9: 'stop', 10: 'stop'}",
                                    "variable_type": "dict",
                                    "variable_shape": "33"
                                },
                                "c": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "split": {
                                    "variable_value": "'stop'",
                                    "variable_type": "str",
                                    "variable_shape": "4"
                                },
                                "filters": {
                                    "variable_value": "'!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{",
                                    "variable_type": "str",
                                    "variable_shape": "}~\\t\\n'"
                                },
                                "text.translate": {
                                    "variable_value": "<built-in method translate of str object at 0x12c0747c0>",
                                    "variable_type": "builtin_function_or_method",
                                    "variable_shape": null
                                },
                                "maketrans": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "text.replace": {
                                    "variable_value": "<built-in method replace of str object at 0x12c0747c0>",
                                    "variable_type": "builtin_function_or_method",
                                    "variable_shape": null
                                },
                                "translate_dict": {
                                    "variable_value": "{'!': 'stop', '\"': 'stop', '#': 'stop', '$': 'stop', '%': 'stop', '&': 'stop', '(': 'stop', ')': 'stop', '*': 'stop', '+': 'stop', ',': 'stop', '-': 'stop', '.': 'stop', '/': 'stop', ':': 'stop', ';': 'stop', '<': 'stop', '=': 'stop', '>': 'stop', '?': 'stop', '@': 'stop', '[': 'stop', '\\\\': 'stop', ']': 'stop', '^': 'stop', '_': 'stop', '`': 'stop', '{': 'stop', '",
                                    "variable_type": "dict",
                                    "variable_shape": "': 'stop', '}': 'stop', '~': 'stop', '\\t': 'stop', '\\n': 'stop'}"
                                },
                                "seq": {
                                    "variable_value": "['ali', '', 'veli', '', 'k\u0131rk', 'dokuz', 'elli']",
                                    "variable_type": "list",
                                    "variable_shape": "7"
                                },
                                "text.split": {
                                    "variable_value": "<built-in method split of str object at 0x12c0747c0>",
                                    "variable_type": "builtin_function_or_method",
                                    "variable_shape": null
                                },
                                "i": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                }
                            }
                        ]
                    ]
                }
            ],
            "inscope_functions": [
                "def text_to_word_sequence(text,\n                          filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n                          lower=True, split=\" \"):\n    \"\"\"Converts a text to a sequence of words (or tokens).\n\n    # Arguments\n        text: Input text (string).\n        filters: Sequence of characters to filter out.\n        lower: Whether to convert the input to lowercase.\n        split: Sentence split marker (string).\n\n    # Returns\n        A list of words (or tokens).\n    \"\"\"\n    if lower:\n        text = text.lower()\n\n    if sys.version_info < (3,) and isinstance(text, unicode):\n        translate_map = dict((ord(c), unicode(split)) for c in filters)\n    else:\n        translate_map = maketrans(filters, split * len(filters))\n\n    text = text.translate(translate_map)\n    seq = text.split(split)\n    return [i for i in seq if i]",
                "def one_hot(text, n,\n            filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n            lower=True,\n            split=' '):\n    \"\"\"One-hot encodes a text into a list of word indexes of size n.\n\n    This is a wrapper to the `hashing_trick` function using `hash` as the\n    hashing function; unicity of word to index mapping non-guaranteed.\n\n    # Arguments\n        text: Input text (string).\n        n: Dimension of the hashing space.\n        filters: Sequence of characters to filter out.\n        lower: Whether to convert the input to lowercase.\n        split: Sentence split marker (string).\n\n    # Returns\n        A list of integer word indices (unicity non-guaranteed).\n    \"\"\"\n    return hashing_trick(text, n,\n                         hash_function=hash,\n                         filters=filters,\n                         lower=lower,\n                         split=split)",
                "def hashing_trick(text, n,\n                  hash_function=None,\n                  filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n                  lower=True,\n                  split=' '):\n    \"\"\"Converts a text to a sequence of indexes in a fixed-size hashing space.\n\n    # Arguments\n        text: Input text (string).\n        n: Dimension of the hashing space.\n        hash_function: if `None` uses python `hash` function, can be 'md5' or\n            any function that takes in input a string and returns a int.\n            Note that `hash` is not a stable hashing function, so\n            it is not consistent across different runs, while 'md5'\n            is a stable hashing function.\n        filters: Sequence of characters to filter out.\n        lower: Whether to convert the input to lowercase.\n        split: Sentence split marker (string).\n\n    # Returns\n        A list of integer word indices (unicity non-guaranteed).\n\n    `0` is a reserved index that won't be assigned to any word.\n\n    Two or more words may be assigned to the same index, due to possible\n    collisions by the hashing function.\n    The [probability](https://en.wikipedia.org/wiki/Birthday_problem#Probability_table)\n    of a collision is in relation to the dimension of the hashing space and\n    the number of distinct objects.\n    \"\"\"\n    if hash_function is None:\n        hash_function = hash\n    elif hash_function == 'md5':\n        hash_function = lambda w: int(md5(w.encode()).hexdigest(), 16)\n\n    seq = text_to_word_sequence(text,\n                                filters=filters,\n                                lower=lower,\n                                split=split)\n    return [(hash_function(w) % (n - 1) + 1) for w in seq]",
                "def __init__(self, num_words=None,\n             filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n             lower=True,\n             split=' ',\n             char_level=False,\n             oov_token=None,\n             **kwargs):\n    # Legacy support\n    if 'nb_words' in kwargs:\n        warnings.warn('The `nb_words` argument in `Tokenizer` '\n                      'has been renamed `num_words`.')\n        num_words = kwargs.pop('nb_words')\n    if kwargs:\n        raise TypeError('Unrecognized keyword arguments: ' + str(kwargs))\n\n    self.word_counts = OrderedDict()\n    self.word_docs = {}\n    self.filters = filters\n    self.split = split\n    self.lower = lower\n    self.num_words = num_words\n    self.document_count = 0\n    self.char_level = char_level\n    self.oov_token = oov_token\n    self.index_docs = {}",
                "def fit_on_texts(self, texts):\n    \"\"\"Updates internal vocabulary based on a list of texts.\n    In the case where texts contains lists, we assume each entry of the lists\n    to be a token.\n\n    Required before using `texts_to_sequences` or `texts_to_matrix`.\n\n    # Arguments\n        texts: can be a list of strings,\n            a generator of strings (for memory-efficiency),\n            or a list of list of strings.\n    \"\"\"\n    for text in texts:\n        self.document_count += 1\n        if self.char_level or isinstance(text, list):\n            seq = text\n        else:\n            seq = text_to_word_sequence(text,\n                                        self.filters,\n                                        self.lower,\n                                        self.split)\n        for w in seq:\n            if w in self.word_counts:\n                self.word_counts[w] += 1\n            else:\n                self.word_counts[w] = 1\n        for w in set(seq):\n            if w in self.word_docs:\n                self.word_docs[w] += 1\n            else:\n                self.word_docs[w] = 1\n\n    wcounts = list(self.word_counts.items())\n    wcounts.sort(key=lambda x: x[1], reverse=True)\n    sorted_voc = [wc[0] for wc in wcounts]\n    # note that index 0 is reserved, never assigned to an existing word\n    self.word_index = dict(list(zip(sorted_voc, list(range(1, len(sorted_voc) + 1)))))\n\n    if self.oov_token is not None:\n        i = self.word_index.get(self.oov_token)\n        if i is None:\n            self.word_index[self.oov_token] = len(self.word_index) + 1\n\n    for w, c in list(self.word_docs.items()):\n        self.index_docs[self.word_index[w]] = c",
                "def fit_on_sequences(self, sequences):\n    \"\"\"Updates internal vocabulary based on a list of sequences.\n\n    Required before using `sequences_to_matrix`\n    (if `fit_on_texts` was never called).\n\n    # Arguments\n        sequences: A list of sequence.\n            A \"sequence\" is a list of integer word indices.\n    \"\"\"\n    self.document_count += len(sequences)\n    for seq in sequences:\n        seq = set(seq)\n        for i in seq:\n            if i not in self.index_docs:\n                self.index_docs[i] = 1\n            else:\n                self.index_docs[i] += 1",
                "def texts_to_sequences(self, texts):\n    \"\"\"Transforms each text in texts in a sequence of integers.\n\n    Only top \"num_words\" most frequent words will be taken into account.\n    Only words known by the tokenizer will be taken into account.\n\n    # Arguments\n        texts: A list of texts (strings).\n\n    # Returns\n        A list of sequences.\n    \"\"\"\n    res = []\n    for vect in self.texts_to_sequences_generator(texts):\n        res.append(vect)\n    return res",
                "def texts_to_sequences_generator(self, texts):\n    \"\"\"Transforms each text in `texts` in a sequence of integers.\n    Each item in texts can also be a list, in which case we assume each item of that list\n    to be a token.\n\n    Only top \"num_words\" most frequent words will be taken into account.\n    Only words known by the tokenizer will be taken into account.\n\n    # Arguments\n        texts: A list of texts (strings).\n\n    # Yields\n        Yields individual sequences.\n    \"\"\"\n    num_words = self.num_words\n    for text in texts:\n        if self.char_level or isinstance(text, list):\n            seq = text\n        else:\n            seq = text_to_word_sequence(text,\n                                        self.filters,\n                                        self.lower,\n                                        self.split)\n        vect = []\n        for w in seq:\n            i = self.word_index.get(w)\n            if i is not None:\n                if num_words and i >= num_words:\n                    continue\n                else:\n                    vect.append(i)\n            elif self.oov_token is not None:\n                i = self.word_index.get(self.oov_token)\n                if i is not None:\n                    vect.append(i)\n        yield vect",
                "def texts_to_matrix(self, texts, mode='binary'):\n    \"\"\"Convert a list of texts to a Numpy matrix.\n\n    # Arguments\n        texts: list of strings.\n        mode: one of \"binary\", \"count\", \"tfidf\", \"freq\".\n\n    # Returns\n        A Numpy matrix.\n    \"\"\"\n    sequences = self.texts_to_sequences(texts)\n    return self.sequences_to_matrix(sequences, mode=mode)",
                "def sequences_to_matrix(self, sequences, mode='binary'):\n    \"\"\"Converts a list of sequences into a Numpy matrix.\n\n    # Arguments\n        sequences: list of sequences\n            (a sequence is a list of integer word indices).\n        mode: one of \"binary\", \"count\", \"tfidf\", \"freq\"\n\n    # Returns\n        A Numpy matrix.\n\n    # Raises\n        ValueError: In case of invalid `mode` argument,\n            or if the Tokenizer requires to be fit to sample data.\n    \"\"\"\n    if not self.num_words:\n        if self.word_index:\n            num_words = len(self.word_index) + 1\n        else:\n            raise ValueError('Specify a dimension (num_words argument), '\n                             'or fit on some text data first.')\n    else:\n        num_words = self.num_words\n\n    if mode == 'tfidf' and not self.document_count:\n        raise ValueError('Fit the Tokenizer on some data '\n                         'before using tfidf mode.')\n\n    x = np.zeros((len(sequences), num_words))\n    for i, seq in enumerate(sequences):\n        if not seq:\n            continue\n        counts = {}\n        for j in seq:\n            if j >= num_words:\n                continue\n            if j not in counts:\n                counts[j] = 1.\n            else:\n                counts[j] += 1\n        for j, c in list(counts.items()):\n            if mode == 'count':\n                x[i][j] = c\n            elif mode == 'freq':\n                x[i][j] = c / len(seq)\n            elif mode == 'binary':\n                x[i][j] = 1\n            elif mode == 'tfidf':\n                # Use weighting scheme 2 in\n                # https://en.wikipedia.org/wiki/Tf%E2%80%93idf\n                tf = 1 + np.log(c)\n                idf = np.log(1 + self.document_count /\n                             (1 + self.index_docs.get(j, 0)))\n                x[i][j] = tf * idf\n            else:\n                raise ValueError('Unknown vectorization mode:', mode)\n    return x"
            ],
            "inscope_function_signatures": [
                "text_to_word_sequence(text, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ')",
                "one_hot(text, n, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ')",
                "hashing_trick(text, n, hash_function=None, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ')",
                "__init__(self, num_words=None, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ', char_level=False, oov_token=None, **kwargs)",
                "fit_on_texts(self, texts)",
                "fit_on_sequences(self, sequences)",
                "texts_to_sequences(self, texts)",
                "texts_to_sequences_generator(self, texts)",
                "texts_to_matrix(self, texts, mode='binary')",
                "sequences_to_matrix(self, sequences, mode='binary')"
            ],
            "variables_in_file": {
                "sys.version_info": [
                    41,
                    18
                ],
                "sys": [
                    41,
                    18
                ],
                "maketrans": [
                    19,
                    44,
                    21
                ],
                "string.maketrans": [
                    19
                ],
                "string": [
                    19
                ],
                "str.maketrans": [
                    21
                ],
                "str": [
                    161,
                    21
                ],
                "lower": [
                    73,
                    114,
                    38,
                    167
                ],
                "text": [
                    70,
                    39,
                    41,
                    46,
                    47,
                    112,
                    271,
                    272,
                    273,
                    275,
                    186,
                    188,
                    189,
                    191
                ],
                "text.lower": [
                    39
                ],
                "isinstance": [
                    272,
                    41,
                    188
                ],
                "unicode": [
                    41,
                    42
                ],
                "translate_map": [
                    42,
                    44,
                    46
                ],
                "dict": [
                    210,
                    42
                ],
                "ord": [
                    42
                ],
                "c": [
                    356,
                    218,
                    42,
                    217,
                    346,
                    348,
                    350
                ],
                "split": [
                    166,
                    42,
                    74,
                    44,
                    47,
                    115
                ],
                "filters": [
                    165,
                    72,
                    42,
                    44,
                    113
                ],
                "len": [
                    323,
                    230,
                    44,
                    334,
                    210,
                    215,
                    350
                ],
                "text.translate": [
                    46
                ],
                "seq": [
                    195,
                    231,
                    200,
                    232,
                    233,
                    47,
                    48,
                    112,
                    273,
                    275,
                    116,
                    335,
                    336,
                    339,
                    280,
                    189,
                    350,
                    191
                ],
                "text.split": [
                    47
                ],
                "i": [
                    281,
                    282,
                    283,
                    286,
                    288,
                    289,
                    290,
                    48,
                    335,
                    213,
                    214,
                    348,
                    350,
                    352,
                    359,
                    233,
                    234,
                    235,
                    237
                ],
                "hashing_trick": [
                    70
                ],
                "n": [
                    116,
                    70
                ],
                "hash": [
                    108,
                    71
                ],
                "hash_function": [
                    107,
                    108,
                    109,
                    110,
                    116
                ],
                "int": [
                    110
                ],
                "hexdigest": [
                    110
                ],
                "md5": [
                    110
                ],
                "w.encode": [
                    110
                ],
                "w": [
                    195,
                    196,
                    197,
                    281,
                    199,
                    200,
                    201,
                    202,
                    204,
                    110,
                    116,
                    280,
                    217,
                    218
                ],
                "text_to_word_sequence": [
                    112,
                    275,
                    191
                ],
                "object": [
                    119
                ],
                "kwargs": [
                    160,
                    161,
                    156,
                    159
                ],
                "warnings.warn": [
                    157
                ],
                "warnings": [
                    157
                ],
                "num_words": [
                    323,
                    168,
                    328,
                    270,
                    334,
                    340,
                    283,
                    159
                ],
                "kwargs.pop": [
                    159
                ],
                "TypeError": [
                    161
                ],
                "self.word_counts": [
                    163,
                    196,
                    197,
                    199,
                    206
                ],
                "self": [
                    270,
                    272,
                    276,
                    277,
                    278,
                    281,
                    287,
                    288,
                    163,
                    164,
                    165,
                    166,
                    167,
                    168,
                    169,
                    170,
                    171,
                    172,
                    303,
                    304,
                    187,
                    188,
                    192,
                    193,
                    194,
                    321,
                    196,
                    197,
                    322,
                    199,
                    323,
                    201,
                    202,
                    328,
                    204,
                    330,
                    206,
                    210,
                    212,
                    213,
                    215,
                    217,
                    218,
                    357,
                    230,
                    358,
                    234,
                    235,
                    237,
                    252
                ],
                "OrderedDict": [
                    163
                ],
                "self.word_docs": [
                    164,
                    201,
                    202,
                    204,
                    217
                ],
                "self.filters": [
                    192,
                    276,
                    165
                ],
                "self.split": [
                    194,
                    166,
                    278
                ],
                "self.lower": [
                    193,
                    277,
                    167
                ],
                "self.num_words": [
                    168,
                    321,
                    328,
                    270
                ],
                "self.document_count": [
                    357,
                    230,
                    169,
                    330,
                    187
                ],
                "self.char_level": [
                    272,
                    170,
                    188
                ],
                "char_level": [
                    170
                ],
                "self.oov_token": [
                    288,
                    171,
                    212,
                    213,
                    215,
                    287
                ],
                "oov_token": [
                    171
                ],
                "self.index_docs": [
                    358,
                    234,
                    235,
                    172,
                    237,
                    218
                ],
                "texts": [
                    186,
                    252,
                    303,
                    271
                ],
                "list": [
                    206,
                    272,
                    210,
                    217,
                    346,
                    188
                ],
                "set": [
                    200,
                    232
                ],
                "wcounts": [
                    208,
                    206,
                    207
                ],
                "self.word_counts.items": [
                    206
                ],
                "wcounts.sort": [
                    207
                ],
                "x": [
                    352,
                    359,
                    362,
                    334,
                    207,
                    348,
                    350
                ],
                "sorted_voc": [
                    208,
                    210
                ],
                "wc": [
                    208
                ],
                "self.word_index": [
                    288,
                    322,
                    323,
                    210,
                    213,
                    215,
                    281,
                    218
                ],
                "zip": [
                    210
                ],
                "range": [
                    210
                ],
                "self.word_index.get": [
                    288,
                    281,
                    213
                ],
                "self.word_docs.items": [
                    217
                ],
                "sequences": [
                    230,
                    231,
                    334,
                    303,
                    304,
                    335
                ],
                "res": [
                    251,
                    253,
                    254
                ],
                "vect": [
                    290,
                    291,
                    279,
                    252,
                    253,
                    286
                ],
                "self.texts_to_sequences_generator": [
                    252
                ],
                "res.append": [
                    253
                ],
                "vect.append": [
                    290,
                    286
                ],
                "self.texts_to_sequences": [
                    303
                ],
                "self.sequences_to_matrix": [
                    304
                ],
                "mode": [
                    353,
                    361,
                    330,
                    304,
                    347,
                    349,
                    351
                ],
                "ValueError": [
                    361,
                    331,
                    325
                ],
                "np.zeros": [
                    334
                ],
                "np": [
                    356,
                    357,
                    334
                ],
                "enumerate": [
                    335
                ],
                "counts": [
                    338,
                    342,
                    343,
                    345,
                    346
                ],
                "j": [
                    352,
                    358,
                    359,
                    339,
                    340,
                    342,
                    343,
                    345,
                    346,
                    348,
                    350
                ],
                "counts.items": [
                    346
                ],
                "tf": [
                    356,
                    359
                ],
                "np.log": [
                    356,
                    357
                ],
                "idf": [
                    357,
                    359
                ],
                "self.index_docs.get": [
                    358
                ]
            },
            "filtered_variables_in_file": {
                "sys.version_info": [
                    41,
                    18
                ],
                "sys": [
                    41,
                    18
                ],
                "maketrans": [
                    19,
                    44,
                    21
                ],
                "string.maketrans": [
                    19
                ],
                "string": [
                    19
                ],
                "str.maketrans": [
                    21
                ],
                "lower": [
                    73,
                    114,
                    38,
                    167
                ],
                "text": [
                    70,
                    39,
                    41,
                    46,
                    47,
                    112,
                    271,
                    272,
                    273,
                    275,
                    186,
                    188,
                    189,
                    191
                ],
                "text.lower": [
                    39
                ],
                "unicode": [
                    41,
                    42
                ],
                "translate_map": [
                    42,
                    44,
                    46
                ],
                "c": [
                    356,
                    218,
                    42,
                    217,
                    346,
                    348,
                    350
                ],
                "split": [
                    166,
                    42,
                    74,
                    44,
                    47,
                    115
                ],
                "filters": [
                    165,
                    72,
                    42,
                    44,
                    113
                ],
                "text.translate": [
                    46
                ],
                "seq": [
                    195,
                    231,
                    200,
                    232,
                    233,
                    47,
                    48,
                    112,
                    273,
                    275,
                    116,
                    335,
                    336,
                    339,
                    280,
                    189,
                    350,
                    191
                ],
                "text.split": [
                    47
                ],
                "i": [
                    281,
                    282,
                    283,
                    286,
                    288,
                    289,
                    290,
                    48,
                    335,
                    213,
                    214,
                    348,
                    350,
                    352,
                    359,
                    233,
                    234,
                    235,
                    237
                ],
                "hashing_trick": [
                    70
                ],
                "n": [
                    116,
                    70
                ],
                "hash_function": [
                    107,
                    108,
                    109,
                    110,
                    116
                ],
                "hexdigest": [
                    110
                ],
                "md5": [
                    110
                ],
                "w.encode": [
                    110
                ],
                "w": [
                    195,
                    196,
                    197,
                    281,
                    199,
                    200,
                    201,
                    202,
                    204,
                    110,
                    116,
                    280,
                    217,
                    218
                ],
                "text_to_word_sequence": [
                    112,
                    275,
                    191
                ],
                "kwargs": [
                    160,
                    161,
                    156,
                    159
                ],
                "warnings.warn": [
                    157
                ],
                "warnings": [
                    157
                ],
                "num_words": [
                    323,
                    168,
                    328,
                    270,
                    334,
                    340,
                    283,
                    159
                ],
                "kwargs.pop": [
                    159
                ],
                "self.word_counts": [
                    163,
                    196,
                    197,
                    199,
                    206
                ],
                "self": [
                    270,
                    272,
                    276,
                    277,
                    278,
                    281,
                    287,
                    288,
                    163,
                    164,
                    165,
                    166,
                    167,
                    168,
                    169,
                    170,
                    171,
                    172,
                    303,
                    304,
                    187,
                    188,
                    192,
                    193,
                    194,
                    321,
                    196,
                    197,
                    322,
                    199,
                    323,
                    201,
                    202,
                    328,
                    204,
                    330,
                    206,
                    210,
                    212,
                    213,
                    215,
                    217,
                    218,
                    357,
                    230,
                    358,
                    234,
                    235,
                    237,
                    252
                ],
                "OrderedDict": [
                    163
                ],
                "self.word_docs": [
                    164,
                    201,
                    202,
                    204,
                    217
                ],
                "self.filters": [
                    192,
                    276,
                    165
                ],
                "self.split": [
                    194,
                    166,
                    278
                ],
                "self.lower": [
                    193,
                    277,
                    167
                ],
                "self.num_words": [
                    168,
                    321,
                    328,
                    270
                ],
                "self.document_count": [
                    357,
                    230,
                    169,
                    330,
                    187
                ],
                "self.char_level": [
                    272,
                    170,
                    188
                ],
                "char_level": [
                    170
                ],
                "self.oov_token": [
                    288,
                    171,
                    212,
                    213,
                    215,
                    287
                ],
                "oov_token": [
                    171
                ],
                "self.index_docs": [
                    358,
                    234,
                    235,
                    172,
                    237,
                    218
                ],
                "texts": [
                    186,
                    252,
                    303,
                    271
                ],
                "wcounts": [
                    208,
                    206,
                    207
                ],
                "self.word_counts.items": [
                    206
                ],
                "wcounts.sort": [
                    207
                ],
                "x": [
                    352,
                    359,
                    362,
                    334,
                    207,
                    348,
                    350
                ],
                "sorted_voc": [
                    208,
                    210
                ],
                "wc": [
                    208
                ],
                "self.word_index": [
                    288,
                    322,
                    323,
                    210,
                    213,
                    215,
                    281,
                    218
                ],
                "self.word_index.get": [
                    288,
                    281,
                    213
                ],
                "self.word_docs.items": [
                    217
                ],
                "sequences": [
                    230,
                    231,
                    334,
                    303,
                    304,
                    335
                ],
                "res": [
                    251,
                    253,
                    254
                ],
                "vect": [
                    290,
                    291,
                    279,
                    252,
                    253,
                    286
                ],
                "self.texts_to_sequences_generator": [
                    252
                ],
                "res.append": [
                    253
                ],
                "vect.append": [
                    290,
                    286
                ],
                "self.texts_to_sequences": [
                    303
                ],
                "self.sequences_to_matrix": [
                    304
                ],
                "mode": [
                    353,
                    361,
                    330,
                    304,
                    347,
                    349,
                    351
                ],
                "np.zeros": [
                    334
                ],
                "np": [
                    356,
                    357,
                    334
                ],
                "counts": [
                    338,
                    342,
                    343,
                    345,
                    346
                ],
                "j": [
                    352,
                    358,
                    359,
                    339,
                    340,
                    342,
                    343,
                    345,
                    346,
                    348,
                    350
                ],
                "counts.items": [
                    346
                ],
                "tf": [
                    356,
                    359
                ],
                "np.log": [
                    356,
                    357
                ],
                "idf": [
                    357,
                    359
                ],
                "self.index_docs.get": [
                    358
                ]
            }
        },
        "test_data": [
            {
                "test_path": "/Volumes/SSD2T/bgp_envs/repos/keras_33/tests/keras/preprocessing/text_test.py",
                "test_function": "test_text_to_word_sequence_multichar_split",
                "test_function_code": "def test_text_to_word_sequence_multichar_split():\n    text = 'hello!stop?world!'\n    assert text_to_word_sequence(text, split='stop') == ['hello', 'world']",
                "test_error": "ValueError: the first two maketrans arguments must have equal length",
                "full_test_error": "def test_text_to_word_sequence_multichar_split():\n        text = 'hello!stop?world!'\n>       assert text_to_word_sequence(text, split='stop') == ['hello', 'world']\n\ntests/keras/preprocessing/text_test.py:78: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ntext = 'hello!stop?world!', filters = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\nlower = True, split = 'stop'\n\n    def text_to_word_sequence(text,\n                              filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n                              lower=True, split=\" \"):\n        \"\"\"Converts a text to a sequence of words (or tokens).\n    \n        # Arguments\n            text: Input text (string).\n            filters: Sequence of characters to filter out.\n            lower: Whether to convert the input to lowercase.\n            split: Sentence split marker (string).\n    \n        # Returns\n            A list of words (or tokens).\n        \"\"\"\n        if lower:\n            text = text.lower()\n    \n        if sys.version_info < (3,) and isinstance(text, unicode):\n            translate_map = dict((ord(c), unicode(split)) for c in filters)\n        else:\n>           translate_map = maketrans(filters, split * len(filters))\nE           ValueError: the first two maketrans arguments must have equal length\n\nkeras/preprocessing/text.py:44: ValueError",
                "traceback": null,
                "test_error_location": null,
                "test_function_decorators": []
            },
            {
                "test_path": "/Volumes/SSD2T/bgp_envs/repos/keras_33/tests/keras/preprocessing/text_test.py",
                "test_function": "test_text_to_word_sequence_unicode_multichar_split",
                "test_function_code": "def test_text_to_word_sequence_unicode_multichar_split():\n    text = u'ali!stopveli?stopk\u0131rkstopdokuzstopelli'\n    assert text_to_word_sequence(text, split='stop') == [u'ali', u'veli', u'k\u0131rk', u'dokuz', u'elli']",
                "test_error": "ValueError: the first two maketrans arguments must have equal length",
                "full_test_error": "def test_text_to_word_sequence_unicode_multichar_split():\n        text = u'ali!stopveli?stopk\u0131rkstopdokuzstopelli'\n>       assert text_to_word_sequence(text, split='stop') == [u'ali', u'veli', u'k\u0131rk', u'dokuz', u'elli']\n\ntests/keras/preprocessing/text_test.py:88: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ntext = 'ali!stopveli?stopk\u0131rkstopdokuzstopelli'\nfilters = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower = True, split = 'stop'\n\n    def text_to_word_sequence(text,\n                              filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n                              lower=True, split=\" \"):\n        \"\"\"Converts a text to a sequence of words (or tokens).\n    \n        # Arguments\n            text: Input text (string).\n            filters: Sequence of characters to filter out.\n            lower: Whether to convert the input to lowercase.\n            split: Sentence split marker (string).\n    \n        # Returns\n            A list of words (or tokens).\n        \"\"\"\n        if lower:\n            text = text.lower()\n    \n        if sys.version_info < (3,) and isinstance(text, unicode):\n            translate_map = dict((ord(c), unicode(split)) for c in filters)\n        else:\n>           translate_map = maketrans(filters, split * len(filters))\nE           ValueError: the first two maketrans arguments must have equal length\n\nkeras/preprocessing/text.py:44: ValueError",
                "traceback": null,
                "test_error_location": null,
                "test_function_decorators": []
            }
        ]
    }
}