# Test code

```json
[
    "    def test_robotstxt_immediate_error(self):\n        self.crawler.settings.set('ROBOTSTXT_OBEY', True)\n        err = error.DNSLookupError('Robotstxt address not found')\n        def immediate_failure(request, spider):\n            deferred = Deferred()\n            deferred.errback(failure.Failure(err))\n            return deferred\n        self.crawler.engine.download.side_effect = immediate_failure\n\n        middleware = RobotsTxtMiddleware(self.crawler)\n        return self.assertNotIgnored(Request('http://site.local'), middleware)"
]
```
