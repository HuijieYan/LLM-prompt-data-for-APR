{
    "luigi:24": {
        "/home/ubuntu/Desktop/bgp_envs_local/repos/luigi_24/luigi/contrib/spark.py": {
            "buggy_functions": [
                {
                    "function_name": "_dict_arg",
                    "function_code": "def _dict_arg(self, name, value):\n    command = []\n    if value and isinstance(value, dict):\n        for prop, value in value.items():\n            command += [name, '\"{0}={1}\"'.format(prop, value)]\n    return command\n",
                    "decorators": [],
                    "docstring": null,
                    "start_line": 268,
                    "end_line": 273,
                    "variables": {
                        "command": [
                            272,
                            273,
                            269
                        ],
                        "value": [
                            272,
                            270,
                            271
                        ],
                        "isinstance": [
                            270
                        ],
                        "dict": [
                            270
                        ],
                        "prop": [
                            272,
                            271
                        ],
                        "value.items": [
                            271
                        ],
                        "name": [
                            272
                        ],
                        "format": [
                            272
                        ]
                    },
                    "filtered_variables": {
                        "command": [
                            272,
                            273,
                            269
                        ],
                        "value": [
                            272,
                            270,
                            271
                        ],
                        "prop": [
                            272,
                            271
                        ],
                        "value.items": [
                            271
                        ],
                        "name": [
                            272
                        ]
                    },
                    "diff_line_number": 272,
                    "class_data": {
                        "signature": "class SparkSubmitTask(luigi.Task)",
                        "docstring": "Template task for running a Spark job\n\nSupports running jobs on Spark local, standalone, Mesos or Yarn\n\nSee http://spark.apache.org/docs/latest/submitting-applications.html\nfor more information",
                        "constructor_docstring": null,
                        "functions": [
                            "def app_options(self):\n    \"\"\"\n    Subclass this method to map your task parameters to the app's arguments\n\n    \"\"\"\n    return []",
                            "@property\ndef spark_submit(self):\n    return configuration.get_config().get('spark', 'spark-submit', 'spark-submit')",
                            "@property\ndef master(self):\n    return configuration.get_config().get('spark', 'master', None)",
                            "@property\ndef deploy_mode(self):\n    return configuration.get_config().get('spark', 'deploy-mode', None)",
                            "@property\ndef jars(self):\n    return self._list_config(configuration.get_config().get('spark', 'jars', None))",
                            "@property\ndef py_files(self):\n    return self._list_config(configuration.get_config().get('spark', 'py-files', None))",
                            "@property\ndef files(self):\n    return self._list_config(configuration.get_config().get('spark', 'files', None))",
                            "@property\ndef conf(self):\n    return self._dict_config(configuration.get_config().get('spark', 'conf', None))",
                            "@property\ndef properties_file(self):\n    return configuration.get_config().get('spark', 'properties-file', None)",
                            "@property\ndef driver_memory(self):\n    return configuration.get_config().get('spark', 'driver-memory', None)",
                            "@property\ndef driver_java_options(self):\n    return configuration.get_config().get('spark', 'driver-java-options', None)",
                            "@property\ndef driver_library_path(self):\n    return configuration.get_config().get('spark', 'driver-library-path', None)",
                            "@property\ndef driver_class_path(self):\n    return configuration.get_config().get('spark', 'driver-class-path', None)",
                            "@property\ndef executor_memory(self):\n    return configuration.get_config().get('spark', 'executor-memory', None)",
                            "@property\ndef driver_cores(self):\n    return configuration.get_config().get('spark', 'driver-cores', None)",
                            "@property\ndef supervise(self):\n    return bool(configuration.get_config().get('spark', 'supervise', False))",
                            "@property\ndef total_executor_cores(self):\n    return configuration.get_config().get('spark', 'total-executor-cores', None)",
                            "@property\ndef executor_cores(self):\n    return configuration.get_config().get('spark', 'executor-cores', None)",
                            "@property\ndef queue(self):\n    return configuration.get_config().get('spark', 'queue', None)",
                            "@property\ndef num_executors(self):\n    return configuration.get_config().get('spark', 'num-executors', None)",
                            "@property\ndef archives(self):\n    return self._list_config(configuration.get_config().get('spark', 'archives', None))",
                            "@property\ndef hadoop_conf_dir(self):\n    return configuration.get_config().get('spark', 'hadoop-conf-dir', None)",
                            "def get_environment(self):\n    env = os.environ.copy()\n    hadoop_conf_dir = self.hadoop_conf_dir\n    if hadoop_conf_dir:\n        env['HADOOP_CONF_DIR'] = hadoop_conf_dir\n    return env",
                            "def spark_command(self):\n    command = [self.spark_submit]\n    command += self._text_arg('--master', self.master)\n    command += self._text_arg('--deploy-mode', self.deploy_mode)\n    command += self._text_arg('--name', self.name)\n    command += self._text_arg('--class', self.entry_class)\n    command += self._list_arg('--jars', self.jars)\n    command += self._list_arg('--py-files', self.py_files)\n    command += self._list_arg('--files', self.files)\n    command += self._list_arg('--archives', self.archives)\n    command += self._dict_arg('--conf', self.conf)\n    command += self._text_arg('--properties-file', self.properties_file)\n    command += self._text_arg('--driver-memory', self.driver_memory)\n    command += self._text_arg('--driver-java-options', self.driver_java_options)\n    command += self._text_arg('--driver-library-path', self.driver_library_path)\n    command += self._text_arg('--driver-class-path', self.driver_class_path)\n    command += self._text_arg('--executor-memory', self.executor_memory)\n    command += self._text_arg('--driver-cores', self.driver_cores)\n    command += self._flag_arg('--supervise', self.supervise)\n    command += self._text_arg('--total-executor-cores', self.total_executor_cores)\n    command += self._text_arg('--executor-cores', self.executor_cores)\n    command += self._text_arg('--queue', self.queue)\n    command += self._text_arg('--num-executors', self.num_executors)\n    return command",
                            "def app_command(self):\n    if not self.app:\n        raise NotImplementedError('subclass should define an app (.jar or .py file)')\n    return [self.app] + self.app_options()",
                            "def run(self):\n    args = list(map(str, self.spark_command() + self.app_command()))\n    logger.info('Running: %s', repr(args))\n    (tmp_stdout, tmp_stderr) = (tempfile.TemporaryFile(), tempfile.TemporaryFile())\n    proc = subprocess.Popen(args, stdout=tmp_stdout, stderr=tmp_stderr, env=self.get_environment(), close_fds=True, universal_newlines=True)\n    try:\n        with SparkRunContext(proc):\n            proc.wait()\n        tmp_stdout.seek(0)\n        stdout = ''.join(map(lambda s: s.decode('utf-8'), tmp_stdout.readlines()))\n        logger.info('Spark job stdout:\\n{0}'.format(stdout))\n        if proc.returncode != 0:\n            tmp_stderr.seek(0)\n            stderr = ''.join(map(lambda s: s.decode('utf-8'), tmp_stderr.readlines()))\n            raise SparkJobError('Spark job failed {0}'.format(repr(args)), out=stdout, err=stderr)\n    finally:\n        tmp_stderr.close()\n        tmp_stdout.close()",
                            "def _list_config(self, config):\n    if config and isinstance(config, six.string_types):\n        return list(map(lambda x: x.strip(), config.split(',')))",
                            "def _dict_config(self, config):\n    if config and isinstance(config, six.string_types):\n        return dict(map(lambda i: i.split('='), config.split('|')))",
                            "def _text_arg(self, name, value):\n    if value:\n        return [name, value]\n    return []",
                            "def _list_arg(self, name, value):\n    if value and isinstance(value, (list, tuple)):\n        return [name, ','.join(value)]\n    return []",
                            "def _dict_arg(self, name, value):\n    command = []\n    if value and isinstance(value, dict):\n        for (prop, value) in value.items():\n            command += [name, '\"{0}={1}\"'.format(prop, value)]\n    return command",
                            "def _flag_arg(self, name, value):\n    if value:\n        return [name]\n    return []"
                        ],
                        "constructor_variables": [],
                        "class_level_variables": [
                            "name = None",
                            "entry_class = None",
                            "app = None"
                        ],
                        "class_decorators": [],
                        "function_signatures": [
                            "app_options(self)",
                            "spark_submit(self)",
                            "master(self)",
                            "deploy_mode(self)",
                            "jars(self)",
                            "py_files(self)",
                            "files(self)",
                            "conf(self)",
                            "properties_file(self)",
                            "driver_memory(self)",
                            "driver_java_options(self)",
                            "driver_library_path(self)",
                            "driver_class_path(self)",
                            "executor_memory(self)",
                            "driver_cores(self)",
                            "supervise(self)",
                            "total_executor_cores(self)",
                            "executor_cores(self)",
                            "queue(self)",
                            "num_executors(self)",
                            "archives(self)",
                            "hadoop_conf_dir(self)",
                            "get_environment(self)",
                            "spark_command(self)",
                            "app_command(self)",
                            "run(self)",
                            "_list_config(self, config)",
                            "_dict_config(self, config)",
                            "_text_arg(self, name, value)",
                            "_list_arg(self, name, value)",
                            "_dict_arg(self, name, value)",
                            "_flag_arg(self, name, value)"
                        ],
                        "class_level_variable_names": [
                            "name",
                            "entry_class",
                            "app"
                        ],
                        "constructor_variable_names": []
                    },
                    "used_imports": [],
                    "variable_values": [
                        [
                            {
                                "command": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "value": {
                                    "variable_value": "{'Prop': 'Value'}",
                                    "variable_type": "dict",
                                    "variable_shape": "1"
                                },
                                "prop": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "value.items": {
                                    "variable_value": "<built-in method items of dict object at 0x7f1cd0222f40>",
                                    "variable_type": "builtin_function_or_method",
                                    "variable_shape": null
                                },
                                "name": {
                                    "variable_value": "'--conf'",
                                    "variable_type": "str",
                                    "variable_shape": "6"
                                }
                            },
                            {
                                "command": {
                                    "variable_value": "['--conf', '\"Prop=Value\"']",
                                    "variable_type": "list",
                                    "variable_shape": "2"
                                },
                                "value": {
                                    "variable_value": "'Value'",
                                    "variable_type": "str",
                                    "variable_shape": "5"
                                },
                                "prop": {
                                    "variable_value": "'Prop'",
                                    "variable_type": "str",
                                    "variable_shape": "4"
                                },
                                "value.items": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "name": {
                                    "variable_value": "'--conf'",
                                    "variable_type": "str",
                                    "variable_shape": "6"
                                }
                            }
                        ],
                        [
                            {
                                "command": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "value": {
                                    "variable_value": "{'prop1': 'val1'}",
                                    "variable_type": "dict",
                                    "variable_shape": "1"
                                },
                                "prop": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "value.items": {
                                    "variable_value": "<built-in method items of dict object at 0x7f1ccc600f40>",
                                    "variable_type": "builtin_function_or_method",
                                    "variable_shape": null
                                },
                                "name": {
                                    "variable_value": "'--conf'",
                                    "variable_type": "str",
                                    "variable_shape": "6"
                                }
                            },
                            {
                                "command": {
                                    "variable_value": "['--conf', '\"prop1=val1\"']",
                                    "variable_type": "list",
                                    "variable_shape": "2"
                                },
                                "value": {
                                    "variable_value": "'val1'",
                                    "variable_type": "str",
                                    "variable_shape": "4"
                                },
                                "prop": {
                                    "variable_value": "'prop1'",
                                    "variable_type": "str",
                                    "variable_shape": "5"
                                },
                                "value.items": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "name": {
                                    "variable_value": "'--conf'",
                                    "variable_type": "str",
                                    "variable_shape": "6"
                                }
                            }
                        ]
                    ],
                    "angelic_variable_values": [
                        [
                            {
                                "command": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "value": {
                                    "variable_value": "{'Prop': 'Value'}",
                                    "variable_type": "dict",
                                    "variable_shape": "1"
                                },
                                "prop": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "value.items": {
                                    "variable_value": "<built-in method items of dict object at 0x7f15bd0c6a00>",
                                    "variable_type": "builtin_function_or_method",
                                    "variable_shape": null
                                },
                                "name": {
                                    "variable_value": "'--conf'",
                                    "variable_type": "str",
                                    "variable_shape": "6"
                                }
                            },
                            {
                                "command": {
                                    "variable_value": "['--conf', 'Prop=Value']",
                                    "variable_type": "list",
                                    "variable_shape": "2"
                                },
                                "value": {
                                    "variable_value": "'Value'",
                                    "variable_type": "str",
                                    "variable_shape": "5"
                                },
                                "prop": {
                                    "variable_value": "'Prop'",
                                    "variable_type": "str",
                                    "variable_shape": "4"
                                },
                                "value.items": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "name": {
                                    "variable_value": "'--conf'",
                                    "variable_type": "str",
                                    "variable_shape": "6"
                                }
                            }
                        ],
                        [
                            {
                                "command": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "value": {
                                    "variable_value": "{'prop1': 'val1'}",
                                    "variable_type": "dict",
                                    "variable_shape": "1"
                                },
                                "prop": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "value.items": {
                                    "variable_value": "<built-in method items of dict object at 0x7f15bcfa2200>",
                                    "variable_type": "builtin_function_or_method",
                                    "variable_shape": null
                                },
                                "name": {
                                    "variable_value": "'--conf'",
                                    "variable_type": "str",
                                    "variable_shape": "6"
                                }
                            },
                            {
                                "command": {
                                    "variable_value": "['--conf', 'prop1=val1']",
                                    "variable_type": "list",
                                    "variable_shape": "2"
                                },
                                "value": {
                                    "variable_value": "'val1'",
                                    "variable_type": "str",
                                    "variable_shape": "4"
                                },
                                "prop": {
                                    "variable_value": "'prop1'",
                                    "variable_type": "str",
                                    "variable_shape": "5"
                                },
                                "value.items": {
                                    "variable_value": "None",
                                    "variable_type": "NoneType",
                                    "variable_shape": null
                                },
                                "name": {
                                    "variable_value": "'--conf'",
                                    "variable_type": "str",
                                    "variable_shape": "6"
                                }
                            }
                        ]
                    ]
                }
            ],
            "inscope_functions": {
                "file_scope_functions": [],
                "file_scope_classes": [
                    {
                        "class_declaration": "class SparkRunContext:",
                        "functions": [
                            {
                                "code": "def __init__(self, proc):\n    self.proc = proc",
                                "signature": "__init__(self, proc)"
                            },
                            {
                                "code": "def __enter__(self):\n    self.__old_signal = signal.getsignal(signal.SIGTERM)\n    signal.signal(signal.SIGTERM, self.kill_job)\n    return self",
                                "signature": "__enter__(self)"
                            },
                            {
                                "code": "def __exit__(self, exc_type, exc_val, exc_tb):\n    if exc_type is KeyboardInterrupt:\n        self.kill_job()\n    signal.signal(signal.SIGTERM, self.__old_signal)",
                                "signature": "__exit__(self, exc_type, exc_val, exc_tb)"
                            },
                            {
                                "code": "def kill_job(self, captured_signal=None, stack_frame=None):\n    self.proc.kill()\n    if captured_signal is not None:\n        # adding 128 gives the exit code corresponding to a signal\n        sys.exit(128 + captured_signal)",
                                "signature": "kill_job(self, captured_signal=None, stack_frame=None)"
                            }
                        ]
                    },
                    {
                        "class_declaration": "class SparkJobError:",
                        "functions": [
                            {
                                "code": "def __init__(self, message, out=None, err=None):\n    super(SparkJobError, self).__init__(message, out, err)\n    self.message = message\n    self.out = out\n    self.err = err",
                                "signature": "__init__(self, message, out=None, err=None)"
                            },
                            {
                                "code": "def __str__(self):\n    info = self.message\n    if self.out:\n        info += \"\\nSTDOUT: \" + str(self.out)\n    if self.err:\n        info += \"\\nSTDERR: \" + str(self.err)\n    return info",
                                "signature": "__str__(self)"
                            }
                        ]
                    },
                    {
                        "class_declaration": "class SparkSubmitTask:",
                        "functions": [
                            {
                                "code": "def app_options(self):\n    \"\"\"\n    Subclass this method to map your task parameters to the app's arguments\n\n    \"\"\"\n    return []",
                                "signature": "app_options(self)"
                            },
                            {
                                "code": "@property\ndef spark_submit(self):\n    return configuration.get_config().get('spark', 'spark-submit', 'spark-submit')",
                                "signature": "spark_submit(self)"
                            },
                            {
                                "code": "@property\ndef master(self):\n    return configuration.get_config().get(\"spark\", \"master\", None)",
                                "signature": "master(self)"
                            },
                            {
                                "code": "@property\ndef deploy_mode(self):\n    return configuration.get_config().get(\"spark\", \"deploy-mode\", None)",
                                "signature": "deploy_mode(self)"
                            },
                            {
                                "code": "@property\ndef jars(self):\n    return self._list_config(configuration.get_config().get(\"spark\", \"jars\", None))",
                                "signature": "jars(self)"
                            },
                            {
                                "code": "@property\ndef py_files(self):\n    return self._list_config(configuration.get_config().get(\"spark\", \"py-files\", None))",
                                "signature": "py_files(self)"
                            },
                            {
                                "code": "@property\ndef files(self):\n    return self._list_config(configuration.get_config().get(\"spark\", \"files\", None))",
                                "signature": "files(self)"
                            },
                            {
                                "code": "@property\ndef conf(self):\n    return self._dict_config(configuration.get_config().get(\"spark\", \"conf\", None))",
                                "signature": "conf(self)"
                            },
                            {
                                "code": "@property\ndef properties_file(self):\n    return configuration.get_config().get(\"spark\", \"properties-file\", None)",
                                "signature": "properties_file(self)"
                            },
                            {
                                "code": "@property\ndef driver_memory(self):\n    return configuration.get_config().get(\"spark\", \"driver-memory\", None)",
                                "signature": "driver_memory(self)"
                            },
                            {
                                "code": "@property\ndef driver_java_options(self):\n    return configuration.get_config().get(\"spark\", \"driver-java-options\", None)",
                                "signature": "driver_java_options(self)"
                            },
                            {
                                "code": "@property\ndef driver_library_path(self):\n    return configuration.get_config().get(\"spark\", \"driver-library-path\", None)",
                                "signature": "driver_library_path(self)"
                            },
                            {
                                "code": "@property\ndef driver_class_path(self):\n    return configuration.get_config().get(\"spark\", \"driver-class-path\", None)",
                                "signature": "driver_class_path(self)"
                            },
                            {
                                "code": "@property\ndef executor_memory(self):\n    return configuration.get_config().get(\"spark\", \"executor-memory\", None)",
                                "signature": "executor_memory(self)"
                            },
                            {
                                "code": "@property\ndef driver_cores(self):\n    return configuration.get_config().get(\"spark\", \"driver-cores\", None)",
                                "signature": "driver_cores(self)"
                            },
                            {
                                "code": "@property\ndef supervise(self):\n    return bool(configuration.get_config().get(\"spark\", \"supervise\", False))",
                                "signature": "supervise(self)"
                            },
                            {
                                "code": "@property\ndef total_executor_cores(self):\n    return configuration.get_config().get(\"spark\", \"total-executor-cores\", None)",
                                "signature": "total_executor_cores(self)"
                            },
                            {
                                "code": "@property\ndef executor_cores(self):\n    return configuration.get_config().get(\"spark\", \"executor-cores\", None)",
                                "signature": "executor_cores(self)"
                            },
                            {
                                "code": "@property\ndef queue(self):\n    return configuration.get_config().get(\"spark\", \"queue\", None)",
                                "signature": "queue(self)"
                            },
                            {
                                "code": "@property\ndef num_executors(self):\n    return configuration.get_config().get(\"spark\", \"num-executors\", None)",
                                "signature": "num_executors(self)"
                            },
                            {
                                "code": "@property\ndef archives(self):\n    return self._list_config(configuration.get_config().get(\"spark\", \"archives\", None))",
                                "signature": "archives(self)"
                            },
                            {
                                "code": "@property\ndef hadoop_conf_dir(self):\n    return configuration.get_config().get(\"spark\", \"hadoop-conf-dir\", None)",
                                "signature": "hadoop_conf_dir(self)"
                            },
                            {
                                "code": "def get_environment(self):\n    env = os.environ.copy()\n    hadoop_conf_dir = self.hadoop_conf_dir\n    if hadoop_conf_dir:\n        env['HADOOP_CONF_DIR'] = hadoop_conf_dir\n    return env",
                                "signature": "get_environment(self)"
                            },
                            {
                                "code": "def spark_command(self):\n    command = [self.spark_submit]\n    command += self._text_arg('--master', self.master)\n    command += self._text_arg('--deploy-mode', self.deploy_mode)\n    command += self._text_arg('--name', self.name)\n    command += self._text_arg('--class', self.entry_class)\n    command += self._list_arg('--jars', self.jars)\n    command += self._list_arg('--py-files', self.py_files)\n    command += self._list_arg('--files', self.files)\n    command += self._list_arg('--archives', self.archives)\n    command += self._dict_arg('--conf', self.conf)\n    command += self._text_arg('--properties-file', self.properties_file)\n    command += self._text_arg('--driver-memory', self.driver_memory)\n    command += self._text_arg('--driver-java-options', self.driver_java_options)\n    command += self._text_arg('--driver-library-path', self.driver_library_path)\n    command += self._text_arg('--driver-class-path', self.driver_class_path)\n    command += self._text_arg('--executor-memory', self.executor_memory)\n    command += self._text_arg('--driver-cores', self.driver_cores)\n    command += self._flag_arg('--supervise', self.supervise)\n    command += self._text_arg('--total-executor-cores', self.total_executor_cores)\n    command += self._text_arg('--executor-cores', self.executor_cores)\n    command += self._text_arg('--queue', self.queue)\n    command += self._text_arg('--num-executors', self.num_executors)\n    return command",
                                "signature": "spark_command(self)"
                            },
                            {
                                "code": "def app_command(self):\n    if not self.app:\n        raise NotImplementedError(\"subclass should define an app (.jar or .py file)\")\n    return [self.app] + self.app_options()",
                                "signature": "app_command(self)"
                            },
                            {
                                "code": "def run(self):\n    args = list(map(str, self.spark_command() + self.app_command()))\n    logger.info('Running: %s', repr(args))\n    tmp_stdout, tmp_stderr = tempfile.TemporaryFile(), tempfile.TemporaryFile()\n    proc = subprocess.Popen(args, stdout=tmp_stdout, stderr=tmp_stderr,\n                            env=self.get_environment(), close_fds=True,\n                            universal_newlines=True)\n    try:\n        with SparkRunContext(proc):\n            proc.wait()\n        tmp_stdout.seek(0)\n        stdout = \"\".join(map(lambda s: s.decode('utf-8'), tmp_stdout.readlines()))\n        logger.info(\"Spark job stdout:\\n{0}\".format(stdout))\n        if proc.returncode != 0:\n            tmp_stderr.seek(0)\n            stderr = \"\".join(map(lambda s: s.decode('utf-8'), tmp_stderr.readlines()))\n            raise SparkJobError('Spark job failed {0}'.format(repr(args)), out=stdout, err=stderr)\n    finally:\n        tmp_stderr.close()\n        tmp_stdout.close()",
                                "signature": "run(self)"
                            },
                            {
                                "code": "def _list_config(self, config):\n    if config and isinstance(config, six.string_types):\n        return list(map(lambda x: x.strip(), config.split(',')))",
                                "signature": "_list_config(self, config)"
                            },
                            {
                                "code": "def _dict_config(self, config):\n    if config and isinstance(config, six.string_types):\n        return dict(map(lambda i: i.split('='), config.split('|')))",
                                "signature": "_dict_config(self, config)"
                            },
                            {
                                "code": "def _text_arg(self, name, value):\n    if value:\n        return [name, value]\n    return []",
                                "signature": "_text_arg(self, name, value)"
                            },
                            {
                                "code": "def _list_arg(self, name, value):\n    if value and isinstance(value, (list, tuple)):\n        return [name, ','.join(value)]\n    return []",
                                "signature": "_list_arg(self, name, value)"
                            },
                            {
                                "code": "def _dict_arg(self, name, value):\n    command = []\n    if value and isinstance(value, dict):\n        for prop, value in value.items():\n            command += [name, '\"{0}={1}\"'.format(prop, value)]\n    return command",
                                "signature": "_dict_arg(self, name, value)"
                            },
                            {
                                "code": "def _flag_arg(self, name, value):\n    if value:\n        return [name]\n    return []",
                                "signature": "_flag_arg(self, name, value)"
                            }
                        ]
                    },
                    {
                        "class_declaration": "class PySparkTask:",
                        "functions": [
                            {
                                "code": "@property\ndef name(self):\n    return self.__class__.__name__",
                                "signature": "name(self)"
                            },
                            {
                                "code": "@property\ndef py_packages(self):\n    packages = configuration.get_config().get('spark', 'py-packages', None)\n    if packages:\n        return map(lambda s: s.strip(), packages.split(','))",
                                "signature": "py_packages(self)"
                            },
                            {
                                "code": "def setup(self, conf):\n    \"\"\"\n    Called by the pyspark_runner with a SparkConf instance that will be used to instantiate the SparkContext\n\n    :param conf: SparkConf\n    \"\"\"",
                                "signature": "setup(self, conf)"
                            },
                            {
                                "code": "def setup_remote(self, sc):\n    self._setup_packages(sc)",
                                "signature": "setup_remote(self, sc)"
                            },
                            {
                                "code": "def main(self, sc, *args):\n    \"\"\"\n    Called by the pyspark_runner with a SparkContext and any arguments returned by ``app_options()``\n\n    :param sc: SparkContext\n    :param args: arguments list\n    \"\"\"\n    raise NotImplementedError(\"subclass should define a main method\")",
                                "signature": "main(self, sc, *args)"
                            },
                            {
                                "code": "def app_command(self):\n    return [self.app, self.run_pickle] + self.app_options()",
                                "signature": "app_command(self)"
                            },
                            {
                                "code": "def run(self):\n    self.run_path = tempfile.mkdtemp(prefix=self.name)\n    self.run_pickle = os.path.join(self.run_path, '.'.join([self.name.replace(' ', '_'), 'pickle']))\n    with open(self.run_pickle, 'wb') as fd:\n        self._dump(fd)\n    try:\n        super(PySparkTask, self).run()\n    finally:\n        shutil.rmtree(self.run_path)",
                                "signature": "run(self)"
                            },
                            {
                                "code": "def _dump(self, fd):\n    if self.__module__ == '__main__':\n        d = pickle.dumps(self)\n        module_name = os.path.basename(sys.argv[0]).rsplit('.', 1)[0]\n        d = d.replace(b'(c__main__', \"(c\" + module_name)\n        fd.write(d)\n    else:\n        pickle.dump(self, fd)",
                                "signature": "_dump(self, fd)"
                            },
                            {
                                "code": "def _setup_packages(self, sc):\n    \"\"\"\n    This method compresses and uploads packages to the cluster\n\n    \"\"\"\n    packages = self.py_packages\n    if not packages:\n        return\n    for package in packages:\n        mod = importlib.import_module(package)\n        try:\n            mod_path = mod.__path__[0]\n        except AttributeError:\n            mod_path = mod.__file__\n        tar_path = os.path.join(self.run_path, package + '.tar.gz')\n        tar = tarfile.open(tar_path, \"w:gz\")\n        tar.add(mod_path, os.path.basename(mod_path))\n        tar.close()\n        sc.addPyFile(tar_path)",
                                "signature": "_setup_packages(self, sc)"
                            }
                        ]
                    },
                    {
                        "class_declaration": "class SparkJob:",
                        "functions": [
                            {
                                "code": "def requires_local(self):\n    \"\"\"\n    Default impl - override this method if you need any local input to be accessible in init().\n\n    \"\"\"\n    return []",
                                "signature": "requires_local(self)"
                            },
                            {
                                "code": "def requires_hadoop(self):\n    return self.requires()  # default impl",
                                "signature": "requires_hadoop(self)"
                            },
                            {
                                "code": "def input_local(self):\n    return luigi.task.getpaths(self.requires_local())",
                                "signature": "input_local(self)"
                            },
                            {
                                "code": "def input(self):\n    return luigi.task.getpaths(self.requires())",
                                "signature": "input(self)"
                            },
                            {
                                "code": "def deps(self):\n    # Overrides the default implementation\n    return luigi.task.flatten(self.requires_hadoop()) + luigi.task.flatten(self.requires_local())",
                                "signature": "deps(self)"
                            },
                            {
                                "code": "def jar(self):\n    raise NotImplementedError(\"subclass should define jar containing job_class\")",
                                "signature": "jar(self)"
                            },
                            {
                                "code": "def job_class(self):\n    raise NotImplementedError(\"subclass should define Spark job_class\")",
                                "signature": "job_class(self)"
                            },
                            {
                                "code": "def job_args(self):\n    return []",
                                "signature": "job_args(self)"
                            },
                            {
                                "code": "def output(self):\n    raise NotImplementedError(\"subclass should define HDFS output path\")",
                                "signature": "output(self)"
                            },
                            {
                                "code": "def run(self):\n    warnings.warn(\"The use of SparkJob is deprecated. Please use SparkSubmitTask or PySparkTask.\", stacklevel=2)\n    original_output_path = self.output().path\n    path_no_slash = original_output_path[:-2] if original_output_path.endswith('/*') else original_output_path\n    path_no_slash = original_output_path[:-1] if original_output_path[-1] == '/' else path_no_slash\n    tmp_output = luigi.contrib.hdfs.HdfsTarget(path_no_slash + '-luigi-tmp-%09d' % random.randrange(0, 1e10))\n\n    args = ['org.apache.spark.deploy.yarn.Client']\n    args += ['--jar', self.jar()]\n    args += ['--class', self.job_class()]\n\n    for a in self.job_args():\n        if a == self.output().path:\n            # pass temporary output path to job args\n            logger.info('Using temp path: %s for path %s', tmp_output.path, original_output_path)\n            args += ['--args', tmp_output.path]\n        else:\n            args += ['--args', str(a)]\n\n    if self.spark_workers is not None:\n        args += ['--num-workers', self.spark_workers]\n\n    if self.spark_master_memory is not None:\n        args += ['--master-memory', self.spark_master_memory]\n\n    if self.spark_worker_memory is not None:\n        args += ['--worker-memory', self.spark_worker_memory]\n\n    queue = self.queue\n    if queue is not None:\n        args += ['--queue', queue]\n\n    env = os.environ.copy()\n    env['SPARK_JAR'] = configuration.get_config().get('spark', 'spark-jar')\n    env['HADOOP_CONF_DIR'] = configuration.get_config().get('spark', 'hadoop-conf-dir')\n    env['MASTER'] = 'yarn-client'\n    spark_class = configuration.get_config().get('spark', 'spark-class')\n\n    temp_stderr = tempfile.TemporaryFile()\n    logger.info('Running: %s %s', spark_class, ' '.join(args))\n    proc = subprocess.Popen([spark_class] + args, stdout=subprocess.PIPE,\n                            stderr=temp_stderr, env=env, close_fds=True)\n\n    return_code, final_state, app_id = self.track_progress(proc)\n    if return_code == 0 and final_state != 'FAILED':\n        tmp_output.move(path_no_slash)\n    elif final_state == 'FAILED':\n        raise SparkJobError('Spark job failed: see yarn logs for %s' % app_id)\n    else:\n        temp_stderr.seek(0)\n        errors = \"\".join((x.decode('utf8') for x in temp_stderr.readlines()))\n        logger.error(errors)\n        raise SparkJobError('Spark job failed', err=errors)",
                                "signature": "run(self)"
                            },
                            {
                                "code": "def track_progress(self, proc):\n    # The Spark client currently outputs a multiline status to stdout every second\n    # while the application is running.  This instead captures status data and updates\n    # a single line of output until the application finishes.\n    app_id = None\n    app_status = 'N/A'\n    url = 'N/A'\n    final_state = None\n    start = time.time()\n    with SparkRunContext(proc) as context:\n        while proc.poll() is None:\n            s = proc.stdout.readline().decode('utf8')\n            app_id_s = re.compile('application identifier: (\\w+)').search(s)\n            if app_id_s:\n                app_id = app_id_s.group(1)\n                context.app_id = app_id\n            app_status_s = re.compile('yarnAppState: (\\w+)').search(s)\n            if app_status_s:\n                app_status = app_status_s.group(1)\n            url_s = re.compile('appTrackingUrl: (.+)').search(s)\n            if url_s:\n                url = url_s.group(1)\n            final_state_s = re.compile('distributedFinalState: (\\w+)').search(s)\n            if final_state_s:\n                final_state = final_state_s.group(1)\n            if not app_id:\n                logger.info(s.strip())\n            else:\n                elapsed_mins, elapsed_secs = divmod(datetime.timedelta(seconds=time.time() - start).seconds, 60)\n                status = '[%0d:%02d] Status: %s Tracking: %s' % (elapsed_mins, elapsed_secs, app_status, url)\n                sys.stdout.write(\"\\r\\x1b[K\" + status)\n                sys.stdout.flush()\n    logger.info(proc.communicate()[0])\n    return proc.returncode, final_state, app_id",
                                "signature": "track_progress(self, proc)"
                            }
                        ]
                    },
                    {
                        "class_declaration": "class Spark1xBackwardCompat:",
                        "functions": [
                            {
                                "code": "@property\ndef master(self):\n    return configuration.get_config().get(\"spark\", \"master\", \"yarn-client\")",
                                "signature": "master(self)"
                            },
                            {
                                "code": "def output(self):\n    raise NotImplementedError(\"subclass should define an output target\")",
                                "signature": "output(self)"
                            },
                            {
                                "code": "def spark_options(self):\n    return []",
                                "signature": "spark_options(self)"
                            },
                            {
                                "code": "def dependency_jars(self):\n    return []",
                                "signature": "dependency_jars(self)"
                            },
                            {
                                "code": "def job_args(self):\n    return []",
                                "signature": "job_args(self)"
                            },
                            {
                                "code": "@property\ndef jars(self):\n    return self.dependency_jars()",
                                "signature": "jars(self)"
                            },
                            {
                                "code": "def app_options(self):\n    return self.job_args()",
                                "signature": "app_options(self)"
                            },
                            {
                                "code": "def spark_command(self):\n    return super(Spark1xBackwardCompat, self).spark_command() + self.spark_options()",
                                "signature": "spark_command(self)"
                            }
                        ]
                    },
                    {
                        "class_declaration": "class Spark1xJob:",
                        "functions": [
                            {
                                "code": "def job_class(self):\n    raise NotImplementedError(\"subclass should define Spark job_class\")",
                                "signature": "job_class(self)"
                            },
                            {
                                "code": "def jar(self):\n    raise NotImplementedError(\"subclass should define jar containing job_class\")",
                                "signature": "jar(self)"
                            },
                            {
                                "code": "@property\ndef entry_class(self):\n    return self.job_class()",
                                "signature": "entry_class(self)"
                            },
                            {
                                "code": "@property\ndef app(self):\n    return self.jar()",
                                "signature": "app(self)"
                            },
                            {
                                "code": "def run(self):\n    warnings.warn(\"The use of Spark1xJob is deprecated. Please use SparkSubmitTask or PySparkTask.\", stacklevel=2)\n    return super(Spark1xJob, self).run()",
                                "signature": "run(self)"
                            }
                        ]
                    },
                    {
                        "class_declaration": "class PySpark1xJob:",
                        "functions": [
                            {
                                "code": "def program(self):\n    raise NotImplementedError(\"subclass should define Spark .py file\")",
                                "signature": "program(self)"
                            },
                            {
                                "code": "@property\ndef app(self):\n    return self.program()",
                                "signature": "app(self)"
                            },
                            {
                                "code": "def run(self):\n    warnings.warn(\"The use of PySpark1xJob is deprecated. Please use SparkSubmitTask or PySparkTask.\", stacklevel=2)\n    return super(PySpark1xJob, self).run()",
                                "signature": "run(self)"
                            }
                        ]
                    }
                ]
            },
            "variables_in_file": {
                "ImportError": [
                    33
                ],
                "logger": [
                    452,
                    231,
                    43,
                    427,
                    493,
                    464,
                    241,
                    499
                ],
                "logging.getLogger": [
                    43
                ],
                "logging": [
                    43
                ],
                "object": [
                    46
                ],
                "self.proc": [
                    49,
                    62
                ],
                "self": [
                    528,
                    531,
                    534,
                    553,
                    557,
                    49,
                    561,
                    52,
                    53,
                    54,
                    58,
                    59,
                    62,
                    579,
                    71,
                    72,
                    73,
                    74,
                    583,
                    77,
                    78,
                    79,
                    80,
                    81,
                    122,
                    126,
                    130,
                    134,
                    186,
                    194,
                    200,
                    201,
                    202,
                    203,
                    204,
                    205,
                    206,
                    207,
                    208,
                    209,
                    210,
                    211,
                    212,
                    213,
                    214,
                    215,
                    216,
                    217,
                    218,
                    219,
                    220,
                    221,
                    225,
                    227,
                    230,
                    234,
                    299,
                    315,
                    327,
                    330,
                    331,
                    332,
                    333,
                    335,
                    337,
                    340,
                    341,
                    346,
                    353,
                    362,
                    389,
                    392,
                    395,
                    399,
                    415,
                    421,
                    422,
                    424,
                    425,
                    432,
                    433,
                    435,
                    436,
                    438,
                    439,
                    441,
                    456
                ],
                "proc": [
                    453,
                    456,
                    233,
                    237,
                    238,
                    49,
                    242,
                    499,
                    500,
                    476,
                    477,
                    478
                ],
                "self.__old_signal": [
                    59,
                    52
                ],
                "signal.getsignal": [
                    52
                ],
                "signal": [
                    59,
                    52,
                    53
                ],
                "signal.SIGTERM": [
                    59,
                    52,
                    53
                ],
                "signal.signal": [
                    59,
                    53
                ],
                "self.kill_job": [
                    58,
                    53
                ],
                "exc_type": [
                    57
                ],
                "KeyboardInterrupt": [
                    57
                ],
                "self.proc.kill": [
                    62
                ],
                "captured_signal": [
                    65,
                    63
                ],
                "sys.exit": [
                    65
                ],
                "sys": [
                    65,
                    498,
                    497,
                    342
                ],
                "RuntimeError": [
                    68
                ],
                "__init__": [
                    71
                ],
                "super": [
                    583,
                    71,
                    335,
                    561,
                    534
                ],
                "SparkJobError": [
                    465,
                    460,
                    245,
                    71
                ],
                "message": [
                    72,
                    71
                ],
                "out": [
                    73,
                    71
                ],
                "err": [
                    74,
                    71
                ],
                "self.message": [
                    72,
                    77
                ],
                "self.out": [
                    73,
                    78,
                    79
                ],
                "self.err": [
                    80,
                    81,
                    74
                ],
                "info": [
                    81,
                    82,
                    77,
                    79
                ],
                "str": [
                    81,
                    430,
                    230,
                    79
                ],
                "luigi.Task": [
                    369,
                    85
                ],
                "luigi": [
                    418,
                    392,
                    395,
                    399,
                    369,
                    85,
                    378
                ],
                "name": [
                    97,
                    260,
                    265,
                    272,
                    277
                ],
                "entry_class": [
                    98
                ],
                "app": [
                    99,
                    293
                ],
                "get": [
                    130,
                    134,
                    138,
                    142,
                    146,
                    150,
                    154,
                    158,
                    162,
                    166,
                    170,
                    174,
                    303,
                    178,
                    182,
                    186,
                    190,
                    446,
                    447,
                    449,
                    110,
                    114,
                    118,
                    122,
                    126,
                    511
                ],
                "configuration.get_config": [
                    130,
                    134,
                    138,
                    142,
                    146,
                    150,
                    154,
                    158,
                    162,
                    166,
                    170,
                    174,
                    303,
                    178,
                    182,
                    186,
                    190,
                    446,
                    447,
                    449,
                    110,
                    114,
                    118,
                    122,
                    126,
                    511
                ],
                "configuration": [
                    130,
                    134,
                    138,
                    142,
                    146,
                    150,
                    154,
                    158,
                    162,
                    166,
                    170,
                    174,
                    303,
                    178,
                    182,
                    186,
                    190,
                    446,
                    447,
                    449,
                    110,
                    114,
                    118,
                    122,
                    126,
                    511
                ],
                "property": [
                    128,
                    132,
                    136,
                    140,
                    526,
                    144,
                    148,
                    152,
                    156,
                    160,
                    164,
                    551,
                    168,
                    297,
                    555,
                    172,
                    301,
                    176,
                    180,
                    184,
                    188,
                    577,
                    108,
                    112,
                    116,
                    120,
                    124,
                    509
                ],
                "self._list_config": [
                    186,
                    122,
                    126,
                    130
                ],
                "self._dict_config": [
                    134
                ],
                "bool": [
                    166
                ],
                "env": [
                    448,
                    193,
                    196,
                    197,
                    454,
                    445,
                    446,
                    447
                ],
                "os.environ.copy": [
                    193,
                    445
                ],
                "os.environ": [
                    193,
                    445
                ],
                "os": [
                    193,
                    293,
                    362,
                    331,
                    364,
                    342,
                    445
                ],
                "hadoop_conf_dir": [
                    194,
                    195,
                    196
                ],
                "self.hadoop_conf_dir": [
                    194
                ],
                "command": [
                    269,
                    272,
                    273,
                    200,
                    201,
                    202,
                    203,
                    204,
                    205,
                    206,
                    207,
                    208,
                    209,
                    210,
                    211,
                    212,
                    213,
                    214,
                    215,
                    216,
                    217,
                    218,
                    219,
                    220,
                    221,
                    222
                ],
                "self.spark_submit": [
                    200
                ],
                "self._text_arg": [
                    201,
                    202,
                    203,
                    204,
                    210,
                    211,
                    212,
                    213,
                    214,
                    215,
                    216,
                    218,
                    219,
                    220,
                    221
                ],
                "self.master": [
                    201
                ],
                "self.deploy_mode": [
                    202
                ],
                "self.name": [
                    331,
                    330,
                    203
                ],
                "self.entry_class": [
                    204
                ],
                "self._list_arg": [
                    208,
                    205,
                    206,
                    207
                ],
                "self.jars": [
                    205
                ],
                "self.py_files": [
                    206
                ],
                "self.files": [
                    207
                ],
                "self.archives": [
                    208
                ],
                "self._dict_arg": [
                    209
                ],
                "self.conf": [
                    209
                ],
                "self.properties_file": [
                    210
                ],
                "self.driver_memory": [
                    211
                ],
                "self.driver_java_options": [
                    212
                ],
                "self.driver_library_path": [
                    213
                ],
                "self.driver_class_path": [
                    214
                ],
                "self.executor_memory": [
                    215
                ],
                "self.driver_cores": [
                    216
                ],
                "self._flag_arg": [
                    217
                ],
                "self.supervise": [
                    217
                ],
                "self.total_executor_cores": [
                    218
                ],
                "self.executor_cores": [
                    219
                ],
                "self.queue": [
                    441,
                    220
                ],
                "self.num_executors": [
                    221
                ],
                "self.app": [
                    225,
                    227,
                    327
                ],
                "NotImplementedError": [
                    545,
                    226,
                    514,
                    324,
                    548,
                    402,
                    405,
                    411,
                    574
                ],
                "self.app_options": [
                    227,
                    327
                ],
                "args": [
                    420,
                    421,
                    230,
                    231,
                    422,
                    233,
                    452,
                    453,
                    428,
                    430,
                    433,
                    436,
                    245,
                    439,
                    443
                ],
                "list": [
                    264,
                    252,
                    230
                ],
                "map": [
                    256,
                    230,
                    240,
                    305,
                    244,
                    252
                ],
                "self.spark_command": [
                    230
                ],
                "self.app_command": [
                    230
                ],
                "logger.info": [
                    452,
                    231,
                    427,
                    493,
                    241,
                    499
                ],
                "repr": [
                    245,
                    231
                ],
                "tmp_stdout": [
                    232,
                    233,
                    239,
                    240,
                    248
                ],
                "tmp_stderr": [
                    232,
                    233,
                    243,
                    244,
                    247
                ],
                "tempfile.TemporaryFile": [
                    232,
                    451
                ],
                "tempfile": [
                    232,
                    330,
                    451
                ],
                "subprocess.Popen": [
                    233,
                    453
                ],
                "subprocess": [
                    233,
                    453
                ],
                "self.get_environment": [
                    234
                ],
                "SparkRunContext": [
                    476,
                    237
                ],
                "proc.wait": [
                    238
                ],
                "tmp_stdout.seek": [
                    239
                ],
                "stdout": [
                    240,
                    241,
                    245
                ],
                "join": [
                    452,
                    265,
                    331,
                    463,
                    240,
                    244
                ],
                "s.decode": [
                    240,
                    244
                ],
                "s": [
                    483,
                    486,
                    489,
                    493,
                    240,
                    305,
                    244,
                    478,
                    479
                ],
                "tmp_stdout.readlines": [
                    240
                ],
                "format": [
                    272,
                    241,
                    245
                ],
                "proc.returncode": [
                    242,
                    500
                ],
                "tmp_stderr.seek": [
                    243
                ],
                "stderr": [
                    244,
                    245
                ],
                "tmp_stderr.readlines": [
                    244
                ],
                "tmp_stderr.close": [
                    247
                ],
                "tmp_stdout.close": [
                    248
                ],
                "config": [
                    256,
                    251,
                    252,
                    255
                ],
                "isinstance": [
                    264,
                    251,
                    270,
                    255
                ],
                "six.string_types": [
                    251,
                    255
                ],
                "six": [
                    251,
                    255
                ],
                "x.strip": [
                    252
                ],
                "x": [
                    252,
                    463
                ],
                "config.split": [
                    256,
                    252
                ],
                "dict": [
                    256,
                    270
                ],
                "i.split": [
                    256
                ],
                "i": [
                    256
                ],
                "value": [
                    259,
                    260,
                    264,
                    265,
                    270,
                    271,
                    272,
                    276
                ],
                "tuple": [
                    264
                ],
                "prop": [
                    272,
                    271
                ],
                "value.items": [
                    271
                ],
                "SparkSubmitTask": [
                    281,
                    503
                ],
                "os.path.join": [
                    362,
                    331,
                    293
                ],
                "os.path": [
                    293,
                    362,
                    331,
                    364,
                    342
                ],
                "os.path.dirname": [
                    293
                ],
                "__file__": [
                    293
                ],
                "deploy_mode": [
                    295
                ],
                "self.__class__.__name__": [
                    299
                ],
                "self.__class__": [
                    299
                ],
                "packages": [
                    353,
                    354,
                    356,
                    303,
                    304,
                    305
                ],
                "s.strip": [
                    305,
                    493
                ],
                "packages.split": [
                    305
                ],
                "self._setup_packages": [
                    315
                ],
                "sc": [
                    315,
                    366
                ],
                "self.run_pickle": [
                    331,
                    332,
                    327
                ],
                "self.run_path": [
                    337,
                    330,
                    331,
                    362
                ],
                "tempfile.mkdtemp": [
                    330
                ],
                "self.name.replace": [
                    331
                ],
                "open": [
                    332
                ],
                "fd": [
                    344,
                    346,
                    332,
                    333
                ],
                "self._dump": [
                    333
                ],
                "run": [
                    561,
                    583,
                    335
                ],
                "PySparkTask": [
                    335
                ],
                "shutil.rmtree": [
                    337
                ],
                "shutil": [
                    337
                ],
                "self.__module__": [
                    340
                ],
                "d": [
                    344,
                    341,
                    343
                ],
                "pickle.dumps": [
                    341
                ],
                "pickle": [
                    346,
                    341
                ],
                "module_name": [
                    342,
                    343
                ],
                "rsplit": [
                    342
                ],
                "os.path.basename": [
                    364,
                    342
                ],
                "sys.argv": [
                    342
                ],
                "d.replace": [
                    343
                ],
                "fd.write": [
                    344
                ],
                "pickle.dump": [
                    346
                ],
                "self.py_packages": [
                    353
                ],
                "package": [
                    362,
                    356,
                    357
                ],
                "mod": [
                    361,
                    357,
                    359
                ],
                "importlib.import_module": [
                    357
                ],
                "importlib": [
                    357
                ],
                "mod_path": [
                    361,
                    364,
                    359
                ],
                "mod.__path__": [
                    359
                ],
                "AttributeError": [
                    360
                ],
                "mod.__file__": [
                    361
                ],
                "tar_path": [
                    362,
                    363,
                    366
                ],
                "tar": [
                    363,
                    364,
                    365
                ],
                "tarfile.open": [
                    363
                ],
                "tarfile": [
                    363
                ],
                "tar.add": [
                    364
                ],
                "tar.close": [
                    365
                ],
                "sc.addPyFile": [
                    366
                ],
                "spark_workers": [
                    375
                ],
                "spark_master_memory": [
                    376
                ],
                "spark_worker_memory": [
                    377
                ],
                "queue": [
                    442,
                    441,
                    378,
                    443
                ],
                "luigi.Parameter": [
                    378
                ],
                "temp_hadoop_output_file": [
                    379
                ],
                "self.requires": [
                    395,
                    389
                ],
                "luigi.task.getpaths": [
                    392,
                    395
                ],
                "luigi.task": [
                    392,
                    395,
                    399
                ],
                "self.requires_local": [
                    392,
                    399
                ],
                "luigi.task.flatten": [
                    399
                ],
                "self.requires_hadoop": [
                    399
                ],
                "warnings.warn": [
                    560,
                    582,
                    414
                ],
                "warnings": [
                    560,
                    582,
                    414
                ],
                "original_output_path": [
                    416,
                    417,
                    427,
                    415
                ],
                "path": [
                    425,
                    415
                ],
                "self.output": [
                    425,
                    415
                ],
                "path_no_slash": [
                    416,
                    417,
                    418,
                    458
                ],
                "original_output_path.endswith": [
                    416
                ],
                "tmp_output": [
                    458,
                    418,
                    427,
                    428
                ],
                "luigi.contrib.hdfs.HdfsTarget": [
                    418
                ],
                "luigi.contrib.hdfs": [
                    418
                ],
                "luigi.contrib": [
                    418
                ],
                "random.randrange": [
                    418
                ],
                "random": [
                    418
                ],
                "self.jar": [
                    557,
                    421
                ],
                "self.job_class": [
                    553,
                    422
                ],
                "a": [
                    424,
                    425,
                    430
                ],
                "self.job_args": [
                    424,
                    531
                ],
                "tmp_output.path": [
                    427,
                    428
                ],
                "self.spark_workers": [
                    432,
                    433
                ],
                "self.spark_master_memory": [
                    435,
                    436
                ],
                "self.spark_worker_memory": [
                    438,
                    439
                ],
                "spark_class": [
                    449,
                    452,
                    453
                ],
                "temp_stderr": [
                    451,
                    462,
                    454,
                    463
                ],
                "subprocess.PIPE": [
                    453
                ],
                "return_code": [
                    456,
                    457
                ],
                "final_state": [
                    456,
                    457,
                    459,
                    491,
                    500,
                    474
                ],
                "app_id": [
                    481,
                    482,
                    456,
                    460,
                    492,
                    500,
                    471
                ],
                "self.track_progress": [
                    456
                ],
                "tmp_output.move": [
                    458
                ],
                "temp_stderr.seek": [
                    462
                ],
                "errors": [
                    464,
                    465,
                    463
                ],
                "x.decode": [
                    463
                ],
                "temp_stderr.readlines": [
                    463
                ],
                "logger.error": [
                    464
                ],
                "app_status": [
                    472,
                    496,
                    485
                ],
                "url": [
                    488,
                    473,
                    496
                ],
                "start": [
                    475,
                    495
                ],
                "time.time": [
                    475,
                    495
                ],
                "time": [
                    475,
                    495
                ],
                "context": [
                    482,
                    476
                ],
                "proc.poll": [
                    477
                ],
                "decode": [
                    478
                ],
                "proc.stdout.readline": [
                    478
                ],
                "proc.stdout": [
                    478
                ],
                "app_id_s": [
                    480,
                    481,
                    479
                ],
                "search": [
                    489,
                    483,
                    486,
                    479
                ],
                "re.compile": [
                    489,
                    483,
                    486,
                    479
                ],
                "re": [
                    489,
                    483,
                    486,
                    479
                ],
                "app_id_s.group": [
                    481
                ],
                "context.app_id": [
                    482
                ],
                "app_status_s": [
                    483,
                    484,
                    485
                ],
                "app_status_s.group": [
                    485
                ],
                "url_s": [
                    488,
                    486,
                    487
                ],
                "url_s.group": [
                    488
                ],
                "final_state_s": [
                    489,
                    490,
                    491
                ],
                "final_state_s.group": [
                    491
                ],
                "elapsed_mins": [
                    496,
                    495
                ],
                "elapsed_secs": [
                    496,
                    495
                ],
                "divmod": [
                    495
                ],
                "seconds": [
                    495
                ],
                "datetime.timedelta": [
                    495
                ],
                "datetime": [
                    495
                ],
                "status": [
                    496,
                    497
                ],
                "sys.stdout.write": [
                    497
                ],
                "sys.stdout": [
                    497,
                    498
                ],
                "sys.stdout.flush": [
                    498
                ],
                "proc.communicate": [
                    499
                ],
                "self.dependency_jars": [
                    528
                ],
                "spark_command": [
                    534
                ],
                "Spark1xBackwardCompat": [
                    537,
                    564,
                    534
                ],
                "self.spark_options": [
                    534
                ],
                "Spark1xJob": [
                    561
                ],
                "self.program": [
                    579
                ],
                "PySpark1xJob": [
                    583
                ]
            },
            "filtered_variables_in_file": {
                "logger": [
                    452,
                    231,
                    43,
                    427,
                    493,
                    464,
                    241,
                    499
                ],
                "logging.getLogger": [
                    43
                ],
                "logging": [
                    43
                ],
                "self.proc": [
                    49,
                    62
                ],
                "self": [
                    528,
                    531,
                    534,
                    553,
                    557,
                    49,
                    561,
                    52,
                    53,
                    54,
                    58,
                    59,
                    62,
                    579,
                    71,
                    72,
                    73,
                    74,
                    583,
                    77,
                    78,
                    79,
                    80,
                    81,
                    122,
                    126,
                    130,
                    134,
                    186,
                    194,
                    200,
                    201,
                    202,
                    203,
                    204,
                    205,
                    206,
                    207,
                    208,
                    209,
                    210,
                    211,
                    212,
                    213,
                    214,
                    215,
                    216,
                    217,
                    218,
                    219,
                    220,
                    221,
                    225,
                    227,
                    230,
                    234,
                    299,
                    315,
                    327,
                    330,
                    331,
                    332,
                    333,
                    335,
                    337,
                    340,
                    341,
                    346,
                    353,
                    362,
                    389,
                    392,
                    395,
                    399,
                    415,
                    421,
                    422,
                    424,
                    425,
                    432,
                    433,
                    435,
                    436,
                    438,
                    439,
                    441,
                    456
                ],
                "proc": [
                    453,
                    456,
                    233,
                    237,
                    238,
                    49,
                    242,
                    499,
                    500,
                    476,
                    477,
                    478
                ],
                "self.__old_signal": [
                    59,
                    52
                ],
                "signal.getsignal": [
                    52
                ],
                "signal": [
                    59,
                    52,
                    53
                ],
                "signal.SIGTERM": [
                    59,
                    52,
                    53
                ],
                "signal.signal": [
                    59,
                    53
                ],
                "self.kill_job": [
                    58,
                    53
                ],
                "exc_type": [
                    57
                ],
                "self.proc.kill": [
                    62
                ],
                "captured_signal": [
                    65,
                    63
                ],
                "sys.exit": [
                    65
                ],
                "sys": [
                    65,
                    498,
                    497,
                    342
                ],
                "__init__": [
                    71
                ],
                "SparkJobError": [
                    465,
                    460,
                    245,
                    71
                ],
                "message": [
                    72,
                    71
                ],
                "out": [
                    73,
                    71
                ],
                "err": [
                    74,
                    71
                ],
                "self.message": [
                    72,
                    77
                ],
                "self.out": [
                    73,
                    78,
                    79
                ],
                "self.err": [
                    80,
                    81,
                    74
                ],
                "info": [
                    81,
                    82,
                    77,
                    79
                ],
                "luigi.Task": [
                    369,
                    85
                ],
                "luigi": [
                    418,
                    392,
                    395,
                    399,
                    369,
                    85,
                    378
                ],
                "name": [
                    97,
                    260,
                    265,
                    272,
                    277
                ],
                "entry_class": [
                    98
                ],
                "app": [
                    99,
                    293
                ],
                "get": [
                    130,
                    134,
                    138,
                    142,
                    146,
                    150,
                    154,
                    158,
                    162,
                    166,
                    170,
                    174,
                    303,
                    178,
                    182,
                    186,
                    190,
                    446,
                    447,
                    449,
                    110,
                    114,
                    118,
                    122,
                    126,
                    511
                ],
                "configuration.get_config": [
                    130,
                    134,
                    138,
                    142,
                    146,
                    150,
                    154,
                    158,
                    162,
                    166,
                    170,
                    174,
                    303,
                    178,
                    182,
                    186,
                    190,
                    446,
                    447,
                    449,
                    110,
                    114,
                    118,
                    122,
                    126,
                    511
                ],
                "configuration": [
                    130,
                    134,
                    138,
                    142,
                    146,
                    150,
                    154,
                    158,
                    162,
                    166,
                    170,
                    174,
                    303,
                    178,
                    182,
                    186,
                    190,
                    446,
                    447,
                    449,
                    110,
                    114,
                    118,
                    122,
                    126,
                    511
                ],
                "self._list_config": [
                    186,
                    122,
                    126,
                    130
                ],
                "self._dict_config": [
                    134
                ],
                "env": [
                    448,
                    193,
                    196,
                    197,
                    454,
                    445,
                    446,
                    447
                ],
                "os.environ.copy": [
                    193,
                    445
                ],
                "os.environ": [
                    193,
                    445
                ],
                "os": [
                    193,
                    293,
                    362,
                    331,
                    364,
                    342,
                    445
                ],
                "hadoop_conf_dir": [
                    194,
                    195,
                    196
                ],
                "self.hadoop_conf_dir": [
                    194
                ],
                "command": [
                    269,
                    272,
                    273,
                    200,
                    201,
                    202,
                    203,
                    204,
                    205,
                    206,
                    207,
                    208,
                    209,
                    210,
                    211,
                    212,
                    213,
                    214,
                    215,
                    216,
                    217,
                    218,
                    219,
                    220,
                    221,
                    222
                ],
                "self.spark_submit": [
                    200
                ],
                "self._text_arg": [
                    201,
                    202,
                    203,
                    204,
                    210,
                    211,
                    212,
                    213,
                    214,
                    215,
                    216,
                    218,
                    219,
                    220,
                    221
                ],
                "self.master": [
                    201
                ],
                "self.deploy_mode": [
                    202
                ],
                "self.name": [
                    331,
                    330,
                    203
                ],
                "self.entry_class": [
                    204
                ],
                "self._list_arg": [
                    208,
                    205,
                    206,
                    207
                ],
                "self.jars": [
                    205
                ],
                "self.py_files": [
                    206
                ],
                "self.files": [
                    207
                ],
                "self.archives": [
                    208
                ],
                "self._dict_arg": [
                    209
                ],
                "self.conf": [
                    209
                ],
                "self.properties_file": [
                    210
                ],
                "self.driver_memory": [
                    211
                ],
                "self.driver_java_options": [
                    212
                ],
                "self.driver_library_path": [
                    213
                ],
                "self.driver_class_path": [
                    214
                ],
                "self.executor_memory": [
                    215
                ],
                "self.driver_cores": [
                    216
                ],
                "self._flag_arg": [
                    217
                ],
                "self.supervise": [
                    217
                ],
                "self.total_executor_cores": [
                    218
                ],
                "self.executor_cores": [
                    219
                ],
                "self.queue": [
                    441,
                    220
                ],
                "self.num_executors": [
                    221
                ],
                "self.app": [
                    225,
                    227,
                    327
                ],
                "self.app_options": [
                    227,
                    327
                ],
                "args": [
                    420,
                    421,
                    230,
                    231,
                    422,
                    233,
                    452,
                    453,
                    428,
                    430,
                    433,
                    436,
                    245,
                    439,
                    443
                ],
                "self.spark_command": [
                    230
                ],
                "self.app_command": [
                    230
                ],
                "logger.info": [
                    452,
                    231,
                    427,
                    493,
                    241,
                    499
                ],
                "tmp_stdout": [
                    232,
                    233,
                    239,
                    240,
                    248
                ],
                "tmp_stderr": [
                    232,
                    233,
                    243,
                    244,
                    247
                ],
                "tempfile.TemporaryFile": [
                    232,
                    451
                ],
                "tempfile": [
                    232,
                    330,
                    451
                ],
                "subprocess.Popen": [
                    233,
                    453
                ],
                "subprocess": [
                    233,
                    453
                ],
                "self.get_environment": [
                    234
                ],
                "SparkRunContext": [
                    476,
                    237
                ],
                "proc.wait": [
                    238
                ],
                "tmp_stdout.seek": [
                    239
                ],
                "stdout": [
                    240,
                    241,
                    245
                ],
                "join": [
                    452,
                    265,
                    331,
                    463,
                    240,
                    244
                ],
                "s.decode": [
                    240,
                    244
                ],
                "s": [
                    483,
                    486,
                    489,
                    493,
                    240,
                    305,
                    244,
                    478,
                    479
                ],
                "tmp_stdout.readlines": [
                    240
                ],
                "proc.returncode": [
                    242,
                    500
                ],
                "tmp_stderr.seek": [
                    243
                ],
                "stderr": [
                    244,
                    245
                ],
                "tmp_stderr.readlines": [
                    244
                ],
                "tmp_stderr.close": [
                    247
                ],
                "tmp_stdout.close": [
                    248
                ],
                "config": [
                    256,
                    251,
                    252,
                    255
                ],
                "six.string_types": [
                    251,
                    255
                ],
                "six": [
                    251,
                    255
                ],
                "x.strip": [
                    252
                ],
                "x": [
                    252,
                    463
                ],
                "config.split": [
                    256,
                    252
                ],
                "i.split": [
                    256
                ],
                "i": [
                    256
                ],
                "value": [
                    259,
                    260,
                    264,
                    265,
                    270,
                    271,
                    272,
                    276
                ],
                "prop": [
                    272,
                    271
                ],
                "value.items": [
                    271
                ],
                "SparkSubmitTask": [
                    281,
                    503
                ],
                "os.path.join": [
                    362,
                    331,
                    293
                ],
                "os.path": [
                    293,
                    362,
                    331,
                    364,
                    342
                ],
                "os.path.dirname": [
                    293
                ],
                "__file__": [
                    293
                ],
                "deploy_mode": [
                    295
                ],
                "self.__class__.__name__": [
                    299
                ],
                "self.__class__": [
                    299
                ],
                "packages": [
                    353,
                    354,
                    356,
                    303,
                    304,
                    305
                ],
                "s.strip": [
                    305,
                    493
                ],
                "packages.split": [
                    305
                ],
                "self._setup_packages": [
                    315
                ],
                "sc": [
                    315,
                    366
                ],
                "self.run_pickle": [
                    331,
                    332,
                    327
                ],
                "self.run_path": [
                    337,
                    330,
                    331,
                    362
                ],
                "tempfile.mkdtemp": [
                    330
                ],
                "self.name.replace": [
                    331
                ],
                "fd": [
                    344,
                    346,
                    332,
                    333
                ],
                "self._dump": [
                    333
                ],
                "run": [
                    561,
                    583,
                    335
                ],
                "PySparkTask": [
                    335
                ],
                "shutil.rmtree": [
                    337
                ],
                "shutil": [
                    337
                ],
                "self.__module__": [
                    340
                ],
                "d": [
                    344,
                    341,
                    343
                ],
                "pickle.dumps": [
                    341
                ],
                "pickle": [
                    346,
                    341
                ],
                "module_name": [
                    342,
                    343
                ],
                "rsplit": [
                    342
                ],
                "os.path.basename": [
                    364,
                    342
                ],
                "sys.argv": [
                    342
                ],
                "d.replace": [
                    343
                ],
                "fd.write": [
                    344
                ],
                "pickle.dump": [
                    346
                ],
                "self.py_packages": [
                    353
                ],
                "package": [
                    362,
                    356,
                    357
                ],
                "mod": [
                    361,
                    357,
                    359
                ],
                "importlib.import_module": [
                    357
                ],
                "importlib": [
                    357
                ],
                "mod_path": [
                    361,
                    364,
                    359
                ],
                "mod.__path__": [
                    359
                ],
                "mod.__file__": [
                    361
                ],
                "tar_path": [
                    362,
                    363,
                    366
                ],
                "tar": [
                    363,
                    364,
                    365
                ],
                "tarfile.open": [
                    363
                ],
                "tarfile": [
                    363
                ],
                "tar.add": [
                    364
                ],
                "tar.close": [
                    365
                ],
                "sc.addPyFile": [
                    366
                ],
                "spark_workers": [
                    375
                ],
                "spark_master_memory": [
                    376
                ],
                "spark_worker_memory": [
                    377
                ],
                "queue": [
                    442,
                    441,
                    378,
                    443
                ],
                "luigi.Parameter": [
                    378
                ],
                "temp_hadoop_output_file": [
                    379
                ],
                "self.requires": [
                    395,
                    389
                ],
                "luigi.task.getpaths": [
                    392,
                    395
                ],
                "luigi.task": [
                    392,
                    395,
                    399
                ],
                "self.requires_local": [
                    392,
                    399
                ],
                "luigi.task.flatten": [
                    399
                ],
                "self.requires_hadoop": [
                    399
                ],
                "warnings.warn": [
                    560,
                    582,
                    414
                ],
                "warnings": [
                    560,
                    582,
                    414
                ],
                "original_output_path": [
                    416,
                    417,
                    427,
                    415
                ],
                "path": [
                    425,
                    415
                ],
                "self.output": [
                    425,
                    415
                ],
                "path_no_slash": [
                    416,
                    417,
                    418,
                    458
                ],
                "original_output_path.endswith": [
                    416
                ],
                "tmp_output": [
                    458,
                    418,
                    427,
                    428
                ],
                "luigi.contrib.hdfs.HdfsTarget": [
                    418
                ],
                "luigi.contrib.hdfs": [
                    418
                ],
                "luigi.contrib": [
                    418
                ],
                "random.randrange": [
                    418
                ],
                "random": [
                    418
                ],
                "self.jar": [
                    557,
                    421
                ],
                "self.job_class": [
                    553,
                    422
                ],
                "a": [
                    424,
                    425,
                    430
                ],
                "self.job_args": [
                    424,
                    531
                ],
                "tmp_output.path": [
                    427,
                    428
                ],
                "self.spark_workers": [
                    432,
                    433
                ],
                "self.spark_master_memory": [
                    435,
                    436
                ],
                "self.spark_worker_memory": [
                    438,
                    439
                ],
                "spark_class": [
                    449,
                    452,
                    453
                ],
                "temp_stderr": [
                    451,
                    462,
                    454,
                    463
                ],
                "subprocess.PIPE": [
                    453
                ],
                "return_code": [
                    456,
                    457
                ],
                "final_state": [
                    456,
                    457,
                    459,
                    491,
                    500,
                    474
                ],
                "app_id": [
                    481,
                    482,
                    456,
                    460,
                    492,
                    500,
                    471
                ],
                "self.track_progress": [
                    456
                ],
                "tmp_output.move": [
                    458
                ],
                "temp_stderr.seek": [
                    462
                ],
                "errors": [
                    464,
                    465,
                    463
                ],
                "x.decode": [
                    463
                ],
                "temp_stderr.readlines": [
                    463
                ],
                "logger.error": [
                    464
                ],
                "app_status": [
                    472,
                    496,
                    485
                ],
                "url": [
                    488,
                    473,
                    496
                ],
                "start": [
                    475,
                    495
                ],
                "time.time": [
                    475,
                    495
                ],
                "time": [
                    475,
                    495
                ],
                "context": [
                    482,
                    476
                ],
                "proc.poll": [
                    477
                ],
                "decode": [
                    478
                ],
                "proc.stdout.readline": [
                    478
                ],
                "proc.stdout": [
                    478
                ],
                "app_id_s": [
                    480,
                    481,
                    479
                ],
                "search": [
                    489,
                    483,
                    486,
                    479
                ],
                "re.compile": [
                    489,
                    483,
                    486,
                    479
                ],
                "re": [
                    489,
                    483,
                    486,
                    479
                ],
                "app_id_s.group": [
                    481
                ],
                "context.app_id": [
                    482
                ],
                "app_status_s": [
                    483,
                    484,
                    485
                ],
                "app_status_s.group": [
                    485
                ],
                "url_s": [
                    488,
                    486,
                    487
                ],
                "url_s.group": [
                    488
                ],
                "final_state_s": [
                    489,
                    490,
                    491
                ],
                "final_state_s.group": [
                    491
                ],
                "elapsed_mins": [
                    496,
                    495
                ],
                "elapsed_secs": [
                    496,
                    495
                ],
                "seconds": [
                    495
                ],
                "datetime.timedelta": [
                    495
                ],
                "datetime": [
                    495
                ],
                "status": [
                    496,
                    497
                ],
                "sys.stdout.write": [
                    497
                ],
                "sys.stdout": [
                    497,
                    498
                ],
                "sys.stdout.flush": [
                    498
                ],
                "proc.communicate": [
                    499
                ],
                "self.dependency_jars": [
                    528
                ],
                "spark_command": [
                    534
                ],
                "Spark1xBackwardCompat": [
                    537,
                    564,
                    534
                ],
                "self.spark_options": [
                    534
                ],
                "Spark1xJob": [
                    561
                ],
                "self.program": [
                    579
                ],
                "PySpark1xJob": [
                    583
                ]
            }
        },
        "test_data": [
            {
                "test_path": "/home/ubuntu/Desktop/bgp_envs_local/repos/luigi_24/test/contrib/spark_test.py",
                "test_function": "test_run",
                "test_function_code": "    @with_config({'spark': {'spark-submit': ss, 'master': \"yarn-client\", 'hadoop-conf-dir': 'path'}})\n    @patch('luigi.contrib.spark.subprocess.Popen')\n    def test_run(self, proc):\n        setup_run_process(proc)\n        job = TestSparkSubmitTask()\n        job.run()\n\n        self.assertEqual(proc.call_args[0][0],\n                         ['ss-stub', '--master', 'yarn-client', '--deploy-mode', 'client', '--name', 'AppName',\n                          '--class', 'org.test.MyClass', '--jars', 'jars/my.jar', '--py-files', 'file1.py,file2.py',\n                          '--files', 'file1,file2', '--archives', 'archive1,archive2', '--conf', 'Prop=Value',\n                          '--properties-file', 'conf/spark-defaults.conf', '--driver-memory', '4G', '--driver-java-options', '-Xopt',\n                          '--driver-library-path', 'library/path', '--driver-class-path', 'class/path', '--executor-memory', '8G',\n                          '--driver-cores', '8', '--supervise', '--total-executor-cores', '150', '--executor-cores', '10',\n                          '--queue', 'queue', '--num-executors', '2', 'file', 'arg1', 'arg2'])",
                "test_error": "AssertionError: Lists differ: ['ss-[240 chars]f', '\"Prop=Value\"', '--properties-file', 'conf[346 chars]rg2'] != ['ss-[240 chars]f', 'Prop=Value', '--properties-file', 'conf/s[344 chars]rg2']  First differing element 18: '\"Prop=Value\"' 'Prop=Value'  Diff is 812 characters long. Set self.maxDiff to None to see it.",
                "full_test_error": "self = <contrib.spark_test.SparkSubmitTaskTest testMethod=test_run>\nproc = <MagicMock name='Popen' id='140503796130624'>\n\n    @with_config({'spark': {'spark-submit': ss, 'master': \"yarn-client\", 'hadoop-conf-dir': 'path'}})\n    @patch('luigi.contrib.spark.subprocess.Popen')\n    def test_run(self, proc):\n        setup_run_process(proc)\n        job = TestSparkSubmitTask()\n        job.run()\n    \n>       self.assertEqual(proc.call_args[0][0],\n                         ['ss-stub', '--master', 'yarn-client', '--deploy-mode', 'client', '--name', 'AppName',\n                          '--class', 'org.test.MyClass', '--jars', 'jars/my.jar', '--py-files', 'file1.py,file2.py',\n                          '--files', 'file1,file2', '--archives', 'archive1,archive2', '--conf', 'Prop=Value',\n                          '--properties-file', 'conf/spark-defaults.conf', '--driver-memory', '4G', '--driver-java-options', '-Xopt',\n                          '--driver-library-path', 'library/path', '--driver-class-path', 'class/path', '--executor-memory', '8G',\n                          '--driver-cores', '8', '--supervise', '--total-executor-cores', '150', '--executor-cores', '10',\n                          '--queue', 'queue', '--num-executors', '2', 'file', 'arg1', 'arg2'])\nE       AssertionError: Lists differ: ['ss-[240 chars]f', '\"Prop=Value\"', '--properties-file', 'conf[346 chars]rg2'] != ['ss-[240 chars]f', 'Prop=Value', '--properties-file', 'conf/s[344 chars]rg2']\nE       \nE       First differing element 18:\nE       '\"Prop=Value\"'\nE       'Prop=Value'\nE       \nE       Diff is 812 characters long. Set self.maxDiff to None to see it.\n\ntest/contrib/spark_test.py:149: AssertionError",
                "traceback": null,
                "test_error_location": null,
                "test_function_decorators": [
                    "with_config({'spark': {'spark-submit': ss, 'master': 'yarn-client', 'hadoop-conf-dir': 'path'}})",
                    "patch('luigi.contrib.spark.subprocess.Popen')"
                ]
            },
            {
                "test_path": "/home/ubuntu/Desktop/bgp_envs_local/repos/luigi_24/test/contrib/spark_test.py",
                "test_function": "test_defaults",
                "test_function_code": "    @with_config({'spark': {'spark-submit': ss, 'master': 'spark://host:7077', 'conf': 'prop1=val1', 'jars': 'jar1.jar,jar2.jar',\n                            'files': 'file1,file2', 'py-files': 'file1.py,file2.py', 'archives': 'archive1'}})\n    @patch('luigi.contrib.spark.subprocess.Popen')\n    def test_defaults(self, proc):\n        proc.return_value.returncode = 0\n        job = TestDefaultSparkSubmitTask()\n        job.run()\n        self.assertEqual(proc.call_args[0][0],\n                         ['ss-stub', '--master', 'spark://host:7077', '--jars', 'jar1.jar,jar2.jar',\n                          '--py-files', 'file1.py,file2.py', '--files', 'file1,file2', '--archives', 'archive1',\n                          '--conf', 'prop1=val1', 'test.py'])",
                "test_error": "AssertionError: Lists differ: ['ss-[131 chars] '--archives', 'archive1', '--conf', '\"prop1=val1\"', 'test.py'] != ['ss-[131 chars] '--archives', 'archive1', '--conf', 'prop1=val1', 'test.py']  First differing element 12: '\"prop1=val1\"' 'prop1=val1'    ['ss-stub',    '--master',    'spark://host:7077',    '--jars',    'jar1.jar,jar2.jar',    '--py-files',    'file1.py,file2.py',    '--files',    'file1,file2',    '--archives',    'archive1',    '--conf', -  '\"prop1=val1\"', ?   -          -  +  'prop1=val1',    'test.py']",
                "full_test_error": "self = <contrib.spark_test.SparkSubmitTaskTest testMethod=test_defaults>\nproc = <MagicMock name='Popen' id='140503795783712'>\n\n    @with_config({'spark': {'spark-submit': ss, 'master': 'spark://host:7077', 'conf': 'prop1=val1', 'jars': 'jar1.jar,jar2.jar',\n                            'files': 'file1,file2', 'py-files': 'file1.py,file2.py', 'archives': 'archive1'}})\n    @patch('luigi.contrib.spark.subprocess.Popen')\n    def test_defaults(self, proc):\n        proc.return_value.returncode = 0\n        job = TestDefaultSparkSubmitTask()\n        job.run()\n>       self.assertEqual(proc.call_args[0][0],\n                         ['ss-stub', '--master', 'spark://host:7077', '--jars', 'jar1.jar,jar2.jar',\n                          '--py-files', 'file1.py,file2.py', '--files', 'file1,file2', '--archives', 'archive1',\n                          '--conf', 'prop1=val1', 'test.py'])\nE       AssertionError: Lists differ: ['ss-[131 chars] '--archives', 'archive1', '--conf', '\"prop1=val1\"', 'test.py'] != ['ss-[131 chars] '--archives', 'archive1', '--conf', 'prop1=val1', 'test.py']\nE       \nE       First differing element 12:\nE       '\"prop1=val1\"'\nE       'prop1=val1'\nE       \nE         ['ss-stub',\nE          '--master',\nE          'spark://host:7077',\nE          '--jars',\nE          'jar1.jar,jar2.jar',\nE          '--py-files',\nE          'file1.py,file2.py',\nE          '--files',\nE          'file1,file2',\nE          '--archives',\nE          'archive1',\nE          '--conf',\nE       -  '\"prop1=val1\"',\nE       ?   -          -\nE       \nE       +  'prop1=val1',\nE          'test.py']\n\ntest/contrib/spark_test.py:165: AssertionError",
                "traceback": null,
                "test_error_location": null,
                "test_function_decorators": [
                    "with_config({'spark': {'spark-submit': ss, 'master': 'spark://host:7077', 'conf': 'prop1=val1', 'jars': 'jar1.jar,jar2.jar', 'files': 'file1,file2', 'py-files': 'file1.py,file2.py', 'archives': 'archive1'}})",
                    "patch('luigi.contrib.spark.subprocess.Popen')"
                ]
            }
        ]
    }
}