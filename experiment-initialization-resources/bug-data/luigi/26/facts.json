{
    "1.1.1": "def run_job(self, job):\n    ssh_config = job.ssh()\n    if ssh_config:\n        host = ssh_config.get(\"host\", None)\n        key_file = ssh_config.get(\"key_file\", None)\n        username = ssh_config.get(\"username\", None)\n        if not host or not key_file or not username or not job.jar():\n            raise HadoopJarJobError(\"missing some config for HadoopRemoteJarJobRunner\")\n        arglist = ['ssh', '-i', key_file,\n                   '-o', 'BatchMode=yes']  # no password prompts etc\n        if ssh_config.get(\"no_host_key_check\", False):\n            arglist += ['-o', 'UserKnownHostsFile=/dev/null',\n                        '-o', 'StrictHostKeyChecking=no']\n        arglist.append('{}@{}'.format(username, host))\n    else:\n        arglist = []\n        if not job.jar() or not os.path.exists(job.jar()):\n            logger.error(\"Can't find jar: %s, full path %s\", job.jar(), os.path.abspath(job.jar()))\n            raise HadoopJarJobError(\"job jar does not exist\")\n\n    # TODO(jcrobak): libjars, files, etc. Can refactor out of\n    # hadoop.HadoopJobRunner\n    hadoop_arglist = luigi.contrib.hdfs.load_hadoop_cmd() + ['jar', job.jar()]\n    if job.main():\n        hadoop_arglist.append(job.main())\n\n    jobconfs = job.jobconfs()\n\n    for jc in jobconfs:\n        hadoop_arglist += ['-D' + jc]\n\n    (tmp_files, job_args) = fix_paths(job)\n\n    hadoop_arglist += job_args\n    arglist.extend(hadoop_arglist)\n\n    luigi.contrib.hadoop.run_and_track_hadoop_job(arglist)\n\n    for a, b in tmp_files:\n        a.move(b)\n",
    "1.1.2": null,
    "1.2.1": "class HadoopJarJobRunner(luigi.contrib.hadoop.JobRunner)",
    "1.2.2": "JobRunner for `hadoop jar` commands. Used to run a HadoopJarJobTask.",
    "1.2.3": null,
    "1.3.1": "luigi/contrib/hadoop_jar.py",
    "1.3.2": [
        "fix_paths(job)",
        "jar(self)",
        "main(self)",
        "ssh(self)"
    ],
    "1.4.1": [
        "    @patch('luigi.contrib.hadoop.run_and_track_hadoop_job')\n    def test_missing_jar(self, mock_job):\n        mock_job.return_value = None\n        task = TestMissingJarJob()\n        self.assertRaises(HadoopJarJobError, task.run)"
    ],
    "1.4.2": [
        "test/contrib/hadoop_jar_test.py"
    ],
    "2.1.1": [
        [
            "E       TypeError: expected str, bytes or os.PathLike object, not NoneType"
        ]
    ],
    "2.1.2": [
        [
            "self = <contrib.hadoop_jar_test.HadoopJarJobTaskTest testMethod=test_missing_jar>\nmock_job = <MagicMock name='run_and_track_hadoop_job' id='139620915505808'>\n\n    @patch('luigi.contrib.hadoop.run_and_track_hadoop_job')\n    def test_missing_jar(self, mock_job):\n        mock_job.return_value = None\n        task = TestMissingJarJob()\n>       self.assertRaises(HadoopJarJobError, task.run)\n\ntest/contrib/hadoop_jar_test.py:58: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nluigi/contrib/hadoop.py:651: in run\n    self.job_runner().run_job(self)\nluigi/contrib/hadoop_jar.py:87: in run_job\n    logger.error(\"Can't find jar: %s, full path %s\", job.jar(), os.path.abspath(job.jar()))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n    def abspath(path):\n        \"\"\"Return an absolute path.\"\"\"\n>       path = os.fspath(path)",
            "\n/usr/local/lib/python3.8/posixpath.py:374: TypeError"
        ]
    ],
    "2.1.3": null,
    "2.1.4": null,
    "2.1.5": null,
    "2.1.6": null,
    "3.1.1": null,
    "3.1.2": null,
    "used_imports": "import os"
}