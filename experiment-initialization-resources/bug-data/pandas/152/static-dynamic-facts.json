{
    "pandas:152": {
        "/home/ubuntu/Desktop/bgp_envs_local/repos/pandas_152/pandas/core/series.py": {
            "buggy_functions": [
                {
                    "function_name": "append",
                    "function_code": "def append(self, to_append, ignore_index=False, verify_integrity=False):\n    \"\"\"\n    Concatenate two or more Series.\n\n    Parameters\n    ----------\n    to_append : Series or list/tuple of Series\n        Series to append with self.\n    ignore_index : bool, default False\n        If True, do not use the index labels.\n    verify_integrity : bool, default False\n        If True, raise Exception on creating index with duplicates.\n\n    Returns\n    -------\n    Series\n        Concatenated Series.\n\n    See Also\n    --------\n    concat : General function to concatenate DataFrame or Series objects.\n\n    Notes\n    -----\n    Iteratively appending to a Series can be more computationally intensive\n    than a single concatenate. A better solution is to append values to a\n    list and then concatenate the list with the original Series all at\n    once.\n\n    Examples\n    --------\n    >>> s1 = pd.Series([1, 2, 3])\n    >>> s2 = pd.Series([4, 5, 6])\n    >>> s3 = pd.Series([4, 5, 6], index=[3, 4, 5])\n    >>> s1.append(s2)\n    0    1\n    1    2\n    2    3\n    0    4\n    1    5\n    2    6\n    dtype: int64\n\n    >>> s1.append(s3)\n    0    1\n    1    2\n    2    3\n    3    4\n    4    5\n    5    6\n    dtype: int64\n\n    With `ignore_index` set to True:\n\n    >>> s1.append(s2, ignore_index=True)\n    0    1\n    1    2\n    2    3\n    3    4\n    4    5\n    5    6\n    dtype: int64\n\n    With `verify_integrity` set to True:\n\n    >>> s1.append(s2, verify_integrity=True)\n    Traceback (most recent call last):\n    ...\n    ValueError: Indexes have overlapping values: [0, 1, 2]\n    \"\"\"\n    from pandas.core.reshape.concat import concat\n\n    if isinstance(to_append, (list, tuple)):\n        to_concat = [self] + to_append\n    else:\n        to_concat = [self, to_append]\n    return concat(\n        to_concat, ignore_index=ignore_index, verify_integrity=verify_integrity\n    )\n",
                    "decorators": [],
                    "docstring": "Concatenate two or more Series.\n\nParameters\n----------\nto_append : Series or list/tuple of Series\n    Series to append with self.\nignore_index : bool, default False\n    If True, do not use the index labels.\nverify_integrity : bool, default False\n    If True, raise Exception on creating index with duplicates.\n\nReturns\n-------\nSeries\n    Concatenated Series.\n\nSee Also\n--------\nconcat : General function to concatenate DataFrame or Series objects.\n\nNotes\n-----\nIteratively appending to a Series can be more computationally intensive\nthan a single concatenate. A better solution is to append values to a\nlist and then concatenate the list with the original Series all at\nonce.\n\nExamples\n--------\n>>> s1 = pd.Series([1, 2, 3])\n>>> s2 = pd.Series([4, 5, 6])\n>>> s3 = pd.Series([4, 5, 6], index=[3, 4, 5])\n>>> s1.append(s2)\n0    1\n1    2\n2    3\n0    4\n1    5\n2    6\ndtype: int64\n\n>>> s1.append(s3)\n0    1\n1    2\n2    3\n3    4\n4    5\n5    6\ndtype: int64\n\nWith `ignore_index` set to True:\n\n>>> s1.append(s2, ignore_index=True)\n0    1\n1    2\n2    3\n3    4\n4    5\n5    6\ndtype: int64\n\nWith `verify_integrity` set to True:\n\n>>> s1.append(s2, verify_integrity=True)\nTraceback (most recent call last):\n...\nValueError: Indexes have overlapping values: [0, 1, 2]",
                    "start_line": 2660,
                    "end_line": 2738,
                    "variables": {
                        "isinstance": [
                            2732
                        ],
                        "to_append": [
                            2732,
                            2733,
                            2735
                        ],
                        "list": [
                            2732
                        ],
                        "tuple": [
                            2732
                        ],
                        "to_concat": [
                            2737,
                            2733,
                            2735
                        ],
                        "self": [
                            2733,
                            2735
                        ],
                        "concat": [
                            2736
                        ],
                        "ignore_index": [
                            2737
                        ],
                        "verify_integrity": [
                            2737
                        ]
                    },
                    "filtered_variables": {
                        "to_append": [
                            2732,
                            2733,
                            2735
                        ],
                        "to_concat": [
                            2737,
                            2733,
                            2735
                        ],
                        "self": [
                            2733,
                            2735
                        ],
                        "concat": [
                            2736
                        ],
                        "ignore_index": [
                            2737
                        ],
                        "verify_integrity": [
                            2737
                        ]
                    },
                    "diff_line_number": 2733,
                    "class_data": {
                        "signature": "class Series(base.IndexOpsMixin, generic.NDFrame)",
                        "docstring": "One-dimensional ndarray with axis labels (including time series).\n\nLabels need not be unique but must be a hashable type. The object\nsupports both integer- and label-based indexing and provides a host of\nmethods for performing operations involving the index. Statistical\nmethods from ndarray have been overridden to automatically exclude\nmissing data (currently represented as NaN).\n\nOperations between Series (+, -, /, *, **) align values based on their\nassociated index values-- they need not be the same length. The result\nindex will be the sorted union of the two indexes.\n\nParameters\n----------\ndata : array-like, Iterable, dict, or scalar value\n    Contains data stored in Series.\n\n    .. versionchanged:: 0.23.0\n       If data is a dict, argument order is maintained for Python 3.6\n       and later.\n\nindex : array-like or Index (1d)\n    Values must be hashable and have the same length as `data`.\n    Non-unique index values are allowed. Will default to\n    RangeIndex (0, 1, 2, ..., n) if not provided. If both a dict and index\n    sequence are used, the index will override the keys found in the\n    dict.\ndtype : str, numpy.dtype, or ExtensionDtype, optional\n    Data type for the output Series. If not specified, this will be\n    inferred from `data`.\n    See the :ref:`user guide <basics.dtypes>` for more usages.\ncopy : bool, default False\n    Copy input data.",
                        "constructor_docstring": null,
                        "functions": [
                            "def __init__(self, data=None, index=None, dtype=None, name=None, copy=False, fastpath=False):\n    if fastpath:\n        if not isinstance(data, SingleBlockManager):\n            data = SingleBlockManager(data, index, fastpath=True)\n        if copy:\n            data = data.copy()\n        if index is None:\n            index = data.index\n    else:\n        if index is not None:\n            index = ensure_index(index)\n        if data is None:\n            data = {}\n        if dtype is not None:\n            if isinstance(dtype, str) and dtype == 'category' and is_categorical(data):\n                dtype = data.dtype\n            dtype = self._validate_dtype(dtype)\n        if isinstance(data, MultiIndex):\n            raise NotImplementedError('initializing a Series from a MultiIndex is not supported')\n        elif isinstance(data, Index):\n            if name is None:\n                name = data.name\n            if dtype is not None:\n                data = data.astype(dtype)\n            else:\n                data = data._values.copy()\n                if isinstance(data, ABCDatetimeIndex) and data.tz is not None:\n                    data = data._values.copy(deep=True)\n            copy = False\n        elif isinstance(data, np.ndarray):\n            pass\n        elif isinstance(data, (ABCSeries, ABCSparseSeries)):\n            if name is None:\n                name = data.name\n            if index is None:\n                index = data.index\n            else:\n                data = data.reindex(index, copy=copy)\n            data = data._data\n        elif isinstance(data, dict):\n            (data, index) = self._init_dict(data, index, dtype)\n            dtype = None\n            copy = False\n        elif isinstance(data, SingleBlockManager):\n            if index is None:\n                index = data.index\n            elif not data.index.equals(index) or copy:\n                raise AssertionError('Cannot pass both SingleBlockManager `data` argument and a different `index` argument.  `copy` must be False.')\n        elif is_extension_array_dtype(data):\n            pass\n        elif isinstance(data, (set, frozenset)):\n            raise TypeError('{0!r} type is unordered'.format(data.__class__.__name__))\n        elif isinstance(data, ABCSparseArray):\n            data = data.to_dense()\n        else:\n            data = com.maybe_iterable_to_list(data)\n        if index is None:\n            if not is_list_like(data):\n                data = [data]\n            index = ibase.default_index(len(data))\n        elif is_list_like(data):\n            try:\n                if len(index) != len(data):\n                    raise ValueError('Length of passed values is {val}, index implies {ind}'.format(val=len(data), ind=len(index)))\n            except TypeError:\n                pass\n        if isinstance(data, SingleBlockManager):\n            if dtype is not None:\n                data = data.astype(dtype=dtype, errors='ignore', copy=copy)\n            elif copy:\n                data = data.copy()\n        else:\n            data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True)\n            data = SingleBlockManager(data, index, fastpath=True)\n    generic.NDFrame.__init__(self, data, fastpath=True)\n    self.name = name\n    self._set_axis(0, index, fastpath=True)",
                            "def _init_dict(self, data, index=None, dtype=None):\n    \"\"\"\n    Derive the \"_data\" and \"index\" attributes of a new Series from a\n    dictionary input.\n\n    Parameters\n    ----------\n    data : dict or dict-like\n        Data used to populate the new Series\n    index : Index or index-like, default None\n        index for the new Series: if None, use dict keys\n    dtype : dtype, default None\n        dtype for the new Series: if None, infer from data\n\n    Returns\n    -------\n    _data : BlockManager for the new Series\n    index : index for the new Series\n    \"\"\"\n    if data:\n        (keys, values) = zip(*data.items())\n        values = list(values)\n    elif index is not None:\n        values = na_value_for_dtype(dtype)\n        keys = index\n    else:\n        (keys, values) = ([], [])\n    s = Series(values, index=keys, dtype=dtype)\n    if data and index is not None:\n        s = s.reindex(index, copy=False)\n    elif not PY36 and (not isinstance(data, OrderedDict)) and data:\n        try:\n            s = s.sort_index()\n        except TypeError:\n            pass\n    return (s._data, s.index)",
                            "@classmethod\ndef from_array(cls, arr, index=None, name=None, dtype=None, copy=False, fastpath=False):\n    \"\"\"\n    Construct Series from array.\n\n    .. deprecated:: 0.23.0\n        Use pd.Series(..) constructor instead.\n\n    Returns\n    -------\n    Series\n        Constructed Series.\n    \"\"\"\n    warnings.warn(\"'from_array' is deprecated and will be removed in a future version. Please use the pd.Series(..) constructor instead.\", FutureWarning, stacklevel=2)\n    if isinstance(arr, ABCSparseArray):\n        from pandas.core.sparse.series import SparseSeries\n        cls = SparseSeries\n    return cls(arr, index=index, name=name, dtype=dtype, copy=copy, fastpath=fastpath)",
                            "@property\ndef _constructor(self):\n    return Series",
                            "@property\ndef _constructor_expanddim(self):\n    from pandas.core.frame import DataFrame\n    return DataFrame",
                            "@property\ndef _can_hold_na(self):\n    return self._data._can_hold_na",
                            "def _set_axis(self, axis, labels, fastpath=False):\n    \"\"\"\n    Override generic, we want to set the _typ here.\n    \"\"\"\n    if not fastpath:\n        labels = ensure_index(labels)\n    is_all_dates = labels.is_all_dates\n    if is_all_dates:\n        if not isinstance(labels, (DatetimeIndex, PeriodIndex, TimedeltaIndex)):\n            try:\n                labels = DatetimeIndex(labels)\n                if fastpath:\n                    self._data.set_axis(axis, labels)\n            except (tslibs.OutOfBoundsDatetime, ValueError):\n                pass\n    self._set_subtyp(is_all_dates)\n    object.__setattr__(self, '_index', labels)\n    if not fastpath:\n        self._data.set_axis(axis, labels)",
                            "def _set_subtyp(self, is_all_dates):\n    if is_all_dates:\n        object.__setattr__(self, '_subtyp', 'time_series')\n    else:\n        object.__setattr__(self, '_subtyp', 'series')",
                            "def _update_inplace(self, result, **kwargs):\n    return generic.NDFrame._update_inplace(self, result, **kwargs)",
                            "@property\ndef name(self):\n    \"\"\"\n    Return name of the Series.\n    \"\"\"\n    return self._name",
                            "@name.setter\ndef name(self, value):\n    if value is not None and (not is_hashable(value)):\n        raise TypeError('Series.name must be a hashable type')\n    object.__setattr__(self, '_name', value)",
                            "@property\ndef dtype(self):\n    \"\"\"\n    Return the dtype object of the underlying data.\n    \"\"\"\n    return self._data.dtype",
                            "@property\ndef dtypes(self):\n    \"\"\"\n    Return the dtype object of the underlying data.\n    \"\"\"\n    return self._data.dtype",
                            "@property\ndef ftype(self):\n    \"\"\"\n    Return if the data is sparse|dense.\n\n    .. deprecated:: 0.25.0\n       Use :func:`dtype` instead.\n    \"\"\"\n    warnings.warn('Series.ftype is deprecated and will be removed in a future version. Use Series.dtype instead.', FutureWarning, stacklevel=2)\n    return self._data.ftype",
                            "@property\ndef ftypes(self):\n    \"\"\"\n    Return if the data is sparse|dense.\n\n    .. deprecated:: 0.25.0\n       Use :func:`dtypes` instead.\n    \"\"\"\n    warnings.warn('Series.ftypes is deprecated and will be removed in a future version. Use Series.dtype instead.', FutureWarning, stacklevel=2)\n    return self._data.ftype",
                            "@property\ndef values(self):\n    \"\"\"\n    Return Series as ndarray or ndarray-like depending on the dtype.\n\n    .. warning::\n\n       We recommend using :attr:`Series.array` or\n       :meth:`Series.to_numpy`, depending on whether you need\n       a reference to the underlying data or a NumPy array.\n\n    Returns\n    -------\n    numpy.ndarray or ndarray-like\n\n    See Also\n    --------\n    Series.array : Reference to the underlying data.\n    Series.to_numpy : A NumPy array representing the underlying data.\n\n    Examples\n    --------\n    >>> pd.Series([1, 2, 3]).values\n    array([1, 2, 3])\n\n    >>> pd.Series(list('aabc')).values\n    array(['a', 'a', 'b', 'c'], dtype=object)\n\n    >>> pd.Series(list('aabc')).astype('category').values\n    [a, a, b, c]\n    Categories (3, object): [a, b, c]\n\n    Timezone aware datetime data is converted to UTC:\n\n    >>> pd.Series(pd.date_range('20130101', periods=3,\n    ...                         tz='US/Eastern')).values\n    array(['2013-01-01T05:00:00.000000000',\n           '2013-01-02T05:00:00.000000000',\n           '2013-01-03T05:00:00.000000000'], dtype='datetime64[ns]')\n    \"\"\"\n    return self._data.external_values()",
                            "@property\ndef _values(self):\n    \"\"\"\n    Return the internal repr of this data.\n    \"\"\"\n    return self._data.internal_values()",
                            "def get_values(self):\n    \"\"\"\n    Same as values (but handles sparseness conversions); is a view.\n\n    .. deprecated:: 0.25.0\n        Use :meth:`Series.to_numpy` or :attr:`Series.array` instead.\n\n    Returns\n    -------\n    numpy.ndarray\n        Data of the Series.\n    \"\"\"\n    warnings.warn(\"The 'get_values' method is deprecated and will be removed in a future version. Use '.to_numpy()' or '.array' instead.\", FutureWarning, stacklevel=2)\n    return self._internal_get_values()",
                            "def _internal_get_values(self):\n    return self._data.get_values()",
                            "@property\ndef asobject(self):\n    \"\"\"\n    Return object Series which contains boxed values.\n\n    .. deprecated:: 0.23.0\n\n       Use ``astype(object)`` instead.\n\n    *this is an internal non-public method*\n    \"\"\"\n    warnings.warn(\"'asobject' is deprecated. Use 'astype(object)' instead\", FutureWarning, stacklevel=2)\n    return self.astype(object).values",
                            "def ravel(self, order='C'):\n    \"\"\"\n    Return the flattened underlying data as an ndarray.\n\n    Returns\n    -------\n    numpy.ndarray or ndarray-like\n        Flattened data of the Series.\n\n    See Also\n    --------\n    numpy.ndarray.ravel\n    \"\"\"\n    return self._values.ravel(order=order)",
                            "def compress(self, condition, *args, **kwargs):\n    \"\"\"\n    Return selected slices of an array along given axis as a Series.\n\n    .. deprecated:: 0.24.0\n\n    Returns\n    -------\n    Series\n        Series without the slices for which condition is false.\n\n    See Also\n    --------\n    numpy.ndarray.compress\n    \"\"\"\n    msg = \"Series.compress(condition) is deprecated. Use 'Series[condition]' or 'np.asarray(series).compress(condition)' instead.\"\n    warnings.warn(msg, FutureWarning, stacklevel=2)\n    nv.validate_compress(args, kwargs)\n    return self[condition]",
                            "def nonzero(self):\n    \"\"\"\n    Return the *integer* indices of the elements that are non-zero.\n\n    .. deprecated:: 0.24.0\n       Please use .to_numpy().nonzero() as a replacement.\n\n    This method is equivalent to calling `numpy.nonzero` on the\n    series data. For compatibility with NumPy, the return value is\n    the same (a tuple with an array of indices for each dimension),\n    but it will always be a one-item tuple because series only have\n    one dimension.\n\n    Returns\n    -------\n    numpy.ndarray\n        Indices of elements that are non-zero.\n\n    See Also\n    --------\n    numpy.nonzero\n\n    Examples\n    --------\n    >>> s = pd.Series([0, 3, 0, 4])\n    >>> s.nonzero()\n    (array([1, 3]),)\n    >>> s.iloc[s.nonzero()[0]]\n    1    3\n    3    4\n    dtype: int64\n\n    # same return although index of s is different\n    >>> s = pd.Series([0, 3, 0, 4], index=['a', 'b', 'c', 'd'])\n    >>> s.nonzero()\n    (array([1, 3]),)\n    >>> s.iloc[s.nonzero()[0]]\n    b    3\n    d    4\n    dtype: int64\n    \"\"\"\n    msg = 'Series.nonzero() is deprecated and will be removed in a future version.Use Series.to_numpy().nonzero() instead'\n    warnings.warn(msg, FutureWarning, stacklevel=2)\n    return self._values.nonzero()",
                            "def put(self, *args, **kwargs):\n    \"\"\"\n    Apply the `put` method to its `values` attribute if it has one.\n\n    .. deprecated:: 0.25.0\n\n    See Also\n    --------\n    numpy.ndarray.put\n    \"\"\"\n    warnings.warn('`put` has been deprecated and will be removed in a future version.', FutureWarning, stacklevel=2)\n    self._values.put(*args, **kwargs)",
                            "def __len__(self):\n    \"\"\"\n    Return the length of the Series.\n    \"\"\"\n    return len(self._data)",
                            "def view(self, dtype=None):\n    \"\"\"\n    Create a new view of the Series.\n\n    This function will return a new Series with a view of the same\n    underlying values in memory, optionally reinterpreted with a new data\n    type. The new data type must preserve the same size in bytes as to not\n    cause index misalignment.\n\n    Parameters\n    ----------\n    dtype : data type\n        Data type object or one of their string representations.\n\n    Returns\n    -------\n    Series\n        A new Series object as a view of the same data in memory.\n\n    See Also\n    --------\n    numpy.ndarray.view : Equivalent numpy function to create a new view of\n        the same data in memory.\n\n    Notes\n    -----\n    Series are instantiated with ``dtype=float64`` by default. While\n    ``numpy.ndarray.view()`` will return a view with the same data type as\n    the original array, ``Series.view()`` (without specified dtype)\n    will try using ``float64`` and may fail if the original data type size\n    in bytes is not the same.\n\n    Examples\n    --------\n    >>> s = pd.Series([-2, -1, 0, 1, 2], dtype='int8')\n    >>> s\n    0   -2\n    1   -1\n    2    0\n    3    1\n    4    2\n    dtype: int8\n\n    The 8 bit signed integer representation of `-1` is `0b11111111`, but\n    the same bytes represent 255 if read as an 8 bit unsigned integer:\n\n    >>> us = s.view('uint8')\n    >>> us\n    0    254\n    1    255\n    2      0\n    3      1\n    4      2\n    dtype: uint8\n\n    The views share the same underlying values:\n\n    >>> us[0] = 128\n    >>> s\n    0   -128\n    1     -1\n    2      0\n    3      1\n    4      2\n    dtype: int8\n    \"\"\"\n    return self._constructor(self._values.view(dtype), index=self.index).__finalize__(self)",
                            "def __array_ufunc__(self, ufunc: Callable, method: str, *inputs: Any, **kwargs: Any):\n    cls = type(self)\n    result = ops.maybe_dispatch_ufunc_to_dunder_op(self, ufunc, method, *inputs, **kwargs)\n    if result is not NotImplemented:\n        return result\n    no_defer = (np.ndarray.__array_ufunc__, cls.__array_ufunc__)\n    for item in inputs:\n        higher_priority = hasattr(item, '__array_priority__') and item.__array_priority__ > self.__array_priority__\n        has_array_ufunc = hasattr(item, '__array_ufunc__') and type(item).__array_ufunc__ not in no_defer and (not isinstance(item, self._HANDLED_TYPES))\n        if higher_priority or has_array_ufunc:\n            return NotImplemented\n    names = [getattr(x, 'name') for x in inputs if hasattr(x, 'name')]\n    types = tuple((type(x) for x in inputs))\n    alignable = [x for (x, t) in zip(inputs, types) if issubclass(t, Series)]\n    if len(alignable) > 1:\n        index = alignable[0].index\n        for s in alignable[1:]:\n            index |= s.index\n        inputs = tuple((x.reindex(index) if issubclass(t, Series) else x for (x, t) in zip(inputs, types)))\n    else:\n        index = self.index\n    inputs = tuple((extract_array(x, extract_numpy=True) for x in inputs))\n    result = getattr(ufunc, method)(*inputs, **kwargs)\n    if len(set(names)) == 1:\n        name = names[0]\n    else:\n        name = None\n\n    def construct_return(result):\n        if lib.is_scalar(result):\n            return result\n        elif result.ndim > 1:\n            if method == 'outer':\n                msg = \"outer method for ufunc {} is not implemented on pandas objects. Returning an ndarray, but in the future this will raise a 'NotImplementedError'. Consider explicitly converting the Series to an array with '.array' first.\"\n                warnings.warn(msg.format(ufunc), FutureWarning, stacklevel=3)\n            return result\n        return self._constructor(result, index=index, name=name, copy=False)\n    if type(result) is tuple:\n        return tuple((construct_return(x) for x in result))\n    elif method == 'at':\n        return None\n    else:\n        return construct_return(result)",
                            "def __array__(self, dtype=None):\n    \"\"\"\n    Return the values as a NumPy array.\n\n    Users should not call this directly. Rather, it is invoked by\n    :func:`numpy.array` and :func:`numpy.asarray`.\n\n    Parameters\n    ----------\n    dtype : str or numpy.dtype, optional\n        The dtype to use for the resulting NumPy array. By default,\n        the dtype is inferred from the data.\n\n    Returns\n    -------\n    numpy.ndarray\n        The values in the series converted to a :class:`numpy.ndarary`\n        with the specified `dtype`.\n\n    See Also\n    --------\n    array : Create a new array from data.\n    Series.array : Zero-copy view to the array backing the Series.\n    Series.to_numpy : Series method for similar behavior.\n\n    Examples\n    --------\n    >>> ser = pd.Series([1, 2, 3])\n    >>> np.asarray(ser)\n    array([1, 2, 3])\n\n    For timezone-aware data, the timezones may be retained with\n    ``dtype='object'``\n\n    >>> tzser = pd.Series(pd.date_range('2000', periods=2, tz=\"CET\"))\n    >>> np.asarray(tzser, dtype=\"object\")\n    array([Timestamp('2000-01-01 00:00:00+0100', tz='CET', freq='D'),\n           Timestamp('2000-01-02 00:00:00+0100', tz='CET', freq='D')],\n          dtype=object)\n\n    Or the values may be localized to UTC and the tzinfo discared with\n    ``dtype='datetime64[ns]'``\n\n    >>> np.asarray(tzser, dtype=\"datetime64[ns]\")  # doctest: +ELLIPSIS\n    array(['1999-12-31T23:00:00.000000000', ...],\n          dtype='datetime64[ns]')\n    \"\"\"\n    if dtype is None and isinstance(self.array, ABCDatetimeArray) and getattr(self.dtype, 'tz', None):\n        msg = 'Converting timezone-aware DatetimeArray to timezone-naive ndarray with \\'datetime64[ns]\\' dtype. In the future, this will return an ndarray with \\'object\\' dtype where each element is a \\'pandas.Timestamp\\' with the correct \\'tz\\'.\\n\\tTo accept the future behavior, pass \\'dtype=object\\'.\\n\\tTo keep the old behavior, pass \\'dtype=\"datetime64[ns]\"\\'.'\n        warnings.warn(msg, FutureWarning, stacklevel=3)\n        dtype = 'M8[ns]'\n    return np.asarray(self.array, dtype)",
                            "@property\ndef real(self):\n    \"\"\"\n    Return the real value of vector.\n\n    .. deprecated:: 0.25.0\n    \"\"\"\n    warnings.warn('`real` is deprecated and will be removed in a future version. To eliminate this warning for a Series `ser`, use `np.real(ser.to_numpy())` or `ser.to_numpy().real`.', FutureWarning, stacklevel=2)\n    return self.values.real",
                            "@real.setter\ndef real(self, v):\n    self.values.real = v",
                            "@property\ndef imag(self):\n    \"\"\"\n    Return imag value of vector.\n\n    .. deprecated:: 0.25.0\n    \"\"\"\n    warnings.warn('`imag` is deprecated and will be removed in a future version. To eliminate this warning for a Series `ser`, use `np.imag(ser.to_numpy())` or `ser.to_numpy().imag`.', FutureWarning, stacklevel=2)\n    return self.values.imag",
                            "@imag.setter\ndef imag(self, v):\n    self.values.imag = v",
                            "def _unpickle_series_compat(self, state):\n    if isinstance(state, dict):\n        self._data = state['_data']\n        self.name = state['name']\n        self.index = self._data.index\n    elif isinstance(state, tuple):\n        (nd_state, own_state) = state\n        data = np.empty(nd_state[1], dtype=nd_state[2])\n        np.ndarray.__setstate__(data, nd_state)\n        (index, name) = (own_state[0], None)\n        if len(own_state) > 1:\n            name = own_state[1]\n        self._data = SingleBlockManager(data, index, fastpath=True)\n        self._index = index\n        self.name = name\n    else:\n        raise Exception('cannot unpickle legacy formats -> [%s]' % state)",
                            "@property\ndef axes(self):\n    \"\"\"\n    Return a list of the row axis labels.\n    \"\"\"\n    return [self.index]",
                            "@Appender(generic.NDFrame.take.__doc__)\ndef take(self, indices, axis=0, is_copy=False, **kwargs):\n    nv.validate_take(tuple(), kwargs)\n    indices = ensure_platform_int(indices)\n    new_index = self.index.take(indices)\n    if is_categorical_dtype(self):\n        indices = maybe_convert_indices(indices, len(self._get_axis(axis)))\n        kwargs = {'allow_fill': False}\n    else:\n        kwargs = {}\n    new_values = self._values.take(indices, **kwargs)\n    result = self._constructor(new_values, index=new_index, fastpath=True).__finalize__(self)\n    if is_copy:\n        if not result._get_axis(axis).equals(self._get_axis(axis)):\n            result._set_is_copy(self)\n    return result",
                            "def _ixs(self, i: int, axis: int=0):\n    \"\"\"\n    Return the i-th value or values in the Series by location.\n\n    Parameters\n    ----------\n    i : int\n\n    Returns\n    -------\n    scalar (int) or Series (slice, sequence)\n    \"\"\"\n    values = self._values\n    if isinstance(values, np.ndarray):\n        return libindex.get_value_at(values, i)\n    else:\n        return values[i]",
                            "def _slice(self, slobj: slice, axis: int=0, kind=None):\n    slobj = self.index._convert_slice_indexer(slobj, kind=kind or 'getitem')\n    return self._get_values(slobj)",
                            "def __getitem__(self, key):\n    key = com.apply_if_callable(key, self)\n    try:\n        result = self.index.get_value(self, key)\n        if not is_scalar(result):\n            if is_list_like(result) and (not isinstance(result, Series)):\n                try:\n                    if not is_scalar(self.index.get_loc(key)):\n                        result = self._constructor(result, index=[key] * len(result), dtype=self.dtype).__finalize__(self)\n                except KeyError:\n                    pass\n        return result\n    except InvalidIndexError:\n        pass\n    except (KeyError, ValueError):\n        if isinstance(key, tuple) and isinstance(self.index, MultiIndex):\n            pass\n        elif key is Ellipsis:\n            return self\n        elif com.is_bool_indexer(key):\n            pass\n        else:\n            new_key = self.index._convert_scalar_indexer(key, kind='getitem')\n            if type(new_key) != type(key):\n                return self.__getitem__(new_key)\n            raise\n    if is_iterator(key):\n        key = list(key)\n    if com.is_bool_indexer(key):\n        key = check_bool_indexer(self.index, key)\n    return self._get_with(key)",
                            "def _get_with(self, key):\n    if isinstance(key, slice):\n        return self._slice(key)\n    elif isinstance(key, ABCDataFrame):\n        raise TypeError('Indexing a Series with DataFrame is not supported, use the appropriate DataFrame column')\n    elif isinstance(key, tuple):\n        try:\n            return self._get_values_tuple(key)\n        except Exception:\n            if len(key) == 1:\n                key = key[0]\n                if isinstance(key, slice):\n                    return self._get_values(key)\n            raise\n    if not isinstance(key, (list, np.ndarray, Series, Index)):\n        key = list(key)\n    if isinstance(key, Index):\n        key_type = key.inferred_type\n    else:\n        key_type = lib.infer_dtype(key, skipna=False)\n    if key_type == 'integer':\n        if self.index.is_integer() or self.index.is_floating():\n            return self.loc[key]\n        else:\n            return self._get_values(key)\n    elif key_type == 'boolean':\n        return self._get_values(key)\n    if isinstance(key, (list, tuple)):\n        if len(key) == 1 and isinstance(key[0], slice):\n            return self._get_values(key)\n        return self.loc[key]\n    return self.reindex(key)",
                            "def _get_values_tuple(self, key):\n    if com.any_none(*key):\n        return self._get_values(key)\n    if not isinstance(self.index, MultiIndex):\n        raise ValueError('Can only tuple-index with a MultiIndex')\n    (indexer, new_index) = self.index.get_loc_level(key)\n    return self._constructor(self._values[indexer], index=new_index).__finalize__(self)",
                            "def _get_values(self, indexer):\n    try:\n        return self._constructor(self._data.get_slice(indexer), fastpath=True).__finalize__(self)\n    except Exception:\n        return self._values[indexer]",
                            "def _get_value(self, label, takeable: bool=False):\n    \"\"\"\n    Quickly retrieve single value at passed index label.\n\n    Parameters\n    ----------\n    label : object\n    takeable : interpret the index as indexers, default False\n\n    Returns\n    -------\n    scalar value\n    \"\"\"\n    if takeable:\n        return com.maybe_box_datetimelike(self._values[label])\n    return self.index.get_value(self._values, label)",
                            "def __setitem__(self, key, value):\n    key = com.apply_if_callable(key, self)\n    cacher_needs_updating = self._check_is_chained_assignment_possible()\n    try:\n        self._set_with_engine(key, value)\n    except com.SettingWithCopyError:\n        raise\n    except (KeyError, ValueError):\n        values = self._values\n        if is_integer(key) and (not self.index.inferred_type == 'integer'):\n            values[key] = value\n        elif key is Ellipsis:\n            self[:] = value\n        else:\n            self.loc[key] = value\n    except TypeError as e:\n        if isinstance(key, tuple) and (not isinstance(self.index, MultiIndex)):\n            raise ValueError('Can only tuple-index with a MultiIndex')\n        if _is_unorderable_exception(e):\n            raise IndexError(key)\n        if com.is_bool_indexer(key):\n            key = check_bool_indexer(self.index, key)\n            try:\n                self._where(~key, value, inplace=True)\n                return\n            except InvalidIndexError:\n                pass\n        self._set_with(key, value)\n    if cacher_needs_updating:\n        self._maybe_update_cacher()",
                            "def _set_with_engine(self, key, value):\n    values = self._values\n    if is_extension_array_dtype(values.dtype):\n        values[self.index.get_loc(key)] = value\n        return\n    try:\n        self.index._engine.set_value(values, key, value)\n        return\n    except KeyError:\n        values[self.index.get_loc(key)] = value\n        return",
                            "def _set_with(self, key, value):\n    if isinstance(key, slice):\n        indexer = self.index._convert_slice_indexer(key, kind='getitem')\n        return self._set_values(indexer, value)\n    elif is_scalar(key) and (not is_integer(key)) and (key not in self.index):\n        self.loc[key] = value\n        return\n    else:\n        if isinstance(key, tuple):\n            try:\n                self._set_values(key, value)\n            except Exception:\n                pass\n        if is_scalar(key):\n            key = [key]\n        elif not isinstance(key, (list, Series, np.ndarray)):\n            try:\n                key = list(key)\n            except Exception:\n                key = [key]\n        if isinstance(key, Index):\n            key_type = key.inferred_type\n            key = key._values\n        else:\n            key_type = lib.infer_dtype(key, skipna=False)\n        if key_type == 'integer':\n            if self.index.inferred_type == 'integer':\n                self._set_labels(key, value)\n            else:\n                return self._set_values(key, value)\n        elif key_type == 'boolean':\n            self._set_values(key.astype(np.bool_), value)\n        else:\n            self._set_labels(key, value)",
                            "def _set_labels(self, key, value):\n    key = com.asarray_tuplesafe(key)\n    indexer = self.index.get_indexer(key)\n    mask = indexer == -1\n    if mask.any():\n        raise ValueError('%s not contained in the index' % str(key[mask]))\n    self._set_values(indexer, value)",
                            "def _set_values(self, key, value):\n    if isinstance(key, Series):\n        key = key._values\n    self._data = self._data.setitem(indexer=key, value=value)\n    self._maybe_update_cacher()",
                            "def _set_value(self, label, value, takeable: bool=False):\n    \"\"\"\n    Quickly set single value at passed label.\n\n    If label is not contained, a new object is created with the label\n    placed at the end of the result index.\n\n    Parameters\n    ----------\n    label : object\n        Partial indexing with MultiIndex not allowed\n    value : object\n        Scalar value\n    takeable : interpret the index as indexers, default False\n\n    Returns\n    -------\n    Series\n        If label is contained, will be reference to calling Series,\n        otherwise a new object.\n    \"\"\"\n    try:\n        if takeable:\n            self._values[label] = value\n        else:\n            self.index._engine.set_value(self._values, label, value)\n    except (KeyError, TypeError):\n        self.loc[label] = value\n    return self",
                            "@property\ndef _is_mixed_type(self):\n    return False",
                            "def repeat(self, repeats, axis=None):\n    \"\"\"\n    Repeat elements of a Series.\n\n    Returns a new Series where each element of the current Series\n    is repeated consecutively a given number of times.\n\n    Parameters\n    ----------\n    repeats : int or array of ints\n        The number of repetitions for each element. This should be a\n        non-negative integer. Repeating 0 times will return an empty\n        Series.\n    axis : None\n        Must be ``None``. Has no effect but is accepted for compatibility\n        with numpy.\n\n    Returns\n    -------\n    Series\n        Newly created Series with repeated elements.\n\n    See Also\n    --------\n    Index.repeat : Equivalent function for Index.\n    numpy.repeat : Similar method for :class:`numpy.ndarray`.\n\n    Examples\n    --------\n    >>> s = pd.Series(['a', 'b', 'c'])\n    >>> s\n    0    a\n    1    b\n    2    c\n    dtype: object\n    >>> s.repeat(2)\n    0    a\n    0    a\n    1    b\n    1    b\n    2    c\n    2    c\n    dtype: object\n    >>> s.repeat([1, 2, 3])\n    0    a\n    1    b\n    1    b\n    2    c\n    2    c\n    2    c\n    dtype: object\n    \"\"\"\n    nv.validate_repeat(tuple(), dict(axis=axis))\n    new_index = self.index.repeat(repeats)\n    new_values = self._values.repeat(repeats)\n    return self._constructor(new_values, index=new_index).__finalize__(self)",
                            "def reset_index(self, level=None, drop=False, name=None, inplace=False):\n    \"\"\"\n    Generate a new DataFrame or Series with the index reset.\n\n    This is useful when the index needs to be treated as a column, or\n    when the index is meaningless and needs to be reset to the default\n    before another operation.\n\n    Parameters\n    ----------\n    level : int, str, tuple, or list, default optional\n        For a Series with a MultiIndex, only remove the specified levels\n        from the index. Removes all levels by default.\n    drop : bool, default False\n        Just reset the index, without inserting it as a column in\n        the new DataFrame.\n    name : object, optional\n        The name to use for the column containing the original Series\n        values. Uses ``self.name`` by default. This argument is ignored\n        when `drop` is True.\n    inplace : bool, default False\n        Modify the Series in place (do not create a new object).\n\n    Returns\n    -------\n    Series or DataFrame\n        When `drop` is False (the default), a DataFrame is returned.\n        The newly created columns will come first in the DataFrame,\n        followed by the original Series values.\n        When `drop` is True, a `Series` is returned.\n        In either case, if ``inplace=True``, no value is returned.\n\n    See Also\n    --------\n    DataFrame.reset_index: Analogous function for DataFrame.\n\n    Examples\n    --------\n    >>> s = pd.Series([1, 2, 3, 4], name='foo',\n    ...               index=pd.Index(['a', 'b', 'c', 'd'], name='idx'))\n\n    Generate a DataFrame with default index.\n\n    >>> s.reset_index()\n      idx  foo\n    0   a    1\n    1   b    2\n    2   c    3\n    3   d    4\n\n    To specify the name of the new column use `name`.\n\n    >>> s.reset_index(name='values')\n      idx  values\n    0   a       1\n    1   b       2\n    2   c       3\n    3   d       4\n\n    To generate a new Series with the default set `drop` to True.\n\n    >>> s.reset_index(drop=True)\n    0    1\n    1    2\n    2    3\n    3    4\n    Name: foo, dtype: int64\n\n    To update the Series in place, without generating a new one\n    set `inplace` to True. Note that it also requires ``drop=True``.\n\n    >>> s.reset_index(inplace=True, drop=True)\n    >>> s\n    0    1\n    1    2\n    2    3\n    3    4\n    Name: foo, dtype: int64\n\n    The `level` parameter is interesting for Series with a multi-level\n    index.\n\n    >>> arrays = [np.array(['bar', 'bar', 'baz', 'baz']),\n    ...           np.array(['one', 'two', 'one', 'two'])]\n    >>> s2 = pd.Series(\n    ...     range(4), name='foo',\n    ...     index=pd.MultiIndex.from_arrays(arrays,\n    ...                                     names=['a', 'b']))\n\n    To remove a specific level from the Index, use `level`.\n\n    >>> s2.reset_index(level='a')\n           a  foo\n    b\n    one  bar    0\n    two  bar    1\n    one  baz    2\n    two  baz    3\n\n    If `level` is not set, all levels are removed from the Index.\n\n    >>> s2.reset_index()\n         a    b  foo\n    0  bar  one    0\n    1  bar  two    1\n    2  baz  one    2\n    3  baz  two    3\n    \"\"\"\n    inplace = validate_bool_kwarg(inplace, 'inplace')\n    if drop:\n        new_index = ibase.default_index(len(self))\n        if level is not None:\n            if not isinstance(level, (tuple, list)):\n                level = [level]\n            level = [self.index._get_level_number(lev) for lev in level]\n            if len(level) < self.index.nlevels:\n                new_index = self.index.droplevel(level)\n        if inplace:\n            self.index = new_index\n            self.name = name or self.name\n        else:\n            return self._constructor(self._values.copy(), index=new_index).__finalize__(self)\n    elif inplace:\n        raise TypeError('Cannot reset_index inplace on a Series to create a DataFrame')\n    else:\n        df = self.to_frame(name)\n        return df.reset_index(level=level, drop=drop)",
                            "def __repr__(self):\n    \"\"\"\n    Return a string representation for a particular Series.\n    \"\"\"\n    buf = StringIO('')\n    (width, height) = get_terminal_size()\n    max_rows = height if get_option('display.max_rows') == 0 else get_option('display.max_rows')\n    min_rows = height if get_option('display.max_rows') == 0 else get_option('display.min_rows')\n    show_dimensions = get_option('display.show_dimensions')\n    self.to_string(buf=buf, name=self.name, dtype=self.dtype, min_rows=min_rows, max_rows=max_rows, length=show_dimensions)\n    result = buf.getvalue()\n    return result",
                            "def to_string(self, buf=None, na_rep='NaN', float_format=None, header=True, index=True, length=False, dtype=False, name=False, max_rows=None, min_rows=None):\n    \"\"\"\n    Render a string representation of the Series.\n\n    Parameters\n    ----------\n    buf : StringIO-like, optional\n        Buffer to write to.\n    na_rep : str, optional\n        String representation of NaN to use, default 'NaN'.\n    float_format : one-parameter function, optional\n        Formatter function to apply to columns' elements if they are\n        floats, default None.\n    header : bool, default True\n        Add the Series header (index name).\n    index : bool, optional\n        Add index (row) labels, default True.\n    length : bool, default False\n        Add the Series length.\n    dtype : bool, default False\n        Add the Series dtype.\n    name : bool, default False\n        Add the Series name if not None.\n    max_rows : int, optional\n        Maximum number of rows to show before truncating. If None, show\n        all.\n    min_rows : int, optional\n        The number of rows to display in a truncated repr (when number\n        of rows is above `max_rows`).\n\n    Returns\n    -------\n    str or None\n        String representation of Series if ``buf=None``, otherwise None.\n    \"\"\"\n    formatter = fmt.SeriesFormatter(self, name=name, length=length, header=header, index=index, dtype=dtype, na_rep=na_rep, float_format=float_format, min_rows=min_rows, max_rows=max_rows)\n    result = formatter.to_string()\n    if not isinstance(result, str):\n        raise AssertionError('result must be of type unicode, type of result is {0!r}'.format(result.__class__.__name__))\n    if buf is None:\n        return result\n    else:\n        try:\n            buf.write(result)\n        except AttributeError:\n            with open(buf, 'w') as f:\n                f.write(result)",
                            "def items(self):\n    \"\"\"\n    Lazily iterate over (index, value) tuples.\n\n    This method returns an iterable tuple (index, value). This is\n    convenient if you want to create a lazy iterator.\n\n    Returns\n    -------\n    iterable\n        Iterable of tuples containing the (index, value) pairs from a\n        Series.\n\n    See Also\n    --------\n    DataFrame.items : Iterate over (column name, Series) pairs.\n    DataFrame.iterrows : Iterate over DataFrame rows as (index, Series) pairs.\n\n    Examples\n    --------\n    >>> s = pd.Series(['A', 'B', 'C'])\n    >>> for index, value in s.items():\n    ...     print(\"Index : {}, Value : {}\".format(index, value))\n    Index : 0, Value : A\n    Index : 1, Value : B\n    Index : 2, Value : C\n    \"\"\"\n    return zip(iter(self.index), iter(self))",
                            "@Appender(items.__doc__)\ndef iteritems(self):\n    return self.items()",
                            "def keys(self):\n    \"\"\"\n    Return alias for index.\n\n    Returns\n    -------\n    Index\n        Index of the Series.\n    \"\"\"\n    return self.index",
                            "def to_dict(self, into=dict):\n    \"\"\"\n    Convert Series to {label -> value} dict or dict-like object.\n\n    Parameters\n    ----------\n    into : class, default dict\n        The collections.abc.Mapping subclass to use as the return\n        object. Can be the actual class or an empty\n        instance of the mapping type you want.  If you want a\n        collections.defaultdict, you must pass it initialized.\n\n        .. versionadded:: 0.21.0\n\n    Returns\n    -------\n    collections.abc.Mapping\n        Key-value representation of Series.\n\n    Examples\n    --------\n    >>> s = pd.Series([1, 2, 3, 4])\n    >>> s.to_dict()\n    {0: 1, 1: 2, 2: 3, 3: 4}\n    >>> from collections import OrderedDict, defaultdict\n    >>> s.to_dict(OrderedDict)\n    OrderedDict([(0, 1), (1, 2), (2, 3), (3, 4)])\n    >>> dd = defaultdict(list)\n    >>> s.to_dict(dd)\n    defaultdict(<class 'list'>, {0: 1, 1: 2, 2: 3, 3: 4})\n    \"\"\"\n    into_c = com.standardize_mapping(into)\n    return into_c(self.items())",
                            "def to_frame(self, name=None):\n    \"\"\"\n    Convert Series to DataFrame.\n\n    Parameters\n    ----------\n    name : object, default None\n        The passed name should substitute for the series name (if it has\n        one).\n\n    Returns\n    -------\n    DataFrame\n        DataFrame representation of Series.\n\n    Examples\n    --------\n    >>> s = pd.Series([\"a\", \"b\", \"c\"],\n    ...               name=\"vals\")\n    >>> s.to_frame()\n      vals\n    0    a\n    1    b\n    2    c\n    \"\"\"\n    if name is None:\n        df = self._constructor_expanddim(self)\n    else:\n        df = self._constructor_expanddim({name: self})\n    return df",
                            "def to_sparse(self, kind='block', fill_value=None):\n    \"\"\"\n    Convert Series to SparseSeries.\n\n    .. deprecated:: 0.25.0\n\n    Parameters\n    ----------\n    kind : {'block', 'integer'}, default 'block'\n    fill_value : float, defaults to NaN (missing)\n        Value to use for filling NaN values.\n\n    Returns\n    -------\n    SparseSeries\n        Sparse representation of the Series.\n    \"\"\"\n    warnings.warn('Series.to_sparse is deprecated and will be removed in a future version', FutureWarning, stacklevel=2)\n    from pandas.core.sparse.series import SparseSeries\n    values = SparseArray(self, kind=kind, fill_value=fill_value)\n    with warnings.catch_warnings():\n        warnings.filterwarnings('ignore', message='SparseSeries')\n        return SparseSeries(values, index=self.index, name=self.name).__finalize__(self)",
                            "def _set_name(self, name, inplace=False):\n    \"\"\"\n    Set the Series name.\n\n    Parameters\n    ----------\n    name : str\n    inplace : bool\n        whether to modify `self` directly or return a copy\n    \"\"\"\n    inplace = validate_bool_kwarg(inplace, 'inplace')\n    ser = self if inplace else self.copy()\n    ser.name = name\n    return ser",
                            "def count(self, level=None):\n    \"\"\"\n    Return number of non-NA/null observations in the Series.\n\n    Parameters\n    ----------\n    level : int or level name, default None\n        If the axis is a MultiIndex (hierarchical), count along a\n        particular level, collapsing into a smaller Series.\n\n    Returns\n    -------\n    int or Series (if level specified)\n        Number of non-null values in the Series.\n\n    Examples\n    --------\n    >>> s = pd.Series([0.0, 1.0, np.nan])\n    >>> s.count()\n    2\n    \"\"\"\n    if level is None:\n        return notna(self.array).sum()\n    if isinstance(level, str):\n        level = self.index._get_level_number(level)\n    lev = self.index.levels[level]\n    level_codes = np.array(self.index.codes[level], subok=False, copy=True)\n    mask = level_codes == -1\n    if mask.any():\n        level_codes[mask] = cnt = len(lev)\n        lev = lev.insert(cnt, lev._na_value)\n    obs = level_codes[notna(self.values)]\n    out = np.bincount(obs, minlength=len(lev) or None)\n    return self._constructor(out, index=lev, dtype='int64').__finalize__(self)",
                            "def mode(self, dropna=True):\n    \"\"\"\n    Return the mode(s) of the dataset.\n\n    Always returns Series even if only one value is returned.\n\n    Parameters\n    ----------\n    dropna : bool, default True\n        Don't consider counts of NaN/NaT.\n\n        .. versionadded:: 0.24.0\n\n    Returns\n    -------\n    Series\n        Modes of the Series in sorted order.\n    \"\"\"\n    return algorithms.mode(self, dropna=dropna)",
                            "def unique(self):\n    \"\"\"\n    Return unique values of Series object.\n\n    Uniques are returned in order of appearance. Hash table-based unique,\n    therefore does NOT sort.\n\n    Returns\n    -------\n    ndarray or ExtensionArray\n        The unique values returned as a NumPy array. See Notes.\n\n    See Also\n    --------\n    unique : Top-level unique method for any 1-d array-like object.\n    Index.unique : Return Index with unique values from an Index object.\n\n    Notes\n    -----\n    Returns the unique values as a NumPy array. In case of an\n    extension-array backed Series, a new\n    :class:`~api.extensions.ExtensionArray` of that type with just\n    the unique values is returned. This includes\n\n        * Categorical\n        * Period\n        * Datetime with Timezone\n        * Interval\n        * Sparse\n        * IntegerNA\n\n    See Examples section.\n\n    Examples\n    --------\n    >>> pd.Series([2, 1, 3, 3], name='A').unique()\n    array([2, 1, 3])\n\n    >>> pd.Series([pd.Timestamp('2016-01-01') for _ in range(3)]).unique()\n    array(['2016-01-01T00:00:00.000000000'], dtype='datetime64[ns]')\n\n    >>> pd.Series([pd.Timestamp('2016-01-01', tz='US/Eastern')\n    ...            for _ in range(3)]).unique()\n    <DatetimeArray>\n    ['2016-01-01 00:00:00-05:00']\n    Length: 1, dtype: datetime64[ns, US/Eastern]\n\n    An unordered Categorical will return categories in the order of\n    appearance.\n\n    >>> pd.Series(pd.Categorical(list('baabc'))).unique()\n    [b, a, c]\n    Categories (3, object): [b, a, c]\n\n    An ordered Categorical preserves the category ordering.\n\n    >>> pd.Series(pd.Categorical(list('baabc'), categories=list('abc'),\n    ...                          ordered=True)).unique()\n    [b, a, c]\n    Categories (3, object): [a < b < c]\n    \"\"\"\n    result = super().unique()\n    return result",
                            "def drop_duplicates(self, keep='first', inplace=False):\n    \"\"\"\n    Return Series with duplicate values removed.\n\n    Parameters\n    ----------\n    keep : {'first', 'last', ``False``}, default 'first'\n        - 'first' : Drop duplicates except for the first occurrence.\n        - 'last' : Drop duplicates except for the last occurrence.\n        - ``False`` : Drop all duplicates.\n    inplace : bool, default ``False``\n        If ``True``, performs operation inplace and returns None.\n\n    Returns\n    -------\n    Series\n        Series with duplicates dropped.\n\n    See Also\n    --------\n    Index.drop_duplicates : Equivalent method on Index.\n    DataFrame.drop_duplicates : Equivalent method on DataFrame.\n    Series.duplicated : Related method on Series, indicating duplicate\n        Series values.\n\n    Examples\n    --------\n    Generate a Series with duplicated entries.\n\n    >>> s = pd.Series(['lama', 'cow', 'lama', 'beetle', 'lama', 'hippo'],\n    ...               name='animal')\n    >>> s\n    0      lama\n    1       cow\n    2      lama\n    3    beetle\n    4      lama\n    5     hippo\n    Name: animal, dtype: object\n\n    With the 'keep' parameter, the selection behaviour of duplicated values\n    can be changed. The value 'first' keeps the first occurrence for each\n    set of duplicated entries. The default value of keep is 'first'.\n\n    >>> s.drop_duplicates()\n    0      lama\n    1       cow\n    3    beetle\n    5     hippo\n    Name: animal, dtype: object\n\n    The value 'last' for parameter 'keep' keeps the last occurrence for\n    each set of duplicated entries.\n\n    >>> s.drop_duplicates(keep='last')\n    1       cow\n    3    beetle\n    4      lama\n    5     hippo\n    Name: animal, dtype: object\n\n    The value ``False`` for parameter 'keep' discards all sets of\n    duplicated entries. Setting the value of 'inplace' to ``True`` performs\n    the operation inplace and returns ``None``.\n\n    >>> s.drop_duplicates(keep=False, inplace=True)\n    >>> s\n    1       cow\n    3    beetle\n    5     hippo\n    Name: animal, dtype: object\n    \"\"\"\n    return super().drop_duplicates(keep=keep, inplace=inplace)",
                            "def duplicated(self, keep='first'):\n    \"\"\"\n    Indicate duplicate Series values.\n\n    Duplicated values are indicated as ``True`` values in the resulting\n    Series. Either all duplicates, all except the first or all except the\n    last occurrence of duplicates can be indicated.\n\n    Parameters\n    ----------\n    keep : {'first', 'last', False}, default 'first'\n        - 'first' : Mark duplicates as ``True`` except for the first\n          occurrence.\n        - 'last' : Mark duplicates as ``True`` except for the last\n          occurrence.\n        - ``False`` : Mark all duplicates as ``True``.\n\n    Returns\n    -------\n    Series\n        Series indicating whether each value has occurred in the\n        preceding values.\n\n    See Also\n    --------\n    Index.duplicated : Equivalent method on pandas.Index.\n    DataFrame.duplicated : Equivalent method on pandas.DataFrame.\n    Series.drop_duplicates : Remove duplicate values from Series.\n\n    Examples\n    --------\n    By default, for each set of duplicated values, the first occurrence is\n    set on False and all others on True:\n\n    >>> animals = pd.Series(['lama', 'cow', 'lama', 'beetle', 'lama'])\n    >>> animals.duplicated()\n    0    False\n    1    False\n    2     True\n    3    False\n    4     True\n    dtype: bool\n\n    which is equivalent to\n\n    >>> animals.duplicated(keep='first')\n    0    False\n    1    False\n    2     True\n    3    False\n    4     True\n    dtype: bool\n\n    By using 'last', the last occurrence of each set of duplicated values\n    is set on False and all others on True:\n\n    >>> animals.duplicated(keep='last')\n    0     True\n    1    False\n    2     True\n    3    False\n    4    False\n    dtype: bool\n\n    By setting keep on ``False``, all duplicates are True:\n\n    >>> animals.duplicated(keep=False)\n    0     True\n    1    False\n    2     True\n    3    False\n    4     True\n    dtype: bool\n    \"\"\"\n    return super().duplicated(keep=keep)",
                            "def idxmin(self, axis=0, skipna=True, *args, **kwargs):\n    \"\"\"\n    Return the row label of the minimum value.\n\n    If multiple values equal the minimum, the first row label with that\n    value is returned.\n\n    Parameters\n    ----------\n    skipna : bool, default True\n        Exclude NA/null values. If the entire Series is NA, the result\n        will be NA.\n    axis : int, default 0\n        For compatibility with DataFrame.idxmin. Redundant for application\n        on Series.\n    *args, **kwargs\n        Additional keywords have no effect but might be accepted\n        for compatibility with NumPy.\n\n    Returns\n    -------\n    Index\n        Label of the minimum value.\n\n    Raises\n    ------\n    ValueError\n        If the Series is empty.\n\n    See Also\n    --------\n    numpy.argmin : Return indices of the minimum values\n        along the given axis.\n    DataFrame.idxmin : Return index of first occurrence of minimum\n        over requested axis.\n    Series.idxmax : Return index *label* of the first occurrence\n        of maximum of values.\n\n    Notes\n    -----\n    This method is the Series version of ``ndarray.argmin``. This method\n    returns the label of the minimum, while ``ndarray.argmin`` returns\n    the position. To get the position, use ``series.values.argmin()``.\n\n    Examples\n    --------\n    >>> s = pd.Series(data=[1, None, 4, 1],\n    ...               index=['A', 'B', 'C', 'D'])\n    >>> s\n    A    1.0\n    B    NaN\n    C    4.0\n    D    1.0\n    dtype: float64\n\n    >>> s.idxmin()\n    'A'\n\n    If `skipna` is False and there is an NA value in the data,\n    the function returns ``nan``.\n\n    >>> s.idxmin(skipna=False)\n    nan\n    \"\"\"\n    skipna = nv.validate_argmin_with_skipna(skipna, args, kwargs)\n    i = nanops.nanargmin(com.values_from_object(self), skipna=skipna)\n    if i == -1:\n        return np.nan\n    return self.index[i]",
                            "def idxmax(self, axis=0, skipna=True, *args, **kwargs):\n    \"\"\"\n    Return the row label of the maximum value.\n\n    If multiple values equal the maximum, the first row label with that\n    value is returned.\n\n    Parameters\n    ----------\n    skipna : bool, default True\n        Exclude NA/null values. If the entire Series is NA, the result\n        will be NA.\n    axis : int, default 0\n        For compatibility with DataFrame.idxmax. Redundant for application\n        on Series.\n    *args, **kwargs\n        Additional keywords have no effect but might be accepted\n        for compatibility with NumPy.\n\n    Returns\n    -------\n    Index\n        Label of the maximum value.\n\n    Raises\n    ------\n    ValueError\n        If the Series is empty.\n\n    See Also\n    --------\n    numpy.argmax : Return indices of the maximum values\n        along the given axis.\n    DataFrame.idxmax : Return index of first occurrence of maximum\n        over requested axis.\n    Series.idxmin : Return index *label* of the first occurrence\n        of minimum of values.\n\n    Notes\n    -----\n    This method is the Series version of ``ndarray.argmax``. This method\n    returns the label of the maximum, while ``ndarray.argmax`` returns\n    the position. To get the position, use ``series.values.argmax()``.\n\n    Examples\n    --------\n    >>> s = pd.Series(data=[1, None, 4, 3, 4],\n    ...               index=['A', 'B', 'C', 'D', 'E'])\n    >>> s\n    A    1.0\n    B    NaN\n    C    4.0\n    D    3.0\n    E    4.0\n    dtype: float64\n\n    >>> s.idxmax()\n    'C'\n\n    If `skipna` is False and there is an NA value in the data,\n    the function returns ``nan``.\n\n    >>> s.idxmax(skipna=False)\n    nan\n    \"\"\"\n    skipna = nv.validate_argmax_with_skipna(skipna, args, kwargs)\n    i = nanops.nanargmax(com.values_from_object(self), skipna=skipna)\n    if i == -1:\n        return np.nan\n    return self.index[i]",
                            "def round(self, decimals=0, *args, **kwargs):\n    \"\"\"\n    Round each value in a Series to the given number of decimals.\n\n    Parameters\n    ----------\n    decimals : int\n        Number of decimal places to round to (default: 0).\n        If decimals is negative, it specifies the number of\n        positions to the left of the decimal point.\n\n    Returns\n    -------\n    Series\n        Rounded values of the Series.\n\n    See Also\n    --------\n    numpy.around : Round values of an np.array.\n    DataFrame.round : Round values of a DataFrame.\n\n    Examples\n    --------\n    >>> s = pd.Series([0.1, 1.3, 2.7])\n    >>> s.round()\n    0    0.0\n    1    1.0\n    2    3.0\n    dtype: float64\n    \"\"\"\n    nv.validate_round(args, kwargs)\n    result = com.values_from_object(self).round(decimals)\n    result = self._constructor(result, index=self.index).__finalize__(self)\n    return result",
                            "def quantile(self, q=0.5, interpolation='linear'):\n    \"\"\"\n    Return value at the given quantile.\n\n    Parameters\n    ----------\n    q : float or array-like, default 0.5 (50% quantile)\n        0 <= q <= 1, the quantile(s) to compute.\n    interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}\n        This optional parameter specifies the interpolation method to use,\n        when the desired quantile lies between two data points `i` and `j`:\n\n            * linear: `i + (j - i) * fraction`, where `fraction` is the\n              fractional part of the index surrounded by `i` and `j`.\n            * lower: `i`.\n            * higher: `j`.\n            * nearest: `i` or `j` whichever is nearest.\n            * midpoint: (`i` + `j`) / 2.\n\n    Returns\n    -------\n    float or Series\n        If ``q`` is an array, a Series will be returned where the\n        index is ``q`` and the values are the quantiles, otherwise\n        a float will be returned.\n\n    See Also\n    --------\n    core.window.Rolling.quantile\n    numpy.percentile\n\n    Examples\n    --------\n    >>> s = pd.Series([1, 2, 3, 4])\n    >>> s.quantile(.5)\n    2.5\n    >>> s.quantile([.25, .5, .75])\n    0.25    1.75\n    0.50    2.50\n    0.75    3.25\n    dtype: float64\n    \"\"\"\n    self._check_percentile(q)\n    df = self.to_frame()\n    result = df.quantile(q=q, interpolation=interpolation, numeric_only=False)\n    if result.ndim == 2:\n        result = result.iloc[:, 0]\n    if is_list_like(q):\n        result.name = self.name\n        return self._constructor(result, index=Float64Index(q), name=self.name)\n    else:\n        return result.iloc[0]",
                            "def corr(self, other, method='pearson', min_periods=None):\n    \"\"\"\n    Compute correlation with `other` Series, excluding missing values.\n\n    Parameters\n    ----------\n    other : Series\n        Series with which to compute the correlation.\n    method : {'pearson', 'kendall', 'spearman'} or callable\n        * pearson : standard correlation coefficient\n        * kendall : Kendall Tau correlation coefficient\n        * spearman : Spearman rank correlation\n        * callable: callable with input two 1d ndarrays\n            and returning a float. Note that the returned matrix from corr\n            will have 1 along the diagonals and will be symmetric\n            regardless of the callable's behavior\n            .. versionadded:: 0.24.0\n\n    min_periods : int, optional\n        Minimum number of observations needed to have a valid result.\n\n    Returns\n    -------\n    float\n        Correlation with other.\n\n    Examples\n    --------\n    >>> def histogram_intersection(a, b):\n    ...     v = np.minimum(a, b).sum().round(decimals=1)\n    ...     return v\n    >>> s1 = pd.Series([.2, .0, .6, .2])\n    >>> s2 = pd.Series([.3, .6, .0, .1])\n    >>> s1.corr(s2, method=histogram_intersection)\n    0.3\n    \"\"\"\n    (this, other) = self.align(other, join='inner', copy=False)\n    if len(this) == 0:\n        return np.nan\n    if method in ['pearson', 'spearman', 'kendall'] or callable(method):\n        return nanops.nancorr(this.values, other.values, method=method, min_periods=min_periods)\n    raise ValueError(\"method must be either 'pearson', 'spearman', 'kendall', or a callable, '{method}' was supplied\".format(method=method))",
                            "def cov(self, other, min_periods=None):\n    \"\"\"\n    Compute covariance with Series, excluding missing values.\n\n    Parameters\n    ----------\n    other : Series\n        Series with which to compute the covariance.\n    min_periods : int, optional\n        Minimum number of observations needed to have a valid result.\n\n    Returns\n    -------\n    float\n        Covariance between Series and other normalized by N-1\n        (unbiased estimator).\n\n    Examples\n    --------\n    >>> s1 = pd.Series([0.90010907, 0.13484424, 0.62036035])\n    >>> s2 = pd.Series([0.12528585, 0.26962463, 0.51111198])\n    >>> s1.cov(s2)\n    -0.01685762652715874\n    \"\"\"\n    (this, other) = self.align(other, join='inner', copy=False)\n    if len(this) == 0:\n        return np.nan\n    return nanops.nancov(this.values, other.values, min_periods=min_periods)",
                            "def diff(self, periods=1):\n    \"\"\"\n    First discrete difference of element.\n\n    Calculates the difference of a Series element compared with another\n    element in the Series (default is element in previous row).\n\n    Parameters\n    ----------\n    periods : int, default 1\n        Periods to shift for calculating difference, accepts negative\n        values.\n\n    Returns\n    -------\n    Series\n        First differences of the Series.\n\n    See Also\n    --------\n    Series.pct_change: Percent change over given number of periods.\n    Series.shift: Shift index by desired number of periods with an\n        optional time freq.\n    DataFrame.diff: First discrete difference of object.\n\n    Examples\n    --------\n    Difference with previous row\n\n    >>> s = pd.Series([1, 1, 2, 3, 5, 8])\n    >>> s.diff()\n    0    NaN\n    1    0.0\n    2    1.0\n    3    1.0\n    4    2.0\n    5    3.0\n    dtype: float64\n\n    Difference with 3rd previous row\n\n    >>> s.diff(periods=3)\n    0    NaN\n    1    NaN\n    2    NaN\n    3    2.0\n    4    4.0\n    5    6.0\n    dtype: float64\n\n    Difference with following row\n\n    >>> s.diff(periods=-1)\n    0    0.0\n    1   -1.0\n    2   -1.0\n    3   -2.0\n    4   -3.0\n    5    NaN\n    dtype: float64\n    \"\"\"\n    result = algorithms.diff(com.values_from_object(self), periods)\n    return self._constructor(result, index=self.index).__finalize__(self)",
                            "def autocorr(self, lag=1):\n    \"\"\"\n    Compute the lag-N autocorrelation.\n\n    This method computes the Pearson correlation between\n    the Series and its shifted self.\n\n    Parameters\n    ----------\n    lag : int, default 1\n        Number of lags to apply before performing autocorrelation.\n\n    Returns\n    -------\n    float\n        The Pearson correlation between self and self.shift(lag).\n\n    See Also\n    --------\n    Series.corr : Compute the correlation between two Series.\n    Series.shift : Shift index by desired number of periods.\n    DataFrame.corr : Compute pairwise correlation of columns.\n    DataFrame.corrwith : Compute pairwise correlation between rows or\n        columns of two DataFrame objects.\n\n    Notes\n    -----\n    If the Pearson correlation is not well defined return 'NaN'.\n\n    Examples\n    --------\n    >>> s = pd.Series([0.25, 0.5, 0.2, -0.05])\n    >>> s.autocorr()  # doctest: +ELLIPSIS\n    0.10355...\n    >>> s.autocorr(lag=2)  # doctest: +ELLIPSIS\n    -0.99999...\n\n    If the Pearson correlation is not well defined, then 'NaN' is returned.\n\n    >>> s = pd.Series([1, 0, 0, 0])\n    >>> s.autocorr()\n    nan\n    \"\"\"\n    return self.corr(self.shift(lag))",
                            "def dot(self, other):\n    \"\"\"\n    Compute the dot product between the Series and the columns of other.\n\n    This method computes the dot product between the Series and another\n    one, or the Series and each columns of a DataFrame, or the Series and\n    each columns of an array.\n\n    It can also be called using `self @ other` in Python >= 3.5.\n\n    Parameters\n    ----------\n    other : Series, DataFrame or array-like\n        The other object to compute the dot product with its columns.\n\n    Returns\n    -------\n    scalar, Series or numpy.ndarray\n        Return the dot product of the Series and other if other is a\n        Series, the Series of the dot product of Series and each rows of\n        other if other is a DataFrame or a numpy.ndarray between the Series\n        and each columns of the numpy array.\n\n    See Also\n    --------\n    DataFrame.dot: Compute the matrix product with the DataFrame.\n    Series.mul: Multiplication of series and other, element-wise.\n\n    Notes\n    -----\n    The Series and other has to share the same index if other is a Series\n    or a DataFrame.\n\n    Examples\n    --------\n    >>> s = pd.Series([0, 1, 2, 3])\n    >>> other = pd.Series([-1, 2, -3, 4])\n    >>> s.dot(other)\n    8\n    >>> s @ other\n    8\n    >>> df = pd.DataFrame([[0, 1], [-2, 3], [4, -5], [6, 7]])\n    >>> s.dot(df)\n    0    24\n    1    14\n    dtype: int64\n    >>> arr = np.array([[0, 1], [-2, 3], [4, -5], [6, 7]])\n    >>> s.dot(arr)\n    array([24, 14])\n    \"\"\"\n    if isinstance(other, (Series, ABCDataFrame)):\n        common = self.index.union(other.index)\n        if len(common) > len(self.index) or len(common) > len(other.index):\n            raise ValueError('matrices are not aligned')\n        left = self.reindex(index=common, copy=False)\n        right = other.reindex(index=common, copy=False)\n        lvals = left.values\n        rvals = right.values\n    else:\n        lvals = self.values\n        rvals = np.asarray(other)\n        if lvals.shape[0] != rvals.shape[0]:\n            raise Exception('Dot product shape mismatch, %s vs %s' % (lvals.shape, rvals.shape))\n    if isinstance(other, ABCDataFrame):\n        return self._constructor(np.dot(lvals, rvals), index=other.columns).__finalize__(self)\n    elif isinstance(other, Series):\n        return np.dot(lvals, rvals)\n    elif isinstance(rvals, np.ndarray):\n        return np.dot(lvals, rvals)\n    else:\n        raise TypeError('unsupported type: %s' % type(other))",
                            "def __matmul__(self, other):\n    \"\"\"\n    Matrix multiplication using binary `@` operator in Python>=3.5.\n    \"\"\"\n    return self.dot(other)",
                            "def __rmatmul__(self, other):\n    \"\"\"\n    Matrix multiplication using binary `@` operator in Python>=3.5.\n    \"\"\"\n    return self.dot(np.transpose(other))",
                            "@Substitution(klass='Series')\n@Appender(base._shared_docs['searchsorted'])\ndef searchsorted(self, value, side='left', sorter=None):\n    return algorithms.searchsorted(self._values, value, side=side, sorter=sorter)",
                            "def append(self, to_append, ignore_index=False, verify_integrity=False):\n    \"\"\"\n    Concatenate two or more Series.\n\n    Parameters\n    ----------\n    to_append : Series or list/tuple of Series\n        Series to append with self.\n    ignore_index : bool, default False\n        If True, do not use the index labels.\n    verify_integrity : bool, default False\n        If True, raise Exception on creating index with duplicates.\n\n    Returns\n    -------\n    Series\n        Concatenated Series.\n\n    See Also\n    --------\n    concat : General function to concatenate DataFrame or Series objects.\n\n    Notes\n    -----\n    Iteratively appending to a Series can be more computationally intensive\n    than a single concatenate. A better solution is to append values to a\n    list and then concatenate the list with the original Series all at\n    once.\n\n    Examples\n    --------\n    >>> s1 = pd.Series([1, 2, 3])\n    >>> s2 = pd.Series([4, 5, 6])\n    >>> s3 = pd.Series([4, 5, 6], index=[3, 4, 5])\n    >>> s1.append(s2)\n    0    1\n    1    2\n    2    3\n    0    4\n    1    5\n    2    6\n    dtype: int64\n\n    >>> s1.append(s3)\n    0    1\n    1    2\n    2    3\n    3    4\n    4    5\n    5    6\n    dtype: int64\n\n    With `ignore_index` set to True:\n\n    >>> s1.append(s2, ignore_index=True)\n    0    1\n    1    2\n    2    3\n    3    4\n    4    5\n    5    6\n    dtype: int64\n\n    With `verify_integrity` set to True:\n\n    >>> s1.append(s2, verify_integrity=True)\n    Traceback (most recent call last):\n    ...\n    ValueError: Indexes have overlapping values: [0, 1, 2]\n    \"\"\"\n    from pandas.core.reshape.concat import concat\n    if isinstance(to_append, (list, tuple)):\n        to_concat = [self] + to_append\n    else:\n        to_concat = [self, to_append]\n    return concat(to_concat, ignore_index=ignore_index, verify_integrity=verify_integrity)",
                            "def _binop(self, other, func, level=None, fill_value=None):\n    \"\"\"\n    Perform generic binary operation with optional fill value.\n\n    Parameters\n    ----------\n    other : Series\n    func : binary operator\n    fill_value : float or object\n        Value to substitute for NA/null values. If both Series are NA in a\n        location, the result will be NA regardless of the passed fill value\n    level : int or level name, default None\n        Broadcast across a level, matching Index values on the\n        passed MultiIndex level\n\n    Returns\n    -------\n    Series\n    \"\"\"\n    if not isinstance(other, Series):\n        raise AssertionError('Other operand must be Series')\n    new_index = self.index\n    this = self\n    if not self.index.equals(other.index):\n        (this, other) = self.align(other, level=level, join='outer', copy=False)\n        new_index = this.index\n    (this_vals, other_vals) = ops.fill_binop(this.values, other.values, fill_value)\n    with np.errstate(all='ignore'):\n        result = func(this_vals, other_vals)\n    name = ops.get_op_result_name(self, other)\n    if func.__name__ in ['divmod', 'rdivmod']:\n        ret = ops._construct_divmod_result(self, result, new_index, name)\n    else:\n        ret = ops._construct_result(self, result, new_index, name)\n    return ret",
                            "def combine(self, other, func, fill_value=None):\n    \"\"\"\n    Combine the Series with a Series or scalar according to `func`.\n\n    Combine the Series and `other` using `func` to perform elementwise\n    selection for combined Series.\n    `fill_value` is assumed when value is missing at some index\n    from one of the two objects being combined.\n\n    Parameters\n    ----------\n    other : Series or scalar\n        The value(s) to be combined with the `Series`.\n    func : function\n        Function that takes two scalars as inputs and returns an element.\n    fill_value : scalar, optional\n        The value to assume when an index is missing from\n        one Series or the other. The default specifies to use the\n        appropriate NaN value for the underlying dtype of the Series.\n\n    Returns\n    -------\n    Series\n        The result of combining the Series with the other object.\n\n    See Also\n    --------\n    Series.combine_first : Combine Series values, choosing the calling\n        Series' values first.\n\n    Examples\n    --------\n    Consider 2 Datasets ``s1`` and ``s2`` containing\n    highest clocked speeds of different birds.\n\n    >>> s1 = pd.Series({'falcon': 330.0, 'eagle': 160.0})\n    >>> s1\n    falcon    330.0\n    eagle     160.0\n    dtype: float64\n    >>> s2 = pd.Series({'falcon': 345.0, 'eagle': 200.0, 'duck': 30.0})\n    >>> s2\n    falcon    345.0\n    eagle     200.0\n    duck       30.0\n    dtype: float64\n\n    Now, to combine the two datasets and view the highest speeds\n    of the birds across the two datasets\n\n    >>> s1.combine(s2, max)\n    duck        NaN\n    eagle     200.0\n    falcon    345.0\n    dtype: float64\n\n    In the previous example, the resulting value for duck is missing,\n    because the maximum of a NaN and a float is a NaN.\n    So, in the example, we set ``fill_value=0``,\n    so the maximum value returned will be the value from some dataset.\n\n    >>> s1.combine(s2, max, fill_value=0)\n    duck       30.0\n    eagle     200.0\n    falcon    345.0\n    dtype: float64\n    \"\"\"\n    if fill_value is None:\n        fill_value = na_value_for_dtype(self.dtype, compat=False)\n    if isinstance(other, Series):\n        new_index = self.index.union(other.index)\n        new_name = ops.get_op_result_name(self, other)\n        new_values = []\n        for idx in new_index:\n            lv = self.get(idx, fill_value)\n            rv = other.get(idx, fill_value)\n            with np.errstate(all='ignore'):\n                new_values.append(func(lv, rv))\n    else:\n        new_index = self.index\n        with np.errstate(all='ignore'):\n            new_values = [func(lv, other) for lv in self._values]\n        new_name = self.name\n    if is_categorical_dtype(self.values):\n        pass\n    elif is_extension_array_dtype(self.values):\n        try:\n            new_values = self._values._from_sequence(new_values)\n        except Exception:\n            pass\n    return self._constructor(new_values, index=new_index, name=new_name)",
                            "def combine_first(self, other):\n    \"\"\"\n    Combine Series values, choosing the calling Series's values first.\n\n    Parameters\n    ----------\n    other : Series\n        The value(s) to be combined with the `Series`.\n\n    Returns\n    -------\n    Series\n        The result of combining the Series with the other object.\n\n    See Also\n    --------\n    Series.combine : Perform elementwise operation on two Series\n        using a given function.\n\n    Notes\n    -----\n    Result index will be the union of the two indexes.\n\n    Examples\n    --------\n    >>> s1 = pd.Series([1, np.nan])\n    >>> s2 = pd.Series([3, 4])\n    >>> s1.combine_first(s2)\n    0    1.0\n    1    4.0\n    dtype: float64\n    \"\"\"\n    new_index = self.index.union(other.index)\n    this = self.reindex(new_index, copy=False)\n    other = other.reindex(new_index, copy=False)\n    if is_datetimelike(this) and (not is_datetimelike(other)):\n        other = to_datetime(other)\n    return this.where(notna(this), other)",
                            "def update(self, other):\n    \"\"\"\n    Modify Series in place using non-NA values from passed\n    Series. Aligns on index.\n\n    Parameters\n    ----------\n    other : Series\n\n    Examples\n    --------\n    >>> s = pd.Series([1, 2, 3])\n    >>> s.update(pd.Series([4, 5, 6]))\n    >>> s\n    0    4\n    1    5\n    2    6\n    dtype: int64\n\n    >>> s = pd.Series(['a', 'b', 'c'])\n    >>> s.update(pd.Series(['d', 'e'], index=[0, 2]))\n    >>> s\n    0    d\n    1    b\n    2    e\n    dtype: object\n\n    >>> s = pd.Series([1, 2, 3])\n    >>> s.update(pd.Series([4, 5, 6, 7, 8]))\n    >>> s\n    0    4\n    1    5\n    2    6\n    dtype: int64\n\n    If ``other`` contains NaNs the corresponding values are not updated\n    in the original Series.\n\n    >>> s = pd.Series([1, 2, 3])\n    >>> s.update(pd.Series([4, np.nan, 6]))\n    >>> s\n    0    4\n    1    2\n    2    6\n    dtype: int64\n    \"\"\"\n    other = other.reindex_like(self)\n    mask = notna(other)\n    self._data = self._data.putmask(mask=mask, new=other, inplace=True)\n    self._maybe_update_cacher()",
                            "def sort_values(self, axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last'):\n    \"\"\"\n    Sort by the values.\n\n    Sort a Series in ascending or descending order by some\n    criterion.\n\n    Parameters\n    ----------\n    axis : {0 or 'index'}, default 0\n        Axis to direct sorting. The value 'index' is accepted for\n        compatibility with DataFrame.sort_values.\n    ascending : bool, default True\n        If True, sort values in ascending order, otherwise descending.\n    inplace : bool, default False\n        If True, perform operation in-place.\n    kind : {'quicksort', 'mergesort' or 'heapsort'}, default 'quicksort'\n        Choice of sorting algorithm. See also :func:`numpy.sort` for more\n        information. 'mergesort' is the only stable  algorithm.\n    na_position : {'first' or 'last'}, default 'last'\n        Argument 'first' puts NaNs at the beginning, 'last' puts NaNs at\n        the end.\n\n    Returns\n    -------\n    Series\n        Series ordered by values.\n\n    See Also\n    --------\n    Series.sort_index : Sort by the Series indices.\n    DataFrame.sort_values : Sort DataFrame by the values along either axis.\n    DataFrame.sort_index : Sort DataFrame by indices.\n\n    Examples\n    --------\n    >>> s = pd.Series([np.nan, 1, 3, 10, 5])\n    >>> s\n    0     NaN\n    1     1.0\n    2     3.0\n    3     10.0\n    4     5.0\n    dtype: float64\n\n    Sort values ascending order (default behaviour)\n\n    >>> s.sort_values(ascending=True)\n    1     1.0\n    2     3.0\n    4     5.0\n    3    10.0\n    0     NaN\n    dtype: float64\n\n    Sort values descending order\n\n    >>> s.sort_values(ascending=False)\n    3    10.0\n    4     5.0\n    2     3.0\n    1     1.0\n    0     NaN\n    dtype: float64\n\n    Sort values inplace\n\n    >>> s.sort_values(ascending=False, inplace=True)\n    >>> s\n    3    10.0\n    4     5.0\n    2     3.0\n    1     1.0\n    0     NaN\n    dtype: float64\n\n    Sort values putting NAs first\n\n    >>> s.sort_values(na_position='first')\n    0     NaN\n    1     1.0\n    2     3.0\n    4     5.0\n    3    10.0\n    dtype: float64\n\n    Sort a series of strings\n\n    >>> s = pd.Series(['z', 'b', 'd', 'a', 'c'])\n    >>> s\n    0    z\n    1    b\n    2    d\n    3    a\n    4    c\n    dtype: object\n\n    >>> s.sort_values()\n    3    a\n    1    b\n    4    c\n    2    d\n    0    z\n    dtype: object\n    \"\"\"\n    inplace = validate_bool_kwarg(inplace, 'inplace')\n    self._get_axis_number(axis)\n    if inplace and self._is_cached:\n        raise ValueError('This Series is a view of some other array, to sort in-place you must create a copy')\n\n    def _try_kind_sort(arr):\n        try:\n            return arr.argsort(kind=kind)\n        except TypeError:\n            return arr.argsort(kind='quicksort')\n    arr = self._values\n    sortedIdx = np.empty(len(self), dtype=np.int32)\n    bad = isna(arr)\n    good = ~bad\n    idx = ibase.default_index(len(self))\n    argsorted = _try_kind_sort(arr[good])\n    if is_list_like(ascending):\n        if len(ascending) != 1:\n            raise ValueError('Length of ascending (%d) must be 1 for Series' % len(ascending))\n        ascending = ascending[0]\n    if not is_bool(ascending):\n        raise ValueError('ascending must be boolean')\n    if not ascending:\n        argsorted = argsorted[::-1]\n    if na_position == 'last':\n        n = good.sum()\n        sortedIdx[:n] = idx[good][argsorted]\n        sortedIdx[n:] = idx[bad]\n    elif na_position == 'first':\n        n = bad.sum()\n        sortedIdx[n:] = idx[good][argsorted]\n        sortedIdx[:n] = idx[bad]\n    else:\n        raise ValueError('invalid na_position: {!r}'.format(na_position))\n    result = self._constructor(arr[sortedIdx], index=self.index[sortedIdx])\n    if inplace:\n        self._update_inplace(result)\n    else:\n        return result.__finalize__(self)",
                            "def sort_index(self, axis=0, level=None, ascending=True, inplace=False, kind='quicksort', na_position='last', sort_remaining=True):\n    \"\"\"\n    Sort Series by index labels.\n\n    Returns a new Series sorted by label if `inplace` argument is\n    ``False``, otherwise updates the original series and returns None.\n\n    Parameters\n    ----------\n    axis : int, default 0\n        Axis to direct sorting. This can only be 0 for Series.\n    level : int, optional\n        If not None, sort on values in specified index level(s).\n    ascending : bool, default true\n        Sort ascending vs. descending.\n    inplace : bool, default False\n        If True, perform operation in-place.\n    kind : {'quicksort', 'mergesort', 'heapsort'}, default 'quicksort'\n        Choice of sorting algorithm. See also :func:`numpy.sort` for more\n        information.  'mergesort' is the only stable algorithm. For\n        DataFrames, this option is only applied when sorting on a single\n        column or label.\n    na_position : {'first', 'last'}, default 'last'\n        If 'first' puts NaNs at the beginning, 'last' puts NaNs at the end.\n        Not implemented for MultiIndex.\n    sort_remaining : bool, default True\n        If True and sorting by level and index is multilevel, sort by other\n        levels too (in order) after sorting by specified level.\n\n    Returns\n    -------\n    Series\n        The original Series sorted by the labels.\n\n    See Also\n    --------\n    DataFrame.sort_index: Sort DataFrame by the index.\n    DataFrame.sort_values: Sort DataFrame by the value.\n    Series.sort_values : Sort Series by the value.\n\n    Examples\n    --------\n    >>> s = pd.Series(['a', 'b', 'c', 'd'], index=[3, 2, 1, 4])\n    >>> s.sort_index()\n    1    c\n    2    b\n    3    a\n    4    d\n    dtype: object\n\n    Sort Descending\n\n    >>> s.sort_index(ascending=False)\n    4    d\n    3    a\n    2    b\n    1    c\n    dtype: object\n\n    Sort Inplace\n\n    >>> s.sort_index(inplace=True)\n    >>> s\n    1    c\n    2    b\n    3    a\n    4    d\n    dtype: object\n\n    By default NaNs are put at the end, but use `na_position` to place\n    them at the beginning\n\n    >>> s = pd.Series(['a', 'b', 'c', 'd'], index=[3, 2, 1, np.nan])\n    >>> s.sort_index(na_position='first')\n    NaN     d\n     1.0    c\n     2.0    b\n     3.0    a\n    dtype: object\n\n    Specify index level to sort\n\n    >>> arrays = [np.array(['qux', 'qux', 'foo', 'foo',\n    ...                     'baz', 'baz', 'bar', 'bar']),\n    ...           np.array(['two', 'one', 'two', 'one',\n    ...                     'two', 'one', 'two', 'one'])]\n    >>> s = pd.Series([1, 2, 3, 4, 5, 6, 7, 8], index=arrays)\n    >>> s.sort_index(level=1)\n    bar  one    8\n    baz  one    6\n    foo  one    4\n    qux  one    2\n    bar  two    7\n    baz  two    5\n    foo  two    3\n    qux  two    1\n    dtype: int64\n\n    Does not sort by remaining levels when sorting by levels\n\n    >>> s.sort_index(level=1, sort_remaining=False)\n    qux  one    2\n    foo  one    4\n    baz  one    6\n    bar  one    8\n    qux  two    1\n    foo  two    3\n    baz  two    5\n    bar  two    7\n    dtype: int64\n    \"\"\"\n    inplace = validate_bool_kwarg(inplace, 'inplace')\n    self._get_axis_number(axis)\n    index = self.index\n    if level is not None:\n        (new_index, indexer) = index.sortlevel(level, ascending=ascending, sort_remaining=sort_remaining)\n    elif isinstance(index, MultiIndex):\n        from pandas.core.sorting import lexsort_indexer\n        labels = index._sort_levels_monotonic()\n        indexer = lexsort_indexer(labels._get_codes_for_sorting(), orders=ascending, na_position=na_position)\n    else:\n        from pandas.core.sorting import nargsort\n        if ascending and index.is_monotonic_increasing or (not ascending and index.is_monotonic_decreasing):\n            if inplace:\n                return\n            else:\n                return self.copy()\n        indexer = nargsort(index, kind=kind, ascending=ascending, na_position=na_position)\n    indexer = ensure_platform_int(indexer)\n    new_index = index.take(indexer)\n    new_index = new_index._sort_levels_monotonic()\n    new_values = self._values.take(indexer)\n    result = self._constructor(new_values, index=new_index)\n    if inplace:\n        self._update_inplace(result)\n    else:\n        return result.__finalize__(self)",
                            "def argsort(self, axis=0, kind='quicksort', order=None):\n    \"\"\"\n    Override ndarray.argsort. Argsorts the value, omitting NA/null values,\n    and places the result in the same locations as the non-NA values.\n\n    Parameters\n    ----------\n    axis : int\n        Has no effect but is accepted for compatibility with numpy.\n    kind : {'mergesort', 'quicksort', 'heapsort'}, default 'quicksort'\n        Choice of sorting algorithm. See np.sort for more\n        information. 'mergesort' is the only stable algorithm\n    order : None\n        Has no effect but is accepted for compatibility with numpy.\n\n    Returns\n    -------\n    Series\n        Positions of values within the sort order with -1 indicating\n        nan values.\n\n    See Also\n    --------\n    numpy.ndarray.argsort\n    \"\"\"\n    values = self._values\n    mask = isna(values)\n    if mask.any():\n        result = Series(-1, index=self.index, name=self.name, dtype='int64')\n        notmask = ~mask\n        result[notmask] = np.argsort(values[notmask], kind=kind)\n        return self._constructor(result, index=self.index).__finalize__(self)\n    else:\n        return self._constructor(np.argsort(values, kind=kind), index=self.index, dtype='int64').__finalize__(self)",
                            "def nlargest(self, n=5, keep='first'):\n    \"\"\"\n    Return the largest `n` elements.\n\n    Parameters\n    ----------\n    n : int, default 5\n        Return this many descending sorted values.\n    keep : {'first', 'last', 'all'}, default 'first'\n        When there are duplicate values that cannot all fit in a\n        Series of `n` elements:\n\n        - ``first`` : return the first `n` occurrences in order\n            of appearance.\n        - ``last`` : return the last `n` occurrences in reverse\n            order of appearance.\n        - ``all`` : keep all occurrences. This can result in a Series of\n            size larger than `n`.\n\n    Returns\n    -------\n    Series\n        The `n` largest values in the Series, sorted in decreasing order.\n\n    See Also\n    --------\n    Series.nsmallest: Get the `n` smallest elements.\n    Series.sort_values: Sort Series by values.\n    Series.head: Return the first `n` rows.\n\n    Notes\n    -----\n    Faster than ``.sort_values(ascending=False).head(n)`` for small `n`\n    relative to the size of the ``Series`` object.\n\n    Examples\n    --------\n    >>> countries_population = {\"Italy\": 59000000, \"France\": 65000000,\n    ...                         \"Malta\": 434000, \"Maldives\": 434000,\n    ...                         \"Brunei\": 434000, \"Iceland\": 337000,\n    ...                         \"Nauru\": 11300, \"Tuvalu\": 11300,\n    ...                         \"Anguilla\": 11300, \"Monserat\": 5200}\n    >>> s = pd.Series(countries_population)\n    >>> s\n    Italy       59000000\n    France      65000000\n    Malta         434000\n    Maldives      434000\n    Brunei        434000\n    Iceland       337000\n    Nauru          11300\n    Tuvalu         11300\n    Anguilla       11300\n    Monserat        5200\n    dtype: int64\n\n    The `n` largest elements where ``n=5`` by default.\n\n    >>> s.nlargest()\n    France      65000000\n    Italy       59000000\n    Malta         434000\n    Maldives      434000\n    Brunei        434000\n    dtype: int64\n\n    The `n` largest elements where ``n=3``. Default `keep` value is 'first'\n    so Malta will be kept.\n\n    >>> s.nlargest(3)\n    France    65000000\n    Italy     59000000\n    Malta       434000\n    dtype: int64\n\n    The `n` largest elements where ``n=3`` and keeping the last duplicates.\n    Brunei will be kept since it is the last with value 434000 based on\n    the index order.\n\n    >>> s.nlargest(3, keep='last')\n    France      65000000\n    Italy       59000000\n    Brunei        434000\n    dtype: int64\n\n    The `n` largest elements where ``n=3`` with all duplicates kept. Note\n    that the returned Series has five elements due to the three duplicates.\n\n    >>> s.nlargest(3, keep='all')\n    France      65000000\n    Italy       59000000\n    Malta         434000\n    Maldives      434000\n    Brunei        434000\n    dtype: int64\n    \"\"\"\n    return algorithms.SelectNSeries(self, n=n, keep=keep).nlargest()",
                            "def nsmallest(self, n=5, keep='first'):\n    \"\"\"\n    Return the smallest `n` elements.\n\n    Parameters\n    ----------\n    n : int, default 5\n        Return this many ascending sorted values.\n    keep : {'first', 'last', 'all'}, default 'first'\n        When there are duplicate values that cannot all fit in a\n        Series of `n` elements:\n\n        - ``first`` : return the first `n` occurrences in order\n            of appearance.\n        - ``last`` : return the last `n` occurrences in reverse\n            order of appearance.\n        - ``all`` : keep all occurrences. This can result in a Series of\n            size larger than `n`.\n\n    Returns\n    -------\n    Series\n        The `n` smallest values in the Series, sorted in increasing order.\n\n    See Also\n    --------\n    Series.nlargest: Get the `n` largest elements.\n    Series.sort_values: Sort Series by values.\n    Series.head: Return the first `n` rows.\n\n    Notes\n    -----\n    Faster than ``.sort_values().head(n)`` for small `n` relative to\n    the size of the ``Series`` object.\n\n    Examples\n    --------\n    >>> countries_population = {\"Italy\": 59000000, \"France\": 65000000,\n    ...                         \"Brunei\": 434000, \"Malta\": 434000,\n    ...                         \"Maldives\": 434000, \"Iceland\": 337000,\n    ...                         \"Nauru\": 11300, \"Tuvalu\": 11300,\n    ...                         \"Anguilla\": 11300, \"Monserat\": 5200}\n    >>> s = pd.Series(countries_population)\n    >>> s\n    Italy       59000000\n    France      65000000\n    Brunei        434000\n    Malta         434000\n    Maldives      434000\n    Iceland       337000\n    Nauru          11300\n    Tuvalu         11300\n    Anguilla       11300\n    Monserat        5200\n    dtype: int64\n\n    The `n` smallest elements where ``n=5`` by default.\n\n    >>> s.nsmallest()\n    Monserat      5200\n    Nauru        11300\n    Tuvalu       11300\n    Anguilla     11300\n    Iceland     337000\n    dtype: int64\n\n    The `n` smallest elements where ``n=3``. Default `keep` value is\n    'first' so Nauru and Tuvalu will be kept.\n\n    >>> s.nsmallest(3)\n    Monserat     5200\n    Nauru       11300\n    Tuvalu      11300\n    dtype: int64\n\n    The `n` smallest elements where ``n=3`` and keeping the last\n    duplicates. Anguilla and Tuvalu will be kept since they are the last\n    with value 11300 based on the index order.\n\n    >>> s.nsmallest(3, keep='last')\n    Monserat     5200\n    Anguilla    11300\n    Tuvalu      11300\n    dtype: int64\n\n    The `n` smallest elements where ``n=3`` with all duplicates kept. Note\n    that the returned Series has four elements due to the three duplicates.\n\n    >>> s.nsmallest(3, keep='all')\n    Monserat     5200\n    Nauru       11300\n    Tuvalu      11300\n    Anguilla    11300\n    dtype: int64\n    \"\"\"\n    return algorithms.SelectNSeries(self, n=n, keep=keep).nsmallest()",
                            "def swaplevel(self, i=-2, j=-1, copy=True):\n    \"\"\"\n    Swap levels i and j in a :class:`MultiIndex`.\n\n    Default is to swap the two innermost levels of the index.\n\n    Parameters\n    ----------\n    i, j : int, str (can be mixed)\n        Level of index to be swapped. Can pass level name as string.\n    copy : bool, default True\n        Whether to copy underlying data.\n\n    Returns\n    -------\n    Series\n        Series with levels swapped in MultiIndex.\n    \"\"\"\n    new_index = self.index.swaplevel(i, j)\n    return self._constructor(self._values, index=new_index, copy=copy).__finalize__(self)",
                            "def reorder_levels(self, order):\n    \"\"\"\n    Rearrange index levels using input order.\n\n    May not drop or duplicate levels.\n\n    Parameters\n    ----------\n    order : list of int representing new level order\n           (reference level by number or key)\n\n    Returns\n    -------\n    type of caller (new object)\n    \"\"\"\n    if not isinstance(self.index, MultiIndex):\n        raise Exception('Can only reorder levels on a hierarchical axis.')\n    result = self.copy()\n    result.index = result.index.reorder_levels(order)\n    return result",
                            "def explode(self) -> 'Series':\n    \"\"\"\n    Transform each element of a list-like to a row, replicating the\n    index values.\n\n    .. versionadded:: 0.25.0\n\n    Returns\n    -------\n    Series\n        Exploded lists to rows; index will be duplicated for these rows.\n\n    See Also\n    --------\n    Series.str.split : Split string values on specified separator.\n    Series.unstack : Unstack, a.k.a. pivot, Series with MultiIndex\n        to produce DataFrame.\n    DataFrame.melt : Unpivot a DataFrame from wide format to long format.\n    DataFrame.explode : Explode a DataFrame from list-like\n        columns to long format.\n\n    Notes\n    -----\n    This routine will explode list-likes including lists, tuples,\n    Series, and np.ndarray. The result dtype of the subset rows will\n    be object. Scalars will be returned unchanged. Empty list-likes will\n    result in a np.nan for that row.\n\n    Examples\n    --------\n    >>> s = pd.Series([[1, 2, 3], 'foo', [], [3, 4]])\n    >>> s\n    0    [1, 2, 3]\n    1          foo\n    2           []\n    3       [3, 4]\n    dtype: object\n\n    >>> s.explode()\n    0      1\n    0      2\n    0      3\n    1    foo\n    2    NaN\n    3      3\n    3      4\n    dtype: object\n    \"\"\"\n    if not len(self) or not is_object_dtype(self):\n        return self.copy()\n    (values, counts) = reshape.explode(np.asarray(self.array))\n    result = Series(values, index=self.index.repeat(counts), name=self.name)\n    return result",
                            "def unstack(self, level=-1, fill_value=None):\n    \"\"\"\n    Unstack, a.k.a. pivot, Series with MultiIndex to produce DataFrame.\n    The level involved will automatically get sorted.\n\n    Parameters\n    ----------\n    level : int, str, or list of these, default last level\n        Level(s) to unstack, can pass level name.\n    fill_value : scalar value, default None\n        Value to use when replacing NaN values.\n\n    Returns\n    -------\n    DataFrame\n        Unstacked Series.\n\n    Examples\n    --------\n    >>> s = pd.Series([1, 2, 3, 4],\n    ...               index=pd.MultiIndex.from_product([['one', 'two'],\n    ...                                                 ['a', 'b']]))\n    >>> s\n    one  a    1\n         b    2\n    two  a    3\n         b    4\n    dtype: int64\n\n    >>> s.unstack(level=-1)\n         a  b\n    one  1  2\n    two  3  4\n\n    >>> s.unstack(level=0)\n       one  two\n    a    1    3\n    b    2    4\n    \"\"\"\n    from pandas.core.reshape.reshape import unstack\n    return unstack(self, level, fill_value)",
                            "def map(self, arg, na_action=None):\n    \"\"\"\n    Map values of Series according to input correspondence.\n\n    Used for substituting each value in a Series with another value,\n    that may be derived from a function, a ``dict`` or\n    a :class:`Series`.\n\n    Parameters\n    ----------\n    arg : function, dict, or Series\n        Mapping correspondence.\n    na_action : {None, 'ignore'}, default None\n        If 'ignore', propagate NaN values, without passing them to the\n        mapping correspondence.\n\n    Returns\n    -------\n    Series\n        Same index as caller.\n\n    See Also\n    --------\n    Series.apply : For applying more complex functions on a Series.\n    DataFrame.apply : Apply a function row-/column-wise.\n    DataFrame.applymap : Apply a function elementwise on a whole DataFrame.\n\n    Notes\n    -----\n    When ``arg`` is a dictionary, values in Series that are not in the\n    dictionary (as keys) are converted to ``NaN``. However, if the\n    dictionary is a ``dict`` subclass that defines ``__missing__`` (i.e.\n    provides a method for default values), then this default is used\n    rather than ``NaN``.\n\n    Examples\n    --------\n    >>> s = pd.Series(['cat', 'dog', np.nan, 'rabbit'])\n    >>> s\n    0      cat\n    1      dog\n    2      NaN\n    3   rabbit\n    dtype: object\n\n    ``map`` accepts a ``dict`` or a ``Series``. Values that are not found\n    in the ``dict`` are converted to ``NaN``, unless the dict has a default\n    value (e.g. ``defaultdict``):\n\n    >>> s.map({'cat': 'kitten', 'dog': 'puppy'})\n    0   kitten\n    1    puppy\n    2      NaN\n    3      NaN\n    dtype: object\n\n    It also accepts a function:\n\n    >>> s.map('I am a {}'.format)\n    0       I am a cat\n    1       I am a dog\n    2       I am a nan\n    3    I am a rabbit\n    dtype: object\n\n    To avoid applying the function to missing values (and keep them as\n    ``NaN``) ``na_action='ignore'`` can be used:\n\n    >>> s.map('I am a {}'.format, na_action='ignore')\n    0     I am a cat\n    1     I am a dog\n    2            NaN\n    3  I am a rabbit\n    dtype: object\n    \"\"\"\n    new_values = super()._map_values(arg, na_action=na_action)\n    return self._constructor(new_values, index=self.index).__finalize__(self)",
                            "def _gotitem(self, key, ndim, subset=None):\n    \"\"\"\n    Sub-classes to define. Return a sliced object.\n\n    Parameters\n    ----------\n    key : string / list of selections\n    ndim : 1,2\n        requested ndim of result\n    subset : object, default None\n        subset to act on\n    \"\"\"\n    return self",
                            "@Substitution(see_also=_agg_see_also_doc, examples=_agg_examples_doc, versionadded='\\n.. versionadded:: 0.20.0\\n', **_shared_doc_kwargs)\n@Appender(generic._shared_docs['aggregate'])\ndef aggregate(self, func, axis=0, *args, **kwargs):\n    self._get_axis_number(axis)\n    (result, how) = self._aggregate(func, *args, **kwargs)\n    if result is None:\n        kwargs.pop('_axis', None)\n        kwargs.pop('_level', None)\n        try:\n            result = self.apply(func, *args, **kwargs)\n        except (ValueError, AttributeError, TypeError):\n            result = func(self, *args, **kwargs)\n    return result",
                            "@Appender(generic._shared_docs['transform'] % _shared_doc_kwargs)\ndef transform(self, func, axis=0, *args, **kwargs):\n    self._get_axis_number(axis)\n    return super().transform(func, *args, **kwargs)",
                            "def apply(self, func, convert_dtype=True, args=(), **kwds):\n    \"\"\"\n    Invoke function on values of Series.\n\n    Can be ufunc (a NumPy function that applies to the entire Series)\n    or a Python function that only works on single values.\n\n    Parameters\n    ----------\n    func : function\n        Python function or NumPy ufunc to apply.\n    convert_dtype : bool, default True\n        Try to find better dtype for elementwise function results. If\n        False, leave as dtype=object.\n    args : tuple\n        Positional arguments passed to func after the series value.\n    **kwds\n        Additional keyword arguments passed to func.\n\n    Returns\n    -------\n    Series or DataFrame\n        If func returns a Series object the result will be a DataFrame.\n\n    See Also\n    --------\n    Series.map: For element-wise operations.\n    Series.agg: Only perform aggregating type operations.\n    Series.transform: Only perform transforming type operations.\n\n    Examples\n    --------\n    Create a series with typical summer temperatures for each city.\n\n    >>> s = pd.Series([20, 21, 12],\n    ...               index=['London', 'New York', 'Helsinki'])\n    >>> s\n    London      20\n    New York    21\n    Helsinki    12\n    dtype: int64\n\n    Square the values by defining a function and passing it as an\n    argument to ``apply()``.\n\n    >>> def square(x):\n    ...     return x ** 2\n    >>> s.apply(square)\n    London      400\n    New York    441\n    Helsinki    144\n    dtype: int64\n\n    Square the values by passing an anonymous function as an\n    argument to ``apply()``.\n\n    >>> s.apply(lambda x: x ** 2)\n    London      400\n    New York    441\n    Helsinki    144\n    dtype: int64\n\n    Define a custom function that needs additional positional\n    arguments and pass these additional arguments using the\n    ``args`` keyword.\n\n    >>> def subtract_custom_value(x, custom_value):\n    ...     return x - custom_value\n\n    >>> s.apply(subtract_custom_value, args=(5,))\n    London      15\n    New York    16\n    Helsinki     7\n    dtype: int64\n\n    Define a custom function that takes keyword arguments\n    and pass these arguments to ``apply``.\n\n    >>> def add_custom_values(x, **kwargs):\n    ...     for month in kwargs:\n    ...         x += kwargs[month]\n    ...     return x\n\n    >>> s.apply(add_custom_values, june=30, july=20, august=25)\n    London      95\n    New York    96\n    Helsinki    87\n    dtype: int64\n\n    Use a function from the Numpy library.\n\n    >>> s.apply(np.log)\n    London      2.995732\n    New York    3.044522\n    Helsinki    2.484907\n    dtype: float64\n    \"\"\"\n    if len(self) == 0:\n        return self._constructor(dtype=self.dtype, index=self.index).__finalize__(self)\n    if isinstance(func, (list, dict)):\n        return self.aggregate(func, *args, **kwds)\n    if isinstance(func, str):\n        return self._try_aggregate_string_function(func, *args, **kwds)\n    if kwds or (args and (not isinstance(func, np.ufunc))):\n\n        def f(x):\n            return func(x, *args, **kwds)\n    else:\n        f = func\n    with np.errstate(all='ignore'):\n        if isinstance(f, np.ufunc):\n            return f(self)\n        if is_extension_type(self.dtype):\n            mapped = self._values.map(f)\n        else:\n            values = self.astype(object).values\n            mapped = lib.map_infer(values, f, convert=convert_dtype)\n    if len(mapped) and isinstance(mapped[0], Series):\n        return self._constructor_expanddim(pd.array(mapped), index=self.index)\n    else:\n        return self._constructor(mapped, index=self.index).__finalize__(self)",
                            "def _reduce(self, op, name, axis=0, skipna=True, numeric_only=None, filter_type=None, **kwds):\n    \"\"\"\n    Perform a reduction operation.\n\n    If we have an ndarray as a value, then simply perform the operation,\n    otherwise delegate to the object.\n    \"\"\"\n    delegate = self._values\n    if axis is not None:\n        self._get_axis_number(axis)\n    if isinstance(delegate, Categorical):\n        return delegate._reduce(name, numeric_only=numeric_only, **kwds)\n    elif isinstance(delegate, ExtensionArray):\n        return delegate._reduce(name, skipna=skipna, **kwds)\n    elif is_datetime64_dtype(delegate):\n        delegate = DatetimeIndex(delegate)\n    elif is_timedelta64_dtype(delegate) and hasattr(TimedeltaIndex, name):\n        delegate = TimedeltaIndex(delegate)\n    elif isinstance(delegate, np.ndarray):\n        if numeric_only:\n            raise NotImplementedError('Series.{0} does not implement numeric_only.'.format(name))\n        with np.errstate(all='ignore'):\n            return op(delegate, skipna=skipna, **kwds)\n    return delegate._reduce(op=op, name=name, axis=axis, skipna=skipna, numeric_only=numeric_only, filter_type=filter_type, **kwds)",
                            "def _reindex_indexer(self, new_index, indexer, copy):\n    if indexer is None:\n        if copy:\n            return self.copy()\n        return self\n    new_values = algorithms.take_1d(self._values, indexer, allow_fill=True, fill_value=None)\n    return self._constructor(new_values, index=new_index)",
                            "def _needs_reindex_multi(self, axes, method, level):\n    \"\"\"\n    Check if we do need a multi reindex; this is for compat with\n    higher dims.\n    \"\"\"\n    return False",
                            "@Appender(generic._shared_docs['align'] % _shared_doc_kwargs)\ndef align(self, other, join='outer', axis=None, level=None, copy=True, fill_value=None, method=None, limit=None, fill_axis=0, broadcast_axis=None):\n    return super().align(other, join=join, axis=axis, level=level, copy=copy, fill_value=fill_value, method=method, limit=limit, fill_axis=fill_axis, broadcast_axis=broadcast_axis)",
                            "def rename(self, index=None, **kwargs):\n    \"\"\"\n    Alter Series index labels or name.\n\n    Function / dict values must be unique (1-to-1). Labels not contained in\n    a dict / Series will be left as-is. Extra labels listed don't throw an\n    error.\n\n    Alternatively, change ``Series.name`` with a scalar value.\n\n    See the :ref:`user guide <basics.rename>` for more.\n\n    Parameters\n    ----------\n    index : scalar, hashable sequence, dict-like or function, optional\n        dict-like or functions are transformations to apply to\n        the index.\n        Scalar or hashable sequence-like will alter the ``Series.name``\n        attribute.\n    copy : bool, default True\n        Whether to copy underlying data.\n    inplace : bool, default False\n        Whether to return a new Series. If True then value of copy is\n        ignored.\n    level : int or level name, default None\n        In case of a MultiIndex, only rename labels in the specified\n        level.\n\n    Returns\n    -------\n    Series\n        Series with index labels or name altered.\n\n    See Also\n    --------\n    Series.rename_axis : Set the name of the axis.\n\n    Examples\n    --------\n    >>> s = pd.Series([1, 2, 3])\n    >>> s\n    0    1\n    1    2\n    2    3\n    dtype: int64\n    >>> s.rename(\"my_name\")  # scalar, changes Series.name\n    0    1\n    1    2\n    2    3\n    Name: my_name, dtype: int64\n    >>> s.rename(lambda x: x ** 2)  # function, changes labels\n    0    1\n    1    2\n    4    3\n    dtype: int64\n    >>> s.rename({1: 3, 2: 5})  # mapping, changes labels\n    0    1\n    3    2\n    5    3\n    dtype: int64\n    \"\"\"\n    kwargs['inplace'] = validate_bool_kwarg(kwargs.get('inplace', False), 'inplace')\n    if callable(index) or is_dict_like(index):\n        return super().rename(index=index, **kwargs)\n    else:\n        return self._set_name(index, inplace=kwargs.get('inplace'))",
                            "@Substitution(**_shared_doc_kwargs)\n@Appender(generic.NDFrame.reindex.__doc__)\ndef reindex(self, index=None, **kwargs):\n    return super().reindex(index=index, **kwargs)",
                            "def drop(self, labels=None, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise'):\n    \"\"\"\n    Return Series with specified index labels removed.\n\n    Remove elements of a Series based on specifying the index labels.\n    When using a multi-index, labels on different levels can be removed\n    by specifying the level.\n\n    Parameters\n    ----------\n    labels : single label or list-like\n        Index labels to drop.\n    axis : 0, default 0\n        Redundant for application on Series.\n    index, columns : None\n        Redundant for application on Series, but index can be used instead\n        of labels.\n\n        .. versionadded:: 0.21.0\n    level : int or level name, optional\n        For MultiIndex, level for which the labels will be removed.\n    inplace : bool, default False\n        If True, do operation inplace and return None.\n    errors : {'ignore', 'raise'}, default 'raise'\n        If 'ignore', suppress error and only existing labels are dropped.\n\n    Returns\n    -------\n    Series\n        Series with specified index labels removed.\n\n    Raises\n    ------\n    KeyError\n        If none of the labels are found in the index.\n\n    See Also\n    --------\n    Series.reindex : Return only specified index labels of Series.\n    Series.dropna : Return series without null values.\n    Series.drop_duplicates : Return Series with duplicate values removed.\n    DataFrame.drop : Drop specified labels from rows or columns.\n\n    Examples\n    --------\n    >>> s = pd.Series(data=np.arange(3), index=['A', 'B', 'C'])\n    >>> s\n    A  0\n    B  1\n    C  2\n    dtype: int64\n\n    Drop labels B en C\n\n    >>> s.drop(labels=['B', 'C'])\n    A  0\n    dtype: int64\n\n    Drop 2nd level label in MultiIndex Series\n\n    >>> midx = pd.MultiIndex(levels=[['lama', 'cow', 'falcon'],\n    ...                              ['speed', 'weight', 'length']],\n    ...                      codes=[[0, 0, 0, 1, 1, 1, 2, 2, 2],\n    ...                             [0, 1, 2, 0, 1, 2, 0, 1, 2]])\n    >>> s = pd.Series([45, 200, 1.2, 30, 250, 1.5, 320, 1, 0.3],\n    ...               index=midx)\n    >>> s\n    lama    speed      45.0\n            weight    200.0\n            length      1.2\n    cow     speed      30.0\n            weight    250.0\n            length      1.5\n    falcon  speed     320.0\n            weight      1.0\n            length      0.3\n    dtype: float64\n\n    >>> s.drop(labels='weight', level=1)\n    lama    speed      45.0\n            length      1.2\n    cow     speed      30.0\n            length      1.5\n    falcon  speed     320.0\n            length      0.3\n    dtype: float64\n    \"\"\"\n    return super().drop(labels=labels, axis=axis, index=index, columns=columns, level=level, inplace=inplace, errors=errors)",
                            "@Substitution(**_shared_doc_kwargs)\n@Appender(generic.NDFrame.fillna.__doc__)\ndef fillna(self, value=None, method=None, axis=None, inplace=False, limit=None, downcast=None, **kwargs):\n    return super().fillna(value=value, method=method, axis=axis, inplace=inplace, limit=limit, downcast=downcast, **kwargs)",
                            "@Appender(generic._shared_docs['replace'] % _shared_doc_kwargs)\ndef replace(self, to_replace=None, value=None, inplace=False, limit=None, regex=False, method='pad'):\n    return super().replace(to_replace=to_replace, value=value, inplace=inplace, limit=limit, regex=regex, method=method)",
                            "@Appender(generic._shared_docs['shift'] % _shared_doc_kwargs)\ndef shift(self, periods=1, freq=None, axis=0, fill_value=None):\n    return super().shift(periods=periods, freq=freq, axis=axis, fill_value=fill_value)",
                            "def memory_usage(self, index=True, deep=False):\n    \"\"\"\n    Return the memory usage of the Series.\n\n    The memory usage can optionally include the contribution of\n    the index and of elements of `object` dtype.\n\n    Parameters\n    ----------\n    index : bool, default True\n        Specifies whether to include the memory usage of the Series index.\n    deep : bool, default False\n        If True, introspect the data deeply by interrogating\n        `object` dtypes for system-level memory consumption, and include\n        it in the returned value.\n\n    Returns\n    -------\n    int\n        Bytes of memory consumed.\n\n    See Also\n    --------\n    numpy.ndarray.nbytes : Total bytes consumed by the elements of the\n        array.\n    DataFrame.memory_usage : Bytes consumed by a DataFrame.\n\n    Examples\n    --------\n    >>> s = pd.Series(range(3))\n    >>> s.memory_usage()\n    152\n\n    Not including the index gives the size of the rest of the data, which\n    is necessarily smaller:\n\n    >>> s.memory_usage(index=False)\n    24\n\n    The memory footprint of `object` values is ignored by default:\n\n    >>> s = pd.Series([\"a\", \"b\"])\n    >>> s.values\n    array(['a', 'b'], dtype=object)\n    >>> s.memory_usage()\n    144\n    >>> s.memory_usage(deep=True)\n    260\n    \"\"\"\n    v = super().memory_usage(deep=deep)\n    if index:\n        v += self.index.memory_usage(deep=deep)\n    return v",
                            "def isin(self, values):\n    \"\"\"\n    Check whether `values` are contained in Series.\n\n    Return a boolean Series showing whether each element in the Series\n    matches an element in the passed sequence of `values` exactly.\n\n    Parameters\n    ----------\n    values : set or list-like\n        The sequence of values to test. Passing in a single string will\n        raise a ``TypeError``. Instead, turn a single string into a\n        list of one element.\n\n    Returns\n    -------\n    Series\n        Series of booleans indicating if each element is in values.\n\n    Raises\n    ------\n    TypeError\n      * If `values` is a string\n\n    See Also\n    --------\n    DataFrame.isin : Equivalent method on DataFrame.\n\n    Examples\n    --------\n    >>> s = pd.Series(['lama', 'cow', 'lama', 'beetle', 'lama',\n    ...                'hippo'], name='animal')\n    >>> s.isin(['cow', 'lama'])\n    0     True\n    1     True\n    2     True\n    3    False\n    4     True\n    5    False\n    Name: animal, dtype: bool\n\n    Passing a single string as ``s.isin('lama')`` will raise an error. Use\n    a list of one element instead:\n\n    >>> s.isin(['lama'])\n    0     True\n    1    False\n    2     True\n    3    False\n    4     True\n    5    False\n    Name: animal, dtype: bool\n    \"\"\"\n    result = algorithms.isin(self, values)\n    return self._constructor(result, index=self.index).__finalize__(self)",
                            "def between(self, left, right, inclusive=True):\n    \"\"\"\n    Return boolean Series equivalent to left <= series <= right.\n\n    This function returns a boolean vector containing `True` wherever the\n    corresponding Series element is between the boundary values `left` and\n    `right`. NA values are treated as `False`.\n\n    Parameters\n    ----------\n    left : scalar\n        Left boundary.\n    right : scalar\n        Right boundary.\n    inclusive : bool, default True\n        Include boundaries.\n\n    Returns\n    -------\n    Series\n        Series representing whether each element is between left and\n        right (inclusive).\n\n    See Also\n    --------\n    Series.gt : Greater than of series and other.\n    Series.lt : Less than of series and other.\n\n    Notes\n    -----\n    This function is equivalent to ``(left <= ser) & (ser <= right)``\n\n    Examples\n    --------\n    >>> s = pd.Series([2, 0, 4, 8, np.nan])\n\n    Boundary values are included by default:\n\n    >>> s.between(1, 4)\n    0     True\n    1    False\n    2     True\n    3    False\n    4    False\n    dtype: bool\n\n    With `inclusive` set to ``False`` boundary values are excluded:\n\n    >>> s.between(1, 4, inclusive=False)\n    0     True\n    1    False\n    2    False\n    3    False\n    4    False\n    dtype: bool\n\n    `left` and `right` can be any scalar value:\n\n    >>> s = pd.Series(['Alice', 'Bob', 'Carol', 'Eve'])\n    >>> s.between('Anna', 'Daniel')\n    0    False\n    1     True\n    2     True\n    3    False\n    dtype: bool\n    \"\"\"\n    if inclusive:\n        lmask = self >= left\n        rmask = self <= right\n    else:\n        lmask = self > left\n        rmask = self < right\n    return lmask & rmask",
                            "@Appender(generic.NDFrame.to_csv.__doc__)\ndef to_csv(self, *args, **kwargs):\n    names = ['path_or_buf', 'sep', 'na_rep', 'float_format', 'columns', 'header', 'index', 'index_label', 'mode', 'encoding', 'compression', 'quoting', 'quotechar', 'line_terminator', 'chunksize', 'date_format', 'doublequote', 'escapechar', 'decimal']\n    old_names = ['path_or_buf', 'index', 'sep', 'na_rep', 'float_format', 'header', 'index_label', 'mode', 'encoding', 'compression', 'date_format', 'decimal']\n    if 'path' in kwargs:\n        warnings.warn(\"The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'path' will be renamed to 'path_or_buf'.\", FutureWarning, stacklevel=2)\n        kwargs['path_or_buf'] = kwargs.pop('path')\n    if len(args) > 1:\n        maybe_sep = args[1]\n        if not (is_string_like(maybe_sep) and len(maybe_sep) == 1):\n            warnings.warn('The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`. Note that the order of arguments changed, and the new one has \\'sep\\' in first place, for which \"{}\" is not a valid value. The old order will cease to be supported in a future version. Please refer to the documentation for `DataFrame.to_csv` when updating your function calls.'.format(maybe_sep), FutureWarning, stacklevel=2)\n            names = old_names\n    pos_args = dict(zip(names[:len(args)], args))\n    for key in pos_args:\n        if key in kwargs:\n            raise ValueError(\"Argument given by name ('{}') and position ({})\".format(key, names.index(key)))\n        kwargs[key] = pos_args[key]\n    if kwargs.get('header', None) is None:\n        warnings.warn(\"The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\", FutureWarning, stacklevel=2)\n        kwargs['header'] = False\n    return self.to_frame().to_csv(**kwargs)",
                            "@Appender(generic._shared_docs['isna'] % _shared_doc_kwargs)\ndef isna(self):\n    return super().isna()",
                            "@Appender(generic._shared_docs['isna'] % _shared_doc_kwargs)\ndef isnull(self):\n    return super().isnull()",
                            "@Appender(generic._shared_docs['notna'] % _shared_doc_kwargs)\ndef notna(self):\n    return super().notna()",
                            "@Appender(generic._shared_docs['notna'] % _shared_doc_kwargs)\ndef notnull(self):\n    return super().notnull()",
                            "def dropna(self, axis=0, inplace=False, **kwargs):\n    \"\"\"\n    Return a new Series with missing values removed.\n\n    See the :ref:`User Guide <missing_data>` for more on which values are\n    considered missing, and how to work with missing data.\n\n    Parameters\n    ----------\n    axis : {0 or 'index'}, default 0\n        There is only one axis to drop values from.\n    inplace : bool, default False\n        If True, do operation inplace and return None.\n    **kwargs\n        Not in use.\n\n    Returns\n    -------\n    Series\n        Series with NA entries dropped from it.\n\n    See Also\n    --------\n    Series.isna: Indicate missing values.\n    Series.notna : Indicate existing (non-missing) values.\n    Series.fillna : Replace missing values.\n    DataFrame.dropna : Drop rows or columns which contain NA values.\n    Index.dropna : Drop missing indices.\n\n    Examples\n    --------\n    >>> ser = pd.Series([1., 2., np.nan])\n    >>> ser\n    0    1.0\n    1    2.0\n    2    NaN\n    dtype: float64\n\n    Drop NA values from a Series.\n\n    >>> ser.dropna()\n    0    1.0\n    1    2.0\n    dtype: float64\n\n    Keep the Series with valid entries in the same variable.\n\n    >>> ser.dropna(inplace=True)\n    >>> ser\n    0    1.0\n    1    2.0\n    dtype: float64\n\n    Empty strings are not considered NA values. ``None`` is considered an\n    NA value.\n\n    >>> ser = pd.Series([np.NaN, 2, pd.NaT, '', None, 'I stay'])\n    >>> ser\n    0       NaN\n    1         2\n    2       NaT\n    3\n    4      None\n    5    I stay\n    dtype: object\n    >>> ser.dropna()\n    1         2\n    3\n    5    I stay\n    dtype: object\n    \"\"\"\n    inplace = validate_bool_kwarg(inplace, 'inplace')\n    kwargs.pop('how', None)\n    if kwargs:\n        raise TypeError('dropna() got an unexpected keyword argument \"{0}\"'.format(list(kwargs.keys())[0]))\n    self._get_axis_number(axis or 0)\n    if self._can_hold_na:\n        result = remove_na_arraylike(self)\n        if inplace:\n            self._update_inplace(result)\n        else:\n            return result\n    elif inplace:\n        pass\n    else:\n        return self.copy()",
                            "def valid(self, inplace=False, **kwargs):\n    \"\"\"\n    Return Series without null values.\n\n    .. deprecated:: 0.23.0\n        Use :meth:`Series.dropna` instead.\n\n    Returns\n    -------\n    Series\n        Series without null values.\n    \"\"\"\n    warnings.warn('Method .valid will be removed in a future version. Use .dropna instead.', FutureWarning, stacklevel=2)\n    return self.dropna(inplace=inplace, **kwargs)",
                            "def to_timestamp(self, freq=None, how='start', copy=True):\n    \"\"\"\n    Cast to DatetimeIndex of Timestamps, at *beginning* of period.\n\n    Parameters\n    ----------\n    freq : str, default frequency of PeriodIndex\n        Desired frequency.\n    how : {'s', 'e', 'start', 'end'}\n        Convention for converting period to timestamp; start of period\n        vs. end.\n    copy : bool, default True\n        Whether or not to return a copy.\n\n    Returns\n    -------\n    Series with DatetimeIndex\n    \"\"\"\n    new_values = self._values\n    if copy:\n        new_values = new_values.copy()\n    new_index = self.index.to_timestamp(freq=freq, how=how)\n    return self._constructor(new_values, index=new_index).__finalize__(self)",
                            "def to_period(self, freq=None, copy=True):\n    \"\"\"\n    Convert Series from DatetimeIndex to PeriodIndex with desired\n    frequency (inferred from index if not passed).\n\n    Parameters\n    ----------\n    freq : str, default None\n        Frequency associated with the PeriodIndex.\n    copy : bool, default True\n        Whether or not to return a copy.\n\n    Returns\n    -------\n    Series\n        Series with index converted to PeriodIndex.\n    \"\"\"\n    new_values = self._values\n    if copy:\n        new_values = new_values.copy()\n    new_index = self.index.to_period(freq=freq)\n    return self._constructor(new_values, index=new_index).__finalize__(self)",
                            "def construct_return(result):\n    if lib.is_scalar(result):\n        return result\n    elif result.ndim > 1:\n        if method == 'outer':\n            msg = \"outer method for ufunc {} is not implemented on pandas objects. Returning an ndarray, but in the future this will raise a 'NotImplementedError'. Consider explicitly converting the Series to an array with '.array' first.\"\n            warnings.warn(msg.format(ufunc), FutureWarning, stacklevel=3)\n        return result\n    return self._constructor(result, index=index, name=name, copy=False)",
                            "def _try_kind_sort(arr):\n    try:\n        return arr.argsort(kind=kind)\n    except TypeError:\n        return arr.argsort(kind='quicksort')",
                            "def f(x):\n    return func(x, *args, **kwds)"
                        ],
                        "constructor_variables": [
                            "self.name = name"
                        ],
                        "class_level_variables": [
                            "_metadata = ['name']",
                            "_accessors = {'dt', 'cat', 'str', 'sparse'}",
                            "_deprecations = generic.NDFrame._deprecations | frozenset(['asobject', 'reshape', 'valid', 'tolist'])",
                            "hasnans = property(base.IndexOpsMixin.hasnans.func, doc=base.IndexOpsMixin.hasnans.__doc__)",
                            "_data = None",
                            "_index = None",
                            "_HANDLED_TYPES = (Index, ExtensionArray, np.ndarray)",
                            "__float__ = _coerce_method(float)",
                            "__long__ = _coerce_method(int)",
                            "__int__ = _coerce_method(int)",
                            "argmin = deprecate('argmin', idxmin, '0.21.0', msg=dedent(\"\\n        The current behaviour of 'Series.argmin' is deprecated, use 'idxmin'\\n        instead.\\n        The behavior of 'argmin' will be corrected to return the positional\\n        minimum in the future. For now, use 'series.values.argmin' or\\n        'np.argmin(np.array(values))' to get the position of the minimum\\n        row.\"))",
                            "argmax = deprecate('argmax', idxmax, '0.21.0', msg=dedent(\"\\n        The current behaviour of 'Series.argmax' is deprecated, use 'idxmax'\\n        instead.\\n        The behavior of 'argmax' will be corrected to return the positional\\n        maximum in the future. For now, use 'series.values.argmax' or\\n        'np.argmax(np.array(values))' to get the position of the maximum\\n        row.\"))",
                            "_agg_see_also_doc = dedent('\\n    See Also\\n    --------\\n    Series.apply : Invoke function on a Series.\\n    Series.transform : Transform function producing a Series with like indexes.\\n    ')",
                            "_agg_examples_doc = dedent(\"\\n    Examples\\n    --------\\n    >>> s = pd.Series([1, 2, 3, 4])\\n    >>> s\\n    0    1\\n    1    2\\n    2    3\\n    3    4\\n    dtype: int64\\n\\n    >>> s.agg('min')\\n    1\\n\\n    >>> s.agg(['min', 'max'])\\n    min   1\\n    max   4\\n    dtype: int64\\n    \")",
                            "agg = aggregate",
                            "str = CachedAccessor('str', StringMethods)",
                            "dt = CachedAccessor('dt', CombinedDatetimelikeProperties)",
                            "cat = CachedAccessor('cat', CategoricalAccessor)",
                            "plot = CachedAccessor('plot', pandas.plotting.PlotAccessor)",
                            "sparse = CachedAccessor('sparse', SparseAccessor)",
                            "hist = pandas.plotting.hist_series"
                        ],
                        "class_decorators": [],
                        "function_signatures": [
                            "__init__(self, data=None, index=None, dtype=None, name=None, copy=False, fastpath=False)",
                            "_init_dict(self, data, index=None, dtype=None)",
                            "from_array(cls, arr, index=None, name=None, dtype=None, copy=False, fastpath=False)",
                            "_constructor(self)",
                            "_constructor_expanddim(self)",
                            "_can_hold_na(self)",
                            "_set_axis(self, axis, labels, fastpath=False)",
                            "_set_subtyp(self, is_all_dates)",
                            "_update_inplace(self, result, **kwargs)",
                            "name(self)",
                            "name(self, value)",
                            "dtype(self)",
                            "dtypes(self)",
                            "ftype(self)",
                            "ftypes(self)",
                            "values(self)",
                            "_values(self)",
                            "get_values(self)",
                            "_internal_get_values(self)",
                            "asobject(self)",
                            "ravel(self, order='C')",
                            "compress(self, condition, *args, **kwargs)",
                            "nonzero(self)",
                            "put(self, *args, **kwargs)",
                            "__len__(self)",
                            "view(self, dtype=None)",
                            "__array_ufunc__(self, ufunc: Callable, method: str, *inputs: Any, **kwargs: Any)",
                            "__array__(self, dtype=None)",
                            "real(self)",
                            "real(self, v)",
                            "imag(self)",
                            "imag(self, v)",
                            "_unpickle_series_compat(self, state)",
                            "axes(self)",
                            "take(self, indices, axis=0, is_copy=False, **kwargs)",
                            "_ixs(self, i: int, axis: int=0)",
                            "_slice(self, slobj: slice, axis: int=0, kind=None)",
                            "__getitem__(self, key)",
                            "_get_with(self, key)",
                            "_get_values_tuple(self, key)",
                            "_get_values(self, indexer)",
                            "_get_value(self, label, takeable: bool=False)",
                            "__setitem__(self, key, value)",
                            "_set_with_engine(self, key, value)",
                            "_set_with(self, key, value)",
                            "_set_labels(self, key, value)",
                            "_set_values(self, key, value)",
                            "_set_value(self, label, value, takeable: bool=False)",
                            "_is_mixed_type(self)",
                            "repeat(self, repeats, axis=None)",
                            "reset_index(self, level=None, drop=False, name=None, inplace=False)",
                            "__repr__(self)",
                            "to_string(self, buf=None, na_rep='NaN', float_format=None, header=True, index=True, length=False, dtype=False, name=False, max_rows=None, min_rows=None)",
                            "items(self)",
                            "iteritems(self)",
                            "keys(self)",
                            "to_dict(self, into=dict)",
                            "to_frame(self, name=None)",
                            "to_sparse(self, kind='block', fill_value=None)",
                            "_set_name(self, name, inplace=False)",
                            "count(self, level=None)",
                            "mode(self, dropna=True)",
                            "unique(self)",
                            "drop_duplicates(self, keep='first', inplace=False)",
                            "duplicated(self, keep='first')",
                            "idxmin(self, axis=0, skipna=True, *args, **kwargs)",
                            "idxmax(self, axis=0, skipna=True, *args, **kwargs)",
                            "round(self, decimals=0, *args, **kwargs)",
                            "quantile(self, q=0.5, interpolation='linear')",
                            "corr(self, other, method='pearson', min_periods=None)",
                            "cov(self, other, min_periods=None)",
                            "diff(self, periods=1)",
                            "autocorr(self, lag=1)",
                            "dot(self, other)",
                            "__matmul__(self, other)",
                            "__rmatmul__(self, other)",
                            "searchsorted(self, value, side='left', sorter=None)",
                            "append(self, to_append, ignore_index=False, verify_integrity=False)",
                            "_binop(self, other, func, level=None, fill_value=None)",
                            "combine(self, other, func, fill_value=None)",
                            "combine_first(self, other)",
                            "update(self, other)",
                            "sort_values(self, axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')",
                            "sort_index(self, axis=0, level=None, ascending=True, inplace=False, kind='quicksort', na_position='last', sort_remaining=True)",
                            "argsort(self, axis=0, kind='quicksort', order=None)",
                            "nlargest(self, n=5, keep='first')",
                            "nsmallest(self, n=5, keep='first')",
                            "swaplevel(self, i=-2, j=-1, copy=True)",
                            "reorder_levels(self, order)",
                            "explode(self) -> 'Series'",
                            "unstack(self, level=-1, fill_value=None)",
                            "map(self, arg, na_action=None)",
                            "_gotitem(self, key, ndim, subset=None)",
                            "aggregate(self, func, axis=0, *args, **kwargs)",
                            "transform(self, func, axis=0, *args, **kwargs)",
                            "apply(self, func, convert_dtype=True, args=(), **kwds)",
                            "_reduce(self, op, name, axis=0, skipna=True, numeric_only=None, filter_type=None, **kwds)",
                            "_reindex_indexer(self, new_index, indexer, copy)",
                            "_needs_reindex_multi(self, axes, method, level)",
                            "align(self, other, join='outer', axis=None, level=None, copy=True, fill_value=None, method=None, limit=None, fill_axis=0, broadcast_axis=None)",
                            "rename(self, index=None, **kwargs)",
                            "reindex(self, index=None, **kwargs)",
                            "drop(self, labels=None, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise')",
                            "fillna(self, value=None, method=None, axis=None, inplace=False, limit=None, downcast=None, **kwargs)",
                            "replace(self, to_replace=None, value=None, inplace=False, limit=None, regex=False, method='pad')",
                            "shift(self, periods=1, freq=None, axis=0, fill_value=None)",
                            "memory_usage(self, index=True, deep=False)",
                            "isin(self, values)",
                            "between(self, left, right, inclusive=True)",
                            "to_csv(self, *args, **kwargs)",
                            "isna(self)",
                            "isnull(self)",
                            "notna(self)",
                            "notnull(self)",
                            "dropna(self, axis=0, inplace=False, **kwargs)",
                            "valid(self, inplace=False, **kwargs)",
                            "to_timestamp(self, freq=None, how='start', copy=True)",
                            "to_period(self, freq=None, copy=True)",
                            "construct_return(result)",
                            "_try_kind_sort(arr)",
                            "f(x)"
                        ],
                        "class_level_variable_names": [
                            "_metadata",
                            "_accessors",
                            "_deprecations",
                            "hasnans",
                            "_data",
                            "_index",
                            "_HANDLED_TYPES",
                            "__float__",
                            "__long__",
                            "__int__",
                            "argmin",
                            "argmax",
                            "_agg_see_also_doc",
                            "_agg_examples_doc",
                            "agg",
                            "str",
                            "dt",
                            "cat",
                            "plot",
                            "sparse",
                            "hist"
                        ],
                        "constructor_variable_names": [
                            "copy",
                            "data",
                            "name",
                            "index",
                            "dtype"
                        ]
                    },
                    "used_imports": [
                        "from pandas.core.reshape.concat import concat"
                    ],
                    "variable_values": [
                        [
                            {
                                "to_append": {
                                    "variable_value": "[0    1\n1    2\n2    3\ndtype: int64, 0    1\n1    2\n2    3\ndtype: int64]",
                                    "variable_type": "list",
                                    "variable_shape": "2"
                                },
                                "to_concat": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self": {
                                    "variable_value": "0    1\n1    2\n2    3\ndtype: int64",
                                    "variable_type": "Series",
                                    "variable_shape": "(3,)"
                                },
                                "concat": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "ignore_index": {
                                    "variable_value": "False",
                                    "variable_type": "bool",
                                    "variable_shape": null
                                },
                                "verify_integrity": {
                                    "variable_value": "False",
                                    "variable_type": "bool",
                                    "variable_shape": null
                                }
                            },
                            {
                                "to_append": {
                                    "variable_value": "[0    1\n1    2\n2    3\ndtype: int64, 0    1\n1    2\n2    3\ndtype: int64]",
                                    "variable_type": "list",
                                    "variable_shape": "2"
                                },
                                "to_concat": {
                                    "variable_value": "[0    1\n1    2\n2    3\ndtype: int64, 0    1\n1    2\n2    3\ndtype: int64, 0    1\n1    2\n2    3\ndtype: int64]",
                                    "variable_type": "list",
                                    "variable_shape": "3"
                                },
                                "self": {
                                    "variable_value": "0    1\n1    2\n2    3\ndtype: int64",
                                    "variable_type": "Series",
                                    "variable_shape": "(3,)"
                                },
                                "concat": {
                                    "variable_value": "<function concat at 0x7fe4941c2ca0>",
                                    "variable_type": "function",
                                    "variable_shape": null
                                },
                                "ignore_index": {
                                    "variable_value": "False",
                                    "variable_type": "bool",
                                    "variable_shape": null
                                },
                                "verify_integrity": {
                                    "variable_value": "False",
                                    "variable_type": "bool",
                                    "variable_shape": null
                                }
                            }
                        ]
                    ],
                    "angelic_variable_values": [
                        [
                            {
                                "to_append": {
                                    "variable_value": "[0    1\n1    2\n2    3\ndtype: int64, 0    1\n1    2\n2    3\ndtype: int64]",
                                    "variable_type": "list",
                                    "variable_shape": "2"
                                },
                                "to_concat": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self": {
                                    "variable_value": "0    1\n1    2\n2    3\ndtype: int64",
                                    "variable_type": "Series",
                                    "variable_shape": "(3,)"
                                },
                                "to_concat.extend": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "concat": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "ignore_index": {
                                    "variable_value": "False",
                                    "variable_type": "bool",
                                    "variable_shape": null
                                },
                                "verify_integrity": {
                                    "variable_value": "False",
                                    "variable_type": "bool",
                                    "variable_shape": null
                                }
                            },
                            {
                                "to_append": {
                                    "variable_value": "[0    1\n1    2\n2    3\ndtype: int64, 0    1\n1    2\n2    3\ndtype: int64]",
                                    "variable_type": "list",
                                    "variable_shape": "2"
                                },
                                "to_concat": {
                                    "variable_value": "[0    1\n1    2\n2    3\ndtype: int64, 0    1\n1    2\n2    3\ndtype: int64, 0    1\n1    2\n2    3\ndtype: int64]",
                                    "variable_type": "list",
                                    "variable_shape": "3"
                                },
                                "self": {
                                    "variable_value": "0    1\n1    2\n2    3\ndtype: int64",
                                    "variable_type": "Series",
                                    "variable_shape": "(3,)"
                                },
                                "to_concat.extend": {
                                    "variable_value": "<built-in method extend of list object at 0x7fc107726680>",
                                    "variable_type": "builtin_function_or_method",
                                    "variable_shape": null
                                },
                                "concat": {
                                    "variable_value": "<function concat at 0x7fc0ebb60ca0>",
                                    "variable_type": "function",
                                    "variable_shape": null
                                },
                                "ignore_index": {
                                    "variable_value": "False",
                                    "variable_type": "bool",
                                    "variable_shape": null
                                },
                                "verify_integrity": {
                                    "variable_value": "False",
                                    "variable_type": "bool",
                                    "variable_shape": null
                                }
                            }
                        ],
                        [
                            {
                                "to_append": {
                                    "variable_value": "(0    1\n1    2\n2    3\ndtype: int64, 0    1\n1    2\n2    3\ndtype: int64)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "to_concat": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "self": {
                                    "variable_value": "0    1\n1    2\n2    3\ndtype: int64",
                                    "variable_type": "Series",
                                    "variable_shape": "(3,)"
                                },
                                "to_concat.extend": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "concat": {
                                    "variable_value": null,
                                    "variable_type": "None",
                                    "variable_shape": null
                                },
                                "ignore_index": {
                                    "variable_value": "False",
                                    "variable_type": "bool",
                                    "variable_shape": null
                                },
                                "verify_integrity": {
                                    "variable_value": "False",
                                    "variable_type": "bool",
                                    "variable_shape": null
                                }
                            },
                            {
                                "to_append": {
                                    "variable_value": "(0    1\n1    2\n2    3\ndtype: int64, 0    1\n1    2\n2    3\ndtype: int64)",
                                    "variable_type": "tuple",
                                    "variable_shape": "2"
                                },
                                "to_concat": {
                                    "variable_value": "[0    1\n1    2\n2    3\ndtype: int64, 0    1\n1    2\n2    3\ndtype: int64, 0    1\n1    2\n2    3\ndtype: int64]",
                                    "variable_type": "list",
                                    "variable_shape": "3"
                                },
                                "self": {
                                    "variable_value": "0    1\n1    2\n2    3\ndtype: int64",
                                    "variable_type": "Series",
                                    "variable_shape": "(3,)"
                                },
                                "to_concat.extend": {
                                    "variable_value": "<built-in method extend of list object at 0x7fc107775c40>",
                                    "variable_type": "builtin_function_or_method",
                                    "variable_shape": null
                                },
                                "concat": {
                                    "variable_value": "<function concat at 0x7fc0ebb60ca0>",
                                    "variable_type": "function",
                                    "variable_shape": null
                                },
                                "ignore_index": {
                                    "variable_value": "False",
                                    "variable_type": "bool",
                                    "variable_shape": null
                                },
                                "verify_integrity": {
                                    "variable_value": "False",
                                    "variable_type": "bool",
                                    "variable_shape": null
                                }
                            }
                        ]
                    ]
                }
            ],
            "inscope_functions": [
                "def remove_na(arr):\n    \"\"\"\n    Remove null values from array like structure.\n\n    .. deprecated:: 0.21.0\n        Use s[s.notnull()] instead.\n    \"\"\"\n\n    warnings.warn(\n        \"remove_na is deprecated and is a private function. Do not use.\",\n        FutureWarning,\n        stacklevel=2,\n    )\n    return remove_na_arraylike(arr)",
                "def _coerce_method(converter):\n    \"\"\"\n    Install the scalar coercion methods.\n    \"\"\"\n\n    def wrapper(self):\n        if len(self) == 1:\n            return converter(self.iloc[0])\n        raise TypeError(\"cannot convert the series to {0}\".format(str(converter)))\n\n    wrapper.__name__ = \"__{name}__\".format(name=converter.__name__)\n    return wrapper",
                "def wrapper(self):\n    if len(self) == 1:\n        return converter(self.iloc[0])\n    raise TypeError(\"cannot convert the series to {0}\".format(str(converter)))",
                "def __init__(\n    self, data=None, index=None, dtype=None, name=None, copy=False, fastpath=False\n):\n\n    # we are called internally, so short-circuit\n    if fastpath:\n\n        # data is an ndarray, index is defined\n        if not isinstance(data, SingleBlockManager):\n            data = SingleBlockManager(data, index, fastpath=True)\n        if copy:\n            data = data.copy()\n        if index is None:\n            index = data.index\n\n    else:\n\n        if index is not None:\n            index = ensure_index(index)\n\n        if data is None:\n            data = {}\n        if dtype is not None:\n            # GH 26336: explicitly handle 'category' to avoid warning\n            # TODO: Remove after CategoricalDtype defaults to ordered=False\n            if (\n                isinstance(dtype, str)\n                and dtype == \"category\"\n                and is_categorical(data)\n            ):\n                dtype = data.dtype\n\n            dtype = self._validate_dtype(dtype)\n\n        if isinstance(data, MultiIndex):\n            raise NotImplementedError(\n                \"initializing a Series from a MultiIndex is not supported\"\n            )\n        elif isinstance(data, Index):\n            if name is None:\n                name = data.name\n\n            if dtype is not None:\n                # astype copies\n                data = data.astype(dtype)\n            else:\n                # need to copy to avoid aliasing issues\n                data = data._values.copy()\n                if isinstance(data, ABCDatetimeIndex) and data.tz is not None:\n                    # GH#24096 need copy to be deep for datetime64tz case\n                    # TODO: See if we can avoid these copies\n                    data = data._values.copy(deep=True)\n            copy = False\n\n        elif isinstance(data, np.ndarray):\n            pass\n        elif isinstance(data, (ABCSeries, ABCSparseSeries)):\n            if name is None:\n                name = data.name\n            if index is None:\n                index = data.index\n            else:\n                data = data.reindex(index, copy=copy)\n            data = data._data\n        elif isinstance(data, dict):\n            data, index = self._init_dict(data, index, dtype)\n            dtype = None\n            copy = False\n        elif isinstance(data, SingleBlockManager):\n            if index is None:\n                index = data.index\n            elif not data.index.equals(index) or copy:\n                # GH#19275 SingleBlockManager input should only be called\n                # internally\n                raise AssertionError(\n                    \"Cannot pass both SingleBlockManager \"\n                    \"`data` argument and a different \"\n                    \"`index` argument.  `copy` must \"\n                    \"be False.\"\n                )\n\n        elif is_extension_array_dtype(data):\n            pass\n        elif isinstance(data, (set, frozenset)):\n            raise TypeError(\n                \"{0!r} type is unordered\".format(data.__class__.__name__)\n            )\n        elif isinstance(data, ABCSparseArray):\n            # handle sparse passed here (and force conversion)\n            data = data.to_dense()\n        else:\n            data = com.maybe_iterable_to_list(data)\n\n        if index is None:\n            if not is_list_like(data):\n                data = [data]\n            index = ibase.default_index(len(data))\n        elif is_list_like(data):\n\n            # a scalar numpy array is list-like but doesn't\n            # have a proper length\n            try:\n                if len(index) != len(data):\n                    raise ValueError(\n                        \"Length of passed values is {val}, \"\n                        \"index implies {ind}\".format(val=len(data), ind=len(index))\n                    )\n            except TypeError:\n                pass\n\n        # create/copy the manager\n        if isinstance(data, SingleBlockManager):\n            if dtype is not None:\n                data = data.astype(dtype=dtype, errors=\"ignore\", copy=copy)\n            elif copy:\n                data = data.copy()\n        else:\n            data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True)\n\n            data = SingleBlockManager(data, index, fastpath=True)\n\n    generic.NDFrame.__init__(self, data, fastpath=True)\n\n    self.name = name\n    self._set_axis(0, index, fastpath=True)",
                "def _init_dict(self, data, index=None, dtype=None):\n    \"\"\"\n    Derive the \"_data\" and \"index\" attributes of a new Series from a\n    dictionary input.\n\n    Parameters\n    ----------\n    data : dict or dict-like\n        Data used to populate the new Series\n    index : Index or index-like, default None\n        index for the new Series: if None, use dict keys\n    dtype : dtype, default None\n        dtype for the new Series: if None, infer from data\n\n    Returns\n    -------\n    _data : BlockManager for the new Series\n    index : index for the new Series\n    \"\"\"\n    # Looking for NaN in dict doesn't work ({np.nan : 1}[float('nan')]\n    # raises KeyError), so we iterate the entire dict, and align\n    if data:\n        keys, values = zip(*data.items())\n        values = list(values)\n    elif index is not None:\n        # fastpath for Series(data=None). Just use broadcasting a scalar\n        # instead of reindexing.\n        values = na_value_for_dtype(dtype)\n        keys = index\n    else:\n        keys, values = [], []\n\n    # Input is now list-like, so rely on \"standard\" construction:\n    s = Series(values, index=keys, dtype=dtype)\n\n    # Now we just make sure the order is respected, if any\n    if data and index is not None:\n        s = s.reindex(index, copy=False)\n    elif not PY36 and not isinstance(data, OrderedDict) and data:\n        # Need the `and data` to avoid sorting Series(None, index=[...])\n        # since that isn't really dict-like\n        try:\n            s = s.sort_index()\n        except TypeError:\n            pass\n    return s._data, s.index",
                "@classmethod\ndef from_array(\n    cls, arr, index=None, name=None, dtype=None, copy=False, fastpath=False\n):\n    \"\"\"\n    Construct Series from array.\n\n    .. deprecated:: 0.23.0\n        Use pd.Series(..) constructor instead.\n\n    Returns\n    -------\n    Series\n        Constructed Series.\n    \"\"\"\n    warnings.warn(\n        \"'from_array' is deprecated and will be removed in a \"\n        \"future version. Please use the pd.Series(..) \"\n        \"constructor instead.\",\n        FutureWarning,\n        stacklevel=2,\n    )\n    if isinstance(arr, ABCSparseArray):\n        from pandas.core.sparse.series import SparseSeries\n\n        cls = SparseSeries\n    return cls(\n        arr, index=index, name=name, dtype=dtype, copy=copy, fastpath=fastpath\n    )",
                "@property\ndef _constructor(self):\n    return Series",
                "@property\ndef _constructor_expanddim(self):\n    from pandas.core.frame import DataFrame\n\n    return DataFrame",
                "@property\ndef _can_hold_na(self):\n    return self._data._can_hold_na",
                "def _set_axis(self, axis, labels, fastpath=False):\n    \"\"\"\n    Override generic, we want to set the _typ here.\n    \"\"\"\n\n    if not fastpath:\n        labels = ensure_index(labels)\n\n    is_all_dates = labels.is_all_dates\n    if is_all_dates:\n        if not isinstance(labels, (DatetimeIndex, PeriodIndex, TimedeltaIndex)):\n            try:\n                labels = DatetimeIndex(labels)\n                # need to set here because we changed the index\n                if fastpath:\n                    self._data.set_axis(axis, labels)\n            except (tslibs.OutOfBoundsDatetime, ValueError):\n                # labels may exceeds datetime bounds,\n                # or not be a DatetimeIndex\n                pass\n\n    self._set_subtyp(is_all_dates)\n\n    object.__setattr__(self, \"_index\", labels)\n    if not fastpath:\n        self._data.set_axis(axis, labels)",
                "def _set_subtyp(self, is_all_dates):\n    if is_all_dates:\n        object.__setattr__(self, \"_subtyp\", \"time_series\")\n    else:\n        object.__setattr__(self, \"_subtyp\", \"series\")",
                "def _update_inplace(self, result, **kwargs):\n    # we want to call the generic version and not the IndexOpsMixin\n    return generic.NDFrame._update_inplace(self, result, **kwargs)",
                "@property\ndef name(self):\n    \"\"\"\n    Return name of the Series.\n    \"\"\"\n    return self._name",
                "@name.setter\ndef name(self, value):\n    if value is not None and not is_hashable(value):\n        raise TypeError(\"Series.name must be a hashable type\")\n    object.__setattr__(self, \"_name\", value)",
                "@property\ndef dtype(self):\n    \"\"\"\n    Return the dtype object of the underlying data.\n    \"\"\"\n    return self._data.dtype",
                "@property\ndef dtypes(self):\n    \"\"\"\n    Return the dtype object of the underlying data.\n    \"\"\"\n    return self._data.dtype",
                "@property\ndef ftype(self):\n    \"\"\"\n    Return if the data is sparse|dense.\n\n    .. deprecated:: 0.25.0\n       Use :func:`dtype` instead.\n    \"\"\"\n    warnings.warn(\n        \"Series.ftype is deprecated and will \"\n        \"be removed in a future version. \"\n        \"Use Series.dtype instead.\",\n        FutureWarning,\n        stacklevel=2,\n    )\n\n    return self._data.ftype",
                "@property\ndef ftypes(self):\n    \"\"\"\n    Return if the data is sparse|dense.\n\n    .. deprecated:: 0.25.0\n       Use :func:`dtypes` instead.\n    \"\"\"\n    warnings.warn(\n        \"Series.ftypes is deprecated and will \"\n        \"be removed in a future version. \"\n        \"Use Series.dtype instead.\",\n        FutureWarning,\n        stacklevel=2,\n    )\n\n    return self._data.ftype",
                "@property\ndef values(self):\n    \"\"\"\n    Return Series as ndarray or ndarray-like depending on the dtype.\n\n    .. warning::\n\n       We recommend using :attr:`Series.array` or\n       :meth:`Series.to_numpy`, depending on whether you need\n       a reference to the underlying data or a NumPy array.\n\n    Returns\n    -------\n    numpy.ndarray or ndarray-like\n\n    See Also\n    --------\n    Series.array : Reference to the underlying data.\n    Series.to_numpy : A NumPy array representing the underlying data.\n\n    Examples\n    --------\n    >>> pd.Series([1, 2, 3]).values\n    array([1, 2, 3])\n\n    >>> pd.Series(list('aabc')).values\n    array(['a', 'a', 'b', 'c'], dtype=object)\n\n    >>> pd.Series(list('aabc')).astype('category').values\n    [a, a, b, c]\n    Categories (3, object): [a, b, c]\n\n    Timezone aware datetime data is converted to UTC:\n\n    >>> pd.Series(pd.date_range('20130101', periods=3,\n    ...                         tz='US/Eastern')).values\n    array(['2013-01-01T05:00:00.000000000',\n           '2013-01-02T05:00:00.000000000',\n           '2013-01-03T05:00:00.000000000'], dtype='datetime64[ns]')\n    \"\"\"\n    return self._data.external_values()",
                "@property\ndef _values(self):\n    \"\"\"\n    Return the internal repr of this data.\n    \"\"\"\n    return self._data.internal_values()",
                "def get_values(self):\n    \"\"\"\n    Same as values (but handles sparseness conversions); is a view.\n\n    .. deprecated:: 0.25.0\n        Use :meth:`Series.to_numpy` or :attr:`Series.array` instead.\n\n    Returns\n    -------\n    numpy.ndarray\n        Data of the Series.\n    \"\"\"\n    warnings.warn(\n        \"The 'get_values' method is deprecated and will be removed in a \"\n        \"future version. Use '.to_numpy()' or '.array' instead.\",\n        FutureWarning,\n        stacklevel=2,\n    )\n    return self._internal_get_values()",
                "def _internal_get_values(self):\n    return self._data.get_values()",
                "@property\ndef asobject(self):\n    \"\"\"\n    Return object Series which contains boxed values.\n\n    .. deprecated:: 0.23.0\n\n       Use ``astype(object)`` instead.\n\n    *this is an internal non-public method*\n    \"\"\"\n    warnings.warn(\n        \"'asobject' is deprecated. Use 'astype(object)' instead\",\n        FutureWarning,\n        stacklevel=2,\n    )\n    return self.astype(object).values",
                "def ravel(self, order=\"C\"):\n    \"\"\"\n    Return the flattened underlying data as an ndarray.\n\n    Returns\n    -------\n    numpy.ndarray or ndarray-like\n        Flattened data of the Series.\n\n    See Also\n    --------\n    numpy.ndarray.ravel\n    \"\"\"\n    return self._values.ravel(order=order)",
                "def compress(self, condition, *args, **kwargs):\n    \"\"\"\n    Return selected slices of an array along given axis as a Series.\n\n    .. deprecated:: 0.24.0\n\n    Returns\n    -------\n    Series\n        Series without the slices for which condition is false.\n\n    See Also\n    --------\n    numpy.ndarray.compress\n    \"\"\"\n    msg = (\n        \"Series.compress(condition) is deprecated. \"\n        \"Use 'Series[condition]' or \"\n        \"'np.asarray(series).compress(condition)' instead.\"\n    )\n    warnings.warn(msg, FutureWarning, stacklevel=2)\n    nv.validate_compress(args, kwargs)\n    return self[condition]",
                "def nonzero(self):\n    \"\"\"\n    Return the *integer* indices of the elements that are non-zero.\n\n    .. deprecated:: 0.24.0\n       Please use .to_numpy().nonzero() as a replacement.\n\n    This method is equivalent to calling `numpy.nonzero` on the\n    series data. For compatibility with NumPy, the return value is\n    the same (a tuple with an array of indices for each dimension),\n    but it will always be a one-item tuple because series only have\n    one dimension.\n\n    Returns\n    -------\n    numpy.ndarray\n        Indices of elements that are non-zero.\n\n    See Also\n    --------\n    numpy.nonzero\n\n    Examples\n    --------\n    >>> s = pd.Series([0, 3, 0, 4])\n    >>> s.nonzero()\n    (array([1, 3]),)\n    >>> s.iloc[s.nonzero()[0]]\n    1    3\n    3    4\n    dtype: int64\n\n    # same return although index of s is different\n    >>> s = pd.Series([0, 3, 0, 4], index=['a', 'b', 'c', 'd'])\n    >>> s.nonzero()\n    (array([1, 3]),)\n    >>> s.iloc[s.nonzero()[0]]\n    b    3\n    d    4\n    dtype: int64\n    \"\"\"\n    msg = (\n        \"Series.nonzero() is deprecated \"\n        \"and will be removed in a future version.\"\n        \"Use Series.to_numpy().nonzero() instead\"\n    )\n    warnings.warn(msg, FutureWarning, stacklevel=2)\n    return self._values.nonzero()",
                "def put(self, *args, **kwargs):\n    \"\"\"\n    Apply the `put` method to its `values` attribute if it has one.\n\n    .. deprecated:: 0.25.0\n\n    See Also\n    --------\n    numpy.ndarray.put\n    \"\"\"\n    warnings.warn(\n        \"`put` has been deprecated and will be removed in a future version.\",\n        FutureWarning,\n        stacklevel=2,\n    )\n    self._values.put(*args, **kwargs)",
                "def __len__(self):\n    \"\"\"\n    Return the length of the Series.\n    \"\"\"\n    return len(self._data)",
                "def view(self, dtype=None):\n    \"\"\"\n    Create a new view of the Series.\n\n    This function will return a new Series with a view of the same\n    underlying values in memory, optionally reinterpreted with a new data\n    type. The new data type must preserve the same size in bytes as to not\n    cause index misalignment.\n\n    Parameters\n    ----------\n    dtype : data type\n        Data type object or one of their string representations.\n\n    Returns\n    -------\n    Series\n        A new Series object as a view of the same data in memory.\n\n    See Also\n    --------\n    numpy.ndarray.view : Equivalent numpy function to create a new view of\n        the same data in memory.\n\n    Notes\n    -----\n    Series are instantiated with ``dtype=float64`` by default. While\n    ``numpy.ndarray.view()`` will return a view with the same data type as\n    the original array, ``Series.view()`` (without specified dtype)\n    will try using ``float64`` and may fail if the original data type size\n    in bytes is not the same.\n\n    Examples\n    --------\n    >>> s = pd.Series([-2, -1, 0, 1, 2], dtype='int8')\n    >>> s\n    0   -2\n    1   -1\n    2    0\n    3    1\n    4    2\n    dtype: int8\n\n    The 8 bit signed integer representation of `-1` is `0b11111111`, but\n    the same bytes represent 255 if read as an 8 bit unsigned integer:\n\n    >>> us = s.view('uint8')\n    >>> us\n    0    254\n    1    255\n    2      0\n    3      1\n    4      2\n    dtype: uint8\n\n    The views share the same underlying values:\n\n    >>> us[0] = 128\n    >>> s\n    0   -128\n    1     -1\n    2      0\n    3      1\n    4      2\n    dtype: int8\n    \"\"\"\n    return self._constructor(\n        self._values.view(dtype), index=self.index\n    ).__finalize__(self)",
                "def __array_ufunc__(\n    self, ufunc: Callable, method: str, *inputs: Any, **kwargs: Any\n):\n    # TODO: handle DataFrame\n    cls = type(self)\n\n    # for binary ops, use our custom dunder methods\n    result = ops.maybe_dispatch_ufunc_to_dunder_op(\n        self, ufunc, method, *inputs, **kwargs\n    )\n    if result is not NotImplemented:\n        return result\n\n    # Determine if we should defer.\n    no_defer = (np.ndarray.__array_ufunc__, cls.__array_ufunc__)\n\n    for item in inputs:\n        higher_priority = (\n            hasattr(item, \"__array_priority__\")\n            and item.__array_priority__ > self.__array_priority__\n        )\n        has_array_ufunc = (\n            hasattr(item, \"__array_ufunc__\")\n            and type(item).__array_ufunc__ not in no_defer\n            and not isinstance(item, self._HANDLED_TYPES)\n        )\n        if higher_priority or has_array_ufunc:\n            return NotImplemented\n\n    # align all the inputs.\n    names = [getattr(x, \"name\") for x in inputs if hasattr(x, \"name\")]\n    types = tuple(type(x) for x in inputs)\n    # TODO: dataframe\n    alignable = [x for x, t in zip(inputs, types) if issubclass(t, Series)]\n\n    if len(alignable) > 1:\n        # This triggers alignment.\n        # At the moment, there aren't any ufuncs with more than two inputs\n        # so this ends up just being x1.index | x2.index, but we write\n        # it to handle *args.\n        index = alignable[0].index\n        for s in alignable[1:]:\n            index |= s.index\n        inputs = tuple(\n            x.reindex(index) if issubclass(t, Series) else x\n            for x, t in zip(inputs, types)\n        )\n    else:\n        index = self.index\n\n    inputs = tuple(extract_array(x, extract_numpy=True) for x in inputs)\n    result = getattr(ufunc, method)(*inputs, **kwargs)\n    if len(set(names)) == 1:\n        # we require names to be hashable, right?\n        name = names[0]  # type: Any\n    else:\n        name = None\n\n    def construct_return(result):\n        if lib.is_scalar(result):\n            return result\n        elif result.ndim > 1:\n            # e.g. np.subtract.outer\n            if method == \"outer\":\n                msg = (\n                    \"outer method for ufunc {} is not implemented on \"\n                    \"pandas objects. Returning an ndarray, but in the \"\n                    \"future this will raise a 'NotImplementedError'. \"\n                    \"Consider explicitly converting the Series \"\n                    \"to an array with '.array' first.\"\n                )\n                warnings.warn(msg.format(ufunc), FutureWarning, stacklevel=3)\n            return result\n        return self._constructor(result, index=index, name=name, copy=False)\n\n    if type(result) is tuple:\n        # multiple return values\n        return tuple(construct_return(x) for x in result)\n    elif method == \"at\":\n        # no return value\n        return None\n    else:\n        return construct_return(result)",
                "def __array__(self, dtype=None):\n    \"\"\"\n    Return the values as a NumPy array.\n\n    Users should not call this directly. Rather, it is invoked by\n    :func:`numpy.array` and :func:`numpy.asarray`.\n\n    Parameters\n    ----------\n    dtype : str or numpy.dtype, optional\n        The dtype to use for the resulting NumPy array. By default,\n        the dtype is inferred from the data.\n\n    Returns\n    -------\n    numpy.ndarray\n        The values in the series converted to a :class:`numpy.ndarary`\n        with the specified `dtype`.\n\n    See Also\n    --------\n    array : Create a new array from data.\n    Series.array : Zero-copy view to the array backing the Series.\n    Series.to_numpy : Series method for similar behavior.\n\n    Examples\n    --------\n    >>> ser = pd.Series([1, 2, 3])\n    >>> np.asarray(ser)\n    array([1, 2, 3])\n\n    For timezone-aware data, the timezones may be retained with\n    ``dtype='object'``\n\n    >>> tzser = pd.Series(pd.date_range('2000', periods=2, tz=\"CET\"))\n    >>> np.asarray(tzser, dtype=\"object\")\n    array([Timestamp('2000-01-01 00:00:00+0100', tz='CET', freq='D'),\n           Timestamp('2000-01-02 00:00:00+0100', tz='CET', freq='D')],\n          dtype=object)\n\n    Or the values may be localized to UTC and the tzinfo discared with\n    ``dtype='datetime64[ns]'``\n\n    >>> np.asarray(tzser, dtype=\"datetime64[ns]\")  # doctest: +ELLIPSIS\n    array(['1999-12-31T23:00:00.000000000', ...],\n          dtype='datetime64[ns]')\n    \"\"\"\n    if (\n        dtype is None\n        and isinstance(self.array, ABCDatetimeArray)\n        and getattr(self.dtype, \"tz\", None)\n    ):\n        msg = (\n            \"Converting timezone-aware DatetimeArray to timezone-naive \"\n            \"ndarray with 'datetime64[ns]' dtype. In the future, this \"\n            \"will return an ndarray with 'object' dtype where each \"\n            \"element is a 'pandas.Timestamp' with the correct 'tz'.\\n\\t\"\n            \"To accept the future behavior, pass 'dtype=object'.\\n\\t\"\n            \"To keep the old behavior, pass 'dtype=\\\"datetime64[ns]\\\"'.\"\n        )\n        warnings.warn(msg, FutureWarning, stacklevel=3)\n        dtype = \"M8[ns]\"\n    return np.asarray(self.array, dtype)",
                "@property\ndef real(self):\n    \"\"\"\n    Return the real value of vector.\n\n    .. deprecated:: 0.25.0\n    \"\"\"\n    warnings.warn(\n        \"`real` is deprecated and will be removed in a future version. \"\n        \"To eliminate this warning for a Series `ser`, use \"\n        \"`np.real(ser.to_numpy())` or `ser.to_numpy().real`.\",\n        FutureWarning,\n        stacklevel=2,\n    )\n    return self.values.real",
                "@real.setter\ndef real(self, v):\n    self.values.real = v",
                "@property\ndef imag(self):\n    \"\"\"\n    Return imag value of vector.\n\n    .. deprecated:: 0.25.0\n    \"\"\"\n    warnings.warn(\n        \"`imag` is deprecated and will be removed in a future version. \"\n        \"To eliminate this warning for a Series `ser`, use \"\n        \"`np.imag(ser.to_numpy())` or `ser.to_numpy().imag`.\",\n        FutureWarning,\n        stacklevel=2,\n    )\n    return self.values.imag",
                "@imag.setter\ndef imag(self, v):\n    self.values.imag = v",
                "def _unpickle_series_compat(self, state):\n    if isinstance(state, dict):\n        self._data = state[\"_data\"]\n        self.name = state[\"name\"]\n        self.index = self._data.index\n\n    elif isinstance(state, tuple):\n\n        # < 0.12 series pickle\n\n        nd_state, own_state = state\n\n        # recreate the ndarray\n        data = np.empty(nd_state[1], dtype=nd_state[2])\n        np.ndarray.__setstate__(data, nd_state)\n\n        # backwards compat\n        index, name = own_state[0], None\n        if len(own_state) > 1:\n            name = own_state[1]\n\n        # recreate\n        self._data = SingleBlockManager(data, index, fastpath=True)\n        self._index = index\n        self.name = name\n\n    else:\n        raise Exception(\"cannot unpickle legacy formats -> [%s]\" % state)",
                "@property\ndef axes(self):\n    \"\"\"\n    Return a list of the row axis labels.\n    \"\"\"\n    return [self.index]",
                "@Appender(generic.NDFrame.take.__doc__)\ndef take(self, indices, axis=0, is_copy=False, **kwargs):\n    nv.validate_take(tuple(), kwargs)\n\n    indices = ensure_platform_int(indices)\n    new_index = self.index.take(indices)\n\n    if is_categorical_dtype(self):\n        # https://github.com/pandas-dev/pandas/issues/20664\n        # TODO: remove when the default Categorical.take behavior changes\n        indices = maybe_convert_indices(indices, len(self._get_axis(axis)))\n        kwargs = {\"allow_fill\": False}\n    else:\n        kwargs = {}\n    new_values = self._values.take(indices, **kwargs)\n\n    result = self._constructor(\n        new_values, index=new_index, fastpath=True\n    ).__finalize__(self)\n\n    # Maybe set copy if we didn't actually change the index.\n    if is_copy:\n        if not result._get_axis(axis).equals(self._get_axis(axis)):\n            result._set_is_copy(self)\n\n    return result",
                "def _ixs(self, i: int, axis: int = 0):\n    \"\"\"\n    Return the i-th value or values in the Series by location.\n\n    Parameters\n    ----------\n    i : int\n\n    Returns\n    -------\n    scalar (int) or Series (slice, sequence)\n    \"\"\"\n\n    # dispatch to the values if we need\n    values = self._values\n    if isinstance(values, np.ndarray):\n        return libindex.get_value_at(values, i)\n    else:\n        return values[i]",
                "def _slice(self, slobj: slice, axis: int = 0, kind=None):\n    slobj = self.index._convert_slice_indexer(slobj, kind=kind or \"getitem\")\n    return self._get_values(slobj)",
                "def __getitem__(self, key):\n    key = com.apply_if_callable(key, self)\n    try:\n        result = self.index.get_value(self, key)\n\n        if not is_scalar(result):\n            if is_list_like(result) and not isinstance(result, Series):\n\n                # we need to box if loc of the key isn't scalar here\n                # otherwise have inline ndarray/lists\n                try:\n                    if not is_scalar(self.index.get_loc(key)):\n                        result = self._constructor(\n                            result, index=[key] * len(result), dtype=self.dtype\n                        ).__finalize__(self)\n                except KeyError:\n                    pass\n        return result\n    except InvalidIndexError:\n        pass\n    except (KeyError, ValueError):\n        if isinstance(key, tuple) and isinstance(self.index, MultiIndex):\n            # kludge\n            pass\n        elif key is Ellipsis:\n            return self\n        elif com.is_bool_indexer(key):\n            pass\n        else:\n\n            # we can try to coerce the indexer (or this will raise)\n            new_key = self.index._convert_scalar_indexer(key, kind=\"getitem\")\n            if type(new_key) != type(key):\n                return self.__getitem__(new_key)\n            raise\n\n    if is_iterator(key):\n        key = list(key)\n\n    if com.is_bool_indexer(key):\n        key = check_bool_indexer(self.index, key)\n\n    return self._get_with(key)",
                "def _get_with(self, key):\n    # other: fancy integer or otherwise\n    if isinstance(key, slice):\n        return self._slice(key)\n    elif isinstance(key, ABCDataFrame):\n        raise TypeError(\n            \"Indexing a Series with DataFrame is not \"\n            \"supported, use the appropriate DataFrame column\"\n        )\n    elif isinstance(key, tuple):\n        try:\n            return self._get_values_tuple(key)\n        except Exception:\n            if len(key) == 1:\n                key = key[0]\n                if isinstance(key, slice):\n                    return self._get_values(key)\n            raise\n\n    if not isinstance(key, (list, np.ndarray, Series, Index)):\n        key = list(key)\n\n    if isinstance(key, Index):\n        key_type = key.inferred_type\n    else:\n        key_type = lib.infer_dtype(key, skipna=False)\n\n    if key_type == \"integer\":\n        if self.index.is_integer() or self.index.is_floating():\n            return self.loc[key]\n        else:\n            return self._get_values(key)\n    elif key_type == \"boolean\":\n        return self._get_values(key)\n\n    if isinstance(key, (list, tuple)):\n        # TODO: de-dup with tuple case handled above?\n        # handle the dup indexing case GH#4246\n        if len(key) == 1 and isinstance(key[0], slice):\n            # [slice(0, 5, None)] will break if you convert to ndarray,\n            # e.g. as requested by np.median\n            # FIXME: hack\n            return self._get_values(key)\n\n        return self.loc[key]\n\n    return self.reindex(key)",
                "def _get_values_tuple(self, key):\n    # mpl hackaround\n    if com.any_none(*key):\n        return self._get_values(key)\n\n    if not isinstance(self.index, MultiIndex):\n        raise ValueError(\"Can only tuple-index with a MultiIndex\")\n\n    # If key is contained, would have returned by now\n    indexer, new_index = self.index.get_loc_level(key)\n    return self._constructor(self._values[indexer], index=new_index).__finalize__(\n        self\n    )",
                "def _get_values(self, indexer):\n    try:\n        return self._constructor(\n            self._data.get_slice(indexer), fastpath=True\n        ).__finalize__(self)\n    except Exception:\n        return self._values[indexer]",
                "def _get_value(self, label, takeable: bool = False):\n    \"\"\"\n    Quickly retrieve single value at passed index label.\n\n    Parameters\n    ----------\n    label : object\n    takeable : interpret the index as indexers, default False\n\n    Returns\n    -------\n    scalar value\n    \"\"\"\n    if takeable:\n        return com.maybe_box_datetimelike(self._values[label])\n    return self.index.get_value(self._values, label)",
                "def __setitem__(self, key, value):\n    key = com.apply_if_callable(key, self)\n    cacher_needs_updating = self._check_is_chained_assignment_possible()\n\n    try:\n        self._set_with_engine(key, value)\n    except com.SettingWithCopyError:\n        raise\n    except (KeyError, ValueError):\n        values = self._values\n        if is_integer(key) and not self.index.inferred_type == \"integer\":\n            values[key] = value\n        elif key is Ellipsis:\n            self[:] = value\n        else:\n            self.loc[key] = value\n\n    except TypeError as e:\n        if isinstance(key, tuple) and not isinstance(self.index, MultiIndex):\n            raise ValueError(\"Can only tuple-index with a MultiIndex\")\n\n        # python 3 type errors should be raised\n        if _is_unorderable_exception(e):\n            raise IndexError(key)\n\n        if com.is_bool_indexer(key):\n            key = check_bool_indexer(self.index, key)\n            try:\n                self._where(~key, value, inplace=True)\n                return\n            except InvalidIndexError:\n                pass\n\n        self._set_with(key, value)\n\n    if cacher_needs_updating:\n        self._maybe_update_cacher()",
                "def _set_with_engine(self, key, value):\n    values = self._values\n    if is_extension_array_dtype(values.dtype):\n        # The cython indexing engine does not support ExtensionArrays.\n        values[self.index.get_loc(key)] = value\n        return\n    try:\n        self.index._engine.set_value(values, key, value)\n        return\n    except KeyError:\n        values[self.index.get_loc(key)] = value\n        return",
                "def _set_with(self, key, value):\n    # other: fancy integer or otherwise\n    if isinstance(key, slice):\n        indexer = self.index._convert_slice_indexer(key, kind=\"getitem\")\n        return self._set_values(indexer, value)\n\n    elif is_scalar(key) and not is_integer(key) and key not in self.index:\n        # GH#12862 adding an new key to the Series\n        # Note: have to exclude integers because that is ambiguously\n        #  position-based\n        self.loc[key] = value\n        return\n\n    else:\n        if isinstance(key, tuple):\n            try:\n                self._set_values(key, value)\n            except Exception:\n                pass\n\n        if is_scalar(key):\n            key = [key]\n        elif not isinstance(key, (list, Series, np.ndarray)):\n            try:\n                key = list(key)\n            except Exception:\n                key = [key]\n\n        if isinstance(key, Index):\n            key_type = key.inferred_type\n            key = key._values\n        else:\n            key_type = lib.infer_dtype(key, skipna=False)\n\n        if key_type == \"integer\":\n            if self.index.inferred_type == \"integer\":\n                self._set_labels(key, value)\n            else:\n                return self._set_values(key, value)\n        elif key_type == \"boolean\":\n            self._set_values(key.astype(np.bool_), value)\n        else:\n            self._set_labels(key, value)",
                "def _set_labels(self, key, value):\n    key = com.asarray_tuplesafe(key)\n    indexer = self.index.get_indexer(key)\n    mask = indexer == -1\n    if mask.any():\n        raise ValueError(\"%s not contained in the index\" % str(key[mask]))\n    self._set_values(indexer, value)",
                "def _set_values(self, key, value):\n    if isinstance(key, Series):\n        key = key._values\n    self._data = self._data.setitem(indexer=key, value=value)\n    self._maybe_update_cacher()",
                "def _set_value(self, label, value, takeable: bool = False):\n    \"\"\"\n    Quickly set single value at passed label.\n\n    If label is not contained, a new object is created with the label\n    placed at the end of the result index.\n\n    Parameters\n    ----------\n    label : object\n        Partial indexing with MultiIndex not allowed\n    value : object\n        Scalar value\n    takeable : interpret the index as indexers, default False\n\n    Returns\n    -------\n    Series\n        If label is contained, will be reference to calling Series,\n        otherwise a new object.\n    \"\"\"\n    try:\n        if takeable:\n            self._values[label] = value\n        else:\n            self.index._engine.set_value(self._values, label, value)\n    except (KeyError, TypeError):\n\n        # set using a non-recursive method\n        self.loc[label] = value\n\n    return self",
                "@property\ndef _is_mixed_type(self):\n    return False",
                "def repeat(self, repeats, axis=None):\n    \"\"\"\n    Repeat elements of a Series.\n\n    Returns a new Series where each element of the current Series\n    is repeated consecutively a given number of times.\n\n    Parameters\n    ----------\n    repeats : int or array of ints\n        The number of repetitions for each element. This should be a\n        non-negative integer. Repeating 0 times will return an empty\n        Series.\n    axis : None\n        Must be ``None``. Has no effect but is accepted for compatibility\n        with numpy.\n\n    Returns\n    -------\n    Series\n        Newly created Series with repeated elements.\n\n    See Also\n    --------\n    Index.repeat : Equivalent function for Index.\n    numpy.repeat : Similar method for :class:`numpy.ndarray`.\n\n    Examples\n    --------\n    >>> s = pd.Series(['a', 'b', 'c'])\n    >>> s\n    0    a\n    1    b\n    2    c\n    dtype: object\n    >>> s.repeat(2)\n    0    a\n    0    a\n    1    b\n    1    b\n    2    c\n    2    c\n    dtype: object\n    >>> s.repeat([1, 2, 3])\n    0    a\n    1    b\n    1    b\n    2    c\n    2    c\n    2    c\n    dtype: object\n    \"\"\"\n    nv.validate_repeat(tuple(), dict(axis=axis))\n    new_index = self.index.repeat(repeats)\n    new_values = self._values.repeat(repeats)\n    return self._constructor(new_values, index=new_index).__finalize__(self)",
                "def reset_index(self, level=None, drop=False, name=None, inplace=False):\n    \"\"\"\n    Generate a new DataFrame or Series with the index reset.\n\n    This is useful when the index needs to be treated as a column, or\n    when the index is meaningless and needs to be reset to the default\n    before another operation.\n\n    Parameters\n    ----------\n    level : int, str, tuple, or list, default optional\n        For a Series with a MultiIndex, only remove the specified levels\n        from the index. Removes all levels by default.\n    drop : bool, default False\n        Just reset the index, without inserting it as a column in\n        the new DataFrame.\n    name : object, optional\n        The name to use for the column containing the original Series\n        values. Uses ``self.name`` by default. This argument is ignored\n        when `drop` is True.\n    inplace : bool, default False\n        Modify the Series in place (do not create a new object).\n\n    Returns\n    -------\n    Series or DataFrame\n        When `drop` is False (the default), a DataFrame is returned.\n        The newly created columns will come first in the DataFrame,\n        followed by the original Series values.\n        When `drop` is True, a `Series` is returned.\n        In either case, if ``inplace=True``, no value is returned.\n\n    See Also\n    --------\n    DataFrame.reset_index: Analogous function for DataFrame.\n\n    Examples\n    --------\n    >>> s = pd.Series([1, 2, 3, 4], name='foo',\n    ...               index=pd.Index(['a', 'b', 'c', 'd'], name='idx'))\n\n    Generate a DataFrame with default index.\n\n    >>> s.reset_index()\n      idx  foo\n    0   a    1\n    1   b    2\n    2   c    3\n    3   d    4\n\n    To specify the name of the new column use `name`.\n\n    >>> s.reset_index(name='values')\n      idx  values\n    0   a       1\n    1   b       2\n    2   c       3\n    3   d       4\n\n    To generate a new Series with the default set `drop` to True.\n\n    >>> s.reset_index(drop=True)\n    0    1\n    1    2\n    2    3\n    3    4\n    Name: foo, dtype: int64\n\n    To update the Series in place, without generating a new one\n    set `inplace` to True. Note that it also requires ``drop=True``.\n\n    >>> s.reset_index(inplace=True, drop=True)\n    >>> s\n    0    1\n    1    2\n    2    3\n    3    4\n    Name: foo, dtype: int64\n\n    The `level` parameter is interesting for Series with a multi-level\n    index.\n\n    >>> arrays = [np.array(['bar', 'bar', 'baz', 'baz']),\n    ...           np.array(['one', 'two', 'one', 'two'])]\n    >>> s2 = pd.Series(\n    ...     range(4), name='foo',\n    ...     index=pd.MultiIndex.from_arrays(arrays,\n    ...                                     names=['a', 'b']))\n\n    To remove a specific level from the Index, use `level`.\n\n    >>> s2.reset_index(level='a')\n           a  foo\n    b\n    one  bar    0\n    two  bar    1\n    one  baz    2\n    two  baz    3\n\n    If `level` is not set, all levels are removed from the Index.\n\n    >>> s2.reset_index()\n         a    b  foo\n    0  bar  one    0\n    1  bar  two    1\n    2  baz  one    2\n    3  baz  two    3\n    \"\"\"\n    inplace = validate_bool_kwarg(inplace, \"inplace\")\n    if drop:\n        new_index = ibase.default_index(len(self))\n        if level is not None:\n            if not isinstance(level, (tuple, list)):\n                level = [level]\n            level = [self.index._get_level_number(lev) for lev in level]\n            if len(level) < self.index.nlevels:\n                new_index = self.index.droplevel(level)\n\n        if inplace:\n            self.index = new_index\n            # set name if it was passed, otherwise, keep the previous name\n            self.name = name or self.name\n        else:\n            return self._constructor(\n                self._values.copy(), index=new_index\n            ).__finalize__(self)\n    elif inplace:\n        raise TypeError(\n            \"Cannot reset_index inplace on a Series to create a DataFrame\"\n        )\n    else:\n        df = self.to_frame(name)\n        return df.reset_index(level=level, drop=drop)",
                "def __repr__(self):\n    \"\"\"\n    Return a string representation for a particular Series.\n    \"\"\"\n    buf = StringIO(\"\")\n    width, height = get_terminal_size()\n    max_rows = (\n        height\n        if get_option(\"display.max_rows\") == 0\n        else get_option(\"display.max_rows\")\n    )\n    min_rows = (\n        height\n        if get_option(\"display.max_rows\") == 0\n        else get_option(\"display.min_rows\")\n    )\n    show_dimensions = get_option(\"display.show_dimensions\")\n\n    self.to_string(\n        buf=buf,\n        name=self.name,\n        dtype=self.dtype,\n        min_rows=min_rows,\n        max_rows=max_rows,\n        length=show_dimensions,\n    )\n    result = buf.getvalue()\n\n    return result",
                "def to_string(\n    self,\n    buf=None,\n    na_rep=\"NaN\",\n    float_format=None,\n    header=True,\n    index=True,\n    length=False,\n    dtype=False,\n    name=False,\n    max_rows=None,\n    min_rows=None,\n):\n    \"\"\"\n    Render a string representation of the Series.\n\n    Parameters\n    ----------\n    buf : StringIO-like, optional\n        Buffer to write to.\n    na_rep : str, optional\n        String representation of NaN to use, default 'NaN'.\n    float_format : one-parameter function, optional\n        Formatter function to apply to columns' elements if they are\n        floats, default None.\n    header : bool, default True\n        Add the Series header (index name).\n    index : bool, optional\n        Add index (row) labels, default True.\n    length : bool, default False\n        Add the Series length.\n    dtype : bool, default False\n        Add the Series dtype.\n    name : bool, default False\n        Add the Series name if not None.\n    max_rows : int, optional\n        Maximum number of rows to show before truncating. If None, show\n        all.\n    min_rows : int, optional\n        The number of rows to display in a truncated repr (when number\n        of rows is above `max_rows`).\n\n    Returns\n    -------\n    str or None\n        String representation of Series if ``buf=None``, otherwise None.\n    \"\"\"\n\n    formatter = fmt.SeriesFormatter(\n        self,\n        name=name,\n        length=length,\n        header=header,\n        index=index,\n        dtype=dtype,\n        na_rep=na_rep,\n        float_format=float_format,\n        min_rows=min_rows,\n        max_rows=max_rows,\n    )\n    result = formatter.to_string()\n\n    # catch contract violations\n    if not isinstance(result, str):\n        raise AssertionError(\n            \"result must be of type unicode, type\"\n            \" of result is {0!r}\"\n            \"\".format(result.__class__.__name__)\n        )\n\n    if buf is None:\n        return result\n    else:\n        try:\n            buf.write(result)\n        except AttributeError:\n            with open(buf, \"w\") as f:\n                f.write(result)",
                "def items(self):\n    \"\"\"\n    Lazily iterate over (index, value) tuples.\n\n    This method returns an iterable tuple (index, value). This is\n    convenient if you want to create a lazy iterator.\n\n    Returns\n    -------\n    iterable\n        Iterable of tuples containing the (index, value) pairs from a\n        Series.\n\n    See Also\n    --------\n    DataFrame.items : Iterate over (column name, Series) pairs.\n    DataFrame.iterrows : Iterate over DataFrame rows as (index, Series) pairs.\n\n    Examples\n    --------\n    >>> s = pd.Series(['A', 'B', 'C'])\n    >>> for index, value in s.items():\n    ...     print(\"Index : {}, Value : {}\".format(index, value))\n    Index : 0, Value : A\n    Index : 1, Value : B\n    Index : 2, Value : C\n    \"\"\"\n    return zip(iter(self.index), iter(self))",
                "@Appender(items.__doc__)\ndef iteritems(self):\n    return self.items()",
                "def keys(self):\n    \"\"\"\n    Return alias for index.\n\n    Returns\n    -------\n    Index\n        Index of the Series.\n    \"\"\"\n    return self.index",
                "def to_dict(self, into=dict):\n    \"\"\"\n    Convert Series to {label -> value} dict or dict-like object.\n\n    Parameters\n    ----------\n    into : class, default dict\n        The collections.abc.Mapping subclass to use as the return\n        object. Can be the actual class or an empty\n        instance of the mapping type you want.  If you want a\n        collections.defaultdict, you must pass it initialized.\n\n        .. versionadded:: 0.21.0\n\n    Returns\n    -------\n    collections.abc.Mapping\n        Key-value representation of Series.\n\n    Examples\n    --------\n    >>> s = pd.Series([1, 2, 3, 4])\n    >>> s.to_dict()\n    {0: 1, 1: 2, 2: 3, 3: 4}\n    >>> from collections import OrderedDict, defaultdict\n    >>> s.to_dict(OrderedDict)\n    OrderedDict([(0, 1), (1, 2), (2, 3), (3, 4)])\n    >>> dd = defaultdict(list)\n    >>> s.to_dict(dd)\n    defaultdict(<class 'list'>, {0: 1, 1: 2, 2: 3, 3: 4})\n    \"\"\"\n    # GH16122\n    into_c = com.standardize_mapping(into)\n    return into_c(self.items())",
                "def to_frame(self, name=None):\n    \"\"\"\n    Convert Series to DataFrame.\n\n    Parameters\n    ----------\n    name : object, default None\n        The passed name should substitute for the series name (if it has\n        one).\n\n    Returns\n    -------\n    DataFrame\n        DataFrame representation of Series.\n\n    Examples\n    --------\n    >>> s = pd.Series([\"a\", \"b\", \"c\"],\n    ...               name=\"vals\")\n    >>> s.to_frame()\n      vals\n    0    a\n    1    b\n    2    c\n    \"\"\"\n    if name is None:\n        df = self._constructor_expanddim(self)\n    else:\n        df = self._constructor_expanddim({name: self})\n\n    return df",
                "def to_sparse(self, kind=\"block\", fill_value=None):\n    \"\"\"\n    Convert Series to SparseSeries.\n\n    .. deprecated:: 0.25.0\n\n    Parameters\n    ----------\n    kind : {'block', 'integer'}, default 'block'\n    fill_value : float, defaults to NaN (missing)\n        Value to use for filling NaN values.\n\n    Returns\n    -------\n    SparseSeries\n        Sparse representation of the Series.\n    \"\"\"\n\n    warnings.warn(\n        \"Series.to_sparse is deprecated and will be removed in a future version\",\n        FutureWarning,\n        stacklevel=2,\n    )\n    from pandas.core.sparse.series import SparseSeries\n\n    values = SparseArray(self, kind=kind, fill_value=fill_value)\n    with warnings.catch_warnings():\n        warnings.filterwarnings(\"ignore\", message=\"SparseSeries\")\n        return SparseSeries(values, index=self.index, name=self.name).__finalize__(\n            self\n        )",
                "def _set_name(self, name, inplace=False):\n    \"\"\"\n    Set the Series name.\n\n    Parameters\n    ----------\n    name : str\n    inplace : bool\n        whether to modify `self` directly or return a copy\n    \"\"\"\n    inplace = validate_bool_kwarg(inplace, \"inplace\")\n    ser = self if inplace else self.copy()\n    ser.name = name\n    return ser",
                "def count(self, level=None):\n    \"\"\"\n    Return number of non-NA/null observations in the Series.\n\n    Parameters\n    ----------\n    level : int or level name, default None\n        If the axis is a MultiIndex (hierarchical), count along a\n        particular level, collapsing into a smaller Series.\n\n    Returns\n    -------\n    int or Series (if level specified)\n        Number of non-null values in the Series.\n\n    Examples\n    --------\n    >>> s = pd.Series([0.0, 1.0, np.nan])\n    >>> s.count()\n    2\n    \"\"\"\n    if level is None:\n        return notna(self.array).sum()\n\n    if isinstance(level, str):\n        level = self.index._get_level_number(level)\n\n    lev = self.index.levels[level]\n    level_codes = np.array(self.index.codes[level], subok=False, copy=True)\n\n    mask = level_codes == -1\n    if mask.any():\n        level_codes[mask] = cnt = len(lev)\n        lev = lev.insert(cnt, lev._na_value)\n\n    obs = level_codes[notna(self.values)]\n    out = np.bincount(obs, minlength=len(lev) or None)\n    return self._constructor(out, index=lev, dtype=\"int64\").__finalize__(self)",
                "def mode(self, dropna=True):\n    \"\"\"\n    Return the mode(s) of the dataset.\n\n    Always returns Series even if only one value is returned.\n\n    Parameters\n    ----------\n    dropna : bool, default True\n        Don't consider counts of NaN/NaT.\n\n        .. versionadded:: 0.24.0\n\n    Returns\n    -------\n    Series\n        Modes of the Series in sorted order.\n    \"\"\"\n    # TODO: Add option for bins like value_counts()\n    return algorithms.mode(self, dropna=dropna)",
                "def unique(self):\n    \"\"\"\n    Return unique values of Series object.\n\n    Uniques are returned in order of appearance. Hash table-based unique,\n    therefore does NOT sort.\n\n    Returns\n    -------\n    ndarray or ExtensionArray\n        The unique values returned as a NumPy array. See Notes.\n\n    See Also\n    --------\n    unique : Top-level unique method for any 1-d array-like object.\n    Index.unique : Return Index with unique values from an Index object.\n\n    Notes\n    -----\n    Returns the unique values as a NumPy array. In case of an\n    extension-array backed Series, a new\n    :class:`~api.extensions.ExtensionArray` of that type with just\n    the unique values is returned. This includes\n\n        * Categorical\n        * Period\n        * Datetime with Timezone\n        * Interval\n        * Sparse\n        * IntegerNA\n\n    See Examples section.\n\n    Examples\n    --------\n    >>> pd.Series([2, 1, 3, 3], name='A').unique()\n    array([2, 1, 3])\n\n    >>> pd.Series([pd.Timestamp('2016-01-01') for _ in range(3)]).unique()\n    array(['2016-01-01T00:00:00.000000000'], dtype='datetime64[ns]')\n\n    >>> pd.Series([pd.Timestamp('2016-01-01', tz='US/Eastern')\n    ...            for _ in range(3)]).unique()\n    <DatetimeArray>\n    ['2016-01-01 00:00:00-05:00']\n    Length: 1, dtype: datetime64[ns, US/Eastern]\n\n    An unordered Categorical will return categories in the order of\n    appearance.\n\n    >>> pd.Series(pd.Categorical(list('baabc'))).unique()\n    [b, a, c]\n    Categories (3, object): [b, a, c]\n\n    An ordered Categorical preserves the category ordering.\n\n    >>> pd.Series(pd.Categorical(list('baabc'), categories=list('abc'),\n    ...                          ordered=True)).unique()\n    [b, a, c]\n    Categories (3, object): [a < b < c]\n    \"\"\"\n    result = super().unique()\n    return result",
                "def drop_duplicates(self, keep=\"first\", inplace=False):\n    \"\"\"\n    Return Series with duplicate values removed.\n\n    Parameters\n    ----------\n    keep : {'first', 'last', ``False``}, default 'first'\n        - 'first' : Drop duplicates except for the first occurrence.\n        - 'last' : Drop duplicates except for the last occurrence.\n        - ``False`` : Drop all duplicates.\n    inplace : bool, default ``False``\n        If ``True``, performs operation inplace and returns None.\n\n    Returns\n    -------\n    Series\n        Series with duplicates dropped.\n\n    See Also\n    --------\n    Index.drop_duplicates : Equivalent method on Index.\n    DataFrame.drop_duplicates : Equivalent method on DataFrame.\n    Series.duplicated : Related method on Series, indicating duplicate\n        Series values.\n\n    Examples\n    --------\n    Generate a Series with duplicated entries.\n\n    >>> s = pd.Series(['lama', 'cow', 'lama', 'beetle', 'lama', 'hippo'],\n    ...               name='animal')\n    >>> s\n    0      lama\n    1       cow\n    2      lama\n    3    beetle\n    4      lama\n    5     hippo\n    Name: animal, dtype: object\n\n    With the 'keep' parameter, the selection behaviour of duplicated values\n    can be changed. The value 'first' keeps the first occurrence for each\n    set of duplicated entries. The default value of keep is 'first'.\n\n    >>> s.drop_duplicates()\n    0      lama\n    1       cow\n    3    beetle\n    5     hippo\n    Name: animal, dtype: object\n\n    The value 'last' for parameter 'keep' keeps the last occurrence for\n    each set of duplicated entries.\n\n    >>> s.drop_duplicates(keep='last')\n    1       cow\n    3    beetle\n    4      lama\n    5     hippo\n    Name: animal, dtype: object\n\n    The value ``False`` for parameter 'keep' discards all sets of\n    duplicated entries. Setting the value of 'inplace' to ``True`` performs\n    the operation inplace and returns ``None``.\n\n    >>> s.drop_duplicates(keep=False, inplace=True)\n    >>> s\n    1       cow\n    3    beetle\n    5     hippo\n    Name: animal, dtype: object\n    \"\"\"\n    return super().drop_duplicates(keep=keep, inplace=inplace)",
                "def duplicated(self, keep=\"first\"):\n    \"\"\"\n    Indicate duplicate Series values.\n\n    Duplicated values are indicated as ``True`` values in the resulting\n    Series. Either all duplicates, all except the first or all except the\n    last occurrence of duplicates can be indicated.\n\n    Parameters\n    ----------\n    keep : {'first', 'last', False}, default 'first'\n        - 'first' : Mark duplicates as ``True`` except for the first\n          occurrence.\n        - 'last' : Mark duplicates as ``True`` except for the last\n          occurrence.\n        - ``False`` : Mark all duplicates as ``True``.\n\n    Returns\n    -------\n    Series\n        Series indicating whether each value has occurred in the\n        preceding values.\n\n    See Also\n    --------\n    Index.duplicated : Equivalent method on pandas.Index.\n    DataFrame.duplicated : Equivalent method on pandas.DataFrame.\n    Series.drop_duplicates : Remove duplicate values from Series.\n\n    Examples\n    --------\n    By default, for each set of duplicated values, the first occurrence is\n    set on False and all others on True:\n\n    >>> animals = pd.Series(['lama', 'cow', 'lama', 'beetle', 'lama'])\n    >>> animals.duplicated()\n    0    False\n    1    False\n    2     True\n    3    False\n    4     True\n    dtype: bool\n\n    which is equivalent to\n\n    >>> animals.duplicated(keep='first')\n    0    False\n    1    False\n    2     True\n    3    False\n    4     True\n    dtype: bool\n\n    By using 'last', the last occurrence of each set of duplicated values\n    is set on False and all others on True:\n\n    >>> animals.duplicated(keep='last')\n    0     True\n    1    False\n    2     True\n    3    False\n    4    False\n    dtype: bool\n\n    By setting keep on ``False``, all duplicates are True:\n\n    >>> animals.duplicated(keep=False)\n    0     True\n    1    False\n    2     True\n    3    False\n    4     True\n    dtype: bool\n    \"\"\"\n    return super().duplicated(keep=keep)",
                "def idxmin(self, axis=0, skipna=True, *args, **kwargs):\n    \"\"\"\n    Return the row label of the minimum value.\n\n    If multiple values equal the minimum, the first row label with that\n    value is returned.\n\n    Parameters\n    ----------\n    skipna : bool, default True\n        Exclude NA/null values. If the entire Series is NA, the result\n        will be NA.\n    axis : int, default 0\n        For compatibility with DataFrame.idxmin. Redundant for application\n        on Series.\n    *args, **kwargs\n        Additional keywords have no effect but might be accepted\n        for compatibility with NumPy.\n\n    Returns\n    -------\n    Index\n        Label of the minimum value.\n\n    Raises\n    ------\n    ValueError\n        If the Series is empty.\n\n    See Also\n    --------\n    numpy.argmin : Return indices of the minimum values\n        along the given axis.\n    DataFrame.idxmin : Return index of first occurrence of minimum\n        over requested axis.\n    Series.idxmax : Return index *label* of the first occurrence\n        of maximum of values.\n\n    Notes\n    -----\n    This method is the Series version of ``ndarray.argmin``. This method\n    returns the label of the minimum, while ``ndarray.argmin`` returns\n    the position. To get the position, use ``series.values.argmin()``.\n\n    Examples\n    --------\n    >>> s = pd.Series(data=[1, None, 4, 1],\n    ...               index=['A', 'B', 'C', 'D'])\n    >>> s\n    A    1.0\n    B    NaN\n    C    4.0\n    D    1.0\n    dtype: float64\n\n    >>> s.idxmin()\n    'A'\n\n    If `skipna` is False and there is an NA value in the data,\n    the function returns ``nan``.\n\n    >>> s.idxmin(skipna=False)\n    nan\n    \"\"\"\n    skipna = nv.validate_argmin_with_skipna(skipna, args, kwargs)\n    i = nanops.nanargmin(com.values_from_object(self), skipna=skipna)\n    if i == -1:\n        return np.nan\n    return self.index[i]",
                "def idxmax(self, axis=0, skipna=True, *args, **kwargs):\n    \"\"\"\n    Return the row label of the maximum value.\n\n    If multiple values equal the maximum, the first row label with that\n    value is returned.\n\n    Parameters\n    ----------\n    skipna : bool, default True\n        Exclude NA/null values. If the entire Series is NA, the result\n        will be NA.\n    axis : int, default 0\n        For compatibility with DataFrame.idxmax. Redundant for application\n        on Series.\n    *args, **kwargs\n        Additional keywords have no effect but might be accepted\n        for compatibility with NumPy.\n\n    Returns\n    -------\n    Index\n        Label of the maximum value.\n\n    Raises\n    ------\n    ValueError\n        If the Series is empty.\n\n    See Also\n    --------\n    numpy.argmax : Return indices of the maximum values\n        along the given axis.\n    DataFrame.idxmax : Return index of first occurrence of maximum\n        over requested axis.\n    Series.idxmin : Return index *label* of the first occurrence\n        of minimum of values.\n\n    Notes\n    -----\n    This method is the Series version of ``ndarray.argmax``. This method\n    returns the label of the maximum, while ``ndarray.argmax`` returns\n    the position. To get the position, use ``series.values.argmax()``.\n\n    Examples\n    --------\n    >>> s = pd.Series(data=[1, None, 4, 3, 4],\n    ...               index=['A', 'B', 'C', 'D', 'E'])\n    >>> s\n    A    1.0\n    B    NaN\n    C    4.0\n    D    3.0\n    E    4.0\n    dtype: float64\n\n    >>> s.idxmax()\n    'C'\n\n    If `skipna` is False and there is an NA value in the data,\n    the function returns ``nan``.\n\n    >>> s.idxmax(skipna=False)\n    nan\n    \"\"\"\n    skipna = nv.validate_argmax_with_skipna(skipna, args, kwargs)\n    i = nanops.nanargmax(com.values_from_object(self), skipna=skipna)\n    if i == -1:\n        return np.nan\n    return self.index[i]",
                "def round(self, decimals=0, *args, **kwargs):\n    \"\"\"\n    Round each value in a Series to the given number of decimals.\n\n    Parameters\n    ----------\n    decimals : int\n        Number of decimal places to round to (default: 0).\n        If decimals is negative, it specifies the number of\n        positions to the left of the decimal point.\n\n    Returns\n    -------\n    Series\n        Rounded values of the Series.\n\n    See Also\n    --------\n    numpy.around : Round values of an np.array.\n    DataFrame.round : Round values of a DataFrame.\n\n    Examples\n    --------\n    >>> s = pd.Series([0.1, 1.3, 2.7])\n    >>> s.round()\n    0    0.0\n    1    1.0\n    2    3.0\n    dtype: float64\n    \"\"\"\n    nv.validate_round(args, kwargs)\n    result = com.values_from_object(self).round(decimals)\n    result = self._constructor(result, index=self.index).__finalize__(self)\n\n    return result",
                "def quantile(self, q=0.5, interpolation=\"linear\"):\n    \"\"\"\n    Return value at the given quantile.\n\n    Parameters\n    ----------\n    q : float or array-like, default 0.5 (50% quantile)\n        0 <= q <= 1, the quantile(s) to compute.\n    interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}\n        This optional parameter specifies the interpolation method to use,\n        when the desired quantile lies between two data points `i` and `j`:\n\n            * linear: `i + (j - i) * fraction`, where `fraction` is the\n              fractional part of the index surrounded by `i` and `j`.\n            * lower: `i`.\n            * higher: `j`.\n            * nearest: `i` or `j` whichever is nearest.\n            * midpoint: (`i` + `j`) / 2.\n\n    Returns\n    -------\n    float or Series\n        If ``q`` is an array, a Series will be returned where the\n        index is ``q`` and the values are the quantiles, otherwise\n        a float will be returned.\n\n    See Also\n    --------\n    core.window.Rolling.quantile\n    numpy.percentile\n\n    Examples\n    --------\n    >>> s = pd.Series([1, 2, 3, 4])\n    >>> s.quantile(.5)\n    2.5\n    >>> s.quantile([.25, .5, .75])\n    0.25    1.75\n    0.50    2.50\n    0.75    3.25\n    dtype: float64\n    \"\"\"\n\n    self._check_percentile(q)\n\n    # We dispatch to DataFrame so that core.internals only has to worry\n    #  about 2D cases.\n    df = self.to_frame()\n\n    result = df.quantile(q=q, interpolation=interpolation, numeric_only=False)\n    if result.ndim == 2:\n        result = result.iloc[:, 0]\n\n    if is_list_like(q):\n        result.name = self.name\n        return self._constructor(result, index=Float64Index(q), name=self.name)\n    else:\n        # scalar\n        return result.iloc[0]",
                "def corr(self, other, method=\"pearson\", min_periods=None):\n    \"\"\"\n    Compute correlation with `other` Series, excluding missing values.\n\n    Parameters\n    ----------\n    other : Series\n        Series with which to compute the correlation.\n    method : {'pearson', 'kendall', 'spearman'} or callable\n        * pearson : standard correlation coefficient\n        * kendall : Kendall Tau correlation coefficient\n        * spearman : Spearman rank correlation\n        * callable: callable with input two 1d ndarrays\n            and returning a float. Note that the returned matrix from corr\n            will have 1 along the diagonals and will be symmetric\n            regardless of the callable's behavior\n            .. versionadded:: 0.24.0\n\n    min_periods : int, optional\n        Minimum number of observations needed to have a valid result.\n\n    Returns\n    -------\n    float\n        Correlation with other.\n\n    Examples\n    --------\n    >>> def histogram_intersection(a, b):\n    ...     v = np.minimum(a, b).sum().round(decimals=1)\n    ...     return v\n    >>> s1 = pd.Series([.2, .0, .6, .2])\n    >>> s2 = pd.Series([.3, .6, .0, .1])\n    >>> s1.corr(s2, method=histogram_intersection)\n    0.3\n    \"\"\"\n    this, other = self.align(other, join=\"inner\", copy=False)\n    if len(this) == 0:\n        return np.nan\n\n    if method in [\"pearson\", \"spearman\", \"kendall\"] or callable(method):\n        return nanops.nancorr(\n            this.values, other.values, method=method, min_periods=min_periods\n        )\n\n    raise ValueError(\n        \"method must be either 'pearson', \"\n        \"'spearman', 'kendall', or a callable, \"\n        \"'{method}' was supplied\".format(method=method)\n    )",
                "def cov(self, other, min_periods=None):\n    \"\"\"\n    Compute covariance with Series, excluding missing values.\n\n    Parameters\n    ----------\n    other : Series\n        Series with which to compute the covariance.\n    min_periods : int, optional\n        Minimum number of observations needed to have a valid result.\n\n    Returns\n    -------\n    float\n        Covariance between Series and other normalized by N-1\n        (unbiased estimator).\n\n    Examples\n    --------\n    >>> s1 = pd.Series([0.90010907, 0.13484424, 0.62036035])\n    >>> s2 = pd.Series([0.12528585, 0.26962463, 0.51111198])\n    >>> s1.cov(s2)\n    -0.01685762652715874\n    \"\"\"\n    this, other = self.align(other, join=\"inner\", copy=False)\n    if len(this) == 0:\n        return np.nan\n    return nanops.nancov(this.values, other.values, min_periods=min_periods)",
                "def diff(self, periods=1):\n    \"\"\"\n    First discrete difference of element.\n\n    Calculates the difference of a Series element compared with another\n    element in the Series (default is element in previous row).\n\n    Parameters\n    ----------\n    periods : int, default 1\n        Periods to shift for calculating difference, accepts negative\n        values.\n\n    Returns\n    -------\n    Series\n        First differences of the Series.\n\n    See Also\n    --------\n    Series.pct_change: Percent change over given number of periods.\n    Series.shift: Shift index by desired number of periods with an\n        optional time freq.\n    DataFrame.diff: First discrete difference of object.\n\n    Examples\n    --------\n    Difference with previous row\n\n    >>> s = pd.Series([1, 1, 2, 3, 5, 8])\n    >>> s.diff()\n    0    NaN\n    1    0.0\n    2    1.0\n    3    1.0\n    4    2.0\n    5    3.0\n    dtype: float64\n\n    Difference with 3rd previous row\n\n    >>> s.diff(periods=3)\n    0    NaN\n    1    NaN\n    2    NaN\n    3    2.0\n    4    4.0\n    5    6.0\n    dtype: float64\n\n    Difference with following row\n\n    >>> s.diff(periods=-1)\n    0    0.0\n    1   -1.0\n    2   -1.0\n    3   -2.0\n    4   -3.0\n    5    NaN\n    dtype: float64\n    \"\"\"\n    result = algorithms.diff(com.values_from_object(self), periods)\n    return self._constructor(result, index=self.index).__finalize__(self)",
                "def autocorr(self, lag=1):\n    \"\"\"\n    Compute the lag-N autocorrelation.\n\n    This method computes the Pearson correlation between\n    the Series and its shifted self.\n\n    Parameters\n    ----------\n    lag : int, default 1\n        Number of lags to apply before performing autocorrelation.\n\n    Returns\n    -------\n    float\n        The Pearson correlation between self and self.shift(lag).\n\n    See Also\n    --------\n    Series.corr : Compute the correlation between two Series.\n    Series.shift : Shift index by desired number of periods.\n    DataFrame.corr : Compute pairwise correlation of columns.\n    DataFrame.corrwith : Compute pairwise correlation between rows or\n        columns of two DataFrame objects.\n\n    Notes\n    -----\n    If the Pearson correlation is not well defined return 'NaN'.\n\n    Examples\n    --------\n    >>> s = pd.Series([0.25, 0.5, 0.2, -0.05])\n    >>> s.autocorr()  # doctest: +ELLIPSIS\n    0.10355...\n    >>> s.autocorr(lag=2)  # doctest: +ELLIPSIS\n    -0.99999...\n\n    If the Pearson correlation is not well defined, then 'NaN' is returned.\n\n    >>> s = pd.Series([1, 0, 0, 0])\n    >>> s.autocorr()\n    nan\n    \"\"\"\n    return self.corr(self.shift(lag))",
                "def dot(self, other):\n    \"\"\"\n    Compute the dot product between the Series and the columns of other.\n\n    This method computes the dot product between the Series and another\n    one, or the Series and each columns of a DataFrame, or the Series and\n    each columns of an array.\n\n    It can also be called using `self @ other` in Python >= 3.5.\n\n    Parameters\n    ----------\n    other : Series, DataFrame or array-like\n        The other object to compute the dot product with its columns.\n\n    Returns\n    -------\n    scalar, Series or numpy.ndarray\n        Return the dot product of the Series and other if other is a\n        Series, the Series of the dot product of Series and each rows of\n        other if other is a DataFrame or a numpy.ndarray between the Series\n        and each columns of the numpy array.\n\n    See Also\n    --------\n    DataFrame.dot: Compute the matrix product with the DataFrame.\n    Series.mul: Multiplication of series and other, element-wise.\n\n    Notes\n    -----\n    The Series and other has to share the same index if other is a Series\n    or a DataFrame.\n\n    Examples\n    --------\n    >>> s = pd.Series([0, 1, 2, 3])\n    >>> other = pd.Series([-1, 2, -3, 4])\n    >>> s.dot(other)\n    8\n    >>> s @ other\n    8\n    >>> df = pd.DataFrame([[0, 1], [-2, 3], [4, -5], [6, 7]])\n    >>> s.dot(df)\n    0    24\n    1    14\n    dtype: int64\n    >>> arr = np.array([[0, 1], [-2, 3], [4, -5], [6, 7]])\n    >>> s.dot(arr)\n    array([24, 14])\n    \"\"\"\n    if isinstance(other, (Series, ABCDataFrame)):\n        common = self.index.union(other.index)\n        if len(common) > len(self.index) or len(common) > len(other.index):\n            raise ValueError(\"matrices are not aligned\")\n\n        left = self.reindex(index=common, copy=False)\n        right = other.reindex(index=common, copy=False)\n        lvals = left.values\n        rvals = right.values\n    else:\n        lvals = self.values\n        rvals = np.asarray(other)\n        if lvals.shape[0] != rvals.shape[0]:\n            raise Exception(\n                \"Dot product shape mismatch, %s vs %s\" % (lvals.shape, rvals.shape)\n            )\n\n    if isinstance(other, ABCDataFrame):\n        return self._constructor(\n            np.dot(lvals, rvals), index=other.columns\n        ).__finalize__(self)\n    elif isinstance(other, Series):\n        return np.dot(lvals, rvals)\n    elif isinstance(rvals, np.ndarray):\n        return np.dot(lvals, rvals)\n    else:  # pragma: no cover\n        raise TypeError(\"unsupported type: %s\" % type(other))",
                "def __matmul__(self, other):\n    \"\"\"\n    Matrix multiplication using binary `@` operator in Python>=3.5.\n    \"\"\"\n    return self.dot(other)",
                "def __rmatmul__(self, other):\n    \"\"\"\n    Matrix multiplication using binary `@` operator in Python>=3.5.\n    \"\"\"\n    return self.dot(np.transpose(other))",
                "@Substitution(klass=\"Series\")\n@Appender(base._shared_docs[\"searchsorted\"])\ndef searchsorted(self, value, side=\"left\", sorter=None):\n    return algorithms.searchsorted(self._values, value, side=side, sorter=sorter)",
                "def append(self, to_append, ignore_index=False, verify_integrity=False):\n    \"\"\"\n    Concatenate two or more Series.\n\n    Parameters\n    ----------\n    to_append : Series or list/tuple of Series\n        Series to append with self.\n    ignore_index : bool, default False\n        If True, do not use the index labels.\n    verify_integrity : bool, default False\n        If True, raise Exception on creating index with duplicates.\n\n    Returns\n    -------\n    Series\n        Concatenated Series.\n\n    See Also\n    --------\n    concat : General function to concatenate DataFrame or Series objects.\n\n    Notes\n    -----\n    Iteratively appending to a Series can be more computationally intensive\n    than a single concatenate. A better solution is to append values to a\n    list and then concatenate the list with the original Series all at\n    once.\n\n    Examples\n    --------\n    >>> s1 = pd.Series([1, 2, 3])\n    >>> s2 = pd.Series([4, 5, 6])\n    >>> s3 = pd.Series([4, 5, 6], index=[3, 4, 5])\n    >>> s1.append(s2)\n    0    1\n    1    2\n    2    3\n    0    4\n    1    5\n    2    6\n    dtype: int64\n\n    >>> s1.append(s3)\n    0    1\n    1    2\n    2    3\n    3    4\n    4    5\n    5    6\n    dtype: int64\n\n    With `ignore_index` set to True:\n\n    >>> s1.append(s2, ignore_index=True)\n    0    1\n    1    2\n    2    3\n    3    4\n    4    5\n    5    6\n    dtype: int64\n\n    With `verify_integrity` set to True:\n\n    >>> s1.append(s2, verify_integrity=True)\n    Traceback (most recent call last):\n    ...\n    ValueError: Indexes have overlapping values: [0, 1, 2]\n    \"\"\"\n    from pandas.core.reshape.concat import concat\n\n    if isinstance(to_append, (list, tuple)):\n        to_concat = [self] + to_append\n    else:\n        to_concat = [self, to_append]\n    return concat(\n        to_concat, ignore_index=ignore_index, verify_integrity=verify_integrity\n    )",
                "def _binop(self, other, func, level=None, fill_value=None):\n    \"\"\"\n    Perform generic binary operation with optional fill value.\n\n    Parameters\n    ----------\n    other : Series\n    func : binary operator\n    fill_value : float or object\n        Value to substitute for NA/null values. If both Series are NA in a\n        location, the result will be NA regardless of the passed fill value\n    level : int or level name, default None\n        Broadcast across a level, matching Index values on the\n        passed MultiIndex level\n\n    Returns\n    -------\n    Series\n    \"\"\"\n\n    if not isinstance(other, Series):\n        raise AssertionError(\"Other operand must be Series\")\n\n    new_index = self.index\n    this = self\n\n    if not self.index.equals(other.index):\n        this, other = self.align(other, level=level, join=\"outer\", copy=False)\n        new_index = this.index\n\n    this_vals, other_vals = ops.fill_binop(this.values, other.values, fill_value)\n\n    with np.errstate(all=\"ignore\"):\n        result = func(this_vals, other_vals)\n\n    name = ops.get_op_result_name(self, other)\n    if func.__name__ in [\"divmod\", \"rdivmod\"]:\n        ret = ops._construct_divmod_result(self, result, new_index, name)\n    else:\n        ret = ops._construct_result(self, result, new_index, name)\n    return ret",
                "def combine(self, other, func, fill_value=None):\n    \"\"\"\n    Combine the Series with a Series or scalar according to `func`.\n\n    Combine the Series and `other` using `func` to perform elementwise\n    selection for combined Series.\n    `fill_value` is assumed when value is missing at some index\n    from one of the two objects being combined.\n\n    Parameters\n    ----------\n    other : Series or scalar\n        The value(s) to be combined with the `Series`.\n    func : function\n        Function that takes two scalars as inputs and returns an element.\n    fill_value : scalar, optional\n        The value to assume when an index is missing from\n        one Series or the other. The default specifies to use the\n        appropriate NaN value for the underlying dtype of the Series.\n\n    Returns\n    -------\n    Series\n        The result of combining the Series with the other object.\n\n    See Also\n    --------\n    Series.combine_first : Combine Series values, choosing the calling\n        Series' values first.\n\n    Examples\n    --------\n    Consider 2 Datasets ``s1`` and ``s2`` containing\n    highest clocked speeds of different birds.\n\n    >>> s1 = pd.Series({'falcon': 330.0, 'eagle': 160.0})\n    >>> s1\n    falcon    330.0\n    eagle     160.0\n    dtype: float64\n    >>> s2 = pd.Series({'falcon': 345.0, 'eagle': 200.0, 'duck': 30.0})\n    >>> s2\n    falcon    345.0\n    eagle     200.0\n    duck       30.0\n    dtype: float64\n\n    Now, to combine the two datasets and view the highest speeds\n    of the birds across the two datasets\n\n    >>> s1.combine(s2, max)\n    duck        NaN\n    eagle     200.0\n    falcon    345.0\n    dtype: float64\n\n    In the previous example, the resulting value for duck is missing,\n    because the maximum of a NaN and a float is a NaN.\n    So, in the example, we set ``fill_value=0``,\n    so the maximum value returned will be the value from some dataset.\n\n    >>> s1.combine(s2, max, fill_value=0)\n    duck       30.0\n    eagle     200.0\n    falcon    345.0\n    dtype: float64\n    \"\"\"\n    if fill_value is None:\n        fill_value = na_value_for_dtype(self.dtype, compat=False)\n\n    if isinstance(other, Series):\n        # If other is a Series, result is based on union of Series,\n        # so do this element by element\n        new_index = self.index.union(other.index)\n        new_name = ops.get_op_result_name(self, other)\n        new_values = []\n        for idx in new_index:\n            lv = self.get(idx, fill_value)\n            rv = other.get(idx, fill_value)\n            with np.errstate(all=\"ignore\"):\n                new_values.append(func(lv, rv))\n    else:\n        # Assume that other is a scalar, so apply the function for\n        # each element in the Series\n        new_index = self.index\n        with np.errstate(all=\"ignore\"):\n            new_values = [func(lv, other) for lv in self._values]\n        new_name = self.name\n\n    if is_categorical_dtype(self.values):\n        pass\n    elif is_extension_array_dtype(self.values):\n        # The function can return something of any type, so check\n        # if the type is compatible with the calling EA.\n        try:\n            new_values = self._values._from_sequence(new_values)\n        except Exception:\n            # https://github.com/pandas-dev/pandas/issues/22850\n            # pandas has no control over what 3rd-party ExtensionArrays\n            # do in _values_from_sequence. We still want ops to work\n            # though, so we catch any regular Exception.\n            pass\n    return self._constructor(new_values, index=new_index, name=new_name)",
                "def combine_first(self, other):\n    \"\"\"\n    Combine Series values, choosing the calling Series's values first.\n\n    Parameters\n    ----------\n    other : Series\n        The value(s) to be combined with the `Series`.\n\n    Returns\n    -------\n    Series\n        The result of combining the Series with the other object.\n\n    See Also\n    --------\n    Series.combine : Perform elementwise operation on two Series\n        using a given function.\n\n    Notes\n    -----\n    Result index will be the union of the two indexes.\n\n    Examples\n    --------\n    >>> s1 = pd.Series([1, np.nan])\n    >>> s2 = pd.Series([3, 4])\n    >>> s1.combine_first(s2)\n    0    1.0\n    1    4.0\n    dtype: float64\n    \"\"\"\n    new_index = self.index.union(other.index)\n    this = self.reindex(new_index, copy=False)\n    other = other.reindex(new_index, copy=False)\n    if is_datetimelike(this) and not is_datetimelike(other):\n        other = to_datetime(other)\n\n    return this.where(notna(this), other)",
                "def update(self, other):\n    \"\"\"\n    Modify Series in place using non-NA values from passed\n    Series. Aligns on index.\n\n    Parameters\n    ----------\n    other : Series\n\n    Examples\n    --------\n    >>> s = pd.Series([1, 2, 3])\n    >>> s.update(pd.Series([4, 5, 6]))\n    >>> s\n    0    4\n    1    5\n    2    6\n    dtype: int64\n\n    >>> s = pd.Series(['a', 'b', 'c'])\n    >>> s.update(pd.Series(['d', 'e'], index=[0, 2]))\n    >>> s\n    0    d\n    1    b\n    2    e\n    dtype: object\n\n    >>> s = pd.Series([1, 2, 3])\n    >>> s.update(pd.Series([4, 5, 6, 7, 8]))\n    >>> s\n    0    4\n    1    5\n    2    6\n    dtype: int64\n\n    If ``other`` contains NaNs the corresponding values are not updated\n    in the original Series.\n\n    >>> s = pd.Series([1, 2, 3])\n    >>> s.update(pd.Series([4, np.nan, 6]))\n    >>> s\n    0    4\n    1    2\n    2    6\n    dtype: int64\n    \"\"\"\n    other = other.reindex_like(self)\n    mask = notna(other)\n\n    self._data = self._data.putmask(mask=mask, new=other, inplace=True)\n    self._maybe_update_cacher()",
                "def sort_values(\n    self,\n    axis=0,\n    ascending=True,\n    inplace=False,\n    kind=\"quicksort\",\n    na_position=\"last\",\n):\n    \"\"\"\n    Sort by the values.\n\n    Sort a Series in ascending or descending order by some\n    criterion.\n\n    Parameters\n    ----------\n    axis : {0 or 'index'}, default 0\n        Axis to direct sorting. The value 'index' is accepted for\n        compatibility with DataFrame.sort_values.\n    ascending : bool, default True\n        If True, sort values in ascending order, otherwise descending.\n    inplace : bool, default False\n        If True, perform operation in-place.\n    kind : {'quicksort', 'mergesort' or 'heapsort'}, default 'quicksort'\n        Choice of sorting algorithm. See also :func:`numpy.sort` for more\n        information. 'mergesort' is the only stable  algorithm.\n    na_position : {'first' or 'last'}, default 'last'\n        Argument 'first' puts NaNs at the beginning, 'last' puts NaNs at\n        the end.\n\n    Returns\n    -------\n    Series\n        Series ordered by values.\n\n    See Also\n    --------\n    Series.sort_index : Sort by the Series indices.\n    DataFrame.sort_values : Sort DataFrame by the values along either axis.\n    DataFrame.sort_index : Sort DataFrame by indices.\n\n    Examples\n    --------\n    >>> s = pd.Series([np.nan, 1, 3, 10, 5])\n    >>> s\n    0     NaN\n    1     1.0\n    2     3.0\n    3     10.0\n    4     5.0\n    dtype: float64\n\n    Sort values ascending order (default behaviour)\n\n    >>> s.sort_values(ascending=True)\n    1     1.0\n    2     3.0\n    4     5.0\n    3    10.0\n    0     NaN\n    dtype: float64\n\n    Sort values descending order\n\n    >>> s.sort_values(ascending=False)\n    3    10.0\n    4     5.0\n    2     3.0\n    1     1.0\n    0     NaN\n    dtype: float64\n\n    Sort values inplace\n\n    >>> s.sort_values(ascending=False, inplace=True)\n    >>> s\n    3    10.0\n    4     5.0\n    2     3.0\n    1     1.0\n    0     NaN\n    dtype: float64\n\n    Sort values putting NAs first\n\n    >>> s.sort_values(na_position='first')\n    0     NaN\n    1     1.0\n    2     3.0\n    4     5.0\n    3    10.0\n    dtype: float64\n\n    Sort a series of strings\n\n    >>> s = pd.Series(['z', 'b', 'd', 'a', 'c'])\n    >>> s\n    0    z\n    1    b\n    2    d\n    3    a\n    4    c\n    dtype: object\n\n    >>> s.sort_values()\n    3    a\n    1    b\n    4    c\n    2    d\n    0    z\n    dtype: object\n    \"\"\"\n    inplace = validate_bool_kwarg(inplace, \"inplace\")\n    # Validate the axis parameter\n    self._get_axis_number(axis)\n\n    # GH 5856/5853\n    if inplace and self._is_cached:\n        raise ValueError(\n            \"This Series is a view of some other array, to \"\n            \"sort in-place you must create a copy\"\n        )\n\n    def _try_kind_sort(arr):\n        # easier to ask forgiveness than permission\n        try:\n            # if kind==mergesort, it can fail for object dtype\n            return arr.argsort(kind=kind)\n        except TypeError:\n            # stable sort not available for object dtype\n            # uses the argsort default quicksort\n            return arr.argsort(kind=\"quicksort\")\n\n    arr = self._values\n    sortedIdx = np.empty(len(self), dtype=np.int32)\n\n    bad = isna(arr)\n\n    good = ~bad\n    idx = ibase.default_index(len(self))\n\n    argsorted = _try_kind_sort(arr[good])\n\n    if is_list_like(ascending):\n        if len(ascending) != 1:\n            raise ValueError(\n                \"Length of ascending (%d) must be 1 \"\n                \"for Series\" % (len(ascending))\n            )\n        ascending = ascending[0]\n\n    if not is_bool(ascending):\n        raise ValueError(\"ascending must be boolean\")\n\n    if not ascending:\n        argsorted = argsorted[::-1]\n\n    if na_position == \"last\":\n        n = good.sum()\n        sortedIdx[:n] = idx[good][argsorted]\n        sortedIdx[n:] = idx[bad]\n    elif na_position == \"first\":\n        n = bad.sum()\n        sortedIdx[n:] = idx[good][argsorted]\n        sortedIdx[:n] = idx[bad]\n    else:\n        raise ValueError(\"invalid na_position: {!r}\".format(na_position))\n\n    result = self._constructor(arr[sortedIdx], index=self.index[sortedIdx])\n\n    if inplace:\n        self._update_inplace(result)\n    else:\n        return result.__finalize__(self)",
                "def sort_index(\n    self,\n    axis=0,\n    level=None,\n    ascending=True,\n    inplace=False,\n    kind=\"quicksort\",\n    na_position=\"last\",\n    sort_remaining=True,\n):\n    \"\"\"\n    Sort Series by index labels.\n\n    Returns a new Series sorted by label if `inplace` argument is\n    ``False``, otherwise updates the original series and returns None.\n\n    Parameters\n    ----------\n    axis : int, default 0\n        Axis to direct sorting. This can only be 0 for Series.\n    level : int, optional\n        If not None, sort on values in specified index level(s).\n    ascending : bool, default true\n        Sort ascending vs. descending.\n    inplace : bool, default False\n        If True, perform operation in-place.\n    kind : {'quicksort', 'mergesort', 'heapsort'}, default 'quicksort'\n        Choice of sorting algorithm. See also :func:`numpy.sort` for more\n        information.  'mergesort' is the only stable algorithm. For\n        DataFrames, this option is only applied when sorting on a single\n        column or label.\n    na_position : {'first', 'last'}, default 'last'\n        If 'first' puts NaNs at the beginning, 'last' puts NaNs at the end.\n        Not implemented for MultiIndex.\n    sort_remaining : bool, default True\n        If True and sorting by level and index is multilevel, sort by other\n        levels too (in order) after sorting by specified level.\n\n    Returns\n    -------\n    Series\n        The original Series sorted by the labels.\n\n    See Also\n    --------\n    DataFrame.sort_index: Sort DataFrame by the index.\n    DataFrame.sort_values: Sort DataFrame by the value.\n    Series.sort_values : Sort Series by the value.\n\n    Examples\n    --------\n    >>> s = pd.Series(['a', 'b', 'c', 'd'], index=[3, 2, 1, 4])\n    >>> s.sort_index()\n    1    c\n    2    b\n    3    a\n    4    d\n    dtype: object\n\n    Sort Descending\n\n    >>> s.sort_index(ascending=False)\n    4    d\n    3    a\n    2    b\n    1    c\n    dtype: object\n\n    Sort Inplace\n\n    >>> s.sort_index(inplace=True)\n    >>> s\n    1    c\n    2    b\n    3    a\n    4    d\n    dtype: object\n\n    By default NaNs are put at the end, but use `na_position` to place\n    them at the beginning\n\n    >>> s = pd.Series(['a', 'b', 'c', 'd'], index=[3, 2, 1, np.nan])\n    >>> s.sort_index(na_position='first')\n    NaN     d\n     1.0    c\n     2.0    b\n     3.0    a\n    dtype: object\n\n    Specify index level to sort\n\n    >>> arrays = [np.array(['qux', 'qux', 'foo', 'foo',\n    ...                     'baz', 'baz', 'bar', 'bar']),\n    ...           np.array(['two', 'one', 'two', 'one',\n    ...                     'two', 'one', 'two', 'one'])]\n    >>> s = pd.Series([1, 2, 3, 4, 5, 6, 7, 8], index=arrays)\n    >>> s.sort_index(level=1)\n    bar  one    8\n    baz  one    6\n    foo  one    4\n    qux  one    2\n    bar  two    7\n    baz  two    5\n    foo  two    3\n    qux  two    1\n    dtype: int64\n\n    Does not sort by remaining levels when sorting by levels\n\n    >>> s.sort_index(level=1, sort_remaining=False)\n    qux  one    2\n    foo  one    4\n    baz  one    6\n    bar  one    8\n    qux  two    1\n    foo  two    3\n    baz  two    5\n    bar  two    7\n    dtype: int64\n    \"\"\"\n    # TODO: this can be combined with DataFrame.sort_index impl as\n    # almost identical\n    inplace = validate_bool_kwarg(inplace, \"inplace\")\n    # Validate the axis parameter\n    self._get_axis_number(axis)\n    index = self.index\n\n    if level is not None:\n        new_index, indexer = index.sortlevel(\n            level, ascending=ascending, sort_remaining=sort_remaining\n        )\n    elif isinstance(index, MultiIndex):\n        from pandas.core.sorting import lexsort_indexer\n\n        labels = index._sort_levels_monotonic()\n        indexer = lexsort_indexer(\n            labels._get_codes_for_sorting(),\n            orders=ascending,\n            na_position=na_position,\n        )\n    else:\n        from pandas.core.sorting import nargsort\n\n        # Check monotonic-ness before sort an index\n        # GH11080\n        if (ascending and index.is_monotonic_increasing) or (\n            not ascending and index.is_monotonic_decreasing\n        ):\n            if inplace:\n                return\n            else:\n                return self.copy()\n\n        indexer = nargsort(\n            index, kind=kind, ascending=ascending, na_position=na_position\n        )\n\n    indexer = ensure_platform_int(indexer)\n    new_index = index.take(indexer)\n    new_index = new_index._sort_levels_monotonic()\n\n    new_values = self._values.take(indexer)\n    result = self._constructor(new_values, index=new_index)\n\n    if inplace:\n        self._update_inplace(result)\n    else:\n        return result.__finalize__(self)",
                "def argsort(self, axis=0, kind=\"quicksort\", order=None):\n    \"\"\"\n    Override ndarray.argsort. Argsorts the value, omitting NA/null values,\n    and places the result in the same locations as the non-NA values.\n\n    Parameters\n    ----------\n    axis : int\n        Has no effect but is accepted for compatibility with numpy.\n    kind : {'mergesort', 'quicksort', 'heapsort'}, default 'quicksort'\n        Choice of sorting algorithm. See np.sort for more\n        information. 'mergesort' is the only stable algorithm\n    order : None\n        Has no effect but is accepted for compatibility with numpy.\n\n    Returns\n    -------\n    Series\n        Positions of values within the sort order with -1 indicating\n        nan values.\n\n    See Also\n    --------\n    numpy.ndarray.argsort\n    \"\"\"\n    values = self._values\n    mask = isna(values)\n\n    if mask.any():\n        result = Series(-1, index=self.index, name=self.name, dtype=\"int64\")\n        notmask = ~mask\n        result[notmask] = np.argsort(values[notmask], kind=kind)\n        return self._constructor(result, index=self.index).__finalize__(self)\n    else:\n        return self._constructor(\n            np.argsort(values, kind=kind), index=self.index, dtype=\"int64\"\n        ).__finalize__(self)",
                "def nlargest(self, n=5, keep=\"first\"):\n    \"\"\"\n    Return the largest `n` elements.\n\n    Parameters\n    ----------\n    n : int, default 5\n        Return this many descending sorted values.\n    keep : {'first', 'last', 'all'}, default 'first'\n        When there are duplicate values that cannot all fit in a\n        Series of `n` elements:\n\n        - ``first`` : return the first `n` occurrences in order\n            of appearance.\n        - ``last`` : return the last `n` occurrences in reverse\n            order of appearance.\n        - ``all`` : keep all occurrences. This can result in a Series of\n            size larger than `n`.\n\n    Returns\n    -------\n    Series\n        The `n` largest values in the Series, sorted in decreasing order.\n\n    See Also\n    --------\n    Series.nsmallest: Get the `n` smallest elements.\n    Series.sort_values: Sort Series by values.\n    Series.head: Return the first `n` rows.\n\n    Notes\n    -----\n    Faster than ``.sort_values(ascending=False).head(n)`` for small `n`\n    relative to the size of the ``Series`` object.\n\n    Examples\n    --------\n    >>> countries_population = {\"Italy\": 59000000, \"France\": 65000000,\n    ...                         \"Malta\": 434000, \"Maldives\": 434000,\n    ...                         \"Brunei\": 434000, \"Iceland\": 337000,\n    ...                         \"Nauru\": 11300, \"Tuvalu\": 11300,\n    ...                         \"Anguilla\": 11300, \"Monserat\": 5200}\n    >>> s = pd.Series(countries_population)\n    >>> s\n    Italy       59000000\n    France      65000000\n    Malta         434000\n    Maldives      434000\n    Brunei        434000\n    Iceland       337000\n    Nauru          11300\n    Tuvalu         11300\n    Anguilla       11300\n    Monserat        5200\n    dtype: int64\n\n    The `n` largest elements where ``n=5`` by default.\n\n    >>> s.nlargest()\n    France      65000000\n    Italy       59000000\n    Malta         434000\n    Maldives      434000\n    Brunei        434000\n    dtype: int64\n\n    The `n` largest elements where ``n=3``. Default `keep` value is 'first'\n    so Malta will be kept.\n\n    >>> s.nlargest(3)\n    France    65000000\n    Italy     59000000\n    Malta       434000\n    dtype: int64\n\n    The `n` largest elements where ``n=3`` and keeping the last duplicates.\n    Brunei will be kept since it is the last with value 434000 based on\n    the index order.\n\n    >>> s.nlargest(3, keep='last')\n    France      65000000\n    Italy       59000000\n    Brunei        434000\n    dtype: int64\n\n    The `n` largest elements where ``n=3`` with all duplicates kept. Note\n    that the returned Series has five elements due to the three duplicates.\n\n    >>> s.nlargest(3, keep='all')\n    France      65000000\n    Italy       59000000\n    Malta         434000\n    Maldives      434000\n    Brunei        434000\n    dtype: int64\n    \"\"\"\n    return algorithms.SelectNSeries(self, n=n, keep=keep).nlargest()",
                "def nsmallest(self, n=5, keep=\"first\"):\n    \"\"\"\n    Return the smallest `n` elements.\n\n    Parameters\n    ----------\n    n : int, default 5\n        Return this many ascending sorted values.\n    keep : {'first', 'last', 'all'}, default 'first'\n        When there are duplicate values that cannot all fit in a\n        Series of `n` elements:\n\n        - ``first`` : return the first `n` occurrences in order\n            of appearance.\n        - ``last`` : return the last `n` occurrences in reverse\n            order of appearance.\n        - ``all`` : keep all occurrences. This can result in a Series of\n            size larger than `n`.\n\n    Returns\n    -------\n    Series\n        The `n` smallest values in the Series, sorted in increasing order.\n\n    See Also\n    --------\n    Series.nlargest: Get the `n` largest elements.\n    Series.sort_values: Sort Series by values.\n    Series.head: Return the first `n` rows.\n\n    Notes\n    -----\n    Faster than ``.sort_values().head(n)`` for small `n` relative to\n    the size of the ``Series`` object.\n\n    Examples\n    --------\n    >>> countries_population = {\"Italy\": 59000000, \"France\": 65000000,\n    ...                         \"Brunei\": 434000, \"Malta\": 434000,\n    ...                         \"Maldives\": 434000, \"Iceland\": 337000,\n    ...                         \"Nauru\": 11300, \"Tuvalu\": 11300,\n    ...                         \"Anguilla\": 11300, \"Monserat\": 5200}\n    >>> s = pd.Series(countries_population)\n    >>> s\n    Italy       59000000\n    France      65000000\n    Brunei        434000\n    Malta         434000\n    Maldives      434000\n    Iceland       337000\n    Nauru          11300\n    Tuvalu         11300\n    Anguilla       11300\n    Monserat        5200\n    dtype: int64\n\n    The `n` smallest elements where ``n=5`` by default.\n\n    >>> s.nsmallest()\n    Monserat      5200\n    Nauru        11300\n    Tuvalu       11300\n    Anguilla     11300\n    Iceland     337000\n    dtype: int64\n\n    The `n` smallest elements where ``n=3``. Default `keep` value is\n    'first' so Nauru and Tuvalu will be kept.\n\n    >>> s.nsmallest(3)\n    Monserat     5200\n    Nauru       11300\n    Tuvalu      11300\n    dtype: int64\n\n    The `n` smallest elements where ``n=3`` and keeping the last\n    duplicates. Anguilla and Tuvalu will be kept since they are the last\n    with value 11300 based on the index order.\n\n    >>> s.nsmallest(3, keep='last')\n    Monserat     5200\n    Anguilla    11300\n    Tuvalu      11300\n    dtype: int64\n\n    The `n` smallest elements where ``n=3`` with all duplicates kept. Note\n    that the returned Series has four elements due to the three duplicates.\n\n    >>> s.nsmallest(3, keep='all')\n    Monserat     5200\n    Nauru       11300\n    Tuvalu      11300\n    Anguilla    11300\n    dtype: int64\n    \"\"\"\n    return algorithms.SelectNSeries(self, n=n, keep=keep).nsmallest()",
                "def swaplevel(self, i=-2, j=-1, copy=True):\n    \"\"\"\n    Swap levels i and j in a :class:`MultiIndex`.\n\n    Default is to swap the two innermost levels of the index.\n\n    Parameters\n    ----------\n    i, j : int, str (can be mixed)\n        Level of index to be swapped. Can pass level name as string.\n    copy : bool, default True\n        Whether to copy underlying data.\n\n    Returns\n    -------\n    Series\n        Series with levels swapped in MultiIndex.\n    \"\"\"\n    new_index = self.index.swaplevel(i, j)\n    return self._constructor(self._values, index=new_index, copy=copy).__finalize__(\n        self\n    )",
                "def reorder_levels(self, order):\n    \"\"\"\n    Rearrange index levels using input order.\n\n    May not drop or duplicate levels.\n\n    Parameters\n    ----------\n    order : list of int representing new level order\n           (reference level by number or key)\n\n    Returns\n    -------\n    type of caller (new object)\n    \"\"\"\n    if not isinstance(self.index, MultiIndex):  # pragma: no cover\n        raise Exception(\"Can only reorder levels on a hierarchical axis.\")\n\n    result = self.copy()\n    result.index = result.index.reorder_levels(order)\n    return result",
                "def explode(self) -> \"Series\":\n    \"\"\"\n    Transform each element of a list-like to a row, replicating the\n    index values.\n\n    .. versionadded:: 0.25.0\n\n    Returns\n    -------\n    Series\n        Exploded lists to rows; index will be duplicated for these rows.\n\n    See Also\n    --------\n    Series.str.split : Split string values on specified separator.\n    Series.unstack : Unstack, a.k.a. pivot, Series with MultiIndex\n        to produce DataFrame.\n    DataFrame.melt : Unpivot a DataFrame from wide format to long format.\n    DataFrame.explode : Explode a DataFrame from list-like\n        columns to long format.\n\n    Notes\n    -----\n    This routine will explode list-likes including lists, tuples,\n    Series, and np.ndarray. The result dtype of the subset rows will\n    be object. Scalars will be returned unchanged. Empty list-likes will\n    result in a np.nan for that row.\n\n    Examples\n    --------\n    >>> s = pd.Series([[1, 2, 3], 'foo', [], [3, 4]])\n    >>> s\n    0    [1, 2, 3]\n    1          foo\n    2           []\n    3       [3, 4]\n    dtype: object\n\n    >>> s.explode()\n    0      1\n    0      2\n    0      3\n    1    foo\n    2    NaN\n    3      3\n    3      4\n    dtype: object\n    \"\"\"\n    if not len(self) or not is_object_dtype(self):\n        return self.copy()\n\n    values, counts = reshape.explode(np.asarray(self.array))\n\n    result = Series(values, index=self.index.repeat(counts), name=self.name)\n    return result",
                "def unstack(self, level=-1, fill_value=None):\n    \"\"\"\n    Unstack, a.k.a. pivot, Series with MultiIndex to produce DataFrame.\n    The level involved will automatically get sorted.\n\n    Parameters\n    ----------\n    level : int, str, or list of these, default last level\n        Level(s) to unstack, can pass level name.\n    fill_value : scalar value, default None\n        Value to use when replacing NaN values.\n\n    Returns\n    -------\n    DataFrame\n        Unstacked Series.\n\n    Examples\n    --------\n    >>> s = pd.Series([1, 2, 3, 4],\n    ...               index=pd.MultiIndex.from_product([['one', 'two'],\n    ...                                                 ['a', 'b']]))\n    >>> s\n    one  a    1\n         b    2\n    two  a    3\n         b    4\n    dtype: int64\n\n    >>> s.unstack(level=-1)\n         a  b\n    one  1  2\n    two  3  4\n\n    >>> s.unstack(level=0)\n       one  two\n    a    1    3\n    b    2    4\n    \"\"\"\n    from pandas.core.reshape.reshape import unstack\n\n    return unstack(self, level, fill_value)",
                "def map(self, arg, na_action=None):\n    \"\"\"\n    Map values of Series according to input correspondence.\n\n    Used for substituting each value in a Series with another value,\n    that may be derived from a function, a ``dict`` or\n    a :class:`Series`.\n\n    Parameters\n    ----------\n    arg : function, dict, or Series\n        Mapping correspondence.\n    na_action : {None, 'ignore'}, default None\n        If 'ignore', propagate NaN values, without passing them to the\n        mapping correspondence.\n\n    Returns\n    -------\n    Series\n        Same index as caller.\n\n    See Also\n    --------\n    Series.apply : For applying more complex functions on a Series.\n    DataFrame.apply : Apply a function row-/column-wise.\n    DataFrame.applymap : Apply a function elementwise on a whole DataFrame.\n\n    Notes\n    -----\n    When ``arg`` is a dictionary, values in Series that are not in the\n    dictionary (as keys) are converted to ``NaN``. However, if the\n    dictionary is a ``dict`` subclass that defines ``__missing__`` (i.e.\n    provides a method for default values), then this default is used\n    rather than ``NaN``.\n\n    Examples\n    --------\n    >>> s = pd.Series(['cat', 'dog', np.nan, 'rabbit'])\n    >>> s\n    0      cat\n    1      dog\n    2      NaN\n    3   rabbit\n    dtype: object\n\n    ``map`` accepts a ``dict`` or a ``Series``. Values that are not found\n    in the ``dict`` are converted to ``NaN``, unless the dict has a default\n    value (e.g. ``defaultdict``):\n\n    >>> s.map({'cat': 'kitten', 'dog': 'puppy'})\n    0   kitten\n    1    puppy\n    2      NaN\n    3      NaN\n    dtype: object\n\n    It also accepts a function:\n\n    >>> s.map('I am a {}'.format)\n    0       I am a cat\n    1       I am a dog\n    2       I am a nan\n    3    I am a rabbit\n    dtype: object\n\n    To avoid applying the function to missing values (and keep them as\n    ``NaN``) ``na_action='ignore'`` can be used:\n\n    >>> s.map('I am a {}'.format, na_action='ignore')\n    0     I am a cat\n    1     I am a dog\n    2            NaN\n    3  I am a rabbit\n    dtype: object\n    \"\"\"\n    new_values = super()._map_values(arg, na_action=na_action)\n    return self._constructor(new_values, index=self.index).__finalize__(self)",
                "def _gotitem(self, key, ndim, subset=None):\n    \"\"\"\n    Sub-classes to define. Return a sliced object.\n\n    Parameters\n    ----------\n    key : string / list of selections\n    ndim : 1,2\n        requested ndim of result\n    subset : object, default None\n        subset to act on\n    \"\"\"\n    return self",
                "@Substitution(\n    see_also=_agg_see_also_doc,\n    examples=_agg_examples_doc,\n    versionadded=\"\\n.. versionadded:: 0.20.0\\n\",\n    **_shared_doc_kwargs\n)\n@Appender(generic._shared_docs[\"aggregate\"])\ndef aggregate(self, func, axis=0, *args, **kwargs):\n    # Validate the axis parameter\n    self._get_axis_number(axis)\n    result, how = self._aggregate(func, *args, **kwargs)\n    if result is None:\n\n        # we can be called from an inner function which\n        # passes this meta-data\n        kwargs.pop(\"_axis\", None)\n        kwargs.pop(\"_level\", None)\n\n        # try a regular apply, this evaluates lambdas\n        # row-by-row; however if the lambda is expected a Series\n        # expression, e.g.: lambda x: x-x.quantile(0.25)\n        # this will fail, so we can try a vectorized evaluation\n\n        # we cannot FIRST try the vectorized evaluation, because\n        # then .agg and .apply would have different semantics if the\n        # operation is actually defined on the Series, e.g. str\n        try:\n            result = self.apply(func, *args, **kwargs)\n        except (ValueError, AttributeError, TypeError):\n            result = func(self, *args, **kwargs)\n\n    return result",
                "@Appender(generic._shared_docs[\"transform\"] % _shared_doc_kwargs)\ndef transform(self, func, axis=0, *args, **kwargs):\n    # Validate the axis parameter\n    self._get_axis_number(axis)\n    return super().transform(func, *args, **kwargs)",
                "def apply(self, func, convert_dtype=True, args=(), **kwds):\n    \"\"\"\n    Invoke function on values of Series.\n\n    Can be ufunc (a NumPy function that applies to the entire Series)\n    or a Python function that only works on single values.\n\n    Parameters\n    ----------\n    func : function\n        Python function or NumPy ufunc to apply.\n    convert_dtype : bool, default True\n        Try to find better dtype for elementwise function results. If\n        False, leave as dtype=object.\n    args : tuple\n        Positional arguments passed to func after the series value.\n    **kwds\n        Additional keyword arguments passed to func.\n\n    Returns\n    -------\n    Series or DataFrame\n        If func returns a Series object the result will be a DataFrame.\n\n    See Also\n    --------\n    Series.map: For element-wise operations.\n    Series.agg: Only perform aggregating type operations.\n    Series.transform: Only perform transforming type operations.\n\n    Examples\n    --------\n    Create a series with typical summer temperatures for each city.\n\n    >>> s = pd.Series([20, 21, 12],\n    ...               index=['London', 'New York', 'Helsinki'])\n    >>> s\n    London      20\n    New York    21\n    Helsinki    12\n    dtype: int64\n\n    Square the values by defining a function and passing it as an\n    argument to ``apply()``.\n\n    >>> def square(x):\n    ...     return x ** 2\n    >>> s.apply(square)\n    London      400\n    New York    441\n    Helsinki    144\n    dtype: int64\n\n    Square the values by passing an anonymous function as an\n    argument to ``apply()``.\n\n    >>> s.apply(lambda x: x ** 2)\n    London      400\n    New York    441\n    Helsinki    144\n    dtype: int64\n\n    Define a custom function that needs additional positional\n    arguments and pass these additional arguments using the\n    ``args`` keyword.\n\n    >>> def subtract_custom_value(x, custom_value):\n    ...     return x - custom_value\n\n    >>> s.apply(subtract_custom_value, args=(5,))\n    London      15\n    New York    16\n    Helsinki     7\n    dtype: int64\n\n    Define a custom function that takes keyword arguments\n    and pass these arguments to ``apply``.\n\n    >>> def add_custom_values(x, **kwargs):\n    ...     for month in kwargs:\n    ...         x += kwargs[month]\n    ...     return x\n\n    >>> s.apply(add_custom_values, june=30, july=20, august=25)\n    London      95\n    New York    96\n    Helsinki    87\n    dtype: int64\n\n    Use a function from the Numpy library.\n\n    >>> s.apply(np.log)\n    London      2.995732\n    New York    3.044522\n    Helsinki    2.484907\n    dtype: float64\n    \"\"\"\n    if len(self) == 0:\n        return self._constructor(dtype=self.dtype, index=self.index).__finalize__(\n            self\n        )\n\n    # dispatch to agg\n    if isinstance(func, (list, dict)):\n        return self.aggregate(func, *args, **kwds)\n\n    # if we are a string, try to dispatch\n    if isinstance(func, str):\n        return self._try_aggregate_string_function(func, *args, **kwds)\n\n    # handle ufuncs and lambdas\n    if kwds or args and not isinstance(func, np.ufunc):\n\n        def f(x):\n            return func(x, *args, **kwds)\n\n    else:\n        f = func\n\n    with np.errstate(all=\"ignore\"):\n        if isinstance(f, np.ufunc):\n            return f(self)\n\n        # row-wise access\n        if is_extension_type(self.dtype):\n            mapped = self._values.map(f)\n        else:\n            values = self.astype(object).values\n            mapped = lib.map_infer(values, f, convert=convert_dtype)\n\n    if len(mapped) and isinstance(mapped[0], Series):\n        # GH 25959 use pd.array instead of tolist\n        # so extension arrays can be used\n        return self._constructor_expanddim(pd.array(mapped), index=self.index)\n    else:\n        return self._constructor(mapped, index=self.index).__finalize__(self)",
                "def _reduce(\n    self, op, name, axis=0, skipna=True, numeric_only=None, filter_type=None, **kwds\n):\n    \"\"\"\n    Perform a reduction operation.\n\n    If we have an ndarray as a value, then simply perform the operation,\n    otherwise delegate to the object.\n    \"\"\"\n    delegate = self._values\n\n    if axis is not None:\n        self._get_axis_number(axis)\n\n    if isinstance(delegate, Categorical):\n        # TODO deprecate numeric_only argument for Categorical and use\n        # skipna as well, see GH25303\n        return delegate._reduce(name, numeric_only=numeric_only, **kwds)\n    elif isinstance(delegate, ExtensionArray):\n        # dispatch to ExtensionArray interface\n        return delegate._reduce(name, skipna=skipna, **kwds)\n    elif is_datetime64_dtype(delegate):\n        # use DatetimeIndex implementation to handle skipna correctly\n        delegate = DatetimeIndex(delegate)\n    elif is_timedelta64_dtype(delegate) and hasattr(TimedeltaIndex, name):\n        # use TimedeltaIndex to handle skipna correctly\n        # TODO: remove hasattr check after TimedeltaIndex has `std` method\n        delegate = TimedeltaIndex(delegate)\n\n    # dispatch to numpy arrays\n    elif isinstance(delegate, np.ndarray):\n        if numeric_only:\n            raise NotImplementedError(\n                \"Series.{0} does not implement numeric_only.\".format(name)\n            )\n        with np.errstate(all=\"ignore\"):\n            return op(delegate, skipna=skipna, **kwds)\n\n    # TODO(EA) dispatch to Index\n    # remove once all internals extension types are\n    # moved to ExtensionArrays\n    return delegate._reduce(\n        op=op,\n        name=name,\n        axis=axis,\n        skipna=skipna,\n        numeric_only=numeric_only,\n        filter_type=filter_type,\n        **kwds\n    )",
                "def _reindex_indexer(self, new_index, indexer, copy):\n    if indexer is None:\n        if copy:\n            return self.copy()\n        return self\n\n    new_values = algorithms.take_1d(\n        self._values, indexer, allow_fill=True, fill_value=None\n    )\n    return self._constructor(new_values, index=new_index)",
                "def _needs_reindex_multi(self, axes, method, level):\n    \"\"\"\n    Check if we do need a multi reindex; this is for compat with\n    higher dims.\n    \"\"\"\n    return False",
                "@Appender(generic._shared_docs[\"align\"] % _shared_doc_kwargs)\ndef align(\n    self,\n    other,\n    join=\"outer\",\n    axis=None,\n    level=None,\n    copy=True,\n    fill_value=None,\n    method=None,\n    limit=None,\n    fill_axis=0,\n    broadcast_axis=None,\n):\n    return super().align(\n        other,\n        join=join,\n        axis=axis,\n        level=level,\n        copy=copy,\n        fill_value=fill_value,\n        method=method,\n        limit=limit,\n        fill_axis=fill_axis,\n        broadcast_axis=broadcast_axis,\n    )",
                "def rename(self, index=None, **kwargs):\n    \"\"\"\n    Alter Series index labels or name.\n\n    Function / dict values must be unique (1-to-1). Labels not contained in\n    a dict / Series will be left as-is. Extra labels listed don't throw an\n    error.\n\n    Alternatively, change ``Series.name`` with a scalar value.\n\n    See the :ref:`user guide <basics.rename>` for more.\n\n    Parameters\n    ----------\n    index : scalar, hashable sequence, dict-like or function, optional\n        dict-like or functions are transformations to apply to\n        the index.\n        Scalar or hashable sequence-like will alter the ``Series.name``\n        attribute.\n    copy : bool, default True\n        Whether to copy underlying data.\n    inplace : bool, default False\n        Whether to return a new Series. If True then value of copy is\n        ignored.\n    level : int or level name, default None\n        In case of a MultiIndex, only rename labels in the specified\n        level.\n\n    Returns\n    -------\n    Series\n        Series with index labels or name altered.\n\n    See Also\n    --------\n    Series.rename_axis : Set the name of the axis.\n\n    Examples\n    --------\n    >>> s = pd.Series([1, 2, 3])\n    >>> s\n    0    1\n    1    2\n    2    3\n    dtype: int64\n    >>> s.rename(\"my_name\")  # scalar, changes Series.name\n    0    1\n    1    2\n    2    3\n    Name: my_name, dtype: int64\n    >>> s.rename(lambda x: x ** 2)  # function, changes labels\n    0    1\n    1    2\n    4    3\n    dtype: int64\n    >>> s.rename({1: 3, 2: 5})  # mapping, changes labels\n    0    1\n    3    2\n    5    3\n    dtype: int64\n    \"\"\"\n    kwargs[\"inplace\"] = validate_bool_kwarg(kwargs.get(\"inplace\", False), \"inplace\")\n\n    if callable(index) or is_dict_like(index):\n        return super().rename(index=index, **kwargs)\n    else:\n        return self._set_name(index, inplace=kwargs.get(\"inplace\"))",
                "@Substitution(**_shared_doc_kwargs)\n@Appender(generic.NDFrame.reindex.__doc__)\ndef reindex(self, index=None, **kwargs):\n    return super().reindex(index=index, **kwargs)",
                "def drop(\n    self,\n    labels=None,\n    axis=0,\n    index=None,\n    columns=None,\n    level=None,\n    inplace=False,\n    errors=\"raise\",\n):\n    \"\"\"\n    Return Series with specified index labels removed.\n\n    Remove elements of a Series based on specifying the index labels.\n    When using a multi-index, labels on different levels can be removed\n    by specifying the level.\n\n    Parameters\n    ----------\n    labels : single label or list-like\n        Index labels to drop.\n    axis : 0, default 0\n        Redundant for application on Series.\n    index, columns : None\n        Redundant for application on Series, but index can be used instead\n        of labels.\n\n        .. versionadded:: 0.21.0\n    level : int or level name, optional\n        For MultiIndex, level for which the labels will be removed.\n    inplace : bool, default False\n        If True, do operation inplace and return None.\n    errors : {'ignore', 'raise'}, default 'raise'\n        If 'ignore', suppress error and only existing labels are dropped.\n\n    Returns\n    -------\n    Series\n        Series with specified index labels removed.\n\n    Raises\n    ------\n    KeyError\n        If none of the labels are found in the index.\n\n    See Also\n    --------\n    Series.reindex : Return only specified index labels of Series.\n    Series.dropna : Return series without null values.\n    Series.drop_duplicates : Return Series with duplicate values removed.\n    DataFrame.drop : Drop specified labels from rows or columns.\n\n    Examples\n    --------\n    >>> s = pd.Series(data=np.arange(3), index=['A', 'B', 'C'])\n    >>> s\n    A  0\n    B  1\n    C  2\n    dtype: int64\n\n    Drop labels B en C\n\n    >>> s.drop(labels=['B', 'C'])\n    A  0\n    dtype: int64\n\n    Drop 2nd level label in MultiIndex Series\n\n    >>> midx = pd.MultiIndex(levels=[['lama', 'cow', 'falcon'],\n    ...                              ['speed', 'weight', 'length']],\n    ...                      codes=[[0, 0, 0, 1, 1, 1, 2, 2, 2],\n    ...                             [0, 1, 2, 0, 1, 2, 0, 1, 2]])\n    >>> s = pd.Series([45, 200, 1.2, 30, 250, 1.5, 320, 1, 0.3],\n    ...               index=midx)\n    >>> s\n    lama    speed      45.0\n            weight    200.0\n            length      1.2\n    cow     speed      30.0\n            weight    250.0\n            length      1.5\n    falcon  speed     320.0\n            weight      1.0\n            length      0.3\n    dtype: float64\n\n    >>> s.drop(labels='weight', level=1)\n    lama    speed      45.0\n            length      1.2\n    cow     speed      30.0\n            length      1.5\n    falcon  speed     320.0\n            length      0.3\n    dtype: float64\n    \"\"\"\n    return super().drop(\n        labels=labels,\n        axis=axis,\n        index=index,\n        columns=columns,\n        level=level,\n        inplace=inplace,\n        errors=errors,\n    )",
                "@Substitution(**_shared_doc_kwargs)\n@Appender(generic.NDFrame.fillna.__doc__)\ndef fillna(\n    self,\n    value=None,\n    method=None,\n    axis=None,\n    inplace=False,\n    limit=None,\n    downcast=None,\n    **kwargs\n):\n    return super().fillna(\n        value=value,\n        method=method,\n        axis=axis,\n        inplace=inplace,\n        limit=limit,\n        downcast=downcast,\n        **kwargs\n    )",
                "@Appender(generic._shared_docs[\"replace\"] % _shared_doc_kwargs)\ndef replace(\n    self,\n    to_replace=None,\n    value=None,\n    inplace=False,\n    limit=None,\n    regex=False,\n    method=\"pad\",\n):\n    return super().replace(\n        to_replace=to_replace,\n        value=value,\n        inplace=inplace,\n        limit=limit,\n        regex=regex,\n        method=method,\n    )",
                "@Appender(generic._shared_docs[\"shift\"] % _shared_doc_kwargs)\ndef shift(self, periods=1, freq=None, axis=0, fill_value=None):\n    return super().shift(\n        periods=periods, freq=freq, axis=axis, fill_value=fill_value\n    )",
                "def memory_usage(self, index=True, deep=False):\n    \"\"\"\n    Return the memory usage of the Series.\n\n    The memory usage can optionally include the contribution of\n    the index and of elements of `object` dtype.\n\n    Parameters\n    ----------\n    index : bool, default True\n        Specifies whether to include the memory usage of the Series index.\n    deep : bool, default False\n        If True, introspect the data deeply by interrogating\n        `object` dtypes for system-level memory consumption, and include\n        it in the returned value.\n\n    Returns\n    -------\n    int\n        Bytes of memory consumed.\n\n    See Also\n    --------\n    numpy.ndarray.nbytes : Total bytes consumed by the elements of the\n        array.\n    DataFrame.memory_usage : Bytes consumed by a DataFrame.\n\n    Examples\n    --------\n    >>> s = pd.Series(range(3))\n    >>> s.memory_usage()\n    152\n\n    Not including the index gives the size of the rest of the data, which\n    is necessarily smaller:\n\n    >>> s.memory_usage(index=False)\n    24\n\n    The memory footprint of `object` values is ignored by default:\n\n    >>> s = pd.Series([\"a\", \"b\"])\n    >>> s.values\n    array(['a', 'b'], dtype=object)\n    >>> s.memory_usage()\n    144\n    >>> s.memory_usage(deep=True)\n    260\n    \"\"\"\n    v = super().memory_usage(deep=deep)\n    if index:\n        v += self.index.memory_usage(deep=deep)\n    return v",
                "def isin(self, values):\n    \"\"\"\n    Check whether `values` are contained in Series.\n\n    Return a boolean Series showing whether each element in the Series\n    matches an element in the passed sequence of `values` exactly.\n\n    Parameters\n    ----------\n    values : set or list-like\n        The sequence of values to test. Passing in a single string will\n        raise a ``TypeError``. Instead, turn a single string into a\n        list of one element.\n\n    Returns\n    -------\n    Series\n        Series of booleans indicating if each element is in values.\n\n    Raises\n    ------\n    TypeError\n      * If `values` is a string\n\n    See Also\n    --------\n    DataFrame.isin : Equivalent method on DataFrame.\n\n    Examples\n    --------\n    >>> s = pd.Series(['lama', 'cow', 'lama', 'beetle', 'lama',\n    ...                'hippo'], name='animal')\n    >>> s.isin(['cow', 'lama'])\n    0     True\n    1     True\n    2     True\n    3    False\n    4     True\n    5    False\n    Name: animal, dtype: bool\n\n    Passing a single string as ``s.isin('lama')`` will raise an error. Use\n    a list of one element instead:\n\n    >>> s.isin(['lama'])\n    0     True\n    1    False\n    2     True\n    3    False\n    4     True\n    5    False\n    Name: animal, dtype: bool\n    \"\"\"\n    result = algorithms.isin(self, values)\n    return self._constructor(result, index=self.index).__finalize__(self)",
                "def between(self, left, right, inclusive=True):\n    \"\"\"\n    Return boolean Series equivalent to left <= series <= right.\n\n    This function returns a boolean vector containing `True` wherever the\n    corresponding Series element is between the boundary values `left` and\n    `right`. NA values are treated as `False`.\n\n    Parameters\n    ----------\n    left : scalar\n        Left boundary.\n    right : scalar\n        Right boundary.\n    inclusive : bool, default True\n        Include boundaries.\n\n    Returns\n    -------\n    Series\n        Series representing whether each element is between left and\n        right (inclusive).\n\n    See Also\n    --------\n    Series.gt : Greater than of series and other.\n    Series.lt : Less than of series and other.\n\n    Notes\n    -----\n    This function is equivalent to ``(left <= ser) & (ser <= right)``\n\n    Examples\n    --------\n    >>> s = pd.Series([2, 0, 4, 8, np.nan])\n\n    Boundary values are included by default:\n\n    >>> s.between(1, 4)\n    0     True\n    1    False\n    2     True\n    3    False\n    4    False\n    dtype: bool\n\n    With `inclusive` set to ``False`` boundary values are excluded:\n\n    >>> s.between(1, 4, inclusive=False)\n    0     True\n    1    False\n    2    False\n    3    False\n    4    False\n    dtype: bool\n\n    `left` and `right` can be any scalar value:\n\n    >>> s = pd.Series(['Alice', 'Bob', 'Carol', 'Eve'])\n    >>> s.between('Anna', 'Daniel')\n    0    False\n    1     True\n    2     True\n    3    False\n    dtype: bool\n    \"\"\"\n    if inclusive:\n        lmask = self >= left\n        rmask = self <= right\n    else:\n        lmask = self > left\n        rmask = self < right\n\n    return lmask & rmask",
                "@Appender(generic.NDFrame.to_csv.__doc__)\ndef to_csv(self, *args, **kwargs):\n\n    names = [\n        \"path_or_buf\",\n        \"sep\",\n        \"na_rep\",\n        \"float_format\",\n        \"columns\",\n        \"header\",\n        \"index\",\n        \"index_label\",\n        \"mode\",\n        \"encoding\",\n        \"compression\",\n        \"quoting\",\n        \"quotechar\",\n        \"line_terminator\",\n        \"chunksize\",\n        \"date_format\",\n        \"doublequote\",\n        \"escapechar\",\n        \"decimal\",\n    ]\n\n    old_names = [\n        \"path_or_buf\",\n        \"index\",\n        \"sep\",\n        \"na_rep\",\n        \"float_format\",\n        \"header\",\n        \"index_label\",\n        \"mode\",\n        \"encoding\",\n        \"compression\",\n        \"date_format\",\n        \"decimal\",\n    ]\n\n    if \"path\" in kwargs:\n        warnings.warn(\n            \"The signature of `Series.to_csv` was aligned \"\n            \"to that of `DataFrame.to_csv`, and argument \"\n            \"'path' will be renamed to 'path_or_buf'.\",\n            FutureWarning,\n            stacklevel=2,\n        )\n        kwargs[\"path_or_buf\"] = kwargs.pop(\"path\")\n\n    if len(args) > 1:\n        # Either \"index\" (old signature) or \"sep\" (new signature) is being\n        # passed as second argument (while the first is the same)\n        maybe_sep = args[1]\n\n        if not (is_string_like(maybe_sep) and len(maybe_sep) == 1):\n            # old signature\n            warnings.warn(\n                \"The signature of `Series.to_csv` was aligned \"\n                \"to that of `DataFrame.to_csv`. Note that the \"\n                \"order of arguments changed, and the new one \"\n                \"has 'sep' in first place, for which \\\"{}\\\" is \"\n                \"not a valid value. The old order will cease to \"\n                \"be supported in a future version. Please refer \"\n                \"to the documentation for `DataFrame.to_csv` \"\n                \"when updating your function \"\n                \"calls.\".format(maybe_sep),\n                FutureWarning,\n                stacklevel=2,\n            )\n            names = old_names\n\n    pos_args = dict(zip(names[: len(args)], args))\n\n    for key in pos_args:\n        if key in kwargs:\n            raise ValueError(\n                \"Argument given by name ('{}') and position \"\n                \"({})\".format(key, names.index(key))\n            )\n        kwargs[key] = pos_args[key]\n\n    if kwargs.get(\"header\", None) is None:\n        warnings.warn(\n            \"The signature of `Series.to_csv` was aligned \"\n            \"to that of `DataFrame.to_csv`, and argument \"\n            \"'header' will change its default value from False \"\n            \"to True: please pass an explicit value to suppress \"\n            \"this warning.\",\n            FutureWarning,\n            stacklevel=2,\n        )\n        kwargs[\"header\"] = False  # Backwards compatibility.\n    return self.to_frame().to_csv(**kwargs)",
                "@Appender(generic._shared_docs[\"isna\"] % _shared_doc_kwargs)\ndef isna(self):\n    return super().isna()",
                "@Appender(generic._shared_docs[\"isna\"] % _shared_doc_kwargs)\ndef isnull(self):\n    return super().isnull()",
                "@Appender(generic._shared_docs[\"notna\"] % _shared_doc_kwargs)\ndef notna(self):\n    return super().notna()",
                "@Appender(generic._shared_docs[\"notna\"] % _shared_doc_kwargs)\ndef notnull(self):\n    return super().notnull()",
                "def dropna(self, axis=0, inplace=False, **kwargs):\n    \"\"\"\n    Return a new Series with missing values removed.\n\n    See the :ref:`User Guide <missing_data>` for more on which values are\n    considered missing, and how to work with missing data.\n\n    Parameters\n    ----------\n    axis : {0 or 'index'}, default 0\n        There is only one axis to drop values from.\n    inplace : bool, default False\n        If True, do operation inplace and return None.\n    **kwargs\n        Not in use.\n\n    Returns\n    -------\n    Series\n        Series with NA entries dropped from it.\n\n    See Also\n    --------\n    Series.isna: Indicate missing values.\n    Series.notna : Indicate existing (non-missing) values.\n    Series.fillna : Replace missing values.\n    DataFrame.dropna : Drop rows or columns which contain NA values.\n    Index.dropna : Drop missing indices.\n\n    Examples\n    --------\n    >>> ser = pd.Series([1., 2., np.nan])\n    >>> ser\n    0    1.0\n    1    2.0\n    2    NaN\n    dtype: float64\n\n    Drop NA values from a Series.\n\n    >>> ser.dropna()\n    0    1.0\n    1    2.0\n    dtype: float64\n\n    Keep the Series with valid entries in the same variable.\n\n    >>> ser.dropna(inplace=True)\n    >>> ser\n    0    1.0\n    1    2.0\n    dtype: float64\n\n    Empty strings are not considered NA values. ``None`` is considered an\n    NA value.\n\n    >>> ser = pd.Series([np.NaN, 2, pd.NaT, '', None, 'I stay'])\n    >>> ser\n    0       NaN\n    1         2\n    2       NaT\n    3\n    4      None\n    5    I stay\n    dtype: object\n    >>> ser.dropna()\n    1         2\n    3\n    5    I stay\n    dtype: object\n    \"\"\"\n    inplace = validate_bool_kwarg(inplace, \"inplace\")\n    kwargs.pop(\"how\", None)\n    if kwargs:\n        raise TypeError(\n            \"dropna() got an unexpected keyword \"\n            'argument \"{0}\"'.format(list(kwargs.keys())[0])\n        )\n    # Validate the axis parameter\n    self._get_axis_number(axis or 0)\n\n    if self._can_hold_na:\n        result = remove_na_arraylike(self)\n        if inplace:\n            self._update_inplace(result)\n        else:\n            return result\n    else:\n        if inplace:\n            # do nothing\n            pass\n        else:\n            return self.copy()",
                "def valid(self, inplace=False, **kwargs):\n    \"\"\"\n    Return Series without null values.\n\n    .. deprecated:: 0.23.0\n        Use :meth:`Series.dropna` instead.\n\n    Returns\n    -------\n    Series\n        Series without null values.\n    \"\"\"\n    warnings.warn(\n        \"Method .valid will be removed in a future version. \"\n        \"Use .dropna instead.\",\n        FutureWarning,\n        stacklevel=2,\n    )\n    return self.dropna(inplace=inplace, **kwargs)",
                "def to_timestamp(self, freq=None, how=\"start\", copy=True):\n    \"\"\"\n    Cast to DatetimeIndex of Timestamps, at *beginning* of period.\n\n    Parameters\n    ----------\n    freq : str, default frequency of PeriodIndex\n        Desired frequency.\n    how : {'s', 'e', 'start', 'end'}\n        Convention for converting period to timestamp; start of period\n        vs. end.\n    copy : bool, default True\n        Whether or not to return a copy.\n\n    Returns\n    -------\n    Series with DatetimeIndex\n    \"\"\"\n    new_values = self._values\n    if copy:\n        new_values = new_values.copy()\n\n    new_index = self.index.to_timestamp(freq=freq, how=how)\n    return self._constructor(new_values, index=new_index).__finalize__(self)",
                "def to_period(self, freq=None, copy=True):\n    \"\"\"\n    Convert Series from DatetimeIndex to PeriodIndex with desired\n    frequency (inferred from index if not passed).\n\n    Parameters\n    ----------\n    freq : str, default None\n        Frequency associated with the PeriodIndex.\n    copy : bool, default True\n        Whether or not to return a copy.\n\n    Returns\n    -------\n    Series\n        Series with index converted to PeriodIndex.\n    \"\"\"\n    new_values = self._values\n    if copy:\n        new_values = new_values.copy()\n\n    new_index = self.index.to_period(freq=freq)\n    return self._constructor(new_values, index=new_index).__finalize__(self)",
                "def construct_return(result):\n    if lib.is_scalar(result):\n        return result\n    elif result.ndim > 1:\n        # e.g. np.subtract.outer\n        if method == \"outer\":\n            msg = (\n                \"outer method for ufunc {} is not implemented on \"\n                \"pandas objects. Returning an ndarray, but in the \"\n                \"future this will raise a 'NotImplementedError'. \"\n                \"Consider explicitly converting the Series \"\n                \"to an array with '.array' first.\"\n            )\n            warnings.warn(msg.format(ufunc), FutureWarning, stacklevel=3)\n        return result\n    return self._constructor(result, index=index, name=name, copy=False)",
                "def _try_kind_sort(arr):\n    # easier to ask forgiveness than permission\n    try:\n        # if kind==mergesort, it can fail for object dtype\n        return arr.argsort(kind=kind)\n    except TypeError:\n        # stable sort not available for object dtype\n        # uses the argsort default quicksort\n        return arr.argsort(kind=\"quicksort\")",
                "def f(x):\n    return func(x, *args, **kwds)"
            ],
            "inscope_function_signatures": [
                "remove_na(arr)",
                "_coerce_method(converter)",
                "wrapper(self)",
                "__init__(self, data=None, index=None, dtype=None, name=None, copy=False, fastpath=False)",
                "_init_dict(self, data, index=None, dtype=None)",
                "from_array(cls, arr, index=None, name=None, dtype=None, copy=False, fastpath=False)",
                "_constructor(self)",
                "_constructor_expanddim(self)",
                "_can_hold_na(self)",
                "_set_axis(self, axis, labels, fastpath=False)",
                "_set_subtyp(self, is_all_dates)",
                "_update_inplace(self, result, **kwargs)",
                "name(self)",
                "name(self, value)",
                "dtype(self)",
                "dtypes(self)",
                "ftype(self)",
                "ftypes(self)",
                "values(self)",
                "_values(self)",
                "get_values(self)",
                "_internal_get_values(self)",
                "asobject(self)",
                "ravel(self, order='C')",
                "compress(self, condition, *args, **kwargs)",
                "nonzero(self)",
                "put(self, *args, **kwargs)",
                "__len__(self)",
                "view(self, dtype=None)",
                "__array_ufunc__(self, ufunc: Callable, method: str, *inputs: Any, **kwargs: Any)",
                "__array__(self, dtype=None)",
                "real(self)",
                "real(self, v)",
                "imag(self)",
                "imag(self, v)",
                "_unpickle_series_compat(self, state)",
                "axes(self)",
                "take(self, indices, axis=0, is_copy=False, **kwargs)",
                "_ixs(self, i: int, axis: int=0)",
                "_slice(self, slobj: slice, axis: int=0, kind=None)",
                "__getitem__(self, key)",
                "_get_with(self, key)",
                "_get_values_tuple(self, key)",
                "_get_values(self, indexer)",
                "_get_value(self, label, takeable: bool=False)",
                "__setitem__(self, key, value)",
                "_set_with_engine(self, key, value)",
                "_set_with(self, key, value)",
                "_set_labels(self, key, value)",
                "_set_values(self, key, value)",
                "_set_value(self, label, value, takeable: bool=False)",
                "_is_mixed_type(self)",
                "repeat(self, repeats, axis=None)",
                "reset_index(self, level=None, drop=False, name=None, inplace=False)",
                "__repr__(self)",
                "to_string(self, buf=None, na_rep='NaN', float_format=None, header=True, index=True, length=False, dtype=False, name=False, max_rows=None, min_rows=None)",
                "items(self)",
                "iteritems(self)",
                "keys(self)",
                "to_dict(self, into=dict)",
                "to_frame(self, name=None)",
                "to_sparse(self, kind='block', fill_value=None)",
                "_set_name(self, name, inplace=False)",
                "count(self, level=None)",
                "mode(self, dropna=True)",
                "unique(self)",
                "drop_duplicates(self, keep='first', inplace=False)",
                "duplicated(self, keep='first')",
                "idxmin(self, axis=0, skipna=True, *args, **kwargs)",
                "idxmax(self, axis=0, skipna=True, *args, **kwargs)",
                "round(self, decimals=0, *args, **kwargs)",
                "quantile(self, q=0.5, interpolation='linear')",
                "corr(self, other, method='pearson', min_periods=None)",
                "cov(self, other, min_periods=None)",
                "diff(self, periods=1)",
                "autocorr(self, lag=1)",
                "dot(self, other)",
                "__matmul__(self, other)",
                "__rmatmul__(self, other)",
                "searchsorted(self, value, side='left', sorter=None)",
                "append(self, to_append, ignore_index=False, verify_integrity=False)",
                "_binop(self, other, func, level=None, fill_value=None)",
                "combine(self, other, func, fill_value=None)",
                "combine_first(self, other)",
                "update(self, other)",
                "sort_values(self, axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')",
                "sort_index(self, axis=0, level=None, ascending=True, inplace=False, kind='quicksort', na_position='last', sort_remaining=True)",
                "argsort(self, axis=0, kind='quicksort', order=None)",
                "nlargest(self, n=5, keep='first')",
                "nsmallest(self, n=5, keep='first')",
                "swaplevel(self, i=-2, j=-1, copy=True)",
                "reorder_levels(self, order)",
                "explode(self) -> 'Series'",
                "unstack(self, level=-1, fill_value=None)",
                "map(self, arg, na_action=None)",
                "_gotitem(self, key, ndim, subset=None)",
                "aggregate(self, func, axis=0, *args, **kwargs)",
                "transform(self, func, axis=0, *args, **kwargs)",
                "apply(self, func, convert_dtype=True, args=(), **kwds)",
                "_reduce(self, op, name, axis=0, skipna=True, numeric_only=None, filter_type=None, **kwds)",
                "_reindex_indexer(self, new_index, indexer, copy)",
                "_needs_reindex_multi(self, axes, method, level)",
                "align(self, other, join='outer', axis=None, level=None, copy=True, fill_value=None, method=None, limit=None, fill_axis=0, broadcast_axis=None)",
                "rename(self, index=None, **kwargs)",
                "reindex(self, index=None, **kwargs)",
                "drop(self, labels=None, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise')",
                "fillna(self, value=None, method=None, axis=None, inplace=False, limit=None, downcast=None, **kwargs)",
                "replace(self, to_replace=None, value=None, inplace=False, limit=None, regex=False, method='pad')",
                "shift(self, periods=1, freq=None, axis=0, fill_value=None)",
                "memory_usage(self, index=True, deep=False)",
                "isin(self, values)",
                "between(self, left, right, inclusive=True)",
                "to_csv(self, *args, **kwargs)",
                "isna(self)",
                "isnull(self)",
                "notna(self)",
                "notnull(self)",
                "dropna(self, axis=0, inplace=False, **kwargs)",
                "valid(self, inplace=False, **kwargs)",
                "to_timestamp(self, freq=None, how='start', copy=True)",
                "to_period(self, freq=None, copy=True)",
                "construct_return(result)",
                "_try_kind_sort(arr)",
                "f(x)"
            ],
            "variables_in_file": {
                "__all__": [
                    85
                ],
                "_shared_doc_kwargs": [
                    4608,
                    4322,
                    4612,
                    4616,
                    4170,
                    4075,
                    4620,
                    4303,
                    87,
                    3863,
                    3832,
                    4281
                ],
                "dict": [
                    257,
                    3972,
                    1413,
                    4585,
                    1713,
                    87,
                    991
                ],
                "warnings.warn": [
                    577,
                    642,
                    705,
                    1798,
                    488,
                    936,
                    970,
                    4554,
                    4570,
                    114,
                    692,
                    4596,
                    950,
                    599,
                    4730,
                    506,
                    381,
                    863
                ],
                "warnings": [
                    642,
                    1798,
                    1806,
                    1807,
                    936,
                    692,
                    950,
                    577,
                    705,
                    970,
                    4554,
                    599,
                    4570,
                    863,
                    488,
                    114,
                    4596,
                    4730,
                    506,
                    381
                ],
                "FutureWarning": [
                    385,
                    642,
                    707,
                    580,
                    4580,
                    936,
                    1800,
                    492,
                    974,
                    4558,
                    4602,
                    116,
                    692,
                    601,
                    954,
                    4733,
                    510,
                    863
                ],
                "remove_na_arraylike": [
                    4706,
                    119
                ],
                "arr": [
                    388,
                    3108,
                    3112,
                    393,
                    3114,
                    3117,
                    3149,
                    3122,
                    119
                ],
                "len": [
                    128,
                    1163,
                    1040,
                    2449,
                    3999,
                    289,
                    295,
                    298,
                    3115,
                    3120,
                    3125,
                    2614,
                    3128,
                    827,
                    3651,
                    1094,
                    1864,
                    716,
                    844,
                    1868,
                    4563,
                    4568,
                    4585,
                    2410,
                    1008,
                    1138,
                    1528,
                    1533,
                    3966
                ],
                "self": [
                    2560,
                    1025,
                    514,
                    1537,
                    1539,
                    1541,
                    1542,
                    1543,
                    1035,
                    3596,
                    1037,
                    1549,
                    3599,
                    1040,
                    4379,
                    1044,
                    1046,
                    3095,
                    1048,
                    3098,
                    1052,
                    1053,
                    1573,
                    1575,
                    1576,
                    3114,
                    3115,
                    556,
                    1071,
                    3120,
                    563,
                    2613,
                    1078,
                    1079,
                    2614,
                    2617,
                    1082,
                    1084,
                    2622,
                    3651,
                    1092,
                    1093,
                    1094,
                    583,
                    1095,
                    2630,
                    586,
                    2632,
                    3576,
                    3149,
                    1102,
                    3654,
                    3152,
                    3656,
                    1106,
                    3154,
                    2644,
                    1112,
                    1114,
                    2650,
                    604,
                    2655,
                    4703,
                    1121,
                    1634,
                    1123,
                    4705,
                    4706,
                    4708,
                    1128,
                    620,
                    4716,
                    1136,
                    3700,
                    1141,
                    2171,
                    2174,
                    128,
                    129,
                    1153,
                    1154,
                    644,
                    1156,
                    1158,
                    4606,
                    4736,
                    4505,
                    2877,
                    1167,
                    1169,
                    1171,
                    4759,
                    1176,
                    1178,
                    4763,
                    4764,
                    1693,
                    1182,
                    1183,
                    1184,
                    1697,
                    1189,
                    1190,
                    1191,
                    1193,
                    2733,
                    1711,
                    2735,
                    4783,
                    4787,
                    4788,
                    693,
                    1209,
                    1210,
                    1213,
                    1214,
                    1217,
                    2242,
                    1221,
                    710,
                    1222,
                    2245,
                    1225,
                    3781,
                    1227,
                    716,
                    2763,
                    1230,
                    2764,
                    2766,
                    2767,
                    1746,
                    3280,
                    3281,
                    3795,
                    1238,
                    2775,
                    1240,
                    2777,
                    2779,
                    1245,
                    1248,
                    225,
                    1251,
                    1254,
                    1257,
                    3307,
                    1260,
                    1774,
                    1776,
                    1266,
                    1267,
                    1269,
                    3317,
                    3318,
                    1273,
                    3321,
                    3323,
                    3837,
                    3838,
                    1279,
                    258,
                    2308,
                    2309,
                    1805,
                    3855,
                    784,
                    785,
                    786,
                    1298,
                    1299,
                    1301,
                    1808,
                    1303,
                    1809,
                    1305,
                    3350,
                    3354,
                    796,
                    1309,
                    3357,
                    1823,
                    800,
                    1313,
                    2850,
                    3359,
                    3360,
                    3361,
                    1318,
                    1319,
                    2855,
                    2856,
                    811,
                    2859,
                    816,
                    2866,
                    2356,
                    2868,
                    2869,
                    2871,
                    2360,
                    2873,
                    314,
                    316,
                    317,
                    1854,
                    2367,
                    1344,
                    1857,
                    1346,
                    1859,
                    1860,
                    2368,
                    1350,
                    2884,
                    840,
                    1352,
                    1867,
                    1869,
                    4435,
                    4436,
                    865,
                    1890,
                    2918,
                    2919,
                    2409,
                    3966,
                    3967,
                    3968,
                    3459,
                    3973,
                    1414,
                    1415,
                    1416,
                    3977,
                    2448,
                    3990,
                    3993,
                    3994,
                    411,
                    2972,
                    925,
                    926,
                    2975,
                    2976,
                    3996,
                    4002,
                    4506,
                    4004,
                    4508,
                    4509,
                    938,
                    430,
                    4015,
                    4018,
                    436,
                    438,
                    440,
                    444,
                    957,
                    446,
                    961,
                    450,
                    3652,
                    457,
                    3857,
                    463,
                    977,
                    2514,
                    2515,
                    981,
                    471,
                    4060,
                    4061,
                    478,
                    992,
                    993,
                    994,
                    4064,
                    3556,
                    4066,
                    4168,
                    496,
                    1012,
                    1013,
                    1014,
                    1528,
                    3577,
                    3578,
                    3866,
                    1532,
                    1533,
                    1534
                ],
                "converter": [
                    129,
                    130,
                    132
                ],
                "self.iloc": [
                    129
                ],
                "TypeError": [
                    130,
                    1347,
                    3109,
                    1545,
                    362,
                    1130,
                    300,
                    1229,
                    462,
                    2638,
                    3856,
                    277,
                    4698
                ],
                "format": [
                    130,
                    132,
                    4039,
                    297,
                    3147,
                    4590,
                    1650,
                    2419,
                    278,
                    4699,
                    4571
                ],
                "str": [
                    1312,
                    1856,
                    130,
                    3976,
                    1648,
                    4793,
                    793,
                    219
                ],
                "wrapper.__name__": [
                    132
                ],
                "wrapper": [
                    132,
                    133
                ],
                "converter.__name__": [
                    132
                ],
                "base.IndexOpsMixin": [
                    186,
                    140
                ],
                "base": [
                    186,
                    140,
                    2653
                ],
                "generic.NDFrame": [
                    4513,
                    450,
                    1030,
                    4282,
                    4171,
                    140,
                    180,
                    314
                ],
                "generic": [
                    4608,
                    4513,
                    450,
                    4322,
                    4612,
                    1030,
                    3834,
                    4282,
                    4616,
                    4075,
                    140,
                    4171,
                    4620,
                    4303,
                    180,
                    3863,
                    314
                ],
                "_metadata": [
                    177
                ],
                "_accessors": [
                    178
                ],
                "_deprecations": [
                    180
                ],
                "generic.NDFrame._deprecations": [
                    180
                ],
                "frozenset": [
                    180,
                    276
                ],
                "hasnans": [
                    185
                ],
                "property": [
                    480,
                    963,
                    452,
                    516,
                    409,
                    473,
                    588,
                    398,
                    558,
                    943,
                    1357,
                    402,
                    466,
                    498,
                    185,
                    1020
                ],
                "base.IndexOpsMixin.hasnans.func": [
                    186
                ],
                "base.IndexOpsMixin.hasnans": [
                    186
                ],
                "base.IndexOpsMixin.hasnans.__doc__": [
                    186
                ],
                "_data": [
                    188
                ],
                "fastpath": [
                    420,
                    198,
                    393,
                    429,
                    439
                ],
                "isinstance": [
                    257,
                    388,
                    261,
                    1285,
                    3972,
                    1160,
                    3976,
                    1163,
                    1291,
                    3596,
                    3980,
                    276,
                    3989,
                    280,
                    1178,
                    925,
                    3999,
                    1316,
                    2852,
                    425,
                    2732,
                    304,
                    816,
                    1072,
                    2612,
                    4020,
                    4024,
                    1087,
                    1856,
                    4036,
                    2629,
                    2760,
                    201,
                    2633,
                    2635,
                    1102,
                    1230,
                    3287,
                    219,
                    991,
                    227,
                    996,
                    357,
                    231,
                    1127,
                    1129,
                    1134,
                    1648,
                    241,
                    1265,
                    1140,
                    247,
                    1144,
                    249,
                    1530,
                    1147,
                    1277
                ],
                "data": [
                    256,
                    257,
                    258,
                    261,
                    263,
                    264,
                    274,
                    276,
                    278,
                    280,
                    282,
                    284,
                    287,
                    288,
                    289,
                    290,
                    295,
                    298,
                    304,
                    306,
                    308,
                    310,
                    312,
                    314,
                    201,
                    202,
                    204,
                    206,
                    340,
                    213,
                    214,
                    341,
                    221,
                    223,
                    227,
                    355,
                    357,
                    231,
                    233,
                    1003,
                    1004,
                    237,
                    240,
                    241,
                    244,
                    1012,
                    247,
                    249,
                    251,
                    253,
                    255
                ],
                "SingleBlockManager": [
                    261,
                    201,
                    202,
                    304,
                    1012,
                    312
                ],
                "index": [
                    258,
                    262,
                    263,
                    264,
                    393,
                    4378,
                    286,
                    289,
                    295,
                    298,
                    4274,
                    310,
                    312,
                    317,
                    832,
                    834,
                    836,
                    4165,
                    4166,
                    840,
                    4168,
                    202,
                    205,
                    206,
                    4173,
                    3281,
                    210,
                    211,
                    3284,
                    343,
                    3287,
                    3290,
                    347,
                    865,
                    355,
                    356,
                    3301,
                    1638,
                    3302,
                    3310,
                    1007,
                    3314,
                    1012,
                    1013,
                    252,
                    253,
                    255
                ],
                "copy": [
                    260,
                    264,
                    393,
                    203,
                    4784,
                    306,
                    307,
                    245,
                    310,
                    4760,
                    3577,
                    4059,
                    4094,
                    255
                ],
                "data.copy": [
                    204,
                    308
                ],
                "data.index": [
                    264,
                    253,
                    206,
                    263
                ],
                "ensure_index": [
                    211,
                    421
                ],
                "dtype": [
                    258,
                    259,
                    393,
                    785,
                    924,
                    937,
                    938,
                    305,
                    306,
                    310,
                    215,
                    346,
                    219,
                    220,
                    223,
                    352,
                    225,
                    1639,
                    235,
                    237
                ],
                "is_categorical": [
                    221
                ],
                "data.dtype": [
                    223
                ],
                "self._validate_dtype": [
                    225
                ],
                "MultiIndex": [
                    227,
                    3596,
                    1230,
                    1102,
                    3287,
                    1178
                ],
                "NotImplementedError": [
                    228,
                    4038
                ],
                "Index": [
                    231,
                    1291,
                    790,
                    1144,
                    1147
                ],
                "name": [
                    1539,
                    393,
                    1549,
                    1824,
                    4023,
                    4026,
                    316,
                    4030,
                    4039,
                    459,
                    846,
                    848,
                    4049,
                    2775,
                    2777,
                    2779,
                    865,
                    1635,
                    232,
                    233,
                    1773,
                    1007,
                    1776,
                    1009,
                    1014,
                    250,
                    251
                ],
                "data.name": [
                    233,
                    251
                ],
                "data.astype": [
                    306,
                    237
                ],
                "data._values.copy": [
                    240,
                    244
                ],
                "data._values": [
                    240,
                    244
                ],
                "ABCDatetimeIndex": [
                    241
                ],
                "data.tz": [
                    241
                ],
                "np.ndarray": [
                    4036,
                    1285,
                    806,
                    2635,
                    1004,
                    1072,
                    790,
                    247,
                    1144
                ],
                "np": [
                    1285,
                    3980,
                    2450,
                    3988,
                    3989,
                    790,
                    1303,
                    3356,
                    3360,
                    806,
                    938,
                    3115,
                    2861,
                    1072,
                    2867,
                    2623,
                    1860,
                    2244,
                    3654,
                    2631,
                    4036,
                    4041,
                    2634,
                    2635,
                    1868,
                    2636,
                    2772,
                    2650,
                    1003,
                    1004,
                    2411,
                    247,
                    1144,
                    2173
                ],
                "ABCSeries": [
                    249
                ],
                "ABCSparseSeries": [
                    249
                ],
                "data.reindex": [
                    255
                ],
                "data._data": [
                    256
                ],
                "self._init_dict": [
                    258
                ],
                "data.index.equals": [
                    264
                ],
                "AssertionError": [
                    1649,
                    267,
                    2761
                ],
                "is_extension_array_dtype": [
                    2873,
                    274,
                    1252
                ],
                "set": [
                    276,
                    844
                ],
                "data.__class__.__name__": [
                    278
                ],
                "data.__class__": [
                    278
                ],
                "ABCSparseArray": [
                    280,
                    388
                ],
                "data.to_dense": [
                    282
                ],
                "com.maybe_iterable_to_list": [
                    284
                ],
                "com": [
                    1120,
                    1218,
                    2242,
                    2308,
                    1745,
                    2514,
                    1107,
                    1237,
                    1308,
                    1175,
                    1209,
                    1082,
                    2171,
                    284,
                    1213
                ],
                "is_list_like": [
                    290,
                    287,
                    3124,
                    2366,
                    1087
                ],
                "ibase.default_index": [
                    1528,
                    289,
                    3120
                ],
                "ibase": [
                    1528,
                    289,
                    3120
                ],
                "ValueError": [
                    1312,
                    1220,
                    296,
                    3099,
                    3147,
                    1101,
                    4589,
                    431,
                    1231,
                    3856,
                    2418,
                    3126,
                    2615,
                    1179,
                    3133
                ],
                "sanitize_array": [
                    310
                ],
                "generic.NDFrame.__init__": [
                    314
                ],
                "self.name": [
                    2368,
                    993,
                    1539,
                    1575,
                    3656,
                    1808,
                    2869,
                    1014,
                    3354,
                    316,
                    2367
                ],
                "self._set_axis": [
                    317
                ],
                "keys": [
                    352,
                    347,
                    349,
                    341
                ],
                "values": [
                    1805,
                    1808,
                    3350,
                    3351,
                    3356,
                    3996,
                    3997,
                    3360,
                    1071,
                    1072,
                    1073,
                    1075,
                    1221,
                    3654,
                    1223,
                    3656,
                    4435,
                    341,
                    342,
                    346,
                    604,
                    349,
                    352,
                    1251,
                    1252,
                    1254,
                    1257,
                    1260
                ],
                "zip": [
                    837,
                    4585,
                    341,
                    825,
                    1693
                ],
                "data.items": [
                    341
                ],
                "list": [
                    3972,
                    1285,
                    1287,
                    1160,
                    2732,
                    342,
                    1144,
                    1145,
                    1530,
                    4700,
                    1118
                ],
                "na_value_for_dtype": [
                    346,
                    2850
                ],
                "s": [
                    352,
                    833,
                    834,
                    356,
                    361,
                    364
                ],
                "Series": [
                    1285,
                    400,
                    3354,
                    3999,
                    1316,
                    2852,
                    2612,
                    825,
                    1087,
                    836,
                    4804,
                    2760,
                    2633,
                    3656,
                    4811,
                    4812,
                    4813,
                    4816,
                    4817,
                    352,
                    1144
                ],
                "s.reindex": [
                    356
                ],
                "PY36": [
                    357
                ],
                "OrderedDict": [
                    357
                ],
                "s.sort_index": [
                    361
                ],
                "s._data": [
                    364
                ],
                "s.index": [
                    834,
                    364
                ],
                "cls": [
                    392,
                    796,
                    806,
                    391
                ],
                "SparseSeries": [
                    1808,
                    391
                ],
                "classmethod": [
                    366
                ],
                "DataFrame": [
                    406
                ],
                "self._data._can_hold_na": [
                    411
                ],
                "self._data": [
                    992,
                    514,
                    994,
                    1190,
                    1318,
                    586,
                    556,
                    716,
                    430,
                    496,
                    563,
                    1012,
                    471,
                    440,
                    411,
                    478,
                    2975
                ],
                "_index": [
                    413
                ],
                "labels": [
                    421,
                    423,
                    425,
                    427,
                    430,
                    4272,
                    438,
                    440,
                    3290,
                    3292
                ],
                "is_all_dates": [
                    424,
                    443,
                    436,
                    423
                ],
                "labels.is_all_dates": [
                    423
                ],
                "DatetimeIndex": [
                    425,
                    427,
                    4029
                ],
                "PeriodIndex": [
                    425
                ],
                "TimedeltaIndex": [
                    425,
                    4033,
                    4030
                ],
                "self._data.set_axis": [
                    440,
                    430
                ],
                "axis": [
                    1413,
                    4325,
                    4296,
                    4092,
                    430,
                    1040,
                    3280,
                    4017,
                    4018,
                    4050,
                    4273,
                    3095,
                    440,
                    3866,
                    1052,
                    3837,
                    4703
                ],
                "tslibs.OutOfBoundsDatetime": [
                    431
                ],
                "tslibs": [
                    431
                ],
                "self._set_subtyp": [
                    436
                ],
                "object.__setattr__": [
                    444,
                    446,
                    438,
                    463
                ],
                "object": [
                    3996,
                    463,
                    438,
                    444,
                    604,
                    446
                ],
                "generic.NDFrame._update_inplace": [
                    450
                ],
                "result": [
                    2308,
                    2309,
                    2311,
                    3599,
                    3600,
                    3601,
                    3855,
                    3857,
                    3859,
                    1046,
                    3354,
                    1052,
                    1053,
                    3356,
                    1055,
                    799,
                    1953,
                    802,
                    803,
                    1954,
                    3357,
                    1581,
                    1583,
                    2362,
                    2363,
                    1084,
                    2364,
                    1086,
                    1087,
                    2367,
                    2368,
                    450,
                    2371,
                    1093,
                    1094,
                    3656,
                    3657,
                    1098,
                    843,
                    3149,
                    3323,
                    3152,
                    2514,
                    851,
                    852,
                    853,
                    2515,
                    2773,
                    3154,
                    2777,
                    4435,
                    2779,
                    4436,
                    864,
                    865,
                    4706,
                    867,
                    4708,
                    869,
                    4710,
                    874,
                    1645,
                    3838,
                    1648,
                    1652,
                    3318,
                    1656,
                    3321,
                    1659,
                    1662,
                    3839
                ],
                "kwargs": [
                    4736,
                    643,
                    2307,
                    3843,
                    3844,
                    4606,
                    1032,
                    3855,
                    1041,
                    3857,
                    1043,
                    1044,
                    3867,
                    800,
                    2241,
                    450,
                    4163,
                    710,
                    4166,
                    4168,
                    4553,
                    843,
                    4300,
                    4173,
                    4561,
                    4696,
                    4697,
                    4700,
                    4588,
                    4593,
                    4595,
                    2170,
                    4605,
                    3838
                ],
                "self._name": [
                    457
                ],
                "value": [
                    1299,
                    1301,
                    1303,
                    1305,
                    1313,
                    1318,
                    1344,
                    1217,
                    1346,
                    1350,
                    1223,
                    4294,
                    1225,
                    1227,
                    461,
                    463,
                    1240,
                    4315,
                    1245,
                    2655,
                    1254,
                    1257,
                    1260,
                    1267,
                    1273,
                    1279
                ],
                "is_hashable": [
                    461
                ],
                "name.setter": [
                    459
                ],
                "self._data.dtype": [
                    478,
                    471
                ],
                "self._data.ftype": [
                    496,
                    514
                ],
                "self._data.external_values": [
                    556
                ],
                "self._data.internal_values": [
                    563
                ],
                "self._internal_get_values": [
                    583
                ],
                "self._data.get_values": [
                    586
                ],
                "self.astype": [
                    3996,
                    604
                ],
                "self._values.ravel": [
                    620
                ],
                "self._values": [
                    1542,
                    1415,
                    785,
                    1044,
                    3350,
                    4759,
                    3994,
                    1183,
                    1193,
                    3114,
                    1071,
                    4015,
                    4783,
                    2868,
                    693,
                    1209,
                    1210,
                    2877,
                    1344,
                    1346,
                    1221,
                    710,
                    2655,
                    4064,
                    1251,
                    620,
                    3317,
                    3577
                ],
                "order": [
                    3600,
                    620
                ],
                "msg": [
                    928,
                    642,
                    936,
                    687,
                    692,
                    856,
                    637,
                    863
                ],
                "nv.validate_compress": [
                    643
                ],
                "nv": [
                    2241,
                    643,
                    2307,
                    1413,
                    1032,
                    2170
                ],
                "args": [
                    2241,
                    2307,
                    643,
                    3973,
                    710,
                    3977,
                    4585,
                    3980,
                    3855,
                    3983,
                    3857,
                    4563,
                    4566,
                    2170,
                    3867,
                    3838
                ],
                "condition": [
                    644
                ],
                "self._values.nonzero": [
                    693
                ],
                "self._values.put": [
                    710
                ],
                "__finalize__": [
                    1541,
                    2309,
                    1416,
                    784,
                    1808,
                    1046,
                    4764,
                    3357,
                    3359,
                    1183,
                    4004,
                    1189,
                    4788,
                    1093,
                    2630,
                    3781,
                    1869,
                    2515,
                    4436,
                    3577,
                    3967
                ],
                "self._constructor": [
                    1541,
                    2309,
                    1416,
                    784,
                    1046,
                    4764,
                    3357,
                    3359,
                    1183,
                    4004,
                    1189,
                    4788,
                    2368,
                    2884,
                    1093,
                    2630,
                    3781,
                    1869,
                    3149,
                    2515,
                    4436,
                    865,
                    4066,
                    3318,
                    3577,
                    3967
                ],
                "self._values.view": [
                    785
                ],
                "self.index": [
                    1025,
                    1153,
                    1537,
                    2309,
                    1414,
                    1035,
                    3596,
                    1808,
                    785,
                    1298,
                    1178,
                    3354,
                    4379,
                    1309,
                    1182,
                    1693,
                    3357,
                    3360,
                    4002,
                    4763,
                    4004,
                    2855,
                    1711,
                    2866,
                    4787,
                    2613,
                    1078,
                    2614,
                    1210,
                    2174,
                    1084,
                    1857,
                    1346,
                    1859,
                    1092,
                    1860,
                    1222,
                    2245,
                    840,
                    3656,
                    3781,
                    2763,
                    3149,
                    1102,
                    1230,
                    2766,
                    3281,
                    2515,
                    4436,
                    1238,
                    1112,
                    1121,
                    994,
                    1254,
                    2918,
                    1257,
                    1260,
                    1266,
                    1269,
                    3576,
                    1532,
                    1533,
                    1534,
                    3967
                ],
                "_HANDLED_TYPES": [
                    790
                ],
                "ExtensionArray": [
                    4024,
                    790
                ],
                "Callable": [
                    793
                ],
                "Any": [
                    793
                ],
                "type": [
                    867,
                    2638,
                    815,
                    823,
                    1113,
                    796
                ],
                "ops.maybe_dispatch_ufunc_to_dunder_op": [
                    799
                ],
                "ops": [
                    2856,
                    4816,
                    4817,
                    2770,
                    2775,
                    2777,
                    2779,
                    799
                ],
                "ufunc": [
                    800,
                    843,
                    863
                ],
                "method": [
                    800,
                    4096,
                    870,
                    4295,
                    843,
                    2413,
                    2415,
                    2421,
                    855,
                    4319
                ],
                "inputs": [
                    800,
                    835,
                    837,
                    808,
                    842,
                    843,
                    822,
                    823,
                    825
                ],
                "NotImplemented": [
                    802,
                    819
                ],
                "no_defer": [
                    806,
                    815
                ],
                "np.ndarray.__array_ufunc__": [
                    806
                ],
                "cls.__array_ufunc__": [
                    806
                ],
                "item": [
                    808,
                    810,
                    811,
                    814,
                    815,
                    816
                ],
                "higher_priority": [
                    809,
                    818
                ],
                "hasattr": [
                    822,
                    810,
                    4030,
                    814
                ],
                "item.__array_priority__": [
                    811
                ],
                "self.__array_priority__": [
                    811
                ],
                "has_array_ufunc": [
                    818,
                    813
                ],
                "__array_ufunc__": [
                    815
                ],
                "self._HANDLED_TYPES": [
                    816
                ],
                "names": [
                    4516,
                    4583,
                    4585,
                    844,
                    846,
                    4591,
                    822
                ],
                "getattr": [
                    926,
                    843,
                    822
                ],
                "x": [
                    836,
                    837,
                    869,
                    842,
                    3983,
                    822,
                    823,
                    825
                ],
                "types": [
                    825,
                    837,
                    823
                ],
                "tuple": [
                    867,
                    835,
                    869,
                    996,
                    1413,
                    1032,
                    1160,
                    842,
                    2732,
                    1102,
                    1134,
                    1230,
                    823,
                    1530,
                    1277
                ],
                "alignable": [
                    832,
                    825,
                    827,
                    833
                ],
                "t": [
                    825,
                    836,
                    837
                ],
                "issubclass": [
                    825,
                    836
                ],
                "x.reindex": [
                    836
                ],
                "extract_array": [
                    842
                ],
                "lib.is_scalar": [
                    851
                ],
                "lib": [
                    851,
                    3997,
                    1150,
                    1295
                ],
                "result.ndim": [
                    2363,
                    853
                ],
                "msg.format": [
                    863
                ],
                "construct_return": [
                    874,
                    869
                ],
                "self.array": [
                    3654,
                    938,
                    925,
                    1854
                ],
                "ABCDatetimeArray": [
                    925
                ],
                "self.dtype": [
                    2850,
                    1094,
                    1576,
                    3993,
                    926,
                    3967
                ],
                "np.asarray": [
                    938,
                    3654,
                    2623
                ],
                "self.values.real": [
                    961,
                    957
                ],
                "self.values": [
                    961,
                    1867,
                    977,
                    981,
                    2871,
                    2873,
                    957,
                    2622
                ],
                "v": [
                    961,
                    981,
                    4377,
                    4379,
                    4380
                ],
                "real.setter": [
                    959
                ],
                "real": [
                    959
                ],
                "self.values.imag": [
                    977,
                    981
                ],
                "imag.setter": [
                    979
                ],
                "imag": [
                    979
                ],
                "__float__": [
                    984
                ],
                "_coerce_method": [
                    984,
                    985,
                    986
                ],
                "float": [
                    984
                ],
                "__long__": [
                    985
                ],
                "int": [
                    985,
                    986,
                    1077,
                    1057
                ],
                "__int__": [
                    986
                ],
                "state": [
                    992,
                    993,
                    996,
                    1000,
                    1017,
                    991
                ],
                "self._data.index": [
                    994
                ],
                "nd_state": [
                    1000,
                    1003,
                    1004
                ],
                "own_state": [
                    1000,
                    1008,
                    1009,
                    1007
                ],
                "np.empty": [
                    3115,
                    1003
                ],
                "np.ndarray.__setstate__": [
                    1004
                ],
                "self._index": [
                    1013
                ],
                "Exception": [
                    1280,
                    2625,
                    1192,
                    1288,
                    3597,
                    1137,
                    1017,
                    2878
                ],
                "nv.validate_take": [
                    1032
                ],
                "indices": [
                    1040,
                    1034,
                    1035,
                    1044
                ],
                "ensure_platform_int": [
                    3313,
                    1034
                ],
                "new_index": [
                    1537,
                    1414,
                    1542,
                    1416,
                    1035,
                    1047,
                    4763,
                    4764,
                    1182,
                    1183,
                    2855,
                    2858,
                    2866,
                    4787,
                    4788,
                    2884,
                    3576,
                    2763,
                    2768,
                    3284,
                    2777,
                    2779,
                    4066,
                    2918,
                    2919,
                    2920,
                    3314,
                    3315,
                    3318,
                    1528,
                    3577,
                    1534
                ],
                "self.index.take": [
                    1035
                ],
                "is_categorical_dtype": [
                    1037,
                    2871
                ],
                "maybe_convert_indices": [
                    1040
                ],
                "self._get_axis": [
                    1040,
                    1052
                ],
                "new_values": [
                    1415,
                    1416,
                    1044,
                    4759,
                    1047,
                    4761,
                    4764,
                    2857,
                    2862,
                    4783,
                    4785,
                    2868,
                    4788,
                    2877,
                    2884,
                    3780,
                    3781,
                    4063,
                    4066,
                    3317,
                    3318
                ],
                "self._values.take": [
                    1044,
                    3317
                ],
                "is_copy": [
                    1051
                ],
                "equals": [
                    1052
                ],
                "result._get_axis": [
                    1052
                ],
                "result._set_is_copy": [
                    1053
                ],
                "Appender": [
                    4608,
                    4513,
                    4322,
                    4612,
                    1030,
                    4282,
                    4616,
                    4075,
                    4171,
                    4620,
                    4303,
                    3863,
                    3834,
                    2653,
                    1695
                ],
                "generic.NDFrame.take.__doc__": [
                    1030
                ],
                "generic.NDFrame.take": [
                    1030
                ],
                "libindex.get_value_at": [
                    1073
                ],
                "libindex": [
                    1073
                ],
                "i": [
                    2242,
                    2243,
                    2245,
                    1073,
                    1075,
                    3576,
                    2171,
                    2172,
                    2174
                ],
                "slice": [
                    1127,
                    1163,
                    1265,
                    1140,
                    1077
                ],
                "slobj": [
                    1078,
                    1079
                ],
                "self.index._convert_slice_indexer": [
                    1266,
                    1078
                ],
                "kind": [
                    3360,
                    3108,
                    1805,
                    3310,
                    1078,
                    3356
                ],
                "self._get_values": [
                    1156,
                    1158,
                    1167,
                    1141,
                    1079,
                    1176
                ],
                "key": [
                    1082,
                    1084,
                    1092,
                    1094,
                    1102,
                    1105,
                    1107,
                    1112,
                    1113,
                    1117,
                    1118,
                    1120,
                    1121,
                    1123,
                    1127,
                    1128,
                    1129,
                    1134,
                    1136,
                    1138,
                    1139,
                    1140,
                    1141,
                    1144,
                    1145,
                    1147,
                    1148,
                    1150,
                    1154,
                    1156,
                    1158,
                    1160,
                    1163,
                    1167,
                    1169,
                    1171,
                    1175,
                    1176,
                    1182,
                    1213,
                    1217,
                    1222,
                    1223,
                    1224,
                    1227,
                    1230,
                    1235,
                    1237,
                    1238,
                    1240,
                    1245,
                    1254,
                    1257,
                    1260,
                    1265,
                    1266,
                    1269,
                    1273,
                    1277,
                    1279,
                    1283,
                    1284,
                    1285,
                    1287,
                    1289,
                    1291,
                    1292,
                    1293,
                    1295,
                    1299,
                    1301,
                    1303,
                    1305,
                    1308,
                    1309,
                    1312,
                    1316,
                    1317,
                    1318,
                    4587,
                    4588,
                    4591,
                    4593
                ],
                "com.apply_if_callable": [
                    1082,
                    1213
                ],
                "self.index.get_value": [
                    1210,
                    1084
                ],
                "is_scalar": [
                    1283,
                    1092,
                    1269,
                    1086
                ],
                "self.index.get_loc": [
                    1092,
                    1254,
                    1260
                ],
                "KeyError": [
                    1347,
                    1220,
                    1096,
                    1259,
                    1101
                ],
                "InvalidIndexError": [
                    1242,
                    1099
                ],
                "Ellipsis": [
                    1224,
                    1105
                ],
                "com.is_bool_indexer": [
                    1120,
                    1107,
                    1237
                ],
                "new_key": [
                    1112,
                    1113,
                    1114
                ],
                "self.index._convert_scalar_indexer": [
                    1112
                ],
                "self.__getitem__": [
                    1114
                ],
                "is_iterator": [
                    1117
                ],
                "check_bool_indexer": [
                    1121,
                    1238
                ],
                "self._get_with": [
                    1123
                ],
                "self._slice": [
                    1128
                ],
                "ABCDataFrame": [
                    1129,
                    2612,
                    2629
                ],
                "self._get_values_tuple": [
                    1136
                ],
                "key_type": [
                    1152,
                    1157,
                    1292,
                    1295,
                    1297,
                    1302,
                    1148,
                    1150
                ],
                "key.inferred_type": [
                    1148,
                    1292
                ],
                "lib.infer_dtype": [
                    1150,
                    1295
                ],
                "self.index.is_integer": [
                    1153
                ],
                "self.index.is_floating": [
                    1153
                ],
                "self.loc": [
                    1154,
                    1350,
                    1227,
                    1169,
                    1273
                ],
                "self.reindex": [
                    2617,
                    1171,
                    2919
                ],
                "com.any_none": [
                    1175
                ],
                "indexer": [
                    4064,
                    1313,
                    1190,
                    1193,
                    3309,
                    3313,
                    1266,
                    1267,
                    1310,
                    3284,
                    3314,
                    3317,
                    4058,
                    3291,
                    1309,
                    1182,
                    1183
                ],
                "self.index.get_loc_level": [
                    1182
                ],
                "self._data.get_slice": [
                    1190
                ],
                "bool": [
                    1321,
                    1195
                ],
                "takeable": [
                    1208,
                    1343
                ],
                "com.maybe_box_datetimelike": [
                    1209
                ],
                "label": [
                    1344,
                    1346,
                    1350,
                    1209,
                    1210
                ],
                "cacher_needs_updating": [
                    1214,
                    1247
                ],
                "self._check_is_chained_assignment_possible": [
                    1214
                ],
                "self._set_with_engine": [
                    1217
                ],
                "com.SettingWithCopyError": [
                    1218
                ],
                "is_integer": [
                    1269,
                    1222
                ],
                "self.index.inferred_type": [
                    1298,
                    1222
                ],
                "_is_unorderable_exception": [
                    1234
                ],
                "e": [
                    1234
                ],
                "IndexError": [
                    1235
                ],
                "self._where": [
                    1240
                ],
                "self._set_with": [
                    1245
                ],
                "self._maybe_update_cacher": [
                    1248,
                    2976,
                    1319
                ],
                "values.dtype": [
                    1252
                ],
                "self.index._engine.set_value": [
                    1257,
                    1346
                ],
                "self.index._engine": [
                    1257,
                    1346
                ],
                "self._set_values": [
                    1313,
                    1267,
                    1301,
                    1303,
                    1279
                ],
                "key._values": [
                    1317,
                    1293
                ],
                "self._set_labels": [
                    1305,
                    1299
                ],
                "key.astype": [
                    1303
                ],
                "np.bool_": [
                    1303
                ],
                "com.asarray_tuplesafe": [
                    1308
                ],
                "self.index.get_indexer": [
                    1309
                ],
                "mask": [
                    1312,
                    1862,
                    1863,
                    1864,
                    3351,
                    2975,
                    3353,
                    3355,
                    2973,
                    1310,
                    1311
                ],
                "mask.any": [
                    3353,
                    1863,
                    1311
                ],
                "self._data.setitem": [
                    1318
                ],
                "nv.validate_repeat": [
                    1413
                ],
                "self.index.repeat": [
                    3656,
                    1414
                ],
                "repeats": [
                    1414,
                    1415
                ],
                "self._values.repeat": [
                    1415
                ],
                "inplace": [
                    1536,
                    4736,
                    1544,
                    3093,
                    3098,
                    1822,
                    1823,
                    4277,
                    4297,
                    3278,
                    3151,
                    4695,
                    4316,
                    4707,
                    3304,
                    4712,
                    2028,
                    1526,
                    3320
                ],
                "validate_bool_kwarg": [
                    4163,
                    3278,
                    3093,
                    1526,
                    4695,
                    1822
                ],
                "drop": [
                    4271,
                    1550,
                    1527
                ],
                "level": [
                    1856,
                    1857,
                    1859,
                    1860,
                    1853,
                    1550,
                    2767,
                    4093,
                    3283,
                    3700,
                    3285,
                    4276,
                    1529,
                    1530,
                    1531,
                    1532,
                    1533,
                    1534
                ],
                "self.index._get_level_number": [
                    1857,
                    1532
                ],
                "lev": [
                    1859,
                    1864,
                    1865,
                    1868,
                    1869,
                    1532
                ],
                "self.index.nlevels": [
                    1533
                ],
                "self.index.droplevel": [
                    1534
                ],
                "self._values.copy": [
                    1542
                ],
                "df": [
                    1549,
                    1774,
                    1550,
                    1776,
                    1778,
                    2360,
                    2362
                ],
                "self.to_frame": [
                    2360,
                    1549,
                    4606
                ],
                "df.reset_index": [
                    1550
                ],
                "buf": [
                    1559,
                    1574,
                    1581,
                    1655,
                    1659,
                    1661
                ],
                "StringIO": [
                    1559
                ],
                "width": [
                    1560
                ],
                "height": [
                    1560,
                    1562,
                    1567
                ],
                "get_terminal_size": [
                    1560
                ],
                "max_rows": [
                    1561,
                    1578,
                    1643
                ],
                "get_option": [
                    1568,
                    1569,
                    1571,
                    1563,
                    1564
                ],
                "min_rows": [
                    1577,
                    1642,
                    1566
                ],
                "show_dimensions": [
                    1579,
                    1571
                ],
                "self.to_string": [
                    1573
                ],
                "buf.getvalue": [
                    1581
                ],
                "formatter": [
                    1633,
                    1645
                ],
                "fmt.SeriesFormatter": [
                    1633
                ],
                "fmt": [
                    1633
                ],
                "length": [
                    1636
                ],
                "header": [
                    1637
                ],
                "na_rep": [
                    1640
                ],
                "float_format": [
                    1641
                ],
                "formatter.to_string": [
                    1645
                ],
                "result.__class__.__name__": [
                    1652
                ],
                "result.__class__": [
                    1652
                ],
                "buf.write": [
                    1659
                ],
                "AttributeError": [
                    3856,
                    1660
                ],
                "open": [
                    1661
                ],
                "f": [
                    3997,
                    3986,
                    3989,
                    3990,
                    3994,
                    1661,
                    1662
                ],
                "f.write": [
                    1662
                ],
                "iter": [
                    1693
                ],
                "self.items": [
                    1697,
                    1746
                ],
                "items.__doc__": [
                    1695
                ],
                "items": [
                    1695
                ],
                "into_c": [
                    1745,
                    1746
                ],
                "com.standardize_mapping": [
                    1745
                ],
                "into": [
                    1745
                ],
                "self._constructor_expanddim": [
                    1776,
                    4002,
                    1774
                ],
                "SparseArray": [
                    1805
                ],
                "fill_value": [
                    2849,
                    2850,
                    4325,
                    2859,
                    2860,
                    1805,
                    2770,
                    3700,
                    4095
                ],
                "warnings.catch_warnings": [
                    1806
                ],
                "warnings.filterwarnings": [
                    1807
                ],
                "ser": [
                    1824,
                    1825,
                    1823
                ],
                "self.copy": [
                    3652,
                    3307,
                    4716,
                    3599,
                    4060,
                    1823
                ],
                "ser.name": [
                    1824
                ],
                "sum": [
                    1854
                ],
                "notna": [
                    4618,
                    1867,
                    2924,
                    2973,
                    1854
                ],
                "self.index.levels": [
                    1859
                ],
                "level_codes": [
                    1864,
                    1867,
                    1860,
                    1862
                ],
                "np.array": [
                    1860
                ],
                "self.index.codes": [
                    1860
                ],
                "cnt": [
                    1864,
                    1865
                ],
                "lev.insert": [
                    1865
                ],
                "lev._na_value": [
                    1865
                ],
                "obs": [
                    1867,
                    1868
                ],
                "out": [
                    1868,
                    1869
                ],
                "np.bincount": [
                    1868
                ],
                "algorithms.mode": [
                    1890
                ],
                "algorithms": [
                    1890,
                    3459,
                    3556,
                    2514,
                    4435,
                    4063,
                    2655
                ],
                "dropna": [
                    1890
                ],
                "unique": [
                    1953
                ],
                "super": [
                    1953,
                    4610,
                    3780,
                    4293,
                    4166,
                    4313,
                    4324,
                    4377,
                    4614,
                    4618,
                    2028,
                    4173,
                    4622,
                    4271,
                    2104,
                    4089,
                    3867
                ],
                "drop_duplicates": [
                    2028
                ],
                "keep": [
                    2104,
                    3556,
                    3459,
                    2028
                ],
                "duplicated": [
                    2104
                ],
                "skipna": [
                    4026,
                    2241,
                    2242,
                    4042,
                    4051,
                    2170,
                    2171
                ],
                "nv.validate_argmin_with_skipna": [
                    2170
                ],
                "nanops.nanargmin": [
                    2171
                ],
                "nanops": [
                    2242,
                    2171,
                    2451,
                    2414
                ],
                "com.values_from_object": [
                    2514,
                    2242,
                    2171,
                    2308
                ],
                "np.nan": [
                    2450,
                    2411,
                    2244,
                    2173
                ],
                "nv.validate_argmax_with_skipna": [
                    2241
                ],
                "nanops.nanargmax": [
                    2242
                ],
                "argmin": [
                    2248
                ],
                "deprecate": [
                    2248,
                    2262
                ],
                "idxmin": [
                    2250
                ],
                "dedent": [
                    2266,
                    2252,
                    3797,
                    3806
                ],
                "argmax": [
                    2262
                ],
                "idxmax": [
                    2264
                ],
                "nv.validate_round": [
                    2307
                ],
                "round": [
                    2308
                ],
                "decimals": [
                    2308
                ],
                "self._check_percentile": [
                    2356
                ],
                "q": [
                    2368,
                    2362,
                    2356,
                    2366
                ],
                "df.quantile": [
                    2362
                ],
                "interpolation": [
                    2362
                ],
                "result.iloc": [
                    2371,
                    2364
                ],
                "result.name": [
                    2367
                ],
                "Float64Index": [
                    2368
                ],
                "this": [
                    2919,
                    2409,
                    2410,
                    2921,
                    2764,
                    2924,
                    2415,
                    2448,
                    2449,
                    2767,
                    2451,
                    2768,
                    2770
                ],
                "other": [
                    2448,
                    2451,
                    2972,
                    2973,
                    2975,
                    2852,
                    2855,
                    2856,
                    2860,
                    2612,
                    2613,
                    2614,
                    2868,
                    2618,
                    2623,
                    2629,
                    2631,
                    2760,
                    2633,
                    2638,
                    2766,
                    2767,
                    2770,
                    2644,
                    2775,
                    2650,
                    2918,
                    2920,
                    2409,
                    2921,
                    2922,
                    2924,
                    2415,
                    4090
                ],
                "self.align": [
                    2448,
                    2409,
                    2767
                ],
                "callable": [
                    4165,
                    2413
                ],
                "nanops.nancorr": [
                    2414
                ],
                "this.values": [
                    2770,
                    2451,
                    2415
                ],
                "other.values": [
                    2770,
                    2451,
                    2415
                ],
                "min_periods": [
                    2451,
                    2415
                ],
                "nanops.nancov": [
                    2451
                ],
                "algorithms.diff": [
                    2514
                ],
                "periods": [
                    2514,
                    4325
                ],
                "self.corr": [
                    2560
                ],
                "self.shift": [
                    2560
                ],
                "lag": [
                    2560
                ],
                "common": [
                    2617,
                    2618,
                    2613,
                    2614
                ],
                "self.index.union": [
                    2613,
                    2918,
                    2855
                ],
                "other.index": [
                    2918,
                    2855,
                    2766,
                    2613,
                    2614
                ],
                "left": [
                    2617,
                    4505,
                    2619,
                    4508
                ],
                "right": [
                    2618,
                    2620,
                    4509,
                    4506
                ],
                "other.reindex": [
                    2920,
                    2618
                ],
                "lvals": [
                    2624,
                    2626,
                    2631,
                    2634,
                    2636,
                    2619,
                    2622
                ],
                "left.values": [
                    2619
                ],
                "rvals": [
                    2624,
                    2626,
                    2631,
                    2634,
                    2635,
                    2636,
                    2620,
                    2623
                ],
                "right.values": [
                    2620
                ],
                "lvals.shape": [
                    2624,
                    2626
                ],
                "rvals.shape": [
                    2624,
                    2626
                ],
                "np.dot": [
                    2634,
                    2636,
                    2631
                ],
                "other.columns": [
                    2631
                ],
                "self.dot": [
                    2650,
                    2644
                ],
                "np.transpose": [
                    2650
                ],
                "algorithms.searchsorted": [
                    2655
                ],
                "side": [
                    2655
                ],
                "sorter": [
                    2655
                ],
                "Substitution": [
                    3828,
                    4281,
                    4170,
                    2652
                ],
                "base._shared_docs": [
                    2653
                ],
                "to_append": [
                    2732,
                    2733,
                    2735
                ],
                "to_concat": [
                    2737,
                    2733,
                    2735
                ],
                "concat": [
                    2736
                ],
                "ignore_index": [
                    2737
                ],
                "verify_integrity": [
                    2737
                ],
                "self.index.equals": [
                    2766
                ],
                "this.index": [
                    2768
                ],
                "this_vals": [
                    2770,
                    2773
                ],
                "other_vals": [
                    2770,
                    2773
                ],
                "ops.fill_binop": [
                    2770
                ],
                "np.errstate": [
                    4041,
                    2861,
                    2867,
                    3988,
                    2772
                ],
                "func": [
                    3972,
                    3973,
                    3976,
                    3977,
                    3980,
                    2862,
                    3855,
                    3983,
                    3857,
                    3986,
                    2868,
                    2773,
                    2776,
                    3867,
                    3838
                ],
                "ops.get_op_result_name": [
                    2856,
                    2775
                ],
                "func.__name__": [
                    2776
                ],
                "ret": [
                    2777,
                    2779,
                    2780
                ],
                "ops._construct_divmod_result": [
                    2777
                ],
                "ops._construct_result": [
                    2779
                ],
                "new_name": [
                    2856,
                    2884,
                    2869
                ],
                "idx": [
                    3140,
                    3141,
                    3144,
                    3145,
                    2858,
                    2859,
                    2860,
                    3120
                ],
                "lv": [
                    2859,
                    2868,
                    2862
                ],
                "self.get": [
                    2859
                ],
                "rv": [
                    2860,
                    2862
                ],
                "other.get": [
                    2860
                ],
                "new_values.append": [
                    2862
                ],
                "self._values._from_sequence": [
                    2877
                ],
                "is_datetimelike": [
                    2921
                ],
                "to_datetime": [
                    2922
                ],
                "this.where": [
                    2924
                ],
                "other.reindex_like": [
                    2972
                ],
                "self._data.putmask": [
                    2975
                ],
                "self._get_axis_number": [
                    3280,
                    4018,
                    3095,
                    3866,
                    3837,
                    4703
                ],
                "self._is_cached": [
                    3098
                ],
                "arr.argsort": [
                    3112,
                    3108
                ],
                "sortedIdx": [
                    3140,
                    3141,
                    3144,
                    3145,
                    3115,
                    3149
                ],
                "np.int32": [
                    3115
                ],
                "bad": [
                    3141,
                    3143,
                    3145,
                    3117,
                    3119
                ],
                "isna": [
                    4610,
                    3117,
                    3351
                ],
                "good": [
                    3139,
                    3140,
                    3144,
                    3119,
                    3122
                ],
                "argsorted": [
                    3136,
                    3122,
                    3144,
                    3140
                ],
                "_try_kind_sort": [
                    3122
                ],
                "ascending": [
                    3301,
                    3302,
                    3310,
                    3124,
                    3125,
                    3285,
                    3128,
                    3130,
                    3132,
                    3293,
                    3135
                ],
                "is_bool": [
                    3132
                ],
                "na_position": [
                    3138,
                    3142,
                    3147,
                    3310,
                    3294
                ],
                "n": [
                    3139,
                    3140,
                    3141,
                    3459,
                    3143,
                    3144,
                    3145,
                    3556
                ],
                "good.sum": [
                    3139
                ],
                "bad.sum": [
                    3143
                ],
                "self._update_inplace": [
                    3152,
                    3321,
                    4708
                ],
                "result.__finalize__": [
                    3154,
                    3323
                ],
                "index.sortlevel": [
                    3284
                ],
                "sort_remaining": [
                    3285
                ],
                "index._sort_levels_monotonic": [
                    3290
                ],
                "lexsort_indexer": [
                    3291
                ],
                "labels._get_codes_for_sorting": [
                    3292
                ],
                "index.is_monotonic_increasing": [
                    3301
                ],
                "index.is_monotonic_decreasing": [
                    3302
                ],
                "nargsort": [
                    3309
                ],
                "index.take": [
                    3314
                ],
                "new_index._sort_levels_monotonic": [
                    3315
                ],
                "notmask": [
                    3355,
                    3356
                ],
                "np.argsort": [
                    3360,
                    3356
                ],
                "nlargest": [
                    3459
                ],
                "algorithms.SelectNSeries": [
                    3459,
                    3556
                ],
                "nsmallest": [
                    3556
                ],
                "self.index.swaplevel": [
                    3576
                ],
                "j": [
                    3576
                ],
                "result.index": [
                    3600
                ],
                "result.index.reorder_levels": [
                    3600
                ],
                "is_object_dtype": [
                    3651
                ],
                "counts": [
                    3656,
                    3654
                ],
                "reshape.explode": [
                    3654
                ],
                "reshape": [
                    3654
                ],
                "unstack": [
                    3700
                ],
                "_map_values": [
                    3780
                ],
                "arg": [
                    3780
                ],
                "na_action": [
                    3780
                ],
                "_agg_see_also_doc": [
                    3829,
                    3797
                ],
                "_agg_examples_doc": [
                    3830,
                    3806
                ],
                "how": [
                    4763,
                    3838
                ],
                "self._aggregate": [
                    3838
                ],
                "kwargs.pop": [
                    4696,
                    4561,
                    3843,
                    3844
                ],
                "self.apply": [
                    3855
                ],
                "generic._shared_docs": [
                    4608,
                    4322,
                    4612,
                    4616,
                    4075,
                    4620,
                    4303,
                    3863,
                    3834
                ],
                "agg": [
                    3861
                ],
                "aggregate": [
                    3861
                ],
                "transform": [
                    3867
                ],
                "self.aggregate": [
                    3973
                ],
                "kwds": [
                    3973,
                    3977,
                    4042,
                    3980,
                    3983,
                    4054,
                    4023,
                    4026
                ],
                "self._try_aggregate_string_function": [
                    3977
                ],
                "np.ufunc": [
                    3980,
                    3989
                ],
                "is_extension_type": [
                    3993
                ],
                "mapped": [
                    4002,
                    4004,
                    3994,
                    3997,
                    3999
                ],
                "self._values.map": [
                    3994
                ],
                "lib.map_infer": [
                    3997
                ],
                "convert_dtype": [
                    3997
                ],
                "pd.array": [
                    4002
                ],
                "pd": [
                    4002
                ],
                "delegate": [
                    4033,
                    4036,
                    4042,
                    4015,
                    4047,
                    4020,
                    4023,
                    4024,
                    4026,
                    4027,
                    4029,
                    4030
                ],
                "Categorical": [
                    4020
                ],
                "delegate._reduce": [
                    4026,
                    4047,
                    4023
                ],
                "numeric_only": [
                    4052,
                    4037,
                    4023
                ],
                "is_datetime64_dtype": [
                    4027
                ],
                "is_timedelta64_dtype": [
                    4030
                ],
                "op": [
                    4048,
                    4042
                ],
                "filter_type": [
                    4053
                ],
                "algorithms.take_1d": [
                    4063
                ],
                "align": [
                    4089
                ],
                "join": [
                    4091
                ],
                "limit": [
                    4097,
                    4298,
                    4317
                ],
                "fill_axis": [
                    4098
                ],
                "broadcast_axis": [
                    4099
                ],
                "kwargs.get": [
                    4168,
                    4163,
                    4595
                ],
                "is_dict_like": [
                    4165
                ],
                "rename": [
                    4166
                ],
                "self._set_name": [
                    4168
                ],
                "reindex": [
                    4173
                ],
                "generic.NDFrame.reindex.__doc__": [
                    4171
                ],
                "generic.NDFrame.reindex": [
                    4171
                ],
                "columns": [
                    4275
                ],
                "errors": [
                    4278
                ],
                "fillna": [
                    4293
                ],
                "downcast": [
                    4299
                ],
                "generic.NDFrame.fillna.__doc__": [
                    4282
                ],
                "generic.NDFrame.fillna": [
                    4282
                ],
                "replace": [
                    4313
                ],
                "to_replace": [
                    4314
                ],
                "regex": [
                    4318
                ],
                "shift": [
                    4324
                ],
                "freq": [
                    4763,
                    4325,
                    4787
                ],
                "memory_usage": [
                    4377
                ],
                "deep": [
                    4377,
                    4379
                ],
                "self.index.memory_usage": [
                    4379
                ],
                "algorithms.isin": [
                    4435
                ],
                "inclusive": [
                    4504
                ],
                "lmask": [
                    4505,
                    4508,
                    4511
                ],
                "rmask": [
                    4506,
                    4509,
                    4511
                ],
                "old_names": [
                    4538,
                    4583
                ],
                "maybe_sep": [
                    4568,
                    4579,
                    4566
                ],
                "is_string_like": [
                    4568
                ],
                "pos_args": [
                    4585,
                    4587,
                    4593
                ],
                "names.index": [
                    4591
                ],
                "to_csv": [
                    4606
                ],
                "generic.NDFrame.to_csv.__doc__": [
                    4513
                ],
                "generic.NDFrame.to_csv": [
                    4513
                ],
                "isnull": [
                    4614
                ],
                "notnull": [
                    4622
                ],
                "kwargs.keys": [
                    4700
                ],
                "self._can_hold_na": [
                    4705
                ],
                "self.dropna": [
                    4736
                ],
                "new_values.copy": [
                    4761,
                    4785
                ],
                "self.index.to_timestamp": [
                    4763
                ],
                "self.index.to_period": [
                    4787
                ],
                "CachedAccessor": [
                    4793,
                    4794,
                    4795,
                    4796,
                    4797
                ],
                "StringMethods": [
                    4793
                ],
                "dt": [
                    4794
                ],
                "CombinedDatetimelikeProperties": [
                    4794
                ],
                "cat": [
                    4795
                ],
                "CategoricalAccessor": [
                    4795
                ],
                "plot": [
                    4796
                ],
                "pandas.plotting.PlotAccessor": [
                    4796
                ],
                "pandas.plotting": [
                    4801,
                    4796
                ],
                "pandas": [
                    4801,
                    4796
                ],
                "sparse": [
                    4797
                ],
                "SparseAccessor": [
                    4797
                ],
                "hist": [
                    4801
                ],
                "pandas.plotting.hist_series": [
                    4801
                ],
                "Series._setup_axes": [
                    4804
                ],
                "Series._add_numeric_operations": [
                    4811
                ],
                "Series._add_series_only_operations": [
                    4812
                ],
                "Series._add_series_or_dataframe_operations": [
                    4813
                ],
                "ops.add_flex_arithmetic_methods": [
                    4816
                ],
                "ops.add_special_arithmetic_methods": [
                    4817
                ]
            },
            "filtered_variables_in_file": {
                "__all__": [
                    85
                ],
                "_shared_doc_kwargs": [
                    4608,
                    4322,
                    4612,
                    4616,
                    4170,
                    4075,
                    4620,
                    4303,
                    87,
                    3863,
                    3832,
                    4281
                ],
                "warnings.warn": [
                    577,
                    642,
                    705,
                    1798,
                    488,
                    936,
                    970,
                    4554,
                    4570,
                    114,
                    692,
                    4596,
                    950,
                    599,
                    4730,
                    506,
                    381,
                    863
                ],
                "warnings": [
                    642,
                    1798,
                    1806,
                    1807,
                    936,
                    692,
                    950,
                    577,
                    705,
                    970,
                    4554,
                    599,
                    4570,
                    863,
                    488,
                    114,
                    4596,
                    4730,
                    506,
                    381
                ],
                "remove_na_arraylike": [
                    4706,
                    119
                ],
                "arr": [
                    388,
                    3108,
                    3112,
                    393,
                    3114,
                    3117,
                    3149,
                    3122,
                    119
                ],
                "self": [
                    2560,
                    1025,
                    514,
                    1537,
                    1539,
                    1541,
                    1542,
                    1543,
                    1035,
                    3596,
                    1037,
                    1549,
                    3599,
                    1040,
                    4379,
                    1044,
                    1046,
                    3095,
                    1048,
                    3098,
                    1052,
                    1053,
                    1573,
                    1575,
                    1576,
                    3114,
                    3115,
                    556,
                    1071,
                    3120,
                    563,
                    2613,
                    1078,
                    1079,
                    2614,
                    2617,
                    1082,
                    1084,
                    2622,
                    3651,
                    1092,
                    1093,
                    1094,
                    583,
                    1095,
                    2630,
                    586,
                    2632,
                    3576,
                    3149,
                    1102,
                    3654,
                    3152,
                    3656,
                    1106,
                    3154,
                    2644,
                    1112,
                    1114,
                    2650,
                    604,
                    2655,
                    4703,
                    1121,
                    1634,
                    1123,
                    4705,
                    4706,
                    4708,
                    1128,
                    620,
                    4716,
                    1136,
                    3700,
                    1141,
                    2171,
                    2174,
                    128,
                    129,
                    1153,
                    1154,
                    644,
                    1156,
                    1158,
                    4606,
                    4736,
                    4505,
                    2877,
                    1167,
                    1169,
                    1171,
                    4759,
                    1176,
                    1178,
                    4763,
                    4764,
                    1693,
                    1182,
                    1183,
                    1184,
                    1697,
                    1189,
                    1190,
                    1191,
                    1193,
                    2733,
                    1711,
                    2735,
                    4783,
                    4787,
                    4788,
                    693,
                    1209,
                    1210,
                    1213,
                    1214,
                    1217,
                    2242,
                    1221,
                    710,
                    1222,
                    2245,
                    1225,
                    3781,
                    1227,
                    716,
                    2763,
                    1230,
                    2764,
                    2766,
                    2767,
                    1746,
                    3280,
                    3281,
                    3795,
                    1238,
                    2775,
                    1240,
                    2777,
                    2779,
                    1245,
                    1248,
                    225,
                    1251,
                    1254,
                    1257,
                    3307,
                    1260,
                    1774,
                    1776,
                    1266,
                    1267,
                    1269,
                    3317,
                    3318,
                    1273,
                    3321,
                    3323,
                    3837,
                    3838,
                    1279,
                    258,
                    2308,
                    2309,
                    1805,
                    3855,
                    784,
                    785,
                    786,
                    1298,
                    1299,
                    1301,
                    1808,
                    1303,
                    1809,
                    1305,
                    3350,
                    3354,
                    796,
                    1309,
                    3357,
                    1823,
                    800,
                    1313,
                    2850,
                    3359,
                    3360,
                    3361,
                    1318,
                    1319,
                    2855,
                    2856,
                    811,
                    2859,
                    816,
                    2866,
                    2356,
                    2868,
                    2869,
                    2871,
                    2360,
                    2873,
                    314,
                    316,
                    317,
                    1854,
                    2367,
                    1344,
                    1857,
                    1346,
                    1859,
                    1860,
                    2368,
                    1350,
                    2884,
                    840,
                    1352,
                    1867,
                    1869,
                    4435,
                    4436,
                    865,
                    1890,
                    2918,
                    2919,
                    2409,
                    3966,
                    3967,
                    3968,
                    3459,
                    3973,
                    1414,
                    1415,
                    1416,
                    3977,
                    2448,
                    3990,
                    3993,
                    3994,
                    411,
                    2972,
                    925,
                    926,
                    2975,
                    2976,
                    3996,
                    4002,
                    4506,
                    4004,
                    4508,
                    4509,
                    938,
                    430,
                    4015,
                    4018,
                    436,
                    438,
                    440,
                    444,
                    957,
                    446,
                    961,
                    450,
                    3652,
                    457,
                    3857,
                    463,
                    977,
                    2514,
                    2515,
                    981,
                    471,
                    4060,
                    4061,
                    478,
                    992,
                    993,
                    994,
                    4064,
                    3556,
                    4066,
                    4168,
                    496,
                    1012,
                    1013,
                    1014,
                    1528,
                    3577,
                    3578,
                    3866,
                    1532,
                    1533,
                    1534
                ],
                "converter": [
                    129,
                    130,
                    132
                ],
                "self.iloc": [
                    129
                ],
                "wrapper.__name__": [
                    132
                ],
                "wrapper": [
                    132,
                    133
                ],
                "converter.__name__": [
                    132
                ],
                "base.IndexOpsMixin": [
                    186,
                    140
                ],
                "base": [
                    186,
                    140,
                    2653
                ],
                "generic.NDFrame": [
                    4513,
                    450,
                    1030,
                    4282,
                    4171,
                    140,
                    180,
                    314
                ],
                "generic": [
                    4608,
                    4513,
                    450,
                    4322,
                    4612,
                    1030,
                    3834,
                    4282,
                    4616,
                    4075,
                    140,
                    4171,
                    4620,
                    4303,
                    180,
                    3863,
                    314
                ],
                "_metadata": [
                    177
                ],
                "_accessors": [
                    178
                ],
                "_deprecations": [
                    180
                ],
                "generic.NDFrame._deprecations": [
                    180
                ],
                "hasnans": [
                    185
                ],
                "base.IndexOpsMixin.hasnans.func": [
                    186
                ],
                "base.IndexOpsMixin.hasnans": [
                    186
                ],
                "base.IndexOpsMixin.hasnans.__doc__": [
                    186
                ],
                "_data": [
                    188
                ],
                "fastpath": [
                    420,
                    198,
                    393,
                    429,
                    439
                ],
                "data": [
                    256,
                    257,
                    258,
                    261,
                    263,
                    264,
                    274,
                    276,
                    278,
                    280,
                    282,
                    284,
                    287,
                    288,
                    289,
                    290,
                    295,
                    298,
                    304,
                    306,
                    308,
                    310,
                    312,
                    314,
                    201,
                    202,
                    204,
                    206,
                    340,
                    213,
                    214,
                    341,
                    221,
                    223,
                    227,
                    355,
                    357,
                    231,
                    233,
                    1003,
                    1004,
                    237,
                    240,
                    241,
                    244,
                    1012,
                    247,
                    249,
                    251,
                    253,
                    255
                ],
                "SingleBlockManager": [
                    261,
                    201,
                    202,
                    304,
                    1012,
                    312
                ],
                "index": [
                    258,
                    262,
                    263,
                    264,
                    393,
                    4378,
                    286,
                    289,
                    295,
                    298,
                    4274,
                    310,
                    312,
                    317,
                    832,
                    834,
                    836,
                    4165,
                    4166,
                    840,
                    4168,
                    202,
                    205,
                    206,
                    4173,
                    3281,
                    210,
                    211,
                    3284,
                    343,
                    3287,
                    3290,
                    347,
                    865,
                    355,
                    356,
                    3301,
                    1638,
                    3302,
                    3310,
                    1007,
                    3314,
                    1012,
                    1013,
                    252,
                    253,
                    255
                ],
                "copy": [
                    260,
                    264,
                    393,
                    203,
                    4784,
                    306,
                    307,
                    245,
                    310,
                    4760,
                    3577,
                    4059,
                    4094,
                    255
                ],
                "data.copy": [
                    204,
                    308
                ],
                "data.index": [
                    264,
                    253,
                    206,
                    263
                ],
                "ensure_index": [
                    211,
                    421
                ],
                "dtype": [
                    258,
                    259,
                    393,
                    785,
                    924,
                    937,
                    938,
                    305,
                    306,
                    310,
                    215,
                    346,
                    219,
                    220,
                    223,
                    352,
                    225,
                    1639,
                    235,
                    237
                ],
                "is_categorical": [
                    221
                ],
                "data.dtype": [
                    223
                ],
                "self._validate_dtype": [
                    225
                ],
                "MultiIndex": [
                    227,
                    3596,
                    1230,
                    1102,
                    3287,
                    1178
                ],
                "Index": [
                    231,
                    1291,
                    790,
                    1144,
                    1147
                ],
                "name": [
                    1539,
                    393,
                    1549,
                    1824,
                    4023,
                    4026,
                    316,
                    4030,
                    4039,
                    459,
                    846,
                    848,
                    4049,
                    2775,
                    2777,
                    2779,
                    865,
                    1635,
                    232,
                    233,
                    1773,
                    1007,
                    1776,
                    1009,
                    1014,
                    250,
                    251
                ],
                "data.name": [
                    233,
                    251
                ],
                "data.astype": [
                    306,
                    237
                ],
                "data._values.copy": [
                    240,
                    244
                ],
                "data._values": [
                    240,
                    244
                ],
                "ABCDatetimeIndex": [
                    241
                ],
                "data.tz": [
                    241
                ],
                "np.ndarray": [
                    4036,
                    1285,
                    806,
                    2635,
                    1004,
                    1072,
                    790,
                    247,
                    1144
                ],
                "np": [
                    1285,
                    3980,
                    2450,
                    3988,
                    3989,
                    790,
                    1303,
                    3356,
                    3360,
                    806,
                    938,
                    3115,
                    2861,
                    1072,
                    2867,
                    2623,
                    1860,
                    2244,
                    3654,
                    2631,
                    4036,
                    4041,
                    2634,
                    2635,
                    1868,
                    2636,
                    2772,
                    2650,
                    1003,
                    1004,
                    2411,
                    247,
                    1144,
                    2173
                ],
                "ABCSeries": [
                    249
                ],
                "ABCSparseSeries": [
                    249
                ],
                "data.reindex": [
                    255
                ],
                "data._data": [
                    256
                ],
                "self._init_dict": [
                    258
                ],
                "data.index.equals": [
                    264
                ],
                "is_extension_array_dtype": [
                    2873,
                    274,
                    1252
                ],
                "data.__class__.__name__": [
                    278
                ],
                "data.__class__": [
                    278
                ],
                "ABCSparseArray": [
                    280,
                    388
                ],
                "data.to_dense": [
                    282
                ],
                "com.maybe_iterable_to_list": [
                    284
                ],
                "com": [
                    1120,
                    1218,
                    2242,
                    2308,
                    1745,
                    2514,
                    1107,
                    1237,
                    1308,
                    1175,
                    1209,
                    1082,
                    2171,
                    284,
                    1213
                ],
                "is_list_like": [
                    290,
                    287,
                    3124,
                    2366,
                    1087
                ],
                "ibase.default_index": [
                    1528,
                    289,
                    3120
                ],
                "ibase": [
                    1528,
                    289,
                    3120
                ],
                "sanitize_array": [
                    310
                ],
                "generic.NDFrame.__init__": [
                    314
                ],
                "self.name": [
                    2368,
                    993,
                    1539,
                    1575,
                    3656,
                    1808,
                    2869,
                    1014,
                    3354,
                    316,
                    2367
                ],
                "self._set_axis": [
                    317
                ],
                "keys": [
                    352,
                    347,
                    349,
                    341
                ],
                "values": [
                    1805,
                    1808,
                    3350,
                    3351,
                    3356,
                    3996,
                    3997,
                    3360,
                    1071,
                    1072,
                    1073,
                    1075,
                    1221,
                    3654,
                    1223,
                    3656,
                    4435,
                    341,
                    342,
                    346,
                    604,
                    349,
                    352,
                    1251,
                    1252,
                    1254,
                    1257,
                    1260
                ],
                "data.items": [
                    341
                ],
                "na_value_for_dtype": [
                    346,
                    2850
                ],
                "s": [
                    352,
                    833,
                    834,
                    356,
                    361,
                    364
                ],
                "Series": [
                    1285,
                    400,
                    3354,
                    3999,
                    1316,
                    2852,
                    2612,
                    825,
                    1087,
                    836,
                    4804,
                    2760,
                    2633,
                    3656,
                    4811,
                    4812,
                    4813,
                    4816,
                    4817,
                    352,
                    1144
                ],
                "s.reindex": [
                    356
                ],
                "PY36": [
                    357
                ],
                "OrderedDict": [
                    357
                ],
                "s.sort_index": [
                    361
                ],
                "s._data": [
                    364
                ],
                "s.index": [
                    834,
                    364
                ],
                "cls": [
                    392,
                    796,
                    806,
                    391
                ],
                "SparseSeries": [
                    1808,
                    391
                ],
                "DataFrame": [
                    406
                ],
                "self._data._can_hold_na": [
                    411
                ],
                "self._data": [
                    992,
                    514,
                    994,
                    1190,
                    1318,
                    586,
                    556,
                    716,
                    430,
                    496,
                    563,
                    1012,
                    471,
                    440,
                    411,
                    478,
                    2975
                ],
                "_index": [
                    413
                ],
                "labels": [
                    421,
                    423,
                    425,
                    427,
                    430,
                    4272,
                    438,
                    440,
                    3290,
                    3292
                ],
                "is_all_dates": [
                    424,
                    443,
                    436,
                    423
                ],
                "labels.is_all_dates": [
                    423
                ],
                "DatetimeIndex": [
                    425,
                    427,
                    4029
                ],
                "PeriodIndex": [
                    425
                ],
                "TimedeltaIndex": [
                    425,
                    4033,
                    4030
                ],
                "self._data.set_axis": [
                    440,
                    430
                ],
                "axis": [
                    1413,
                    4325,
                    4296,
                    4092,
                    430,
                    1040,
                    3280,
                    4017,
                    4018,
                    4050,
                    4273,
                    3095,
                    440,
                    3866,
                    1052,
                    3837,
                    4703
                ],
                "tslibs.OutOfBoundsDatetime": [
                    431
                ],
                "tslibs": [
                    431
                ],
                "self._set_subtyp": [
                    436
                ],
                "object.__setattr__": [
                    444,
                    446,
                    438,
                    463
                ],
                "generic.NDFrame._update_inplace": [
                    450
                ],
                "result": [
                    2308,
                    2309,
                    2311,
                    3599,
                    3600,
                    3601,
                    3855,
                    3857,
                    3859,
                    1046,
                    3354,
                    1052,
                    1053,
                    3356,
                    1055,
                    799,
                    1953,
                    802,
                    803,
                    1954,
                    3357,
                    1581,
                    1583,
                    2362,
                    2363,
                    1084,
                    2364,
                    1086,
                    1087,
                    2367,
                    2368,
                    450,
                    2371,
                    1093,
                    1094,
                    3656,
                    3657,
                    1098,
                    843,
                    3149,
                    3323,
                    3152,
                    2514,
                    851,
                    852,
                    853,
                    2515,
                    2773,
                    3154,
                    2777,
                    4435,
                    2779,
                    4436,
                    864,
                    865,
                    4706,
                    867,
                    4708,
                    869,
                    4710,
                    874,
                    1645,
                    3838,
                    1648,
                    1652,
                    3318,
                    1656,
                    3321,
                    1659,
                    1662,
                    3839
                ],
                "kwargs": [
                    4736,
                    643,
                    2307,
                    3843,
                    3844,
                    4606,
                    1032,
                    3855,
                    1041,
                    3857,
                    1043,
                    1044,
                    3867,
                    800,
                    2241,
                    450,
                    4163,
                    710,
                    4166,
                    4168,
                    4553,
                    843,
                    4300,
                    4173,
                    4561,
                    4696,
                    4697,
                    4700,
                    4588,
                    4593,
                    4595,
                    2170,
                    4605,
                    3838
                ],
                "self._name": [
                    457
                ],
                "value": [
                    1299,
                    1301,
                    1303,
                    1305,
                    1313,
                    1318,
                    1344,
                    1217,
                    1346,
                    1350,
                    1223,
                    4294,
                    1225,
                    1227,
                    461,
                    463,
                    1240,
                    4315,
                    1245,
                    2655,
                    1254,
                    1257,
                    1260,
                    1267,
                    1273,
                    1279
                ],
                "is_hashable": [
                    461
                ],
                "name.setter": [
                    459
                ],
                "self._data.dtype": [
                    478,
                    471
                ],
                "self._data.ftype": [
                    496,
                    514
                ],
                "self._data.external_values": [
                    556
                ],
                "self._data.internal_values": [
                    563
                ],
                "self._internal_get_values": [
                    583
                ],
                "self._data.get_values": [
                    586
                ],
                "self.astype": [
                    3996,
                    604
                ],
                "self._values.ravel": [
                    620
                ],
                "self._values": [
                    1542,
                    1415,
                    785,
                    1044,
                    3350,
                    4759,
                    3994,
                    1183,
                    1193,
                    3114,
                    1071,
                    4015,
                    4783,
                    2868,
                    693,
                    1209,
                    1210,
                    2877,
                    1344,
                    1346,
                    1221,
                    710,
                    2655,
                    4064,
                    1251,
                    620,
                    3317,
                    3577
                ],
                "order": [
                    3600,
                    620
                ],
                "msg": [
                    928,
                    642,
                    936,
                    687,
                    692,
                    856,
                    637,
                    863
                ],
                "nv.validate_compress": [
                    643
                ],
                "nv": [
                    2241,
                    643,
                    2307,
                    1413,
                    1032,
                    2170
                ],
                "args": [
                    2241,
                    2307,
                    643,
                    3973,
                    710,
                    3977,
                    4585,
                    3980,
                    3855,
                    3983,
                    3857,
                    4563,
                    4566,
                    2170,
                    3867,
                    3838
                ],
                "condition": [
                    644
                ],
                "self._values.nonzero": [
                    693
                ],
                "self._values.put": [
                    710
                ],
                "__finalize__": [
                    1541,
                    2309,
                    1416,
                    784,
                    1808,
                    1046,
                    4764,
                    3357,
                    3359,
                    1183,
                    4004,
                    1189,
                    4788,
                    1093,
                    2630,
                    3781,
                    1869,
                    2515,
                    4436,
                    3577,
                    3967
                ],
                "self._constructor": [
                    1541,
                    2309,
                    1416,
                    784,
                    1046,
                    4764,
                    3357,
                    3359,
                    1183,
                    4004,
                    1189,
                    4788,
                    2368,
                    2884,
                    1093,
                    2630,
                    3781,
                    1869,
                    3149,
                    2515,
                    4436,
                    865,
                    4066,
                    3318,
                    3577,
                    3967
                ],
                "self._values.view": [
                    785
                ],
                "self.index": [
                    1025,
                    1153,
                    1537,
                    2309,
                    1414,
                    1035,
                    3596,
                    1808,
                    785,
                    1298,
                    1178,
                    3354,
                    4379,
                    1309,
                    1182,
                    1693,
                    3357,
                    3360,
                    4002,
                    4763,
                    4004,
                    2855,
                    1711,
                    2866,
                    4787,
                    2613,
                    1078,
                    2614,
                    1210,
                    2174,
                    1084,
                    1857,
                    1346,
                    1859,
                    1092,
                    1860,
                    1222,
                    2245,
                    840,
                    3656,
                    3781,
                    2763,
                    3149,
                    1102,
                    1230,
                    2766,
                    3281,
                    2515,
                    4436,
                    1238,
                    1112,
                    1121,
                    994,
                    1254,
                    2918,
                    1257,
                    1260,
                    1266,
                    1269,
                    3576,
                    1532,
                    1533,
                    1534,
                    3967
                ],
                "_HANDLED_TYPES": [
                    790
                ],
                "ExtensionArray": [
                    4024,
                    790
                ],
                "Callable": [
                    793
                ],
                "Any": [
                    793
                ],
                "ops.maybe_dispatch_ufunc_to_dunder_op": [
                    799
                ],
                "ops": [
                    2856,
                    4816,
                    4817,
                    2770,
                    2775,
                    2777,
                    2779,
                    799
                ],
                "ufunc": [
                    800,
                    843,
                    863
                ],
                "method": [
                    800,
                    4096,
                    870,
                    4295,
                    843,
                    2413,
                    2415,
                    2421,
                    855,
                    4319
                ],
                "inputs": [
                    800,
                    835,
                    837,
                    808,
                    842,
                    843,
                    822,
                    823,
                    825
                ],
                "no_defer": [
                    806,
                    815
                ],
                "np.ndarray.__array_ufunc__": [
                    806
                ],
                "cls.__array_ufunc__": [
                    806
                ],
                "item": [
                    808,
                    810,
                    811,
                    814,
                    815,
                    816
                ],
                "higher_priority": [
                    809,
                    818
                ],
                "item.__array_priority__": [
                    811
                ],
                "self.__array_priority__": [
                    811
                ],
                "has_array_ufunc": [
                    818,
                    813
                ],
                "__array_ufunc__": [
                    815
                ],
                "self._HANDLED_TYPES": [
                    816
                ],
                "names": [
                    4516,
                    4583,
                    4585,
                    844,
                    846,
                    4591,
                    822
                ],
                "x": [
                    836,
                    837,
                    869,
                    842,
                    3983,
                    822,
                    823,
                    825
                ],
                "types": [
                    825,
                    837,
                    823
                ],
                "alignable": [
                    832,
                    825,
                    827,
                    833
                ],
                "t": [
                    825,
                    836,
                    837
                ],
                "x.reindex": [
                    836
                ],
                "extract_array": [
                    842
                ],
                "lib.is_scalar": [
                    851
                ],
                "lib": [
                    851,
                    3997,
                    1150,
                    1295
                ],
                "result.ndim": [
                    2363,
                    853
                ],
                "msg.format": [
                    863
                ],
                "construct_return": [
                    874,
                    869
                ],
                "self.array": [
                    3654,
                    938,
                    925,
                    1854
                ],
                "ABCDatetimeArray": [
                    925
                ],
                "self.dtype": [
                    2850,
                    1094,
                    1576,
                    3993,
                    926,
                    3967
                ],
                "np.asarray": [
                    938,
                    3654,
                    2623
                ],
                "self.values.real": [
                    961,
                    957
                ],
                "self.values": [
                    961,
                    1867,
                    977,
                    981,
                    2871,
                    2873,
                    957,
                    2622
                ],
                "v": [
                    961,
                    981,
                    4377,
                    4379,
                    4380
                ],
                "real.setter": [
                    959
                ],
                "real": [
                    959
                ],
                "self.values.imag": [
                    977,
                    981
                ],
                "imag.setter": [
                    979
                ],
                "imag": [
                    979
                ],
                "__float__": [
                    984
                ],
                "_coerce_method": [
                    984,
                    985,
                    986
                ],
                "__long__": [
                    985
                ],
                "__int__": [
                    986
                ],
                "state": [
                    992,
                    993,
                    996,
                    1000,
                    1017,
                    991
                ],
                "self._data.index": [
                    994
                ],
                "nd_state": [
                    1000,
                    1003,
                    1004
                ],
                "own_state": [
                    1000,
                    1008,
                    1009,
                    1007
                ],
                "np.empty": [
                    3115,
                    1003
                ],
                "np.ndarray.__setstate__": [
                    1004
                ],
                "self._index": [
                    1013
                ],
                "nv.validate_take": [
                    1032
                ],
                "indices": [
                    1040,
                    1034,
                    1035,
                    1044
                ],
                "ensure_platform_int": [
                    3313,
                    1034
                ],
                "new_index": [
                    1537,
                    1414,
                    1542,
                    1416,
                    1035,
                    1047,
                    4763,
                    4764,
                    1182,
                    1183,
                    2855,
                    2858,
                    2866,
                    4787,
                    4788,
                    2884,
                    3576,
                    2763,
                    2768,
                    3284,
                    2777,
                    2779,
                    4066,
                    2918,
                    2919,
                    2920,
                    3314,
                    3315,
                    3318,
                    1528,
                    3577,
                    1534
                ],
                "self.index.take": [
                    1035
                ],
                "is_categorical_dtype": [
                    1037,
                    2871
                ],
                "maybe_convert_indices": [
                    1040
                ],
                "self._get_axis": [
                    1040,
                    1052
                ],
                "new_values": [
                    1415,
                    1416,
                    1044,
                    4759,
                    1047,
                    4761,
                    4764,
                    2857,
                    2862,
                    4783,
                    4785,
                    2868,
                    4788,
                    2877,
                    2884,
                    3780,
                    3781,
                    4063,
                    4066,
                    3317,
                    3318
                ],
                "self._values.take": [
                    1044,
                    3317
                ],
                "is_copy": [
                    1051
                ],
                "equals": [
                    1052
                ],
                "result._get_axis": [
                    1052
                ],
                "result._set_is_copy": [
                    1053
                ],
                "Appender": [
                    4608,
                    4513,
                    4322,
                    4612,
                    1030,
                    4282,
                    4616,
                    4075,
                    4171,
                    4620,
                    4303,
                    3863,
                    3834,
                    2653,
                    1695
                ],
                "generic.NDFrame.take.__doc__": [
                    1030
                ],
                "generic.NDFrame.take": [
                    1030
                ],
                "libindex.get_value_at": [
                    1073
                ],
                "libindex": [
                    1073
                ],
                "i": [
                    2242,
                    2243,
                    2245,
                    1073,
                    1075,
                    3576,
                    2171,
                    2172,
                    2174
                ],
                "slobj": [
                    1078,
                    1079
                ],
                "self.index._convert_slice_indexer": [
                    1266,
                    1078
                ],
                "kind": [
                    3360,
                    3108,
                    1805,
                    3310,
                    1078,
                    3356
                ],
                "self._get_values": [
                    1156,
                    1158,
                    1167,
                    1141,
                    1079,
                    1176
                ],
                "key": [
                    1082,
                    1084,
                    1092,
                    1094,
                    1102,
                    1105,
                    1107,
                    1112,
                    1113,
                    1117,
                    1118,
                    1120,
                    1121,
                    1123,
                    1127,
                    1128,
                    1129,
                    1134,
                    1136,
                    1138,
                    1139,
                    1140,
                    1141,
                    1144,
                    1145,
                    1147,
                    1148,
                    1150,
                    1154,
                    1156,
                    1158,
                    1160,
                    1163,
                    1167,
                    1169,
                    1171,
                    1175,
                    1176,
                    1182,
                    1213,
                    1217,
                    1222,
                    1223,
                    1224,
                    1227,
                    1230,
                    1235,
                    1237,
                    1238,
                    1240,
                    1245,
                    1254,
                    1257,
                    1260,
                    1265,
                    1266,
                    1269,
                    1273,
                    1277,
                    1279,
                    1283,
                    1284,
                    1285,
                    1287,
                    1289,
                    1291,
                    1292,
                    1293,
                    1295,
                    1299,
                    1301,
                    1303,
                    1305,
                    1308,
                    1309,
                    1312,
                    1316,
                    1317,
                    1318,
                    4587,
                    4588,
                    4591,
                    4593
                ],
                "com.apply_if_callable": [
                    1082,
                    1213
                ],
                "self.index.get_value": [
                    1210,
                    1084
                ],
                "is_scalar": [
                    1283,
                    1092,
                    1269,
                    1086
                ],
                "self.index.get_loc": [
                    1092,
                    1254,
                    1260
                ],
                "InvalidIndexError": [
                    1242,
                    1099
                ],
                "com.is_bool_indexer": [
                    1120,
                    1107,
                    1237
                ],
                "new_key": [
                    1112,
                    1113,
                    1114
                ],
                "self.index._convert_scalar_indexer": [
                    1112
                ],
                "self.__getitem__": [
                    1114
                ],
                "is_iterator": [
                    1117
                ],
                "check_bool_indexer": [
                    1121,
                    1238
                ],
                "self._get_with": [
                    1123
                ],
                "self._slice": [
                    1128
                ],
                "ABCDataFrame": [
                    1129,
                    2612,
                    2629
                ],
                "self._get_values_tuple": [
                    1136
                ],
                "key_type": [
                    1152,
                    1157,
                    1292,
                    1295,
                    1297,
                    1302,
                    1148,
                    1150
                ],
                "key.inferred_type": [
                    1148,
                    1292
                ],
                "lib.infer_dtype": [
                    1150,
                    1295
                ],
                "self.index.is_integer": [
                    1153
                ],
                "self.index.is_floating": [
                    1153
                ],
                "self.loc": [
                    1154,
                    1350,
                    1227,
                    1169,
                    1273
                ],
                "self.reindex": [
                    2617,
                    1171,
                    2919
                ],
                "com.any_none": [
                    1175
                ],
                "indexer": [
                    4064,
                    1313,
                    1190,
                    1193,
                    3309,
                    3313,
                    1266,
                    1267,
                    1310,
                    3284,
                    3314,
                    3317,
                    4058,
                    3291,
                    1309,
                    1182,
                    1183
                ],
                "self.index.get_loc_level": [
                    1182
                ],
                "self._data.get_slice": [
                    1190
                ],
                "takeable": [
                    1208,
                    1343
                ],
                "com.maybe_box_datetimelike": [
                    1209
                ],
                "label": [
                    1344,
                    1346,
                    1350,
                    1209,
                    1210
                ],
                "cacher_needs_updating": [
                    1214,
                    1247
                ],
                "self._check_is_chained_assignment_possible": [
                    1214
                ],
                "self._set_with_engine": [
                    1217
                ],
                "com.SettingWithCopyError": [
                    1218
                ],
                "is_integer": [
                    1269,
                    1222
                ],
                "self.index.inferred_type": [
                    1298,
                    1222
                ],
                "_is_unorderable_exception": [
                    1234
                ],
                "e": [
                    1234
                ],
                "self._where": [
                    1240
                ],
                "self._set_with": [
                    1245
                ],
                "self._maybe_update_cacher": [
                    1248,
                    2976,
                    1319
                ],
                "values.dtype": [
                    1252
                ],
                "self.index._engine.set_value": [
                    1257,
                    1346
                ],
                "self.index._engine": [
                    1257,
                    1346
                ],
                "self._set_values": [
                    1313,
                    1267,
                    1301,
                    1303,
                    1279
                ],
                "key._values": [
                    1317,
                    1293
                ],
                "self._set_labels": [
                    1305,
                    1299
                ],
                "key.astype": [
                    1303
                ],
                "np.bool_": [
                    1303
                ],
                "com.asarray_tuplesafe": [
                    1308
                ],
                "self.index.get_indexer": [
                    1309
                ],
                "mask": [
                    1312,
                    1862,
                    1863,
                    1864,
                    3351,
                    2975,
                    3353,
                    3355,
                    2973,
                    1310,
                    1311
                ],
                "mask.any": [
                    3353,
                    1863,
                    1311
                ],
                "self._data.setitem": [
                    1318
                ],
                "nv.validate_repeat": [
                    1413
                ],
                "self.index.repeat": [
                    3656,
                    1414
                ],
                "repeats": [
                    1414,
                    1415
                ],
                "self._values.repeat": [
                    1415
                ],
                "inplace": [
                    1536,
                    4736,
                    1544,
                    3093,
                    3098,
                    1822,
                    1823,
                    4277,
                    4297,
                    3278,
                    3151,
                    4695,
                    4316,
                    4707,
                    3304,
                    4712,
                    2028,
                    1526,
                    3320
                ],
                "validate_bool_kwarg": [
                    4163,
                    3278,
                    3093,
                    1526,
                    4695,
                    1822
                ],
                "drop": [
                    4271,
                    1550,
                    1527
                ],
                "level": [
                    1856,
                    1857,
                    1859,
                    1860,
                    1853,
                    1550,
                    2767,
                    4093,
                    3283,
                    3700,
                    3285,
                    4276,
                    1529,
                    1530,
                    1531,
                    1532,
                    1533,
                    1534
                ],
                "self.index._get_level_number": [
                    1857,
                    1532
                ],
                "lev": [
                    1859,
                    1864,
                    1865,
                    1868,
                    1869,
                    1532
                ],
                "self.index.nlevels": [
                    1533
                ],
                "self.index.droplevel": [
                    1534
                ],
                "self._values.copy": [
                    1542
                ],
                "df": [
                    1549,
                    1774,
                    1550,
                    1776,
                    1778,
                    2360,
                    2362
                ],
                "self.to_frame": [
                    2360,
                    1549,
                    4606
                ],
                "df.reset_index": [
                    1550
                ],
                "buf": [
                    1559,
                    1574,
                    1581,
                    1655,
                    1659,
                    1661
                ],
                "StringIO": [
                    1559
                ],
                "width": [
                    1560
                ],
                "height": [
                    1560,
                    1562,
                    1567
                ],
                "get_terminal_size": [
                    1560
                ],
                "max_rows": [
                    1561,
                    1578,
                    1643
                ],
                "get_option": [
                    1568,
                    1569,
                    1571,
                    1563,
                    1564
                ],
                "min_rows": [
                    1577,
                    1642,
                    1566
                ],
                "show_dimensions": [
                    1579,
                    1571
                ],
                "self.to_string": [
                    1573
                ],
                "buf.getvalue": [
                    1581
                ],
                "formatter": [
                    1633,
                    1645
                ],
                "fmt.SeriesFormatter": [
                    1633
                ],
                "fmt": [
                    1633
                ],
                "length": [
                    1636
                ],
                "header": [
                    1637
                ],
                "na_rep": [
                    1640
                ],
                "float_format": [
                    1641
                ],
                "formatter.to_string": [
                    1645
                ],
                "result.__class__.__name__": [
                    1652
                ],
                "result.__class__": [
                    1652
                ],
                "buf.write": [
                    1659
                ],
                "f": [
                    3997,
                    3986,
                    3989,
                    3990,
                    3994,
                    1661,
                    1662
                ],
                "f.write": [
                    1662
                ],
                "self.items": [
                    1697,
                    1746
                ],
                "items.__doc__": [
                    1695
                ],
                "items": [
                    1695
                ],
                "into_c": [
                    1745,
                    1746
                ],
                "com.standardize_mapping": [
                    1745
                ],
                "into": [
                    1745
                ],
                "self._constructor_expanddim": [
                    1776,
                    4002,
                    1774
                ],
                "SparseArray": [
                    1805
                ],
                "fill_value": [
                    2849,
                    2850,
                    4325,
                    2859,
                    2860,
                    1805,
                    2770,
                    3700,
                    4095
                ],
                "warnings.catch_warnings": [
                    1806
                ],
                "warnings.filterwarnings": [
                    1807
                ],
                "ser": [
                    1824,
                    1825,
                    1823
                ],
                "self.copy": [
                    3652,
                    3307,
                    4716,
                    3599,
                    4060,
                    1823
                ],
                "ser.name": [
                    1824
                ],
                "notna": [
                    4618,
                    1867,
                    2924,
                    2973,
                    1854
                ],
                "self.index.levels": [
                    1859
                ],
                "level_codes": [
                    1864,
                    1867,
                    1860,
                    1862
                ],
                "np.array": [
                    1860
                ],
                "self.index.codes": [
                    1860
                ],
                "cnt": [
                    1864,
                    1865
                ],
                "lev.insert": [
                    1865
                ],
                "lev._na_value": [
                    1865
                ],
                "obs": [
                    1867,
                    1868
                ],
                "out": [
                    1868,
                    1869
                ],
                "np.bincount": [
                    1868
                ],
                "algorithms.mode": [
                    1890
                ],
                "algorithms": [
                    1890,
                    3459,
                    3556,
                    2514,
                    4435,
                    4063,
                    2655
                ],
                "dropna": [
                    1890
                ],
                "unique": [
                    1953
                ],
                "drop_duplicates": [
                    2028
                ],
                "keep": [
                    2104,
                    3556,
                    3459,
                    2028
                ],
                "duplicated": [
                    2104
                ],
                "skipna": [
                    4026,
                    2241,
                    2242,
                    4042,
                    4051,
                    2170,
                    2171
                ],
                "nv.validate_argmin_with_skipna": [
                    2170
                ],
                "nanops.nanargmin": [
                    2171
                ],
                "nanops": [
                    2242,
                    2171,
                    2451,
                    2414
                ],
                "com.values_from_object": [
                    2514,
                    2242,
                    2171,
                    2308
                ],
                "np.nan": [
                    2450,
                    2411,
                    2244,
                    2173
                ],
                "nv.validate_argmax_with_skipna": [
                    2241
                ],
                "nanops.nanargmax": [
                    2242
                ],
                "argmin": [
                    2248
                ],
                "deprecate": [
                    2248,
                    2262
                ],
                "idxmin": [
                    2250
                ],
                "dedent": [
                    2266,
                    2252,
                    3797,
                    3806
                ],
                "argmax": [
                    2262
                ],
                "idxmax": [
                    2264
                ],
                "nv.validate_round": [
                    2307
                ],
                "decimals": [
                    2308
                ],
                "self._check_percentile": [
                    2356
                ],
                "q": [
                    2368,
                    2362,
                    2356,
                    2366
                ],
                "df.quantile": [
                    2362
                ],
                "interpolation": [
                    2362
                ],
                "result.iloc": [
                    2371,
                    2364
                ],
                "result.name": [
                    2367
                ],
                "Float64Index": [
                    2368
                ],
                "this": [
                    2919,
                    2409,
                    2410,
                    2921,
                    2764,
                    2924,
                    2415,
                    2448,
                    2449,
                    2767,
                    2451,
                    2768,
                    2770
                ],
                "other": [
                    2448,
                    2451,
                    2972,
                    2973,
                    2975,
                    2852,
                    2855,
                    2856,
                    2860,
                    2612,
                    2613,
                    2614,
                    2868,
                    2618,
                    2623,
                    2629,
                    2631,
                    2760,
                    2633,
                    2638,
                    2766,
                    2767,
                    2770,
                    2644,
                    2775,
                    2650,
                    2918,
                    2920,
                    2409,
                    2921,
                    2922,
                    2924,
                    2415,
                    4090
                ],
                "self.align": [
                    2448,
                    2409,
                    2767
                ],
                "nanops.nancorr": [
                    2414
                ],
                "this.values": [
                    2770,
                    2451,
                    2415
                ],
                "other.values": [
                    2770,
                    2451,
                    2415
                ],
                "min_periods": [
                    2451,
                    2415
                ],
                "nanops.nancov": [
                    2451
                ],
                "algorithms.diff": [
                    2514
                ],
                "periods": [
                    2514,
                    4325
                ],
                "self.corr": [
                    2560
                ],
                "self.shift": [
                    2560
                ],
                "lag": [
                    2560
                ],
                "common": [
                    2617,
                    2618,
                    2613,
                    2614
                ],
                "self.index.union": [
                    2613,
                    2918,
                    2855
                ],
                "other.index": [
                    2918,
                    2855,
                    2766,
                    2613,
                    2614
                ],
                "left": [
                    2617,
                    4505,
                    2619,
                    4508
                ],
                "right": [
                    2618,
                    2620,
                    4509,
                    4506
                ],
                "other.reindex": [
                    2920,
                    2618
                ],
                "lvals": [
                    2624,
                    2626,
                    2631,
                    2634,
                    2636,
                    2619,
                    2622
                ],
                "left.values": [
                    2619
                ],
                "rvals": [
                    2624,
                    2626,
                    2631,
                    2634,
                    2635,
                    2636,
                    2620,
                    2623
                ],
                "right.values": [
                    2620
                ],
                "lvals.shape": [
                    2624,
                    2626
                ],
                "rvals.shape": [
                    2624,
                    2626
                ],
                "np.dot": [
                    2634,
                    2636,
                    2631
                ],
                "other.columns": [
                    2631
                ],
                "self.dot": [
                    2650,
                    2644
                ],
                "np.transpose": [
                    2650
                ],
                "algorithms.searchsorted": [
                    2655
                ],
                "side": [
                    2655
                ],
                "sorter": [
                    2655
                ],
                "Substitution": [
                    3828,
                    4281,
                    4170,
                    2652
                ],
                "base._shared_docs": [
                    2653
                ],
                "to_append": [
                    2732,
                    2733,
                    2735
                ],
                "to_concat": [
                    2737,
                    2733,
                    2735
                ],
                "concat": [
                    2736
                ],
                "ignore_index": [
                    2737
                ],
                "verify_integrity": [
                    2737
                ],
                "self.index.equals": [
                    2766
                ],
                "this.index": [
                    2768
                ],
                "this_vals": [
                    2770,
                    2773
                ],
                "other_vals": [
                    2770,
                    2773
                ],
                "ops.fill_binop": [
                    2770
                ],
                "np.errstate": [
                    4041,
                    2861,
                    2867,
                    3988,
                    2772
                ],
                "func": [
                    3972,
                    3973,
                    3976,
                    3977,
                    3980,
                    2862,
                    3855,
                    3983,
                    3857,
                    3986,
                    2868,
                    2773,
                    2776,
                    3867,
                    3838
                ],
                "ops.get_op_result_name": [
                    2856,
                    2775
                ],
                "func.__name__": [
                    2776
                ],
                "ret": [
                    2777,
                    2779,
                    2780
                ],
                "ops._construct_divmod_result": [
                    2777
                ],
                "ops._construct_result": [
                    2779
                ],
                "new_name": [
                    2856,
                    2884,
                    2869
                ],
                "idx": [
                    3140,
                    3141,
                    3144,
                    3145,
                    2858,
                    2859,
                    2860,
                    3120
                ],
                "lv": [
                    2859,
                    2868,
                    2862
                ],
                "self.get": [
                    2859
                ],
                "rv": [
                    2860,
                    2862
                ],
                "other.get": [
                    2860
                ],
                "new_values.append": [
                    2862
                ],
                "self._values._from_sequence": [
                    2877
                ],
                "is_datetimelike": [
                    2921
                ],
                "to_datetime": [
                    2922
                ],
                "this.where": [
                    2924
                ],
                "other.reindex_like": [
                    2972
                ],
                "self._data.putmask": [
                    2975
                ],
                "self._get_axis_number": [
                    3280,
                    4018,
                    3095,
                    3866,
                    3837,
                    4703
                ],
                "self._is_cached": [
                    3098
                ],
                "arr.argsort": [
                    3112,
                    3108
                ],
                "sortedIdx": [
                    3140,
                    3141,
                    3144,
                    3145,
                    3115,
                    3149
                ],
                "np.int32": [
                    3115
                ],
                "bad": [
                    3141,
                    3143,
                    3145,
                    3117,
                    3119
                ],
                "isna": [
                    4610,
                    3117,
                    3351
                ],
                "good": [
                    3139,
                    3140,
                    3144,
                    3119,
                    3122
                ],
                "argsorted": [
                    3136,
                    3122,
                    3144,
                    3140
                ],
                "_try_kind_sort": [
                    3122
                ],
                "ascending": [
                    3301,
                    3302,
                    3310,
                    3124,
                    3125,
                    3285,
                    3128,
                    3130,
                    3132,
                    3293,
                    3135
                ],
                "is_bool": [
                    3132
                ],
                "na_position": [
                    3138,
                    3142,
                    3147,
                    3310,
                    3294
                ],
                "n": [
                    3139,
                    3140,
                    3141,
                    3459,
                    3143,
                    3144,
                    3145,
                    3556
                ],
                "good.sum": [
                    3139
                ],
                "bad.sum": [
                    3143
                ],
                "self._update_inplace": [
                    3152,
                    3321,
                    4708
                ],
                "result.__finalize__": [
                    3154,
                    3323
                ],
                "index.sortlevel": [
                    3284
                ],
                "sort_remaining": [
                    3285
                ],
                "index._sort_levels_monotonic": [
                    3290
                ],
                "lexsort_indexer": [
                    3291
                ],
                "labels._get_codes_for_sorting": [
                    3292
                ],
                "index.is_monotonic_increasing": [
                    3301
                ],
                "index.is_monotonic_decreasing": [
                    3302
                ],
                "nargsort": [
                    3309
                ],
                "index.take": [
                    3314
                ],
                "new_index._sort_levels_monotonic": [
                    3315
                ],
                "notmask": [
                    3355,
                    3356
                ],
                "np.argsort": [
                    3360,
                    3356
                ],
                "nlargest": [
                    3459
                ],
                "algorithms.SelectNSeries": [
                    3459,
                    3556
                ],
                "nsmallest": [
                    3556
                ],
                "self.index.swaplevel": [
                    3576
                ],
                "j": [
                    3576
                ],
                "result.index": [
                    3600
                ],
                "result.index.reorder_levels": [
                    3600
                ],
                "is_object_dtype": [
                    3651
                ],
                "counts": [
                    3656,
                    3654
                ],
                "reshape.explode": [
                    3654
                ],
                "reshape": [
                    3654
                ],
                "unstack": [
                    3700
                ],
                "_map_values": [
                    3780
                ],
                "arg": [
                    3780
                ],
                "na_action": [
                    3780
                ],
                "_agg_see_also_doc": [
                    3829,
                    3797
                ],
                "_agg_examples_doc": [
                    3830,
                    3806
                ],
                "how": [
                    4763,
                    3838
                ],
                "self._aggregate": [
                    3838
                ],
                "kwargs.pop": [
                    4696,
                    4561,
                    3843,
                    3844
                ],
                "self.apply": [
                    3855
                ],
                "generic._shared_docs": [
                    4608,
                    4322,
                    4612,
                    4616,
                    4075,
                    4620,
                    4303,
                    3863,
                    3834
                ],
                "agg": [
                    3861
                ],
                "aggregate": [
                    3861
                ],
                "transform": [
                    3867
                ],
                "self.aggregate": [
                    3973
                ],
                "kwds": [
                    3973,
                    3977,
                    4042,
                    3980,
                    3983,
                    4054,
                    4023,
                    4026
                ],
                "self._try_aggregate_string_function": [
                    3977
                ],
                "np.ufunc": [
                    3980,
                    3989
                ],
                "is_extension_type": [
                    3993
                ],
                "mapped": [
                    4002,
                    4004,
                    3994,
                    3997,
                    3999
                ],
                "self._values.map": [
                    3994
                ],
                "lib.map_infer": [
                    3997
                ],
                "convert_dtype": [
                    3997
                ],
                "pd.array": [
                    4002
                ],
                "pd": [
                    4002
                ],
                "delegate": [
                    4033,
                    4036,
                    4042,
                    4015,
                    4047,
                    4020,
                    4023,
                    4024,
                    4026,
                    4027,
                    4029,
                    4030
                ],
                "Categorical": [
                    4020
                ],
                "delegate._reduce": [
                    4026,
                    4047,
                    4023
                ],
                "numeric_only": [
                    4052,
                    4037,
                    4023
                ],
                "is_datetime64_dtype": [
                    4027
                ],
                "is_timedelta64_dtype": [
                    4030
                ],
                "op": [
                    4048,
                    4042
                ],
                "filter_type": [
                    4053
                ],
                "algorithms.take_1d": [
                    4063
                ],
                "align": [
                    4089
                ],
                "join": [
                    4091
                ],
                "limit": [
                    4097,
                    4298,
                    4317
                ],
                "fill_axis": [
                    4098
                ],
                "broadcast_axis": [
                    4099
                ],
                "kwargs.get": [
                    4168,
                    4163,
                    4595
                ],
                "is_dict_like": [
                    4165
                ],
                "rename": [
                    4166
                ],
                "self._set_name": [
                    4168
                ],
                "reindex": [
                    4173
                ],
                "generic.NDFrame.reindex.__doc__": [
                    4171
                ],
                "generic.NDFrame.reindex": [
                    4171
                ],
                "columns": [
                    4275
                ],
                "errors": [
                    4278
                ],
                "fillna": [
                    4293
                ],
                "downcast": [
                    4299
                ],
                "generic.NDFrame.fillna.__doc__": [
                    4282
                ],
                "generic.NDFrame.fillna": [
                    4282
                ],
                "replace": [
                    4313
                ],
                "to_replace": [
                    4314
                ],
                "regex": [
                    4318
                ],
                "shift": [
                    4324
                ],
                "freq": [
                    4763,
                    4325,
                    4787
                ],
                "memory_usage": [
                    4377
                ],
                "deep": [
                    4377,
                    4379
                ],
                "self.index.memory_usage": [
                    4379
                ],
                "algorithms.isin": [
                    4435
                ],
                "inclusive": [
                    4504
                ],
                "lmask": [
                    4505,
                    4508,
                    4511
                ],
                "rmask": [
                    4506,
                    4509,
                    4511
                ],
                "old_names": [
                    4538,
                    4583
                ],
                "maybe_sep": [
                    4568,
                    4579,
                    4566
                ],
                "is_string_like": [
                    4568
                ],
                "pos_args": [
                    4585,
                    4587,
                    4593
                ],
                "names.index": [
                    4591
                ],
                "to_csv": [
                    4606
                ],
                "generic.NDFrame.to_csv.__doc__": [
                    4513
                ],
                "generic.NDFrame.to_csv": [
                    4513
                ],
                "isnull": [
                    4614
                ],
                "notnull": [
                    4622
                ],
                "kwargs.keys": [
                    4700
                ],
                "self._can_hold_na": [
                    4705
                ],
                "self.dropna": [
                    4736
                ],
                "new_values.copy": [
                    4761,
                    4785
                ],
                "self.index.to_timestamp": [
                    4763
                ],
                "self.index.to_period": [
                    4787
                ],
                "CachedAccessor": [
                    4793,
                    4794,
                    4795,
                    4796,
                    4797
                ],
                "StringMethods": [
                    4793
                ],
                "dt": [
                    4794
                ],
                "CombinedDatetimelikeProperties": [
                    4794
                ],
                "cat": [
                    4795
                ],
                "CategoricalAccessor": [
                    4795
                ],
                "plot": [
                    4796
                ],
                "pandas.plotting.PlotAccessor": [
                    4796
                ],
                "pandas.plotting": [
                    4801,
                    4796
                ],
                "pandas": [
                    4801,
                    4796
                ],
                "sparse": [
                    4797
                ],
                "SparseAccessor": [
                    4797
                ],
                "hist": [
                    4801
                ],
                "pandas.plotting.hist_series": [
                    4801
                ],
                "Series._setup_axes": [
                    4804
                ],
                "Series._add_numeric_operations": [
                    4811
                ],
                "Series._add_series_only_operations": [
                    4812
                ],
                "Series._add_series_or_dataframe_operations": [
                    4813
                ],
                "ops.add_flex_arithmetic_methods": [
                    4816
                ],
                "ops.add_special_arithmetic_methods": [
                    4817
                ]
            }
        },
        "test_data": [
            {
                "test_path": "/home/ubuntu/Desktop/bgp_envs_local/repos/pandas_152/pandas/tests/series/test_combine_concat.py",
                "test_function": "test_append_tuples",
                "test_function_code": "    def test_append_tuples(self):\n        # GH 28410\n        s = pd.Series([1, 2, 3])\n        list_input = [s, s]\n        tuple_input = (s, s)\n\n        expected = s.append(list_input)\n        result = s.append(tuple_input)\n\n        tm.assert_series_equal(expected, result)",
                "test_error": "TypeError: can only concatenate list (not \"tuple\") to list",
                "full_test_error": "self = <pandas.tests.series.test_combine_concat.TestSeriesCombine object at 0x7f57cc921610>\n\n    def test_append_tuples(self):\n        # GH 28410\n        s = pd.Series([1, 2, 3])\n        list_input = [s, s]\n        tuple_input = (s, s)\n    \n        expected = s.append(list_input)\n>       result = s.append(tuple_input)\n\npandas/tests/series/test_combine_concat.py:64: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = 0    1\n1    2\n2    3\ndtype: int64\nto_append = (0    1\n1    2\n2    3\ndtype: int64, 0    1\n1    2\n2    3\ndtype: int64)\nignore_index = False, verify_integrity = False\n\n    def append(self, to_append, ignore_index=False, verify_integrity=False):\n        \"\"\"\n        Concatenate two or more Series.\n    \n        Parameters\n        ----------\n        to_append : Series or list/tuple of Series\n            Series to append with self.\n        ignore_index : bool, default False\n            If True, do not use the index labels.\n        verify_integrity : bool, default False\n            If True, raise Exception on creating index with duplicates.\n    \n        Returns\n        -------\n        Series\n            Concatenated Series.\n    \n        See Also\n        --------\n        concat : General function to concatenate DataFrame or Series objects.\n    \n        Notes\n        -----\n        Iteratively appending to a Series can be more computationally intensive\n        than a single concatenate. A better solution is to append values to a\n        list and then concatenate the list with the original Series all at\n        once.\n    \n        Examples\n        --------\n        >>> s1 = pd.Series([1, 2, 3])\n        >>> s2 = pd.Series([4, 5, 6])\n        >>> s3 = pd.Series([4, 5, 6], index=[3, 4, 5])\n        >>> s1.append(s2)\n        0    1\n        1    2\n        2    3\n        0    4\n        1    5\n        2    6\n        dtype: int64\n    \n        >>> s1.append(s3)\n        0    1\n        1    2\n        2    3\n        3    4\n        4    5\n        5    6\n        dtype: int64\n    \n        With `ignore_index` set to True:\n    \n        >>> s1.append(s2, ignore_index=True)\n        0    1\n        1    2\n        2    3\n        3    4\n        4    5\n        5    6\n        dtype: int64\n    \n        With `verify_integrity` set to True:\n    \n        >>> s1.append(s2, verify_integrity=True)\n        Traceback (most recent call last):\n        ...\n        ValueError: Indexes have overlapping values: [0, 1, 2]\n        \"\"\"\n        from pandas.core.reshape.concat import concat\n    \n        if isinstance(to_append, (list, tuple)):\n>           to_concat = [self] + to_append\nE           TypeError: can only concatenate list (not \"tuple\") to list\n\npandas/core/series.py:2733: TypeError",
                "traceback": null,
                "test_error_location": null,
                "test_function_decorators": []
            }
        ]
    }
}