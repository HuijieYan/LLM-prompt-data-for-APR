{
    "1.1.1": "def __init__(\n    self,\n    index,\n    grouper=None,\n    obj=None,\n    name=None,\n    level=None,\n    sort=True,\n    observed=False,\n    in_axis=False,\n):\n\n    self.name = name\n    self.level = level\n    self.grouper = _convert_grouper(index, grouper)\n    self.all_grouper = None\n    self.index = index\n    self.sort = sort\n    self.obj = obj\n    self.observed = observed\n    self.in_axis = in_axis\n\n    # right place for this?\n    if isinstance(grouper, (Series, Index)) and name is None:\n        self.name = grouper.name\n\n    if isinstance(grouper, MultiIndex):\n        self.grouper = grouper.values\n\n    # we have a single grouper which may be a myriad of things,\n    # some of which are dependent on the passing in level\n\n    if level is not None:\n        if not isinstance(level, int):\n            if level not in index.names:\n                raise AssertionError(\"Level {} not in index\".format(level))\n            level = index.names.index(level)\n\n        if self.name is None:\n            self.name = index.names[level]\n\n        self.grouper, self._labels, self._group_index = index._get_grouper_for_level(  # noqa: E501\n            self.grouper, level\n        )\n\n    # a passed Grouper like, directly get the grouper in the same way\n    # as single grouper groupby, use the group_info to get labels\n    elif isinstance(self.grouper, Grouper):\n        # get the new grouper; we already have disambiguated\n        # what key/level refer to exactly, don't need to\n        # check again as we have by this point converted these\n        # to an actual value (rather than a pd.Grouper)\n        _, grouper, _ = self.grouper._get_grouper(self.obj, validate=False)\n        if self.name is None:\n            self.name = grouper.result_index.name\n        self.obj = self.grouper.obj\n        self.grouper = grouper._get_grouper()\n\n    else:\n        if self.grouper is None and self.name is not None:\n            self.grouper = self.obj[self.name]\n\n        elif isinstance(self.grouper, (list, tuple)):\n            self.grouper = com.asarray_tuplesafe(self.grouper)\n\n        # a passed Categorical\n        elif is_categorical_dtype(self.grouper):\n\n            self.grouper, self.all_grouper = recode_for_groupby(\n                self.grouper, self.sort, observed\n            )\n            categories = self.grouper.categories\n\n            # we make a CategoricalIndex out of the cat grouper\n            # preserving the categories / ordered attributes\n            self._labels = self.grouper.codes\n            if observed:\n                codes = algorithms.unique1d(self.grouper.codes)\n                codes = codes[codes != -1]\n                if sort or self.grouper.ordered:\n                    codes = np.sort(codes)\n            else:\n                codes = np.arange(len(categories))\n\n            self._group_index = CategoricalIndex(\n                Categorical.from_codes(\n                    codes=codes, categories=categories, ordered=self.grouper.ordered\n                )\n            )\n\n        # we are done\n        if isinstance(self.grouper, Grouping):\n            self.grouper = self.grouper.grouper\n\n        # no level passed\n        elif not isinstance(\n            self.grouper, (Series, Index, ExtensionArray, np.ndarray)\n        ):\n            if getattr(self.grouper, \"ndim\", 1) != 1:\n                t = self.name or str(type(self.grouper))\n                raise ValueError(\"Grouper for '{}' not 1-dimensional\".format(t))\n            self.grouper = self.index.map(self.grouper)\n            if not (\n                hasattr(self.grouper, \"__len__\")\n                and len(self.grouper) == len(self.index)\n            ):\n                errmsg = (\n                    \"Grouper result violates len(labels) == \"\n                    \"len(data)\\nresult: %s\" % pprint_thing(self.grouper)\n                )\n                self.grouper = None  # Try for sanity\n                raise AssertionError(errmsg)\n\n    # if we have a date/time-like grouper, make sure that we have\n    # Timestamps like\n    if getattr(self.grouper, \"dtype\", None) is not None:\n        if is_datetime64_dtype(self.grouper):\n            self.grouper = self.grouper.astype(\"datetime64[ns]\")\n        elif is_timedelta64_dtype(self.grouper):\n\n            self.grouper = self.grouper.astype(\"timedelta64[ns]\")\n",
    "1.1.2": null,
    "1.2.1": "class Grouping()",
    "1.2.2": "Holds the grouping information for a single key\n\nParameters\n----------\nindex : Index\ngrouper :\nobj :\nname :\nlevel :\nobserved : boolean, default False\n    If we are a Categorical, use the observed values\nin_axis : if the Grouping is a column in self.obj and hence among\n    Groupby.exclusions list\n\nReturns\n-------\n**Attributes**:\n  * indices : dict of {group -> index_list}\n  * labels : ndarray, group labels\n  * ids : mapping of label -> group\n  * counts : array of group counts\n  * group_index : unique groups\n  * groups : dict of {group -> label_list}",
    "1.2.3": [
        "result_index(self)"
    ],
    "1.3.1": "pandas/core/groupby/grouper.py",
    "1.3.2": [
        "_get_grouper(obj: NDFrame, key=None, axis=0, level=None, sort=True, observed=False, mutated=False, validate=True)",
        "_convert_grouper(axis, grouper)",
        "_get_grouper(self, obj, validate=True)",
        "result_index(self)"
    ],
    "1.4.1": [
        "def test_preserve_categories():\n    # GH-13179\n    categories = list(\"abc\")\n\n    # ordered=True\n    df = DataFrame({\"A\": Categorical(list(\"ba\"), categories=categories, ordered=True)})\n    index = CategoricalIndex(categories, categories, ordered=True, name=\"A\")\n    tm.assert_index_equal(\n        df.groupby(\"A\", sort=True, observed=False).first().index, index\n    )\n    tm.assert_index_equal(\n        df.groupby(\"A\", sort=False, observed=False).first().index, index\n    )\n\n    # ordered=False\n    df = DataFrame({\"A\": Categorical(list(\"ba\"), categories=categories, ordered=False)})\n    sort_index = CategoricalIndex(categories, categories, ordered=False, name=\"A\")\n    nosort_index = CategoricalIndex(list(\"bac\"), list(\"bac\"), ordered=False, name=\"A\")\n    tm.assert_index_equal(\n        df.groupby(\"A\", sort=True, observed=False).first().index, sort_index\n    )\n    tm.assert_index_equal(\n        df.groupby(\"A\", sort=False, observed=False).first().index, nosort_index\n    )"
    ],
    "1.4.2": [
        "pandas/tests/groupby/test_categorical.py"
    ],
    "2.1.1": [
        [
            "E       AssertionError: Index are different\nE       \nE       Attribute \"names\" are different\nE       [left]:  [None]\nE       [right]: ['A']"
        ]
    ],
    "2.1.2": [
        [
            "def test_preserve_categories():\n        # GH-13179\n        categories = list(\"abc\")\n    \n        # ordered=True\n        df = DataFrame({\"A\": Categorical(list(\"ba\"), categories=categories, ordered=True)})\n        index = CategoricalIndex(categories, categories, ordered=True, name=\"A\")\n>       tm.assert_index_equal(\n            df.groupby(\"A\", sort=True, observed=False).first().index, index\n        )",
            "\npandas/tests/groupby/test_categorical.py:678: AssertionError"
        ]
    ],
    "2.1.3": null,
    "2.1.4": null,
    "2.1.5": null,
    "2.1.6": null,
    "3.1.1": [
        "DataFrame groupby with categoricals and aggreggation with pd.DataFrame.sum with skipna leads to wrong column name\n"
    ],
    "3.1.2": [
        "Problem description\nConsider the following data frame:\n\ndf = pd.DataFrame(data=(('Bob', 2),  ('Greg', None), ('Greg', 6)), columns=['Name', 'Items'])\n   Name  Items\n0   Bob    2.0\n1  Greg    NaN\n2  Greg    6.0\nNow I want to group by Name and sum the Items, but I want the sum to be NaN if there are NaN elements. Due to a bug in pandas (#20824) I cannot simply do\n\ndf.groupby('Name', observed=True).sum(skipna=False).reset_index()\nbecause that results in:\n\n   Name  Items\n0   Bob    2.0\n1  Greg    6.0\nwhich is wrong because it's skipping the NaN for Greg even though it shouldn't (hence the bug). Thus I'm using the following workaround to get the correct result:\n\ndf.groupby('Name', observed=True).agg(pd.DataFrame.sum, skipna=False).reset_index()\nwhich results in the expected:\n\n   Name  Items\n0   Bob    2.0\n1  Greg    NaN\nHowever, if we change the Name column to categorical then the resulting column names are wrong:\n\ndf_cat = df.copy()\ndf_cat['Name'] = df_cat['Name'].astype('category')\ndf_cat.groupby('Name', observed=True).agg(pd.DataFrame.sum, skipna=False).reset_index()\nwhich prints:\n\n  index  Items\n0   Bob    2.0\n1  Greg    NaN\nAs you can see, the column that should be labelled Name is now called index.\n\nExpected Output\nThe same as the non-categorical version, i.e.:\n\n   Name  Items\n0   Bob    2.0\n1  Greg    NaN\n"
    ],
    "used_imports": "import numpy as np\nfrom pandas.core.dtypes.common import ensure_categorical, is_categorical_dtype, is_datetime64_dtype, is_hashable, is_list_like, is_scalar, is_timedelta64_dtype\nimport pandas.core.algorithms as algorithms\nfrom pandas.core.arrays import Categorical, ExtensionArray\nimport pandas.core.common as com\nfrom pandas.core.groupby.categorical import recode_for_groupby, recode_from_groupby\nfrom pandas.core.index import CategoricalIndex, Index, MultiIndex\nfrom pandas.core.series import Series\nfrom pandas.io.formats.printing import pprint_thing"
}