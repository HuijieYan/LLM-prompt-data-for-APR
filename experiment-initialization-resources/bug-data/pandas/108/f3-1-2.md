The issue description is:

```text
Code Sample, a copy-pastable example if possible
In [1]: import pandas as pd; pd.__version__
Out[1]: '0.26.0.dev0+1348.g18bd98fde'

In [2]: from pandas.core.dtypes.cast import infer_dtype_from_scalar

In [3]: # this is fine 
   ...: infer_dtype_from_scalar(pd.Interval(0, 1), pandas_dtype=False)
Out[3]: (numpy.object_, Interval(0, 1, closed='right'))

In [4]: # this is should infer interval[int64] as dtype 
   ...: infer_dtype_from_scalar(pd.Interval(0, 1), pandas_dtype=True)
Out[4]: (numpy.object_, Interval(0, 1, closed='right'))
Problem description
infer_dtype_from_scalar with pandas_dtype=True infers the dtype for Interval objects as np.object_ instead of as an IntervalDtype.

Expected Output
I'd expect Out[4] to have the dtype as IntervalDtype(subtype=np.int64).
```
