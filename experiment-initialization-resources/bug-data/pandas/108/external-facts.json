{
    "pandas:108": {
        "github_issue_title": [
            "BUG: infer_dtype_from_scalar with pandas_dtype=True doesn't infer IntervalDtype\n"
        ],
        "github_issue_description": [
            "Code Sample, a copy-pastable example if possible\nIn [1]: import pandas as pd; pd.__version__\nOut[1]: '0.26.0.dev0+1348.g18bd98fde'\n\nIn [2]: from pandas.core.dtypes.cast import infer_dtype_from_scalar\n\nIn [3]: # this is fine \n   ...: infer_dtype_from_scalar(pd.Interval(0, 1), pandas_dtype=False)\nOut[3]: (numpy.object_, Interval(0, 1, closed='right'))\n\nIn [4]: # this is should infer interval[int64] as dtype \n   ...: infer_dtype_from_scalar(pd.Interval(0, 1), pandas_dtype=True)\nOut[4]: (numpy.object_, Interval(0, 1, closed='right'))\nProblem description\ninfer_dtype_from_scalar with pandas_dtype=True infers the dtype for Interval objects as np.object_ instead of as an IntervalDtype.\n\nExpected Output\nI'd expect Out[4] to have the dtype as IntervalDtype(subtype=np.int64).\n"
        ]
    }
}